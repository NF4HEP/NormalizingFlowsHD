2023-09-11 15:43:24.734563: Importing os...
2023-09-11 15:43:24.734619: Importing sys...
2023-09-11 15:43:24.734632: Importing and initializing argparse...
Visible devices: [0]
2023-09-11 15:43:24.749770: Importing timer from timeit...
2023-09-11 15:43:24.750314: Setting env variables for tf import (only device [0] will be available)...
2023-09-11 15:43:24.750355: Importing numpy...
2023-09-11 15:43:24.916654: Importing pandas...
2023-09-11 15:43:25.120059: Importing shutil...
2023-09-11 15:43:25.120101: Importing subprocess...
2023-09-11 15:43:25.120110: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-11 15:43:27.408326: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-11 15:43:27.793870: Importing textwrap...
2023-09-11 15:43:27.793897: Importing timeit...
2023-09-11 15:43:27.793906: Importing traceback...
2023-09-11 15:43:27.793912: Importing typing...
2023-09-11 15:43:27.793924: Setting tf configs...
2023-09-11 15:43:27.922570: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-11 15:43:29.105307: All modues imported successfully.
Directory ../../results/MsplineN_new/ already exists.
Directory ../../results/MsplineN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

===========
Generating train data for run 5.
===========
Train data generated in 0.23 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_5/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_5/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.2196093,  5.415999 ,  5.1861906,  9.223731 ],
       [ 4.2166486,  7.997426 ,  3.7183957,  8.691994 ],
       [ 4.2201977,  5.41213  ,  5.165699 ,  6.781624 ],
       ...,
       [ 4.231148 ,  6.137215 ,  4.657408 ,  8.099412 ],
       [10.88508  ,  3.984882 ,  8.564816 ,  6.3276396],
       [ 5.928621 ,  9.245907 ,  5.9987693,  5.5968986]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_5/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_5
self.data_kwargs: {'seed': 187}
self.x_data: [[ 4.226144   6.082265   2.6696188  8.70979  ]
 [ 4.2487636  4.8672433  6.252268  10.323003 ]
 [ 4.2390804  7.2450333  4.335793   9.892357 ]
 ...
 [ 4.2721004  6.6043315  4.0861077  9.4028015]
 [ 4.242672   5.281375   4.456547   8.21444  ]
 [ 4.24792    8.1837225  3.1614475 10.065343 ]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 4)]               0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  91064     
 r)                                                              
                                                                 
=================================================================
Total params: 91,064
Trainable params: 91,064
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7fc9e72bd090>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc9cc172170>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc9cc172170>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc9cc172a40>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc9cc173700>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc9cc173c70>, <keras.callbacks.ModelCheckpoint object at 0x7fc9cc173dc0>, <keras.callbacks.EarlyStopping object at 0x7fc9cc173fd0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc9cc173fa0>, <keras.callbacks.TerminateOnNaN object at 0x7fc9cc173d30>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.2196093,  5.415999 ,  5.1861906,  9.223731 ],
       [ 4.2166486,  7.997426 ,  3.7183957,  8.691994 ],
       [ 4.2201977,  5.41213  ,  5.165699 ,  6.781624 ],
       ...,
       [ 4.231148 ,  6.137215 ,  4.657408 ,  8.099412 ],
       [10.88508  ,  3.984882 ,  8.564816 ,  6.3276396],
       [ 5.928621 ,  9.245907 ,  5.9987693,  5.5968986]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_5/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 5/360 with hyperparameters:
timestamp = 2023-09-11 15:43:31.638542
ndims = 4
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 91064
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.226144  6.082265  2.6696188 8.70979  ]
Epoch 1/1000
2023-09-11 15:44:03.277 
Epoch 1/1000 
	 loss: 7.3572, MinusLogProbMetric: 7.3572, val_loss: 3.0983, val_MinusLogProbMetric: 3.0983

Epoch 1: val_loss improved from inf to 3.09827, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 32s - loss: 7.3572 - MinusLogProbMetric: 7.3572 - val_loss: 3.0983 - val_MinusLogProbMetric: 3.0983 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 2/1000
2023-09-11 15:44:14.809 
Epoch 2/1000 
	 loss: 2.9584, MinusLogProbMetric: 2.9584, val_loss: 2.9605, val_MinusLogProbMetric: 2.9605

Epoch 2: val_loss improved from 3.09827 to 2.96047, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.9584 - MinusLogProbMetric: 2.9584 - val_loss: 2.9605 - val_MinusLogProbMetric: 2.9605 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 3/1000
2023-09-11 15:44:25.565 
Epoch 3/1000 
	 loss: 2.7469, MinusLogProbMetric: 2.7469, val_loss: 2.6663, val_MinusLogProbMetric: 2.6663

Epoch 3: val_loss improved from 2.96047 to 2.66628, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 11s - loss: 2.7469 - MinusLogProbMetric: 2.7469 - val_loss: 2.6663 - val_MinusLogProbMetric: 2.6663 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 4/1000
2023-09-11 15:44:37.261 
Epoch 4/1000 
	 loss: 2.7074, MinusLogProbMetric: 2.7074, val_loss: 2.6299, val_MinusLogProbMetric: 2.6299

Epoch 4: val_loss improved from 2.66628 to 2.62990, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.7074 - MinusLogProbMetric: 2.7074 - val_loss: 2.6299 - val_MinusLogProbMetric: 2.6299 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-11 15:44:49.120 
Epoch 5/1000 
	 loss: 2.6438, MinusLogProbMetric: 2.6438, val_loss: 2.6177, val_MinusLogProbMetric: 2.6177

Epoch 5: val_loss improved from 2.62990 to 2.61767, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.6438 - MinusLogProbMetric: 2.6438 - val_loss: 2.6177 - val_MinusLogProbMetric: 2.6177 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 6/1000
2023-09-11 15:45:01.047 
Epoch 6/1000 
	 loss: 2.6237, MinusLogProbMetric: 2.6237, val_loss: 2.6458, val_MinusLogProbMetric: 2.6458

Epoch 6: val_loss did not improve from 2.61767
196/196 - 12s - loss: 2.6237 - MinusLogProbMetric: 2.6237 - val_loss: 2.6458 - val_MinusLogProbMetric: 2.6458 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-11 15:45:12.836 
Epoch 7/1000 
	 loss: 2.6008, MinusLogProbMetric: 2.6008, val_loss: 2.6076, val_MinusLogProbMetric: 2.6076

Epoch 7: val_loss improved from 2.61767 to 2.60759, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.6008 - MinusLogProbMetric: 2.6008 - val_loss: 2.6076 - val_MinusLogProbMetric: 2.6076 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 8/1000
2023-09-11 15:45:24.520 
Epoch 8/1000 
	 loss: 2.5793, MinusLogProbMetric: 2.5793, val_loss: 2.6153, val_MinusLogProbMetric: 2.6153

Epoch 8: val_loss did not improve from 2.60759
196/196 - 12s - loss: 2.5793 - MinusLogProbMetric: 2.5793 - val_loss: 2.6153 - val_MinusLogProbMetric: 2.6153 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 9/1000
2023-09-11 15:45:36.099 
Epoch 9/1000 
	 loss: 2.5525, MinusLogProbMetric: 2.5525, val_loss: 2.5041, val_MinusLogProbMetric: 2.5041

Epoch 9: val_loss improved from 2.60759 to 2.50414, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.5525 - MinusLogProbMetric: 2.5525 - val_loss: 2.5041 - val_MinusLogProbMetric: 2.5041 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 10/1000
2023-09-11 15:45:47.879 
Epoch 10/1000 
	 loss: 2.5498, MinusLogProbMetric: 2.5498, val_loss: 2.6111, val_MinusLogProbMetric: 2.6111

Epoch 10: val_loss did not improve from 2.50414
196/196 - 12s - loss: 2.5498 - MinusLogProbMetric: 2.5498 - val_loss: 2.6111 - val_MinusLogProbMetric: 2.6111 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-11 15:45:59.351 
Epoch 11/1000 
	 loss: 2.5595, MinusLogProbMetric: 2.5595, val_loss: 2.5054, val_MinusLogProbMetric: 2.5054

Epoch 11: val_loss did not improve from 2.50414
196/196 - 11s - loss: 2.5595 - MinusLogProbMetric: 2.5595 - val_loss: 2.5054 - val_MinusLogProbMetric: 2.5054 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 12/1000
2023-09-11 15:46:10.910 
Epoch 12/1000 
	 loss: 2.5310, MinusLogProbMetric: 2.5310, val_loss: 2.4970, val_MinusLogProbMetric: 2.4970

Epoch 12: val_loss improved from 2.50414 to 2.49704, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.5310 - MinusLogProbMetric: 2.5310 - val_loss: 2.4970 - val_MinusLogProbMetric: 2.4970 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 13/1000
2023-09-11 15:46:22.592 
Epoch 13/1000 
	 loss: 2.5080, MinusLogProbMetric: 2.5080, val_loss: 2.4704, val_MinusLogProbMetric: 2.4704

Epoch 13: val_loss improved from 2.49704 to 2.47044, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.5080 - MinusLogProbMetric: 2.5080 - val_loss: 2.4704 - val_MinusLogProbMetric: 2.4704 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-11 15:46:34.358 
Epoch 14/1000 
	 loss: 2.5075, MinusLogProbMetric: 2.5075, val_loss: 2.4971, val_MinusLogProbMetric: 2.4971

Epoch 14: val_loss did not improve from 2.47044
196/196 - 12s - loss: 2.5075 - MinusLogProbMetric: 2.5075 - val_loss: 2.4971 - val_MinusLogProbMetric: 2.4971 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-11 15:46:46.027 
Epoch 15/1000 
	 loss: 2.4988, MinusLogProbMetric: 2.4988, val_loss: 2.5101, val_MinusLogProbMetric: 2.5101

Epoch 15: val_loss did not improve from 2.47044
196/196 - 12s - loss: 2.4988 - MinusLogProbMetric: 2.4988 - val_loss: 2.5101 - val_MinusLogProbMetric: 2.5101 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 16/1000
2023-09-11 15:46:57.691 
Epoch 16/1000 
	 loss: 2.4790, MinusLogProbMetric: 2.4790, val_loss: 2.5401, val_MinusLogProbMetric: 2.5401

Epoch 16: val_loss did not improve from 2.47044
196/196 - 12s - loss: 2.4790 - MinusLogProbMetric: 2.4790 - val_loss: 2.5401 - val_MinusLogProbMetric: 2.5401 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 17/1000
2023-09-11 15:47:09.317 
Epoch 17/1000 
	 loss: 2.4905, MinusLogProbMetric: 2.4905, val_loss: 2.4991, val_MinusLogProbMetric: 2.4991

Epoch 17: val_loss did not improve from 2.47044
196/196 - 12s - loss: 2.4905 - MinusLogProbMetric: 2.4905 - val_loss: 2.4991 - val_MinusLogProbMetric: 2.4991 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 18/1000
2023-09-11 15:47:20.906 
Epoch 18/1000 
	 loss: 2.4845, MinusLogProbMetric: 2.4845, val_loss: 2.4830, val_MinusLogProbMetric: 2.4830

Epoch 18: val_loss did not improve from 2.47044
196/196 - 12s - loss: 2.4845 - MinusLogProbMetric: 2.4845 - val_loss: 2.4830 - val_MinusLogProbMetric: 2.4830 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 19/1000
2023-09-11 15:47:32.529 
Epoch 19/1000 
	 loss: 2.4921, MinusLogProbMetric: 2.4921, val_loss: 2.4657, val_MinusLogProbMetric: 2.4657

Epoch 19: val_loss improved from 2.47044 to 2.46569, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4921 - MinusLogProbMetric: 2.4921 - val_loss: 2.4657 - val_MinusLogProbMetric: 2.4657 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-11 15:47:44.318 
Epoch 20/1000 
	 loss: 2.4685, MinusLogProbMetric: 2.4685, val_loss: 2.4410, val_MinusLogProbMetric: 2.4410

Epoch 20: val_loss improved from 2.46569 to 2.44096, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4685 - MinusLogProbMetric: 2.4685 - val_loss: 2.4410 - val_MinusLogProbMetric: 2.4410 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 21/1000
2023-09-11 15:47:56.139 
Epoch 21/1000 
	 loss: 2.4721, MinusLogProbMetric: 2.4721, val_loss: 2.4660, val_MinusLogProbMetric: 2.4660

Epoch 21: val_loss did not improve from 2.44096
196/196 - 12s - loss: 2.4721 - MinusLogProbMetric: 2.4721 - val_loss: 2.4660 - val_MinusLogProbMetric: 2.4660 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 22/1000
2023-09-11 15:48:07.580 
Epoch 22/1000 
	 loss: 2.4695, MinusLogProbMetric: 2.4695, val_loss: 2.4411, val_MinusLogProbMetric: 2.4411

Epoch 22: val_loss did not improve from 2.44096
196/196 - 11s - loss: 2.4695 - MinusLogProbMetric: 2.4695 - val_loss: 2.4411 - val_MinusLogProbMetric: 2.4411 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 23/1000
2023-09-11 15:48:19.308 
Epoch 23/1000 
	 loss: 2.4606, MinusLogProbMetric: 2.4606, val_loss: 2.4943, val_MinusLogProbMetric: 2.4943

Epoch 23: val_loss did not improve from 2.44096
196/196 - 12s - loss: 2.4606 - MinusLogProbMetric: 2.4606 - val_loss: 2.4943 - val_MinusLogProbMetric: 2.4943 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-11 15:48:31.040 
Epoch 24/1000 
	 loss: 2.4622, MinusLogProbMetric: 2.4622, val_loss: 2.4274, val_MinusLogProbMetric: 2.4274

Epoch 24: val_loss improved from 2.44096 to 2.42742, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4622 - MinusLogProbMetric: 2.4622 - val_loss: 2.4274 - val_MinusLogProbMetric: 2.4274 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-11 15:48:42.775 
Epoch 25/1000 
	 loss: 2.4573, MinusLogProbMetric: 2.4573, val_loss: 2.4443, val_MinusLogProbMetric: 2.4443

Epoch 25: val_loss did not improve from 2.42742
196/196 - 12s - loss: 2.4573 - MinusLogProbMetric: 2.4573 - val_loss: 2.4443 - val_MinusLogProbMetric: 2.4443 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 26/1000
2023-09-11 15:48:54.349 
Epoch 26/1000 
	 loss: 2.4634, MinusLogProbMetric: 2.4634, val_loss: 2.4078, val_MinusLogProbMetric: 2.4078

Epoch 26: val_loss improved from 2.42742 to 2.40778, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4634 - MinusLogProbMetric: 2.4634 - val_loss: 2.4078 - val_MinusLogProbMetric: 2.4078 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-11 15:49:06.156 
Epoch 27/1000 
	 loss: 2.4605, MinusLogProbMetric: 2.4605, val_loss: 2.4183, val_MinusLogProbMetric: 2.4183

Epoch 27: val_loss did not improve from 2.40778
196/196 - 12s - loss: 2.4605 - MinusLogProbMetric: 2.4605 - val_loss: 2.4183 - val_MinusLogProbMetric: 2.4183 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-11 15:49:17.716 
Epoch 28/1000 
	 loss: 2.4478, MinusLogProbMetric: 2.4478, val_loss: 2.4413, val_MinusLogProbMetric: 2.4413

Epoch 28: val_loss did not improve from 2.40778
196/196 - 12s - loss: 2.4478 - MinusLogProbMetric: 2.4478 - val_loss: 2.4413 - val_MinusLogProbMetric: 2.4413 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-11 15:49:29.536 
Epoch 29/1000 
	 loss: 2.4405, MinusLogProbMetric: 2.4405, val_loss: 2.4563, val_MinusLogProbMetric: 2.4563

Epoch 29: val_loss did not improve from 2.40778
196/196 - 12s - loss: 2.4405 - MinusLogProbMetric: 2.4405 - val_loss: 2.4563 - val_MinusLogProbMetric: 2.4563 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 30/1000
2023-09-11 15:49:41.215 
Epoch 30/1000 
	 loss: 2.4453, MinusLogProbMetric: 2.4453, val_loss: 2.4434, val_MinusLogProbMetric: 2.4434

Epoch 30: val_loss did not improve from 2.40778
196/196 - 12s - loss: 2.4453 - MinusLogProbMetric: 2.4453 - val_loss: 2.4434 - val_MinusLogProbMetric: 2.4434 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-11 15:49:52.975 
Epoch 31/1000 
	 loss: 2.4428, MinusLogProbMetric: 2.4428, val_loss: 2.4219, val_MinusLogProbMetric: 2.4219

Epoch 31: val_loss did not improve from 2.40778
196/196 - 12s - loss: 2.4428 - MinusLogProbMetric: 2.4428 - val_loss: 2.4219 - val_MinusLogProbMetric: 2.4219 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-11 15:50:04.630 
Epoch 32/1000 
	 loss: 2.4400, MinusLogProbMetric: 2.4400, val_loss: 2.4103, val_MinusLogProbMetric: 2.4103

Epoch 32: val_loss did not improve from 2.40778
196/196 - 12s - loss: 2.4400 - MinusLogProbMetric: 2.4400 - val_loss: 2.4103 - val_MinusLogProbMetric: 2.4103 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 33/1000
2023-09-11 15:50:16.515 
Epoch 33/1000 
	 loss: 2.4373, MinusLogProbMetric: 2.4373, val_loss: 2.4060, val_MinusLogProbMetric: 2.4060

Epoch 33: val_loss improved from 2.40778 to 2.40603, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4373 - MinusLogProbMetric: 2.4373 - val_loss: 2.4060 - val_MinusLogProbMetric: 2.4060 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 34/1000
2023-09-11 15:50:28.365 
Epoch 34/1000 
	 loss: 2.4383, MinusLogProbMetric: 2.4383, val_loss: 2.4116, val_MinusLogProbMetric: 2.4116

Epoch 34: val_loss did not improve from 2.40603
196/196 - 12s - loss: 2.4383 - MinusLogProbMetric: 2.4383 - val_loss: 2.4116 - val_MinusLogProbMetric: 2.4116 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-11 15:50:40.240 
Epoch 35/1000 
	 loss: 2.4315, MinusLogProbMetric: 2.4315, val_loss: 2.4383, val_MinusLogProbMetric: 2.4383

Epoch 35: val_loss did not improve from 2.40603
196/196 - 12s - loss: 2.4315 - MinusLogProbMetric: 2.4315 - val_loss: 2.4383 - val_MinusLogProbMetric: 2.4383 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 36/1000
2023-09-11 15:50:51.932 
Epoch 36/1000 
	 loss: 2.4448, MinusLogProbMetric: 2.4448, val_loss: 2.4044, val_MinusLogProbMetric: 2.4044

Epoch 36: val_loss improved from 2.40603 to 2.40435, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4448 - MinusLogProbMetric: 2.4448 - val_loss: 2.4044 - val_MinusLogProbMetric: 2.4044 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-11 15:51:03.765 
Epoch 37/1000 
	 loss: 2.4397, MinusLogProbMetric: 2.4397, val_loss: 2.4366, val_MinusLogProbMetric: 2.4366

Epoch 37: val_loss did not improve from 2.40435
196/196 - 12s - loss: 2.4397 - MinusLogProbMetric: 2.4397 - val_loss: 2.4366 - val_MinusLogProbMetric: 2.4366 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 38/1000
2023-09-11 15:51:15.641 
Epoch 38/1000 
	 loss: 2.4291, MinusLogProbMetric: 2.4291, val_loss: 2.3917, val_MinusLogProbMetric: 2.3917

Epoch 38: val_loss improved from 2.40435 to 2.39168, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4291 - MinusLogProbMetric: 2.4291 - val_loss: 2.3917 - val_MinusLogProbMetric: 2.3917 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 39/1000
2023-09-11 15:51:27.522 
Epoch 39/1000 
	 loss: 2.4279, MinusLogProbMetric: 2.4279, val_loss: 2.4223, val_MinusLogProbMetric: 2.4223

Epoch 39: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4279 - MinusLogProbMetric: 2.4279 - val_loss: 2.4223 - val_MinusLogProbMetric: 2.4223 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-11 15:51:39.407 
Epoch 40/1000 
	 loss: 2.4249, MinusLogProbMetric: 2.4249, val_loss: 2.4625, val_MinusLogProbMetric: 2.4625

Epoch 40: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4249 - MinusLogProbMetric: 2.4249 - val_loss: 2.4625 - val_MinusLogProbMetric: 2.4625 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 41/1000
2023-09-11 15:51:51.057 
Epoch 41/1000 
	 loss: 2.4315, MinusLogProbMetric: 2.4315, val_loss: 2.4905, val_MinusLogProbMetric: 2.4905

Epoch 41: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4315 - MinusLogProbMetric: 2.4315 - val_loss: 2.4905 - val_MinusLogProbMetric: 2.4905 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 42/1000
2023-09-11 15:52:02.731 
Epoch 42/1000 
	 loss: 2.4378, MinusLogProbMetric: 2.4378, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 42: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4378 - MinusLogProbMetric: 2.4378 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-11 15:52:14.502 
Epoch 43/1000 
	 loss: 2.4297, MinusLogProbMetric: 2.4297, val_loss: 2.4262, val_MinusLogProbMetric: 2.4262

Epoch 43: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4297 - MinusLogProbMetric: 2.4297 - val_loss: 2.4262 - val_MinusLogProbMetric: 2.4262 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 44/1000
2023-09-11 15:52:26.228 
Epoch 44/1000 
	 loss: 2.4307, MinusLogProbMetric: 2.4307, val_loss: 2.4049, val_MinusLogProbMetric: 2.4049

Epoch 44: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4307 - MinusLogProbMetric: 2.4307 - val_loss: 2.4049 - val_MinusLogProbMetric: 2.4049 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-11 15:52:37.937 
Epoch 45/1000 
	 loss: 2.4263, MinusLogProbMetric: 2.4263, val_loss: 2.4181, val_MinusLogProbMetric: 2.4181

Epoch 45: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4263 - MinusLogProbMetric: 2.4263 - val_loss: 2.4181 - val_MinusLogProbMetric: 2.4181 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-11 15:52:49.795 
Epoch 46/1000 
	 loss: 2.4240, MinusLogProbMetric: 2.4240, val_loss: 2.4993, val_MinusLogProbMetric: 2.4993

Epoch 46: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4240 - MinusLogProbMetric: 2.4240 - val_loss: 2.4993 - val_MinusLogProbMetric: 2.4993 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 47/1000
2023-09-11 15:53:01.543 
Epoch 47/1000 
	 loss: 2.4263, MinusLogProbMetric: 2.4263, val_loss: 2.3920, val_MinusLogProbMetric: 2.3920

Epoch 47: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4263 - MinusLogProbMetric: 2.4263 - val_loss: 2.3920 - val_MinusLogProbMetric: 2.3920 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-11 15:53:13.262 
Epoch 48/1000 
	 loss: 2.4184, MinusLogProbMetric: 2.4184, val_loss: 2.4493, val_MinusLogProbMetric: 2.4493

Epoch 48: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4184 - MinusLogProbMetric: 2.4184 - val_loss: 2.4493 - val_MinusLogProbMetric: 2.4493 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-11 15:53:25.128 
Epoch 49/1000 
	 loss: 2.4204, MinusLogProbMetric: 2.4204, val_loss: 2.4079, val_MinusLogProbMetric: 2.4079

Epoch 49: val_loss did not improve from 2.39168
196/196 - 12s - loss: 2.4204 - MinusLogProbMetric: 2.4204 - val_loss: 2.4079 - val_MinusLogProbMetric: 2.4079 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 50/1000
2023-09-11 15:53:36.956 
Epoch 50/1000 
	 loss: 2.4190, MinusLogProbMetric: 2.4190, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 50: val_loss improved from 2.39168 to 2.38859, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4190 - MinusLogProbMetric: 2.4190 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 51/1000
2023-09-11 15:53:48.841 
Epoch 51/1000 
	 loss: 2.4123, MinusLogProbMetric: 2.4123, val_loss: 2.4286, val_MinusLogProbMetric: 2.4286

Epoch 51: val_loss did not improve from 2.38859
196/196 - 12s - loss: 2.4123 - MinusLogProbMetric: 2.4123 - val_loss: 2.4286 - val_MinusLogProbMetric: 2.4286 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-11 15:54:00.627 
Epoch 52/1000 
	 loss: 2.4167, MinusLogProbMetric: 2.4167, val_loss: 2.3795, val_MinusLogProbMetric: 2.3795

Epoch 52: val_loss improved from 2.38859 to 2.37949, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4167 - MinusLogProbMetric: 2.4167 - val_loss: 2.3795 - val_MinusLogProbMetric: 2.3795 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 53/1000
2023-09-11 15:54:12.476 
Epoch 53/1000 
	 loss: 2.4158, MinusLogProbMetric: 2.4158, val_loss: 2.3872, val_MinusLogProbMetric: 2.3872

Epoch 53: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4158 - MinusLogProbMetric: 2.4158 - val_loss: 2.3872 - val_MinusLogProbMetric: 2.3872 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-11 15:54:24.114 
Epoch 54/1000 
	 loss: 2.4160, MinusLogProbMetric: 2.4160, val_loss: 2.4676, val_MinusLogProbMetric: 2.4676

Epoch 54: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4160 - MinusLogProbMetric: 2.4160 - val_loss: 2.4676 - val_MinusLogProbMetric: 2.4676 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 55/1000
2023-09-11 15:54:35.970 
Epoch 55/1000 
	 loss: 2.4162, MinusLogProbMetric: 2.4162, val_loss: 2.3984, val_MinusLogProbMetric: 2.3984

Epoch 55: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4162 - MinusLogProbMetric: 2.4162 - val_loss: 2.3984 - val_MinusLogProbMetric: 2.3984 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-11 15:54:47.817 
Epoch 56/1000 
	 loss: 2.4234, MinusLogProbMetric: 2.4234, val_loss: 2.4788, val_MinusLogProbMetric: 2.4788

Epoch 56: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4234 - MinusLogProbMetric: 2.4234 - val_loss: 2.4788 - val_MinusLogProbMetric: 2.4788 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-11 15:54:59.556 
Epoch 57/1000 
	 loss: 2.4225, MinusLogProbMetric: 2.4225, val_loss: 2.3838, val_MinusLogProbMetric: 2.3838

Epoch 57: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4225 - MinusLogProbMetric: 2.4225 - val_loss: 2.3838 - val_MinusLogProbMetric: 2.3838 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-11 15:55:11.264 
Epoch 58/1000 
	 loss: 2.4174, MinusLogProbMetric: 2.4174, val_loss: 2.4500, val_MinusLogProbMetric: 2.4500

Epoch 58: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4174 - MinusLogProbMetric: 2.4174 - val_loss: 2.4500 - val_MinusLogProbMetric: 2.4500 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-11 15:55:22.966 
Epoch 59/1000 
	 loss: 2.4127, MinusLogProbMetric: 2.4127, val_loss: 2.4256, val_MinusLogProbMetric: 2.4256

Epoch 59: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4127 - MinusLogProbMetric: 2.4127 - val_loss: 2.4256 - val_MinusLogProbMetric: 2.4256 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-11 15:55:34.679 
Epoch 60/1000 
	 loss: 2.4111, MinusLogProbMetric: 2.4111, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 60: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4111 - MinusLogProbMetric: 2.4111 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-11 15:55:46.427 
Epoch 61/1000 
	 loss: 2.4073, MinusLogProbMetric: 2.4073, val_loss: 2.3797, val_MinusLogProbMetric: 2.3797

Epoch 61: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4073 - MinusLogProbMetric: 2.4073 - val_loss: 2.3797 - val_MinusLogProbMetric: 2.3797 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-11 15:55:58.118 
Epoch 62/1000 
	 loss: 2.4060, MinusLogProbMetric: 2.4060, val_loss: 2.3949, val_MinusLogProbMetric: 2.3949

Epoch 62: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4060 - MinusLogProbMetric: 2.4060 - val_loss: 2.3949 - val_MinusLogProbMetric: 2.3949 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-11 15:56:09.665 
Epoch 63/1000 
	 loss: 2.4063, MinusLogProbMetric: 2.4063, val_loss: 2.4222, val_MinusLogProbMetric: 2.4222

Epoch 63: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4063 - MinusLogProbMetric: 2.4063 - val_loss: 2.4222 - val_MinusLogProbMetric: 2.4222 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 64/1000
2023-09-11 15:56:21.400 
Epoch 64/1000 
	 loss: 2.4152, MinusLogProbMetric: 2.4152, val_loss: 2.4353, val_MinusLogProbMetric: 2.4353

Epoch 64: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4152 - MinusLogProbMetric: 2.4152 - val_loss: 2.4353 - val_MinusLogProbMetric: 2.4353 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-11 15:56:33.102 
Epoch 65/1000 
	 loss: 2.4171, MinusLogProbMetric: 2.4171, val_loss: 2.4083, val_MinusLogProbMetric: 2.4083

Epoch 65: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4171 - MinusLogProbMetric: 2.4171 - val_loss: 2.4083 - val_MinusLogProbMetric: 2.4083 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-11 15:56:44.798 
Epoch 66/1000 
	 loss: 2.4053, MinusLogProbMetric: 2.4053, val_loss: 2.3981, val_MinusLogProbMetric: 2.3981

Epoch 66: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4053 - MinusLogProbMetric: 2.4053 - val_loss: 2.3981 - val_MinusLogProbMetric: 2.3981 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-11 15:56:56.302 
Epoch 67/1000 
	 loss: 2.4050, MinusLogProbMetric: 2.4050, val_loss: 2.4275, val_MinusLogProbMetric: 2.4275

Epoch 67: val_loss did not improve from 2.37949
196/196 - 11s - loss: 2.4050 - MinusLogProbMetric: 2.4050 - val_loss: 2.4275 - val_MinusLogProbMetric: 2.4275 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 68/1000
2023-09-11 15:57:08.059 
Epoch 68/1000 
	 loss: 2.4075, MinusLogProbMetric: 2.4075, val_loss: 2.3977, val_MinusLogProbMetric: 2.3977

Epoch 68: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4075 - MinusLogProbMetric: 2.4075 - val_loss: 2.3977 - val_MinusLogProbMetric: 2.3977 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-11 15:57:19.758 
Epoch 69/1000 
	 loss: 2.4105, MinusLogProbMetric: 2.4105, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 69: val_loss did not improve from 2.37949
196/196 - 12s - loss: 2.4105 - MinusLogProbMetric: 2.4105 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-11 15:57:31.448 
Epoch 70/1000 
	 loss: 2.4090, MinusLogProbMetric: 2.4090, val_loss: 2.3771, val_MinusLogProbMetric: 2.3771

Epoch 70: val_loss improved from 2.37949 to 2.37714, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4090 - MinusLogProbMetric: 2.4090 - val_loss: 2.3771 - val_MinusLogProbMetric: 2.3771 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-11 15:57:43.418 
Epoch 71/1000 
	 loss: 2.4108, MinusLogProbMetric: 2.4108, val_loss: 2.4156, val_MinusLogProbMetric: 2.4156

Epoch 71: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4108 - MinusLogProbMetric: 2.4108 - val_loss: 2.4156 - val_MinusLogProbMetric: 2.4156 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-11 15:57:55.268 
Epoch 72/1000 
	 loss: 2.4096, MinusLogProbMetric: 2.4096, val_loss: 2.4059, val_MinusLogProbMetric: 2.4059

Epoch 72: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4096 - MinusLogProbMetric: 2.4096 - val_loss: 2.4059 - val_MinusLogProbMetric: 2.4059 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-11 15:58:07.034 
Epoch 73/1000 
	 loss: 2.4020, MinusLogProbMetric: 2.4020, val_loss: 2.4298, val_MinusLogProbMetric: 2.4298

Epoch 73: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4020 - MinusLogProbMetric: 2.4020 - val_loss: 2.4298 - val_MinusLogProbMetric: 2.4298 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-11 15:58:18.754 
Epoch 74/1000 
	 loss: 2.4115, MinusLogProbMetric: 2.4115, val_loss: 2.3800, val_MinusLogProbMetric: 2.3800

Epoch 74: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4115 - MinusLogProbMetric: 2.4115 - val_loss: 2.3800 - val_MinusLogProbMetric: 2.3800 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-11 15:58:30.552 
Epoch 75/1000 
	 loss: 2.4073, MinusLogProbMetric: 2.4073, val_loss: 2.4154, val_MinusLogProbMetric: 2.4154

Epoch 75: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4073 - MinusLogProbMetric: 2.4073 - val_loss: 2.4154 - val_MinusLogProbMetric: 2.4154 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-11 15:58:42.348 
Epoch 76/1000 
	 loss: 2.4108, MinusLogProbMetric: 2.4108, val_loss: 2.3821, val_MinusLogProbMetric: 2.3821

Epoch 76: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4108 - MinusLogProbMetric: 2.4108 - val_loss: 2.3821 - val_MinusLogProbMetric: 2.3821 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-11 15:58:54.021 
Epoch 77/1000 
	 loss: 2.4019, MinusLogProbMetric: 2.4019, val_loss: 2.4172, val_MinusLogProbMetric: 2.4172

Epoch 77: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4019 - MinusLogProbMetric: 2.4019 - val_loss: 2.4172 - val_MinusLogProbMetric: 2.4172 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-11 15:59:05.820 
Epoch 78/1000 
	 loss: 2.4062, MinusLogProbMetric: 2.4062, val_loss: 2.3938, val_MinusLogProbMetric: 2.3938

Epoch 78: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4062 - MinusLogProbMetric: 2.4062 - val_loss: 2.3938 - val_MinusLogProbMetric: 2.3938 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-11 15:59:17.547 
Epoch 79/1000 
	 loss: 2.4011, MinusLogProbMetric: 2.4011, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 79: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4011 - MinusLogProbMetric: 2.4011 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-11 15:59:29.169 
Epoch 80/1000 
	 loss: 2.4088, MinusLogProbMetric: 2.4088, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 80: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4088 - MinusLogProbMetric: 2.4088 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-11 15:59:41.154 
Epoch 81/1000 
	 loss: 2.4045, MinusLogProbMetric: 2.4045, val_loss: 2.4093, val_MinusLogProbMetric: 2.4093

Epoch 81: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4045 - MinusLogProbMetric: 2.4045 - val_loss: 2.4093 - val_MinusLogProbMetric: 2.4093 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 82/1000
2023-09-11 15:59:52.935 
Epoch 82/1000 
	 loss: 2.4044, MinusLogProbMetric: 2.4044, val_loss: 2.4583, val_MinusLogProbMetric: 2.4583

Epoch 82: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4044 - MinusLogProbMetric: 2.4044 - val_loss: 2.4583 - val_MinusLogProbMetric: 2.4583 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-11 16:00:04.878 
Epoch 83/1000 
	 loss: 2.4042, MinusLogProbMetric: 2.4042, val_loss: 2.3810, val_MinusLogProbMetric: 2.3810

Epoch 83: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4042 - MinusLogProbMetric: 2.4042 - val_loss: 2.3810 - val_MinusLogProbMetric: 2.3810 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 84/1000
2023-09-11 16:00:16.744 
Epoch 84/1000 
	 loss: 2.4046, MinusLogProbMetric: 2.4046, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 84: val_loss did not improve from 2.37714
196/196 - 12s - loss: 2.4046 - MinusLogProbMetric: 2.4046 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 85/1000
2023-09-11 16:00:28.428 
Epoch 85/1000 
	 loss: 2.4026, MinusLogProbMetric: 2.4026, val_loss: 2.3726, val_MinusLogProbMetric: 2.3726

Epoch 85: val_loss improved from 2.37714 to 2.37262, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.4026 - MinusLogProbMetric: 2.4026 - val_loss: 2.3726 - val_MinusLogProbMetric: 2.3726 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-11 16:00:40.222 
Epoch 86/1000 
	 loss: 2.4051, MinusLogProbMetric: 2.4051, val_loss: 2.3735, val_MinusLogProbMetric: 2.3735

Epoch 86: val_loss did not improve from 2.37262
196/196 - 12s - loss: 2.4051 - MinusLogProbMetric: 2.4051 - val_loss: 2.3735 - val_MinusLogProbMetric: 2.3735 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-11 16:00:52.011 
Epoch 87/1000 
	 loss: 2.3975, MinusLogProbMetric: 2.3975, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 87: val_loss did not improve from 2.37262
196/196 - 12s - loss: 2.3975 - MinusLogProbMetric: 2.3975 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 88/1000
2023-09-11 16:01:03.769 
Epoch 88/1000 
	 loss: 2.3987, MinusLogProbMetric: 2.3987, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 88: val_loss did not improve from 2.37262
196/196 - 12s - loss: 2.3987 - MinusLogProbMetric: 2.3987 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-11 16:01:15.472 
Epoch 89/1000 
	 loss: 2.3974, MinusLogProbMetric: 2.3974, val_loss: 2.3740, val_MinusLogProbMetric: 2.3740

Epoch 89: val_loss did not improve from 2.37262
196/196 - 12s - loss: 2.3974 - MinusLogProbMetric: 2.3974 - val_loss: 2.3740 - val_MinusLogProbMetric: 2.3740 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-11 16:01:27.297 
Epoch 90/1000 
	 loss: 2.4034, MinusLogProbMetric: 2.4034, val_loss: 2.4059, val_MinusLogProbMetric: 2.4059

Epoch 90: val_loss did not improve from 2.37262
196/196 - 12s - loss: 2.4034 - MinusLogProbMetric: 2.4034 - val_loss: 2.4059 - val_MinusLogProbMetric: 2.4059 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-11 16:01:39.141 
Epoch 91/1000 
	 loss: 2.3987, MinusLogProbMetric: 2.3987, val_loss: 2.3852, val_MinusLogProbMetric: 2.3852

Epoch 91: val_loss did not improve from 2.37262
196/196 - 12s - loss: 2.3987 - MinusLogProbMetric: 2.3987 - val_loss: 2.3852 - val_MinusLogProbMetric: 2.3852 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-11 16:01:50.901 
Epoch 92/1000 
	 loss: 2.3959, MinusLogProbMetric: 2.3959, val_loss: 2.3699, val_MinusLogProbMetric: 2.3699

Epoch 92: val_loss improved from 2.37262 to 2.36985, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3959 - MinusLogProbMetric: 2.3959 - val_loss: 2.3699 - val_MinusLogProbMetric: 2.3699 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 93/1000
2023-09-11 16:02:02.737 
Epoch 93/1000 
	 loss: 2.3933, MinusLogProbMetric: 2.3933, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 93: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.3933 - MinusLogProbMetric: 2.3933 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-11 16:02:14.422 
Epoch 94/1000 
	 loss: 2.3947, MinusLogProbMetric: 2.3947, val_loss: 2.4027, val_MinusLogProbMetric: 2.4027

Epoch 94: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.3947 - MinusLogProbMetric: 2.3947 - val_loss: 2.4027 - val_MinusLogProbMetric: 2.4027 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-11 16:02:26.326 
Epoch 95/1000 
	 loss: 2.4019, MinusLogProbMetric: 2.4019, val_loss: 2.4247, val_MinusLogProbMetric: 2.4247

Epoch 95: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.4019 - MinusLogProbMetric: 2.4019 - val_loss: 2.4247 - val_MinusLogProbMetric: 2.4247 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 96/1000
2023-09-11 16:02:38.054 
Epoch 96/1000 
	 loss: 2.3993, MinusLogProbMetric: 2.3993, val_loss: 2.4035, val_MinusLogProbMetric: 2.4035

Epoch 96: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.3993 - MinusLogProbMetric: 2.3993 - val_loss: 2.4035 - val_MinusLogProbMetric: 2.4035 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 97/1000
2023-09-11 16:02:49.948 
Epoch 97/1000 
	 loss: 2.4003, MinusLogProbMetric: 2.4003, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 97: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.4003 - MinusLogProbMetric: 2.4003 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 98/1000
2023-09-11 16:03:01.767 
Epoch 98/1000 
	 loss: 2.3999, MinusLogProbMetric: 2.3999, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 98: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.3999 - MinusLogProbMetric: 2.3999 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 99/1000
2023-09-11 16:03:13.607 
Epoch 99/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.3799, val_MinusLogProbMetric: 2.3799

Epoch 99: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.3799 - val_MinusLogProbMetric: 2.3799 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 100/1000
2023-09-11 16:03:25.389 
Epoch 100/1000 
	 loss: 2.4015, MinusLogProbMetric: 2.4015, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 100: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.4015 - MinusLogProbMetric: 2.4015 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-11 16:03:37.244 
Epoch 101/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.3865, val_MinusLogProbMetric: 2.3865

Epoch 101: val_loss did not improve from 2.36985
196/196 - 12s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.3865 - val_MinusLogProbMetric: 2.3865 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 102/1000
2023-09-11 16:03:48.969 
Epoch 102/1000 
	 loss: 2.3997, MinusLogProbMetric: 2.3997, val_loss: 2.3663, val_MinusLogProbMetric: 2.3663

Epoch 102: val_loss improved from 2.36985 to 2.36633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3997 - MinusLogProbMetric: 2.3997 - val_loss: 2.3663 - val_MinusLogProbMetric: 2.3663 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 103/1000
2023-09-11 16:04:00.813 
Epoch 103/1000 
	 loss: 2.3991, MinusLogProbMetric: 2.3991, val_loss: 2.3780, val_MinusLogProbMetric: 2.3780

Epoch 103: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3991 - MinusLogProbMetric: 2.3991 - val_loss: 2.3780 - val_MinusLogProbMetric: 2.3780 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-11 16:04:12.583 
Epoch 104/1000 
	 loss: 2.4034, MinusLogProbMetric: 2.4034, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 104: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.4034 - MinusLogProbMetric: 2.4034 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 105/1000
2023-09-11 16:04:24.365 
Epoch 105/1000 
	 loss: 2.3919, MinusLogProbMetric: 2.3919, val_loss: 2.3899, val_MinusLogProbMetric: 2.3899

Epoch 105: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3919 - MinusLogProbMetric: 2.3919 - val_loss: 2.3899 - val_MinusLogProbMetric: 2.3899 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-11 16:04:36.076 
Epoch 106/1000 
	 loss: 2.3970, MinusLogProbMetric: 2.3970, val_loss: 2.3809, val_MinusLogProbMetric: 2.3809

Epoch 106: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3970 - MinusLogProbMetric: 2.3970 - val_loss: 2.3809 - val_MinusLogProbMetric: 2.3809 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 107/1000
2023-09-11 16:04:47.807 
Epoch 107/1000 
	 loss: 2.3949, MinusLogProbMetric: 2.3949, val_loss: 2.3731, val_MinusLogProbMetric: 2.3731

Epoch 107: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3949 - MinusLogProbMetric: 2.3949 - val_loss: 2.3731 - val_MinusLogProbMetric: 2.3731 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-11 16:04:59.621 
Epoch 108/1000 
	 loss: 2.3939, MinusLogProbMetric: 2.3939, val_loss: 2.4045, val_MinusLogProbMetric: 2.4045

Epoch 108: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3939 - MinusLogProbMetric: 2.3939 - val_loss: 2.4045 - val_MinusLogProbMetric: 2.4045 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-11 16:05:11.341 
Epoch 109/1000 
	 loss: 2.3890, MinusLogProbMetric: 2.3890, val_loss: 2.4164, val_MinusLogProbMetric: 2.4164

Epoch 109: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3890 - MinusLogProbMetric: 2.3890 - val_loss: 2.4164 - val_MinusLogProbMetric: 2.4164 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 110/1000
2023-09-11 16:05:23.026 
Epoch 110/1000 
	 loss: 2.3951, MinusLogProbMetric: 2.3951, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 110: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3951 - MinusLogProbMetric: 2.3951 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 111/1000
2023-09-11 16:05:34.649 
Epoch 111/1000 
	 loss: 2.3957, MinusLogProbMetric: 2.3957, val_loss: 2.3969, val_MinusLogProbMetric: 2.3969

Epoch 111: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3957 - MinusLogProbMetric: 2.3957 - val_loss: 2.3969 - val_MinusLogProbMetric: 2.3969 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 112/1000
2023-09-11 16:05:46.424 
Epoch 112/1000 
	 loss: 2.3951, MinusLogProbMetric: 2.3951, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 112: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3951 - MinusLogProbMetric: 2.3951 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 113/1000
2023-09-11 16:05:58.131 
Epoch 113/1000 
	 loss: 2.3928, MinusLogProbMetric: 2.3928, val_loss: 2.3962, val_MinusLogProbMetric: 2.3962

Epoch 113: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3928 - MinusLogProbMetric: 2.3928 - val_loss: 2.3962 - val_MinusLogProbMetric: 2.3962 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-11 16:06:09.747 
Epoch 114/1000 
	 loss: 2.3930, MinusLogProbMetric: 2.3930, val_loss: 2.3726, val_MinusLogProbMetric: 2.3726

Epoch 114: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3930 - MinusLogProbMetric: 2.3930 - val_loss: 2.3726 - val_MinusLogProbMetric: 2.3726 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 115/1000
2023-09-11 16:06:21.451 
Epoch 115/1000 
	 loss: 2.3948, MinusLogProbMetric: 2.3948, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 115: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3948 - MinusLogProbMetric: 2.3948 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 116/1000
2023-09-11 16:06:33.206 
Epoch 116/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 116: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 117/1000
2023-09-11 16:06:44.927 
Epoch 117/1000 
	 loss: 2.3959, MinusLogProbMetric: 2.3959, val_loss: 2.4092, val_MinusLogProbMetric: 2.4092

Epoch 117: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3959 - MinusLogProbMetric: 2.3959 - val_loss: 2.4092 - val_MinusLogProbMetric: 2.4092 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-11 16:06:56.665 
Epoch 118/1000 
	 loss: 2.3907, MinusLogProbMetric: 2.3907, val_loss: 2.3840, val_MinusLogProbMetric: 2.3840

Epoch 118: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3907 - MinusLogProbMetric: 2.3907 - val_loss: 2.3840 - val_MinusLogProbMetric: 2.3840 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-11 16:07:08.319 
Epoch 119/1000 
	 loss: 2.3922, MinusLogProbMetric: 2.3922, val_loss: 2.3723, val_MinusLogProbMetric: 2.3723

Epoch 119: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3922 - MinusLogProbMetric: 2.3922 - val_loss: 2.3723 - val_MinusLogProbMetric: 2.3723 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 120/1000
2023-09-11 16:07:19.938 
Epoch 120/1000 
	 loss: 2.3954, MinusLogProbMetric: 2.3954, val_loss: 2.3974, val_MinusLogProbMetric: 2.3974

Epoch 120: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3954 - MinusLogProbMetric: 2.3954 - val_loss: 2.3974 - val_MinusLogProbMetric: 2.3974 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 121/1000
2023-09-11 16:07:31.689 
Epoch 121/1000 
	 loss: 2.3891, MinusLogProbMetric: 2.3891, val_loss: 2.3714, val_MinusLogProbMetric: 2.3714

Epoch 121: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3891 - MinusLogProbMetric: 2.3891 - val_loss: 2.3714 - val_MinusLogProbMetric: 2.3714 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-11 16:07:43.482 
Epoch 122/1000 
	 loss: 2.3904, MinusLogProbMetric: 2.3904, val_loss: 2.3783, val_MinusLogProbMetric: 2.3783

Epoch 122: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3904 - MinusLogProbMetric: 2.3904 - val_loss: 2.3783 - val_MinusLogProbMetric: 2.3783 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-11 16:07:55.324 
Epoch 123/1000 
	 loss: 2.3894, MinusLogProbMetric: 2.3894, val_loss: 2.3771, val_MinusLogProbMetric: 2.3771

Epoch 123: val_loss did not improve from 2.36633
196/196 - 12s - loss: 2.3894 - MinusLogProbMetric: 2.3894 - val_loss: 2.3771 - val_MinusLogProbMetric: 2.3771 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-11 16:08:07.185 
Epoch 124/1000 
	 loss: 2.3943, MinusLogProbMetric: 2.3943, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 124: val_loss improved from 2.36633 to 2.36386, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3943 - MinusLogProbMetric: 2.3943 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 125/1000
2023-09-11 16:08:19.076 
Epoch 125/1000 
	 loss: 2.3906, MinusLogProbMetric: 2.3906, val_loss: 2.3655, val_MinusLogProbMetric: 2.3655

Epoch 125: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3906 - MinusLogProbMetric: 2.3906 - val_loss: 2.3655 - val_MinusLogProbMetric: 2.3655 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 126/1000
2023-09-11 16:08:30.768 
Epoch 126/1000 
	 loss: 2.3896, MinusLogProbMetric: 2.3896, val_loss: 2.4056, val_MinusLogProbMetric: 2.4056

Epoch 126: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3896 - MinusLogProbMetric: 2.3896 - val_loss: 2.4056 - val_MinusLogProbMetric: 2.4056 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-11 16:08:42.558 
Epoch 127/1000 
	 loss: 2.3935, MinusLogProbMetric: 2.3935, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 127: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3935 - MinusLogProbMetric: 2.3935 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 128/1000
2023-09-11 16:08:54.407 
Epoch 128/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.4022, val_MinusLogProbMetric: 2.4022

Epoch 128: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.4022 - val_MinusLogProbMetric: 2.4022 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-11 16:09:06.243 
Epoch 129/1000 
	 loss: 2.3936, MinusLogProbMetric: 2.3936, val_loss: 2.3666, val_MinusLogProbMetric: 2.3666

Epoch 129: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3936 - MinusLogProbMetric: 2.3936 - val_loss: 2.3666 - val_MinusLogProbMetric: 2.3666 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-11 16:09:17.999 
Epoch 130/1000 
	 loss: 2.3890, MinusLogProbMetric: 2.3890, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 130: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3890 - MinusLogProbMetric: 2.3890 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-11 16:09:29.644 
Epoch 131/1000 
	 loss: 2.3944, MinusLogProbMetric: 2.3944, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 131: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3944 - MinusLogProbMetric: 2.3944 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 132/1000
2023-09-11 16:09:41.507 
Epoch 132/1000 
	 loss: 2.3862, MinusLogProbMetric: 2.3862, val_loss: 2.4235, val_MinusLogProbMetric: 2.4235

Epoch 132: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3862 - MinusLogProbMetric: 2.3862 - val_loss: 2.4235 - val_MinusLogProbMetric: 2.4235 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 133/1000
2023-09-11 16:09:53.321 
Epoch 133/1000 
	 loss: 2.3880, MinusLogProbMetric: 2.3880, val_loss: 2.3747, val_MinusLogProbMetric: 2.3747

Epoch 133: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3880 - MinusLogProbMetric: 2.3880 - val_loss: 2.3747 - val_MinusLogProbMetric: 2.3747 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-11 16:10:04.992 
Epoch 134/1000 
	 loss: 2.3846, MinusLogProbMetric: 2.3846, val_loss: 2.3860, val_MinusLogProbMetric: 2.3860

Epoch 134: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3846 - MinusLogProbMetric: 2.3846 - val_loss: 2.3860 - val_MinusLogProbMetric: 2.3860 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-11 16:10:16.779 
Epoch 135/1000 
	 loss: 2.3935, MinusLogProbMetric: 2.3935, val_loss: 2.4164, val_MinusLogProbMetric: 2.4164

Epoch 135: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3935 - MinusLogProbMetric: 2.3935 - val_loss: 2.4164 - val_MinusLogProbMetric: 2.4164 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-11 16:10:28.626 
Epoch 136/1000 
	 loss: 2.3874, MinusLogProbMetric: 2.3874, val_loss: 2.3715, val_MinusLogProbMetric: 2.3715

Epoch 136: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3874 - MinusLogProbMetric: 2.3874 - val_loss: 2.3715 - val_MinusLogProbMetric: 2.3715 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 137/1000
2023-09-11 16:10:40.326 
Epoch 137/1000 
	 loss: 2.3883, MinusLogProbMetric: 2.3883, val_loss: 2.3872, val_MinusLogProbMetric: 2.3872

Epoch 137: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3883 - MinusLogProbMetric: 2.3883 - val_loss: 2.3872 - val_MinusLogProbMetric: 2.3872 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 138/1000
2023-09-11 16:10:52.106 
Epoch 138/1000 
	 loss: 2.3901, MinusLogProbMetric: 2.3901, val_loss: 2.3946, val_MinusLogProbMetric: 2.3946

Epoch 138: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3901 - MinusLogProbMetric: 2.3901 - val_loss: 2.3946 - val_MinusLogProbMetric: 2.3946 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-11 16:11:03.891 
Epoch 139/1000 
	 loss: 2.3894, MinusLogProbMetric: 2.3894, val_loss: 2.3769, val_MinusLogProbMetric: 2.3769

Epoch 139: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3894 - MinusLogProbMetric: 2.3894 - val_loss: 2.3769 - val_MinusLogProbMetric: 2.3769 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-11 16:11:15.518 
Epoch 140/1000 
	 loss: 2.3905, MinusLogProbMetric: 2.3905, val_loss: 2.3939, val_MinusLogProbMetric: 2.3939

Epoch 140: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3905 - MinusLogProbMetric: 2.3905 - val_loss: 2.3939 - val_MinusLogProbMetric: 2.3939 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 141/1000
2023-09-11 16:11:27.325 
Epoch 141/1000 
	 loss: 2.3892, MinusLogProbMetric: 2.3892, val_loss: 2.3681, val_MinusLogProbMetric: 2.3681

Epoch 141: val_loss did not improve from 2.36386
196/196 - 12s - loss: 2.3892 - MinusLogProbMetric: 2.3892 - val_loss: 2.3681 - val_MinusLogProbMetric: 2.3681 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 142/1000
2023-09-11 16:11:39.171 
Epoch 142/1000 
	 loss: 2.3884, MinusLogProbMetric: 2.3884, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 142: val_loss improved from 2.36386 to 2.36215, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3884 - MinusLogProbMetric: 2.3884 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 143/1000
2023-09-11 16:11:51.072 
Epoch 143/1000 
	 loss: 2.3846, MinusLogProbMetric: 2.3846, val_loss: 2.3746, val_MinusLogProbMetric: 2.3746

Epoch 143: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3846 - MinusLogProbMetric: 2.3846 - val_loss: 2.3746 - val_MinusLogProbMetric: 2.3746 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 144/1000
2023-09-11 16:12:02.895 
Epoch 144/1000 
	 loss: 2.3855, MinusLogProbMetric: 2.3855, val_loss: 2.3867, val_MinusLogProbMetric: 2.3867

Epoch 144: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3855 - MinusLogProbMetric: 2.3855 - val_loss: 2.3867 - val_MinusLogProbMetric: 2.3867 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 145/1000
2023-09-11 16:12:14.554 
Epoch 145/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 145: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 146/1000
2023-09-11 16:12:26.271 
Epoch 146/1000 
	 loss: 2.3857, MinusLogProbMetric: 2.3857, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 146: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3857 - MinusLogProbMetric: 2.3857 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-11 16:12:38.130 
Epoch 147/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 147: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-11 16:12:49.845 
Epoch 148/1000 
	 loss: 2.3876, MinusLogProbMetric: 2.3876, val_loss: 2.3796, val_MinusLogProbMetric: 2.3796

Epoch 148: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3876 - MinusLogProbMetric: 2.3876 - val_loss: 2.3796 - val_MinusLogProbMetric: 2.3796 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-11 16:13:01.596 
Epoch 149/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 149: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-11 16:13:13.397 
Epoch 150/1000 
	 loss: 2.3891, MinusLogProbMetric: 2.3891, val_loss: 2.3675, val_MinusLogProbMetric: 2.3675

Epoch 150: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3891 - MinusLogProbMetric: 2.3891 - val_loss: 2.3675 - val_MinusLogProbMetric: 2.3675 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-11 16:13:25.179 
Epoch 151/1000 
	 loss: 2.3844, MinusLogProbMetric: 2.3844, val_loss: 2.3800, val_MinusLogProbMetric: 2.3800

Epoch 151: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3844 - MinusLogProbMetric: 2.3844 - val_loss: 2.3800 - val_MinusLogProbMetric: 2.3800 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-11 16:13:37.005 
Epoch 152/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 152: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-11 16:13:48.719 
Epoch 153/1000 
	 loss: 2.3919, MinusLogProbMetric: 2.3919, val_loss: 2.3899, val_MinusLogProbMetric: 2.3899

Epoch 153: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3919 - MinusLogProbMetric: 2.3919 - val_loss: 2.3899 - val_MinusLogProbMetric: 2.3899 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 154/1000
2023-09-11 16:14:00.457 
Epoch 154/1000 
	 loss: 2.3847, MinusLogProbMetric: 2.3847, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 154: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3847 - MinusLogProbMetric: 2.3847 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 155/1000
2023-09-11 16:14:12.348 
Epoch 155/1000 
	 loss: 2.3852, MinusLogProbMetric: 2.3852, val_loss: 2.3679, val_MinusLogProbMetric: 2.3679

Epoch 155: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3852 - MinusLogProbMetric: 2.3852 - val_loss: 2.3679 - val_MinusLogProbMetric: 2.3679 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 156/1000
2023-09-11 16:14:23.958 
Epoch 156/1000 
	 loss: 2.3849, MinusLogProbMetric: 2.3849, val_loss: 2.3694, val_MinusLogProbMetric: 2.3694

Epoch 156: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3849 - MinusLogProbMetric: 2.3849 - val_loss: 2.3694 - val_MinusLogProbMetric: 2.3694 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 157/1000
2023-09-11 16:14:35.690 
Epoch 157/1000 
	 loss: 2.3905, MinusLogProbMetric: 2.3905, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 157: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3905 - MinusLogProbMetric: 2.3905 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-11 16:14:47.424 
Epoch 158/1000 
	 loss: 2.3849, MinusLogProbMetric: 2.3849, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 158: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3849 - MinusLogProbMetric: 2.3849 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 159/1000
2023-09-11 16:14:59.122 
Epoch 159/1000 
	 loss: 2.3816, MinusLogProbMetric: 2.3816, val_loss: 2.3652, val_MinusLogProbMetric: 2.3652

Epoch 159: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3816 - MinusLogProbMetric: 2.3816 - val_loss: 2.3652 - val_MinusLogProbMetric: 2.3652 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-11 16:15:10.851 
Epoch 160/1000 
	 loss: 2.3865, MinusLogProbMetric: 2.3865, val_loss: 2.3751, val_MinusLogProbMetric: 2.3751

Epoch 160: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3865 - MinusLogProbMetric: 2.3865 - val_loss: 2.3751 - val_MinusLogProbMetric: 2.3751 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 161/1000
2023-09-11 16:15:22.536 
Epoch 161/1000 
	 loss: 2.3822, MinusLogProbMetric: 2.3822, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 161: val_loss improved from 2.36215 to 2.36198, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3822 - MinusLogProbMetric: 2.3822 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 162/1000
2023-09-11 16:15:34.344 
Epoch 162/1000 
	 loss: 2.3869, MinusLogProbMetric: 2.3869, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 162: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3869 - MinusLogProbMetric: 2.3869 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 163/1000
2023-09-11 16:15:46.161 
Epoch 163/1000 
	 loss: 2.3882, MinusLogProbMetric: 2.3882, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 163: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3882 - MinusLogProbMetric: 2.3882 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 164/1000
2023-09-11 16:15:57.906 
Epoch 164/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 164: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 165/1000
2023-09-11 16:16:09.666 
Epoch 165/1000 
	 loss: 2.3873, MinusLogProbMetric: 2.3873, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 165: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3873 - MinusLogProbMetric: 2.3873 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 166/1000
2023-09-11 16:16:21.464 
Epoch 166/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.3727, val_MinusLogProbMetric: 2.3727

Epoch 166: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.3727 - val_MinusLogProbMetric: 2.3727 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 167/1000
2023-09-11 16:16:33.286 
Epoch 167/1000 
	 loss: 2.3843, MinusLogProbMetric: 2.3843, val_loss: 2.3796, val_MinusLogProbMetric: 2.3796

Epoch 167: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3843 - MinusLogProbMetric: 2.3843 - val_loss: 2.3796 - val_MinusLogProbMetric: 2.3796 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 168/1000
2023-09-11 16:16:45.008 
Epoch 168/1000 
	 loss: 2.3860, MinusLogProbMetric: 2.3860, val_loss: 2.4113, val_MinusLogProbMetric: 2.4113

Epoch 168: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3860 - MinusLogProbMetric: 2.3860 - val_loss: 2.4113 - val_MinusLogProbMetric: 2.4113 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-11 16:16:56.749 
Epoch 169/1000 
	 loss: 2.3826, MinusLogProbMetric: 2.3826, val_loss: 2.3737, val_MinusLogProbMetric: 2.3737

Epoch 169: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3826 - MinusLogProbMetric: 2.3826 - val_loss: 2.3737 - val_MinusLogProbMetric: 2.3737 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 170/1000
2023-09-11 16:17:08.442 
Epoch 170/1000 
	 loss: 2.3853, MinusLogProbMetric: 2.3853, val_loss: 2.3813, val_MinusLogProbMetric: 2.3813

Epoch 170: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3853 - MinusLogProbMetric: 2.3853 - val_loss: 2.3813 - val_MinusLogProbMetric: 2.3813 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 171/1000
2023-09-11 16:17:20.136 
Epoch 171/1000 
	 loss: 2.3879, MinusLogProbMetric: 2.3879, val_loss: 2.3762, val_MinusLogProbMetric: 2.3762

Epoch 171: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3879 - MinusLogProbMetric: 2.3879 - val_loss: 2.3762 - val_MinusLogProbMetric: 2.3762 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 172/1000
2023-09-11 16:17:31.803 
Epoch 172/1000 
	 loss: 2.3882, MinusLogProbMetric: 2.3882, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 172: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3882 - MinusLogProbMetric: 2.3882 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 173/1000
2023-09-11 16:17:43.637 
Epoch 173/1000 
	 loss: 2.3864, MinusLogProbMetric: 2.3864, val_loss: 2.3760, val_MinusLogProbMetric: 2.3760

Epoch 173: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3864 - MinusLogProbMetric: 2.3864 - val_loss: 2.3760 - val_MinusLogProbMetric: 2.3760 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 174/1000
2023-09-11 16:17:55.380 
Epoch 174/1000 
	 loss: 2.3852, MinusLogProbMetric: 2.3852, val_loss: 2.3746, val_MinusLogProbMetric: 2.3746

Epoch 174: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3852 - MinusLogProbMetric: 2.3852 - val_loss: 2.3746 - val_MinusLogProbMetric: 2.3746 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 175/1000
2023-09-11 16:18:07.203 
Epoch 175/1000 
	 loss: 2.3856, MinusLogProbMetric: 2.3856, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 175: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3856 - MinusLogProbMetric: 2.3856 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 176/1000
2023-09-11 16:18:18.940 
Epoch 176/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.3686, val_MinusLogProbMetric: 2.3686

Epoch 176: val_loss did not improve from 2.36198
196/196 - 12s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.3686 - val_MinusLogProbMetric: 2.3686 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-11 16:18:30.751 
Epoch 177/1000 
	 loss: 2.3831, MinusLogProbMetric: 2.3831, val_loss: 2.3599, val_MinusLogProbMetric: 2.3599

Epoch 177: val_loss improved from 2.36198 to 2.35991, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3831 - MinusLogProbMetric: 2.3831 - val_loss: 2.3599 - val_MinusLogProbMetric: 2.3599 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 178/1000
2023-09-11 16:18:42.512 
Epoch 178/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.3773, val_MinusLogProbMetric: 2.3773

Epoch 178: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.3773 - val_MinusLogProbMetric: 2.3773 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 179/1000
2023-09-11 16:18:54.133 
Epoch 179/1000 
	 loss: 2.3822, MinusLogProbMetric: 2.3822, val_loss: 2.3854, val_MinusLogProbMetric: 2.3854

Epoch 179: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3822 - MinusLogProbMetric: 2.3822 - val_loss: 2.3854 - val_MinusLogProbMetric: 2.3854 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 180/1000
2023-09-11 16:19:05.908 
Epoch 180/1000 
	 loss: 2.3836, MinusLogProbMetric: 2.3836, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 180: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3836 - MinusLogProbMetric: 2.3836 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 181/1000
2023-09-11 16:19:17.707 
Epoch 181/1000 
	 loss: 2.3826, MinusLogProbMetric: 2.3826, val_loss: 2.4002, val_MinusLogProbMetric: 2.4002

Epoch 181: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3826 - MinusLogProbMetric: 2.3826 - val_loss: 2.4002 - val_MinusLogProbMetric: 2.4002 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 182/1000
2023-09-11 16:19:29.382 
Epoch 182/1000 
	 loss: 2.3853, MinusLogProbMetric: 2.3853, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 182: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3853 - MinusLogProbMetric: 2.3853 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 183/1000
2023-09-11 16:19:41.110 
Epoch 183/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 183: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 184/1000
2023-09-11 16:19:53.116 
Epoch 184/1000 
	 loss: 2.3833, MinusLogProbMetric: 2.3833, val_loss: 2.4029, val_MinusLogProbMetric: 2.4029

Epoch 184: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3833 - MinusLogProbMetric: 2.3833 - val_loss: 2.4029 - val_MinusLogProbMetric: 2.4029 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 185/1000
2023-09-11 16:20:04.831 
Epoch 185/1000 
	 loss: 2.3850, MinusLogProbMetric: 2.3850, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 185: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3850 - MinusLogProbMetric: 2.3850 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 186/1000
2023-09-11 16:20:16.634 
Epoch 186/1000 
	 loss: 2.3844, MinusLogProbMetric: 2.3844, val_loss: 2.3655, val_MinusLogProbMetric: 2.3655

Epoch 186: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3844 - MinusLogProbMetric: 2.3844 - val_loss: 2.3655 - val_MinusLogProbMetric: 2.3655 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 187/1000
2023-09-11 16:20:28.255 
Epoch 187/1000 
	 loss: 2.3843, MinusLogProbMetric: 2.3843, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 187: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3843 - MinusLogProbMetric: 2.3843 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 188/1000
2023-09-11 16:20:39.941 
Epoch 188/1000 
	 loss: 2.3801, MinusLogProbMetric: 2.3801, val_loss: 2.3703, val_MinusLogProbMetric: 2.3703

Epoch 188: val_loss did not improve from 2.35991
196/196 - 12s - loss: 2.3801 - MinusLogProbMetric: 2.3801 - val_loss: 2.3703 - val_MinusLogProbMetric: 2.3703 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 189/1000
2023-09-11 16:20:51.691 
Epoch 189/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 189: val_loss improved from 2.35991 to 2.35864, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 190/1000
2023-09-11 16:21:03.649 
Epoch 190/1000 
	 loss: 2.3822, MinusLogProbMetric: 2.3822, val_loss: 2.3992, val_MinusLogProbMetric: 2.3992

Epoch 190: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3822 - MinusLogProbMetric: 2.3822 - val_loss: 2.3992 - val_MinusLogProbMetric: 2.3992 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-11 16:21:15.352 
Epoch 191/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.3782, val_MinusLogProbMetric: 2.3782

Epoch 191: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.3782 - val_MinusLogProbMetric: 2.3782 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 192/1000
2023-09-11 16:21:27.078 
Epoch 192/1000 
	 loss: 2.3829, MinusLogProbMetric: 2.3829, val_loss: 2.4248, val_MinusLogProbMetric: 2.4248

Epoch 192: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3829 - MinusLogProbMetric: 2.3829 - val_loss: 2.4248 - val_MinusLogProbMetric: 2.4248 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-11 16:21:38.850 
Epoch 193/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 193: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-11 16:21:50.457 
Epoch 194/1000 
	 loss: 2.3827, MinusLogProbMetric: 2.3827, val_loss: 2.3741, val_MinusLogProbMetric: 2.3741

Epoch 194: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3827 - MinusLogProbMetric: 2.3827 - val_loss: 2.3741 - val_MinusLogProbMetric: 2.3741 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 195/1000
2023-09-11 16:22:02.211 
Epoch 195/1000 
	 loss: 2.3822, MinusLogProbMetric: 2.3822, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 195: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3822 - MinusLogProbMetric: 2.3822 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-11 16:22:13.796 
Epoch 196/1000 
	 loss: 2.3818, MinusLogProbMetric: 2.3818, val_loss: 2.3786, val_MinusLogProbMetric: 2.3786

Epoch 196: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3818 - MinusLogProbMetric: 2.3818 - val_loss: 2.3786 - val_MinusLogProbMetric: 2.3786 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 197/1000
2023-09-11 16:22:25.493 
Epoch 197/1000 
	 loss: 2.3825, MinusLogProbMetric: 2.3825, val_loss: 2.3764, val_MinusLogProbMetric: 2.3764

Epoch 197: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3825 - MinusLogProbMetric: 2.3825 - val_loss: 2.3764 - val_MinusLogProbMetric: 2.3764 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-11 16:22:37.176 
Epoch 198/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.3603, val_MinusLogProbMetric: 2.3603

Epoch 198: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.3603 - val_MinusLogProbMetric: 2.3603 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 199/1000
2023-09-11 16:22:48.800 
Epoch 199/1000 
	 loss: 2.3787, MinusLogProbMetric: 2.3787, val_loss: 2.3764, val_MinusLogProbMetric: 2.3764

Epoch 199: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3787 - MinusLogProbMetric: 2.3787 - val_loss: 2.3764 - val_MinusLogProbMetric: 2.3764 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 200/1000
2023-09-11 16:23:00.534 
Epoch 200/1000 
	 loss: 2.3858, MinusLogProbMetric: 2.3858, val_loss: 2.3604, val_MinusLogProbMetric: 2.3604

Epoch 200: val_loss did not improve from 2.35864
196/196 - 12s - loss: 2.3858 - MinusLogProbMetric: 2.3858 - val_loss: 2.3604 - val_MinusLogProbMetric: 2.3604 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-11 16:23:12.219 
Epoch 201/1000 
	 loss: 2.3759, MinusLogProbMetric: 2.3759, val_loss: 2.3584, val_MinusLogProbMetric: 2.3584

Epoch 201: val_loss improved from 2.35864 to 2.35840, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3759 - MinusLogProbMetric: 2.3759 - val_loss: 2.3584 - val_MinusLogProbMetric: 2.3584 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-11 16:23:24.006 
Epoch 202/1000 
	 loss: 2.3805, MinusLogProbMetric: 2.3805, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 202: val_loss did not improve from 2.35840
196/196 - 12s - loss: 2.3805 - MinusLogProbMetric: 2.3805 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-11 16:23:35.721 
Epoch 203/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3692, val_MinusLogProbMetric: 2.3692

Epoch 203: val_loss did not improve from 2.35840
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3692 - val_MinusLogProbMetric: 2.3692 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 204/1000
2023-09-11 16:23:47.476 
Epoch 204/1000 
	 loss: 2.3848, MinusLogProbMetric: 2.3848, val_loss: 2.3579, val_MinusLogProbMetric: 2.3579

Epoch 204: val_loss improved from 2.35840 to 2.35793, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3848 - MinusLogProbMetric: 2.3848 - val_loss: 2.3579 - val_MinusLogProbMetric: 2.3579 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-11 16:23:59.363 
Epoch 205/1000 
	 loss: 2.3804, MinusLogProbMetric: 2.3804, val_loss: 2.3850, val_MinusLogProbMetric: 2.3850

Epoch 205: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3804 - MinusLogProbMetric: 2.3804 - val_loss: 2.3850 - val_MinusLogProbMetric: 2.3850 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 206/1000
2023-09-11 16:24:11.183 
Epoch 206/1000 
	 loss: 2.3892, MinusLogProbMetric: 2.3892, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 206: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3892 - MinusLogProbMetric: 2.3892 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 207/1000
2023-09-11 16:24:22.964 
Epoch 207/1000 
	 loss: 2.3800, MinusLogProbMetric: 2.3800, val_loss: 2.3600, val_MinusLogProbMetric: 2.3600

Epoch 207: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3800 - MinusLogProbMetric: 2.3800 - val_loss: 2.3600 - val_MinusLogProbMetric: 2.3600 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-11 16:24:34.666 
Epoch 208/1000 
	 loss: 2.3768, MinusLogProbMetric: 2.3768, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 208: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3768 - MinusLogProbMetric: 2.3768 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 209/1000
2023-09-11 16:24:46.244 
Epoch 209/1000 
	 loss: 2.3783, MinusLogProbMetric: 2.3783, val_loss: 2.3649, val_MinusLogProbMetric: 2.3649

Epoch 209: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3783 - MinusLogProbMetric: 2.3783 - val_loss: 2.3649 - val_MinusLogProbMetric: 2.3649 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-11 16:24:58.032 
Epoch 210/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 210: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 211/1000
2023-09-11 16:25:09.810 
Epoch 211/1000 
	 loss: 2.3836, MinusLogProbMetric: 2.3836, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 211: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3836 - MinusLogProbMetric: 2.3836 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 212/1000
2023-09-11 16:25:21.682 
Epoch 212/1000 
	 loss: 2.3793, MinusLogProbMetric: 2.3793, val_loss: 2.3714, val_MinusLogProbMetric: 2.3714

Epoch 212: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3793 - MinusLogProbMetric: 2.3793 - val_loss: 2.3714 - val_MinusLogProbMetric: 2.3714 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 213/1000
2023-09-11 16:25:33.479 
Epoch 213/1000 
	 loss: 2.3781, MinusLogProbMetric: 2.3781, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 213: val_loss did not improve from 2.35793
196/196 - 12s - loss: 2.3781 - MinusLogProbMetric: 2.3781 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 214/1000
2023-09-11 16:25:45.168 
Epoch 214/1000 
	 loss: 2.3809, MinusLogProbMetric: 2.3809, val_loss: 2.3563, val_MinusLogProbMetric: 2.3563

Epoch 214: val_loss improved from 2.35793 to 2.35634, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3809 - MinusLogProbMetric: 2.3809 - val_loss: 2.3563 - val_MinusLogProbMetric: 2.3563 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-11 16:25:57.129 
Epoch 215/1000 
	 loss: 2.3782, MinusLogProbMetric: 2.3782, val_loss: 2.3546, val_MinusLogProbMetric: 2.3546

Epoch 215: val_loss improved from 2.35634 to 2.35464, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3782 - MinusLogProbMetric: 2.3782 - val_loss: 2.3546 - val_MinusLogProbMetric: 2.3546 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 216/1000
2023-09-11 16:26:08.998 
Epoch 216/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 216: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 217/1000
2023-09-11 16:26:20.753 
Epoch 217/1000 
	 loss: 2.3867, MinusLogProbMetric: 2.3867, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 217: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3867 - MinusLogProbMetric: 2.3867 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 218/1000
2023-09-11 16:26:32.601 
Epoch 218/1000 
	 loss: 2.3820, MinusLogProbMetric: 2.3820, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 218: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3820 - MinusLogProbMetric: 2.3820 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-11 16:26:44.294 
Epoch 219/1000 
	 loss: 2.3797, MinusLogProbMetric: 2.3797, val_loss: 2.3687, val_MinusLogProbMetric: 2.3687

Epoch 219: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3797 - MinusLogProbMetric: 2.3797 - val_loss: 2.3687 - val_MinusLogProbMetric: 2.3687 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 220/1000
2023-09-11 16:26:56.057 
Epoch 220/1000 
	 loss: 2.3801, MinusLogProbMetric: 2.3801, val_loss: 2.3809, val_MinusLogProbMetric: 2.3809

Epoch 220: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3801 - MinusLogProbMetric: 2.3801 - val_loss: 2.3809 - val_MinusLogProbMetric: 2.3809 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 221/1000
2023-09-11 16:27:07.817 
Epoch 221/1000 
	 loss: 2.3800, MinusLogProbMetric: 2.3800, val_loss: 2.3840, val_MinusLogProbMetric: 2.3840

Epoch 221: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3800 - MinusLogProbMetric: 2.3800 - val_loss: 2.3840 - val_MinusLogProbMetric: 2.3840 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-11 16:27:19.595 
Epoch 222/1000 
	 loss: 2.3819, MinusLogProbMetric: 2.3819, val_loss: 2.3924, val_MinusLogProbMetric: 2.3924

Epoch 222: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3819 - MinusLogProbMetric: 2.3819 - val_loss: 2.3924 - val_MinusLogProbMetric: 2.3924 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-11 16:27:31.311 
Epoch 223/1000 
	 loss: 2.3813, MinusLogProbMetric: 2.3813, val_loss: 2.3779, val_MinusLogProbMetric: 2.3779

Epoch 223: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3813 - MinusLogProbMetric: 2.3813 - val_loss: 2.3779 - val_MinusLogProbMetric: 2.3779 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 224/1000
2023-09-11 16:27:43.055 
Epoch 224/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.3757, val_MinusLogProbMetric: 2.3757

Epoch 224: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.3757 - val_MinusLogProbMetric: 2.3757 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-11 16:27:54.843 
Epoch 225/1000 
	 loss: 2.3828, MinusLogProbMetric: 2.3828, val_loss: 2.3677, val_MinusLogProbMetric: 2.3677

Epoch 225: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3828 - MinusLogProbMetric: 2.3828 - val_loss: 2.3677 - val_MinusLogProbMetric: 2.3677 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-11 16:28:06.492 
Epoch 226/1000 
	 loss: 2.3797, MinusLogProbMetric: 2.3797, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 226: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3797 - MinusLogProbMetric: 2.3797 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 227/1000
2023-09-11 16:28:18.282 
Epoch 227/1000 
	 loss: 2.3801, MinusLogProbMetric: 2.3801, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 227: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3801 - MinusLogProbMetric: 2.3801 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 228/1000
2023-09-11 16:28:30.038 
Epoch 228/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3707, val_MinusLogProbMetric: 2.3707

Epoch 228: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3707 - val_MinusLogProbMetric: 2.3707 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 229/1000
2023-09-11 16:28:41.727 
Epoch 229/1000 
	 loss: 2.3796, MinusLogProbMetric: 2.3796, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 229: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3796 - MinusLogProbMetric: 2.3796 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-11 16:28:53.389 
Epoch 230/1000 
	 loss: 2.3795, MinusLogProbMetric: 2.3795, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 230: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3795 - MinusLogProbMetric: 2.3795 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 231/1000
2023-09-11 16:29:05.257 
Epoch 231/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.3663, val_MinusLogProbMetric: 2.3663

Epoch 231: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.3663 - val_MinusLogProbMetric: 2.3663 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 232/1000
2023-09-11 16:29:17.153 
Epoch 232/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 232: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 233/1000
2023-09-11 16:29:28.984 
Epoch 233/1000 
	 loss: 2.3805, MinusLogProbMetric: 2.3805, val_loss: 2.3570, val_MinusLogProbMetric: 2.3570

Epoch 233: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3805 - MinusLogProbMetric: 2.3805 - val_loss: 2.3570 - val_MinusLogProbMetric: 2.3570 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 234/1000
2023-09-11 16:29:40.708 
Epoch 234/1000 
	 loss: 2.3761, MinusLogProbMetric: 2.3761, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 234: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3761 - MinusLogProbMetric: 2.3761 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-11 16:29:52.666 
Epoch 235/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3805, val_MinusLogProbMetric: 2.3805

Epoch 235: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3805 - val_MinusLogProbMetric: 2.3805 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 236/1000
2023-09-11 16:30:04.461 
Epoch 236/1000 
	 loss: 2.3777, MinusLogProbMetric: 2.3777, val_loss: 2.3726, val_MinusLogProbMetric: 2.3726

Epoch 236: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3777 - MinusLogProbMetric: 2.3777 - val_loss: 2.3726 - val_MinusLogProbMetric: 2.3726 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 237/1000
2023-09-11 16:30:16.184 
Epoch 237/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.3561, val_MinusLogProbMetric: 2.3561

Epoch 237: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.3561 - val_MinusLogProbMetric: 2.3561 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 238/1000
2023-09-11 16:30:27.882 
Epoch 238/1000 
	 loss: 2.3794, MinusLogProbMetric: 2.3794, val_loss: 2.3740, val_MinusLogProbMetric: 2.3740

Epoch 238: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3794 - MinusLogProbMetric: 2.3794 - val_loss: 2.3740 - val_MinusLogProbMetric: 2.3740 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-11 16:30:39.576 
Epoch 239/1000 
	 loss: 2.3834, MinusLogProbMetric: 2.3834, val_loss: 2.3654, val_MinusLogProbMetric: 2.3654

Epoch 239: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3834 - MinusLogProbMetric: 2.3834 - val_loss: 2.3654 - val_MinusLogProbMetric: 2.3654 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 240/1000
2023-09-11 16:30:51.330 
Epoch 240/1000 
	 loss: 2.3815, MinusLogProbMetric: 2.3815, val_loss: 2.3658, val_MinusLogProbMetric: 2.3658

Epoch 240: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3815 - MinusLogProbMetric: 2.3815 - val_loss: 2.3658 - val_MinusLogProbMetric: 2.3658 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-11 16:31:03.103 
Epoch 241/1000 
	 loss: 2.3826, MinusLogProbMetric: 2.3826, val_loss: 2.3765, val_MinusLogProbMetric: 2.3765

Epoch 241: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3826 - MinusLogProbMetric: 2.3826 - val_loss: 2.3765 - val_MinusLogProbMetric: 2.3765 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 242/1000
2023-09-11 16:31:14.869 
Epoch 242/1000 
	 loss: 2.3792, MinusLogProbMetric: 2.3792, val_loss: 2.3818, val_MinusLogProbMetric: 2.3818

Epoch 242: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3792 - MinusLogProbMetric: 2.3792 - val_loss: 2.3818 - val_MinusLogProbMetric: 2.3818 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 243/1000
2023-09-11 16:31:26.508 
Epoch 243/1000 
	 loss: 2.3775, MinusLogProbMetric: 2.3775, val_loss: 2.3603, val_MinusLogProbMetric: 2.3603

Epoch 243: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3775 - MinusLogProbMetric: 2.3775 - val_loss: 2.3603 - val_MinusLogProbMetric: 2.3603 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 244/1000
2023-09-11 16:31:38.139 
Epoch 244/1000 
	 loss: 2.3801, MinusLogProbMetric: 2.3801, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 244: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3801 - MinusLogProbMetric: 2.3801 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 245/1000
2023-09-11 16:31:49.665 
Epoch 245/1000 
	 loss: 2.3795, MinusLogProbMetric: 2.3795, val_loss: 2.3784, val_MinusLogProbMetric: 2.3784

Epoch 245: val_loss did not improve from 2.35464
196/196 - 12s - loss: 2.3795 - MinusLogProbMetric: 2.3795 - val_loss: 2.3784 - val_MinusLogProbMetric: 2.3784 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 246/1000
2023-09-11 16:32:01.257 
Epoch 246/1000 
	 loss: 2.3813, MinusLogProbMetric: 2.3813, val_loss: 2.3543, val_MinusLogProbMetric: 2.3543

Epoch 246: val_loss improved from 2.35464 to 2.35430, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3813 - MinusLogProbMetric: 2.3813 - val_loss: 2.3543 - val_MinusLogProbMetric: 2.3543 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 247/1000
2023-09-11 16:32:13.079 
Epoch 247/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3579, val_MinusLogProbMetric: 2.3579

Epoch 247: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3579 - val_MinusLogProbMetric: 2.3579 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-11 16:32:24.892 
Epoch 248/1000 
	 loss: 2.3820, MinusLogProbMetric: 2.3820, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 248: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3820 - MinusLogProbMetric: 2.3820 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-11 16:32:36.677 
Epoch 249/1000 
	 loss: 2.3787, MinusLogProbMetric: 2.3787, val_loss: 2.3745, val_MinusLogProbMetric: 2.3745

Epoch 249: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3787 - MinusLogProbMetric: 2.3787 - val_loss: 2.3745 - val_MinusLogProbMetric: 2.3745 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 250/1000
2023-09-11 16:32:48.543 
Epoch 250/1000 
	 loss: 2.3771, MinusLogProbMetric: 2.3771, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 250: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3771 - MinusLogProbMetric: 2.3771 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 251/1000
2023-09-11 16:33:00.378 
Epoch 251/1000 
	 loss: 2.3750, MinusLogProbMetric: 2.3750, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 251: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3750 - MinusLogProbMetric: 2.3750 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 252/1000
2023-09-11 16:33:12.069 
Epoch 252/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 252: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-11 16:33:23.829 
Epoch 253/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3658, val_MinusLogProbMetric: 2.3658

Epoch 253: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3658 - val_MinusLogProbMetric: 2.3658 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 254/1000
2023-09-11 16:33:35.561 
Epoch 254/1000 
	 loss: 2.3770, MinusLogProbMetric: 2.3770, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 254: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3770 - MinusLogProbMetric: 2.3770 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-11 16:33:47.296 
Epoch 255/1000 
	 loss: 2.3775, MinusLogProbMetric: 2.3775, val_loss: 2.3776, val_MinusLogProbMetric: 2.3776

Epoch 255: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3775 - MinusLogProbMetric: 2.3775 - val_loss: 2.3776 - val_MinusLogProbMetric: 2.3776 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 256/1000
2023-09-11 16:33:59.078 
Epoch 256/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.3733, val_MinusLogProbMetric: 2.3733

Epoch 256: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.3733 - val_MinusLogProbMetric: 2.3733 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 257/1000
2023-09-11 16:34:10.917 
Epoch 257/1000 
	 loss: 2.3830, MinusLogProbMetric: 2.3830, val_loss: 2.3558, val_MinusLogProbMetric: 2.3558

Epoch 257: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3830 - MinusLogProbMetric: 2.3830 - val_loss: 2.3558 - val_MinusLogProbMetric: 2.3558 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-11 16:34:22.728 
Epoch 258/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 258: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 259/1000
2023-09-11 16:34:34.511 
Epoch 259/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 259: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 260/1000
2023-09-11 16:34:46.086 
Epoch 260/1000 
	 loss: 2.3795, MinusLogProbMetric: 2.3795, val_loss: 2.3700, val_MinusLogProbMetric: 2.3700

Epoch 260: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3795 - MinusLogProbMetric: 2.3795 - val_loss: 2.3700 - val_MinusLogProbMetric: 2.3700 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 261/1000
2023-09-11 16:34:57.726 
Epoch 261/1000 
	 loss: 2.3803, MinusLogProbMetric: 2.3803, val_loss: 2.3648, val_MinusLogProbMetric: 2.3648

Epoch 261: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3803 - MinusLogProbMetric: 2.3803 - val_loss: 2.3648 - val_MinusLogProbMetric: 2.3648 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 262/1000
2023-09-11 16:35:09.460 
Epoch 262/1000 
	 loss: 2.3759, MinusLogProbMetric: 2.3759, val_loss: 2.3787, val_MinusLogProbMetric: 2.3787

Epoch 262: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3759 - MinusLogProbMetric: 2.3759 - val_loss: 2.3787 - val_MinusLogProbMetric: 2.3787 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-11 16:35:21.235 
Epoch 263/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3760, val_MinusLogProbMetric: 2.3760

Epoch 263: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3760 - val_MinusLogProbMetric: 2.3760 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 264/1000
2023-09-11 16:35:32.997 
Epoch 264/1000 
	 loss: 2.3752, MinusLogProbMetric: 2.3752, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 264: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3752 - MinusLogProbMetric: 2.3752 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 265/1000
2023-09-11 16:35:44.768 
Epoch 265/1000 
	 loss: 2.3797, MinusLogProbMetric: 2.3797, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 265: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3797 - MinusLogProbMetric: 2.3797 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 266/1000
2023-09-11 16:35:56.521 
Epoch 266/1000 
	 loss: 2.3723, MinusLogProbMetric: 2.3723, val_loss: 2.3766, val_MinusLogProbMetric: 2.3766

Epoch 266: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3723 - MinusLogProbMetric: 2.3723 - val_loss: 2.3766 - val_MinusLogProbMetric: 2.3766 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 267/1000
2023-09-11 16:36:08.330 
Epoch 267/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.3751, val_MinusLogProbMetric: 2.3751

Epoch 267: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.3751 - val_MinusLogProbMetric: 2.3751 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 268/1000
2023-09-11 16:36:20.143 
Epoch 268/1000 
	 loss: 2.3781, MinusLogProbMetric: 2.3781, val_loss: 2.3756, val_MinusLogProbMetric: 2.3756

Epoch 268: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3781 - MinusLogProbMetric: 2.3781 - val_loss: 2.3756 - val_MinusLogProbMetric: 2.3756 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-11 16:36:31.942 
Epoch 269/1000 
	 loss: 2.3763, MinusLogProbMetric: 2.3763, val_loss: 2.3676, val_MinusLogProbMetric: 2.3676

Epoch 269: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3763 - MinusLogProbMetric: 2.3763 - val_loss: 2.3676 - val_MinusLogProbMetric: 2.3676 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 270/1000
2023-09-11 16:36:43.644 
Epoch 270/1000 
	 loss: 2.3788, MinusLogProbMetric: 2.3788, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 270: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3788 - MinusLogProbMetric: 2.3788 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 271/1000
2023-09-11 16:36:55.464 
Epoch 271/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3661, val_MinusLogProbMetric: 2.3661

Epoch 271: val_loss did not improve from 2.35430
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3661 - val_MinusLogProbMetric: 2.3661 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-11 16:37:07.263 
Epoch 272/1000 
	 loss: 2.3777, MinusLogProbMetric: 2.3777, val_loss: 2.3536, val_MinusLogProbMetric: 2.3536

Epoch 272: val_loss improved from 2.35430 to 2.35360, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3777 - MinusLogProbMetric: 2.3777 - val_loss: 2.3536 - val_MinusLogProbMetric: 2.3536 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 273/1000
2023-09-11 16:37:19.066 
Epoch 273/1000 
	 loss: 2.3780, MinusLogProbMetric: 2.3780, val_loss: 2.3581, val_MinusLogProbMetric: 2.3581

Epoch 273: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3780 - MinusLogProbMetric: 2.3780 - val_loss: 2.3581 - val_MinusLogProbMetric: 2.3581 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 274/1000
2023-09-11 16:37:30.938 
Epoch 274/1000 
	 loss: 2.3746, MinusLogProbMetric: 2.3746, val_loss: 2.3571, val_MinusLogProbMetric: 2.3571

Epoch 274: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3746 - MinusLogProbMetric: 2.3746 - val_loss: 2.3571 - val_MinusLogProbMetric: 2.3571 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 275/1000
2023-09-11 16:37:42.745 
Epoch 275/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 275: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 276/1000
2023-09-11 16:37:54.381 
Epoch 276/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3609, val_MinusLogProbMetric: 2.3609

Epoch 276: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3609 - val_MinusLogProbMetric: 2.3609 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 277/1000
2023-09-11 16:38:06.146 
Epoch 277/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.3650, val_MinusLogProbMetric: 2.3650

Epoch 277: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.3650 - val_MinusLogProbMetric: 2.3650 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 278/1000
2023-09-11 16:38:17.814 
Epoch 278/1000 
	 loss: 2.3736, MinusLogProbMetric: 2.3736, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 278: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3736 - MinusLogProbMetric: 2.3736 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 279/1000
2023-09-11 16:38:29.576 
Epoch 279/1000 
	 loss: 2.3770, MinusLogProbMetric: 2.3770, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 279: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3770 - MinusLogProbMetric: 2.3770 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 280/1000
2023-09-11 16:38:41.326 
Epoch 280/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.3797, val_MinusLogProbMetric: 2.3797

Epoch 280: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.3797 - val_MinusLogProbMetric: 2.3797 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-11 16:38:53.133 
Epoch 281/1000 
	 loss: 2.3768, MinusLogProbMetric: 2.3768, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 281: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3768 - MinusLogProbMetric: 2.3768 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 282/1000
2023-09-11 16:39:04.812 
Epoch 282/1000 
	 loss: 2.3780, MinusLogProbMetric: 2.3780, val_loss: 2.3584, val_MinusLogProbMetric: 2.3584

Epoch 282: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3780 - MinusLogProbMetric: 2.3780 - val_loss: 2.3584 - val_MinusLogProbMetric: 2.3584 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 283/1000
2023-09-11 16:39:16.618 
Epoch 283/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 283: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-11 16:39:28.339 
Epoch 284/1000 
	 loss: 2.3746, MinusLogProbMetric: 2.3746, val_loss: 2.3667, val_MinusLogProbMetric: 2.3667

Epoch 284: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3746 - MinusLogProbMetric: 2.3746 - val_loss: 2.3667 - val_MinusLogProbMetric: 2.3667 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 285/1000
2023-09-11 16:39:39.961 
Epoch 285/1000 
	 loss: 2.3736, MinusLogProbMetric: 2.3736, val_loss: 2.3609, val_MinusLogProbMetric: 2.3609

Epoch 285: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3736 - MinusLogProbMetric: 2.3736 - val_loss: 2.3609 - val_MinusLogProbMetric: 2.3609 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 286/1000
2023-09-11 16:39:51.607 
Epoch 286/1000 
	 loss: 2.3771, MinusLogProbMetric: 2.3771, val_loss: 2.3760, val_MinusLogProbMetric: 2.3760

Epoch 286: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3771 - MinusLogProbMetric: 2.3771 - val_loss: 2.3760 - val_MinusLogProbMetric: 2.3760 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 287/1000
2023-09-11 16:40:03.289 
Epoch 287/1000 
	 loss: 2.3748, MinusLogProbMetric: 2.3748, val_loss: 2.3543, val_MinusLogProbMetric: 2.3543

Epoch 287: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3748 - MinusLogProbMetric: 2.3748 - val_loss: 2.3543 - val_MinusLogProbMetric: 2.3543 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 288/1000
2023-09-11 16:40:15.006 
Epoch 288/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 288: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 289/1000
2023-09-11 16:40:26.692 
Epoch 289/1000 
	 loss: 2.3752, MinusLogProbMetric: 2.3752, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 289: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3752 - MinusLogProbMetric: 2.3752 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 290/1000
2023-09-11 16:40:38.368 
Epoch 290/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3937, val_MinusLogProbMetric: 2.3937

Epoch 290: val_loss did not improve from 2.35360
196/196 - 12s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3937 - val_MinusLogProbMetric: 2.3937 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 291/1000
2023-09-11 16:40:50.204 
Epoch 291/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.3528, val_MinusLogProbMetric: 2.3528

Epoch 291: val_loss improved from 2.35360 to 2.35283, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.3528 - val_MinusLogProbMetric: 2.3528 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 292/1000
2023-09-11 16:41:01.981 
Epoch 292/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3678, val_MinusLogProbMetric: 2.3678

Epoch 292: val_loss did not improve from 2.35283
196/196 - 12s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3678 - val_MinusLogProbMetric: 2.3678 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 293/1000
2023-09-11 16:41:13.761 
Epoch 293/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3527, val_MinusLogProbMetric: 2.3527

Epoch 293: val_loss improved from 2.35283 to 2.35266, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3527 - val_MinusLogProbMetric: 2.3527 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 294/1000
2023-09-11 16:41:25.695 
Epoch 294/1000 
	 loss: 2.3775, MinusLogProbMetric: 2.3775, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 294: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3775 - MinusLogProbMetric: 2.3775 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 295/1000
2023-09-11 16:41:37.627 
Epoch 295/1000 
	 loss: 2.3743, MinusLogProbMetric: 2.3743, val_loss: 2.3815, val_MinusLogProbMetric: 2.3815

Epoch 295: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3743 - MinusLogProbMetric: 2.3743 - val_loss: 2.3815 - val_MinusLogProbMetric: 2.3815 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 296/1000
2023-09-11 16:41:49.516 
Epoch 296/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3707, val_MinusLogProbMetric: 2.3707

Epoch 296: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3707 - val_MinusLogProbMetric: 2.3707 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 297/1000
2023-09-11 16:42:01.365 
Epoch 297/1000 
	 loss: 2.3753, MinusLogProbMetric: 2.3753, val_loss: 2.3672, val_MinusLogProbMetric: 2.3672

Epoch 297: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3753 - MinusLogProbMetric: 2.3753 - val_loss: 2.3672 - val_MinusLogProbMetric: 2.3672 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 298/1000
2023-09-11 16:42:13.230 
Epoch 298/1000 
	 loss: 2.3776, MinusLogProbMetric: 2.3776, val_loss: 2.3724, val_MinusLogProbMetric: 2.3724

Epoch 298: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3776 - MinusLogProbMetric: 2.3776 - val_loss: 2.3724 - val_MinusLogProbMetric: 2.3724 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 299/1000
2023-09-11 16:42:25.010 
Epoch 299/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 299: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 300/1000
2023-09-11 16:42:36.856 
Epoch 300/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.3812, val_MinusLogProbMetric: 2.3812

Epoch 300: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.3812 - val_MinusLogProbMetric: 2.3812 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 301/1000
2023-09-11 16:42:48.763 
Epoch 301/1000 
	 loss: 2.3796, MinusLogProbMetric: 2.3796, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 301: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3796 - MinusLogProbMetric: 2.3796 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 302/1000
2023-09-11 16:43:00.392 
Epoch 302/1000 
	 loss: 2.3736, MinusLogProbMetric: 2.3736, val_loss: 2.3856, val_MinusLogProbMetric: 2.3856

Epoch 302: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3736 - MinusLogProbMetric: 2.3736 - val_loss: 2.3856 - val_MinusLogProbMetric: 2.3856 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 303/1000
2023-09-11 16:43:12.216 
Epoch 303/1000 
	 loss: 2.3734, MinusLogProbMetric: 2.3734, val_loss: 2.3759, val_MinusLogProbMetric: 2.3759

Epoch 303: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3734 - MinusLogProbMetric: 2.3734 - val_loss: 2.3759 - val_MinusLogProbMetric: 2.3759 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 304/1000
2023-09-11 16:43:23.885 
Epoch 304/1000 
	 loss: 2.3745, MinusLogProbMetric: 2.3745, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 304: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3745 - MinusLogProbMetric: 2.3745 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 305/1000
2023-09-11 16:43:35.514 
Epoch 305/1000 
	 loss: 2.3801, MinusLogProbMetric: 2.3801, val_loss: 2.3537, val_MinusLogProbMetric: 2.3537

Epoch 305: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3801 - MinusLogProbMetric: 2.3801 - val_loss: 2.3537 - val_MinusLogProbMetric: 2.3537 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 306/1000
2023-09-11 16:43:47.239 
Epoch 306/1000 
	 loss: 2.3788, MinusLogProbMetric: 2.3788, val_loss: 2.3546, val_MinusLogProbMetric: 2.3546

Epoch 306: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3788 - MinusLogProbMetric: 2.3788 - val_loss: 2.3546 - val_MinusLogProbMetric: 2.3546 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 307/1000
2023-09-11 16:43:59.021 
Epoch 307/1000 
	 loss: 2.3742, MinusLogProbMetric: 2.3742, val_loss: 2.3603, val_MinusLogProbMetric: 2.3603

Epoch 307: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3742 - MinusLogProbMetric: 2.3742 - val_loss: 2.3603 - val_MinusLogProbMetric: 2.3603 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 308/1000
2023-09-11 16:44:10.794 
Epoch 308/1000 
	 loss: 2.3733, MinusLogProbMetric: 2.3733, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 308: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3733 - MinusLogProbMetric: 2.3733 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 309/1000
2023-09-11 16:44:22.477 
Epoch 309/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3597, val_MinusLogProbMetric: 2.3597

Epoch 309: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3597 - val_MinusLogProbMetric: 2.3597 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 310/1000
2023-09-11 16:44:34.065 
Epoch 310/1000 
	 loss: 2.3751, MinusLogProbMetric: 2.3751, val_loss: 2.3610, val_MinusLogProbMetric: 2.3610

Epoch 310: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3751 - MinusLogProbMetric: 2.3751 - val_loss: 2.3610 - val_MinusLogProbMetric: 2.3610 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 311/1000
2023-09-11 16:44:45.725 
Epoch 311/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.3559, val_MinusLogProbMetric: 2.3559

Epoch 311: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.3559 - val_MinusLogProbMetric: 2.3559 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 312/1000
2023-09-11 16:44:57.379 
Epoch 312/1000 
	 loss: 2.3732, MinusLogProbMetric: 2.3732, val_loss: 2.3818, val_MinusLogProbMetric: 2.3818

Epoch 312: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3732 - MinusLogProbMetric: 2.3732 - val_loss: 2.3818 - val_MinusLogProbMetric: 2.3818 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 313/1000
2023-09-11 16:45:09.105 
Epoch 313/1000 
	 loss: 2.3732, MinusLogProbMetric: 2.3732, val_loss: 2.3604, val_MinusLogProbMetric: 2.3604

Epoch 313: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3732 - MinusLogProbMetric: 2.3732 - val_loss: 2.3604 - val_MinusLogProbMetric: 2.3604 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 314/1000
2023-09-11 16:45:20.720 
Epoch 314/1000 
	 loss: 2.3762, MinusLogProbMetric: 2.3762, val_loss: 2.3948, val_MinusLogProbMetric: 2.3948

Epoch 314: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3762 - MinusLogProbMetric: 2.3762 - val_loss: 2.3948 - val_MinusLogProbMetric: 2.3948 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 315/1000
2023-09-11 16:45:32.397 
Epoch 315/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3564, val_MinusLogProbMetric: 2.3564

Epoch 315: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3564 - val_MinusLogProbMetric: 2.3564 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-11 16:45:44.219 
Epoch 316/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 316: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 317/1000
2023-09-11 16:45:55.962 
Epoch 317/1000 
	 loss: 2.3747, MinusLogProbMetric: 2.3747, val_loss: 2.3656, val_MinusLogProbMetric: 2.3656

Epoch 317: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3747 - MinusLogProbMetric: 2.3747 - val_loss: 2.3656 - val_MinusLogProbMetric: 2.3656 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 318/1000
2023-09-11 16:46:07.643 
Epoch 318/1000 
	 loss: 2.3787, MinusLogProbMetric: 2.3787, val_loss: 2.3648, val_MinusLogProbMetric: 2.3648

Epoch 318: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3787 - MinusLogProbMetric: 2.3787 - val_loss: 2.3648 - val_MinusLogProbMetric: 2.3648 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 319/1000
2023-09-11 16:46:19.431 
Epoch 319/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.3725, val_MinusLogProbMetric: 2.3725

Epoch 319: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.3725 - val_MinusLogProbMetric: 2.3725 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 320/1000
2023-09-11 16:46:31.235 
Epoch 320/1000 
	 loss: 2.3743, MinusLogProbMetric: 2.3743, val_loss: 2.3551, val_MinusLogProbMetric: 2.3551

Epoch 320: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3743 - MinusLogProbMetric: 2.3743 - val_loss: 2.3551 - val_MinusLogProbMetric: 2.3551 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 321/1000
2023-09-11 16:46:42.978 
Epoch 321/1000 
	 loss: 2.3750, MinusLogProbMetric: 2.3750, val_loss: 2.3722, val_MinusLogProbMetric: 2.3722

Epoch 321: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3750 - MinusLogProbMetric: 2.3750 - val_loss: 2.3722 - val_MinusLogProbMetric: 2.3722 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 322/1000
2023-09-11 16:46:54.726 
Epoch 322/1000 
	 loss: 2.3723, MinusLogProbMetric: 2.3723, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 322: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3723 - MinusLogProbMetric: 2.3723 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 323/1000
2023-09-11 16:47:06.546 
Epoch 323/1000 
	 loss: 2.3728, MinusLogProbMetric: 2.3728, val_loss: 2.3554, val_MinusLogProbMetric: 2.3554

Epoch 323: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3728 - MinusLogProbMetric: 2.3728 - val_loss: 2.3554 - val_MinusLogProbMetric: 2.3554 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 324/1000
2023-09-11 16:47:18.276 
Epoch 324/1000 
	 loss: 2.3736, MinusLogProbMetric: 2.3736, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 324: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3736 - MinusLogProbMetric: 2.3736 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 325/1000
2023-09-11 16:47:29.994 
Epoch 325/1000 
	 loss: 2.3740, MinusLogProbMetric: 2.3740, val_loss: 2.3664, val_MinusLogProbMetric: 2.3664

Epoch 325: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3740 - MinusLogProbMetric: 2.3740 - val_loss: 2.3664 - val_MinusLogProbMetric: 2.3664 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 326/1000
2023-09-11 16:47:41.673 
Epoch 326/1000 
	 loss: 2.3753, MinusLogProbMetric: 2.3753, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 326: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3753 - MinusLogProbMetric: 2.3753 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-11 16:47:53.480 
Epoch 327/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3931, val_MinusLogProbMetric: 2.3931

Epoch 327: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3931 - val_MinusLogProbMetric: 2.3931 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 328/1000
2023-09-11 16:48:05.170 
Epoch 328/1000 
	 loss: 2.3730, MinusLogProbMetric: 2.3730, val_loss: 2.3607, val_MinusLogProbMetric: 2.3607

Epoch 328: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3730 - MinusLogProbMetric: 2.3730 - val_loss: 2.3607 - val_MinusLogProbMetric: 2.3607 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 329/1000
2023-09-11 16:48:17.031 
Epoch 329/1000 
	 loss: 2.3723, MinusLogProbMetric: 2.3723, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 329: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3723 - MinusLogProbMetric: 2.3723 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 330/1000
2023-09-11 16:48:28.654 
Epoch 330/1000 
	 loss: 2.3732, MinusLogProbMetric: 2.3732, val_loss: 2.3545, val_MinusLogProbMetric: 2.3545

Epoch 330: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3732 - MinusLogProbMetric: 2.3732 - val_loss: 2.3545 - val_MinusLogProbMetric: 2.3545 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 331/1000
2023-09-11 16:48:40.344 
Epoch 331/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3674, val_MinusLogProbMetric: 2.3674

Epoch 331: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3674 - val_MinusLogProbMetric: 2.3674 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 332/1000
2023-09-11 16:48:52.115 
Epoch 332/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3563, val_MinusLogProbMetric: 2.3563

Epoch 332: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3563 - val_MinusLogProbMetric: 2.3563 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 333/1000
2023-09-11 16:49:03.794 
Epoch 333/1000 
	 loss: 2.3740, MinusLogProbMetric: 2.3740, val_loss: 2.3561, val_MinusLogProbMetric: 2.3561

Epoch 333: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3740 - MinusLogProbMetric: 2.3740 - val_loss: 2.3561 - val_MinusLogProbMetric: 2.3561 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 334/1000
2023-09-11 16:49:15.613 
Epoch 334/1000 
	 loss: 2.3740, MinusLogProbMetric: 2.3740, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 334: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3740 - MinusLogProbMetric: 2.3740 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 335/1000
2023-09-11 16:49:27.310 
Epoch 335/1000 
	 loss: 2.3724, MinusLogProbMetric: 2.3724, val_loss: 2.3675, val_MinusLogProbMetric: 2.3675

Epoch 335: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3724 - MinusLogProbMetric: 2.3724 - val_loss: 2.3675 - val_MinusLogProbMetric: 2.3675 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 336/1000
2023-09-11 16:49:39.022 
Epoch 336/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.3572, val_MinusLogProbMetric: 2.3572

Epoch 336: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.3572 - val_MinusLogProbMetric: 2.3572 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 337/1000
2023-09-11 16:49:50.799 
Epoch 337/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.4359, val_MinusLogProbMetric: 2.4359

Epoch 337: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.4359 - val_MinusLogProbMetric: 2.4359 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 338/1000
2023-09-11 16:50:02.486 
Epoch 338/1000 
	 loss: 2.3761, MinusLogProbMetric: 2.3761, val_loss: 2.3807, val_MinusLogProbMetric: 2.3807

Epoch 338: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3761 - MinusLogProbMetric: 2.3761 - val_loss: 2.3807 - val_MinusLogProbMetric: 2.3807 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 339/1000
2023-09-11 16:50:14.134 
Epoch 339/1000 
	 loss: 2.3730, MinusLogProbMetric: 2.3730, val_loss: 2.3723, val_MinusLogProbMetric: 2.3723

Epoch 339: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3730 - MinusLogProbMetric: 2.3730 - val_loss: 2.3723 - val_MinusLogProbMetric: 2.3723 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 340/1000
2023-09-11 16:50:25.887 
Epoch 340/1000 
	 loss: 2.3745, MinusLogProbMetric: 2.3745, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 340: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3745 - MinusLogProbMetric: 2.3745 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 341/1000
2023-09-11 16:50:37.698 
Epoch 341/1000 
	 loss: 2.3750, MinusLogProbMetric: 2.3750, val_loss: 2.3658, val_MinusLogProbMetric: 2.3658

Epoch 341: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3750 - MinusLogProbMetric: 2.3750 - val_loss: 2.3658 - val_MinusLogProbMetric: 2.3658 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 342/1000
2023-09-11 16:50:49.482 
Epoch 342/1000 
	 loss: 2.3736, MinusLogProbMetric: 2.3736, val_loss: 2.3731, val_MinusLogProbMetric: 2.3731

Epoch 342: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3736 - MinusLogProbMetric: 2.3736 - val_loss: 2.3731 - val_MinusLogProbMetric: 2.3731 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-11 16:51:01.371 
Epoch 343/1000 
	 loss: 2.3747, MinusLogProbMetric: 2.3747, val_loss: 2.3572, val_MinusLogProbMetric: 2.3572

Epoch 343: val_loss did not improve from 2.35266
196/196 - 12s - loss: 2.3747 - MinusLogProbMetric: 2.3747 - val_loss: 2.3572 - val_MinusLogProbMetric: 2.3572 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 344/1000
2023-09-11 16:51:13.071 
Epoch 344/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3508, val_MinusLogProbMetric: 2.3508

Epoch 344: val_loss improved from 2.35266 to 2.35078, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3508 - val_MinusLogProbMetric: 2.3508 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 345/1000
2023-09-11 16:51:24.923 
Epoch 345/1000 
	 loss: 2.3652, MinusLogProbMetric: 2.3652, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 345: val_loss did not improve from 2.35078
196/196 - 12s - loss: 2.3652 - MinusLogProbMetric: 2.3652 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 346/1000
2023-09-11 16:51:36.629 
Epoch 346/1000 
	 loss: 2.3658, MinusLogProbMetric: 2.3658, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 346: val_loss did not improve from 2.35078
196/196 - 12s - loss: 2.3658 - MinusLogProbMetric: 2.3658 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 347/1000
2023-09-11 16:51:48.287 
Epoch 347/1000 
	 loss: 2.3624, MinusLogProbMetric: 2.3624, val_loss: 2.3562, val_MinusLogProbMetric: 2.3562

Epoch 347: val_loss did not improve from 2.35078
196/196 - 12s - loss: 2.3624 - MinusLogProbMetric: 2.3624 - val_loss: 2.3562 - val_MinusLogProbMetric: 2.3562 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 348/1000
2023-09-11 16:52:00.032 
Epoch 348/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.3527, val_MinusLogProbMetric: 2.3527

Epoch 348: val_loss did not improve from 2.35078
196/196 - 12s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.3527 - val_MinusLogProbMetric: 2.3527 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 349/1000
2023-09-11 16:52:11.756 
Epoch 349/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3488, val_MinusLogProbMetric: 2.3488

Epoch 349: val_loss improved from 2.35078 to 2.34879, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3488 - val_MinusLogProbMetric: 2.3488 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 350/1000
2023-09-11 16:52:23.638 
Epoch 350/1000 
	 loss: 2.3660, MinusLogProbMetric: 2.3660, val_loss: 2.3521, val_MinusLogProbMetric: 2.3521

Epoch 350: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3660 - MinusLogProbMetric: 2.3660 - val_loss: 2.3521 - val_MinusLogProbMetric: 2.3521 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 351/1000
2023-09-11 16:52:35.378 
Epoch 351/1000 
	 loss: 2.3641, MinusLogProbMetric: 2.3641, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 351: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3641 - MinusLogProbMetric: 2.3641 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 352/1000
2023-09-11 16:52:47.199 
Epoch 352/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3497, val_MinusLogProbMetric: 2.3497

Epoch 352: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3497 - val_MinusLogProbMetric: 2.3497 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 353/1000
2023-09-11 16:52:58.718 
Epoch 353/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3571, val_MinusLogProbMetric: 2.3571

Epoch 353: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3571 - val_MinusLogProbMetric: 2.3571 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 354/1000
2023-09-11 16:53:10.508 
Epoch 354/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3528, val_MinusLogProbMetric: 2.3528

Epoch 354: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3528 - val_MinusLogProbMetric: 2.3528 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 355/1000
2023-09-11 16:53:22.275 
Epoch 355/1000 
	 loss: 2.3639, MinusLogProbMetric: 2.3639, val_loss: 2.3540, val_MinusLogProbMetric: 2.3540

Epoch 355: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3639 - MinusLogProbMetric: 2.3639 - val_loss: 2.3540 - val_MinusLogProbMetric: 2.3540 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 356/1000
2023-09-11 16:53:34.029 
Epoch 356/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3608, val_MinusLogProbMetric: 2.3608

Epoch 356: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3608 - val_MinusLogProbMetric: 2.3608 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 357/1000
2023-09-11 16:53:45.872 
Epoch 357/1000 
	 loss: 2.3653, MinusLogProbMetric: 2.3653, val_loss: 2.3543, val_MinusLogProbMetric: 2.3543

Epoch 357: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3653 - MinusLogProbMetric: 2.3653 - val_loss: 2.3543 - val_MinusLogProbMetric: 2.3543 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 358/1000
2023-09-11 16:53:57.734 
Epoch 358/1000 
	 loss: 2.3645, MinusLogProbMetric: 2.3645, val_loss: 2.3528, val_MinusLogProbMetric: 2.3528

Epoch 358: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3645 - MinusLogProbMetric: 2.3645 - val_loss: 2.3528 - val_MinusLogProbMetric: 2.3528 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 359/1000
2023-09-11 16:54:09.369 
Epoch 359/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.3514, val_MinusLogProbMetric: 2.3514

Epoch 359: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.3514 - val_MinusLogProbMetric: 2.3514 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 360/1000
2023-09-11 16:54:21.059 
Epoch 360/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3497, val_MinusLogProbMetric: 2.3497

Epoch 360: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3497 - val_MinusLogProbMetric: 2.3497 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 361/1000
2023-09-11 16:54:32.773 
Epoch 361/1000 
	 loss: 2.3639, MinusLogProbMetric: 2.3639, val_loss: 2.3563, val_MinusLogProbMetric: 2.3563

Epoch 361: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3639 - MinusLogProbMetric: 2.3639 - val_loss: 2.3563 - val_MinusLogProbMetric: 2.3563 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 362/1000
2023-09-11 16:54:44.584 
Epoch 362/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 362: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 363/1000
2023-09-11 16:54:56.388 
Epoch 363/1000 
	 loss: 2.3638, MinusLogProbMetric: 2.3638, val_loss: 2.3556, val_MinusLogProbMetric: 2.3556

Epoch 363: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3638 - MinusLogProbMetric: 2.3638 - val_loss: 2.3556 - val_MinusLogProbMetric: 2.3556 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 364/1000
2023-09-11 16:55:08.032 
Epoch 364/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3573, val_MinusLogProbMetric: 2.3573

Epoch 364: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3573 - val_MinusLogProbMetric: 2.3573 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 365/1000
2023-09-11 16:55:19.755 
Epoch 365/1000 
	 loss: 2.3659, MinusLogProbMetric: 2.3659, val_loss: 2.3578, val_MinusLogProbMetric: 2.3578

Epoch 365: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3659 - MinusLogProbMetric: 2.3659 - val_loss: 2.3578 - val_MinusLogProbMetric: 2.3578 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 366/1000
2023-09-11 16:55:31.701 
Epoch 366/1000 
	 loss: 2.3658, MinusLogProbMetric: 2.3658, val_loss: 2.3539, val_MinusLogProbMetric: 2.3539

Epoch 366: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3658 - MinusLogProbMetric: 2.3658 - val_loss: 2.3539 - val_MinusLogProbMetric: 2.3539 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 367/1000
2023-09-11 16:55:43.520 
Epoch 367/1000 
	 loss: 2.3649, MinusLogProbMetric: 2.3649, val_loss: 2.3540, val_MinusLogProbMetric: 2.3540

Epoch 367: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3649 - MinusLogProbMetric: 2.3649 - val_loss: 2.3540 - val_MinusLogProbMetric: 2.3540 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 368/1000
2023-09-11 16:55:55.248 
Epoch 368/1000 
	 loss: 2.3649, MinusLogProbMetric: 2.3649, val_loss: 2.3557, val_MinusLogProbMetric: 2.3557

Epoch 368: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3649 - MinusLogProbMetric: 2.3649 - val_loss: 2.3557 - val_MinusLogProbMetric: 2.3557 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 369/1000
2023-09-11 16:56:06.979 
Epoch 369/1000 
	 loss: 2.3647, MinusLogProbMetric: 2.3647, val_loss: 2.3578, val_MinusLogProbMetric: 2.3578

Epoch 369: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3647 - MinusLogProbMetric: 2.3647 - val_loss: 2.3578 - val_MinusLogProbMetric: 2.3578 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 370/1000
2023-09-11 16:56:18.649 
Epoch 370/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.3500, val_MinusLogProbMetric: 2.3500

Epoch 370: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.3500 - val_MinusLogProbMetric: 2.3500 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 371/1000
2023-09-11 16:56:30.175 
Epoch 371/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3558, val_MinusLogProbMetric: 2.3558

Epoch 371: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3558 - val_MinusLogProbMetric: 2.3558 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 372/1000
2023-09-11 16:56:41.756 
Epoch 372/1000 
	 loss: 2.3631, MinusLogProbMetric: 2.3631, val_loss: 2.3514, val_MinusLogProbMetric: 2.3514

Epoch 372: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3631 - MinusLogProbMetric: 2.3631 - val_loss: 2.3514 - val_MinusLogProbMetric: 2.3514 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 373/1000
2023-09-11 16:56:53.341 
Epoch 373/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3546, val_MinusLogProbMetric: 2.3546

Epoch 373: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3546 - val_MinusLogProbMetric: 2.3546 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 374/1000
2023-09-11 16:57:05.151 
Epoch 374/1000 
	 loss: 2.3643, MinusLogProbMetric: 2.3643, val_loss: 2.3534, val_MinusLogProbMetric: 2.3534

Epoch 374: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3643 - MinusLogProbMetric: 2.3643 - val_loss: 2.3534 - val_MinusLogProbMetric: 2.3534 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 375/1000
2023-09-11 16:57:16.765 
Epoch 375/1000 
	 loss: 2.3648, MinusLogProbMetric: 2.3648, val_loss: 2.3518, val_MinusLogProbMetric: 2.3518

Epoch 375: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3648 - MinusLogProbMetric: 2.3648 - val_loss: 2.3518 - val_MinusLogProbMetric: 2.3518 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 376/1000
2023-09-11 16:57:28.544 
Epoch 376/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 376: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-11 16:57:40.441 
Epoch 377/1000 
	 loss: 2.3640, MinusLogProbMetric: 2.3640, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 377: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3640 - MinusLogProbMetric: 2.3640 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 378/1000
2023-09-11 16:57:52.206 
Epoch 378/1000 
	 loss: 2.3649, MinusLogProbMetric: 2.3649, val_loss: 2.3524, val_MinusLogProbMetric: 2.3524

Epoch 378: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3649 - MinusLogProbMetric: 2.3649 - val_loss: 2.3524 - val_MinusLogProbMetric: 2.3524 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 379/1000
2023-09-11 16:58:03.862 
Epoch 379/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3502, val_MinusLogProbMetric: 2.3502

Epoch 379: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3502 - val_MinusLogProbMetric: 2.3502 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 380/1000
2023-09-11 16:58:15.541 
Epoch 380/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 380: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 381/1000
2023-09-11 16:58:27.262 
Epoch 381/1000 
	 loss: 2.3659, MinusLogProbMetric: 2.3659, val_loss: 2.3555, val_MinusLogProbMetric: 2.3555

Epoch 381: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3659 - MinusLogProbMetric: 2.3659 - val_loss: 2.3555 - val_MinusLogProbMetric: 2.3555 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 382/1000
2023-09-11 16:58:38.895 
Epoch 382/1000 
	 loss: 2.3643, MinusLogProbMetric: 2.3643, val_loss: 2.3608, val_MinusLogProbMetric: 2.3608

Epoch 382: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3643 - MinusLogProbMetric: 2.3643 - val_loss: 2.3608 - val_MinusLogProbMetric: 2.3608 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 383/1000
2023-09-11 16:58:50.735 
Epoch 383/1000 
	 loss: 2.3638, MinusLogProbMetric: 2.3638, val_loss: 2.3495, val_MinusLogProbMetric: 2.3495

Epoch 383: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3638 - MinusLogProbMetric: 2.3638 - val_loss: 2.3495 - val_MinusLogProbMetric: 2.3495 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 384/1000
2023-09-11 16:59:02.441 
Epoch 384/1000 
	 loss: 2.3682, MinusLogProbMetric: 2.3682, val_loss: 2.3555, val_MinusLogProbMetric: 2.3555

Epoch 384: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3682 - MinusLogProbMetric: 2.3682 - val_loss: 2.3555 - val_MinusLogProbMetric: 2.3555 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 385/1000
2023-09-11 16:59:14.160 
Epoch 385/1000 
	 loss: 2.3627, MinusLogProbMetric: 2.3627, val_loss: 2.3539, val_MinusLogProbMetric: 2.3539

Epoch 385: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3627 - MinusLogProbMetric: 2.3627 - val_loss: 2.3539 - val_MinusLogProbMetric: 2.3539 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 386/1000
2023-09-11 16:59:25.856 
Epoch 386/1000 
	 loss: 2.3646, MinusLogProbMetric: 2.3646, val_loss: 2.3560, val_MinusLogProbMetric: 2.3560

Epoch 386: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3646 - MinusLogProbMetric: 2.3646 - val_loss: 2.3560 - val_MinusLogProbMetric: 2.3560 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 387/1000
2023-09-11 16:59:37.591 
Epoch 387/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3508, val_MinusLogProbMetric: 2.3508

Epoch 387: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3508 - val_MinusLogProbMetric: 2.3508 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 388/1000
2023-09-11 16:59:49.225 
Epoch 388/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3521, val_MinusLogProbMetric: 2.3521

Epoch 388: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3521 - val_MinusLogProbMetric: 2.3521 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 389/1000
2023-09-11 17:00:00.956 
Epoch 389/1000 
	 loss: 2.3653, MinusLogProbMetric: 2.3653, val_loss: 2.3520, val_MinusLogProbMetric: 2.3520

Epoch 389: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3653 - MinusLogProbMetric: 2.3653 - val_loss: 2.3520 - val_MinusLogProbMetric: 2.3520 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 390/1000
2023-09-11 17:00:12.623 
Epoch 390/1000 
	 loss: 2.3642, MinusLogProbMetric: 2.3642, val_loss: 2.3522, val_MinusLogProbMetric: 2.3522

Epoch 390: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3642 - MinusLogProbMetric: 2.3642 - val_loss: 2.3522 - val_MinusLogProbMetric: 2.3522 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 391/1000
2023-09-11 17:00:24.329 
Epoch 391/1000 
	 loss: 2.3640, MinusLogProbMetric: 2.3640, val_loss: 2.3571, val_MinusLogProbMetric: 2.3571

Epoch 391: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3640 - MinusLogProbMetric: 2.3640 - val_loss: 2.3571 - val_MinusLogProbMetric: 2.3571 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 392/1000
2023-09-11 17:00:36.082 
Epoch 392/1000 
	 loss: 2.3651, MinusLogProbMetric: 2.3651, val_loss: 2.3553, val_MinusLogProbMetric: 2.3553

Epoch 392: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3651 - MinusLogProbMetric: 2.3651 - val_loss: 2.3553 - val_MinusLogProbMetric: 2.3553 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 393/1000
2023-09-11 17:00:47.747 
Epoch 393/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3578, val_MinusLogProbMetric: 2.3578

Epoch 393: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3578 - val_MinusLogProbMetric: 2.3578 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 394/1000
2023-09-11 17:00:59.514 
Epoch 394/1000 
	 loss: 2.3624, MinusLogProbMetric: 2.3624, val_loss: 2.3574, val_MinusLogProbMetric: 2.3574

Epoch 394: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3624 - MinusLogProbMetric: 2.3624 - val_loss: 2.3574 - val_MinusLogProbMetric: 2.3574 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 395/1000
2023-09-11 17:01:11.114 
Epoch 395/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 395: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 396/1000
2023-09-11 17:01:22.814 
Epoch 396/1000 
	 loss: 2.3639, MinusLogProbMetric: 2.3639, val_loss: 2.3511, val_MinusLogProbMetric: 2.3511

Epoch 396: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3639 - MinusLogProbMetric: 2.3639 - val_loss: 2.3511 - val_MinusLogProbMetric: 2.3511 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 397/1000
2023-09-11 17:01:34.556 
Epoch 397/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3576, val_MinusLogProbMetric: 2.3576

Epoch 397: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3576 - val_MinusLogProbMetric: 2.3576 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 398/1000
2023-09-11 17:01:46.274 
Epoch 398/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3529, val_MinusLogProbMetric: 2.3529

Epoch 398: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3529 - val_MinusLogProbMetric: 2.3529 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 399/1000
2023-09-11 17:01:57.951 
Epoch 399/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 399: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 400/1000
2023-09-11 17:02:09.533 
Epoch 400/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3516, val_MinusLogProbMetric: 2.3516

Epoch 400: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3516 - val_MinusLogProbMetric: 2.3516 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 401/1000
2023-09-11 17:02:21.438 
Epoch 401/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3530, val_MinusLogProbMetric: 2.3530

Epoch 401: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3530 - val_MinusLogProbMetric: 2.3530 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 402/1000
2023-09-11 17:02:33.180 
Epoch 402/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3501, val_MinusLogProbMetric: 2.3501

Epoch 402: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3501 - val_MinusLogProbMetric: 2.3501 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 403/1000
2023-09-11 17:02:44.937 
Epoch 403/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 403: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 404/1000
2023-09-11 17:02:56.583 
Epoch 404/1000 
	 loss: 2.3601, MinusLogProbMetric: 2.3601, val_loss: 2.3508, val_MinusLogProbMetric: 2.3508

Epoch 404: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3601 - MinusLogProbMetric: 2.3601 - val_loss: 2.3508 - val_MinusLogProbMetric: 2.3508 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 405/1000
2023-09-11 17:03:08.274 
Epoch 405/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3517, val_MinusLogProbMetric: 2.3517

Epoch 405: val_loss did not improve from 2.34879
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3517 - val_MinusLogProbMetric: 2.3517 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 406/1000
2023-09-11 17:03:19.956 
Epoch 406/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 406: val_loss improved from 2.34879 to 2.34852, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 407/1000
2023-09-11 17:03:31.852 
Epoch 407/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3652, val_MinusLogProbMetric: 2.3652

Epoch 407: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3652 - val_MinusLogProbMetric: 2.3652 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 408/1000
2023-09-11 17:03:43.554 
Epoch 408/1000 
	 loss: 2.3597, MinusLogProbMetric: 2.3597, val_loss: 2.3519, val_MinusLogProbMetric: 2.3519

Epoch 408: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3597 - MinusLogProbMetric: 2.3597 - val_loss: 2.3519 - val_MinusLogProbMetric: 2.3519 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 409/1000
2023-09-11 17:03:55.288 
Epoch 409/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3513, val_MinusLogProbMetric: 2.3513

Epoch 409: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3513 - val_MinusLogProbMetric: 2.3513 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 410/1000
2023-09-11 17:04:07.033 
Epoch 410/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3535, val_MinusLogProbMetric: 2.3535

Epoch 410: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3535 - val_MinusLogProbMetric: 2.3535 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 411/1000
2023-09-11 17:04:18.758 
Epoch 411/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3537, val_MinusLogProbMetric: 2.3537

Epoch 411: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3537 - val_MinusLogProbMetric: 2.3537 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 412/1000
2023-09-11 17:04:30.455 
Epoch 412/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3512, val_MinusLogProbMetric: 2.3512

Epoch 412: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3512 - val_MinusLogProbMetric: 2.3512 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 413/1000
2023-09-11 17:04:42.380 
Epoch 413/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3515, val_MinusLogProbMetric: 2.3515

Epoch 413: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3515 - val_MinusLogProbMetric: 2.3515 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 414/1000
2023-09-11 17:04:54.149 
Epoch 414/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3541, val_MinusLogProbMetric: 2.3541

Epoch 414: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3541 - val_MinusLogProbMetric: 2.3541 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 415/1000
2023-09-11 17:05:05.846 
Epoch 415/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3525, val_MinusLogProbMetric: 2.3525

Epoch 415: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3525 - val_MinusLogProbMetric: 2.3525 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 416/1000
2023-09-11 17:05:17.539 
Epoch 416/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 416: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 417/1000
2023-09-11 17:05:29.335 
Epoch 417/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3519, val_MinusLogProbMetric: 2.3519

Epoch 417: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3519 - val_MinusLogProbMetric: 2.3519 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-11 17:05:41.048 
Epoch 418/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3495, val_MinusLogProbMetric: 2.3495

Epoch 418: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3495 - val_MinusLogProbMetric: 2.3495 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 419/1000
2023-09-11 17:05:52.935 
Epoch 419/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3497, val_MinusLogProbMetric: 2.3497

Epoch 419: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3497 - val_MinusLogProbMetric: 2.3497 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 420/1000
2023-09-11 17:06:04.578 
Epoch 420/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3562, val_MinusLogProbMetric: 2.3562

Epoch 420: val_loss did not improve from 2.34852
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3562 - val_MinusLogProbMetric: 2.3562 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 421/1000
2023-09-11 17:06:16.266 
Epoch 421/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 421: val_loss improved from 2.34852 to 2.34813, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 422/1000
2023-09-11 17:06:28.013 
Epoch 422/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 422: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 423/1000
2023-09-11 17:06:39.685 
Epoch 423/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 423: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 424/1000
2023-09-11 17:06:51.356 
Epoch 424/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 424: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 425/1000
2023-09-11 17:07:03.035 
Epoch 425/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3526, val_MinusLogProbMetric: 2.3526

Epoch 425: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3526 - val_MinusLogProbMetric: 2.3526 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 426/1000
2023-09-11 17:07:14.833 
Epoch 426/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3509, val_MinusLogProbMetric: 2.3509

Epoch 426: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3509 - val_MinusLogProbMetric: 2.3509 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 427/1000
2023-09-11 17:07:26.609 
Epoch 427/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 427: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 428/1000
2023-09-11 17:07:38.281 
Epoch 428/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3482, val_MinusLogProbMetric: 2.3482

Epoch 428: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3482 - val_MinusLogProbMetric: 2.3482 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 429/1000
2023-09-11 17:07:49.880 
Epoch 429/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3503, val_MinusLogProbMetric: 2.3503

Epoch 429: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3503 - val_MinusLogProbMetric: 2.3503 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 430/1000
2023-09-11 17:08:01.692 
Epoch 430/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3533, val_MinusLogProbMetric: 2.3533

Epoch 430: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3533 - val_MinusLogProbMetric: 2.3533 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 431/1000
2023-09-11 17:08:13.321 
Epoch 431/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3523, val_MinusLogProbMetric: 2.3523

Epoch 431: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3523 - val_MinusLogProbMetric: 2.3523 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 432/1000
2023-09-11 17:08:25.032 
Epoch 432/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3503, val_MinusLogProbMetric: 2.3503

Epoch 432: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3503 - val_MinusLogProbMetric: 2.3503 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 433/1000
2023-09-11 17:08:36.625 
Epoch 433/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3508, val_MinusLogProbMetric: 2.3508

Epoch 433: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3508 - val_MinusLogProbMetric: 2.3508 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 434/1000
2023-09-11 17:08:48.255 
Epoch 434/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3520, val_MinusLogProbMetric: 2.3520

Epoch 434: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3520 - val_MinusLogProbMetric: 2.3520 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 435/1000
2023-09-11 17:08:59.839 
Epoch 435/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3540, val_MinusLogProbMetric: 2.3540

Epoch 435: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3540 - val_MinusLogProbMetric: 2.3540 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 436/1000
2023-09-11 17:09:11.536 
Epoch 436/1000 
	 loss: 2.3608, MinusLogProbMetric: 2.3608, val_loss: 2.3529, val_MinusLogProbMetric: 2.3529

Epoch 436: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3608 - MinusLogProbMetric: 2.3608 - val_loss: 2.3529 - val_MinusLogProbMetric: 2.3529 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 437/1000
2023-09-11 17:09:23.191 
Epoch 437/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 437: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 438/1000
2023-09-11 17:09:34.940 
Epoch 438/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 438: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 439/1000
2023-09-11 17:09:46.621 
Epoch 439/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3516, val_MinusLogProbMetric: 2.3516

Epoch 439: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3516 - val_MinusLogProbMetric: 2.3516 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-11 17:09:58.354 
Epoch 440/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3523, val_MinusLogProbMetric: 2.3523

Epoch 440: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3523 - val_MinusLogProbMetric: 2.3523 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 441/1000
2023-09-11 17:10:10.183 
Epoch 441/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3504, val_MinusLogProbMetric: 2.3504

Epoch 441: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3504 - val_MinusLogProbMetric: 2.3504 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 442/1000
2023-09-11 17:10:21.871 
Epoch 442/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3496, val_MinusLogProbMetric: 2.3496

Epoch 442: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3496 - val_MinusLogProbMetric: 2.3496 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 443/1000
2023-09-11 17:10:33.590 
Epoch 443/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3501, val_MinusLogProbMetric: 2.3501

Epoch 443: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3501 - val_MinusLogProbMetric: 2.3501 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 444/1000
2023-09-11 17:10:45.385 
Epoch 444/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 444: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 445/1000
2023-09-11 17:10:57.087 
Epoch 445/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 445: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 446/1000
2023-09-11 17:11:08.817 
Epoch 446/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 446: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 447/1000
2023-09-11 17:11:20.509 
Epoch 447/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3508, val_MinusLogProbMetric: 2.3508

Epoch 447: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3508 - val_MinusLogProbMetric: 2.3508 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 448/1000
2023-09-11 17:11:32.300 
Epoch 448/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3540, val_MinusLogProbMetric: 2.3540

Epoch 448: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3540 - val_MinusLogProbMetric: 2.3540 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 449/1000
2023-09-11 17:11:44.189 
Epoch 449/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3505, val_MinusLogProbMetric: 2.3505

Epoch 449: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3505 - val_MinusLogProbMetric: 2.3505 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 450/1000
2023-09-11 17:11:55.912 
Epoch 450/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 450: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 451/1000
2023-09-11 17:12:07.681 
Epoch 451/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3486, val_MinusLogProbMetric: 2.3486

Epoch 451: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3486 - val_MinusLogProbMetric: 2.3486 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 452/1000
2023-09-11 17:12:19.493 
Epoch 452/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3516, val_MinusLogProbMetric: 2.3516

Epoch 452: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3516 - val_MinusLogProbMetric: 2.3516 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 453/1000
2023-09-11 17:12:31.207 
Epoch 453/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3536, val_MinusLogProbMetric: 2.3536

Epoch 453: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3536 - val_MinusLogProbMetric: 2.3536 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 454/1000
2023-09-11 17:12:43.012 
Epoch 454/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 454: val_loss did not improve from 2.34813
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 455/1000
2023-09-11 17:12:54.773 
Epoch 455/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 455: val_loss improved from 2.34813 to 2.34796, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 456/1000
2023-09-11 17:13:06.773 
Epoch 456/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3518, val_MinusLogProbMetric: 2.3518

Epoch 456: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3518 - val_MinusLogProbMetric: 2.3518 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 457/1000
2023-09-11 17:13:18.505 
Epoch 457/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 457: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 458/1000
2023-09-11 17:13:30.260 
Epoch 458/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3514, val_MinusLogProbMetric: 2.3514

Epoch 458: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3514 - val_MinusLogProbMetric: 2.3514 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 459/1000
2023-09-11 17:13:42.024 
Epoch 459/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 459: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 460/1000
2023-09-11 17:13:53.813 
Epoch 460/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 460: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 461/1000
2023-09-11 17:14:05.515 
Epoch 461/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3519, val_MinusLogProbMetric: 2.3519

Epoch 461: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3519 - val_MinusLogProbMetric: 2.3519 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 462/1000
2023-09-11 17:14:17.420 
Epoch 462/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 462: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 463/1000
2023-09-11 17:14:29.269 
Epoch 463/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 463: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 464/1000
2023-09-11 17:14:41.048 
Epoch 464/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3533, val_MinusLogProbMetric: 2.3533

Epoch 464: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3533 - val_MinusLogProbMetric: 2.3533 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 465/1000
2023-09-11 17:14:52.653 
Epoch 465/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3500, val_MinusLogProbMetric: 2.3500

Epoch 465: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3500 - val_MinusLogProbMetric: 2.3500 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 466/1000
2023-09-11 17:15:04.299 
Epoch 466/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3515, val_MinusLogProbMetric: 2.3515

Epoch 466: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3515 - val_MinusLogProbMetric: 2.3515 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 467/1000
2023-09-11 17:15:16.116 
Epoch 467/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3516, val_MinusLogProbMetric: 2.3516

Epoch 467: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3516 - val_MinusLogProbMetric: 2.3516 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 468/1000
2023-09-11 17:15:27.686 
Epoch 468/1000 
	 loss: 2.3584, MinusLogProbMetric: 2.3584, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 468: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3584 - MinusLogProbMetric: 2.3584 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 469/1000
2023-09-11 17:15:37.196 
Epoch 469/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 469: val_loss did not improve from 2.34796
196/196 - 10s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 2.5000e-04 - 10s/epoch - 48ms/step
Epoch 470/1000
2023-09-11 17:15:47.339 
Epoch 470/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3537, val_MinusLogProbMetric: 2.3537

Epoch 470: val_loss did not improve from 2.34796
196/196 - 10s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3537 - val_MinusLogProbMetric: 2.3537 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 471/1000
2023-09-11 17:15:57.558 
Epoch 471/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3500, val_MinusLogProbMetric: 2.3500

Epoch 471: val_loss did not improve from 2.34796
196/196 - 10s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3500 - val_MinusLogProbMetric: 2.3500 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 472/1000
2023-09-11 17:16:09.003 
Epoch 472/1000 
	 loss: 2.3584, MinusLogProbMetric: 2.3584, val_loss: 2.3516, val_MinusLogProbMetric: 2.3516

Epoch 472: val_loss did not improve from 2.34796
196/196 - 11s - loss: 2.3584 - MinusLogProbMetric: 2.3584 - val_loss: 2.3516 - val_MinusLogProbMetric: 2.3516 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 473/1000
2023-09-11 17:16:20.611 
Epoch 473/1000 
	 loss: 2.3588, MinusLogProbMetric: 2.3588, val_loss: 2.3490, val_MinusLogProbMetric: 2.3490

Epoch 473: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3588 - MinusLogProbMetric: 2.3588 - val_loss: 2.3490 - val_MinusLogProbMetric: 2.3490 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 474/1000
2023-09-11 17:16:32.402 
Epoch 474/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3508, val_MinusLogProbMetric: 2.3508

Epoch 474: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3508 - val_MinusLogProbMetric: 2.3508 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 475/1000
2023-09-11 17:16:44.052 
Epoch 475/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3490, val_MinusLogProbMetric: 2.3490

Epoch 475: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3490 - val_MinusLogProbMetric: 2.3490 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 476/1000
2023-09-11 17:16:55.733 
Epoch 476/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3503, val_MinusLogProbMetric: 2.3503

Epoch 476: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3503 - val_MinusLogProbMetric: 2.3503 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 477/1000
2023-09-11 17:17:07.435 
Epoch 477/1000 
	 loss: 2.3584, MinusLogProbMetric: 2.3584, val_loss: 2.3509, val_MinusLogProbMetric: 2.3509

Epoch 477: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3584 - MinusLogProbMetric: 2.3584 - val_loss: 2.3509 - val_MinusLogProbMetric: 2.3509 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 478/1000
2023-09-11 17:17:19.187 
Epoch 478/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 478: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 479/1000
2023-09-11 17:17:30.934 
Epoch 479/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3493, val_MinusLogProbMetric: 2.3493

Epoch 479: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3493 - val_MinusLogProbMetric: 2.3493 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 480/1000
2023-09-11 17:17:42.605 
Epoch 480/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 480: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 481/1000
2023-09-11 17:17:54.152 
Epoch 481/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3505, val_MinusLogProbMetric: 2.3505

Epoch 481: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3505 - val_MinusLogProbMetric: 2.3505 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 482/1000
2023-09-11 17:18:05.613 
Epoch 482/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3493, val_MinusLogProbMetric: 2.3493

Epoch 482: val_loss did not improve from 2.34796
196/196 - 11s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3493 - val_MinusLogProbMetric: 2.3493 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 483/1000
2023-09-11 17:18:17.142 
Epoch 483/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3513, val_MinusLogProbMetric: 2.3513

Epoch 483: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3513 - val_MinusLogProbMetric: 2.3513 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 484/1000
2023-09-11 17:18:28.852 
Epoch 484/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3531, val_MinusLogProbMetric: 2.3531

Epoch 484: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3531 - val_MinusLogProbMetric: 2.3531 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 485/1000
2023-09-11 17:18:40.427 
Epoch 485/1000 
	 loss: 2.3582, MinusLogProbMetric: 2.3582, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 485: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3582 - MinusLogProbMetric: 2.3582 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 486/1000
2023-09-11 17:18:52.085 
Epoch 486/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 486: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 487/1000
2023-09-11 17:19:03.675 
Epoch 487/1000 
	 loss: 2.3582, MinusLogProbMetric: 2.3582, val_loss: 2.3526, val_MinusLogProbMetric: 2.3526

Epoch 487: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3582 - MinusLogProbMetric: 2.3582 - val_loss: 2.3526 - val_MinusLogProbMetric: 2.3526 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 488/1000
2023-09-11 17:19:15.326 
Epoch 488/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3497, val_MinusLogProbMetric: 2.3497

Epoch 488: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3497 - val_MinusLogProbMetric: 2.3497 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 489/1000
2023-09-11 17:19:27.028 
Epoch 489/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.3503, val_MinusLogProbMetric: 2.3503

Epoch 489: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.3503 - val_MinusLogProbMetric: 2.3503 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 490/1000
2023-09-11 17:19:38.671 
Epoch 490/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 490: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 491/1000
2023-09-11 17:19:50.186 
Epoch 491/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 491: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 492/1000
2023-09-11 17:20:01.844 
Epoch 492/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.3499, val_MinusLogProbMetric: 2.3499

Epoch 492: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.3499 - val_MinusLogProbMetric: 2.3499 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 493/1000
2023-09-11 17:20:13.456 
Epoch 493/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3516, val_MinusLogProbMetric: 2.3516

Epoch 493: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3516 - val_MinusLogProbMetric: 2.3516 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 494/1000
2023-09-11 17:20:25.100 
Epoch 494/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3549, val_MinusLogProbMetric: 2.3549

Epoch 494: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3549 - val_MinusLogProbMetric: 2.3549 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 495/1000
2023-09-11 17:20:36.892 
Epoch 495/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 495: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 496/1000
2023-09-11 17:20:48.450 
Epoch 496/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3505, val_MinusLogProbMetric: 2.3505

Epoch 496: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3505 - val_MinusLogProbMetric: 2.3505 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 497/1000
2023-09-11 17:21:00.174 
Epoch 497/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3518, val_MinusLogProbMetric: 2.3518

Epoch 497: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3518 - val_MinusLogProbMetric: 2.3518 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 498/1000
2023-09-11 17:21:11.832 
Epoch 498/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3525, val_MinusLogProbMetric: 2.3525

Epoch 498: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3525 - val_MinusLogProbMetric: 2.3525 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 499/1000
2023-09-11 17:21:23.455 
Epoch 499/1000 
	 loss: 2.3581, MinusLogProbMetric: 2.3581, val_loss: 2.3516, val_MinusLogProbMetric: 2.3516

Epoch 499: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3581 - MinusLogProbMetric: 2.3581 - val_loss: 2.3516 - val_MinusLogProbMetric: 2.3516 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 500/1000
2023-09-11 17:21:35.168 
Epoch 500/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3495, val_MinusLogProbMetric: 2.3495

Epoch 500: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3495 - val_MinusLogProbMetric: 2.3495 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 501/1000
2023-09-11 17:21:46.734 
Epoch 501/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 501: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 502/1000
2023-09-11 17:21:58.280 
Epoch 502/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 502: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 503/1000
2023-09-11 17:22:09.799 
Epoch 503/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 503: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 504/1000
2023-09-11 17:22:21.403 
Epoch 504/1000 
	 loss: 2.3584, MinusLogProbMetric: 2.3584, val_loss: 2.3530, val_MinusLogProbMetric: 2.3530

Epoch 504: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3584 - MinusLogProbMetric: 2.3584 - val_loss: 2.3530 - val_MinusLogProbMetric: 2.3530 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 505/1000
2023-09-11 17:22:33.185 
Epoch 505/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3502, val_MinusLogProbMetric: 2.3502

Epoch 505: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3502 - val_MinusLogProbMetric: 2.3502 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 506/1000
2023-09-11 17:22:44.940 
Epoch 506/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3496, val_MinusLogProbMetric: 2.3496

Epoch 506: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3496 - val_MinusLogProbMetric: 2.3496 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 507/1000
2023-09-11 17:22:56.602 
Epoch 507/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 507: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 508/1000
2023-09-11 17:23:08.298 
Epoch 508/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3486, val_MinusLogProbMetric: 2.3486

Epoch 508: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3486 - val_MinusLogProbMetric: 2.3486 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 509/1000
2023-09-11 17:23:19.922 
Epoch 509/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3495, val_MinusLogProbMetric: 2.3495

Epoch 509: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3495 - val_MinusLogProbMetric: 2.3495 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 510/1000
2023-09-11 17:23:31.538 
Epoch 510/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3482, val_MinusLogProbMetric: 2.3482

Epoch 510: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3482 - val_MinusLogProbMetric: 2.3482 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 511/1000
2023-09-11 17:23:43.242 
Epoch 511/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 511: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 512/1000
2023-09-11 17:23:54.903 
Epoch 512/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 512: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 513/1000
2023-09-11 17:24:06.566 
Epoch 513/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3508, val_MinusLogProbMetric: 2.3508

Epoch 513: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3508 - val_MinusLogProbMetric: 2.3508 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 514/1000
2023-09-11 17:24:18.359 
Epoch 514/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3507, val_MinusLogProbMetric: 2.3507

Epoch 514: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3507 - val_MinusLogProbMetric: 2.3507 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 515/1000
2023-09-11 17:24:30.054 
Epoch 515/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 515: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 516/1000
2023-09-11 17:24:41.612 
Epoch 516/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 516: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 517/1000
2023-09-11 17:24:53.213 
Epoch 517/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 517: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 518/1000
2023-09-11 17:25:04.835 
Epoch 518/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3482, val_MinusLogProbMetric: 2.3482

Epoch 518: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3482 - val_MinusLogProbMetric: 2.3482 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 519/1000
2023-09-11 17:25:16.430 
Epoch 519/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 519: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 520/1000
2023-09-11 17:25:28.214 
Epoch 520/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 520: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 521/1000
2023-09-11 17:25:39.934 
Epoch 521/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3486, val_MinusLogProbMetric: 2.3486

Epoch 521: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3486 - val_MinusLogProbMetric: 2.3486 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 522/1000
2023-09-11 17:25:51.582 
Epoch 522/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 522: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 523/1000
2023-09-11 17:26:03.247 
Epoch 523/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3488, val_MinusLogProbMetric: 2.3488

Epoch 523: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3488 - val_MinusLogProbMetric: 2.3488 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 524/1000
2023-09-11 17:26:14.835 
Epoch 524/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3515, val_MinusLogProbMetric: 2.3515

Epoch 524: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3515 - val_MinusLogProbMetric: 2.3515 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 525/1000
2023-09-11 17:26:26.532 
Epoch 525/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 525: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 526/1000
2023-09-11 17:26:38.118 
Epoch 526/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3486, val_MinusLogProbMetric: 2.3486

Epoch 526: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3486 - val_MinusLogProbMetric: 2.3486 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 527/1000
2023-09-11 17:26:49.718 
Epoch 527/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3506, val_MinusLogProbMetric: 2.3506

Epoch 527: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3506 - val_MinusLogProbMetric: 2.3506 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 528/1000
2023-09-11 17:27:01.331 
Epoch 528/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 528: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 529/1000
2023-09-11 17:27:13.002 
Epoch 529/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 529: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 530/1000
2023-09-11 17:27:24.673 
Epoch 530/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3499, val_MinusLogProbMetric: 2.3499

Epoch 530: val_loss did not improve from 2.34796
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3499 - val_MinusLogProbMetric: 2.3499 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 531/1000
2023-09-11 17:27:36.377 
Epoch 531/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3474, val_MinusLogProbMetric: 2.3474

Epoch 531: val_loss improved from 2.34796 to 2.34745, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3474 - val_MinusLogProbMetric: 2.3474 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 532/1000
2023-09-11 17:27:48.030 
Epoch 532/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 532: val_loss did not improve from 2.34745
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 533/1000
2023-09-11 17:27:59.516 
Epoch 533/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3490, val_MinusLogProbMetric: 2.3490

Epoch 533: val_loss did not improve from 2.34745
196/196 - 11s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3490 - val_MinusLogProbMetric: 2.3490 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 534/1000
2023-09-11 17:28:11.210 
Epoch 534/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3490, val_MinusLogProbMetric: 2.3490

Epoch 534: val_loss did not improve from 2.34745
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3490 - val_MinusLogProbMetric: 2.3490 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 535/1000
2023-09-11 17:28:22.971 
Epoch 535/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 535: val_loss did not improve from 2.34745
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 536/1000
2023-09-11 17:28:34.722 
Epoch 536/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 536: val_loss did not improve from 2.34745
196/196 - 12s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 537/1000
2023-09-11 17:28:46.480 
Epoch 537/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3496, val_MinusLogProbMetric: 2.3496

Epoch 537: val_loss did not improve from 2.34745
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3496 - val_MinusLogProbMetric: 2.3496 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 538/1000
2023-09-11 17:28:58.134 
Epoch 538/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3495, val_MinusLogProbMetric: 2.3495

Epoch 538: val_loss did not improve from 2.34745
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3495 - val_MinusLogProbMetric: 2.3495 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 539/1000
2023-09-11 17:29:09.800 
Epoch 539/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 539: val_loss did not improve from 2.34745
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 540/1000
2023-09-11 17:29:21.541 
Epoch 540/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3473, val_MinusLogProbMetric: 2.3473

Epoch 540: val_loss improved from 2.34745 to 2.34726, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_5/weights/best_weights.h5
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3473 - val_MinusLogProbMetric: 2.3473 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 541/1000
2023-09-11 17:29:33.299 
Epoch 541/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 541: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 542/1000
2023-09-11 17:29:44.990 
Epoch 542/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3507, val_MinusLogProbMetric: 2.3507

Epoch 542: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3507 - val_MinusLogProbMetric: 2.3507 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 543/1000
2023-09-11 17:29:56.636 
Epoch 543/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3490, val_MinusLogProbMetric: 2.3490

Epoch 543: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3490 - val_MinusLogProbMetric: 2.3490 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 544/1000
2023-09-11 17:30:08.144 
Epoch 544/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 544: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 545/1000
2023-09-11 17:30:19.727 
Epoch 545/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 545: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 546/1000
2023-09-11 17:30:30.926 
Epoch 546/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 546: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 547/1000
2023-09-11 17:30:42.210 
Epoch 547/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3483, val_MinusLogProbMetric: 2.3483

Epoch 547: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3483 - val_MinusLogProbMetric: 2.3483 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 548/1000
2023-09-11 17:30:52.778 
Epoch 548/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 548: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 549/1000
2023-09-11 17:31:04.513 
Epoch 549/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 549: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 550/1000
2023-09-11 17:31:16.263 
Epoch 550/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3506, val_MinusLogProbMetric: 2.3506

Epoch 550: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3506 - val_MinusLogProbMetric: 2.3506 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 551/1000
2023-09-11 17:31:27.952 
Epoch 551/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 551: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 552/1000
2023-09-11 17:31:39.662 
Epoch 552/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 552: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 553/1000
2023-09-11 17:31:51.344 
Epoch 553/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3496, val_MinusLogProbMetric: 2.3496

Epoch 553: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3496 - val_MinusLogProbMetric: 2.3496 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 554/1000
2023-09-11 17:32:02.938 
Epoch 554/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 554: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 555/1000
2023-09-11 17:32:14.581 
Epoch 555/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 555: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 556/1000
2023-09-11 17:32:26.094 
Epoch 556/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 556: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 557/1000
2023-09-11 17:32:37.736 
Epoch 557/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 557: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 558/1000
2023-09-11 17:32:49.390 
Epoch 558/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3486, val_MinusLogProbMetric: 2.3486

Epoch 558: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3486 - val_MinusLogProbMetric: 2.3486 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 559/1000
2023-09-11 17:33:01.077 
Epoch 559/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 559: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 560/1000
2023-09-11 17:33:12.604 
Epoch 560/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 560: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 561/1000
2023-09-11 17:33:24.232 
Epoch 561/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3502, val_MinusLogProbMetric: 2.3502

Epoch 561: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3502 - val_MinusLogProbMetric: 2.3502 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 562/1000
2023-09-11 17:33:35.839 
Epoch 562/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3497, val_MinusLogProbMetric: 2.3497

Epoch 562: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3497 - val_MinusLogProbMetric: 2.3497 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 563/1000
2023-09-11 17:33:47.455 
Epoch 563/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3490, val_MinusLogProbMetric: 2.3490

Epoch 563: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3490 - val_MinusLogProbMetric: 2.3490 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 564/1000
2023-09-11 17:33:59.118 
Epoch 564/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 564: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 565/1000
2023-09-11 17:34:10.737 
Epoch 565/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 565: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 566/1000
2023-09-11 17:34:22.435 
Epoch 566/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3475, val_MinusLogProbMetric: 2.3475

Epoch 566: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3475 - val_MinusLogProbMetric: 2.3475 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 567/1000
2023-09-11 17:34:34.105 
Epoch 567/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 567: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 568/1000
2023-09-11 17:34:45.799 
Epoch 568/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3493, val_MinusLogProbMetric: 2.3493

Epoch 568: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3493 - val_MinusLogProbMetric: 2.3493 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 569/1000
2023-09-11 17:34:57.498 
Epoch 569/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3493, val_MinusLogProbMetric: 2.3493

Epoch 569: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3493 - val_MinusLogProbMetric: 2.3493 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 570/1000
2023-09-11 17:35:09.236 
Epoch 570/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 570: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 571/1000
2023-09-11 17:35:20.975 
Epoch 571/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3483, val_MinusLogProbMetric: 2.3483

Epoch 571: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3483 - val_MinusLogProbMetric: 2.3483 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 572/1000
2023-09-11 17:35:32.649 
Epoch 572/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3498, val_MinusLogProbMetric: 2.3498

Epoch 572: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3498 - val_MinusLogProbMetric: 2.3498 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 573/1000
2023-09-11 17:35:44.228 
Epoch 573/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 573: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 574/1000
2023-09-11 17:35:55.966 
Epoch 574/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 574: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 575/1000
2023-09-11 17:36:07.733 
Epoch 575/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 575: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 576/1000
2023-09-11 17:36:19.430 
Epoch 576/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3496, val_MinusLogProbMetric: 2.3496

Epoch 576: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3496 - val_MinusLogProbMetric: 2.3496 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 577/1000
2023-09-11 17:36:31.063 
Epoch 577/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 577: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 578/1000
2023-09-11 17:36:42.643 
Epoch 578/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3502, val_MinusLogProbMetric: 2.3502

Epoch 578: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3502 - val_MinusLogProbMetric: 2.3502 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 579/1000
2023-09-11 17:36:54.293 
Epoch 579/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 579: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 580/1000
2023-09-11 17:37:06.101 
Epoch 580/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3489, val_MinusLogProbMetric: 2.3489

Epoch 580: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3489 - val_MinusLogProbMetric: 2.3489 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 581/1000
2023-09-11 17:37:17.798 
Epoch 581/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3483, val_MinusLogProbMetric: 2.3483

Epoch 581: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3483 - val_MinusLogProbMetric: 2.3483 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 582/1000
2023-09-11 17:37:29.475 
Epoch 582/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3504, val_MinusLogProbMetric: 2.3504

Epoch 582: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3504 - val_MinusLogProbMetric: 2.3504 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 583/1000
2023-09-11 17:37:41.099 
Epoch 583/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 583: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 584/1000
2023-09-11 17:37:52.717 
Epoch 584/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3502, val_MinusLogProbMetric: 2.3502

Epoch 584: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3502 - val_MinusLogProbMetric: 2.3502 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 585/1000
2023-09-11 17:38:03.463 
Epoch 585/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 585: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 586/1000
2023-09-11 17:38:12.916 
Epoch 586/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3491, val_MinusLogProbMetric: 2.3491

Epoch 586: val_loss did not improve from 2.34726
196/196 - 9s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3491 - val_MinusLogProbMetric: 2.3491 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 587/1000
2023-09-11 17:38:22.992 
Epoch 587/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3504, val_MinusLogProbMetric: 2.3504

Epoch 587: val_loss did not improve from 2.34726
196/196 - 10s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3504 - val_MinusLogProbMetric: 2.3504 - lr: 1.2500e-04 - 10s/epoch - 51ms/step
Epoch 588/1000
2023-09-11 17:38:34.392 
Epoch 588/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 588: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 589/1000
2023-09-11 17:38:45.942 
Epoch 589/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3493, val_MinusLogProbMetric: 2.3493

Epoch 589: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3493 - val_MinusLogProbMetric: 2.3493 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 590/1000
2023-09-11 17:38:57.465 
Epoch 590/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3496, val_MinusLogProbMetric: 2.3496

Epoch 590: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3496 - val_MinusLogProbMetric: 2.3496 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 591/1000
2023-09-11 17:39:09.069 
Epoch 591/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 591: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 592/1000
2023-09-11 17:39:20.698 
Epoch 592/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 592: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 593/1000
2023-09-11 17:39:32.585 
Epoch 593/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 593: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 594/1000
2023-09-11 17:39:44.027 
Epoch 594/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 594: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 595/1000
2023-09-11 17:39:55.472 
Epoch 595/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 595: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 596/1000
2023-09-11 17:40:07.113 
Epoch 596/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 596: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 597/1000
2023-09-11 17:40:18.696 
Epoch 597/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3478, val_MinusLogProbMetric: 2.3478

Epoch 597: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3478 - val_MinusLogProbMetric: 2.3478 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 598/1000
2023-09-11 17:40:30.370 
Epoch 598/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3483, val_MinusLogProbMetric: 2.3483

Epoch 598: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3483 - val_MinusLogProbMetric: 2.3483 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 599/1000
2023-09-11 17:40:41.959 
Epoch 599/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3477, val_MinusLogProbMetric: 2.3477

Epoch 599: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3477 - val_MinusLogProbMetric: 2.3477 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 600/1000
2023-09-11 17:40:53.610 
Epoch 600/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3477, val_MinusLogProbMetric: 2.3477

Epoch 600: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3477 - val_MinusLogProbMetric: 2.3477 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 601/1000
2023-09-11 17:41:05.222 
Epoch 601/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3490, val_MinusLogProbMetric: 2.3490

Epoch 601: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3490 - val_MinusLogProbMetric: 2.3490 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 602/1000
2023-09-11 17:41:16.837 
Epoch 602/1000 
	 loss: 2.3553, MinusLogProbMetric: 2.3553, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 602: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3553 - MinusLogProbMetric: 2.3553 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 603/1000
2023-09-11 17:41:28.488 
Epoch 603/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3482, val_MinusLogProbMetric: 2.3482

Epoch 603: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3482 - val_MinusLogProbMetric: 2.3482 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 604/1000
2023-09-11 17:41:40.021 
Epoch 604/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3477, val_MinusLogProbMetric: 2.3477

Epoch 604: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3477 - val_MinusLogProbMetric: 2.3477 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 605/1000
2023-09-11 17:41:51.670 
Epoch 605/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3494, val_MinusLogProbMetric: 2.3494

Epoch 605: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3494 - val_MinusLogProbMetric: 2.3494 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 606/1000
2023-09-11 17:42:02.979 
Epoch 606/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 606: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 607/1000
2023-09-11 17:42:13.615 
Epoch 607/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 607: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 608/1000
2023-09-11 17:42:25.022 
Epoch 608/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3482, val_MinusLogProbMetric: 2.3482

Epoch 608: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3482 - val_MinusLogProbMetric: 2.3482 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 609/1000
2023-09-11 17:42:36.677 
Epoch 609/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 609: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 610/1000
2023-09-11 17:42:48.234 
Epoch 610/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 610: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 611/1000
2023-09-11 17:42:59.892 
Epoch 611/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 611: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 612/1000
2023-09-11 17:43:11.520 
Epoch 612/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3476, val_MinusLogProbMetric: 2.3476

Epoch 612: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3476 - val_MinusLogProbMetric: 2.3476 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 613/1000
2023-09-11 17:43:23.272 
Epoch 613/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 613: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 614/1000
2023-09-11 17:43:34.956 
Epoch 614/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3478, val_MinusLogProbMetric: 2.3478

Epoch 614: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3478 - val_MinusLogProbMetric: 2.3478 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 615/1000
2023-09-11 17:43:46.518 
Epoch 615/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3484, val_MinusLogProbMetric: 2.3484

Epoch 615: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3484 - val_MinusLogProbMetric: 2.3484 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 616/1000
2023-09-11 17:43:58.279 
Epoch 616/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 616: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 617/1000
2023-09-11 17:44:09.837 
Epoch 617/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 617: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 618/1000
2023-09-11 17:44:21.509 
Epoch 618/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3488, val_MinusLogProbMetric: 2.3488

Epoch 618: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3488 - val_MinusLogProbMetric: 2.3488 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 619/1000
2023-09-11 17:44:33.160 
Epoch 619/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3478, val_MinusLogProbMetric: 2.3478

Epoch 619: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3478 - val_MinusLogProbMetric: 2.3478 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 620/1000
2023-09-11 17:44:44.856 
Epoch 620/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.3477, val_MinusLogProbMetric: 2.3477

Epoch 620: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.3477 - val_MinusLogProbMetric: 2.3477 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 621/1000
2023-09-11 17:44:56.632 
Epoch 621/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 621: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 622/1000
2023-09-11 17:45:08.278 
Epoch 622/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 622: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 623/1000
2023-09-11 17:45:19.967 
Epoch 623/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 623: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 624/1000
2023-09-11 17:45:31.567 
Epoch 624/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3487, val_MinusLogProbMetric: 2.3487

Epoch 624: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3487 - val_MinusLogProbMetric: 2.3487 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 625/1000
2023-09-11 17:45:43.234 
Epoch 625/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 625: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 626/1000
2023-09-11 17:45:54.848 
Epoch 626/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3482, val_MinusLogProbMetric: 2.3482

Epoch 626: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3482 - val_MinusLogProbMetric: 2.3482 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 627/1000
2023-09-11 17:46:06.437 
Epoch 627/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3478, val_MinusLogProbMetric: 2.3478

Epoch 627: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3478 - val_MinusLogProbMetric: 2.3478 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 628/1000
2023-09-11 17:46:18.256 
Epoch 628/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3478, val_MinusLogProbMetric: 2.3478

Epoch 628: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3478 - val_MinusLogProbMetric: 2.3478 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 629/1000
2023-09-11 17:46:29.970 
Epoch 629/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.3486, val_MinusLogProbMetric: 2.3486

Epoch 629: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.3486 - val_MinusLogProbMetric: 2.3486 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 630/1000
2023-09-11 17:46:41.764 
Epoch 630/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 630: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 631/1000
2023-09-11 17:46:53.540 
Epoch 631/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3480, val_MinusLogProbMetric: 2.3480

Epoch 631: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3480 - val_MinusLogProbMetric: 2.3480 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 632/1000
2023-09-11 17:47:05.200 
Epoch 632/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 632: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 633/1000
2023-09-11 17:47:16.783 
Epoch 633/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3492, val_MinusLogProbMetric: 2.3492

Epoch 633: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3492 - val_MinusLogProbMetric: 2.3492 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 634/1000
2023-09-11 17:47:28.453 
Epoch 634/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3485, val_MinusLogProbMetric: 2.3485

Epoch 634: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3485 - val_MinusLogProbMetric: 2.3485 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 635/1000
2023-09-11 17:47:39.919 
Epoch 635/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3481, val_MinusLogProbMetric: 2.3481

Epoch 635: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3481 - val_MinusLogProbMetric: 2.3481 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 636/1000
2023-09-11 17:47:51.642 
Epoch 636/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3477, val_MinusLogProbMetric: 2.3477

Epoch 636: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3477 - val_MinusLogProbMetric: 2.3477 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 637/1000
2023-09-11 17:48:03.389 
Epoch 637/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3478, val_MinusLogProbMetric: 2.3478

Epoch 637: val_loss did not improve from 2.34726
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3478 - val_MinusLogProbMetric: 2.3478 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 638/1000
2023-09-11 17:48:13.838 
Epoch 638/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3477, val_MinusLogProbMetric: 2.3477

Epoch 638: val_loss did not improve from 2.34726
196/196 - 10s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3477 - val_MinusLogProbMetric: 2.3477 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 639/1000
2023-09-11 17:48:25.215 
Epoch 639/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3478, val_MinusLogProbMetric: 2.3478

Epoch 639: val_loss did not improve from 2.34726
196/196 - 11s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3478 - val_MinusLogProbMetric: 2.3478 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 640/1000
2023-09-11 17:48:35.703 
Epoch 640/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3479, val_MinusLogProbMetric: 2.3479

Epoch 640: val_loss did not improve from 2.34726
Restoring model weights from the end of the best epoch: 540.
196/196 - 11s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3479 - val_MinusLogProbMetric: 2.3479 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 640: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.515514625003561 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.947934441966936 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.3316453269217163 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.400494971079752 seconds.
Training succeeded with seed 187.
Model trained in 7504.14 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 19.59 s.
Plots done in 3.24 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 22.83 s.
===========
Run 5/360 done in 7528.37 s.
===========

Directory ../../results/MsplineN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

===========
Generating train data for run 16.
===========
Train data generated in 0.16 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_16/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_16/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.2674317, 7.169562 , 5.441325 , 9.025737 ],
       [6.3738327, 6.6283827, 6.0362544, 5.376315 ],
       [4.2321706, 5.9349465, 4.753843 , 8.277777 ],
       ...,
       [4.2180734, 6.29522  , 6.187969 , 8.81608  ],
       [9.854758 , 2.8779566, 7.568797 , 5.2761784],
       [9.91092  , 3.5335193, 7.469289 , 4.450787 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_16/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_16
self.data_kwargs: {'seed': 440}
self.x_data: [[ 4.239804   6.5859494  3.364883   9.648259 ]
 [ 4.2588253  7.156618   3.9784384 10.08472  ]
 [ 4.2247267  6.6256046  5.131947   9.639997 ]
 ...
 [ 4.222949   6.9587526  2.2993772  8.688217 ]
 [ 4.235814   6.1428423  4.314111   8.676208 ]
 [ 4.2248163  5.440098   4.228207   8.831769 ]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 4)]               0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  337688    
 yer)                                                            
                                                                 
=================================================================
Total params: 337,688
Trainable params: 337,688
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7fcd80db6b00>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc89004d9f0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc89004d9f0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc89004e2c0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc89004ef80>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc89004f4f0>, <keras.callbacks.ModelCheckpoint object at 0x7fc89004f5b0>, <keras.callbacks.EarlyStopping object at 0x7fc89004f820>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc89004f850>, <keras.callbacks.TerminateOnNaN object at 0x7fc89004f490>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.2674317, 7.169562 , 5.441325 , 9.025737 ],
       [6.3738327, 6.6283827, 6.0362544, 5.376315 ],
       [4.2321706, 5.9349465, 4.753843 , 8.277777 ],
       ...,
       [4.2180734, 6.29522  , 6.187969 , 8.81608  ],
       [9.854758 , 2.8779566, 7.568797 , 5.2761784],
       [9.91092  , 3.5335193, 7.469289 , 4.450787 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_16/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 16/360 with hyperparameters:
timestamp = 2023-09-11 17:48:59.809228
ndims = 4
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 337688
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.239804  6.5859494 3.364883  9.648259 ]
Epoch 1/1000
2023-09-11 17:49:29.731 
Epoch 1/1000 
	 loss: 6.5255, MinusLogProbMetric: 6.5255, val_loss: 3.3654, val_MinusLogProbMetric: 3.3654

Epoch 1: val_loss improved from inf to 3.36537, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 30s - loss: 6.5255 - MinusLogProbMetric: 6.5255 - val_loss: 3.3654 - val_MinusLogProbMetric: 3.3654 - lr: 0.0010 - 30s/epoch - 153ms/step
Epoch 2/1000
2023-09-11 17:49:41.667 
Epoch 2/1000 
	 loss: 3.2011, MinusLogProbMetric: 3.2011, val_loss: 3.0466, val_MinusLogProbMetric: 3.0466

Epoch 2: val_loss improved from 3.36537 to 3.04661, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 3.2011 - MinusLogProbMetric: 3.2011 - val_loss: 3.0466 - val_MinusLogProbMetric: 3.0466 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 3/1000
2023-09-11 17:49:53.552 
Epoch 3/1000 
	 loss: 2.7928, MinusLogProbMetric: 2.7928, val_loss: 2.7655, val_MinusLogProbMetric: 2.7655

Epoch 3: val_loss improved from 3.04661 to 2.76552, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.7928 - MinusLogProbMetric: 2.7928 - val_loss: 2.7655 - val_MinusLogProbMetric: 2.7655 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 4/1000
2023-09-11 17:50:05.421 
Epoch 4/1000 
	 loss: 2.6814, MinusLogProbMetric: 2.6814, val_loss: 2.6096, val_MinusLogProbMetric: 2.6096

Epoch 4: val_loss improved from 2.76552 to 2.60956, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.6814 - MinusLogProbMetric: 2.6814 - val_loss: 2.6096 - val_MinusLogProbMetric: 2.6096 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 5/1000
2023-09-11 17:50:17.428 
Epoch 5/1000 
	 loss: 2.6493, MinusLogProbMetric: 2.6493, val_loss: 2.6319, val_MinusLogProbMetric: 2.6319

Epoch 5: val_loss did not improve from 2.60956
196/196 - 12s - loss: 2.6493 - MinusLogProbMetric: 2.6493 - val_loss: 2.6319 - val_MinusLogProbMetric: 2.6319 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 6/1000
2023-09-11 17:50:29.396 
Epoch 6/1000 
	 loss: 2.6294, MinusLogProbMetric: 2.6294, val_loss: 2.7995, val_MinusLogProbMetric: 2.7995

Epoch 6: val_loss did not improve from 2.60956
196/196 - 12s - loss: 2.6294 - MinusLogProbMetric: 2.6294 - val_loss: 2.7995 - val_MinusLogProbMetric: 2.7995 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 7/1000
2023-09-11 17:50:41.197 
Epoch 7/1000 
	 loss: 2.6145, MinusLogProbMetric: 2.6145, val_loss: 2.5289, val_MinusLogProbMetric: 2.5289

Epoch 7: val_loss improved from 2.60956 to 2.52886, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.6145 - MinusLogProbMetric: 2.6145 - val_loss: 2.5289 - val_MinusLogProbMetric: 2.5289 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 8/1000
2023-09-11 17:50:53.090 
Epoch 8/1000 
	 loss: 2.5790, MinusLogProbMetric: 2.5790, val_loss: 2.5560, val_MinusLogProbMetric: 2.5560

Epoch 8: val_loss did not improve from 2.52886
196/196 - 12s - loss: 2.5790 - MinusLogProbMetric: 2.5790 - val_loss: 2.5560 - val_MinusLogProbMetric: 2.5560 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-11 17:51:04.823 
Epoch 9/1000 
	 loss: 2.5664, MinusLogProbMetric: 2.5664, val_loss: 2.4971, val_MinusLogProbMetric: 2.4971

Epoch 9: val_loss improved from 2.52886 to 2.49707, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.5664 - MinusLogProbMetric: 2.5664 - val_loss: 2.4971 - val_MinusLogProbMetric: 2.4971 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-11 17:51:16.690 
Epoch 10/1000 
	 loss: 2.5541, MinusLogProbMetric: 2.5541, val_loss: 2.5558, val_MinusLogProbMetric: 2.5558

Epoch 10: val_loss did not improve from 2.49707
196/196 - 12s - loss: 2.5541 - MinusLogProbMetric: 2.5541 - val_loss: 2.5558 - val_MinusLogProbMetric: 2.5558 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-11 17:51:28.498 
Epoch 11/1000 
	 loss: 2.5446, MinusLogProbMetric: 2.5446, val_loss: 2.6658, val_MinusLogProbMetric: 2.6658

Epoch 11: val_loss did not improve from 2.49707
196/196 - 12s - loss: 2.5446 - MinusLogProbMetric: 2.5446 - val_loss: 2.6658 - val_MinusLogProbMetric: 2.6658 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-11 17:51:40.192 
Epoch 12/1000 
	 loss: 2.5532, MinusLogProbMetric: 2.5532, val_loss: 2.4908, val_MinusLogProbMetric: 2.4908

Epoch 12: val_loss improved from 2.49707 to 2.49084, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.5532 - MinusLogProbMetric: 2.5532 - val_loss: 2.4908 - val_MinusLogProbMetric: 2.4908 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-11 17:51:52.084 
Epoch 13/1000 
	 loss: 2.5178, MinusLogProbMetric: 2.5178, val_loss: 2.5532, val_MinusLogProbMetric: 2.5532

Epoch 13: val_loss did not improve from 2.49084
196/196 - 12s - loss: 2.5178 - MinusLogProbMetric: 2.5178 - val_loss: 2.5532 - val_MinusLogProbMetric: 2.5532 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-11 17:52:03.894 
Epoch 14/1000 
	 loss: 2.5313, MinusLogProbMetric: 2.5313, val_loss: 2.6330, val_MinusLogProbMetric: 2.6330

Epoch 14: val_loss did not improve from 2.49084
196/196 - 12s - loss: 2.5313 - MinusLogProbMetric: 2.5313 - val_loss: 2.6330 - val_MinusLogProbMetric: 2.6330 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-11 17:52:15.742 
Epoch 15/1000 
	 loss: 2.5162, MinusLogProbMetric: 2.5162, val_loss: 2.4430, val_MinusLogProbMetric: 2.4430

Epoch 15: val_loss improved from 2.49084 to 2.44301, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.5162 - MinusLogProbMetric: 2.5162 - val_loss: 2.4430 - val_MinusLogProbMetric: 2.4430 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 16/1000
2023-09-11 17:52:27.497 
Epoch 16/1000 
	 loss: 2.5158, MinusLogProbMetric: 2.5158, val_loss: 2.5804, val_MinusLogProbMetric: 2.5804

Epoch 16: val_loss did not improve from 2.44301
196/196 - 12s - loss: 2.5158 - MinusLogProbMetric: 2.5158 - val_loss: 2.5804 - val_MinusLogProbMetric: 2.5804 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 17/1000
2023-09-11 17:52:39.292 
Epoch 17/1000 
	 loss: 2.4970, MinusLogProbMetric: 2.4970, val_loss: 2.5188, val_MinusLogProbMetric: 2.5188

Epoch 17: val_loss did not improve from 2.44301
196/196 - 12s - loss: 2.4970 - MinusLogProbMetric: 2.4970 - val_loss: 2.5188 - val_MinusLogProbMetric: 2.5188 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-11 17:52:50.984 
Epoch 18/1000 
	 loss: 2.4955, MinusLogProbMetric: 2.4955, val_loss: 2.5344, val_MinusLogProbMetric: 2.5344

Epoch 18: val_loss did not improve from 2.44301
196/196 - 12s - loss: 2.4955 - MinusLogProbMetric: 2.4955 - val_loss: 2.5344 - val_MinusLogProbMetric: 2.5344 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-11 17:53:02.749 
Epoch 19/1000 
	 loss: 2.4874, MinusLogProbMetric: 2.4874, val_loss: 2.4248, val_MinusLogProbMetric: 2.4248

Epoch 19: val_loss improved from 2.44301 to 2.42479, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4874 - MinusLogProbMetric: 2.4874 - val_loss: 2.4248 - val_MinusLogProbMetric: 2.4248 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 20/1000
2023-09-11 17:53:14.639 
Epoch 20/1000 
	 loss: 2.4682, MinusLogProbMetric: 2.4682, val_loss: 2.4671, val_MinusLogProbMetric: 2.4671

Epoch 20: val_loss did not improve from 2.42479
196/196 - 12s - loss: 2.4682 - MinusLogProbMetric: 2.4682 - val_loss: 2.4671 - val_MinusLogProbMetric: 2.4671 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 21/1000
2023-09-11 17:53:26.301 
Epoch 21/1000 
	 loss: 2.4694, MinusLogProbMetric: 2.4694, val_loss: 2.4227, val_MinusLogProbMetric: 2.4227

Epoch 21: val_loss improved from 2.42479 to 2.42269, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4694 - MinusLogProbMetric: 2.4694 - val_loss: 2.4227 - val_MinusLogProbMetric: 2.4227 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 22/1000
2023-09-11 17:53:38.234 
Epoch 22/1000 
	 loss: 2.4717, MinusLogProbMetric: 2.4717, val_loss: 2.4559, val_MinusLogProbMetric: 2.4559

Epoch 22: val_loss did not improve from 2.42269
196/196 - 12s - loss: 2.4717 - MinusLogProbMetric: 2.4717 - val_loss: 2.4559 - val_MinusLogProbMetric: 2.4559 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-11 17:53:50.050 
Epoch 23/1000 
	 loss: 2.4823, MinusLogProbMetric: 2.4823, val_loss: 2.4360, val_MinusLogProbMetric: 2.4360

Epoch 23: val_loss did not improve from 2.42269
196/196 - 12s - loss: 2.4823 - MinusLogProbMetric: 2.4823 - val_loss: 2.4360 - val_MinusLogProbMetric: 2.4360 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-11 17:54:01.890 
Epoch 24/1000 
	 loss: 2.4725, MinusLogProbMetric: 2.4725, val_loss: 2.4674, val_MinusLogProbMetric: 2.4674

Epoch 24: val_loss did not improve from 2.42269
196/196 - 12s - loss: 2.4725 - MinusLogProbMetric: 2.4725 - val_loss: 2.4674 - val_MinusLogProbMetric: 2.4674 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-11 17:54:13.623 
Epoch 25/1000 
	 loss: 2.4591, MinusLogProbMetric: 2.4591, val_loss: 2.4756, val_MinusLogProbMetric: 2.4756

Epoch 25: val_loss did not improve from 2.42269
196/196 - 12s - loss: 2.4591 - MinusLogProbMetric: 2.4591 - val_loss: 2.4756 - val_MinusLogProbMetric: 2.4756 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-11 17:54:25.380 
Epoch 26/1000 
	 loss: 2.4569, MinusLogProbMetric: 2.4569, val_loss: 2.5311, val_MinusLogProbMetric: 2.5311

Epoch 26: val_loss did not improve from 2.42269
196/196 - 12s - loss: 2.4569 - MinusLogProbMetric: 2.4569 - val_loss: 2.5311 - val_MinusLogProbMetric: 2.5311 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-11 17:54:37.148 
Epoch 27/1000 
	 loss: 2.4665, MinusLogProbMetric: 2.4665, val_loss: 2.5134, val_MinusLogProbMetric: 2.5134

Epoch 27: val_loss did not improve from 2.42269
196/196 - 12s - loss: 2.4665 - MinusLogProbMetric: 2.4665 - val_loss: 2.5134 - val_MinusLogProbMetric: 2.5134 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-11 17:54:48.775 
Epoch 28/1000 
	 loss: 2.4627, MinusLogProbMetric: 2.4627, val_loss: 2.4587, val_MinusLogProbMetric: 2.4587

Epoch 28: val_loss did not improve from 2.42269
196/196 - 12s - loss: 2.4627 - MinusLogProbMetric: 2.4627 - val_loss: 2.4587 - val_MinusLogProbMetric: 2.4587 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-11 17:55:00.573 
Epoch 29/1000 
	 loss: 2.4565, MinusLogProbMetric: 2.4565, val_loss: 2.4204, val_MinusLogProbMetric: 2.4204

Epoch 29: val_loss improved from 2.42269 to 2.42039, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4565 - MinusLogProbMetric: 2.4565 - val_loss: 2.4204 - val_MinusLogProbMetric: 2.4204 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 30/1000
2023-09-11 17:55:12.425 
Epoch 30/1000 
	 loss: 2.4437, MinusLogProbMetric: 2.4437, val_loss: 2.4385, val_MinusLogProbMetric: 2.4385

Epoch 30: val_loss did not improve from 2.42039
196/196 - 12s - loss: 2.4437 - MinusLogProbMetric: 2.4437 - val_loss: 2.4385 - val_MinusLogProbMetric: 2.4385 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-11 17:55:24.244 
Epoch 31/1000 
	 loss: 2.4483, MinusLogProbMetric: 2.4483, val_loss: 2.4276, val_MinusLogProbMetric: 2.4276

Epoch 31: val_loss did not improve from 2.42039
196/196 - 12s - loss: 2.4483 - MinusLogProbMetric: 2.4483 - val_loss: 2.4276 - val_MinusLogProbMetric: 2.4276 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-11 17:55:35.936 
Epoch 32/1000 
	 loss: 2.4391, MinusLogProbMetric: 2.4391, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 32: val_loss improved from 2.42039 to 2.40687, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4391 - MinusLogProbMetric: 2.4391 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-11 17:55:47.825 
Epoch 33/1000 
	 loss: 2.4440, MinusLogProbMetric: 2.4440, val_loss: 2.5157, val_MinusLogProbMetric: 2.5157

Epoch 33: val_loss did not improve from 2.40687
196/196 - 12s - loss: 2.4440 - MinusLogProbMetric: 2.4440 - val_loss: 2.5157 - val_MinusLogProbMetric: 2.5157 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-11 17:55:59.607 
Epoch 34/1000 
	 loss: 2.4334, MinusLogProbMetric: 2.4334, val_loss: 2.4941, val_MinusLogProbMetric: 2.4941

Epoch 34: val_loss did not improve from 2.40687
196/196 - 12s - loss: 2.4334 - MinusLogProbMetric: 2.4334 - val_loss: 2.4941 - val_MinusLogProbMetric: 2.4941 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-11 17:56:11.353 
Epoch 35/1000 
	 loss: 2.4523, MinusLogProbMetric: 2.4523, val_loss: 2.5552, val_MinusLogProbMetric: 2.5552

Epoch 35: val_loss did not improve from 2.40687
196/196 - 12s - loss: 2.4523 - MinusLogProbMetric: 2.4523 - val_loss: 2.5552 - val_MinusLogProbMetric: 2.5552 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-11 17:56:23.113 
Epoch 36/1000 
	 loss: 2.4444, MinusLogProbMetric: 2.4444, val_loss: 2.4597, val_MinusLogProbMetric: 2.4597

Epoch 36: val_loss did not improve from 2.40687
196/196 - 12s - loss: 2.4444 - MinusLogProbMetric: 2.4444 - val_loss: 2.4597 - val_MinusLogProbMetric: 2.4597 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-11 17:56:34.887 
Epoch 37/1000 
	 loss: 2.4323, MinusLogProbMetric: 2.4323, val_loss: 2.4060, val_MinusLogProbMetric: 2.4060

Epoch 37: val_loss improved from 2.40687 to 2.40597, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4323 - MinusLogProbMetric: 2.4323 - val_loss: 2.4060 - val_MinusLogProbMetric: 2.4060 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 38/1000
2023-09-11 17:56:46.636 
Epoch 38/1000 
	 loss: 2.4506, MinusLogProbMetric: 2.4506, val_loss: 2.4260, val_MinusLogProbMetric: 2.4260

Epoch 38: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4506 - MinusLogProbMetric: 2.4506 - val_loss: 2.4260 - val_MinusLogProbMetric: 2.4260 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 39/1000
2023-09-11 17:56:58.490 
Epoch 39/1000 
	 loss: 2.4324, MinusLogProbMetric: 2.4324, val_loss: 2.4511, val_MinusLogProbMetric: 2.4511

Epoch 39: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4324 - MinusLogProbMetric: 2.4324 - val_loss: 2.4511 - val_MinusLogProbMetric: 2.4511 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-11 17:57:10.257 
Epoch 40/1000 
	 loss: 2.4352, MinusLogProbMetric: 2.4352, val_loss: 2.4669, val_MinusLogProbMetric: 2.4669

Epoch 40: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4352 - MinusLogProbMetric: 2.4352 - val_loss: 2.4669 - val_MinusLogProbMetric: 2.4669 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-11 17:57:22.011 
Epoch 41/1000 
	 loss: 2.4298, MinusLogProbMetric: 2.4298, val_loss: 2.4587, val_MinusLogProbMetric: 2.4587

Epoch 41: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4298 - MinusLogProbMetric: 2.4298 - val_loss: 2.4587 - val_MinusLogProbMetric: 2.4587 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-11 17:57:33.763 
Epoch 42/1000 
	 loss: 2.4293, MinusLogProbMetric: 2.4293, val_loss: 2.4459, val_MinusLogProbMetric: 2.4459

Epoch 42: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4293 - MinusLogProbMetric: 2.4293 - val_loss: 2.4459 - val_MinusLogProbMetric: 2.4459 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-11 17:57:45.455 
Epoch 43/1000 
	 loss: 2.4339, MinusLogProbMetric: 2.4339, val_loss: 2.4082, val_MinusLogProbMetric: 2.4082

Epoch 43: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4339 - MinusLogProbMetric: 2.4339 - val_loss: 2.4082 - val_MinusLogProbMetric: 2.4082 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 44/1000
2023-09-11 17:57:57.258 
Epoch 44/1000 
	 loss: 2.4334, MinusLogProbMetric: 2.4334, val_loss: 2.4087, val_MinusLogProbMetric: 2.4087

Epoch 44: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4334 - MinusLogProbMetric: 2.4334 - val_loss: 2.4087 - val_MinusLogProbMetric: 2.4087 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-11 17:58:09.125 
Epoch 45/1000 
	 loss: 2.4285, MinusLogProbMetric: 2.4285, val_loss: 2.4207, val_MinusLogProbMetric: 2.4207

Epoch 45: val_loss did not improve from 2.40597
196/196 - 12s - loss: 2.4285 - MinusLogProbMetric: 2.4285 - val_loss: 2.4207 - val_MinusLogProbMetric: 2.4207 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 46/1000
2023-09-11 17:58:20.916 
Epoch 46/1000 
	 loss: 2.4276, MinusLogProbMetric: 2.4276, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 46: val_loss improved from 2.40597 to 2.39888, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4276 - MinusLogProbMetric: 2.4276 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 47/1000
2023-09-11 17:58:32.804 
Epoch 47/1000 
	 loss: 2.4253, MinusLogProbMetric: 2.4253, val_loss: 2.4657, val_MinusLogProbMetric: 2.4657

Epoch 47: val_loss did not improve from 2.39888
196/196 - 12s - loss: 2.4253 - MinusLogProbMetric: 2.4253 - val_loss: 2.4657 - val_MinusLogProbMetric: 2.4657 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-11 17:58:44.544 
Epoch 48/1000 
	 loss: 2.4195, MinusLogProbMetric: 2.4195, val_loss: 2.3873, val_MinusLogProbMetric: 2.3873

Epoch 48: val_loss improved from 2.39888 to 2.38731, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4195 - MinusLogProbMetric: 2.4195 - val_loss: 2.3873 - val_MinusLogProbMetric: 2.3873 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-11 17:58:56.353 
Epoch 49/1000 
	 loss: 2.4313, MinusLogProbMetric: 2.4313, val_loss: 2.4159, val_MinusLogProbMetric: 2.4159

Epoch 49: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4313 - MinusLogProbMetric: 2.4313 - val_loss: 2.4159 - val_MinusLogProbMetric: 2.4159 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-11 17:59:08.049 
Epoch 50/1000 
	 loss: 2.4240, MinusLogProbMetric: 2.4240, val_loss: 2.4063, val_MinusLogProbMetric: 2.4063

Epoch 50: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4240 - MinusLogProbMetric: 2.4240 - val_loss: 2.4063 - val_MinusLogProbMetric: 2.4063 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 51/1000
2023-09-11 17:59:19.985 
Epoch 51/1000 
	 loss: 2.4200, MinusLogProbMetric: 2.4200, val_loss: 2.3997, val_MinusLogProbMetric: 2.3997

Epoch 51: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4200 - MinusLogProbMetric: 2.4200 - val_loss: 2.3997 - val_MinusLogProbMetric: 2.3997 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 52/1000
2023-09-11 17:59:31.779 
Epoch 52/1000 
	 loss: 2.4218, MinusLogProbMetric: 2.4218, val_loss: 2.4000, val_MinusLogProbMetric: 2.4000

Epoch 52: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4218 - MinusLogProbMetric: 2.4218 - val_loss: 2.4000 - val_MinusLogProbMetric: 2.4000 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-11 17:59:43.502 
Epoch 53/1000 
	 loss: 2.4154, MinusLogProbMetric: 2.4154, val_loss: 2.4153, val_MinusLogProbMetric: 2.4153

Epoch 53: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4154 - MinusLogProbMetric: 2.4154 - val_loss: 2.4153 - val_MinusLogProbMetric: 2.4153 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-11 17:59:55.185 
Epoch 54/1000 
	 loss: 2.4220, MinusLogProbMetric: 2.4220, val_loss: 2.4206, val_MinusLogProbMetric: 2.4206

Epoch 54: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4220 - MinusLogProbMetric: 2.4220 - val_loss: 2.4206 - val_MinusLogProbMetric: 2.4206 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 55/1000
2023-09-11 18:00:06.900 
Epoch 55/1000 
	 loss: 2.4171, MinusLogProbMetric: 2.4171, val_loss: 2.3875, val_MinusLogProbMetric: 2.3875

Epoch 55: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4171 - MinusLogProbMetric: 2.4171 - val_loss: 2.3875 - val_MinusLogProbMetric: 2.3875 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-11 18:00:18.786 
Epoch 56/1000 
	 loss: 2.4186, MinusLogProbMetric: 2.4186, val_loss: 2.3967, val_MinusLogProbMetric: 2.3967

Epoch 56: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4186 - MinusLogProbMetric: 2.4186 - val_loss: 2.3967 - val_MinusLogProbMetric: 2.3967 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 57/1000
2023-09-11 18:00:30.485 
Epoch 57/1000 
	 loss: 2.4170, MinusLogProbMetric: 2.4170, val_loss: 2.4100, val_MinusLogProbMetric: 2.4100

Epoch 57: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4170 - MinusLogProbMetric: 2.4170 - val_loss: 2.4100 - val_MinusLogProbMetric: 2.4100 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-11 18:00:42.245 
Epoch 58/1000 
	 loss: 2.4145, MinusLogProbMetric: 2.4145, val_loss: 2.4105, val_MinusLogProbMetric: 2.4105

Epoch 58: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4145 - MinusLogProbMetric: 2.4145 - val_loss: 2.4105 - val_MinusLogProbMetric: 2.4105 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-11 18:00:53.843 
Epoch 59/1000 
	 loss: 2.4172, MinusLogProbMetric: 2.4172, val_loss: 2.4057, val_MinusLogProbMetric: 2.4057

Epoch 59: val_loss did not improve from 2.38731
196/196 - 12s - loss: 2.4172 - MinusLogProbMetric: 2.4172 - val_loss: 2.4057 - val_MinusLogProbMetric: 2.4057 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 60/1000
2023-09-11 18:01:05.724 
Epoch 60/1000 
	 loss: 2.4114, MinusLogProbMetric: 2.4114, val_loss: 2.3867, val_MinusLogProbMetric: 2.3867

Epoch 60: val_loss improved from 2.38731 to 2.38671, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4114 - MinusLogProbMetric: 2.4114 - val_loss: 2.3867 - val_MinusLogProbMetric: 2.3867 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 61/1000
2023-09-11 18:01:17.488 
Epoch 61/1000 
	 loss: 2.4215, MinusLogProbMetric: 2.4215, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 61: val_loss improved from 2.38671 to 2.38658, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4215 - MinusLogProbMetric: 2.4215 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-11 18:01:29.246 
Epoch 62/1000 
	 loss: 2.4118, MinusLogProbMetric: 2.4118, val_loss: 2.3850, val_MinusLogProbMetric: 2.3850

Epoch 62: val_loss improved from 2.38658 to 2.38501, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4118 - MinusLogProbMetric: 2.4118 - val_loss: 2.3850 - val_MinusLogProbMetric: 2.3850 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-11 18:01:41.013 
Epoch 63/1000 
	 loss: 2.4116, MinusLogProbMetric: 2.4116, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 63: val_loss did not improve from 2.38501
196/196 - 12s - loss: 2.4116 - MinusLogProbMetric: 2.4116 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 64/1000
2023-09-11 18:01:52.723 
Epoch 64/1000 
	 loss: 2.4174, MinusLogProbMetric: 2.4174, val_loss: 2.4083, val_MinusLogProbMetric: 2.4083

Epoch 64: val_loss did not improve from 2.38501
196/196 - 12s - loss: 2.4174 - MinusLogProbMetric: 2.4174 - val_loss: 2.4083 - val_MinusLogProbMetric: 2.4083 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-11 18:02:04.423 
Epoch 65/1000 
	 loss: 2.4142, MinusLogProbMetric: 2.4142, val_loss: 2.4453, val_MinusLogProbMetric: 2.4453

Epoch 65: val_loss did not improve from 2.38501
196/196 - 12s - loss: 2.4142 - MinusLogProbMetric: 2.4142 - val_loss: 2.4453 - val_MinusLogProbMetric: 2.4453 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-11 18:02:16.067 
Epoch 66/1000 
	 loss: 2.4112, MinusLogProbMetric: 2.4112, val_loss: 2.3854, val_MinusLogProbMetric: 2.3854

Epoch 66: val_loss did not improve from 2.38501
196/196 - 12s - loss: 2.4112 - MinusLogProbMetric: 2.4112 - val_loss: 2.3854 - val_MinusLogProbMetric: 2.3854 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-11 18:02:27.712 
Epoch 67/1000 
	 loss: 2.4091, MinusLogProbMetric: 2.4091, val_loss: 2.3846, val_MinusLogProbMetric: 2.3846

Epoch 67: val_loss improved from 2.38501 to 2.38465, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4091 - MinusLogProbMetric: 2.4091 - val_loss: 2.3846 - val_MinusLogProbMetric: 2.3846 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-11 18:02:39.595 
Epoch 68/1000 
	 loss: 2.4083, MinusLogProbMetric: 2.4083, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 68: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4083 - MinusLogProbMetric: 2.4083 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-11 18:02:51.413 
Epoch 69/1000 
	 loss: 2.4077, MinusLogProbMetric: 2.4077, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 69: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4077 - MinusLogProbMetric: 2.4077 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-11 18:03:03.208 
Epoch 70/1000 
	 loss: 2.4099, MinusLogProbMetric: 2.4099, val_loss: 2.3967, val_MinusLogProbMetric: 2.3967

Epoch 70: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4099 - MinusLogProbMetric: 2.4099 - val_loss: 2.3967 - val_MinusLogProbMetric: 2.3967 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-11 18:03:14.952 
Epoch 71/1000 
	 loss: 2.4135, MinusLogProbMetric: 2.4135, val_loss: 2.4009, val_MinusLogProbMetric: 2.4009

Epoch 71: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4135 - MinusLogProbMetric: 2.4135 - val_loss: 2.4009 - val_MinusLogProbMetric: 2.4009 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-11 18:03:26.684 
Epoch 72/1000 
	 loss: 2.4123, MinusLogProbMetric: 2.4123, val_loss: 2.4187, val_MinusLogProbMetric: 2.4187

Epoch 72: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4123 - MinusLogProbMetric: 2.4123 - val_loss: 2.4187 - val_MinusLogProbMetric: 2.4187 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-11 18:03:38.323 
Epoch 73/1000 
	 loss: 2.4102, MinusLogProbMetric: 2.4102, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 73: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4102 - MinusLogProbMetric: 2.4102 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-11 18:03:50.036 
Epoch 74/1000 
	 loss: 2.4151, MinusLogProbMetric: 2.4151, val_loss: 2.4171, val_MinusLogProbMetric: 2.4171

Epoch 74: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4151 - MinusLogProbMetric: 2.4151 - val_loss: 2.4171 - val_MinusLogProbMetric: 2.4171 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-11 18:04:01.831 
Epoch 75/1000 
	 loss: 2.4082, MinusLogProbMetric: 2.4082, val_loss: 2.4060, val_MinusLogProbMetric: 2.4060

Epoch 75: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4082 - MinusLogProbMetric: 2.4082 - val_loss: 2.4060 - val_MinusLogProbMetric: 2.4060 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-11 18:04:13.460 
Epoch 76/1000 
	 loss: 2.4092, MinusLogProbMetric: 2.4092, val_loss: 2.4020, val_MinusLogProbMetric: 2.4020

Epoch 76: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4092 - MinusLogProbMetric: 2.4092 - val_loss: 2.4020 - val_MinusLogProbMetric: 2.4020 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 77/1000
2023-09-11 18:04:25.193 
Epoch 77/1000 
	 loss: 2.4098, MinusLogProbMetric: 2.4098, val_loss: 2.3972, val_MinusLogProbMetric: 2.3972

Epoch 77: val_loss did not improve from 2.38465
196/196 - 12s - loss: 2.4098 - MinusLogProbMetric: 2.4098 - val_loss: 2.3972 - val_MinusLogProbMetric: 2.3972 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-11 18:04:36.881 
Epoch 78/1000 
	 loss: 2.4039, MinusLogProbMetric: 2.4039, val_loss: 2.3831, val_MinusLogProbMetric: 2.3831

Epoch 78: val_loss improved from 2.38465 to 2.38306, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4039 - MinusLogProbMetric: 2.4039 - val_loss: 2.3831 - val_MinusLogProbMetric: 2.3831 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-11 18:04:48.703 
Epoch 79/1000 
	 loss: 2.4085, MinusLogProbMetric: 2.4085, val_loss: 2.3947, val_MinusLogProbMetric: 2.3947

Epoch 79: val_loss did not improve from 2.38306
196/196 - 12s - loss: 2.4085 - MinusLogProbMetric: 2.4085 - val_loss: 2.3947 - val_MinusLogProbMetric: 2.3947 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-11 18:05:00.575 
Epoch 80/1000 
	 loss: 2.4070, MinusLogProbMetric: 2.4070, val_loss: 2.4554, val_MinusLogProbMetric: 2.4554

Epoch 80: val_loss did not improve from 2.38306
196/196 - 12s - loss: 2.4070 - MinusLogProbMetric: 2.4070 - val_loss: 2.4554 - val_MinusLogProbMetric: 2.4554 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 81/1000
2023-09-11 18:05:12.437 
Epoch 81/1000 
	 loss: 2.4088, MinusLogProbMetric: 2.4088, val_loss: 2.3775, val_MinusLogProbMetric: 2.3775

Epoch 81: val_loss improved from 2.38306 to 2.37750, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4088 - MinusLogProbMetric: 2.4088 - val_loss: 2.3775 - val_MinusLogProbMetric: 2.3775 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 82/1000
2023-09-11 18:05:24.382 
Epoch 82/1000 
	 loss: 2.4036, MinusLogProbMetric: 2.4036, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 82: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4036 - MinusLogProbMetric: 2.4036 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-11 18:05:36.178 
Epoch 83/1000 
	 loss: 2.4092, MinusLogProbMetric: 2.4092, val_loss: 2.3995, val_MinusLogProbMetric: 2.3995

Epoch 83: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4092 - MinusLogProbMetric: 2.4092 - val_loss: 2.3995 - val_MinusLogProbMetric: 2.3995 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 84/1000
2023-09-11 18:05:48.057 
Epoch 84/1000 
	 loss: 2.4066, MinusLogProbMetric: 2.4066, val_loss: 2.3801, val_MinusLogProbMetric: 2.3801

Epoch 84: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4066 - MinusLogProbMetric: 2.4066 - val_loss: 2.3801 - val_MinusLogProbMetric: 2.3801 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 85/1000
2023-09-11 18:05:59.802 
Epoch 85/1000 
	 loss: 2.4067, MinusLogProbMetric: 2.4067, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 85: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4067 - MinusLogProbMetric: 2.4067 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-11 18:06:11.431 
Epoch 86/1000 
	 loss: 2.4012, MinusLogProbMetric: 2.4012, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 86: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4012 - MinusLogProbMetric: 2.4012 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-11 18:06:23.321 
Epoch 87/1000 
	 loss: 2.4028, MinusLogProbMetric: 2.4028, val_loss: 2.3914, val_MinusLogProbMetric: 2.3914

Epoch 87: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4028 - MinusLogProbMetric: 2.4028 - val_loss: 2.3914 - val_MinusLogProbMetric: 2.3914 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 88/1000
2023-09-11 18:06:35.048 
Epoch 88/1000 
	 loss: 2.4029, MinusLogProbMetric: 2.4029, val_loss: 2.4182, val_MinusLogProbMetric: 2.4182

Epoch 88: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4029 - MinusLogProbMetric: 2.4029 - val_loss: 2.4182 - val_MinusLogProbMetric: 2.4182 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-11 18:06:46.734 
Epoch 89/1000 
	 loss: 2.4051, MinusLogProbMetric: 2.4051, val_loss: 2.3840, val_MinusLogProbMetric: 2.3840

Epoch 89: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4051 - MinusLogProbMetric: 2.4051 - val_loss: 2.3840 - val_MinusLogProbMetric: 2.3840 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-11 18:06:58.445 
Epoch 90/1000 
	 loss: 2.4031, MinusLogProbMetric: 2.4031, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 90: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4031 - MinusLogProbMetric: 2.4031 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-11 18:07:10.079 
Epoch 91/1000 
	 loss: 2.4048, MinusLogProbMetric: 2.4048, val_loss: 2.4134, val_MinusLogProbMetric: 2.4134

Epoch 91: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4048 - MinusLogProbMetric: 2.4048 - val_loss: 2.4134 - val_MinusLogProbMetric: 2.4134 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 92/1000
2023-09-11 18:07:21.813 
Epoch 92/1000 
	 loss: 2.4006, MinusLogProbMetric: 2.4006, val_loss: 2.4005, val_MinusLogProbMetric: 2.4005

Epoch 92: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4006 - MinusLogProbMetric: 2.4006 - val_loss: 2.4005 - val_MinusLogProbMetric: 2.4005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-11 18:07:33.594 
Epoch 93/1000 
	 loss: 2.4049, MinusLogProbMetric: 2.4049, val_loss: 2.4038, val_MinusLogProbMetric: 2.4038

Epoch 93: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4049 - MinusLogProbMetric: 2.4049 - val_loss: 2.4038 - val_MinusLogProbMetric: 2.4038 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-11 18:07:45.343 
Epoch 94/1000 
	 loss: 2.4043, MinusLogProbMetric: 2.4043, val_loss: 2.3925, val_MinusLogProbMetric: 2.3925

Epoch 94: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4043 - MinusLogProbMetric: 2.4043 - val_loss: 2.3925 - val_MinusLogProbMetric: 2.3925 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-11 18:07:57.103 
Epoch 95/1000 
	 loss: 2.4012, MinusLogProbMetric: 2.4012, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 95: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4012 - MinusLogProbMetric: 2.4012 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-11 18:08:08.911 
Epoch 96/1000 
	 loss: 2.4052, MinusLogProbMetric: 2.4052, val_loss: 2.4050, val_MinusLogProbMetric: 2.4050

Epoch 96: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.4052 - MinusLogProbMetric: 2.4052 - val_loss: 2.4050 - val_MinusLogProbMetric: 2.4050 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 97/1000
2023-09-11 18:08:20.705 
Epoch 97/1000 
	 loss: 2.3972, MinusLogProbMetric: 2.3972, val_loss: 2.3930, val_MinusLogProbMetric: 2.3930

Epoch 97: val_loss did not improve from 2.37750
196/196 - 12s - loss: 2.3972 - MinusLogProbMetric: 2.3972 - val_loss: 2.3930 - val_MinusLogProbMetric: 2.3930 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 98/1000
2023-09-11 18:08:32.551 
Epoch 98/1000 
	 loss: 2.4024, MinusLogProbMetric: 2.4024, val_loss: 2.3743, val_MinusLogProbMetric: 2.3743

Epoch 98: val_loss improved from 2.37750 to 2.37433, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.4024 - MinusLogProbMetric: 2.4024 - val_loss: 2.3743 - val_MinusLogProbMetric: 2.3743 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 99/1000
2023-09-11 18:08:44.486 
Epoch 99/1000 
	 loss: 2.3995, MinusLogProbMetric: 2.3995, val_loss: 2.3768, val_MinusLogProbMetric: 2.3768

Epoch 99: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.3995 - MinusLogProbMetric: 2.3995 - val_loss: 2.3768 - val_MinusLogProbMetric: 2.3768 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 100/1000
2023-09-11 18:08:56.236 
Epoch 100/1000 
	 loss: 2.4009, MinusLogProbMetric: 2.4009, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 100: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.4009 - MinusLogProbMetric: 2.4009 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-11 18:09:07.941 
Epoch 101/1000 
	 loss: 2.3994, MinusLogProbMetric: 2.3994, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 101: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.3994 - MinusLogProbMetric: 2.3994 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 102/1000
2023-09-11 18:09:19.756 
Epoch 102/1000 
	 loss: 2.3956, MinusLogProbMetric: 2.3956, val_loss: 2.3914, val_MinusLogProbMetric: 2.3914

Epoch 102: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.3956 - MinusLogProbMetric: 2.3956 - val_loss: 2.3914 - val_MinusLogProbMetric: 2.3914 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 103/1000
2023-09-11 18:09:31.506 
Epoch 103/1000 
	 loss: 2.3963, MinusLogProbMetric: 2.3963, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 103: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.3963 - MinusLogProbMetric: 2.3963 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-11 18:09:43.285 
Epoch 104/1000 
	 loss: 2.4013, MinusLogProbMetric: 2.4013, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 104: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.4013 - MinusLogProbMetric: 2.4013 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 105/1000
2023-09-11 18:09:55.041 
Epoch 105/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.3994, val_MinusLogProbMetric: 2.3994

Epoch 105: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.3994 - val_MinusLogProbMetric: 2.3994 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-11 18:10:06.740 
Epoch 106/1000 
	 loss: 2.3985, MinusLogProbMetric: 2.3985, val_loss: 2.4074, val_MinusLogProbMetric: 2.4074

Epoch 106: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.3985 - MinusLogProbMetric: 2.3985 - val_loss: 2.4074 - val_MinusLogProbMetric: 2.4074 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 107/1000
2023-09-11 18:10:18.497 
Epoch 107/1000 
	 loss: 2.3976, MinusLogProbMetric: 2.3976, val_loss: 2.3752, val_MinusLogProbMetric: 2.3752

Epoch 107: val_loss did not improve from 2.37433
196/196 - 12s - loss: 2.3976 - MinusLogProbMetric: 2.3976 - val_loss: 2.3752 - val_MinusLogProbMetric: 2.3752 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-11 18:10:30.206 
Epoch 108/1000 
	 loss: 2.3984, MinusLogProbMetric: 2.3984, val_loss: 2.3697, val_MinusLogProbMetric: 2.3697

Epoch 108: val_loss improved from 2.37433 to 2.36970, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.3984 - MinusLogProbMetric: 2.3984 - val_loss: 2.3697 - val_MinusLogProbMetric: 2.3697 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-11 18:10:42.028 
Epoch 109/1000 
	 loss: 2.3991, MinusLogProbMetric: 2.3991, val_loss: 2.4115, val_MinusLogProbMetric: 2.4115

Epoch 109: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3991 - MinusLogProbMetric: 2.3991 - val_loss: 2.4115 - val_MinusLogProbMetric: 2.4115 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 110/1000
2023-09-11 18:10:53.876 
Epoch 110/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.3769, val_MinusLogProbMetric: 2.3769

Epoch 110: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.3769 - val_MinusLogProbMetric: 2.3769 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 111/1000
2023-09-11 18:11:05.634 
Epoch 111/1000 
	 loss: 2.3981, MinusLogProbMetric: 2.3981, val_loss: 2.3768, val_MinusLogProbMetric: 2.3768

Epoch 111: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3981 - MinusLogProbMetric: 2.3981 - val_loss: 2.3768 - val_MinusLogProbMetric: 2.3768 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-11 18:11:17.372 
Epoch 112/1000 
	 loss: 2.3967, MinusLogProbMetric: 2.3967, val_loss: 2.3808, val_MinusLogProbMetric: 2.3808

Epoch 112: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3967 - MinusLogProbMetric: 2.3967 - val_loss: 2.3808 - val_MinusLogProbMetric: 2.3808 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 113/1000
2023-09-11 18:11:29.066 
Epoch 113/1000 
	 loss: 2.3973, MinusLogProbMetric: 2.3973, val_loss: 2.3806, val_MinusLogProbMetric: 2.3806

Epoch 113: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3973 - MinusLogProbMetric: 2.3973 - val_loss: 2.3806 - val_MinusLogProbMetric: 2.3806 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-11 18:11:40.727 
Epoch 114/1000 
	 loss: 2.3948, MinusLogProbMetric: 2.3948, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 114: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3948 - MinusLogProbMetric: 2.3948 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 115/1000
2023-09-11 18:11:52.481 
Epoch 115/1000 
	 loss: 2.3939, MinusLogProbMetric: 2.3939, val_loss: 2.4109, val_MinusLogProbMetric: 2.4109

Epoch 115: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3939 - MinusLogProbMetric: 2.3939 - val_loss: 2.4109 - val_MinusLogProbMetric: 2.4109 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 116/1000
2023-09-11 18:12:04.194 
Epoch 116/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.3748, val_MinusLogProbMetric: 2.3748

Epoch 116: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.3748 - val_MinusLogProbMetric: 2.3748 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 117/1000
2023-09-11 18:12:16.090 
Epoch 117/1000 
	 loss: 2.4006, MinusLogProbMetric: 2.4006, val_loss: 2.3821, val_MinusLogProbMetric: 2.3821

Epoch 117: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.4006 - MinusLogProbMetric: 2.4006 - val_loss: 2.3821 - val_MinusLogProbMetric: 2.3821 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 118/1000
2023-09-11 18:12:27.755 
Epoch 118/1000 
	 loss: 2.3992, MinusLogProbMetric: 2.3992, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 118: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3992 - MinusLogProbMetric: 2.3992 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-11 18:12:39.423 
Epoch 119/1000 
	 loss: 2.3974, MinusLogProbMetric: 2.3974, val_loss: 2.3777, val_MinusLogProbMetric: 2.3777

Epoch 119: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3974 - MinusLogProbMetric: 2.3974 - val_loss: 2.3777 - val_MinusLogProbMetric: 2.3777 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 120/1000
2023-09-11 18:12:51.137 
Epoch 120/1000 
	 loss: 2.4000, MinusLogProbMetric: 2.4000, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 120: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.4000 - MinusLogProbMetric: 2.4000 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-11 18:13:02.973 
Epoch 121/1000 
	 loss: 2.3926, MinusLogProbMetric: 2.3926, val_loss: 2.3765, val_MinusLogProbMetric: 2.3765

Epoch 121: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3926 - MinusLogProbMetric: 2.3926 - val_loss: 2.3765 - val_MinusLogProbMetric: 2.3765 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-11 18:13:14.550 
Epoch 122/1000 
	 loss: 2.3957, MinusLogProbMetric: 2.3957, val_loss: 2.4149, val_MinusLogProbMetric: 2.4149

Epoch 122: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3957 - MinusLogProbMetric: 2.3957 - val_loss: 2.4149 - val_MinusLogProbMetric: 2.4149 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 123/1000
2023-09-11 18:13:26.435 
Epoch 123/1000 
	 loss: 2.3981, MinusLogProbMetric: 2.3981, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 123: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3981 - MinusLogProbMetric: 2.3981 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 124/1000
2023-09-11 18:13:38.256 
Epoch 124/1000 
	 loss: 2.4027, MinusLogProbMetric: 2.4027, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 124: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.4027 - MinusLogProbMetric: 2.4027 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-11 18:13:50.045 
Epoch 125/1000 
	 loss: 2.3934, MinusLogProbMetric: 2.3934, val_loss: 2.3763, val_MinusLogProbMetric: 2.3763

Epoch 125: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3934 - MinusLogProbMetric: 2.3934 - val_loss: 2.3763 - val_MinusLogProbMetric: 2.3763 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 126/1000
2023-09-11 18:14:01.800 
Epoch 126/1000 
	 loss: 2.3991, MinusLogProbMetric: 2.3991, val_loss: 2.4007, val_MinusLogProbMetric: 2.4007

Epoch 126: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3991 - MinusLogProbMetric: 2.3991 - val_loss: 2.4007 - val_MinusLogProbMetric: 2.4007 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-11 18:14:13.439 
Epoch 127/1000 
	 loss: 2.3932, MinusLogProbMetric: 2.3932, val_loss: 2.3748, val_MinusLogProbMetric: 2.3748

Epoch 127: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3932 - MinusLogProbMetric: 2.3932 - val_loss: 2.3748 - val_MinusLogProbMetric: 2.3748 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 128/1000
2023-09-11 18:14:25.270 
Epoch 128/1000 
	 loss: 2.3944, MinusLogProbMetric: 2.3944, val_loss: 2.3830, val_MinusLogProbMetric: 2.3830

Epoch 128: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3944 - MinusLogProbMetric: 2.3944 - val_loss: 2.3830 - val_MinusLogProbMetric: 2.3830 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-11 18:14:36.993 
Epoch 129/1000 
	 loss: 2.3925, MinusLogProbMetric: 2.3925, val_loss: 2.3788, val_MinusLogProbMetric: 2.3788

Epoch 129: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3925 - MinusLogProbMetric: 2.3925 - val_loss: 2.3788 - val_MinusLogProbMetric: 2.3788 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-11 18:14:48.795 
Epoch 130/1000 
	 loss: 2.3903, MinusLogProbMetric: 2.3903, val_loss: 2.3770, val_MinusLogProbMetric: 2.3770

Epoch 130: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3903 - MinusLogProbMetric: 2.3903 - val_loss: 2.3770 - val_MinusLogProbMetric: 2.3770 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-11 18:15:00.472 
Epoch 131/1000 
	 loss: 2.4015, MinusLogProbMetric: 2.4015, val_loss: 2.3942, val_MinusLogProbMetric: 2.3942

Epoch 131: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.4015 - MinusLogProbMetric: 2.4015 - val_loss: 2.3942 - val_MinusLogProbMetric: 2.3942 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 132/1000
2023-09-11 18:15:12.333 
Epoch 132/1000 
	 loss: 2.3911, MinusLogProbMetric: 2.3911, val_loss: 2.3751, val_MinusLogProbMetric: 2.3751

Epoch 132: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3911 - MinusLogProbMetric: 2.3911 - val_loss: 2.3751 - val_MinusLogProbMetric: 2.3751 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 133/1000
2023-09-11 18:15:24.040 
Epoch 133/1000 
	 loss: 2.3956, MinusLogProbMetric: 2.3956, val_loss: 2.3753, val_MinusLogProbMetric: 2.3753

Epoch 133: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3956 - MinusLogProbMetric: 2.3956 - val_loss: 2.3753 - val_MinusLogProbMetric: 2.3753 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-11 18:15:35.794 
Epoch 134/1000 
	 loss: 2.3952, MinusLogProbMetric: 2.3952, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 134: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3952 - MinusLogProbMetric: 2.3952 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-11 18:15:47.576 
Epoch 135/1000 
	 loss: 2.3947, MinusLogProbMetric: 2.3947, val_loss: 2.3740, val_MinusLogProbMetric: 2.3740

Epoch 135: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3947 - MinusLogProbMetric: 2.3947 - val_loss: 2.3740 - val_MinusLogProbMetric: 2.3740 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-11 18:15:59.387 
Epoch 136/1000 
	 loss: 2.3940, MinusLogProbMetric: 2.3940, val_loss: 2.3759, val_MinusLogProbMetric: 2.3759

Epoch 136: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3940 - MinusLogProbMetric: 2.3940 - val_loss: 2.3759 - val_MinusLogProbMetric: 2.3759 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 137/1000
2023-09-11 18:16:11.107 
Epoch 137/1000 
	 loss: 2.3924, MinusLogProbMetric: 2.3924, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 137: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3924 - MinusLogProbMetric: 2.3924 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 138/1000
2023-09-11 18:16:22.792 
Epoch 138/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.3788, val_MinusLogProbMetric: 2.3788

Epoch 138: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.3788 - val_MinusLogProbMetric: 2.3788 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-11 18:16:34.567 
Epoch 139/1000 
	 loss: 2.3943, MinusLogProbMetric: 2.3943, val_loss: 2.3863, val_MinusLogProbMetric: 2.3863

Epoch 139: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3943 - MinusLogProbMetric: 2.3943 - val_loss: 2.3863 - val_MinusLogProbMetric: 2.3863 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-11 18:16:46.246 
Epoch 140/1000 
	 loss: 2.3974, MinusLogProbMetric: 2.3974, val_loss: 2.3908, val_MinusLogProbMetric: 2.3908

Epoch 140: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3974 - MinusLogProbMetric: 2.3974 - val_loss: 2.3908 - val_MinusLogProbMetric: 2.3908 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 141/1000
2023-09-11 18:16:57.921 
Epoch 141/1000 
	 loss: 2.3934, MinusLogProbMetric: 2.3934, val_loss: 2.3783, val_MinusLogProbMetric: 2.3783

Epoch 141: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3934 - MinusLogProbMetric: 2.3934 - val_loss: 2.3783 - val_MinusLogProbMetric: 2.3783 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 142/1000
2023-09-11 18:17:09.576 
Epoch 142/1000 
	 loss: 2.3948, MinusLogProbMetric: 2.3948, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 142: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3948 - MinusLogProbMetric: 2.3948 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 143/1000
2023-09-11 18:17:21.380 
Epoch 143/1000 
	 loss: 2.3929, MinusLogProbMetric: 2.3929, val_loss: 2.3766, val_MinusLogProbMetric: 2.3766

Epoch 143: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3929 - MinusLogProbMetric: 2.3929 - val_loss: 2.3766 - val_MinusLogProbMetric: 2.3766 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 144/1000
2023-09-11 18:17:33.126 
Epoch 144/1000 
	 loss: 2.3940, MinusLogProbMetric: 2.3940, val_loss: 2.3737, val_MinusLogProbMetric: 2.3737

Epoch 144: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3940 - MinusLogProbMetric: 2.3940 - val_loss: 2.3737 - val_MinusLogProbMetric: 2.3737 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 145/1000
2023-09-11 18:17:44.823 
Epoch 145/1000 
	 loss: 2.3899, MinusLogProbMetric: 2.3899, val_loss: 2.3936, val_MinusLogProbMetric: 2.3936

Epoch 145: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3899 - MinusLogProbMetric: 2.3899 - val_loss: 2.3936 - val_MinusLogProbMetric: 2.3936 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 146/1000
2023-09-11 18:17:56.674 
Epoch 146/1000 
	 loss: 2.3924, MinusLogProbMetric: 2.3924, val_loss: 2.3865, val_MinusLogProbMetric: 2.3865

Epoch 146: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3924 - MinusLogProbMetric: 2.3924 - val_loss: 2.3865 - val_MinusLogProbMetric: 2.3865 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-11 18:18:08.485 
Epoch 147/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.3723, val_MinusLogProbMetric: 2.3723

Epoch 147: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.3723 - val_MinusLogProbMetric: 2.3723 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-11 18:18:20.421 
Epoch 148/1000 
	 loss: 2.3970, MinusLogProbMetric: 2.3970, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 148: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3970 - MinusLogProbMetric: 2.3970 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 149/1000
2023-09-11 18:18:32.117 
Epoch 149/1000 
	 loss: 2.3963, MinusLogProbMetric: 2.3963, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 149: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3963 - MinusLogProbMetric: 2.3963 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-11 18:18:43.862 
Epoch 150/1000 
	 loss: 2.3901, MinusLogProbMetric: 2.3901, val_loss: 2.3967, val_MinusLogProbMetric: 2.3967

Epoch 150: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3901 - MinusLogProbMetric: 2.3901 - val_loss: 2.3967 - val_MinusLogProbMetric: 2.3967 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-11 18:18:55.700 
Epoch 151/1000 
	 loss: 2.3926, MinusLogProbMetric: 2.3926, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 151: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3926 - MinusLogProbMetric: 2.3926 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-11 18:19:07.479 
Epoch 152/1000 
	 loss: 2.3924, MinusLogProbMetric: 2.3924, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 152: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3924 - MinusLogProbMetric: 2.3924 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-11 18:19:19.289 
Epoch 153/1000 
	 loss: 2.3944, MinusLogProbMetric: 2.3944, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 153: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3944 - MinusLogProbMetric: 2.3944 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 154/1000
2023-09-11 18:19:31.077 
Epoch 154/1000 
	 loss: 2.3915, MinusLogProbMetric: 2.3915, val_loss: 2.3814, val_MinusLogProbMetric: 2.3814

Epoch 154: val_loss did not improve from 2.36970
196/196 - 12s - loss: 2.3915 - MinusLogProbMetric: 2.3915 - val_loss: 2.3814 - val_MinusLogProbMetric: 2.3814 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 155/1000
2023-09-11 18:19:42.812 
Epoch 155/1000 
	 loss: 2.3872, MinusLogProbMetric: 2.3872, val_loss: 2.3682, val_MinusLogProbMetric: 2.3682

Epoch 155: val_loss improved from 2.36970 to 2.36822, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.3872 - MinusLogProbMetric: 2.3872 - val_loss: 2.3682 - val_MinusLogProbMetric: 2.3682 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 156/1000
2023-09-11 18:19:54.729 
Epoch 156/1000 
	 loss: 2.3962, MinusLogProbMetric: 2.3962, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 156: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3962 - MinusLogProbMetric: 2.3962 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 157/1000
2023-09-11 18:20:06.458 
Epoch 157/1000 
	 loss: 2.3957, MinusLogProbMetric: 2.3957, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 157: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3957 - MinusLogProbMetric: 2.3957 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-11 18:20:18.345 
Epoch 158/1000 
	 loss: 2.3887, MinusLogProbMetric: 2.3887, val_loss: 2.3798, val_MinusLogProbMetric: 2.3798

Epoch 158: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3887 - MinusLogProbMetric: 2.3887 - val_loss: 2.3798 - val_MinusLogProbMetric: 2.3798 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 159/1000
2023-09-11 18:20:30.042 
Epoch 159/1000 
	 loss: 2.3929, MinusLogProbMetric: 2.3929, val_loss: 2.3903, val_MinusLogProbMetric: 2.3903

Epoch 159: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3929 - MinusLogProbMetric: 2.3929 - val_loss: 2.3903 - val_MinusLogProbMetric: 2.3903 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-11 18:20:41.682 
Epoch 160/1000 
	 loss: 2.3918, MinusLogProbMetric: 2.3918, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 160: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3918 - MinusLogProbMetric: 2.3918 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 161/1000
2023-09-11 18:20:53.492 
Epoch 161/1000 
	 loss: 2.3942, MinusLogProbMetric: 2.3942, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 161: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3942 - MinusLogProbMetric: 2.3942 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 162/1000
2023-09-11 18:21:05.278 
Epoch 162/1000 
	 loss: 2.3897, MinusLogProbMetric: 2.3897, val_loss: 2.3744, val_MinusLogProbMetric: 2.3744

Epoch 162: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3897 - MinusLogProbMetric: 2.3897 - val_loss: 2.3744 - val_MinusLogProbMetric: 2.3744 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 163/1000
2023-09-11 18:21:16.918 
Epoch 163/1000 
	 loss: 2.3885, MinusLogProbMetric: 2.3885, val_loss: 2.3922, val_MinusLogProbMetric: 2.3922

Epoch 163: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3885 - MinusLogProbMetric: 2.3885 - val_loss: 2.3922 - val_MinusLogProbMetric: 2.3922 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 164/1000
2023-09-11 18:21:28.632 
Epoch 164/1000 
	 loss: 2.3940, MinusLogProbMetric: 2.3940, val_loss: 2.3854, val_MinusLogProbMetric: 2.3854

Epoch 164: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3940 - MinusLogProbMetric: 2.3940 - val_loss: 2.3854 - val_MinusLogProbMetric: 2.3854 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 165/1000
2023-09-11 18:21:40.465 
Epoch 165/1000 
	 loss: 2.3869, MinusLogProbMetric: 2.3869, val_loss: 2.3845, val_MinusLogProbMetric: 2.3845

Epoch 165: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3869 - MinusLogProbMetric: 2.3869 - val_loss: 2.3845 - val_MinusLogProbMetric: 2.3845 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 166/1000
2023-09-11 18:21:52.059 
Epoch 166/1000 
	 loss: 2.3891, MinusLogProbMetric: 2.3891, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 166: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3891 - MinusLogProbMetric: 2.3891 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-11 18:22:03.810 
Epoch 167/1000 
	 loss: 2.3880, MinusLogProbMetric: 2.3880, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 167: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3880 - MinusLogProbMetric: 2.3880 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 168/1000
2023-09-11 18:22:15.524 
Epoch 168/1000 
	 loss: 2.3903, MinusLogProbMetric: 2.3903, val_loss: 2.3860, val_MinusLogProbMetric: 2.3860

Epoch 168: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3903 - MinusLogProbMetric: 2.3903 - val_loss: 2.3860 - val_MinusLogProbMetric: 2.3860 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-11 18:22:27.355 
Epoch 169/1000 
	 loss: 2.3900, MinusLogProbMetric: 2.3900, val_loss: 2.3787, val_MinusLogProbMetric: 2.3787

Epoch 169: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3900 - MinusLogProbMetric: 2.3900 - val_loss: 2.3787 - val_MinusLogProbMetric: 2.3787 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 170/1000
2023-09-11 18:22:39.104 
Epoch 170/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.3792, val_MinusLogProbMetric: 2.3792

Epoch 170: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.3792 - val_MinusLogProbMetric: 2.3792 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 171/1000
2023-09-11 18:22:50.740 
Epoch 171/1000 
	 loss: 2.3904, MinusLogProbMetric: 2.3904, val_loss: 2.4045, val_MinusLogProbMetric: 2.4045

Epoch 171: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3904 - MinusLogProbMetric: 2.3904 - val_loss: 2.4045 - val_MinusLogProbMetric: 2.4045 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 172/1000
2023-09-11 18:23:02.562 
Epoch 172/1000 
	 loss: 2.3924, MinusLogProbMetric: 2.3924, val_loss: 2.3756, val_MinusLogProbMetric: 2.3756

Epoch 172: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3924 - MinusLogProbMetric: 2.3924 - val_loss: 2.3756 - val_MinusLogProbMetric: 2.3756 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 173/1000
2023-09-11 18:23:14.362 
Epoch 173/1000 
	 loss: 2.3889, MinusLogProbMetric: 2.3889, val_loss: 2.3855, val_MinusLogProbMetric: 2.3855

Epoch 173: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3889 - MinusLogProbMetric: 2.3889 - val_loss: 2.3855 - val_MinusLogProbMetric: 2.3855 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 174/1000
2023-09-11 18:23:26.159 
Epoch 174/1000 
	 loss: 2.3872, MinusLogProbMetric: 2.3872, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 174: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3872 - MinusLogProbMetric: 2.3872 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 175/1000
2023-09-11 18:23:37.810 
Epoch 175/1000 
	 loss: 2.3929, MinusLogProbMetric: 2.3929, val_loss: 2.3698, val_MinusLogProbMetric: 2.3698

Epoch 175: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3929 - MinusLogProbMetric: 2.3929 - val_loss: 2.3698 - val_MinusLogProbMetric: 2.3698 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-11 18:23:49.514 
Epoch 176/1000 
	 loss: 2.3871, MinusLogProbMetric: 2.3871, val_loss: 2.3769, val_MinusLogProbMetric: 2.3769

Epoch 176: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3871 - MinusLogProbMetric: 2.3871 - val_loss: 2.3769 - val_MinusLogProbMetric: 2.3769 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-11 18:24:01.296 
Epoch 177/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.3809, val_MinusLogProbMetric: 2.3809

Epoch 177: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.3809 - val_MinusLogProbMetric: 2.3809 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 178/1000
2023-09-11 18:24:13.069 
Epoch 178/1000 
	 loss: 2.3881, MinusLogProbMetric: 2.3881, val_loss: 2.3828, val_MinusLogProbMetric: 2.3828

Epoch 178: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3881 - MinusLogProbMetric: 2.3881 - val_loss: 2.3828 - val_MinusLogProbMetric: 2.3828 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-11 18:24:24.856 
Epoch 179/1000 
	 loss: 2.3878, MinusLogProbMetric: 2.3878, val_loss: 2.4029, val_MinusLogProbMetric: 2.4029

Epoch 179: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3878 - MinusLogProbMetric: 2.3878 - val_loss: 2.4029 - val_MinusLogProbMetric: 2.4029 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 180/1000
2023-09-11 18:24:36.670 
Epoch 180/1000 
	 loss: 2.3918, MinusLogProbMetric: 2.3918, val_loss: 2.3872, val_MinusLogProbMetric: 2.3872

Epoch 180: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3918 - MinusLogProbMetric: 2.3918 - val_loss: 2.3872 - val_MinusLogProbMetric: 2.3872 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 181/1000
2023-09-11 18:24:48.389 
Epoch 181/1000 
	 loss: 2.3863, MinusLogProbMetric: 2.3863, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 181: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3863 - MinusLogProbMetric: 2.3863 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 182/1000
2023-09-11 18:25:00.190 
Epoch 182/1000 
	 loss: 2.3923, MinusLogProbMetric: 2.3923, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 182: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3923 - MinusLogProbMetric: 2.3923 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 183/1000
2023-09-11 18:25:11.990 
Epoch 183/1000 
	 loss: 2.3898, MinusLogProbMetric: 2.3898, val_loss: 2.4045, val_MinusLogProbMetric: 2.4045

Epoch 183: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3898 - MinusLogProbMetric: 2.3898 - val_loss: 2.4045 - val_MinusLogProbMetric: 2.4045 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 184/1000
2023-09-11 18:25:23.733 
Epoch 184/1000 
	 loss: 2.3890, MinusLogProbMetric: 2.3890, val_loss: 2.3731, val_MinusLogProbMetric: 2.3731

Epoch 184: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3890 - MinusLogProbMetric: 2.3890 - val_loss: 2.3731 - val_MinusLogProbMetric: 2.3731 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 185/1000
2023-09-11 18:25:35.521 
Epoch 185/1000 
	 loss: 2.3888, MinusLogProbMetric: 2.3888, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 185: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3888 - MinusLogProbMetric: 2.3888 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 186/1000
2023-09-11 18:25:47.286 
Epoch 186/1000 
	 loss: 2.3894, MinusLogProbMetric: 2.3894, val_loss: 2.3787, val_MinusLogProbMetric: 2.3787

Epoch 186: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3894 - MinusLogProbMetric: 2.3894 - val_loss: 2.3787 - val_MinusLogProbMetric: 2.3787 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 187/1000
2023-09-11 18:25:59.194 
Epoch 187/1000 
	 loss: 2.3885, MinusLogProbMetric: 2.3885, val_loss: 2.3930, val_MinusLogProbMetric: 2.3930

Epoch 187: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3885 - MinusLogProbMetric: 2.3885 - val_loss: 2.3930 - val_MinusLogProbMetric: 2.3930 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 188/1000
2023-09-11 18:26:10.955 
Epoch 188/1000 
	 loss: 2.3899, MinusLogProbMetric: 2.3899, val_loss: 2.3727, val_MinusLogProbMetric: 2.3727

Epoch 188: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3899 - MinusLogProbMetric: 2.3899 - val_loss: 2.3727 - val_MinusLogProbMetric: 2.3727 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 189/1000
2023-09-11 18:26:22.803 
Epoch 189/1000 
	 loss: 2.3872, MinusLogProbMetric: 2.3872, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 189: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3872 - MinusLogProbMetric: 2.3872 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 190/1000
2023-09-11 18:26:34.696 
Epoch 190/1000 
	 loss: 2.3870, MinusLogProbMetric: 2.3870, val_loss: 2.3848, val_MinusLogProbMetric: 2.3848

Epoch 190: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3870 - MinusLogProbMetric: 2.3870 - val_loss: 2.3848 - val_MinusLogProbMetric: 2.3848 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 191/1000
2023-09-11 18:26:46.600 
Epoch 191/1000 
	 loss: 2.3923, MinusLogProbMetric: 2.3923, val_loss: 2.3776, val_MinusLogProbMetric: 2.3776

Epoch 191: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3923 - MinusLogProbMetric: 2.3923 - val_loss: 2.3776 - val_MinusLogProbMetric: 2.3776 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 192/1000
2023-09-11 18:26:58.452 
Epoch 192/1000 
	 loss: 2.3901, MinusLogProbMetric: 2.3901, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 192: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3901 - MinusLogProbMetric: 2.3901 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-11 18:27:10.221 
Epoch 193/1000 
	 loss: 2.3858, MinusLogProbMetric: 2.3858, val_loss: 2.4046, val_MinusLogProbMetric: 2.4046

Epoch 193: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3858 - MinusLogProbMetric: 2.3858 - val_loss: 2.4046 - val_MinusLogProbMetric: 2.4046 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-11 18:27:22.139 
Epoch 194/1000 
	 loss: 2.3878, MinusLogProbMetric: 2.3878, val_loss: 2.3756, val_MinusLogProbMetric: 2.3756

Epoch 194: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3878 - MinusLogProbMetric: 2.3878 - val_loss: 2.3756 - val_MinusLogProbMetric: 2.3756 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 195/1000
2023-09-11 18:27:33.964 
Epoch 195/1000 
	 loss: 2.3913, MinusLogProbMetric: 2.3913, val_loss: 2.3802, val_MinusLogProbMetric: 2.3802

Epoch 195: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3913 - MinusLogProbMetric: 2.3913 - val_loss: 2.3802 - val_MinusLogProbMetric: 2.3802 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-11 18:27:45.755 
Epoch 196/1000 
	 loss: 2.3886, MinusLogProbMetric: 2.3886, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 196: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3886 - MinusLogProbMetric: 2.3886 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-11 18:27:57.304 
Epoch 197/1000 
	 loss: 2.3892, MinusLogProbMetric: 2.3892, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 197: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3892 - MinusLogProbMetric: 2.3892 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 198/1000
2023-09-11 18:28:08.908 
Epoch 198/1000 
	 loss: 2.3863, MinusLogProbMetric: 2.3863, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 198: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3863 - MinusLogProbMetric: 2.3863 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 199/1000
2023-09-11 18:28:20.646 
Epoch 199/1000 
	 loss: 2.3858, MinusLogProbMetric: 2.3858, val_loss: 2.3835, val_MinusLogProbMetric: 2.3835

Epoch 199: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3858 - MinusLogProbMetric: 2.3858 - val_loss: 2.3835 - val_MinusLogProbMetric: 2.3835 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-11 18:28:32.405 
Epoch 200/1000 
	 loss: 2.3956, MinusLogProbMetric: 2.3956, val_loss: 2.3867, val_MinusLogProbMetric: 2.3867

Epoch 200: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3956 - MinusLogProbMetric: 2.3956 - val_loss: 2.3867 - val_MinusLogProbMetric: 2.3867 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-11 18:28:44.104 
Epoch 201/1000 
	 loss: 2.3892, MinusLogProbMetric: 2.3892, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 201: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3892 - MinusLogProbMetric: 2.3892 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-11 18:28:55.841 
Epoch 202/1000 
	 loss: 2.3830, MinusLogProbMetric: 2.3830, val_loss: 2.4151, val_MinusLogProbMetric: 2.4151

Epoch 202: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3830 - MinusLogProbMetric: 2.3830 - val_loss: 2.4151 - val_MinusLogProbMetric: 2.4151 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-11 18:29:07.562 
Epoch 203/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 203: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 204/1000
2023-09-11 18:29:19.194 
Epoch 204/1000 
	 loss: 2.3861, MinusLogProbMetric: 2.3861, val_loss: 2.3928, val_MinusLogProbMetric: 2.3928

Epoch 204: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3861 - MinusLogProbMetric: 2.3861 - val_loss: 2.3928 - val_MinusLogProbMetric: 2.3928 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 205/1000
2023-09-11 18:29:30.887 
Epoch 205/1000 
	 loss: 2.3928, MinusLogProbMetric: 2.3928, val_loss: 2.3702, val_MinusLogProbMetric: 2.3702

Epoch 205: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3928 - MinusLogProbMetric: 2.3928 - val_loss: 2.3702 - val_MinusLogProbMetric: 2.3702 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 206/1000
2023-09-11 18:29:42.568 
Epoch 206/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 206: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 207/1000
2023-09-11 18:29:54.239 
Epoch 207/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 207: val_loss did not improve from 2.36822
196/196 - 12s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-11 18:30:05.871 
Epoch 208/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 208: val_loss improved from 2.36822 to 2.36326, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 209/1000
2023-09-11 18:30:17.694 
Epoch 209/1000 
	 loss: 2.3755, MinusLogProbMetric: 2.3755, val_loss: 2.3691, val_MinusLogProbMetric: 2.3691

Epoch 209: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3755 - MinusLogProbMetric: 2.3755 - val_loss: 2.3691 - val_MinusLogProbMetric: 2.3691 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 210/1000
2023-09-11 18:30:29.441 
Epoch 210/1000 
	 loss: 2.3763, MinusLogProbMetric: 2.3763, val_loss: 2.3645, val_MinusLogProbMetric: 2.3645

Epoch 210: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3763 - MinusLogProbMetric: 2.3763 - val_loss: 2.3645 - val_MinusLogProbMetric: 2.3645 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 211/1000
2023-09-11 18:30:41.272 
Epoch 211/1000 
	 loss: 2.3771, MinusLogProbMetric: 2.3771, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 211: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3771 - MinusLogProbMetric: 2.3771 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 212/1000
2023-09-11 18:30:52.988 
Epoch 212/1000 
	 loss: 2.3771, MinusLogProbMetric: 2.3771, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 212: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3771 - MinusLogProbMetric: 2.3771 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 213/1000
2023-09-11 18:31:04.737 
Epoch 213/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3656, val_MinusLogProbMetric: 2.3656

Epoch 213: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3656 - val_MinusLogProbMetric: 2.3656 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 214/1000
2023-09-11 18:31:16.484 
Epoch 214/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3661, val_MinusLogProbMetric: 2.3661

Epoch 214: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3661 - val_MinusLogProbMetric: 2.3661 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-11 18:31:28.245 
Epoch 215/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 215: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 216/1000
2023-09-11 18:31:40.010 
Epoch 216/1000 
	 loss: 2.3776, MinusLogProbMetric: 2.3776, val_loss: 2.3687, val_MinusLogProbMetric: 2.3687

Epoch 216: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3776 - MinusLogProbMetric: 2.3776 - val_loss: 2.3687 - val_MinusLogProbMetric: 2.3687 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 217/1000
2023-09-11 18:31:51.615 
Epoch 217/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3729, val_MinusLogProbMetric: 2.3729

Epoch 217: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3729 - val_MinusLogProbMetric: 2.3729 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 218/1000
2023-09-11 18:32:03.285 
Epoch 218/1000 
	 loss: 2.3777, MinusLogProbMetric: 2.3777, val_loss: 2.3660, val_MinusLogProbMetric: 2.3660

Epoch 218: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3777 - MinusLogProbMetric: 2.3777 - val_loss: 2.3660 - val_MinusLogProbMetric: 2.3660 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-11 18:32:15.035 
Epoch 219/1000 
	 loss: 2.3750, MinusLogProbMetric: 2.3750, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 219: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3750 - MinusLogProbMetric: 2.3750 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 220/1000
2023-09-11 18:32:26.604 
Epoch 220/1000 
	 loss: 2.3761, MinusLogProbMetric: 2.3761, val_loss: 2.3839, val_MinusLogProbMetric: 2.3839

Epoch 220: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3761 - MinusLogProbMetric: 2.3761 - val_loss: 2.3839 - val_MinusLogProbMetric: 2.3839 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 221/1000
2023-09-11 18:32:38.394 
Epoch 221/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.3664, val_MinusLogProbMetric: 2.3664

Epoch 221: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.3664 - val_MinusLogProbMetric: 2.3664 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-11 18:32:50.074 
Epoch 222/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 222: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-11 18:33:01.669 
Epoch 223/1000 
	 loss: 2.3759, MinusLogProbMetric: 2.3759, val_loss: 2.3748, val_MinusLogProbMetric: 2.3748

Epoch 223: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3759 - MinusLogProbMetric: 2.3759 - val_loss: 2.3748 - val_MinusLogProbMetric: 2.3748 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 224/1000
2023-09-11 18:33:13.295 
Epoch 224/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3691, val_MinusLogProbMetric: 2.3691

Epoch 224: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3691 - val_MinusLogProbMetric: 2.3691 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 225/1000
2023-09-11 18:33:25.021 
Epoch 225/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.3676, val_MinusLogProbMetric: 2.3676

Epoch 225: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.3676 - val_MinusLogProbMetric: 2.3676 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-11 18:33:36.726 
Epoch 226/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3675, val_MinusLogProbMetric: 2.3675

Epoch 226: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3675 - val_MinusLogProbMetric: 2.3675 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 227/1000
2023-09-11 18:33:48.494 
Epoch 227/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3750, val_MinusLogProbMetric: 2.3750

Epoch 227: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3750 - val_MinusLogProbMetric: 2.3750 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 228/1000
2023-09-11 18:34:00.287 
Epoch 228/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 228: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 229/1000
2023-09-11 18:34:11.999 
Epoch 229/1000 
	 loss: 2.3775, MinusLogProbMetric: 2.3775, val_loss: 2.3678, val_MinusLogProbMetric: 2.3678

Epoch 229: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3775 - MinusLogProbMetric: 2.3775 - val_loss: 2.3678 - val_MinusLogProbMetric: 2.3678 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-11 18:34:23.764 
Epoch 230/1000 
	 loss: 2.3762, MinusLogProbMetric: 2.3762, val_loss: 2.3687, val_MinusLogProbMetric: 2.3687

Epoch 230: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3762 - MinusLogProbMetric: 2.3762 - val_loss: 2.3687 - val_MinusLogProbMetric: 2.3687 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 231/1000
2023-09-11 18:34:35.589 
Epoch 231/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.3643, val_MinusLogProbMetric: 2.3643

Epoch 231: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.3643 - val_MinusLogProbMetric: 2.3643 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 232/1000
2023-09-11 18:34:47.369 
Epoch 232/1000 
	 loss: 2.3754, MinusLogProbMetric: 2.3754, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 232: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3754 - MinusLogProbMetric: 2.3754 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 233/1000
2023-09-11 18:34:59.242 
Epoch 233/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 233: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 234/1000
2023-09-11 18:35:11.069 
Epoch 234/1000 
	 loss: 2.3762, MinusLogProbMetric: 2.3762, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 234: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3762 - MinusLogProbMetric: 2.3762 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-11 18:35:22.894 
Epoch 235/1000 
	 loss: 2.3763, MinusLogProbMetric: 2.3763, val_loss: 2.3672, val_MinusLogProbMetric: 2.3672

Epoch 235: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3763 - MinusLogProbMetric: 2.3763 - val_loss: 2.3672 - val_MinusLogProbMetric: 2.3672 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 236/1000
2023-09-11 18:35:34.700 
Epoch 236/1000 
	 loss: 2.3777, MinusLogProbMetric: 2.3777, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 236: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3777 - MinusLogProbMetric: 2.3777 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 237/1000
2023-09-11 18:35:46.460 
Epoch 237/1000 
	 loss: 2.3773, MinusLogProbMetric: 2.3773, val_loss: 2.3767, val_MinusLogProbMetric: 2.3767

Epoch 237: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3773 - MinusLogProbMetric: 2.3773 - val_loss: 2.3767 - val_MinusLogProbMetric: 2.3767 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 238/1000
2023-09-11 18:35:58.111 
Epoch 238/1000 
	 loss: 2.3764, MinusLogProbMetric: 2.3764, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 238: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3764 - MinusLogProbMetric: 2.3764 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 239/1000
2023-09-11 18:36:09.806 
Epoch 239/1000 
	 loss: 2.3750, MinusLogProbMetric: 2.3750, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 239: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3750 - MinusLogProbMetric: 2.3750 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 240/1000
2023-09-11 18:36:21.628 
Epoch 240/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3689, val_MinusLogProbMetric: 2.3689

Epoch 240: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3689 - val_MinusLogProbMetric: 2.3689 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-11 18:36:33.392 
Epoch 241/1000 
	 loss: 2.3760, MinusLogProbMetric: 2.3760, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 241: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3760 - MinusLogProbMetric: 2.3760 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 242/1000
2023-09-11 18:36:45.172 
Epoch 242/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3654, val_MinusLogProbMetric: 2.3654

Epoch 242: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3654 - val_MinusLogProbMetric: 2.3654 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 243/1000
2023-09-11 18:36:56.771 
Epoch 243/1000 
	 loss: 2.3762, MinusLogProbMetric: 2.3762, val_loss: 2.3791, val_MinusLogProbMetric: 2.3791

Epoch 243: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3762 - MinusLogProbMetric: 2.3762 - val_loss: 2.3791 - val_MinusLogProbMetric: 2.3791 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 244/1000
2023-09-11 18:37:08.591 
Epoch 244/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.3725, val_MinusLogProbMetric: 2.3725

Epoch 244: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.3725 - val_MinusLogProbMetric: 2.3725 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 245/1000
2023-09-11 18:37:20.224 
Epoch 245/1000 
	 loss: 2.3761, MinusLogProbMetric: 2.3761, val_loss: 2.3706, val_MinusLogProbMetric: 2.3706

Epoch 245: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3761 - MinusLogProbMetric: 2.3761 - val_loss: 2.3706 - val_MinusLogProbMetric: 2.3706 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 246/1000
2023-09-11 18:37:31.869 
Epoch 246/1000 
	 loss: 2.3755, MinusLogProbMetric: 2.3755, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 246: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3755 - MinusLogProbMetric: 2.3755 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 247/1000
2023-09-11 18:37:43.596 
Epoch 247/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3757, val_MinusLogProbMetric: 2.3757

Epoch 247: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3757 - val_MinusLogProbMetric: 2.3757 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-11 18:37:55.353 
Epoch 248/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 248: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-11 18:38:07.014 
Epoch 249/1000 
	 loss: 2.3751, MinusLogProbMetric: 2.3751, val_loss: 2.3708, val_MinusLogProbMetric: 2.3708

Epoch 249: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3751 - MinusLogProbMetric: 2.3751 - val_loss: 2.3708 - val_MinusLogProbMetric: 2.3708 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 250/1000
2023-09-11 18:38:18.851 
Epoch 250/1000 
	 loss: 2.3745, MinusLogProbMetric: 2.3745, val_loss: 2.3665, val_MinusLogProbMetric: 2.3665

Epoch 250: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3745 - MinusLogProbMetric: 2.3745 - val_loss: 2.3665 - val_MinusLogProbMetric: 2.3665 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-11 18:38:30.663 
Epoch 251/1000 
	 loss: 2.3776, MinusLogProbMetric: 2.3776, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 251: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3776 - MinusLogProbMetric: 2.3776 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 252/1000
2023-09-11 18:38:42.372 
Epoch 252/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3713, val_MinusLogProbMetric: 2.3713

Epoch 252: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3713 - val_MinusLogProbMetric: 2.3713 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-11 18:38:54.098 
Epoch 253/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3692, val_MinusLogProbMetric: 2.3692

Epoch 253: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3692 - val_MinusLogProbMetric: 2.3692 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 254/1000
2023-09-11 18:39:05.837 
Epoch 254/1000 
	 loss: 2.3750, MinusLogProbMetric: 2.3750, val_loss: 2.3733, val_MinusLogProbMetric: 2.3733

Epoch 254: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3750 - MinusLogProbMetric: 2.3750 - val_loss: 2.3733 - val_MinusLogProbMetric: 2.3733 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-11 18:39:17.493 
Epoch 255/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.3751, val_MinusLogProbMetric: 2.3751

Epoch 255: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.3751 - val_MinusLogProbMetric: 2.3751 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 256/1000
2023-09-11 18:39:29.074 
Epoch 256/1000 
	 loss: 2.3747, MinusLogProbMetric: 2.3747, val_loss: 2.3695, val_MinusLogProbMetric: 2.3695

Epoch 256: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3747 - MinusLogProbMetric: 2.3747 - val_loss: 2.3695 - val_MinusLogProbMetric: 2.3695 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 257/1000
2023-09-11 18:39:40.822 
Epoch 257/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 257: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-11 18:39:52.459 
Epoch 258/1000 
	 loss: 2.3747, MinusLogProbMetric: 2.3747, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 258: val_loss did not improve from 2.36326
196/196 - 12s - loss: 2.3747 - MinusLogProbMetric: 2.3747 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 259/1000
2023-09-11 18:40:04.113 
Epoch 259/1000 
	 loss: 2.3705, MinusLogProbMetric: 2.3705, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 259: val_loss improved from 2.36326 to 2.36215, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.3705 - MinusLogProbMetric: 2.3705 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 260/1000
2023-09-11 18:40:16.007 
Epoch 260/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 260: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 261/1000
2023-09-11 18:40:27.611 
Epoch 261/1000 
	 loss: 2.3722, MinusLogProbMetric: 2.3722, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 261: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3722 - MinusLogProbMetric: 2.3722 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 262/1000
2023-09-11 18:40:39.332 
Epoch 262/1000 
	 loss: 2.3718, MinusLogProbMetric: 2.3718, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 262: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3718 - MinusLogProbMetric: 2.3718 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-11 18:40:51.127 
Epoch 263/1000 
	 loss: 2.3710, MinusLogProbMetric: 2.3710, val_loss: 2.3650, val_MinusLogProbMetric: 2.3650

Epoch 263: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3710 - MinusLogProbMetric: 2.3710 - val_loss: 2.3650 - val_MinusLogProbMetric: 2.3650 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 264/1000
2023-09-11 18:41:03.023 
Epoch 264/1000 
	 loss: 2.3712, MinusLogProbMetric: 2.3712, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 264: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3712 - MinusLogProbMetric: 2.3712 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 265/1000
2023-09-11 18:41:14.791 
Epoch 265/1000 
	 loss: 2.3702, MinusLogProbMetric: 2.3702, val_loss: 2.3666, val_MinusLogProbMetric: 2.3666

Epoch 265: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3702 - MinusLogProbMetric: 2.3702 - val_loss: 2.3666 - val_MinusLogProbMetric: 2.3666 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 266/1000
2023-09-11 18:41:26.485 
Epoch 266/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.3662, val_MinusLogProbMetric: 2.3662

Epoch 266: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.3662 - val_MinusLogProbMetric: 2.3662 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 267/1000
2023-09-11 18:41:38.323 
Epoch 267/1000 
	 loss: 2.3715, MinusLogProbMetric: 2.3715, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 267: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3715 - MinusLogProbMetric: 2.3715 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 268/1000
2023-09-11 18:41:50.011 
Epoch 268/1000 
	 loss: 2.3704, MinusLogProbMetric: 2.3704, val_loss: 2.3643, val_MinusLogProbMetric: 2.3643

Epoch 268: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3704 - MinusLogProbMetric: 2.3704 - val_loss: 2.3643 - val_MinusLogProbMetric: 2.3643 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-11 18:42:01.681 
Epoch 269/1000 
	 loss: 2.3703, MinusLogProbMetric: 2.3703, val_loss: 2.3698, val_MinusLogProbMetric: 2.3698

Epoch 269: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3703 - MinusLogProbMetric: 2.3703 - val_loss: 2.3698 - val_MinusLogProbMetric: 2.3698 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 270/1000
2023-09-11 18:42:13.311 
Epoch 270/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 270: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 271/1000
2023-09-11 18:42:25.039 
Epoch 271/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.3662, val_MinusLogProbMetric: 2.3662

Epoch 271: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.3662 - val_MinusLogProbMetric: 2.3662 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-11 18:42:36.696 
Epoch 272/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 272: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 273/1000
2023-09-11 18:42:48.328 
Epoch 273/1000 
	 loss: 2.3708, MinusLogProbMetric: 2.3708, val_loss: 2.3652, val_MinusLogProbMetric: 2.3652

Epoch 273: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3708 - MinusLogProbMetric: 2.3708 - val_loss: 2.3652 - val_MinusLogProbMetric: 2.3652 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 274/1000
2023-09-11 18:43:00.280 
Epoch 274/1000 
	 loss: 2.3705, MinusLogProbMetric: 2.3705, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 274: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3705 - MinusLogProbMetric: 2.3705 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 275/1000
2023-09-11 18:43:11.993 
Epoch 275/1000 
	 loss: 2.3704, MinusLogProbMetric: 2.3704, val_loss: 2.3648, val_MinusLogProbMetric: 2.3648

Epoch 275: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3704 - MinusLogProbMetric: 2.3704 - val_loss: 2.3648 - val_MinusLogProbMetric: 2.3648 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 276/1000
2023-09-11 18:43:23.705 
Epoch 276/1000 
	 loss: 2.3721, MinusLogProbMetric: 2.3721, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 276: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3721 - MinusLogProbMetric: 2.3721 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 277/1000
2023-09-11 18:43:35.356 
Epoch 277/1000 
	 loss: 2.3715, MinusLogProbMetric: 2.3715, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 277: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3715 - MinusLogProbMetric: 2.3715 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 278/1000
2023-09-11 18:43:47.023 
Epoch 278/1000 
	 loss: 2.3703, MinusLogProbMetric: 2.3703, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 278: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3703 - MinusLogProbMetric: 2.3703 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 279/1000
2023-09-11 18:43:58.779 
Epoch 279/1000 
	 loss: 2.3709, MinusLogProbMetric: 2.3709, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 279: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3709 - MinusLogProbMetric: 2.3709 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 280/1000
2023-09-11 18:44:10.433 
Epoch 280/1000 
	 loss: 2.3707, MinusLogProbMetric: 2.3707, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 280: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3707 - MinusLogProbMetric: 2.3707 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 281/1000
2023-09-11 18:44:22.075 
Epoch 281/1000 
	 loss: 2.3716, MinusLogProbMetric: 2.3716, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 281: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3716 - MinusLogProbMetric: 2.3716 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 282/1000
2023-09-11 18:44:33.810 
Epoch 282/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.3726, val_MinusLogProbMetric: 2.3726

Epoch 282: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.3726 - val_MinusLogProbMetric: 2.3726 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 283/1000
2023-09-11 18:44:45.502 
Epoch 283/1000 
	 loss: 2.3702, MinusLogProbMetric: 2.3702, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 283: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3702 - MinusLogProbMetric: 2.3702 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-11 18:44:57.180 
Epoch 284/1000 
	 loss: 2.3720, MinusLogProbMetric: 2.3720, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 284: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3720 - MinusLogProbMetric: 2.3720 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 285/1000
2023-09-11 18:45:08.876 
Epoch 285/1000 
	 loss: 2.3705, MinusLogProbMetric: 2.3705, val_loss: 2.3650, val_MinusLogProbMetric: 2.3650

Epoch 285: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3705 - MinusLogProbMetric: 2.3705 - val_loss: 2.3650 - val_MinusLogProbMetric: 2.3650 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 286/1000
2023-09-11 18:45:20.631 
Epoch 286/1000 
	 loss: 2.3712, MinusLogProbMetric: 2.3712, val_loss: 2.3645, val_MinusLogProbMetric: 2.3645

Epoch 286: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3712 - MinusLogProbMetric: 2.3712 - val_loss: 2.3645 - val_MinusLogProbMetric: 2.3645 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 287/1000
2023-09-11 18:45:32.398 
Epoch 287/1000 
	 loss: 2.3716, MinusLogProbMetric: 2.3716, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 287: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3716 - MinusLogProbMetric: 2.3716 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 288/1000
2023-09-11 18:45:44.210 
Epoch 288/1000 
	 loss: 2.3698, MinusLogProbMetric: 2.3698, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 288: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3698 - MinusLogProbMetric: 2.3698 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 289/1000
2023-09-11 18:45:55.925 
Epoch 289/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.3675, val_MinusLogProbMetric: 2.3675

Epoch 289: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.3675 - val_MinusLogProbMetric: 2.3675 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 290/1000
2023-09-11 18:46:07.631 
Epoch 290/1000 
	 loss: 2.3702, MinusLogProbMetric: 2.3702, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 290: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3702 - MinusLogProbMetric: 2.3702 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 291/1000
2023-09-11 18:46:19.318 
Epoch 291/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.3682, val_MinusLogProbMetric: 2.3682

Epoch 291: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.3682 - val_MinusLogProbMetric: 2.3682 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 292/1000
2023-09-11 18:46:31.048 
Epoch 292/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 292: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 293/1000
2023-09-11 18:46:42.821 
Epoch 293/1000 
	 loss: 2.3701, MinusLogProbMetric: 2.3701, val_loss: 2.3655, val_MinusLogProbMetric: 2.3655

Epoch 293: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3701 - MinusLogProbMetric: 2.3701 - val_loss: 2.3655 - val_MinusLogProbMetric: 2.3655 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 294/1000
2023-09-11 18:46:54.608 
Epoch 294/1000 
	 loss: 2.3710, MinusLogProbMetric: 2.3710, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 294: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3710 - MinusLogProbMetric: 2.3710 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 295/1000
2023-09-11 18:47:06.341 
Epoch 295/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 295: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 296/1000
2023-09-11 18:47:18.013 
Epoch 296/1000 
	 loss: 2.3709, MinusLogProbMetric: 2.3709, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 296: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3709 - MinusLogProbMetric: 2.3709 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 297/1000
2023-09-11 18:47:29.750 
Epoch 297/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.3654, val_MinusLogProbMetric: 2.3654

Epoch 297: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.3654 - val_MinusLogProbMetric: 2.3654 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 298/1000
2023-09-11 18:47:41.433 
Epoch 298/1000 
	 loss: 2.3715, MinusLogProbMetric: 2.3715, val_loss: 2.3645, val_MinusLogProbMetric: 2.3645

Epoch 298: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3715 - MinusLogProbMetric: 2.3715 - val_loss: 2.3645 - val_MinusLogProbMetric: 2.3645 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 299/1000
2023-09-11 18:47:53.113 
Epoch 299/1000 
	 loss: 2.3705, MinusLogProbMetric: 2.3705, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 299: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3705 - MinusLogProbMetric: 2.3705 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 300/1000
2023-09-11 18:48:04.724 
Epoch 300/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 300: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 301/1000
2023-09-11 18:48:16.609 
Epoch 301/1000 
	 loss: 2.3708, MinusLogProbMetric: 2.3708, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 301: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3708 - MinusLogProbMetric: 2.3708 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 302/1000
2023-09-11 18:48:28.319 
Epoch 302/1000 
	 loss: 2.3705, MinusLogProbMetric: 2.3705, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 302: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3705 - MinusLogProbMetric: 2.3705 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 303/1000
2023-09-11 18:48:40.041 
Epoch 303/1000 
	 loss: 2.3697, MinusLogProbMetric: 2.3697, val_loss: 2.3668, val_MinusLogProbMetric: 2.3668

Epoch 303: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3697 - MinusLogProbMetric: 2.3697 - val_loss: 2.3668 - val_MinusLogProbMetric: 2.3668 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 304/1000
2023-09-11 18:48:51.926 
Epoch 304/1000 
	 loss: 2.3701, MinusLogProbMetric: 2.3701, val_loss: 2.3657, val_MinusLogProbMetric: 2.3657

Epoch 304: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3701 - MinusLogProbMetric: 2.3701 - val_loss: 2.3657 - val_MinusLogProbMetric: 2.3657 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 305/1000
2023-09-11 18:49:03.615 
Epoch 305/1000 
	 loss: 2.3705, MinusLogProbMetric: 2.3705, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 305: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3705 - MinusLogProbMetric: 2.3705 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 306/1000
2023-09-11 18:49:15.265 
Epoch 306/1000 
	 loss: 2.3703, MinusLogProbMetric: 2.3703, val_loss: 2.3649, val_MinusLogProbMetric: 2.3649

Epoch 306: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3703 - MinusLogProbMetric: 2.3703 - val_loss: 2.3649 - val_MinusLogProbMetric: 2.3649 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 307/1000
2023-09-11 18:49:26.843 
Epoch 307/1000 
	 loss: 2.3702, MinusLogProbMetric: 2.3702, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 307: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3702 - MinusLogProbMetric: 2.3702 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 308/1000
2023-09-11 18:49:38.540 
Epoch 308/1000 
	 loss: 2.3710, MinusLogProbMetric: 2.3710, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 308: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3710 - MinusLogProbMetric: 2.3710 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 309/1000
2023-09-11 18:49:50.248 
Epoch 309/1000 
	 loss: 2.3705, MinusLogProbMetric: 2.3705, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 309: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3705 - MinusLogProbMetric: 2.3705 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 310/1000
2023-09-11 18:50:02.106 
Epoch 310/1000 
	 loss: 2.3687, MinusLogProbMetric: 2.3687, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 310: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3687 - MinusLogProbMetric: 2.3687 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 311/1000
2023-09-11 18:50:13.834 
Epoch 311/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 311: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 312/1000
2023-09-11 18:50:25.621 
Epoch 312/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 312: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 313/1000
2023-09-11 18:50:37.374 
Epoch 313/1000 
	 loss: 2.3682, MinusLogProbMetric: 2.3682, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 313: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3682 - MinusLogProbMetric: 2.3682 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 314/1000
2023-09-11 18:50:49.020 
Epoch 314/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 314: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 315/1000
2023-09-11 18:51:00.789 
Epoch 315/1000 
	 loss: 2.3682, MinusLogProbMetric: 2.3682, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 315: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3682 - MinusLogProbMetric: 2.3682 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-11 18:51:12.430 
Epoch 316/1000 
	 loss: 2.3675, MinusLogProbMetric: 2.3675, val_loss: 2.3644, val_MinusLogProbMetric: 2.3644

Epoch 316: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3675 - MinusLogProbMetric: 2.3675 - val_loss: 2.3644 - val_MinusLogProbMetric: 2.3644 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 317/1000
2023-09-11 18:51:24.078 
Epoch 317/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 317: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 318/1000
2023-09-11 18:51:35.807 
Epoch 318/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3648, val_MinusLogProbMetric: 2.3648

Epoch 318: val_loss did not improve from 2.36215
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3648 - val_MinusLogProbMetric: 2.3648 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 319/1000
2023-09-11 18:51:47.546 
Epoch 319/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 319: val_loss improved from 2.36215 to 2.36148, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 320/1000
2023-09-11 18:51:59.297 
Epoch 320/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 320: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 321/1000
2023-09-11 18:52:10.987 
Epoch 321/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 321: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 322/1000
2023-09-11 18:52:22.802 
Epoch 322/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 322: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 323/1000
2023-09-11 18:52:34.610 
Epoch 323/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 323: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 324/1000
2023-09-11 18:52:46.415 
Epoch 324/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 324: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 325/1000
2023-09-11 18:52:57.995 
Epoch 325/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 325: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 326/1000
2023-09-11 18:53:09.744 
Epoch 326/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3636, val_MinusLogProbMetric: 2.3636

Epoch 326: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3636 - val_MinusLogProbMetric: 2.3636 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-11 18:53:21.431 
Epoch 327/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 327: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 328/1000
2023-09-11 18:53:32.982 
Epoch 328/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 328: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 329/1000
2023-09-11 18:53:44.716 
Epoch 329/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 329: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 330/1000
2023-09-11 18:53:56.483 
Epoch 330/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 330: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 331/1000
2023-09-11 18:54:08.194 
Epoch 331/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 331: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 332/1000
2023-09-11 18:54:20.047 
Epoch 332/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 332: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 333/1000
2023-09-11 18:54:31.783 
Epoch 333/1000 
	 loss: 2.3675, MinusLogProbMetric: 2.3675, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 333: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3675 - MinusLogProbMetric: 2.3675 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 334/1000
2023-09-11 18:54:43.504 
Epoch 334/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 334: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 335/1000
2023-09-11 18:54:55.373 
Epoch 335/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3650, val_MinusLogProbMetric: 2.3650

Epoch 335: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3650 - val_MinusLogProbMetric: 2.3650 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 336/1000
2023-09-11 18:55:07.272 
Epoch 336/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 336: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 337/1000
2023-09-11 18:55:18.965 
Epoch 337/1000 
	 loss: 2.3683, MinusLogProbMetric: 2.3683, val_loss: 2.3651, val_MinusLogProbMetric: 2.3651

Epoch 337: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3683 - MinusLogProbMetric: 2.3683 - val_loss: 2.3651 - val_MinusLogProbMetric: 2.3651 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 338/1000
2023-09-11 18:55:30.671 
Epoch 338/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 338: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 339/1000
2023-09-11 18:55:42.482 
Epoch 339/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 339: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 340/1000
2023-09-11 18:55:54.251 
Epoch 340/1000 
	 loss: 2.3675, MinusLogProbMetric: 2.3675, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 340: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3675 - MinusLogProbMetric: 2.3675 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 341/1000
2023-09-11 18:56:05.931 
Epoch 341/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 341: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 342/1000
2023-09-11 18:56:17.614 
Epoch 342/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 342: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-11 18:56:29.366 
Epoch 343/1000 
	 loss: 2.3682, MinusLogProbMetric: 2.3682, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 343: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3682 - MinusLogProbMetric: 2.3682 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 344/1000
2023-09-11 18:56:41.162 
Epoch 344/1000 
	 loss: 2.3680, MinusLogProbMetric: 2.3680, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 344: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3680 - MinusLogProbMetric: 2.3680 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 345/1000
2023-09-11 18:56:52.870 
Epoch 345/1000 
	 loss: 2.3674, MinusLogProbMetric: 2.3674, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 345: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3674 - MinusLogProbMetric: 2.3674 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 346/1000
2023-09-11 18:57:04.661 
Epoch 346/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 346: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 347/1000
2023-09-11 18:57:16.514 
Epoch 347/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3720, val_MinusLogProbMetric: 2.3720

Epoch 347: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3720 - val_MinusLogProbMetric: 2.3720 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 348/1000
2023-09-11 18:57:28.260 
Epoch 348/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 348: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 349/1000
2023-09-11 18:57:40.076 
Epoch 349/1000 
	 loss: 2.3675, MinusLogProbMetric: 2.3675, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 349: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3675 - MinusLogProbMetric: 2.3675 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 350/1000
2023-09-11 18:57:51.897 
Epoch 350/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3683, val_MinusLogProbMetric: 2.3683

Epoch 350: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3683 - val_MinusLogProbMetric: 2.3683 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 351/1000
2023-09-11 18:58:03.654 
Epoch 351/1000 
	 loss: 2.3680, MinusLogProbMetric: 2.3680, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 351: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3680 - MinusLogProbMetric: 2.3680 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 352/1000
2023-09-11 18:58:15.348 
Epoch 352/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 352: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 353/1000
2023-09-11 18:58:26.963 
Epoch 353/1000 
	 loss: 2.3680, MinusLogProbMetric: 2.3680, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 353: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3680 - MinusLogProbMetric: 2.3680 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 354/1000
2023-09-11 18:58:38.725 
Epoch 354/1000 
	 loss: 2.3673, MinusLogProbMetric: 2.3673, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 354: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3673 - MinusLogProbMetric: 2.3673 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 355/1000
2023-09-11 18:58:50.468 
Epoch 355/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 355: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 356/1000
2023-09-11 18:59:02.096 
Epoch 356/1000 
	 loss: 2.3680, MinusLogProbMetric: 2.3680, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 356: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3680 - MinusLogProbMetric: 2.3680 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 357/1000
2023-09-11 18:59:13.751 
Epoch 357/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 357: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 358/1000
2023-09-11 18:59:25.563 
Epoch 358/1000 
	 loss: 2.3673, MinusLogProbMetric: 2.3673, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 358: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3673 - MinusLogProbMetric: 2.3673 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 359/1000
2023-09-11 18:59:37.165 
Epoch 359/1000 
	 loss: 2.3674, MinusLogProbMetric: 2.3674, val_loss: 2.3657, val_MinusLogProbMetric: 2.3657

Epoch 359: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3674 - MinusLogProbMetric: 2.3674 - val_loss: 2.3657 - val_MinusLogProbMetric: 2.3657 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 360/1000
2023-09-11 18:59:48.741 
Epoch 360/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 360: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 361/1000
2023-09-11 19:00:00.417 
Epoch 361/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 361: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 362/1000
2023-09-11 19:00:12.111 
Epoch 362/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 362: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 363/1000
2023-09-11 19:00:23.837 
Epoch 363/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 363: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 364/1000
2023-09-11 19:00:35.513 
Epoch 364/1000 
	 loss: 2.3673, MinusLogProbMetric: 2.3673, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 364: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3673 - MinusLogProbMetric: 2.3673 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 365/1000
2023-09-11 19:00:47.228 
Epoch 365/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 365: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 366/1000
2023-09-11 19:00:58.943 
Epoch 366/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 366: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 367/1000
2023-09-11 19:01:10.759 
Epoch 367/1000 
	 loss: 2.3687, MinusLogProbMetric: 2.3687, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 367: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3687 - MinusLogProbMetric: 2.3687 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 368/1000
2023-09-11 19:01:22.403 
Epoch 368/1000 
	 loss: 2.3674, MinusLogProbMetric: 2.3674, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 368: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3674 - MinusLogProbMetric: 2.3674 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 369/1000
2023-09-11 19:01:34.067 
Epoch 369/1000 
	 loss: 2.3680, MinusLogProbMetric: 2.3680, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 369: val_loss did not improve from 2.36148
196/196 - 12s - loss: 2.3680 - MinusLogProbMetric: 2.3680 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 370/1000
2023-09-11 19:01:45.719 
Epoch 370/1000 
	 loss: 2.3666, MinusLogProbMetric: 2.3666, val_loss: 2.3610, val_MinusLogProbMetric: 2.3610

Epoch 370: val_loss improved from 2.36148 to 2.36103, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_16/weights/best_weights.h5
196/196 - 12s - loss: 2.3666 - MinusLogProbMetric: 2.3666 - val_loss: 2.3610 - val_MinusLogProbMetric: 2.3610 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 371/1000
2023-09-11 19:01:57.711 
Epoch 371/1000 
	 loss: 2.3665, MinusLogProbMetric: 2.3665, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 371: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3665 - MinusLogProbMetric: 2.3665 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 372/1000
2023-09-11 19:02:09.538 
Epoch 372/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 372: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 373/1000
2023-09-11 19:02:21.511 
Epoch 373/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 373: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 374/1000
2023-09-11 19:02:33.287 
Epoch 374/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 374: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 375/1000
2023-09-11 19:02:44.916 
Epoch 375/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 375: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 376/1000
2023-09-11 19:02:56.636 
Epoch 376/1000 
	 loss: 2.3665, MinusLogProbMetric: 2.3665, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 376: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3665 - MinusLogProbMetric: 2.3665 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-11 19:03:08.307 
Epoch 377/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 377: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 378/1000
2023-09-11 19:03:20.079 
Epoch 378/1000 
	 loss: 2.3667, MinusLogProbMetric: 2.3667, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 378: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3667 - MinusLogProbMetric: 2.3667 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 379/1000
2023-09-11 19:03:31.745 
Epoch 379/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 379: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-11 19:03:43.367 
Epoch 380/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 380: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 381/1000
2023-09-11 19:03:55.111 
Epoch 381/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 381: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 382/1000
2023-09-11 19:04:06.830 
Epoch 382/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 382: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 383/1000
2023-09-11 19:04:18.562 
Epoch 383/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 383: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 384/1000
2023-09-11 19:04:30.234 
Epoch 384/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 384: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 385/1000
2023-09-11 19:04:42.013 
Epoch 385/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 385: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 386/1000
2023-09-11 19:04:53.898 
Epoch 386/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 386: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 387/1000
2023-09-11 19:05:05.558 
Epoch 387/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 387: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 388/1000
2023-09-11 19:05:17.412 
Epoch 388/1000 
	 loss: 2.3665, MinusLogProbMetric: 2.3665, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 388: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3665 - MinusLogProbMetric: 2.3665 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 389/1000
2023-09-11 19:05:29.307 
Epoch 389/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 389: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 390/1000
2023-09-11 19:05:41.183 
Epoch 390/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 390: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 391/1000
2023-09-11 19:05:52.877 
Epoch 391/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 391: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 392/1000
2023-09-11 19:06:04.530 
Epoch 392/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 392: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 393/1000
2023-09-11 19:06:16.302 
Epoch 393/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 393: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 394/1000
2023-09-11 19:06:28.040 
Epoch 394/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 394: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 395/1000
2023-09-11 19:06:39.794 
Epoch 395/1000 
	 loss: 2.3660, MinusLogProbMetric: 2.3660, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 395: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3660 - MinusLogProbMetric: 2.3660 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 396/1000
2023-09-11 19:06:51.366 
Epoch 396/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 396: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 397/1000
2023-09-11 19:07:03.229 
Epoch 397/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 397: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 398/1000
2023-09-11 19:07:14.912 
Epoch 398/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 398: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 399/1000
2023-09-11 19:07:26.518 
Epoch 399/1000 
	 loss: 2.3660, MinusLogProbMetric: 2.3660, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 399: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3660 - MinusLogProbMetric: 2.3660 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 400/1000
2023-09-11 19:07:38.234 
Epoch 400/1000 
	 loss: 2.3661, MinusLogProbMetric: 2.3661, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 400: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3661 - MinusLogProbMetric: 2.3661 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 401/1000
2023-09-11 19:07:49.906 
Epoch 401/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 401: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 402/1000
2023-09-11 19:08:01.697 
Epoch 402/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 402: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 403/1000
2023-09-11 19:08:13.611 
Epoch 403/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 403: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 404/1000
2023-09-11 19:08:25.335 
Epoch 404/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 404: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 405/1000
2023-09-11 19:08:37.090 
Epoch 405/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 405: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 406/1000
2023-09-11 19:08:48.817 
Epoch 406/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 406: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 407/1000
2023-09-11 19:09:00.530 
Epoch 407/1000 
	 loss: 2.3661, MinusLogProbMetric: 2.3661, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 407: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3661 - MinusLogProbMetric: 2.3661 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 408/1000
2023-09-11 19:09:12.272 
Epoch 408/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 408: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 409/1000
2023-09-11 19:09:23.993 
Epoch 409/1000 
	 loss: 2.3661, MinusLogProbMetric: 2.3661, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 409: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3661 - MinusLogProbMetric: 2.3661 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 410/1000
2023-09-11 19:09:35.851 
Epoch 410/1000 
	 loss: 2.3665, MinusLogProbMetric: 2.3665, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 410: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3665 - MinusLogProbMetric: 2.3665 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 411/1000
2023-09-11 19:09:47.649 
Epoch 411/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 411: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 412/1000
2023-09-11 19:09:59.301 
Epoch 412/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 412: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 413/1000
2023-09-11 19:10:10.906 
Epoch 413/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 413: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 414/1000
2023-09-11 19:10:22.613 
Epoch 414/1000 
	 loss: 2.3661, MinusLogProbMetric: 2.3661, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 414: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3661 - MinusLogProbMetric: 2.3661 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 415/1000
2023-09-11 19:10:34.184 
Epoch 415/1000 
	 loss: 2.3660, MinusLogProbMetric: 2.3660, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 415: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3660 - MinusLogProbMetric: 2.3660 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 416/1000
2023-09-11 19:10:45.841 
Epoch 416/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 416: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 417/1000
2023-09-11 19:10:57.517 
Epoch 417/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 417: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-11 19:11:09.364 
Epoch 418/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 418: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 419/1000
2023-09-11 19:11:21.101 
Epoch 419/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 419: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 420/1000
2023-09-11 19:11:32.779 
Epoch 420/1000 
	 loss: 2.3661, MinusLogProbMetric: 2.3661, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 420: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3661 - MinusLogProbMetric: 2.3661 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 421/1000
2023-09-11 19:11:44.465 
Epoch 421/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 421: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 422/1000
2023-09-11 19:11:56.097 
Epoch 422/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 422: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 423/1000
2023-09-11 19:12:07.343 
Epoch 423/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 423: val_loss did not improve from 2.36103
196/196 - 11s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 3.1250e-05 - 11s/epoch - 57ms/step
Epoch 424/1000
2023-09-11 19:12:18.508 
Epoch 424/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 424: val_loss did not improve from 2.36103
196/196 - 11s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 11s/epoch - 57ms/step
Epoch 425/1000
2023-09-11 19:12:29.007 
Epoch 425/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 425: val_loss did not improve from 2.36103
196/196 - 10s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 3.1250e-05 - 10s/epoch - 54ms/step
Epoch 426/1000
2023-09-11 19:12:40.603 
Epoch 426/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 426: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 427/1000
2023-09-11 19:12:52.178 
Epoch 427/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 427: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 428/1000
2023-09-11 19:13:03.759 
Epoch 428/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 428: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 429/1000
2023-09-11 19:13:15.482 
Epoch 429/1000 
	 loss: 2.3657, MinusLogProbMetric: 2.3657, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 429: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3657 - MinusLogProbMetric: 2.3657 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 430/1000
2023-09-11 19:13:27.190 
Epoch 430/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 430: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 431/1000
2023-09-11 19:13:38.859 
Epoch 431/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 431: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 432/1000
2023-09-11 19:13:50.578 
Epoch 432/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 432: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 433/1000
2023-09-11 19:14:02.304 
Epoch 433/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 433: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 434/1000
2023-09-11 19:14:14.166 
Epoch 434/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 434: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 435/1000
2023-09-11 19:14:25.889 
Epoch 435/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 435: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 436/1000
2023-09-11 19:14:37.458 
Epoch 436/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 436: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 437/1000
2023-09-11 19:14:49.217 
Epoch 437/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 437: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 438/1000
2023-09-11 19:15:00.958 
Epoch 438/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 438: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 439/1000
2023-09-11 19:15:12.669 
Epoch 439/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 439: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-11 19:15:24.406 
Epoch 440/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 440: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 441/1000
2023-09-11 19:15:36.194 
Epoch 441/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 441: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 442/1000
2023-09-11 19:15:47.931 
Epoch 442/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 442: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 443/1000
2023-09-11 19:15:59.657 
Epoch 443/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 443: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 444/1000
2023-09-11 19:16:11.463 
Epoch 444/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 444: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 445/1000
2023-09-11 19:16:23.160 
Epoch 445/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 445: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 446/1000
2023-09-11 19:16:34.998 
Epoch 446/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 446: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 447/1000
2023-09-11 19:16:46.685 
Epoch 447/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 447: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 448/1000
2023-09-11 19:16:58.557 
Epoch 448/1000 
	 loss: 2.3657, MinusLogProbMetric: 2.3657, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 448: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3657 - MinusLogProbMetric: 2.3657 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 449/1000
2023-09-11 19:17:10.374 
Epoch 449/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 449: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 450/1000
2023-09-11 19:17:22.197 
Epoch 450/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 450: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 451/1000
2023-09-11 19:17:33.976 
Epoch 451/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 451: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 452/1000
2023-09-11 19:17:45.487 
Epoch 452/1000 
	 loss: 2.3657, MinusLogProbMetric: 2.3657, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 452: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3657 - MinusLogProbMetric: 2.3657 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 453/1000
2023-09-11 19:17:56.878 
Epoch 453/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 453: val_loss did not improve from 2.36103
196/196 - 11s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 11s/epoch - 58ms/step
Epoch 454/1000
2023-09-11 19:18:07.126 
Epoch 454/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 454: val_loss did not improve from 2.36103
196/196 - 10s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 3.1250e-05 - 10s/epoch - 52ms/step
Epoch 455/1000
2023-09-11 19:18:18.739 
Epoch 455/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 455: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 456/1000
2023-09-11 19:18:30.395 
Epoch 456/1000 
	 loss: 2.3657, MinusLogProbMetric: 2.3657, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 456: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3657 - MinusLogProbMetric: 2.3657 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 457/1000
2023-09-11 19:18:42.192 
Epoch 457/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3619, val_MinusLogProbMetric: 2.3619

Epoch 457: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3619 - val_MinusLogProbMetric: 2.3619 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 458/1000
2023-09-11 19:18:53.907 
Epoch 458/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 458: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 459/1000
2023-09-11 19:19:05.569 
Epoch 459/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 459: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 460/1000
2023-09-11 19:19:17.353 
Epoch 460/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 460: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 461/1000
2023-09-11 19:19:28.969 
Epoch 461/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 461: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 462/1000
2023-09-11 19:19:40.664 
Epoch 462/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 462: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 463/1000
2023-09-11 19:19:52.310 
Epoch 463/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 463: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 464/1000
2023-09-11 19:20:03.934 
Epoch 464/1000 
	 loss: 2.3656, MinusLogProbMetric: 2.3656, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 464: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3656 - MinusLogProbMetric: 2.3656 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 465/1000
2023-09-11 19:20:15.672 
Epoch 465/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 465: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 466/1000
2023-09-11 19:20:27.388 
Epoch 466/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 466: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 467/1000
2023-09-11 19:20:39.004 
Epoch 467/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 467: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 468/1000
2023-09-11 19:20:50.687 
Epoch 468/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 468: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 469/1000
2023-09-11 19:21:02.429 
Epoch 469/1000 
	 loss: 2.3654, MinusLogProbMetric: 2.3654, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 469: val_loss did not improve from 2.36103
196/196 - 12s - loss: 2.3654 - MinusLogProbMetric: 2.3654 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 470/1000
2023-09-11 19:21:14.164 
Epoch 470/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 470: val_loss did not improve from 2.36103
Restoring model weights from the end of the best epoch: 370.
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 470: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.334872568957508 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.256569350953214 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.7386253060540184 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.0034680579556152 seconds.
Training succeeded with seed 440.
Model trained in 5534.44 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 16.61 s.
Plots done in 2.41 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 19.02 s.
===========
Run 16/360 done in 5554.65 s.
===========

Directory ../../results/MsplineN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

===========
Generating train data for run 20.
===========
Train data generated in 0.26 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_20/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_20/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.2548594, 7.0946026, 4.7615414, 9.43823  ],
       [4.232356 , 6.5302997, 4.4809017, 9.592666 ],
       [4.2134495, 7.179828 , 4.533561 , 8.779418 ],
       ...,
       [4.240699 , 7.4401965, 5.062128 , 9.433647 ],
       [4.2825274, 5.9462013, 2.819703 , 9.018203 ],
       [8.961808 , 3.052795 , 7.455145 , 5.2543044]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_20/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_20
self.data_kwargs: {'seed': 520}
self.x_data: [[ 4.2441406  6.7530947  3.3826632 10.332189 ]
 [10.195218   2.5649576  7.9873266  5.103083 ]
 [ 9.97571    4.4703245  8.199758   5.5030446]
 ...
 [ 4.2466564  8.298781   5.5362053 10.0680065]
 [ 4.262163   5.731845   3.7121477  8.4649315]
 [11.055306   5.1953883  7.2777805  4.4987473]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 4)]               0         
                                                                 
 log_prob_layer_2 (LogProbLa  (None,)                  337688    
 yer)                                                            
                                                                 
=================================================================
Total params: 337,688
Trainable params: 337,688
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_2/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_2'")
self.model: <keras.engine.functional.Functional object at 0x7fc7bc3aad10>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc7bc1cd780>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc7bc1cd780>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc7bc2a4190>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc7b4603d90>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc7b4640340>, <keras.callbacks.ModelCheckpoint object at 0x7fc7b4640400>, <keras.callbacks.EarlyStopping object at 0x7fc7b4640670>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc7b46406a0>, <keras.callbacks.TerminateOnNaN object at 0x7fc7b46402e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.2548594, 7.0946026, 4.7615414, 9.43823  ],
       [4.232356 , 6.5302997, 4.4809017, 9.592666 ],
       [4.2134495, 7.179828 , 4.533561 , 8.779418 ],
       ...,
       [4.240699 , 7.4401965, 5.062128 , 9.433647 ],
       [4.2825274, 5.9462013, 2.819703 , 9.018203 ],
       [8.961808 , 3.052795 , 7.455145 , 5.2543044]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_20/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 20/360 with hyperparameters:
timestamp = 2023-09-11 19:21:34.553052
ndims = 4
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 337688
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.2441406  6.7530947  3.3826632 10.332189 ]
Epoch 1/1000
2023-09-11 19:22:05.182 
Epoch 1/1000 
	 loss: 6.4161, MinusLogProbMetric: 6.4161, val_loss: 4.3707, val_MinusLogProbMetric: 4.3707

Epoch 1: val_loss improved from inf to 4.37068, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 31s - loss: 6.4161 - MinusLogProbMetric: 6.4161 - val_loss: 4.3707 - val_MinusLogProbMetric: 4.3707 - lr: 0.0010 - 31s/epoch - 156ms/step
Epoch 2/1000
2023-09-11 19:22:17.051 
Epoch 2/1000 
	 loss: 3.0453, MinusLogProbMetric: 3.0453, val_loss: 3.1784, val_MinusLogProbMetric: 3.1784

Epoch 2: val_loss improved from 4.37068 to 3.17842, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 3.0453 - MinusLogProbMetric: 3.0453 - val_loss: 3.1784 - val_MinusLogProbMetric: 3.1784 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 3/1000
2023-09-11 19:22:28.783 
Epoch 3/1000 
	 loss: 2.7934, MinusLogProbMetric: 2.7934, val_loss: 2.8770, val_MinusLogProbMetric: 2.8770

Epoch 3: val_loss improved from 3.17842 to 2.87698, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.7934 - MinusLogProbMetric: 2.7934 - val_loss: 2.8770 - val_MinusLogProbMetric: 2.8770 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-11 19:22:40.558 
Epoch 4/1000 
	 loss: 2.6795, MinusLogProbMetric: 2.6795, val_loss: 2.9264, val_MinusLogProbMetric: 2.9264

Epoch 4: val_loss did not improve from 2.87698
196/196 - 12s - loss: 2.6795 - MinusLogProbMetric: 2.6795 - val_loss: 2.9264 - val_MinusLogProbMetric: 2.9264 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 5/1000
2023-09-11 19:22:52.342 
Epoch 5/1000 
	 loss: 2.6543, MinusLogProbMetric: 2.6543, val_loss: 2.5338, val_MinusLogProbMetric: 2.5338

Epoch 5: val_loss improved from 2.87698 to 2.53383, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.6543 - MinusLogProbMetric: 2.6543 - val_loss: 2.5338 - val_MinusLogProbMetric: 2.5338 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 6/1000
2023-09-11 19:23:04.177 
Epoch 6/1000 
	 loss: 2.5766, MinusLogProbMetric: 2.5766, val_loss: 2.6375, val_MinusLogProbMetric: 2.6375

Epoch 6: val_loss did not improve from 2.53383
196/196 - 12s - loss: 2.5766 - MinusLogProbMetric: 2.5766 - val_loss: 2.6375 - val_MinusLogProbMetric: 2.6375 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-11 19:23:15.727 
Epoch 7/1000 
	 loss: 2.5602, MinusLogProbMetric: 2.5602, val_loss: 2.5555, val_MinusLogProbMetric: 2.5555

Epoch 7: val_loss did not improve from 2.53383
196/196 - 12s - loss: 2.5602 - MinusLogProbMetric: 2.5602 - val_loss: 2.5555 - val_MinusLogProbMetric: 2.5555 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 8/1000
2023-09-11 19:23:27.316 
Epoch 8/1000 
	 loss: 2.5480, MinusLogProbMetric: 2.5480, val_loss: 2.5791, val_MinusLogProbMetric: 2.5791

Epoch 8: val_loss did not improve from 2.53383
196/196 - 12s - loss: 2.5480 - MinusLogProbMetric: 2.5480 - val_loss: 2.5791 - val_MinusLogProbMetric: 2.5791 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 9/1000
2023-09-11 19:23:38.880 
Epoch 9/1000 
	 loss: 2.5291, MinusLogProbMetric: 2.5291, val_loss: 2.5273, val_MinusLogProbMetric: 2.5273

Epoch 9: val_loss improved from 2.53383 to 2.52726, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.5291 - MinusLogProbMetric: 2.5291 - val_loss: 2.5273 - val_MinusLogProbMetric: 2.5273 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 10/1000
2023-09-11 19:23:50.670 
Epoch 10/1000 
	 loss: 2.5101, MinusLogProbMetric: 2.5101, val_loss: 2.5730, val_MinusLogProbMetric: 2.5730

Epoch 10: val_loss did not improve from 2.52726
196/196 - 12s - loss: 2.5101 - MinusLogProbMetric: 2.5101 - val_loss: 2.5730 - val_MinusLogProbMetric: 2.5730 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-11 19:24:02.301 
Epoch 11/1000 
	 loss: 2.5045, MinusLogProbMetric: 2.5045, val_loss: 2.4835, val_MinusLogProbMetric: 2.4835

Epoch 11: val_loss improved from 2.52726 to 2.48352, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.5045 - MinusLogProbMetric: 2.5045 - val_loss: 2.4835 - val_MinusLogProbMetric: 2.4835 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-11 19:24:14.193 
Epoch 12/1000 
	 loss: 2.4947, MinusLogProbMetric: 2.4947, val_loss: 2.4921, val_MinusLogProbMetric: 2.4921

Epoch 12: val_loss did not improve from 2.48352
196/196 - 12s - loss: 2.4947 - MinusLogProbMetric: 2.4947 - val_loss: 2.4921 - val_MinusLogProbMetric: 2.4921 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-11 19:24:25.795 
Epoch 13/1000 
	 loss: 2.4771, MinusLogProbMetric: 2.4771, val_loss: 2.6077, val_MinusLogProbMetric: 2.6077

Epoch 13: val_loss did not improve from 2.48352
196/196 - 12s - loss: 2.4771 - MinusLogProbMetric: 2.4771 - val_loss: 2.6077 - val_MinusLogProbMetric: 2.6077 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 14/1000
2023-09-11 19:24:37.463 
Epoch 14/1000 
	 loss: 2.4673, MinusLogProbMetric: 2.4673, val_loss: 2.5112, val_MinusLogProbMetric: 2.5112

Epoch 14: val_loss did not improve from 2.48352
196/196 - 12s - loss: 2.4673 - MinusLogProbMetric: 2.4673 - val_loss: 2.5112 - val_MinusLogProbMetric: 2.5112 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-11 19:24:49.070 
Epoch 15/1000 
	 loss: 2.4712, MinusLogProbMetric: 2.4712, val_loss: 2.4494, val_MinusLogProbMetric: 2.4494

Epoch 15: val_loss improved from 2.48352 to 2.44941, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4712 - MinusLogProbMetric: 2.4712 - val_loss: 2.4494 - val_MinusLogProbMetric: 2.4494 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-11 19:25:00.876 
Epoch 16/1000 
	 loss: 2.4609, MinusLogProbMetric: 2.4609, val_loss: 2.4475, val_MinusLogProbMetric: 2.4475

Epoch 16: val_loss improved from 2.44941 to 2.44747, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4609 - MinusLogProbMetric: 2.4609 - val_loss: 2.4475 - val_MinusLogProbMetric: 2.4475 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-11 19:25:12.594 
Epoch 17/1000 
	 loss: 2.4539, MinusLogProbMetric: 2.4539, val_loss: 2.5161, val_MinusLogProbMetric: 2.5161

Epoch 17: val_loss did not improve from 2.44747
196/196 - 12s - loss: 2.4539 - MinusLogProbMetric: 2.4539 - val_loss: 2.5161 - val_MinusLogProbMetric: 2.5161 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 18/1000
2023-09-11 19:25:24.331 
Epoch 18/1000 
	 loss: 2.4616, MinusLogProbMetric: 2.4616, val_loss: 2.4447, val_MinusLogProbMetric: 2.4447

Epoch 18: val_loss improved from 2.44747 to 2.44470, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4616 - MinusLogProbMetric: 2.4616 - val_loss: 2.4447 - val_MinusLogProbMetric: 2.4447 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-11 19:25:36.031 
Epoch 19/1000 
	 loss: 2.4420, MinusLogProbMetric: 2.4420, val_loss: 2.5244, val_MinusLogProbMetric: 2.5244

Epoch 19: val_loss did not improve from 2.44470
196/196 - 12s - loss: 2.4420 - MinusLogProbMetric: 2.4420 - val_loss: 2.5244 - val_MinusLogProbMetric: 2.5244 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 20/1000
2023-09-11 19:25:47.581 
Epoch 20/1000 
	 loss: 2.4606, MinusLogProbMetric: 2.4606, val_loss: 2.4423, val_MinusLogProbMetric: 2.4423

Epoch 20: val_loss improved from 2.44470 to 2.44232, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4606 - MinusLogProbMetric: 2.4606 - val_loss: 2.4423 - val_MinusLogProbMetric: 2.4423 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-11 19:25:59.420 
Epoch 21/1000 
	 loss: 2.4272, MinusLogProbMetric: 2.4272, val_loss: 2.4158, val_MinusLogProbMetric: 2.4158

Epoch 21: val_loss improved from 2.44232 to 2.41578, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4272 - MinusLogProbMetric: 2.4272 - val_loss: 2.4158 - val_MinusLogProbMetric: 2.4158 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 22/1000
2023-09-11 19:26:11.351 
Epoch 22/1000 
	 loss: 2.4266, MinusLogProbMetric: 2.4266, val_loss: 2.4042, val_MinusLogProbMetric: 2.4042

Epoch 22: val_loss improved from 2.41578 to 2.40418, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4266 - MinusLogProbMetric: 2.4266 - val_loss: 2.4042 - val_MinusLogProbMetric: 2.4042 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 23/1000
2023-09-11 19:26:23.243 
Epoch 23/1000 
	 loss: 2.4482, MinusLogProbMetric: 2.4482, val_loss: 2.5905, val_MinusLogProbMetric: 2.5905

Epoch 23: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4482 - MinusLogProbMetric: 2.4482 - val_loss: 2.5905 - val_MinusLogProbMetric: 2.5905 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-11 19:26:34.855 
Epoch 24/1000 
	 loss: 2.4290, MinusLogProbMetric: 2.4290, val_loss: 2.4312, val_MinusLogProbMetric: 2.4312

Epoch 24: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4290 - MinusLogProbMetric: 2.4290 - val_loss: 2.4312 - val_MinusLogProbMetric: 2.4312 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 25/1000
2023-09-11 19:26:46.551 
Epoch 25/1000 
	 loss: 2.4334, MinusLogProbMetric: 2.4334, val_loss: 2.4623, val_MinusLogProbMetric: 2.4623

Epoch 25: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4334 - MinusLogProbMetric: 2.4334 - val_loss: 2.4623 - val_MinusLogProbMetric: 2.4623 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-11 19:26:58.222 
Epoch 26/1000 
	 loss: 2.4235, MinusLogProbMetric: 2.4235, val_loss: 2.4268, val_MinusLogProbMetric: 2.4268

Epoch 26: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4235 - MinusLogProbMetric: 2.4235 - val_loss: 2.4268 - val_MinusLogProbMetric: 2.4268 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-11 19:27:09.934 
Epoch 27/1000 
	 loss: 2.4250, MinusLogProbMetric: 2.4250, val_loss: 2.5144, val_MinusLogProbMetric: 2.5144

Epoch 27: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4250 - MinusLogProbMetric: 2.4250 - val_loss: 2.5144 - val_MinusLogProbMetric: 2.5144 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-11 19:27:21.496 
Epoch 28/1000 
	 loss: 2.4201, MinusLogProbMetric: 2.4201, val_loss: 2.4430, val_MinusLogProbMetric: 2.4430

Epoch 28: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4201 - MinusLogProbMetric: 2.4201 - val_loss: 2.4430 - val_MinusLogProbMetric: 2.4430 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-11 19:27:33.080 
Epoch 29/1000 
	 loss: 2.4222, MinusLogProbMetric: 2.4222, val_loss: 2.4316, val_MinusLogProbMetric: 2.4316

Epoch 29: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4222 - MinusLogProbMetric: 2.4222 - val_loss: 2.4316 - val_MinusLogProbMetric: 2.4316 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 30/1000
2023-09-11 19:27:44.807 
Epoch 30/1000 
	 loss: 2.4228, MinusLogProbMetric: 2.4228, val_loss: 2.4085, val_MinusLogProbMetric: 2.4085

Epoch 30: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4228 - MinusLogProbMetric: 2.4228 - val_loss: 2.4085 - val_MinusLogProbMetric: 2.4085 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-11 19:27:56.519 
Epoch 31/1000 
	 loss: 2.4134, MinusLogProbMetric: 2.4134, val_loss: 2.4153, val_MinusLogProbMetric: 2.4153

Epoch 31: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4134 - MinusLogProbMetric: 2.4134 - val_loss: 2.4153 - val_MinusLogProbMetric: 2.4153 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-11 19:28:08.031 
Epoch 32/1000 
	 loss: 2.4247, MinusLogProbMetric: 2.4247, val_loss: 2.4438, val_MinusLogProbMetric: 2.4438

Epoch 32: val_loss did not improve from 2.40418
196/196 - 12s - loss: 2.4247 - MinusLogProbMetric: 2.4247 - val_loss: 2.4438 - val_MinusLogProbMetric: 2.4438 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 33/1000
2023-09-11 19:28:19.645 
Epoch 33/1000 
	 loss: 2.4252, MinusLogProbMetric: 2.4252, val_loss: 2.4029, val_MinusLogProbMetric: 2.4029

Epoch 33: val_loss improved from 2.40418 to 2.40293, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4252 - MinusLogProbMetric: 2.4252 - val_loss: 2.4029 - val_MinusLogProbMetric: 2.4029 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-11 19:28:31.526 
Epoch 34/1000 
	 loss: 2.4171, MinusLogProbMetric: 2.4171, val_loss: 2.4160, val_MinusLogProbMetric: 2.4160

Epoch 34: val_loss did not improve from 2.40293
196/196 - 12s - loss: 2.4171 - MinusLogProbMetric: 2.4171 - val_loss: 2.4160 - val_MinusLogProbMetric: 2.4160 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-11 19:28:43.126 
Epoch 35/1000 
	 loss: 2.4137, MinusLogProbMetric: 2.4137, val_loss: 2.3825, val_MinusLogProbMetric: 2.3825

Epoch 35: val_loss improved from 2.40293 to 2.38250, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.4137 - MinusLogProbMetric: 2.4137 - val_loss: 2.3825 - val_MinusLogProbMetric: 2.3825 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-11 19:28:55.024 
Epoch 36/1000 
	 loss: 2.4139, MinusLogProbMetric: 2.4139, val_loss: 2.4456, val_MinusLogProbMetric: 2.4456

Epoch 36: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4139 - MinusLogProbMetric: 2.4139 - val_loss: 2.4456 - val_MinusLogProbMetric: 2.4456 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-11 19:29:06.680 
Epoch 37/1000 
	 loss: 2.4106, MinusLogProbMetric: 2.4106, val_loss: 2.4000, val_MinusLogProbMetric: 2.4000

Epoch 37: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4106 - MinusLogProbMetric: 2.4106 - val_loss: 2.4000 - val_MinusLogProbMetric: 2.4000 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 38/1000
2023-09-11 19:29:18.288 
Epoch 38/1000 
	 loss: 2.4138, MinusLogProbMetric: 2.4138, val_loss: 2.5527, val_MinusLogProbMetric: 2.5527

Epoch 38: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4138 - MinusLogProbMetric: 2.4138 - val_loss: 2.5527 - val_MinusLogProbMetric: 2.5527 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 39/1000
2023-09-11 19:29:29.891 
Epoch 39/1000 
	 loss: 2.4128, MinusLogProbMetric: 2.4128, val_loss: 2.4048, val_MinusLogProbMetric: 2.4048

Epoch 39: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4128 - MinusLogProbMetric: 2.4128 - val_loss: 2.4048 - val_MinusLogProbMetric: 2.4048 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-11 19:29:41.587 
Epoch 40/1000 
	 loss: 2.4063, MinusLogProbMetric: 2.4063, val_loss: 2.4139, val_MinusLogProbMetric: 2.4139

Epoch 40: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4063 - MinusLogProbMetric: 2.4063 - val_loss: 2.4139 - val_MinusLogProbMetric: 2.4139 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-11 19:29:53.242 
Epoch 41/1000 
	 loss: 2.4110, MinusLogProbMetric: 2.4110, val_loss: 2.3942, val_MinusLogProbMetric: 2.3942

Epoch 41: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4110 - MinusLogProbMetric: 2.4110 - val_loss: 2.3942 - val_MinusLogProbMetric: 2.3942 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 42/1000
2023-09-11 19:30:04.919 
Epoch 42/1000 
	 loss: 2.4009, MinusLogProbMetric: 2.4009, val_loss: 2.4081, val_MinusLogProbMetric: 2.4081

Epoch 42: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4009 - MinusLogProbMetric: 2.4009 - val_loss: 2.4081 - val_MinusLogProbMetric: 2.4081 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-11 19:30:16.483 
Epoch 43/1000 
	 loss: 2.4046, MinusLogProbMetric: 2.4046, val_loss: 2.4190, val_MinusLogProbMetric: 2.4190

Epoch 43: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4046 - MinusLogProbMetric: 2.4046 - val_loss: 2.4190 - val_MinusLogProbMetric: 2.4190 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-11 19:30:28.094 
Epoch 44/1000 
	 loss: 2.4100, MinusLogProbMetric: 2.4100, val_loss: 2.3994, val_MinusLogProbMetric: 2.3994

Epoch 44: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4100 - MinusLogProbMetric: 2.4100 - val_loss: 2.3994 - val_MinusLogProbMetric: 2.3994 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 45/1000
2023-09-11 19:30:39.718 
Epoch 45/1000 
	 loss: 2.4066, MinusLogProbMetric: 2.4066, val_loss: 2.4027, val_MinusLogProbMetric: 2.4027

Epoch 45: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4066 - MinusLogProbMetric: 2.4066 - val_loss: 2.4027 - val_MinusLogProbMetric: 2.4027 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 46/1000
2023-09-11 19:30:51.358 
Epoch 46/1000 
	 loss: 2.4002, MinusLogProbMetric: 2.4002, val_loss: 2.4171, val_MinusLogProbMetric: 2.4171

Epoch 46: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4002 - MinusLogProbMetric: 2.4002 - val_loss: 2.4171 - val_MinusLogProbMetric: 2.4171 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-11 19:31:03.037 
Epoch 47/1000 
	 loss: 2.4051, MinusLogProbMetric: 2.4051, val_loss: 2.4005, val_MinusLogProbMetric: 2.4005

Epoch 47: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4051 - MinusLogProbMetric: 2.4051 - val_loss: 2.4005 - val_MinusLogProbMetric: 2.4005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-11 19:31:14.627 
Epoch 48/1000 
	 loss: 2.3998, MinusLogProbMetric: 2.3998, val_loss: 2.4003, val_MinusLogProbMetric: 2.4003

Epoch 48: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.3998 - MinusLogProbMetric: 2.3998 - val_loss: 2.4003 - val_MinusLogProbMetric: 2.4003 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 49/1000
2023-09-11 19:31:26.226 
Epoch 49/1000 
	 loss: 2.4001, MinusLogProbMetric: 2.4001, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 49: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.4001 - MinusLogProbMetric: 2.4001 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-11 19:31:37.810 
Epoch 50/1000 
	 loss: 2.3942, MinusLogProbMetric: 2.3942, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 50: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.3942 - MinusLogProbMetric: 2.3942 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 51/1000
2023-09-11 19:31:49.350 
Epoch 51/1000 
	 loss: 2.3974, MinusLogProbMetric: 2.3974, val_loss: 2.3919, val_MinusLogProbMetric: 2.3919

Epoch 51: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.3974 - MinusLogProbMetric: 2.3974 - val_loss: 2.3919 - val_MinusLogProbMetric: 2.3919 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 52/1000
2023-09-11 19:32:01.074 
Epoch 52/1000 
	 loss: 2.3927, MinusLogProbMetric: 2.3927, val_loss: 2.3902, val_MinusLogProbMetric: 2.3902

Epoch 52: val_loss did not improve from 2.38250
196/196 - 12s - loss: 2.3927 - MinusLogProbMetric: 2.3927 - val_loss: 2.3902 - val_MinusLogProbMetric: 2.3902 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-11 19:32:12.662 
Epoch 53/1000 
	 loss: 2.3960, MinusLogProbMetric: 2.3960, val_loss: 2.3809, val_MinusLogProbMetric: 2.3809

Epoch 53: val_loss improved from 2.38250 to 2.38085, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3960 - MinusLogProbMetric: 2.3960 - val_loss: 2.3809 - val_MinusLogProbMetric: 2.3809 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-11 19:32:24.389 
Epoch 54/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.4452, val_MinusLogProbMetric: 2.4452

Epoch 54: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.4452 - val_MinusLogProbMetric: 2.4452 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 55/1000
2023-09-11 19:32:35.953 
Epoch 55/1000 
	 loss: 2.4002, MinusLogProbMetric: 2.4002, val_loss: 2.3971, val_MinusLogProbMetric: 2.3971

Epoch 55: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.4002 - MinusLogProbMetric: 2.4002 - val_loss: 2.3971 - val_MinusLogProbMetric: 2.3971 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 56/1000
2023-09-11 19:32:47.525 
Epoch 56/1000 
	 loss: 2.3918, MinusLogProbMetric: 2.3918, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 56: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.3918 - MinusLogProbMetric: 2.3918 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 57/1000
2023-09-11 19:32:59.247 
Epoch 57/1000 
	 loss: 2.4014, MinusLogProbMetric: 2.4014, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 57: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.4014 - MinusLogProbMetric: 2.4014 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-11 19:33:10.972 
Epoch 58/1000 
	 loss: 2.4076, MinusLogProbMetric: 2.4076, val_loss: 2.4297, val_MinusLogProbMetric: 2.4297

Epoch 58: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.4076 - MinusLogProbMetric: 2.4076 - val_loss: 2.4297 - val_MinusLogProbMetric: 2.4297 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-11 19:33:22.530 
Epoch 59/1000 
	 loss: 2.3942, MinusLogProbMetric: 2.3942, val_loss: 2.4042, val_MinusLogProbMetric: 2.4042

Epoch 59: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.3942 - MinusLogProbMetric: 2.3942 - val_loss: 2.4042 - val_MinusLogProbMetric: 2.4042 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 60/1000
2023-09-11 19:33:34.265 
Epoch 60/1000 
	 loss: 2.3894, MinusLogProbMetric: 2.3894, val_loss: 2.4006, val_MinusLogProbMetric: 2.4006

Epoch 60: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.3894 - MinusLogProbMetric: 2.3894 - val_loss: 2.4006 - val_MinusLogProbMetric: 2.4006 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-11 19:33:45.945 
Epoch 61/1000 
	 loss: 2.3973, MinusLogProbMetric: 2.3973, val_loss: 2.3870, val_MinusLogProbMetric: 2.3870

Epoch 61: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.3973 - MinusLogProbMetric: 2.3973 - val_loss: 2.3870 - val_MinusLogProbMetric: 2.3870 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-11 19:33:57.605 
Epoch 62/1000 
	 loss: 2.3888, MinusLogProbMetric: 2.3888, val_loss: 2.3855, val_MinusLogProbMetric: 2.3855

Epoch 62: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.3888 - MinusLogProbMetric: 2.3888 - val_loss: 2.3855 - val_MinusLogProbMetric: 2.3855 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 63/1000
2023-09-11 19:34:09.105 
Epoch 63/1000 
	 loss: 2.3898, MinusLogProbMetric: 2.3898, val_loss: 2.4003, val_MinusLogProbMetric: 2.4003

Epoch 63: val_loss did not improve from 2.38085
196/196 - 11s - loss: 2.3898 - MinusLogProbMetric: 2.3898 - val_loss: 2.4003 - val_MinusLogProbMetric: 2.4003 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 64/1000
2023-09-11 19:34:20.654 
Epoch 64/1000 
	 loss: 2.3914, MinusLogProbMetric: 2.3914, val_loss: 2.3852, val_MinusLogProbMetric: 2.3852

Epoch 64: val_loss did not improve from 2.38085
196/196 - 12s - loss: 2.3914 - MinusLogProbMetric: 2.3914 - val_loss: 2.3852 - val_MinusLogProbMetric: 2.3852 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 65/1000
2023-09-11 19:34:32.389 
Epoch 65/1000 
	 loss: 2.3887, MinusLogProbMetric: 2.3887, val_loss: 2.3774, val_MinusLogProbMetric: 2.3774

Epoch 65: val_loss improved from 2.38085 to 2.37738, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3887 - MinusLogProbMetric: 2.3887 - val_loss: 2.3774 - val_MinusLogProbMetric: 2.3774 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 66/1000
2023-09-11 19:34:44.151 
Epoch 66/1000 
	 loss: 2.3946, MinusLogProbMetric: 2.3946, val_loss: 2.4244, val_MinusLogProbMetric: 2.4244

Epoch 66: val_loss did not improve from 2.37738
196/196 - 12s - loss: 2.3946 - MinusLogProbMetric: 2.3946 - val_loss: 2.4244 - val_MinusLogProbMetric: 2.4244 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-11 19:34:55.854 
Epoch 67/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.3776, val_MinusLogProbMetric: 2.3776

Epoch 67: val_loss did not improve from 2.37738
196/196 - 12s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.3776 - val_MinusLogProbMetric: 2.3776 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-11 19:35:07.787 
Epoch 68/1000 
	 loss: 2.3923, MinusLogProbMetric: 2.3923, val_loss: 2.3941, val_MinusLogProbMetric: 2.3941

Epoch 68: val_loss did not improve from 2.37738
196/196 - 12s - loss: 2.3923 - MinusLogProbMetric: 2.3923 - val_loss: 2.3941 - val_MinusLogProbMetric: 2.3941 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 69/1000
2023-09-11 19:35:19.367 
Epoch 69/1000 
	 loss: 2.3889, MinusLogProbMetric: 2.3889, val_loss: 2.3805, val_MinusLogProbMetric: 2.3805

Epoch 69: val_loss did not improve from 2.37738
196/196 - 12s - loss: 2.3889 - MinusLogProbMetric: 2.3889 - val_loss: 2.3805 - val_MinusLogProbMetric: 2.3805 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 70/1000
2023-09-11 19:35:30.867 
Epoch 70/1000 
	 loss: 2.3913, MinusLogProbMetric: 2.3913, val_loss: 2.4165, val_MinusLogProbMetric: 2.4165

Epoch 70: val_loss did not improve from 2.37738
196/196 - 11s - loss: 2.3913 - MinusLogProbMetric: 2.3913 - val_loss: 2.4165 - val_MinusLogProbMetric: 2.4165 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 71/1000
2023-09-11 19:35:42.055 
Epoch 71/1000 
	 loss: 2.3857, MinusLogProbMetric: 2.3857, val_loss: 2.4072, val_MinusLogProbMetric: 2.4072

Epoch 71: val_loss did not improve from 2.37738
196/196 - 11s - loss: 2.3857 - MinusLogProbMetric: 2.3857 - val_loss: 2.4072 - val_MinusLogProbMetric: 2.4072 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 72/1000
2023-09-11 19:35:53.333 
Epoch 72/1000 
	 loss: 2.3936, MinusLogProbMetric: 2.3936, val_loss: 2.3997, val_MinusLogProbMetric: 2.3997

Epoch 72: val_loss did not improve from 2.37738
196/196 - 11s - loss: 2.3936 - MinusLogProbMetric: 2.3936 - val_loss: 2.3997 - val_MinusLogProbMetric: 2.3997 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 73/1000
2023-09-11 19:36:04.805 
Epoch 73/1000 
	 loss: 2.3875, MinusLogProbMetric: 2.3875, val_loss: 2.4397, val_MinusLogProbMetric: 2.4397

Epoch 73: val_loss did not improve from 2.37738
196/196 - 11s - loss: 2.3875 - MinusLogProbMetric: 2.3875 - val_loss: 2.4397 - val_MinusLogProbMetric: 2.4397 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 74/1000
2023-09-11 19:36:16.513 
Epoch 74/1000 
	 loss: 2.3950, MinusLogProbMetric: 2.3950, val_loss: 2.3766, val_MinusLogProbMetric: 2.3766

Epoch 74: val_loss improved from 2.37738 to 2.37661, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3950 - MinusLogProbMetric: 2.3950 - val_loss: 2.3766 - val_MinusLogProbMetric: 2.3766 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-11 19:36:28.194 
Epoch 75/1000 
	 loss: 2.3877, MinusLogProbMetric: 2.3877, val_loss: 2.4110, val_MinusLogProbMetric: 2.4110

Epoch 75: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3877 - MinusLogProbMetric: 2.3877 - val_loss: 2.4110 - val_MinusLogProbMetric: 2.4110 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 76/1000
2023-09-11 19:36:39.829 
Epoch 76/1000 
	 loss: 2.3873, MinusLogProbMetric: 2.3873, val_loss: 2.3941, val_MinusLogProbMetric: 2.3941

Epoch 76: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3873 - MinusLogProbMetric: 2.3873 - val_loss: 2.3941 - val_MinusLogProbMetric: 2.3941 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 77/1000
2023-09-11 19:36:51.352 
Epoch 77/1000 
	 loss: 2.3846, MinusLogProbMetric: 2.3846, val_loss: 2.4133, val_MinusLogProbMetric: 2.4133

Epoch 77: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3846 - MinusLogProbMetric: 2.3846 - val_loss: 2.4133 - val_MinusLogProbMetric: 2.4133 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 78/1000
2023-09-11 19:37:02.970 
Epoch 78/1000 
	 loss: 2.3897, MinusLogProbMetric: 2.3897, val_loss: 2.4040, val_MinusLogProbMetric: 2.4040

Epoch 78: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3897 - MinusLogProbMetric: 2.3897 - val_loss: 2.4040 - val_MinusLogProbMetric: 2.4040 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 79/1000
2023-09-11 19:37:14.587 
Epoch 79/1000 
	 loss: 2.3896, MinusLogProbMetric: 2.3896, val_loss: 2.4013, val_MinusLogProbMetric: 2.4013

Epoch 79: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3896 - MinusLogProbMetric: 2.3896 - val_loss: 2.4013 - val_MinusLogProbMetric: 2.4013 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 80/1000
2023-09-11 19:37:26.206 
Epoch 80/1000 
	 loss: 2.3858, MinusLogProbMetric: 2.3858, val_loss: 2.3815, val_MinusLogProbMetric: 2.3815

Epoch 80: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3858 - MinusLogProbMetric: 2.3858 - val_loss: 2.3815 - val_MinusLogProbMetric: 2.3815 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-11 19:37:37.694 
Epoch 81/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.3807, val_MinusLogProbMetric: 2.3807

Epoch 81: val_loss did not improve from 2.37661
196/196 - 11s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.3807 - val_MinusLogProbMetric: 2.3807 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 82/1000
2023-09-11 19:37:49.448 
Epoch 82/1000 
	 loss: 2.3863, MinusLogProbMetric: 2.3863, val_loss: 2.3847, val_MinusLogProbMetric: 2.3847

Epoch 82: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3863 - MinusLogProbMetric: 2.3863 - val_loss: 2.3847 - val_MinusLogProbMetric: 2.3847 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-11 19:38:01.092 
Epoch 83/1000 
	 loss: 2.3796, MinusLogProbMetric: 2.3796, val_loss: 2.4037, val_MinusLogProbMetric: 2.4037

Epoch 83: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3796 - MinusLogProbMetric: 2.3796 - val_loss: 2.4037 - val_MinusLogProbMetric: 2.4037 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-11 19:38:12.740 
Epoch 84/1000 
	 loss: 2.3903, MinusLogProbMetric: 2.3903, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 84: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3903 - MinusLogProbMetric: 2.3903 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 85/1000
2023-09-11 19:38:24.383 
Epoch 85/1000 
	 loss: 2.3933, MinusLogProbMetric: 2.3933, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 85: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3933 - MinusLogProbMetric: 2.3933 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-11 19:38:35.889 
Epoch 86/1000 
	 loss: 2.3819, MinusLogProbMetric: 2.3819, val_loss: 2.3807, val_MinusLogProbMetric: 2.3807

Epoch 86: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3819 - MinusLogProbMetric: 2.3819 - val_loss: 2.3807 - val_MinusLogProbMetric: 2.3807 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-11 19:38:47.358 
Epoch 87/1000 
	 loss: 2.3855, MinusLogProbMetric: 2.3855, val_loss: 2.4145, val_MinusLogProbMetric: 2.4145

Epoch 87: val_loss did not improve from 2.37661
196/196 - 11s - loss: 2.3855 - MinusLogProbMetric: 2.3855 - val_loss: 2.4145 - val_MinusLogProbMetric: 2.4145 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 88/1000
2023-09-11 19:38:58.882 
Epoch 88/1000 
	 loss: 2.3912, MinusLogProbMetric: 2.3912, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 88: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3912 - MinusLogProbMetric: 2.3912 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-11 19:39:10.550 
Epoch 89/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.3965, val_MinusLogProbMetric: 2.3965

Epoch 89: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.3965 - val_MinusLogProbMetric: 2.3965 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 90/1000
2023-09-11 19:39:22.218 
Epoch 90/1000 
	 loss: 2.3860, MinusLogProbMetric: 2.3860, val_loss: 2.3873, val_MinusLogProbMetric: 2.3873

Epoch 90: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3860 - MinusLogProbMetric: 2.3860 - val_loss: 2.3873 - val_MinusLogProbMetric: 2.3873 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-11 19:39:33.651 
Epoch 91/1000 
	 loss: 2.3819, MinusLogProbMetric: 2.3819, val_loss: 2.4019, val_MinusLogProbMetric: 2.4019

Epoch 91: val_loss did not improve from 2.37661
196/196 - 11s - loss: 2.3819 - MinusLogProbMetric: 2.3819 - val_loss: 2.4019 - val_MinusLogProbMetric: 2.4019 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 92/1000
2023-09-11 19:39:45.172 
Epoch 92/1000 
	 loss: 2.3802, MinusLogProbMetric: 2.3802, val_loss: 2.4110, val_MinusLogProbMetric: 2.4110

Epoch 92: val_loss did not improve from 2.37661
196/196 - 12s - loss: 2.3802 - MinusLogProbMetric: 2.3802 - val_loss: 2.4110 - val_MinusLogProbMetric: 2.4110 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 93/1000
2023-09-11 19:39:56.669 
Epoch 93/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.3755, val_MinusLogProbMetric: 2.3755

Epoch 93: val_loss improved from 2.37661 to 2.37553, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.3755 - val_MinusLogProbMetric: 2.3755 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 94/1000
2023-09-11 19:40:08.453 
Epoch 94/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.3838, val_MinusLogProbMetric: 2.3838

Epoch 94: val_loss did not improve from 2.37553
196/196 - 12s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.3838 - val_MinusLogProbMetric: 2.3838 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-11 19:40:19.998 
Epoch 95/1000 
	 loss: 2.3840, MinusLogProbMetric: 2.3840, val_loss: 2.4175, val_MinusLogProbMetric: 2.4175

Epoch 95: val_loss did not improve from 2.37553
196/196 - 12s - loss: 2.3840 - MinusLogProbMetric: 2.3840 - val_loss: 2.4175 - val_MinusLogProbMetric: 2.4175 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 96/1000
2023-09-11 19:40:31.492 
Epoch 96/1000 
	 loss: 2.3823, MinusLogProbMetric: 2.3823, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 96: val_loss improved from 2.37553 to 2.37092, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3823 - MinusLogProbMetric: 2.3823 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 97/1000
2023-09-11 19:40:43.243 
Epoch 97/1000 
	 loss: 2.3810, MinusLogProbMetric: 2.3810, val_loss: 2.3895, val_MinusLogProbMetric: 2.3895

Epoch 97: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3810 - MinusLogProbMetric: 2.3810 - val_loss: 2.3895 - val_MinusLogProbMetric: 2.3895 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 98/1000
2023-09-11 19:40:54.843 
Epoch 98/1000 
	 loss: 2.3845, MinusLogProbMetric: 2.3845, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 98: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3845 - MinusLogProbMetric: 2.3845 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 99/1000
2023-09-11 19:41:06.415 
Epoch 99/1000 
	 loss: 2.3824, MinusLogProbMetric: 2.3824, val_loss: 2.3726, val_MinusLogProbMetric: 2.3726

Epoch 99: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3824 - MinusLogProbMetric: 2.3824 - val_loss: 2.3726 - val_MinusLogProbMetric: 2.3726 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-11 19:41:17.972 
Epoch 100/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.3868, val_MinusLogProbMetric: 2.3868

Epoch 100: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.3868 - val_MinusLogProbMetric: 2.3868 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 101/1000
2023-09-11 19:41:29.476 
Epoch 101/1000 
	 loss: 2.3822, MinusLogProbMetric: 2.3822, val_loss: 2.3868, val_MinusLogProbMetric: 2.3868

Epoch 101: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3822 - MinusLogProbMetric: 2.3822 - val_loss: 2.3868 - val_MinusLogProbMetric: 2.3868 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 102/1000
2023-09-11 19:41:40.927 
Epoch 102/1000 
	 loss: 2.3809, MinusLogProbMetric: 2.3809, val_loss: 2.3808, val_MinusLogProbMetric: 2.3808

Epoch 102: val_loss did not improve from 2.37092
196/196 - 11s - loss: 2.3809 - MinusLogProbMetric: 2.3809 - val_loss: 2.3808 - val_MinusLogProbMetric: 2.3808 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 103/1000
2023-09-11 19:41:52.452 
Epoch 103/1000 
	 loss: 2.3836, MinusLogProbMetric: 2.3836, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 103: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3836 - MinusLogProbMetric: 2.3836 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 104/1000
2023-09-11 19:42:04.035 
Epoch 104/1000 
	 loss: 2.3829, MinusLogProbMetric: 2.3829, val_loss: 2.3786, val_MinusLogProbMetric: 2.3786

Epoch 104: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3829 - MinusLogProbMetric: 2.3829 - val_loss: 2.3786 - val_MinusLogProbMetric: 2.3786 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 105/1000
2023-09-11 19:42:15.632 
Epoch 105/1000 
	 loss: 2.3820, MinusLogProbMetric: 2.3820, val_loss: 2.3910, val_MinusLogProbMetric: 2.3910

Epoch 105: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3820 - MinusLogProbMetric: 2.3820 - val_loss: 2.3910 - val_MinusLogProbMetric: 2.3910 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 106/1000
2023-09-11 19:42:27.217 
Epoch 106/1000 
	 loss: 2.3790, MinusLogProbMetric: 2.3790, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 106: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3790 - MinusLogProbMetric: 2.3790 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 107/1000
2023-09-11 19:42:38.955 
Epoch 107/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.3731, val_MinusLogProbMetric: 2.3731

Epoch 107: val_loss did not improve from 2.37092
196/196 - 12s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.3731 - val_MinusLogProbMetric: 2.3731 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-11 19:42:50.769 
Epoch 108/1000 
	 loss: 2.3799, MinusLogProbMetric: 2.3799, val_loss: 2.3708, val_MinusLogProbMetric: 2.3708

Epoch 108: val_loss improved from 2.37092 to 2.37083, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3799 - MinusLogProbMetric: 2.3799 - val_loss: 2.3708 - val_MinusLogProbMetric: 2.3708 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 109/1000
2023-09-11 19:43:02.441 
Epoch 109/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.3833, val_MinusLogProbMetric: 2.3833

Epoch 109: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.3833 - val_MinusLogProbMetric: 2.3833 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-11 19:43:11.828 
Epoch 110/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.4063, val_MinusLogProbMetric: 2.4063

Epoch 110: val_loss did not improve from 2.37083
196/196 - 9s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.4063 - val_MinusLogProbMetric: 2.4063 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 111/1000
2023-09-11 19:43:22.860 
Epoch 111/1000 
	 loss: 2.3812, MinusLogProbMetric: 2.3812, val_loss: 2.3918, val_MinusLogProbMetric: 2.3918

Epoch 111: val_loss did not improve from 2.37083
196/196 - 11s - loss: 2.3812 - MinusLogProbMetric: 2.3812 - val_loss: 2.3918 - val_MinusLogProbMetric: 2.3918 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 112/1000
2023-09-11 19:43:32.561 
Epoch 112/1000 
	 loss: 2.3815, MinusLogProbMetric: 2.3815, val_loss: 2.3855, val_MinusLogProbMetric: 2.3855

Epoch 112: val_loss did not improve from 2.37083
196/196 - 10s - loss: 2.3815 - MinusLogProbMetric: 2.3815 - val_loss: 2.3855 - val_MinusLogProbMetric: 2.3855 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 113/1000
2023-09-11 19:43:44.279 
Epoch 113/1000 
	 loss: 2.3802, MinusLogProbMetric: 2.3802, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 113: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3802 - MinusLogProbMetric: 2.3802 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-11 19:43:55.944 
Epoch 114/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3737, val_MinusLogProbMetric: 2.3737

Epoch 114: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3737 - val_MinusLogProbMetric: 2.3737 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 115/1000
2023-09-11 19:44:07.589 
Epoch 115/1000 
	 loss: 2.3856, MinusLogProbMetric: 2.3856, val_loss: 2.4018, val_MinusLogProbMetric: 2.4018

Epoch 115: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3856 - MinusLogProbMetric: 2.3856 - val_loss: 2.4018 - val_MinusLogProbMetric: 2.4018 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 116/1000
2023-09-11 19:44:19.179 
Epoch 116/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3820, val_MinusLogProbMetric: 2.3820

Epoch 116: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3820 - val_MinusLogProbMetric: 2.3820 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 117/1000
2023-09-11 19:44:30.980 
Epoch 117/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 117: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-11 19:44:42.673 
Epoch 118/1000 
	 loss: 2.3832, MinusLogProbMetric: 2.3832, val_loss: 2.3772, val_MinusLogProbMetric: 2.3772

Epoch 118: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3832 - MinusLogProbMetric: 2.3832 - val_loss: 2.3772 - val_MinusLogProbMetric: 2.3772 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-11 19:44:54.345 
Epoch 119/1000 
	 loss: 2.3829, MinusLogProbMetric: 2.3829, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 119: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3829 - MinusLogProbMetric: 2.3829 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 120/1000
2023-09-11 19:45:05.890 
Epoch 120/1000 
	 loss: 2.3852, MinusLogProbMetric: 2.3852, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 120: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3852 - MinusLogProbMetric: 2.3852 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 121/1000
2023-09-11 19:45:17.461 
Epoch 121/1000 
	 loss: 2.3807, MinusLogProbMetric: 2.3807, val_loss: 2.3816, val_MinusLogProbMetric: 2.3816

Epoch 121: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3807 - MinusLogProbMetric: 2.3807 - val_loss: 2.3816 - val_MinusLogProbMetric: 2.3816 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 122/1000
2023-09-11 19:45:28.915 
Epoch 122/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3831, val_MinusLogProbMetric: 2.3831

Epoch 122: val_loss did not improve from 2.37083
196/196 - 11s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3831 - val_MinusLogProbMetric: 2.3831 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 123/1000
2023-09-11 19:45:40.616 
Epoch 123/1000 
	 loss: 2.3780, MinusLogProbMetric: 2.3780, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 123: val_loss did not improve from 2.37083
196/196 - 12s - loss: 2.3780 - MinusLogProbMetric: 2.3780 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-11 19:45:51.915 
Epoch 124/1000 
	 loss: 2.3779, MinusLogProbMetric: 2.3779, val_loss: 2.3740, val_MinusLogProbMetric: 2.3740

Epoch 124: val_loss did not improve from 2.37083
196/196 - 11s - loss: 2.3779 - MinusLogProbMetric: 2.3779 - val_loss: 2.3740 - val_MinusLogProbMetric: 2.3740 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 125/1000
2023-09-11 19:46:01.418 
Epoch 125/1000 
	 loss: 2.3767, MinusLogProbMetric: 2.3767, val_loss: 2.3711, val_MinusLogProbMetric: 2.3711

Epoch 125: val_loss did not improve from 2.37083
196/196 - 9s - loss: 2.3767 - MinusLogProbMetric: 2.3767 - val_loss: 2.3711 - val_MinusLogProbMetric: 2.3711 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 126/1000
2023-09-11 19:46:11.775 
Epoch 126/1000 
	 loss: 2.3769, MinusLogProbMetric: 2.3769, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 126: val_loss did not improve from 2.37083
196/196 - 10s - loss: 2.3769 - MinusLogProbMetric: 2.3769 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 127/1000
2023-09-11 19:46:22.930 
Epoch 127/1000 
	 loss: 2.3740, MinusLogProbMetric: 2.3740, val_loss: 2.3794, val_MinusLogProbMetric: 2.3794

Epoch 127: val_loss did not improve from 2.37083
196/196 - 11s - loss: 2.3740 - MinusLogProbMetric: 2.3740 - val_loss: 2.3794 - val_MinusLogProbMetric: 2.3794 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 128/1000
2023-09-11 19:46:34.454 
Epoch 128/1000 
	 loss: 2.3743, MinusLogProbMetric: 2.3743, val_loss: 2.3652, val_MinusLogProbMetric: 2.3652

Epoch 128: val_loss improved from 2.37083 to 2.36520, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3743 - MinusLogProbMetric: 2.3743 - val_loss: 2.3652 - val_MinusLogProbMetric: 2.3652 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 129/1000
2023-09-11 19:46:46.148 
Epoch 129/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3743, val_MinusLogProbMetric: 2.3743

Epoch 129: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3743 - val_MinusLogProbMetric: 2.3743 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 130/1000
2023-09-11 19:46:57.636 
Epoch 130/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3778, val_MinusLogProbMetric: 2.3778

Epoch 130: val_loss did not improve from 2.36520
196/196 - 11s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3778 - val_MinusLogProbMetric: 2.3778 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 131/1000
2023-09-11 19:47:09.141 
Epoch 131/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3755, val_MinusLogProbMetric: 2.3755

Epoch 131: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3755 - val_MinusLogProbMetric: 2.3755 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 132/1000
2023-09-11 19:47:20.603 
Epoch 132/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 132: val_loss did not improve from 2.36520
196/196 - 11s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 133/1000
2023-09-11 19:47:32.249 
Epoch 133/1000 
	 loss: 2.3751, MinusLogProbMetric: 2.3751, val_loss: 2.4073, val_MinusLogProbMetric: 2.4073

Epoch 133: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3751 - MinusLogProbMetric: 2.3751 - val_loss: 2.4073 - val_MinusLogProbMetric: 2.4073 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 134/1000
2023-09-11 19:47:43.930 
Epoch 134/1000 
	 loss: 2.3825, MinusLogProbMetric: 2.3825, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 134: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3825 - MinusLogProbMetric: 2.3825 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-11 19:47:55.539 
Epoch 135/1000 
	 loss: 2.3720, MinusLogProbMetric: 2.3720, val_loss: 2.3777, val_MinusLogProbMetric: 2.3777

Epoch 135: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3720 - MinusLogProbMetric: 2.3720 - val_loss: 2.3777 - val_MinusLogProbMetric: 2.3777 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 136/1000
2023-09-11 19:48:07.153 
Epoch 136/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.3846, val_MinusLogProbMetric: 2.3846

Epoch 136: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.3846 - val_MinusLogProbMetric: 2.3846 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 137/1000
2023-09-11 19:48:18.781 
Epoch 137/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.3798, val_MinusLogProbMetric: 2.3798

Epoch 137: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.3798 - val_MinusLogProbMetric: 2.3798 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 138/1000
2023-09-11 19:48:30.282 
Epoch 138/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3775, val_MinusLogProbMetric: 2.3775

Epoch 138: val_loss did not improve from 2.36520
196/196 - 11s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3775 - val_MinusLogProbMetric: 2.3775 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 139/1000
2023-09-11 19:48:41.789 
Epoch 139/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 139: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 140/1000
2023-09-11 19:48:53.415 
Epoch 140/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3862, val_MinusLogProbMetric: 2.3862

Epoch 140: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3862 - val_MinusLogProbMetric: 2.3862 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 141/1000
2023-09-11 19:49:04.999 
Epoch 141/1000 
	 loss: 2.3768, MinusLogProbMetric: 2.3768, val_loss: 2.3780, val_MinusLogProbMetric: 2.3780

Epoch 141: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3768 - MinusLogProbMetric: 2.3768 - val_loss: 2.3780 - val_MinusLogProbMetric: 2.3780 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 142/1000
2023-09-11 19:49:16.567 
Epoch 142/1000 
	 loss: 2.3724, MinusLogProbMetric: 2.3724, val_loss: 2.3719, val_MinusLogProbMetric: 2.3719

Epoch 142: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3724 - MinusLogProbMetric: 2.3724 - val_loss: 2.3719 - val_MinusLogProbMetric: 2.3719 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 143/1000
2023-09-11 19:49:27.987 
Epoch 143/1000 
	 loss: 2.3763, MinusLogProbMetric: 2.3763, val_loss: 2.3665, val_MinusLogProbMetric: 2.3665

Epoch 143: val_loss did not improve from 2.36520
196/196 - 11s - loss: 2.3763 - MinusLogProbMetric: 2.3763 - val_loss: 2.3665 - val_MinusLogProbMetric: 2.3665 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-11 19:49:39.556 
Epoch 144/1000 
	 loss: 2.3717, MinusLogProbMetric: 2.3717, val_loss: 2.3746, val_MinusLogProbMetric: 2.3746

Epoch 144: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3717 - MinusLogProbMetric: 2.3717 - val_loss: 2.3746 - val_MinusLogProbMetric: 2.3746 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 145/1000
2023-09-11 19:49:51.124 
Epoch 145/1000 
	 loss: 2.3747, MinusLogProbMetric: 2.3747, val_loss: 2.3787, val_MinusLogProbMetric: 2.3787

Epoch 145: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3747 - MinusLogProbMetric: 2.3747 - val_loss: 2.3787 - val_MinusLogProbMetric: 2.3787 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 146/1000
2023-09-11 19:50:02.794 
Epoch 146/1000 
	 loss: 2.3746, MinusLogProbMetric: 2.3746, val_loss: 2.3714, val_MinusLogProbMetric: 2.3714

Epoch 146: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3746 - MinusLogProbMetric: 2.3746 - val_loss: 2.3714 - val_MinusLogProbMetric: 2.3714 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-11 19:50:14.312 
Epoch 147/1000 
	 loss: 2.3802, MinusLogProbMetric: 2.3802, val_loss: 2.3814, val_MinusLogProbMetric: 2.3814

Epoch 147: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3802 - MinusLogProbMetric: 2.3802 - val_loss: 2.3814 - val_MinusLogProbMetric: 2.3814 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 148/1000
2023-09-11 19:50:25.892 
Epoch 148/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 148: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 149/1000
2023-09-11 19:50:37.334 
Epoch 149/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.3713, val_MinusLogProbMetric: 2.3713

Epoch 149: val_loss did not improve from 2.36520
196/196 - 11s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.3713 - val_MinusLogProbMetric: 2.3713 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-11 19:50:48.867 
Epoch 150/1000 
	 loss: 2.3742, MinusLogProbMetric: 2.3742, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 150: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3742 - MinusLogProbMetric: 2.3742 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 151/1000
2023-09-11 19:51:00.451 
Epoch 151/1000 
	 loss: 2.3783, MinusLogProbMetric: 2.3783, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 151: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3783 - MinusLogProbMetric: 2.3783 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 152/1000
2023-09-11 19:51:12.016 
Epoch 152/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.3996, val_MinusLogProbMetric: 2.3996

Epoch 152: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.3996 - val_MinusLogProbMetric: 2.3996 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 153/1000
2023-09-11 19:51:23.581 
Epoch 153/1000 
	 loss: 2.3732, MinusLogProbMetric: 2.3732, val_loss: 2.3909, val_MinusLogProbMetric: 2.3909

Epoch 153: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3732 - MinusLogProbMetric: 2.3732 - val_loss: 2.3909 - val_MinusLogProbMetric: 2.3909 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-11 19:51:35.136 
Epoch 154/1000 
	 loss: 2.3739, MinusLogProbMetric: 2.3739, val_loss: 2.3807, val_MinusLogProbMetric: 2.3807

Epoch 154: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3739 - MinusLogProbMetric: 2.3739 - val_loss: 2.3807 - val_MinusLogProbMetric: 2.3807 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 155/1000
2023-09-11 19:51:46.710 
Epoch 155/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 155: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 156/1000
2023-09-11 19:51:58.283 
Epoch 156/1000 
	 loss: 2.3720, MinusLogProbMetric: 2.3720, val_loss: 2.3775, val_MinusLogProbMetric: 2.3775

Epoch 156: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3720 - MinusLogProbMetric: 2.3720 - val_loss: 2.3775 - val_MinusLogProbMetric: 2.3775 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 157/1000
2023-09-11 19:52:09.841 
Epoch 157/1000 
	 loss: 2.3727, MinusLogProbMetric: 2.3727, val_loss: 2.3773, val_MinusLogProbMetric: 2.3773

Epoch 157: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3727 - MinusLogProbMetric: 2.3727 - val_loss: 2.3773 - val_MinusLogProbMetric: 2.3773 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 158/1000
2023-09-11 19:52:21.397 
Epoch 158/1000 
	 loss: 2.3732, MinusLogProbMetric: 2.3732, val_loss: 2.3653, val_MinusLogProbMetric: 2.3653

Epoch 158: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3732 - MinusLogProbMetric: 2.3732 - val_loss: 2.3653 - val_MinusLogProbMetric: 2.3653 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 159/1000
2023-09-11 19:52:32.883 
Epoch 159/1000 
	 loss: 2.3724, MinusLogProbMetric: 2.3724, val_loss: 2.3689, val_MinusLogProbMetric: 2.3689

Epoch 159: val_loss did not improve from 2.36520
196/196 - 11s - loss: 2.3724 - MinusLogProbMetric: 2.3724 - val_loss: 2.3689 - val_MinusLogProbMetric: 2.3689 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 160/1000
2023-09-11 19:52:44.374 
Epoch 160/1000 
	 loss: 2.3728, MinusLogProbMetric: 2.3728, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 160: val_loss did not improve from 2.36520
196/196 - 11s - loss: 2.3728 - MinusLogProbMetric: 2.3728 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 161/1000
2023-09-11 19:52:56.026 
Epoch 161/1000 
	 loss: 2.3732, MinusLogProbMetric: 2.3732, val_loss: 2.3925, val_MinusLogProbMetric: 2.3925

Epoch 161: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3732 - MinusLogProbMetric: 2.3732 - val_loss: 2.3925 - val_MinusLogProbMetric: 2.3925 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 162/1000
2023-09-11 19:53:07.596 
Epoch 162/1000 
	 loss: 2.3693, MinusLogProbMetric: 2.3693, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 162: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3693 - MinusLogProbMetric: 2.3693 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 163/1000
2023-09-11 19:53:19.151 
Epoch 163/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3676, val_MinusLogProbMetric: 2.3676

Epoch 163: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3676 - val_MinusLogProbMetric: 2.3676 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 164/1000
2023-09-11 19:53:30.815 
Epoch 164/1000 
	 loss: 2.3743, MinusLogProbMetric: 2.3743, val_loss: 2.4063, val_MinusLogProbMetric: 2.4063

Epoch 164: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3743 - MinusLogProbMetric: 2.3743 - val_loss: 2.4063 - val_MinusLogProbMetric: 2.4063 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-11 19:53:42.424 
Epoch 165/1000 
	 loss: 2.3722, MinusLogProbMetric: 2.3722, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 165: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3722 - MinusLogProbMetric: 2.3722 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 166/1000
2023-09-11 19:53:54.027 
Epoch 166/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 166: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-11 19:54:05.594 
Epoch 167/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 167: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 168/1000
2023-09-11 19:54:17.274 
Epoch 168/1000 
	 loss: 2.3725, MinusLogProbMetric: 2.3725, val_loss: 2.3668, val_MinusLogProbMetric: 2.3668

Epoch 168: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3725 - MinusLogProbMetric: 2.3725 - val_loss: 2.3668 - val_MinusLogProbMetric: 2.3668 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-11 19:54:28.911 
Epoch 169/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 169: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 170/1000
2023-09-11 19:54:40.459 
Epoch 170/1000 
	 loss: 2.3687, MinusLogProbMetric: 2.3687, val_loss: 2.3709, val_MinusLogProbMetric: 2.3709

Epoch 170: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3687 - MinusLogProbMetric: 2.3687 - val_loss: 2.3709 - val_MinusLogProbMetric: 2.3709 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 171/1000
2023-09-11 19:54:52.070 
Epoch 171/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 171: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 172/1000
2023-09-11 19:55:03.699 
Epoch 172/1000 
	 loss: 2.3704, MinusLogProbMetric: 2.3704, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 172: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3704 - MinusLogProbMetric: 2.3704 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 173/1000
2023-09-11 19:55:15.309 
Epoch 173/1000 
	 loss: 2.3708, MinusLogProbMetric: 2.3708, val_loss: 2.3797, val_MinusLogProbMetric: 2.3797

Epoch 173: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3708 - MinusLogProbMetric: 2.3708 - val_loss: 2.3797 - val_MinusLogProbMetric: 2.3797 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 174/1000
2023-09-11 19:55:26.872 
Epoch 174/1000 
	 loss: 2.3717, MinusLogProbMetric: 2.3717, val_loss: 2.3813, val_MinusLogProbMetric: 2.3813

Epoch 174: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3717 - MinusLogProbMetric: 2.3717 - val_loss: 2.3813 - val_MinusLogProbMetric: 2.3813 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 175/1000
2023-09-11 19:55:38.493 
Epoch 175/1000 
	 loss: 2.3762, MinusLogProbMetric: 2.3762, val_loss: 2.3921, val_MinusLogProbMetric: 2.3921

Epoch 175: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3762 - MinusLogProbMetric: 2.3762 - val_loss: 2.3921 - val_MinusLogProbMetric: 2.3921 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-11 19:55:50.042 
Epoch 176/1000 
	 loss: 2.3719, MinusLogProbMetric: 2.3719, val_loss: 2.3913, val_MinusLogProbMetric: 2.3913

Epoch 176: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3719 - MinusLogProbMetric: 2.3719 - val_loss: 2.3913 - val_MinusLogProbMetric: 2.3913 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 177/1000
2023-09-11 19:56:01.613 
Epoch 177/1000 
	 loss: 2.3733, MinusLogProbMetric: 2.3733, val_loss: 2.4137, val_MinusLogProbMetric: 2.4137

Epoch 177: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3733 - MinusLogProbMetric: 2.3733 - val_loss: 2.4137 - val_MinusLogProbMetric: 2.4137 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 178/1000
2023-09-11 19:56:13.206 
Epoch 178/1000 
	 loss: 2.3709, MinusLogProbMetric: 2.3709, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 178: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3709 - MinusLogProbMetric: 2.3709 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 179/1000
2023-09-11 19:56:24.803 
Epoch 179/1000 
	 loss: 2.3607, MinusLogProbMetric: 2.3607, val_loss: 2.3666, val_MinusLogProbMetric: 2.3666

Epoch 179: val_loss did not improve from 2.36520
196/196 - 12s - loss: 2.3607 - MinusLogProbMetric: 2.3607 - val_loss: 2.3666 - val_MinusLogProbMetric: 2.3666 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 180/1000
2023-09-11 19:56:36.421 
Epoch 180/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 180: val_loss improved from 2.36520 to 2.36294, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 181/1000
2023-09-11 19:56:48.148 
Epoch 181/1000 
	 loss: 2.3614, MinusLogProbMetric: 2.3614, val_loss: 2.3660, val_MinusLogProbMetric: 2.3660

Epoch 181: val_loss did not improve from 2.36294
196/196 - 12s - loss: 2.3614 - MinusLogProbMetric: 2.3614 - val_loss: 2.3660 - val_MinusLogProbMetric: 2.3660 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 182/1000
2023-09-11 19:56:59.777 
Epoch 182/1000 
	 loss: 2.3618, MinusLogProbMetric: 2.3618, val_loss: 2.3762, val_MinusLogProbMetric: 2.3762

Epoch 182: val_loss did not improve from 2.36294
196/196 - 12s - loss: 2.3618 - MinusLogProbMetric: 2.3618 - val_loss: 2.3762 - val_MinusLogProbMetric: 2.3762 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 183/1000
2023-09-11 19:57:11.259 
Epoch 183/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 183: val_loss improved from 2.36294 to 2.36011, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 184/1000
2023-09-11 19:57:22.980 
Epoch 184/1000 
	 loss: 2.3624, MinusLogProbMetric: 2.3624, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 184: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3624 - MinusLogProbMetric: 2.3624 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 185/1000
2023-09-11 19:57:34.868 
Epoch 185/1000 
	 loss: 2.3609, MinusLogProbMetric: 2.3609, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 185: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3609 - MinusLogProbMetric: 2.3609 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 186/1000
2023-09-11 19:57:46.646 
Epoch 186/1000 
	 loss: 2.3604, MinusLogProbMetric: 2.3604, val_loss: 2.3720, val_MinusLogProbMetric: 2.3720

Epoch 186: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3604 - MinusLogProbMetric: 2.3604 - val_loss: 2.3720 - val_MinusLogProbMetric: 2.3720 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 187/1000
2023-09-11 19:57:58.423 
Epoch 187/1000 
	 loss: 2.3607, MinusLogProbMetric: 2.3607, val_loss: 2.3689, val_MinusLogProbMetric: 2.3689

Epoch 187: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3607 - MinusLogProbMetric: 2.3607 - val_loss: 2.3689 - val_MinusLogProbMetric: 2.3689 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 188/1000
2023-09-11 19:58:10.109 
Epoch 188/1000 
	 loss: 2.3607, MinusLogProbMetric: 2.3607, val_loss: 2.3694, val_MinusLogProbMetric: 2.3694

Epoch 188: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3607 - MinusLogProbMetric: 2.3607 - val_loss: 2.3694 - val_MinusLogProbMetric: 2.3694 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 189/1000
2023-09-11 19:58:21.787 
Epoch 189/1000 
	 loss: 2.3610, MinusLogProbMetric: 2.3610, val_loss: 2.3604, val_MinusLogProbMetric: 2.3604

Epoch 189: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3610 - MinusLogProbMetric: 2.3610 - val_loss: 2.3604 - val_MinusLogProbMetric: 2.3604 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 190/1000
2023-09-11 19:58:33.469 
Epoch 190/1000 
	 loss: 2.3597, MinusLogProbMetric: 2.3597, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 190: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3597 - MinusLogProbMetric: 2.3597 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-11 19:58:45.073 
Epoch 191/1000 
	 loss: 2.3628, MinusLogProbMetric: 2.3628, val_loss: 2.3679, val_MinusLogProbMetric: 2.3679

Epoch 191: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3628 - MinusLogProbMetric: 2.3628 - val_loss: 2.3679 - val_MinusLogProbMetric: 2.3679 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 192/1000
2023-09-11 19:58:56.634 
Epoch 192/1000 
	 loss: 2.3621, MinusLogProbMetric: 2.3621, val_loss: 2.3617, val_MinusLogProbMetric: 2.3617

Epoch 192: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3621 - MinusLogProbMetric: 2.3621 - val_loss: 2.3617 - val_MinusLogProbMetric: 2.3617 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 193/1000
2023-09-11 19:59:08.171 
Epoch 193/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 193: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 194/1000
2023-09-11 19:59:19.696 
Epoch 194/1000 
	 loss: 2.3612, MinusLogProbMetric: 2.3612, val_loss: 2.3809, val_MinusLogProbMetric: 2.3809

Epoch 194: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3612 - MinusLogProbMetric: 2.3612 - val_loss: 2.3809 - val_MinusLogProbMetric: 2.3809 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 195/1000
2023-09-11 19:59:31.314 
Epoch 195/1000 
	 loss: 2.3597, MinusLogProbMetric: 2.3597, val_loss: 2.3687, val_MinusLogProbMetric: 2.3687

Epoch 195: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3597 - MinusLogProbMetric: 2.3597 - val_loss: 2.3687 - val_MinusLogProbMetric: 2.3687 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 196/1000
2023-09-11 19:59:42.893 
Epoch 196/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3649, val_MinusLogProbMetric: 2.3649

Epoch 196: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3649 - val_MinusLogProbMetric: 2.3649 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 197/1000
2023-09-11 19:59:54.392 
Epoch 197/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 197: val_loss did not improve from 2.36011
196/196 - 11s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 198/1000
2023-09-11 20:00:05.970 
Epoch 198/1000 
	 loss: 2.3607, MinusLogProbMetric: 2.3607, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 198: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3607 - MinusLogProbMetric: 2.3607 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 199/1000
2023-09-11 20:00:17.635 
Epoch 199/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 199: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-11 20:00:29.139 
Epoch 200/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 200: val_loss did not improve from 2.36011
196/196 - 11s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 201/1000
2023-09-11 20:00:40.788 
Epoch 201/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 201: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 202/1000
2023-09-11 20:00:52.313 
Epoch 202/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3645, val_MinusLogProbMetric: 2.3645

Epoch 202: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3645 - val_MinusLogProbMetric: 2.3645 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 203/1000
2023-09-11 20:01:04.036 
Epoch 203/1000 
	 loss: 2.3610, MinusLogProbMetric: 2.3610, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 203: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3610 - MinusLogProbMetric: 2.3610 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 204/1000
2023-09-11 20:01:15.612 
Epoch 204/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 204: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 205/1000
2023-09-11 20:01:27.148 
Epoch 205/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3703, val_MinusLogProbMetric: 2.3703

Epoch 205: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3703 - val_MinusLogProbMetric: 2.3703 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 206/1000
2023-09-11 20:01:38.787 
Epoch 206/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 206: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-11 20:01:50.467 
Epoch 207/1000 
	 loss: 2.3611, MinusLogProbMetric: 2.3611, val_loss: 2.3763, val_MinusLogProbMetric: 2.3763

Epoch 207: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3611 - MinusLogProbMetric: 2.3611 - val_loss: 2.3763 - val_MinusLogProbMetric: 2.3763 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-11 20:02:02.175 
Epoch 208/1000 
	 loss: 2.3616, MinusLogProbMetric: 2.3616, val_loss: 2.3706, val_MinusLogProbMetric: 2.3706

Epoch 208: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3616 - MinusLogProbMetric: 2.3616 - val_loss: 2.3706 - val_MinusLogProbMetric: 2.3706 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 209/1000
2023-09-11 20:02:13.858 
Epoch 209/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3636, val_MinusLogProbMetric: 2.3636

Epoch 209: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3636 - val_MinusLogProbMetric: 2.3636 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 210/1000
2023-09-11 20:02:25.444 
Epoch 210/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 210: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 211/1000
2023-09-11 20:02:36.960 
Epoch 211/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 211: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 212/1000
2023-09-11 20:02:48.603 
Epoch 212/1000 
	 loss: 2.3606, MinusLogProbMetric: 2.3606, val_loss: 2.3681, val_MinusLogProbMetric: 2.3681

Epoch 212: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3606 - MinusLogProbMetric: 2.3606 - val_loss: 2.3681 - val_MinusLogProbMetric: 2.3681 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 213/1000
2023-09-11 20:03:00.137 
Epoch 213/1000 
	 loss: 2.3601, MinusLogProbMetric: 2.3601, val_loss: 2.3681, val_MinusLogProbMetric: 2.3681

Epoch 213: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3601 - MinusLogProbMetric: 2.3601 - val_loss: 2.3681 - val_MinusLogProbMetric: 2.3681 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 214/1000
2023-09-11 20:03:11.801 
Epoch 214/1000 
	 loss: 2.3606, MinusLogProbMetric: 2.3606, val_loss: 2.3681, val_MinusLogProbMetric: 2.3681

Epoch 214: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3606 - MinusLogProbMetric: 2.3606 - val_loss: 2.3681 - val_MinusLogProbMetric: 2.3681 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 215/1000
2023-09-11 20:03:23.419 
Epoch 215/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 215: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 216/1000
2023-09-11 20:03:34.967 
Epoch 216/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 216: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 217/1000
2023-09-11 20:03:46.512 
Epoch 217/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3677, val_MinusLogProbMetric: 2.3677

Epoch 217: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3677 - val_MinusLogProbMetric: 2.3677 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 218/1000
2023-09-11 20:03:58.020 
Epoch 218/1000 
	 loss: 2.3583, MinusLogProbMetric: 2.3583, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 218: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3583 - MinusLogProbMetric: 2.3583 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 219/1000
2023-09-11 20:04:09.657 
Epoch 219/1000 
	 loss: 2.3608, MinusLogProbMetric: 2.3608, val_loss: 2.3676, val_MinusLogProbMetric: 2.3676

Epoch 219: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3608 - MinusLogProbMetric: 2.3608 - val_loss: 2.3676 - val_MinusLogProbMetric: 2.3676 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 220/1000
2023-09-11 20:04:21.186 
Epoch 220/1000 
	 loss: 2.3604, MinusLogProbMetric: 2.3604, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 220: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3604 - MinusLogProbMetric: 2.3604 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 221/1000
2023-09-11 20:04:32.738 
Epoch 221/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3653, val_MinusLogProbMetric: 2.3653

Epoch 221: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3653 - val_MinusLogProbMetric: 2.3653 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 222/1000
2023-09-11 20:04:44.412 
Epoch 222/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 222: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-11 20:04:56.079 
Epoch 223/1000 
	 loss: 2.3608, MinusLogProbMetric: 2.3608, val_loss: 2.3732, val_MinusLogProbMetric: 2.3732

Epoch 223: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3608 - MinusLogProbMetric: 2.3608 - val_loss: 2.3732 - val_MinusLogProbMetric: 2.3732 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 224/1000
2023-09-11 20:05:07.570 
Epoch 224/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 224: val_loss did not improve from 2.36011
196/196 - 11s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 225/1000
2023-09-11 20:05:19.178 
Epoch 225/1000 
	 loss: 2.3616, MinusLogProbMetric: 2.3616, val_loss: 2.3666, val_MinusLogProbMetric: 2.3666

Epoch 225: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3616 - MinusLogProbMetric: 2.3616 - val_loss: 2.3666 - val_MinusLogProbMetric: 2.3666 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 226/1000
2023-09-11 20:05:30.644 
Epoch 226/1000 
	 loss: 2.3582, MinusLogProbMetric: 2.3582, val_loss: 2.3668, val_MinusLogProbMetric: 2.3668

Epoch 226: val_loss did not improve from 2.36011
196/196 - 11s - loss: 2.3582 - MinusLogProbMetric: 2.3582 - val_loss: 2.3668 - val_MinusLogProbMetric: 2.3668 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 227/1000
2023-09-11 20:05:42.474 
Epoch 227/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3662, val_MinusLogProbMetric: 2.3662

Epoch 227: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3662 - val_MinusLogProbMetric: 2.3662 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 228/1000
2023-09-11 20:05:53.972 
Epoch 228/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 228: val_loss did not improve from 2.36011
196/196 - 11s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 229/1000
2023-09-11 20:06:05.604 
Epoch 229/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3636, val_MinusLogProbMetric: 2.3636

Epoch 229: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3636 - val_MinusLogProbMetric: 2.3636 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 230/1000
2023-09-11 20:06:15.379 
Epoch 230/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 230: val_loss did not improve from 2.36011
196/196 - 10s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 231/1000
2023-09-11 20:06:26.362 
Epoch 231/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 231: val_loss did not improve from 2.36011
196/196 - 11s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 232/1000
2023-09-11 20:06:37.789 
Epoch 232/1000 
	 loss: 2.3613, MinusLogProbMetric: 2.3613, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 232: val_loss did not improve from 2.36011
196/196 - 11s - loss: 2.3613 - MinusLogProbMetric: 2.3613 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 233/1000
2023-09-11 20:06:49.381 
Epoch 233/1000 
	 loss: 2.3584, MinusLogProbMetric: 2.3584, val_loss: 2.3752, val_MinusLogProbMetric: 2.3752

Epoch 233: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3584 - MinusLogProbMetric: 2.3584 - val_loss: 2.3752 - val_MinusLogProbMetric: 2.3752 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 234/1000
2023-09-11 20:07:00.945 
Epoch 234/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3606, val_MinusLogProbMetric: 2.3606

Epoch 234: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3606 - val_MinusLogProbMetric: 2.3606 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 235/1000
2023-09-11 20:07:12.473 
Epoch 235/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 235: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 236/1000
2023-09-11 20:07:24.023 
Epoch 236/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3644, val_MinusLogProbMetric: 2.3644

Epoch 236: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3644 - val_MinusLogProbMetric: 2.3644 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 237/1000
2023-09-11 20:07:35.645 
Epoch 237/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3602, val_MinusLogProbMetric: 2.3602

Epoch 237: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3602 - val_MinusLogProbMetric: 2.3602 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 238/1000
2023-09-11 20:07:47.323 
Epoch 238/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3616, val_MinusLogProbMetric: 2.3616

Epoch 238: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3616 - val_MinusLogProbMetric: 2.3616 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-11 20:07:58.908 
Epoch 239/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 239: val_loss did not improve from 2.36011
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 240/1000
2023-09-11 20:08:10.537 
Epoch 240/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 240: val_loss improved from 2.36011 to 2.35936, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-11 20:08:22.169 
Epoch 241/1000 
	 loss: 2.3553, MinusLogProbMetric: 2.3553, val_loss: 2.3599, val_MinusLogProbMetric: 2.3599

Epoch 241: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3553 - MinusLogProbMetric: 2.3553 - val_loss: 2.3599 - val_MinusLogProbMetric: 2.3599 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 242/1000
2023-09-11 20:08:33.689 
Epoch 242/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3605, val_MinusLogProbMetric: 2.3605

Epoch 242: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3605 - val_MinusLogProbMetric: 2.3605 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 243/1000
2023-09-11 20:08:45.376 
Epoch 243/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3663, val_MinusLogProbMetric: 2.3663

Epoch 243: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3663 - val_MinusLogProbMetric: 2.3663 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 244/1000
2023-09-11 20:08:57.072 
Epoch 244/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 244: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 245/1000
2023-09-11 20:09:08.742 
Epoch 245/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3691, val_MinusLogProbMetric: 2.3691

Epoch 245: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3691 - val_MinusLogProbMetric: 2.3691 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 246/1000
2023-09-11 20:09:20.218 
Epoch 246/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3597, val_MinusLogProbMetric: 2.3597

Epoch 246: val_loss did not improve from 2.35936
196/196 - 11s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3597 - val_MinusLogProbMetric: 2.3597 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 247/1000
2023-09-11 20:09:31.835 
Epoch 247/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 247: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 248/1000
2023-09-11 20:09:43.493 
Epoch 248/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 248: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 249/1000
2023-09-11 20:09:55.162 
Epoch 249/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3606, val_MinusLogProbMetric: 2.3606

Epoch 249: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3606 - val_MinusLogProbMetric: 2.3606 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 250/1000
2023-09-11 20:10:06.691 
Epoch 250/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3643, val_MinusLogProbMetric: 2.3643

Epoch 250: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3643 - val_MinusLogProbMetric: 2.3643 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 251/1000
2023-09-11 20:10:18.255 
Epoch 251/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 251: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 252/1000
2023-09-11 20:10:29.788 
Epoch 252/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 252: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 253/1000
2023-09-11 20:10:41.274 
Epoch 253/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 253: val_loss did not improve from 2.35936
196/196 - 11s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 254/1000
2023-09-11 20:10:52.837 
Epoch 254/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 254: val_loss did not improve from 2.35936
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 255/1000
2023-09-11 20:11:04.411 
Epoch 255/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 255: val_loss improved from 2.35936 to 2.35928, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 256/1000
2023-09-11 20:11:16.053 
Epoch 256/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3600, val_MinusLogProbMetric: 2.3600

Epoch 256: val_loss did not improve from 2.35928
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3600 - val_MinusLogProbMetric: 2.3600 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 257/1000
2023-09-11 20:11:27.676 
Epoch 257/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 257: val_loss did not improve from 2.35928
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 258/1000
2023-09-11 20:11:39.162 
Epoch 258/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 258: val_loss did not improve from 2.35928
196/196 - 11s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 259/1000
2023-09-11 20:11:50.789 
Epoch 259/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 259: val_loss did not improve from 2.35928
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 260/1000
2023-09-11 20:12:02.407 
Epoch 260/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 260: val_loss did not improve from 2.35928
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 261/1000
2023-09-11 20:12:14.018 
Epoch 261/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 261: val_loss did not improve from 2.35928
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 262/1000
2023-09-11 20:12:25.625 
Epoch 262/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3654, val_MinusLogProbMetric: 2.3654

Epoch 262: val_loss did not improve from 2.35928
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3654 - val_MinusLogProbMetric: 2.3654 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 263/1000
2023-09-11 20:12:37.104 
Epoch 263/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 263: val_loss improved from 2.35928 to 2.35898, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 264/1000
2023-09-11 20:12:48.686 
Epoch 264/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3608, val_MinusLogProbMetric: 2.3608

Epoch 264: val_loss did not improve from 2.35898
196/196 - 11s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3608 - val_MinusLogProbMetric: 2.3608 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 265/1000
2023-09-11 20:13:00.205 
Epoch 265/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3611, val_MinusLogProbMetric: 2.3611

Epoch 265: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3611 - val_MinusLogProbMetric: 2.3611 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 266/1000
2023-09-11 20:13:11.787 
Epoch 266/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 266: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 267/1000
2023-09-11 20:13:23.381 
Epoch 267/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3607, val_MinusLogProbMetric: 2.3607

Epoch 267: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3607 - val_MinusLogProbMetric: 2.3607 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 268/1000
2023-09-11 20:13:35.028 
Epoch 268/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 268: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 269/1000
2023-09-11 20:13:46.788 
Epoch 269/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3664, val_MinusLogProbMetric: 2.3664

Epoch 269: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3664 - val_MinusLogProbMetric: 2.3664 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 270/1000
2023-09-11 20:13:58.379 
Epoch 270/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 270: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 271/1000
2023-09-11 20:14:09.943 
Epoch 271/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 271: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 272/1000
2023-09-11 20:14:21.602 
Epoch 272/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3648, val_MinusLogProbMetric: 2.3648

Epoch 272: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3648 - val_MinusLogProbMetric: 2.3648 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 273/1000
2023-09-11 20:14:33.224 
Epoch 273/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 273: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 274/1000
2023-09-11 20:14:44.839 
Epoch 274/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 274: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 275/1000
2023-09-11 20:14:56.447 
Epoch 275/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 275: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 276/1000
2023-09-11 20:15:08.057 
Epoch 276/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 276: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 277/1000
2023-09-11 20:15:19.613 
Epoch 277/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3602, val_MinusLogProbMetric: 2.3602

Epoch 277: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3602 - val_MinusLogProbMetric: 2.3602 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 278/1000
2023-09-11 20:15:31.229 
Epoch 278/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3609, val_MinusLogProbMetric: 2.3609

Epoch 278: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3609 - val_MinusLogProbMetric: 2.3609 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 279/1000
2023-09-11 20:15:42.875 
Epoch 279/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 279: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 280/1000
2023-09-11 20:15:54.434 
Epoch 280/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 280: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 281/1000
2023-09-11 20:16:06.067 
Epoch 281/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3605, val_MinusLogProbMetric: 2.3605

Epoch 281: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3605 - val_MinusLogProbMetric: 2.3605 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 282/1000
2023-09-11 20:16:17.694 
Epoch 282/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 282: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 283/1000
2023-09-11 20:16:29.209 
Epoch 283/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3657, val_MinusLogProbMetric: 2.3657

Epoch 283: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3657 - val_MinusLogProbMetric: 2.3657 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 284/1000
2023-09-11 20:16:40.867 
Epoch 284/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 284: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 285/1000
2023-09-11 20:16:52.538 
Epoch 285/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3648, val_MinusLogProbMetric: 2.3648

Epoch 285: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3648 - val_MinusLogProbMetric: 2.3648 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 286/1000
2023-09-11 20:17:04.249 
Epoch 286/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 286: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 287/1000
2023-09-11 20:17:15.788 
Epoch 287/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 287: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 288/1000
2023-09-11 20:17:27.359 
Epoch 288/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 288: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 289/1000
2023-09-11 20:17:38.927 
Epoch 289/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 289: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 290/1000
2023-09-11 20:17:50.464 
Epoch 290/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 290: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 291/1000
2023-09-11 20:18:01.910 
Epoch 291/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 291: val_loss did not improve from 2.35898
196/196 - 11s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 292/1000
2023-09-11 20:18:13.513 
Epoch 292/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 292: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 293/1000
2023-09-11 20:18:25.132 
Epoch 293/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3611, val_MinusLogProbMetric: 2.3611

Epoch 293: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3611 - val_MinusLogProbMetric: 2.3611 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 294/1000
2023-09-11 20:18:36.650 
Epoch 294/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3611, val_MinusLogProbMetric: 2.3611

Epoch 294: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3611 - val_MinusLogProbMetric: 2.3611 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 295/1000
2023-09-11 20:18:48.207 
Epoch 295/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3604, val_MinusLogProbMetric: 2.3604

Epoch 295: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3604 - val_MinusLogProbMetric: 2.3604 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 296/1000
2023-09-11 20:18:59.695 
Epoch 296/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 296: val_loss did not improve from 2.35898
196/196 - 11s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 297/1000
2023-09-11 20:19:11.199 
Epoch 297/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 297: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 298/1000
2023-09-11 20:19:22.831 
Epoch 298/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 298: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 299/1000
2023-09-11 20:19:34.344 
Epoch 299/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3604, val_MinusLogProbMetric: 2.3604

Epoch 299: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3604 - val_MinusLogProbMetric: 2.3604 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 300/1000
2023-09-11 20:19:45.842 
Epoch 300/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 300: val_loss did not improve from 2.35898
196/196 - 11s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 301/1000
2023-09-11 20:19:57.420 
Epoch 301/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3597, val_MinusLogProbMetric: 2.3597

Epoch 301: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3597 - val_MinusLogProbMetric: 2.3597 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 302/1000
2023-09-11 20:20:08.989 
Epoch 302/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3620, val_MinusLogProbMetric: 2.3620

Epoch 302: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3620 - val_MinusLogProbMetric: 2.3620 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 303/1000
2023-09-11 20:20:20.673 
Epoch 303/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 303: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 304/1000
2023-09-11 20:20:32.263 
Epoch 304/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3660, val_MinusLogProbMetric: 2.3660

Epoch 304: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3660 - val_MinusLogProbMetric: 2.3660 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 305/1000
2023-09-11 20:20:43.836 
Epoch 305/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 305: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 306/1000
2023-09-11 20:20:55.380 
Epoch 306/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 306: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 307/1000
2023-09-11 20:21:06.937 
Epoch 307/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3607, val_MinusLogProbMetric: 2.3607

Epoch 307: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3607 - val_MinusLogProbMetric: 2.3607 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 308/1000
2023-09-11 20:21:18.503 
Epoch 308/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 308: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 309/1000
2023-09-11 20:21:30.121 
Epoch 309/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 309: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 310/1000
2023-09-11 20:21:41.695 
Epoch 310/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 310: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 311/1000
2023-09-11 20:21:53.240 
Epoch 311/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3643, val_MinusLogProbMetric: 2.3643

Epoch 311: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3643 - val_MinusLogProbMetric: 2.3643 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 312/1000
2023-09-11 20:22:04.874 
Epoch 312/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 312: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 313/1000
2023-09-11 20:22:16.444 
Epoch 313/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 313: val_loss did not improve from 2.35898
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 314/1000
2023-09-11 20:22:27.993 
Epoch 314/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 314: val_loss improved from 2.35898 to 2.35895, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 315/1000
2023-09-11 20:22:39.755 
Epoch 315/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 315: val_loss did not improve from 2.35895
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-11 20:22:51.291 
Epoch 316/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 316: val_loss improved from 2.35895 to 2.35870, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 317/1000
2023-09-11 20:23:03.051 
Epoch 317/1000 
	 loss: 2.3510, MinusLogProbMetric: 2.3510, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 317: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3510 - MinusLogProbMetric: 2.3510 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 318/1000
2023-09-11 20:23:14.645 
Epoch 318/1000 
	 loss: 2.3510, MinusLogProbMetric: 2.3510, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 318: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3510 - MinusLogProbMetric: 2.3510 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 319/1000
2023-09-11 20:23:26.234 
Epoch 319/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 319: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 320/1000
2023-09-11 20:23:37.908 
Epoch 320/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 320: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 321/1000
2023-09-11 20:23:49.590 
Epoch 321/1000 
	 loss: 2.3511, MinusLogProbMetric: 2.3511, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 321: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3511 - MinusLogProbMetric: 2.3511 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 322/1000
2023-09-11 20:24:01.230 
Epoch 322/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3615, val_MinusLogProbMetric: 2.3615

Epoch 322: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3615 - val_MinusLogProbMetric: 2.3615 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 323/1000
2023-09-11 20:24:12.780 
Epoch 323/1000 
	 loss: 2.3511, MinusLogProbMetric: 2.3511, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 323: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3511 - MinusLogProbMetric: 2.3511 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 324/1000
2023-09-11 20:24:24.445 
Epoch 324/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 324: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 325/1000
2023-09-11 20:24:35.963 
Epoch 325/1000 
	 loss: 2.3504, MinusLogProbMetric: 2.3504, val_loss: 2.3614, val_MinusLogProbMetric: 2.3614

Epoch 325: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3504 - MinusLogProbMetric: 2.3504 - val_loss: 2.3614 - val_MinusLogProbMetric: 2.3614 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 326/1000
2023-09-11 20:24:47.652 
Epoch 326/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 326: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-11 20:24:59.302 
Epoch 327/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3602, val_MinusLogProbMetric: 2.3602

Epoch 327: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3602 - val_MinusLogProbMetric: 2.3602 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 328/1000
2023-09-11 20:25:10.885 
Epoch 328/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 328: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 329/1000
2023-09-11 20:25:22.469 
Epoch 329/1000 
	 loss: 2.3503, MinusLogProbMetric: 2.3503, val_loss: 2.3595, val_MinusLogProbMetric: 2.3595

Epoch 329: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3503 - MinusLogProbMetric: 2.3503 - val_loss: 2.3595 - val_MinusLogProbMetric: 2.3595 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 330/1000
2023-09-11 20:25:34.077 
Epoch 330/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 330: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 331/1000
2023-09-11 20:25:45.799 
Epoch 331/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 331: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 332/1000
2023-09-11 20:25:57.313 
Epoch 332/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3603, val_MinusLogProbMetric: 2.3603

Epoch 332: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3603 - val_MinusLogProbMetric: 2.3603 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 333/1000
2023-09-11 20:26:08.870 
Epoch 333/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 333: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 334/1000
2023-09-11 20:26:20.521 
Epoch 334/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 334: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 335/1000
2023-09-11 20:26:32.053 
Epoch 335/1000 
	 loss: 2.3512, MinusLogProbMetric: 2.3512, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 335: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3512 - MinusLogProbMetric: 2.3512 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 336/1000
2023-09-11 20:26:43.650 
Epoch 336/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 336: val_loss did not improve from 2.35870
196/196 - 12s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 337/1000
2023-09-11 20:26:55.387 
Epoch 337/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 337: val_loss improved from 2.35870 to 2.35861, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 338/1000
2023-09-11 20:27:07.120 
Epoch 338/1000 
	 loss: 2.3505, MinusLogProbMetric: 2.3505, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 338: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3505 - MinusLogProbMetric: 2.3505 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 339/1000
2023-09-11 20:27:18.713 
Epoch 339/1000 
	 loss: 2.3503, MinusLogProbMetric: 2.3503, val_loss: 2.3609, val_MinusLogProbMetric: 2.3609

Epoch 339: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3503 - MinusLogProbMetric: 2.3503 - val_loss: 2.3609 - val_MinusLogProbMetric: 2.3609 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 340/1000
2023-09-11 20:27:30.276 
Epoch 340/1000 
	 loss: 2.3513, MinusLogProbMetric: 2.3513, val_loss: 2.3605, val_MinusLogProbMetric: 2.3605

Epoch 340: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3513 - MinusLogProbMetric: 2.3513 - val_loss: 2.3605 - val_MinusLogProbMetric: 2.3605 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 341/1000
2023-09-11 20:27:42.054 
Epoch 341/1000 
	 loss: 2.3505, MinusLogProbMetric: 2.3505, val_loss: 2.3599, val_MinusLogProbMetric: 2.3599

Epoch 341: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3505 - MinusLogProbMetric: 2.3505 - val_loss: 2.3599 - val_MinusLogProbMetric: 2.3599 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 342/1000
2023-09-11 20:27:53.741 
Epoch 342/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 342: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-11 20:28:05.602 
Epoch 343/1000 
	 loss: 2.3503, MinusLogProbMetric: 2.3503, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 343: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3503 - MinusLogProbMetric: 2.3503 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 344/1000
2023-09-11 20:28:17.263 
Epoch 344/1000 
	 loss: 2.3503, MinusLogProbMetric: 2.3503, val_loss: 2.3605, val_MinusLogProbMetric: 2.3605

Epoch 344: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3503 - MinusLogProbMetric: 2.3503 - val_loss: 2.3605 - val_MinusLogProbMetric: 2.3605 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 345/1000
2023-09-11 20:28:28.936 
Epoch 345/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 345: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 346/1000
2023-09-11 20:28:40.608 
Epoch 346/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3610, val_MinusLogProbMetric: 2.3610

Epoch 346: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3610 - val_MinusLogProbMetric: 2.3610 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 347/1000
2023-09-11 20:28:52.344 
Epoch 347/1000 
	 loss: 2.3502, MinusLogProbMetric: 2.3502, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 347: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3502 - MinusLogProbMetric: 2.3502 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 348/1000
2023-09-11 20:29:03.964 
Epoch 348/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 348: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 349/1000
2023-09-11 20:29:15.613 
Epoch 349/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 349: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 350/1000
2023-09-11 20:29:27.215 
Epoch 350/1000 
	 loss: 2.3503, MinusLogProbMetric: 2.3503, val_loss: 2.3600, val_MinusLogProbMetric: 2.3600

Epoch 350: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3503 - MinusLogProbMetric: 2.3503 - val_loss: 2.3600 - val_MinusLogProbMetric: 2.3600 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 351/1000
2023-09-11 20:29:38.838 
Epoch 351/1000 
	 loss: 2.3504, MinusLogProbMetric: 2.3504, val_loss: 2.3607, val_MinusLogProbMetric: 2.3607

Epoch 351: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3504 - MinusLogProbMetric: 2.3504 - val_loss: 2.3607 - val_MinusLogProbMetric: 2.3607 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 352/1000
2023-09-11 20:29:50.671 
Epoch 352/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3609, val_MinusLogProbMetric: 2.3609

Epoch 352: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3609 - val_MinusLogProbMetric: 2.3609 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 353/1000
2023-09-11 20:30:02.395 
Epoch 353/1000 
	 loss: 2.3506, MinusLogProbMetric: 2.3506, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 353: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3506 - MinusLogProbMetric: 2.3506 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 354/1000
2023-09-11 20:30:14.105 
Epoch 354/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 354: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 355/1000
2023-09-11 20:30:25.772 
Epoch 355/1000 
	 loss: 2.3504, MinusLogProbMetric: 2.3504, val_loss: 2.3613, val_MinusLogProbMetric: 2.3613

Epoch 355: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3504 - MinusLogProbMetric: 2.3504 - val_loss: 2.3613 - val_MinusLogProbMetric: 2.3613 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 356/1000
2023-09-11 20:30:37.536 
Epoch 356/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 356: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 357/1000
2023-09-11 20:30:49.165 
Epoch 357/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3621, val_MinusLogProbMetric: 2.3621

Epoch 357: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3621 - val_MinusLogProbMetric: 2.3621 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 358/1000
2023-09-11 20:31:00.738 
Epoch 358/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 358: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 359/1000
2023-09-11 20:31:12.419 
Epoch 359/1000 
	 loss: 2.3502, MinusLogProbMetric: 2.3502, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 359: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3502 - MinusLogProbMetric: 2.3502 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 360/1000
2023-09-11 20:31:24.188 
Epoch 360/1000 
	 loss: 2.3508, MinusLogProbMetric: 2.3508, val_loss: 2.3595, val_MinusLogProbMetric: 2.3595

Epoch 360: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3508 - MinusLogProbMetric: 2.3508 - val_loss: 2.3595 - val_MinusLogProbMetric: 2.3595 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 361/1000
2023-09-11 20:31:35.863 
Epoch 361/1000 
	 loss: 2.3502, MinusLogProbMetric: 2.3502, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 361: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3502 - MinusLogProbMetric: 2.3502 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 362/1000
2023-09-11 20:31:47.690 
Epoch 362/1000 
	 loss: 2.3503, MinusLogProbMetric: 2.3503, val_loss: 2.3605, val_MinusLogProbMetric: 2.3605

Epoch 362: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3503 - MinusLogProbMetric: 2.3503 - val_loss: 2.3605 - val_MinusLogProbMetric: 2.3605 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 363/1000
2023-09-11 20:31:59.610 
Epoch 363/1000 
	 loss: 2.3502, MinusLogProbMetric: 2.3502, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 363: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3502 - MinusLogProbMetric: 2.3502 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 364/1000
2023-09-11 20:32:11.441 
Epoch 364/1000 
	 loss: 2.3507, MinusLogProbMetric: 2.3507, val_loss: 2.3606, val_MinusLogProbMetric: 2.3606

Epoch 364: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3507 - MinusLogProbMetric: 2.3507 - val_loss: 2.3606 - val_MinusLogProbMetric: 2.3606 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 365/1000
2023-09-11 20:32:23.102 
Epoch 365/1000 
	 loss: 2.3505, MinusLogProbMetric: 2.3505, val_loss: 2.3595, val_MinusLogProbMetric: 2.3595

Epoch 365: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3505 - MinusLogProbMetric: 2.3505 - val_loss: 2.3595 - val_MinusLogProbMetric: 2.3595 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 366/1000
2023-09-11 20:32:34.876 
Epoch 366/1000 
	 loss: 2.3509, MinusLogProbMetric: 2.3509, val_loss: 2.3599, val_MinusLogProbMetric: 2.3599

Epoch 366: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3509 - MinusLogProbMetric: 2.3509 - val_loss: 2.3599 - val_MinusLogProbMetric: 2.3599 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 367/1000
2023-09-11 20:32:46.392 
Epoch 367/1000 
	 loss: 2.3495, MinusLogProbMetric: 2.3495, val_loss: 2.3595, val_MinusLogProbMetric: 2.3595

Epoch 367: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3495 - MinusLogProbMetric: 2.3495 - val_loss: 2.3595 - val_MinusLogProbMetric: 2.3595 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 368/1000
2023-09-11 20:32:57.897 
Epoch 368/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 368: val_loss did not improve from 2.35861
196/196 - 11s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 6.2500e-05 - 11s/epoch - 59ms/step
Epoch 369/1000
2023-09-11 20:33:09.492 
Epoch 369/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3597, val_MinusLogProbMetric: 2.3597

Epoch 369: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3597 - val_MinusLogProbMetric: 2.3597 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 370/1000
2023-09-11 20:33:21.155 
Epoch 370/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 370: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 371/1000
2023-09-11 20:33:32.926 
Epoch 371/1000 
	 loss: 2.3492, MinusLogProbMetric: 2.3492, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 371: val_loss did not improve from 2.35861
196/196 - 12s - loss: 2.3492 - MinusLogProbMetric: 2.3492 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 372/1000
2023-09-11 20:33:44.560 
Epoch 372/1000 
	 loss: 2.3492, MinusLogProbMetric: 2.3492, val_loss: 2.3584, val_MinusLogProbMetric: 2.3584

Epoch 372: val_loss improved from 2.35861 to 2.35838, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3492 - MinusLogProbMetric: 2.3492 - val_loss: 2.3584 - val_MinusLogProbMetric: 2.3584 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 373/1000
2023-09-11 20:33:56.392 
Epoch 373/1000 
	 loss: 2.3494, MinusLogProbMetric: 2.3494, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 373: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3494 - MinusLogProbMetric: 2.3494 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 374/1000
2023-09-11 20:34:08.042 
Epoch 374/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3584, val_MinusLogProbMetric: 2.3584

Epoch 374: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3584 - val_MinusLogProbMetric: 2.3584 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 375/1000
2023-09-11 20:34:19.727 
Epoch 375/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 375: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 376/1000
2023-09-11 20:34:31.528 
Epoch 376/1000 
	 loss: 2.3492, MinusLogProbMetric: 2.3492, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 376: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3492 - MinusLogProbMetric: 2.3492 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-11 20:34:43.100 
Epoch 377/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3595, val_MinusLogProbMetric: 2.3595

Epoch 377: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3595 - val_MinusLogProbMetric: 2.3595 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 378/1000
2023-09-11 20:34:54.958 
Epoch 378/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3600, val_MinusLogProbMetric: 2.3600

Epoch 378: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3600 - val_MinusLogProbMetric: 2.3600 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 379/1000
2023-09-11 20:35:06.630 
Epoch 379/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 379: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-11 20:35:18.481 
Epoch 380/1000 
	 loss: 2.3492, MinusLogProbMetric: 2.3492, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 380: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3492 - MinusLogProbMetric: 2.3492 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 381/1000
2023-09-11 20:35:30.291 
Epoch 381/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 381: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 382/1000
2023-09-11 20:35:42.033 
Epoch 382/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 382: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 383/1000
2023-09-11 20:35:53.570 
Epoch 383/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 383: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 384/1000
2023-09-11 20:36:05.153 
Epoch 384/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 384: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 385/1000
2023-09-11 20:36:16.988 
Epoch 385/1000 
	 loss: 2.3492, MinusLogProbMetric: 2.3492, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 385: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3492 - MinusLogProbMetric: 2.3492 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 386/1000
2023-09-11 20:36:28.659 
Epoch 386/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 386: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 387/1000
2023-09-11 20:36:40.228 
Epoch 387/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3584, val_MinusLogProbMetric: 2.3584

Epoch 387: val_loss did not improve from 2.35838
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3584 - val_MinusLogProbMetric: 2.3584 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 388/1000
2023-09-11 20:36:51.909 
Epoch 388/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3583, val_MinusLogProbMetric: 2.3583

Epoch 388: val_loss improved from 2.35838 to 2.35830, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3583 - val_MinusLogProbMetric: 2.3583 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 389/1000
2023-09-11 20:37:03.695 
Epoch 389/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 389: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 390/1000
2023-09-11 20:37:15.343 
Epoch 390/1000 
	 loss: 2.3493, MinusLogProbMetric: 2.3493, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 390: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3493 - MinusLogProbMetric: 2.3493 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 391/1000
2023-09-11 20:37:26.974 
Epoch 391/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 391: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 392/1000
2023-09-11 20:37:38.596 
Epoch 392/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3598, val_MinusLogProbMetric: 2.3598

Epoch 392: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3598 - val_MinusLogProbMetric: 2.3598 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 393/1000
2023-09-11 20:37:50.241 
Epoch 393/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3602, val_MinusLogProbMetric: 2.3602

Epoch 393: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3602 - val_MinusLogProbMetric: 2.3602 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 394/1000
2023-09-11 20:38:01.820 
Epoch 394/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 394: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 395/1000
2023-09-11 20:38:13.468 
Epoch 395/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3612, val_MinusLogProbMetric: 2.3612

Epoch 395: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3612 - val_MinusLogProbMetric: 2.3612 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 396/1000
2023-09-11 20:38:24.910 
Epoch 396/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 396: val_loss did not improve from 2.35830
196/196 - 11s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 397/1000
2023-09-11 20:38:36.555 
Epoch 397/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3585, val_MinusLogProbMetric: 2.3585

Epoch 397: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3585 - val_MinusLogProbMetric: 2.3585 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 398/1000
2023-09-11 20:38:48.193 
Epoch 398/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3602, val_MinusLogProbMetric: 2.3602

Epoch 398: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3602 - val_MinusLogProbMetric: 2.3602 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 399/1000
2023-09-11 20:38:59.857 
Epoch 399/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 399: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 400/1000
2023-09-11 20:39:11.513 
Epoch 400/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 400: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 401/1000
2023-09-11 20:39:23.045 
Epoch 401/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 401: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 402/1000
2023-09-11 20:39:34.656 
Epoch 402/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 402: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 403/1000
2023-09-11 20:39:46.174 
Epoch 403/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3602, val_MinusLogProbMetric: 2.3602

Epoch 403: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3602 - val_MinusLogProbMetric: 2.3602 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 404/1000
2023-09-11 20:39:57.765 
Epoch 404/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 404: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 405/1000
2023-09-11 20:40:09.288 
Epoch 405/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3597, val_MinusLogProbMetric: 2.3597

Epoch 405: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3597 - val_MinusLogProbMetric: 2.3597 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 406/1000
2023-09-11 20:40:20.806 
Epoch 406/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 406: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 407/1000
2023-09-11 20:40:32.420 
Epoch 407/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3618, val_MinusLogProbMetric: 2.3618

Epoch 407: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3618 - val_MinusLogProbMetric: 2.3618 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 408/1000
2023-09-11 20:40:44.118 
Epoch 408/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3603, val_MinusLogProbMetric: 2.3603

Epoch 408: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3603 - val_MinusLogProbMetric: 2.3603 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 409/1000
2023-09-11 20:40:55.742 
Epoch 409/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 409: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 410/1000
2023-09-11 20:41:07.417 
Epoch 410/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3595, val_MinusLogProbMetric: 2.3595

Epoch 410: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3595 - val_MinusLogProbMetric: 2.3595 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 411/1000
2023-09-11 20:41:19.016 
Epoch 411/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 411: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 412/1000
2023-09-11 20:41:30.635 
Epoch 412/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 412: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 413/1000
2023-09-11 20:41:42.323 
Epoch 413/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 413: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 414/1000
2023-09-11 20:41:53.939 
Epoch 414/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 414: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 415/1000
2023-09-11 20:42:05.653 
Epoch 415/1000 
	 loss: 2.3489, MinusLogProbMetric: 2.3489, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 415: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3489 - MinusLogProbMetric: 2.3489 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 416/1000
2023-09-11 20:42:17.210 
Epoch 416/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3597, val_MinusLogProbMetric: 2.3597

Epoch 416: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3597 - val_MinusLogProbMetric: 2.3597 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 417/1000
2023-09-11 20:42:28.907 
Epoch 417/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 417: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-11 20:42:40.443 
Epoch 418/1000 
	 loss: 2.3490, MinusLogProbMetric: 2.3490, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 418: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3490 - MinusLogProbMetric: 2.3490 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 419/1000
2023-09-11 20:42:52.032 
Epoch 419/1000 
	 loss: 2.3486, MinusLogProbMetric: 2.3486, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 419: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3486 - MinusLogProbMetric: 2.3486 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 420/1000
2023-09-11 20:43:03.654 
Epoch 420/1000 
	 loss: 2.3491, MinusLogProbMetric: 2.3491, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 420: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3491 - MinusLogProbMetric: 2.3491 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 421/1000
2023-09-11 20:43:15.277 
Epoch 421/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 421: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 422/1000
2023-09-11 20:43:26.966 
Epoch 422/1000 
	 loss: 2.3488, MinusLogProbMetric: 2.3488, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 422: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3488 - MinusLogProbMetric: 2.3488 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 423/1000
2023-09-11 20:43:38.711 
Epoch 423/1000 
	 loss: 2.3483, MinusLogProbMetric: 2.3483, val_loss: 2.3592, val_MinusLogProbMetric: 2.3592

Epoch 423: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3483 - MinusLogProbMetric: 2.3483 - val_loss: 2.3592 - val_MinusLogProbMetric: 2.3592 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 424/1000
2023-09-11 20:43:50.279 
Epoch 424/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 424: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 425/1000
2023-09-11 20:44:01.816 
Epoch 425/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 425: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 426/1000
2023-09-11 20:44:13.349 
Epoch 426/1000 
	 loss: 2.3483, MinusLogProbMetric: 2.3483, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 426: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3483 - MinusLogProbMetric: 2.3483 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 427/1000
2023-09-11 20:44:24.932 
Epoch 427/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 427: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 428/1000
2023-09-11 20:44:36.467 
Epoch 428/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 428: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 429/1000
2023-09-11 20:44:48.033 
Epoch 429/1000 
	 loss: 2.3483, MinusLogProbMetric: 2.3483, val_loss: 2.3585, val_MinusLogProbMetric: 2.3585

Epoch 429: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3483 - MinusLogProbMetric: 2.3483 - val_loss: 2.3585 - val_MinusLogProbMetric: 2.3585 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 430/1000
2023-09-11 20:44:59.643 
Epoch 430/1000 
	 loss: 2.3483, MinusLogProbMetric: 2.3483, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 430: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3483 - MinusLogProbMetric: 2.3483 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 431/1000
2023-09-11 20:45:11.352 
Epoch 431/1000 
	 loss: 2.3483, MinusLogProbMetric: 2.3483, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 431: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3483 - MinusLogProbMetric: 2.3483 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 432/1000
2023-09-11 20:45:22.963 
Epoch 432/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3596, val_MinusLogProbMetric: 2.3596

Epoch 432: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3596 - val_MinusLogProbMetric: 2.3596 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 433/1000
2023-09-11 20:45:34.519 
Epoch 433/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 433: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 434/1000
2023-09-11 20:45:46.145 
Epoch 434/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 434: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 435/1000
2023-09-11 20:45:57.696 
Epoch 435/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 435: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 436/1000
2023-09-11 20:46:09.149 
Epoch 436/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 436: val_loss did not improve from 2.35830
196/196 - 11s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 3.1250e-05 - 11s/epoch - 58ms/step
Epoch 437/1000
2023-09-11 20:46:20.813 
Epoch 437/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 437: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 438/1000
2023-09-11 20:46:32.358 
Epoch 438/1000 
	 loss: 2.3480, MinusLogProbMetric: 2.3480, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 438: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3480 - MinusLogProbMetric: 2.3480 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 439/1000
2023-09-11 20:46:44.105 
Epoch 439/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 439: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-11 20:46:55.855 
Epoch 440/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 440: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 441/1000
2023-09-11 20:47:07.541 
Epoch 441/1000 
	 loss: 2.3483, MinusLogProbMetric: 2.3483, val_loss: 2.3585, val_MinusLogProbMetric: 2.3585

Epoch 441: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3483 - MinusLogProbMetric: 2.3483 - val_loss: 2.3585 - val_MinusLogProbMetric: 2.3585 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 442/1000
2023-09-11 20:47:19.062 
Epoch 442/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 442: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 443/1000
2023-09-11 20:47:30.688 
Epoch 443/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3585, val_MinusLogProbMetric: 2.3585

Epoch 443: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3585 - val_MinusLogProbMetric: 2.3585 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 444/1000
2023-09-11 20:47:42.212 
Epoch 444/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 444: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 445/1000
2023-09-11 20:47:53.771 
Epoch 445/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 445: val_loss did not improve from 2.35830
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 446/1000
2023-09-11 20:48:05.313 
Epoch 446/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3583, val_MinusLogProbMetric: 2.3583

Epoch 446: val_loss improved from 2.35830 to 2.35828, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_20/weights/best_weights.h5
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3583 - val_MinusLogProbMetric: 2.3583 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 447/1000
2023-09-11 20:48:16.955 
Epoch 447/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3601, val_MinusLogProbMetric: 2.3601

Epoch 447: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3601 - val_MinusLogProbMetric: 2.3601 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 448/1000
2023-09-11 20:48:28.697 
Epoch 448/1000 
	 loss: 2.3480, MinusLogProbMetric: 2.3480, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 448: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3480 - MinusLogProbMetric: 2.3480 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 449/1000
2023-09-11 20:48:40.265 
Epoch 449/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 449: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 450/1000
2023-09-11 20:48:51.845 
Epoch 450/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3585, val_MinusLogProbMetric: 2.3585

Epoch 450: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3585 - val_MinusLogProbMetric: 2.3585 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 451/1000
2023-09-11 20:49:03.448 
Epoch 451/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 451: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 452/1000
2023-09-11 20:49:15.070 
Epoch 452/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3591, val_MinusLogProbMetric: 2.3591

Epoch 452: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3591 - val_MinusLogProbMetric: 2.3591 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 453/1000
2023-09-11 20:49:26.461 
Epoch 453/1000 
	 loss: 2.3480, MinusLogProbMetric: 2.3480, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 453: val_loss did not improve from 2.35828
196/196 - 11s - loss: 2.3480 - MinusLogProbMetric: 2.3480 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 11s/epoch - 58ms/step
Epoch 454/1000
2023-09-11 20:49:37.597 
Epoch 454/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 454: val_loss did not improve from 2.35828
196/196 - 11s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 3.1250e-05 - 11s/epoch - 57ms/step
Epoch 455/1000
2023-09-11 20:49:48.951 
Epoch 455/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 455: val_loss did not improve from 2.35828
196/196 - 11s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 3.1250e-05 - 11s/epoch - 58ms/step
Epoch 456/1000
2023-09-11 20:49:59.829 
Epoch 456/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3597, val_MinusLogProbMetric: 2.3597

Epoch 456: val_loss did not improve from 2.35828
196/196 - 11s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3597 - val_MinusLogProbMetric: 2.3597 - lr: 3.1250e-05 - 11s/epoch - 55ms/step
Epoch 457/1000
2023-09-11 20:50:11.395 
Epoch 457/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 457: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 458/1000
2023-09-11 20:50:23.041 
Epoch 458/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 458: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 459/1000
2023-09-11 20:50:34.559 
Epoch 459/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 459: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 460/1000
2023-09-11 20:50:46.190 
Epoch 460/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 460: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 461/1000
2023-09-11 20:50:57.856 
Epoch 461/1000 
	 loss: 2.3483, MinusLogProbMetric: 2.3483, val_loss: 2.3594, val_MinusLogProbMetric: 2.3594

Epoch 461: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3483 - MinusLogProbMetric: 2.3483 - val_loss: 2.3594 - val_MinusLogProbMetric: 2.3594 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 462/1000
2023-09-11 20:51:09.444 
Epoch 462/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 462: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 463/1000
2023-09-11 20:51:21.022 
Epoch 463/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3593, val_MinusLogProbMetric: 2.3593

Epoch 463: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3593 - val_MinusLogProbMetric: 2.3593 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 464/1000
2023-09-11 20:51:32.511 
Epoch 464/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 464: val_loss did not improve from 2.35828
196/196 - 11s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 11s/epoch - 59ms/step
Epoch 465/1000
2023-09-11 20:51:44.064 
Epoch 465/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3588, val_MinusLogProbMetric: 2.3588

Epoch 465: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3588 - val_MinusLogProbMetric: 2.3588 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 466/1000
2023-09-11 20:51:55.566 
Epoch 466/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3589, val_MinusLogProbMetric: 2.3589

Epoch 466: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3589 - val_MinusLogProbMetric: 2.3589 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 467/1000
2023-09-11 20:52:07.156 
Epoch 467/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3585, val_MinusLogProbMetric: 2.3585

Epoch 467: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3585 - val_MinusLogProbMetric: 2.3585 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 468/1000
2023-09-11 20:52:18.886 
Epoch 468/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3590, val_MinusLogProbMetric: 2.3590

Epoch 468: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3590 - val_MinusLogProbMetric: 2.3590 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 469/1000
2023-09-11 20:52:30.706 
Epoch 469/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3587, val_MinusLogProbMetric: 2.3587

Epoch 469: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3587 - val_MinusLogProbMetric: 2.3587 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 470/1000
2023-09-11 20:52:42.400 
Epoch 470/1000 
	 loss: 2.3482, MinusLogProbMetric: 2.3482, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 470: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3482 - MinusLogProbMetric: 2.3482 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 471/1000
2023-09-11 20:52:54.064 
Epoch 471/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3585, val_MinusLogProbMetric: 2.3585

Epoch 471: val_loss did not improve from 2.35828
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3585 - val_MinusLogProbMetric: 2.3585 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 472/1000
2023-09-11 20:53:05.630 
Epoch 472/1000 
	 loss: 2.3481, MinusLogProbMetric: 2.3481, val_loss: 2.3586, val_MinusLogProbMetric: 2.3586

Epoch 472: val_loss did not improve from 2.35828
Restoring model weights from the end of the best epoch: 372.
196/196 - 12s - loss: 2.3481 - MinusLogProbMetric: 2.3481 - val_loss: 2.3586 - val_MinusLogProbMetric: 2.3586 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 472: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.435089727980085 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.352719304035418 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.8966952040791512 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 4.018555898917839 seconds.
Training succeeded with seed 520.
Model trained in 5491.16 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 18.56 s.
Plots done in 2.89 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 21.45 s.
===========
Run 20/360 done in 5513.91 s.
===========

Directory ../../results/MsplineN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

===========
Generating train data for run 26.
===========
Train data generated in 0.26 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_26/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 721}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_26/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.199659 ,  6.4188223,  4.7532644, 10.006012 ],
       [ 4.22245  ,  5.9659095,  3.7776601,  8.343435 ],
       [ 9.615707 ,  5.49844  ,  7.495583 ,  5.135999 ],
       ...,
       [ 4.2172456,  6.201409 ,  3.6995027,  8.806188 ],
       [ 4.2722325,  7.532345 ,  4.6026692, 11.134918 ],
       [ 4.2096395,  6.545041 ,  4.8637457, 11.02672  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_26/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_26
self.data_kwargs: {'seed': 721}
self.x_data: [[ 5.4491744  7.62697    6.0819464  5.4084225]
 [ 4.24566    6.916348   4.558419   8.932697 ]
 [ 4.226888   5.056197   4.516181  10.139818 ]
 ...
 [ 4.2480607  5.082196   4.7570243  8.905375 ]
 [ 4.2314844  5.8616033  4.122643   8.593621 ]
 [ 4.252966   5.7376084  4.335346   9.082314 ]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 4)]               0         
                                                                 
 log_prob_layer_3 (LogProbLa  (None,)                  313016    
 yer)                                                            
                                                                 
=================================================================
Total params: 313,016
Trainable params: 313,016
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_3/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_3'")
self.model: <keras.engine.functional.Functional object at 0x7fc81c53b880>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc7fc65d6f0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc7fc65d6f0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc81c54dff0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc81c303310>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc81c302e90>, <keras.callbacks.ModelCheckpoint object at 0x7fc81c3027d0>, <keras.callbacks.EarlyStopping object at 0x7fc81c302380>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc81c302350>, <keras.callbacks.TerminateOnNaN object at 0x7fc81c302f20>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.199659 ,  6.4188223,  4.7532644, 10.006012 ],
       [ 4.22245  ,  5.9659095,  3.7776601,  8.343435 ],
       [ 9.615707 ,  5.49844  ,  7.495583 ,  5.135999 ],
       ...,
       [ 4.2172456,  6.201409 ,  3.6995027,  8.806188 ],
       [ 4.2722325,  7.532345 ,  4.6026692, 11.134918 ],
       [ 4.2096395,  6.545041 ,  4.8637457, 11.02672  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_26/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 26/360 with hyperparameters:
timestamp = 2023-09-11 20:53:28.680288
ndims = 4
seed_train = 721
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 313016
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.4491744 7.62697   6.0819464 5.4084225]
Epoch 1/1000
2023-09-11 20:53:59.596 
Epoch 1/1000 
	 loss: 6.4125, MinusLogProbMetric: 6.4125, val_loss: 5.6274, val_MinusLogProbMetric: 5.6274

Epoch 1: val_loss improved from inf to 5.62742, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 31s - loss: 6.4125 - MinusLogProbMetric: 6.4125 - val_loss: 5.6274 - val_MinusLogProbMetric: 5.6274 - lr: 0.0010 - 31s/epoch - 157ms/step
Epoch 2/1000
2023-09-11 20:54:11.488 
Epoch 2/1000 
	 loss: 3.0831, MinusLogProbMetric: 3.0831, val_loss: 2.6918, val_MinusLogProbMetric: 2.6918

Epoch 2: val_loss improved from 5.62742 to 2.69175, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 3.0831 - MinusLogProbMetric: 3.0831 - val_loss: 2.6918 - val_MinusLogProbMetric: 2.6918 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 3/1000
2023-09-11 20:54:23.178 
Epoch 3/1000 
	 loss: 2.7269, MinusLogProbMetric: 2.7269, val_loss: 2.6438, val_MinusLogProbMetric: 2.6438

Epoch 3: val_loss improved from 2.69175 to 2.64385, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.7269 - MinusLogProbMetric: 2.7269 - val_loss: 2.6438 - val_MinusLogProbMetric: 2.6438 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-11 20:54:34.963 
Epoch 4/1000 
	 loss: 2.6626, MinusLogProbMetric: 2.6626, val_loss: 2.5930, val_MinusLogProbMetric: 2.5930

Epoch 4: val_loss improved from 2.64385 to 2.59297, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.6626 - MinusLogProbMetric: 2.6626 - val_loss: 2.5930 - val_MinusLogProbMetric: 2.5930 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-11 20:54:46.698 
Epoch 5/1000 
	 loss: 2.6586, MinusLogProbMetric: 2.6586, val_loss: 2.7338, val_MinusLogProbMetric: 2.7338

Epoch 5: val_loss did not improve from 2.59297
196/196 - 12s - loss: 2.6586 - MinusLogProbMetric: 2.6586 - val_loss: 2.7338 - val_MinusLogProbMetric: 2.7338 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 6/1000
2023-09-11 20:54:58.344 
Epoch 6/1000 
	 loss: 2.6295, MinusLogProbMetric: 2.6295, val_loss: 2.7733, val_MinusLogProbMetric: 2.7733

Epoch 6: val_loss did not improve from 2.59297
196/196 - 12s - loss: 2.6295 - MinusLogProbMetric: 2.6295 - val_loss: 2.7733 - val_MinusLogProbMetric: 2.7733 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 7/1000
2023-09-11 20:55:09.952 
Epoch 7/1000 
	 loss: 2.6048, MinusLogProbMetric: 2.6048, val_loss: 2.6295, val_MinusLogProbMetric: 2.6295

Epoch 7: val_loss did not improve from 2.59297
196/196 - 12s - loss: 2.6048 - MinusLogProbMetric: 2.6048 - val_loss: 2.6295 - val_MinusLogProbMetric: 2.6295 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 8/1000
2023-09-11 20:55:21.550 
Epoch 8/1000 
	 loss: 2.5737, MinusLogProbMetric: 2.5737, val_loss: 2.5741, val_MinusLogProbMetric: 2.5741

Epoch 8: val_loss improved from 2.59297 to 2.57409, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.5737 - MinusLogProbMetric: 2.5737 - val_loss: 2.5741 - val_MinusLogProbMetric: 2.5741 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-11 20:55:33.444 
Epoch 9/1000 
	 loss: 2.5826, MinusLogProbMetric: 2.5826, val_loss: 2.6827, val_MinusLogProbMetric: 2.6827

Epoch 9: val_loss did not improve from 2.57409
196/196 - 12s - loss: 2.5826 - MinusLogProbMetric: 2.5826 - val_loss: 2.6827 - val_MinusLogProbMetric: 2.6827 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 10/1000
2023-09-11 20:55:45.151 
Epoch 10/1000 
	 loss: 2.5569, MinusLogProbMetric: 2.5569, val_loss: 2.5009, val_MinusLogProbMetric: 2.5009

Epoch 10: val_loss improved from 2.57409 to 2.50090, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.5569 - MinusLogProbMetric: 2.5569 - val_loss: 2.5009 - val_MinusLogProbMetric: 2.5009 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-11 20:55:56.915 
Epoch 11/1000 
	 loss: 2.5414, MinusLogProbMetric: 2.5414, val_loss: 2.5702, val_MinusLogProbMetric: 2.5702

Epoch 11: val_loss did not improve from 2.50090
196/196 - 12s - loss: 2.5414 - MinusLogProbMetric: 2.5414 - val_loss: 2.5702 - val_MinusLogProbMetric: 2.5702 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 12/1000
2023-09-11 20:56:08.667 
Epoch 12/1000 
	 loss: 2.5372, MinusLogProbMetric: 2.5372, val_loss: 2.6332, val_MinusLogProbMetric: 2.6332

Epoch 12: val_loss did not improve from 2.50090
196/196 - 12s - loss: 2.5372 - MinusLogProbMetric: 2.5372 - val_loss: 2.6332 - val_MinusLogProbMetric: 2.6332 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-11 20:56:20.427 
Epoch 13/1000 
	 loss: 2.5229, MinusLogProbMetric: 2.5229, val_loss: 2.5609, val_MinusLogProbMetric: 2.5609

Epoch 13: val_loss did not improve from 2.50090
196/196 - 12s - loss: 2.5229 - MinusLogProbMetric: 2.5229 - val_loss: 2.5609 - val_MinusLogProbMetric: 2.5609 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-11 20:56:32.183 
Epoch 14/1000 
	 loss: 2.5110, MinusLogProbMetric: 2.5110, val_loss: 2.5277, val_MinusLogProbMetric: 2.5277

Epoch 14: val_loss did not improve from 2.50090
196/196 - 12s - loss: 2.5110 - MinusLogProbMetric: 2.5110 - val_loss: 2.5277 - val_MinusLogProbMetric: 2.5277 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-11 20:56:43.774 
Epoch 15/1000 
	 loss: 2.5134, MinusLogProbMetric: 2.5134, val_loss: 2.5141, val_MinusLogProbMetric: 2.5141

Epoch 15: val_loss did not improve from 2.50090
196/196 - 12s - loss: 2.5134 - MinusLogProbMetric: 2.5134 - val_loss: 2.5141 - val_MinusLogProbMetric: 2.5141 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 16/1000
2023-09-11 20:56:55.437 
Epoch 16/1000 
	 loss: 2.4927, MinusLogProbMetric: 2.4927, val_loss: 2.4996, val_MinusLogProbMetric: 2.4996

Epoch 16: val_loss improved from 2.50090 to 2.49963, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4927 - MinusLogProbMetric: 2.4927 - val_loss: 2.4996 - val_MinusLogProbMetric: 2.4996 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-11 20:57:07.205 
Epoch 17/1000 
	 loss: 2.4915, MinusLogProbMetric: 2.4915, val_loss: 2.4436, val_MinusLogProbMetric: 2.4436

Epoch 17: val_loss improved from 2.49963 to 2.44364, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4915 - MinusLogProbMetric: 2.4915 - val_loss: 2.4436 - val_MinusLogProbMetric: 2.4436 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-11 20:57:19.163 
Epoch 18/1000 
	 loss: 2.4779, MinusLogProbMetric: 2.4779, val_loss: 2.4524, val_MinusLogProbMetric: 2.4524

Epoch 18: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4779 - MinusLogProbMetric: 2.4779 - val_loss: 2.4524 - val_MinusLogProbMetric: 2.4524 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-11 20:57:31.003 
Epoch 19/1000 
	 loss: 2.4734, MinusLogProbMetric: 2.4734, val_loss: 2.4992, val_MinusLogProbMetric: 2.4992

Epoch 19: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4734 - MinusLogProbMetric: 2.4734 - val_loss: 2.4992 - val_MinusLogProbMetric: 2.4992 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-11 20:57:42.691 
Epoch 20/1000 
	 loss: 2.4817, MinusLogProbMetric: 2.4817, val_loss: 2.5405, val_MinusLogProbMetric: 2.5405

Epoch 20: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4817 - MinusLogProbMetric: 2.4817 - val_loss: 2.5405 - val_MinusLogProbMetric: 2.5405 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 21/1000
2023-09-11 20:57:54.299 
Epoch 21/1000 
	 loss: 2.4715, MinusLogProbMetric: 2.4715, val_loss: 2.4938, val_MinusLogProbMetric: 2.4938

Epoch 21: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4715 - MinusLogProbMetric: 2.4715 - val_loss: 2.4938 - val_MinusLogProbMetric: 2.4938 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-11 20:58:05.992 
Epoch 22/1000 
	 loss: 2.4625, MinusLogProbMetric: 2.4625, val_loss: 2.4893, val_MinusLogProbMetric: 2.4893

Epoch 22: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4625 - MinusLogProbMetric: 2.4625 - val_loss: 2.4893 - val_MinusLogProbMetric: 2.4893 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-11 20:58:17.622 
Epoch 23/1000 
	 loss: 2.4753, MinusLogProbMetric: 2.4753, val_loss: 2.4642, val_MinusLogProbMetric: 2.4642

Epoch 23: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4753 - MinusLogProbMetric: 2.4753 - val_loss: 2.4642 - val_MinusLogProbMetric: 2.4642 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 24/1000
2023-09-11 20:58:29.274 
Epoch 24/1000 
	 loss: 2.4587, MinusLogProbMetric: 2.4587, val_loss: 2.4480, val_MinusLogProbMetric: 2.4480

Epoch 24: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4587 - MinusLogProbMetric: 2.4587 - val_loss: 2.4480 - val_MinusLogProbMetric: 2.4480 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 25/1000
2023-09-11 20:58:40.939 
Epoch 25/1000 
	 loss: 2.4520, MinusLogProbMetric: 2.4520, val_loss: 2.4692, val_MinusLogProbMetric: 2.4692

Epoch 25: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4520 - MinusLogProbMetric: 2.4520 - val_loss: 2.4692 - val_MinusLogProbMetric: 2.4692 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 26/1000
2023-09-11 20:58:52.713 
Epoch 26/1000 
	 loss: 2.4595, MinusLogProbMetric: 2.4595, val_loss: 2.4891, val_MinusLogProbMetric: 2.4891

Epoch 26: val_loss did not improve from 2.44364
196/196 - 12s - loss: 2.4595 - MinusLogProbMetric: 2.4595 - val_loss: 2.4891 - val_MinusLogProbMetric: 2.4891 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-11 20:59:04.503 
Epoch 27/1000 
	 loss: 2.4452, MinusLogProbMetric: 2.4452, val_loss: 2.4335, val_MinusLogProbMetric: 2.4335

Epoch 27: val_loss improved from 2.44364 to 2.43347, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4452 - MinusLogProbMetric: 2.4452 - val_loss: 2.4335 - val_MinusLogProbMetric: 2.4335 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 28/1000
2023-09-11 20:59:16.377 
Epoch 28/1000 
	 loss: 2.4567, MinusLogProbMetric: 2.4567, val_loss: 2.4484, val_MinusLogProbMetric: 2.4484

Epoch 28: val_loss did not improve from 2.43347
196/196 - 12s - loss: 2.4567 - MinusLogProbMetric: 2.4567 - val_loss: 2.4484 - val_MinusLogProbMetric: 2.4484 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 29/1000
2023-09-11 20:59:28.270 
Epoch 29/1000 
	 loss: 2.4463, MinusLogProbMetric: 2.4463, val_loss: 2.4855, val_MinusLogProbMetric: 2.4855

Epoch 29: val_loss did not improve from 2.43347
196/196 - 12s - loss: 2.4463 - MinusLogProbMetric: 2.4463 - val_loss: 2.4855 - val_MinusLogProbMetric: 2.4855 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 30/1000
2023-09-11 20:59:40.040 
Epoch 30/1000 
	 loss: 2.4514, MinusLogProbMetric: 2.4514, val_loss: 2.4550, val_MinusLogProbMetric: 2.4550

Epoch 30: val_loss did not improve from 2.43347
196/196 - 12s - loss: 2.4514 - MinusLogProbMetric: 2.4514 - val_loss: 2.4550 - val_MinusLogProbMetric: 2.4550 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-11 20:59:51.752 
Epoch 31/1000 
	 loss: 2.4400, MinusLogProbMetric: 2.4400, val_loss: 2.4703, val_MinusLogProbMetric: 2.4703

Epoch 31: val_loss did not improve from 2.43347
196/196 - 12s - loss: 2.4400 - MinusLogProbMetric: 2.4400 - val_loss: 2.4703 - val_MinusLogProbMetric: 2.4703 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-11 21:00:03.444 
Epoch 32/1000 
	 loss: 2.4321, MinusLogProbMetric: 2.4321, val_loss: 2.4135, val_MinusLogProbMetric: 2.4135

Epoch 32: val_loss improved from 2.43347 to 2.41346, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4321 - MinusLogProbMetric: 2.4321 - val_loss: 2.4135 - val_MinusLogProbMetric: 2.4135 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-11 21:00:15.259 
Epoch 33/1000 
	 loss: 2.4367, MinusLogProbMetric: 2.4367, val_loss: 2.4424, val_MinusLogProbMetric: 2.4424

Epoch 33: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4367 - MinusLogProbMetric: 2.4367 - val_loss: 2.4424 - val_MinusLogProbMetric: 2.4424 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-11 21:00:27.011 
Epoch 34/1000 
	 loss: 2.4379, MinusLogProbMetric: 2.4379, val_loss: 2.4944, val_MinusLogProbMetric: 2.4944

Epoch 34: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4379 - MinusLogProbMetric: 2.4379 - val_loss: 2.4944 - val_MinusLogProbMetric: 2.4944 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-11 21:00:38.770 
Epoch 35/1000 
	 loss: 2.4357, MinusLogProbMetric: 2.4357, val_loss: 2.4772, val_MinusLogProbMetric: 2.4772

Epoch 35: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4357 - MinusLogProbMetric: 2.4357 - val_loss: 2.4772 - val_MinusLogProbMetric: 2.4772 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-11 21:00:50.407 
Epoch 36/1000 
	 loss: 2.4370, MinusLogProbMetric: 2.4370, val_loss: 2.4503, val_MinusLogProbMetric: 2.4503

Epoch 36: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4370 - MinusLogProbMetric: 2.4370 - val_loss: 2.4503 - val_MinusLogProbMetric: 2.4503 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 37/1000
2023-09-11 21:01:02.022 
Epoch 37/1000 
	 loss: 2.4314, MinusLogProbMetric: 2.4314, val_loss: 2.4371, val_MinusLogProbMetric: 2.4371

Epoch 37: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4314 - MinusLogProbMetric: 2.4314 - val_loss: 2.4371 - val_MinusLogProbMetric: 2.4371 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 38/1000
2023-09-11 21:01:13.743 
Epoch 38/1000 
	 loss: 2.4199, MinusLogProbMetric: 2.4199, val_loss: 2.4385, val_MinusLogProbMetric: 2.4385

Epoch 38: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4199 - MinusLogProbMetric: 2.4199 - val_loss: 2.4385 - val_MinusLogProbMetric: 2.4385 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-11 21:01:25.473 
Epoch 39/1000 
	 loss: 2.4306, MinusLogProbMetric: 2.4306, val_loss: 2.4174, val_MinusLogProbMetric: 2.4174

Epoch 39: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4306 - MinusLogProbMetric: 2.4306 - val_loss: 2.4174 - val_MinusLogProbMetric: 2.4174 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-11 21:01:37.073 
Epoch 40/1000 
	 loss: 2.4210, MinusLogProbMetric: 2.4210, val_loss: 2.4428, val_MinusLogProbMetric: 2.4428

Epoch 40: val_loss did not improve from 2.41346
196/196 - 12s - loss: 2.4210 - MinusLogProbMetric: 2.4210 - val_loss: 2.4428 - val_MinusLogProbMetric: 2.4428 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 41/1000
2023-09-11 21:01:48.697 
Epoch 41/1000 
	 loss: 2.4273, MinusLogProbMetric: 2.4273, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 41: val_loss improved from 2.41346 to 2.40235, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4273 - MinusLogProbMetric: 2.4273 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-11 21:02:00.529 
Epoch 42/1000 
	 loss: 2.4252, MinusLogProbMetric: 2.4252, val_loss: 2.4487, val_MinusLogProbMetric: 2.4487

Epoch 42: val_loss did not improve from 2.40235
196/196 - 12s - loss: 2.4252 - MinusLogProbMetric: 2.4252 - val_loss: 2.4487 - val_MinusLogProbMetric: 2.4487 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-11 21:02:12.133 
Epoch 43/1000 
	 loss: 2.4200, MinusLogProbMetric: 2.4200, val_loss: 2.4337, val_MinusLogProbMetric: 2.4337

Epoch 43: val_loss did not improve from 2.40235
196/196 - 12s - loss: 2.4200 - MinusLogProbMetric: 2.4200 - val_loss: 2.4337 - val_MinusLogProbMetric: 2.4337 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-11 21:02:23.797 
Epoch 44/1000 
	 loss: 2.4222, MinusLogProbMetric: 2.4222, val_loss: 2.4193, val_MinusLogProbMetric: 2.4193

Epoch 44: val_loss did not improve from 2.40235
196/196 - 12s - loss: 2.4222 - MinusLogProbMetric: 2.4222 - val_loss: 2.4193 - val_MinusLogProbMetric: 2.4193 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 45/1000
2023-09-11 21:02:35.505 
Epoch 45/1000 
	 loss: 2.4223, MinusLogProbMetric: 2.4223, val_loss: 2.3910, val_MinusLogProbMetric: 2.3910

Epoch 45: val_loss improved from 2.40235 to 2.39105, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4223 - MinusLogProbMetric: 2.4223 - val_loss: 2.3910 - val_MinusLogProbMetric: 2.3910 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-11 21:02:47.314 
Epoch 46/1000 
	 loss: 2.4183, MinusLogProbMetric: 2.4183, val_loss: 2.3950, val_MinusLogProbMetric: 2.3950

Epoch 46: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4183 - MinusLogProbMetric: 2.4183 - val_loss: 2.3950 - val_MinusLogProbMetric: 2.3950 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 47/1000
2023-09-11 21:02:59.082 
Epoch 47/1000 
	 loss: 2.4184, MinusLogProbMetric: 2.4184, val_loss: 2.4206, val_MinusLogProbMetric: 2.4206

Epoch 47: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4184 - MinusLogProbMetric: 2.4184 - val_loss: 2.4206 - val_MinusLogProbMetric: 2.4206 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-11 21:03:10.810 
Epoch 48/1000 
	 loss: 2.4256, MinusLogProbMetric: 2.4256, val_loss: 2.4196, val_MinusLogProbMetric: 2.4196

Epoch 48: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4256 - MinusLogProbMetric: 2.4256 - val_loss: 2.4196 - val_MinusLogProbMetric: 2.4196 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-11 21:03:22.676 
Epoch 49/1000 
	 loss: 2.4219, MinusLogProbMetric: 2.4219, val_loss: 2.4266, val_MinusLogProbMetric: 2.4266

Epoch 49: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4219 - MinusLogProbMetric: 2.4219 - val_loss: 2.4266 - val_MinusLogProbMetric: 2.4266 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 50/1000
2023-09-11 21:03:34.396 
Epoch 50/1000 
	 loss: 2.4135, MinusLogProbMetric: 2.4135, val_loss: 2.4454, val_MinusLogProbMetric: 2.4454

Epoch 50: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4135 - MinusLogProbMetric: 2.4135 - val_loss: 2.4454 - val_MinusLogProbMetric: 2.4454 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 51/1000
2023-09-11 21:03:46.190 
Epoch 51/1000 
	 loss: 2.4216, MinusLogProbMetric: 2.4216, val_loss: 2.4108, val_MinusLogProbMetric: 2.4108

Epoch 51: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4216 - MinusLogProbMetric: 2.4216 - val_loss: 2.4108 - val_MinusLogProbMetric: 2.4108 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-11 21:03:58.000 
Epoch 52/1000 
	 loss: 2.4180, MinusLogProbMetric: 2.4180, val_loss: 2.4123, val_MinusLogProbMetric: 2.4123

Epoch 52: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4180 - MinusLogProbMetric: 2.4180 - val_loss: 2.4123 - val_MinusLogProbMetric: 2.4123 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-11 21:04:09.845 
Epoch 53/1000 
	 loss: 2.4123, MinusLogProbMetric: 2.4123, val_loss: 2.5029, val_MinusLogProbMetric: 2.5029

Epoch 53: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4123 - MinusLogProbMetric: 2.4123 - val_loss: 2.5029 - val_MinusLogProbMetric: 2.5029 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-11 21:04:21.659 
Epoch 54/1000 
	 loss: 2.4170, MinusLogProbMetric: 2.4170, val_loss: 2.3994, val_MinusLogProbMetric: 2.3994

Epoch 54: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4170 - MinusLogProbMetric: 2.4170 - val_loss: 2.3994 - val_MinusLogProbMetric: 2.3994 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 55/1000
2023-09-11 21:04:33.343 
Epoch 55/1000 
	 loss: 2.4124, MinusLogProbMetric: 2.4124, val_loss: 2.3990, val_MinusLogProbMetric: 2.3990

Epoch 55: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4124 - MinusLogProbMetric: 2.4124 - val_loss: 2.3990 - val_MinusLogProbMetric: 2.3990 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-11 21:04:45.143 
Epoch 56/1000 
	 loss: 2.4061, MinusLogProbMetric: 2.4061, val_loss: 2.4129, val_MinusLogProbMetric: 2.4129

Epoch 56: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4061 - MinusLogProbMetric: 2.4061 - val_loss: 2.4129 - val_MinusLogProbMetric: 2.4129 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-11 21:04:56.753 
Epoch 57/1000 
	 loss: 2.4107, MinusLogProbMetric: 2.4107, val_loss: 2.4088, val_MinusLogProbMetric: 2.4088

Epoch 57: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4107 - MinusLogProbMetric: 2.4107 - val_loss: 2.4088 - val_MinusLogProbMetric: 2.4088 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 58/1000
2023-09-11 21:05:08.481 
Epoch 58/1000 
	 loss: 2.4136, MinusLogProbMetric: 2.4136, val_loss: 2.4136, val_MinusLogProbMetric: 2.4136

Epoch 58: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4136 - MinusLogProbMetric: 2.4136 - val_loss: 2.4136 - val_MinusLogProbMetric: 2.4136 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-11 21:05:20.210 
Epoch 59/1000 
	 loss: 2.4015, MinusLogProbMetric: 2.4015, val_loss: 2.4110, val_MinusLogProbMetric: 2.4110

Epoch 59: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4015 - MinusLogProbMetric: 2.4015 - val_loss: 2.4110 - val_MinusLogProbMetric: 2.4110 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-11 21:05:31.953 
Epoch 60/1000 
	 loss: 2.4113, MinusLogProbMetric: 2.4113, val_loss: 2.4353, val_MinusLogProbMetric: 2.4353

Epoch 60: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4113 - MinusLogProbMetric: 2.4113 - val_loss: 2.4353 - val_MinusLogProbMetric: 2.4353 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-11 21:05:43.558 
Epoch 61/1000 
	 loss: 2.4089, MinusLogProbMetric: 2.4089, val_loss: 2.4124, val_MinusLogProbMetric: 2.4124

Epoch 61: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4089 - MinusLogProbMetric: 2.4089 - val_loss: 2.4124 - val_MinusLogProbMetric: 2.4124 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 62/1000
2023-09-11 21:05:55.222 
Epoch 62/1000 
	 loss: 2.4089, MinusLogProbMetric: 2.4089, val_loss: 2.4513, val_MinusLogProbMetric: 2.4513

Epoch 62: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4089 - MinusLogProbMetric: 2.4089 - val_loss: 2.4513 - val_MinusLogProbMetric: 2.4513 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-11 21:06:07.057 
Epoch 63/1000 
	 loss: 2.4109, MinusLogProbMetric: 2.4109, val_loss: 2.3913, val_MinusLogProbMetric: 2.3913

Epoch 63: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4109 - MinusLogProbMetric: 2.4109 - val_loss: 2.3913 - val_MinusLogProbMetric: 2.3913 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-11 21:06:18.717 
Epoch 64/1000 
	 loss: 2.4066, MinusLogProbMetric: 2.4066, val_loss: 2.3979, val_MinusLogProbMetric: 2.3979

Epoch 64: val_loss did not improve from 2.39105
196/196 - 12s - loss: 2.4066 - MinusLogProbMetric: 2.4066 - val_loss: 2.3979 - val_MinusLogProbMetric: 2.3979 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 65/1000
2023-09-11 21:06:30.410 
Epoch 65/1000 
	 loss: 2.4145, MinusLogProbMetric: 2.4145, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 65: val_loss improved from 2.39105 to 2.38832, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4145 - MinusLogProbMetric: 2.4145 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-11 21:06:42.241 
Epoch 66/1000 
	 loss: 2.4032, MinusLogProbMetric: 2.4032, val_loss: 2.4356, val_MinusLogProbMetric: 2.4356

Epoch 66: val_loss did not improve from 2.38832
196/196 - 12s - loss: 2.4032 - MinusLogProbMetric: 2.4032 - val_loss: 2.4356 - val_MinusLogProbMetric: 2.4356 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-11 21:06:53.814 
Epoch 67/1000 
	 loss: 2.4051, MinusLogProbMetric: 2.4051, val_loss: 2.4042, val_MinusLogProbMetric: 2.4042

Epoch 67: val_loss did not improve from 2.38832
196/196 - 12s - loss: 2.4051 - MinusLogProbMetric: 2.4051 - val_loss: 2.4042 - val_MinusLogProbMetric: 2.4042 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 68/1000
2023-09-11 21:07:05.483 
Epoch 68/1000 
	 loss: 2.4022, MinusLogProbMetric: 2.4022, val_loss: 2.3923, val_MinusLogProbMetric: 2.3923

Epoch 68: val_loss did not improve from 2.38832
196/196 - 12s - loss: 2.4022 - MinusLogProbMetric: 2.4022 - val_loss: 2.3923 - val_MinusLogProbMetric: 2.3923 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-11 21:07:17.077 
Epoch 69/1000 
	 loss: 2.4008, MinusLogProbMetric: 2.4008, val_loss: 2.3873, val_MinusLogProbMetric: 2.3873

Epoch 69: val_loss improved from 2.38832 to 2.38725, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4008 - MinusLogProbMetric: 2.4008 - val_loss: 2.3873 - val_MinusLogProbMetric: 2.3873 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-11 21:07:28.951 
Epoch 70/1000 
	 loss: 2.4080, MinusLogProbMetric: 2.4080, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 70: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.4080 - MinusLogProbMetric: 2.4080 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-11 21:07:40.569 
Epoch 71/1000 
	 loss: 2.4042, MinusLogProbMetric: 2.4042, val_loss: 2.3890, val_MinusLogProbMetric: 2.3890

Epoch 71: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.4042 - MinusLogProbMetric: 2.4042 - val_loss: 2.3890 - val_MinusLogProbMetric: 2.3890 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 72/1000
2023-09-11 21:07:52.263 
Epoch 72/1000 
	 loss: 2.3993, MinusLogProbMetric: 2.3993, val_loss: 2.4028, val_MinusLogProbMetric: 2.4028

Epoch 72: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3993 - MinusLogProbMetric: 2.3993 - val_loss: 2.4028 - val_MinusLogProbMetric: 2.4028 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-11 21:08:04.098 
Epoch 73/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.3953, val_MinusLogProbMetric: 2.3953

Epoch 73: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.3953 - val_MinusLogProbMetric: 2.3953 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-11 21:08:15.857 
Epoch 74/1000 
	 loss: 2.4024, MinusLogProbMetric: 2.4024, val_loss: 2.3814, val_MinusLogProbMetric: 2.3814

Epoch 74: val_loss improved from 2.38725 to 2.38141, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.4024 - MinusLogProbMetric: 2.4024 - val_loss: 2.3814 - val_MinusLogProbMetric: 2.3814 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 75/1000
2023-09-11 21:08:27.610 
Epoch 75/1000 
	 loss: 2.4000, MinusLogProbMetric: 2.4000, val_loss: 2.3862, val_MinusLogProbMetric: 2.3862

Epoch 75: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4000 - MinusLogProbMetric: 2.4000 - val_loss: 2.3862 - val_MinusLogProbMetric: 2.3862 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 76/1000
2023-09-11 21:08:39.297 
Epoch 76/1000 
	 loss: 2.3973, MinusLogProbMetric: 2.3973, val_loss: 2.4514, val_MinusLogProbMetric: 2.4514

Epoch 76: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3973 - MinusLogProbMetric: 2.3973 - val_loss: 2.4514 - val_MinusLogProbMetric: 2.4514 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-11 21:08:51.000 
Epoch 77/1000 
	 loss: 2.4037, MinusLogProbMetric: 2.4037, val_loss: 2.4233, val_MinusLogProbMetric: 2.4233

Epoch 77: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4037 - MinusLogProbMetric: 2.4037 - val_loss: 2.4233 - val_MinusLogProbMetric: 2.4233 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-11 21:09:02.744 
Epoch 78/1000 
	 loss: 2.4023, MinusLogProbMetric: 2.4023, val_loss: 2.4767, val_MinusLogProbMetric: 2.4767

Epoch 78: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4023 - MinusLogProbMetric: 2.4023 - val_loss: 2.4767 - val_MinusLogProbMetric: 2.4767 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-11 21:09:14.447 
Epoch 79/1000 
	 loss: 2.3986, MinusLogProbMetric: 2.3986, val_loss: 2.4093, val_MinusLogProbMetric: 2.4093

Epoch 79: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3986 - MinusLogProbMetric: 2.3986 - val_loss: 2.4093 - val_MinusLogProbMetric: 2.4093 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-11 21:09:26.723 
Epoch 80/1000 
	 loss: 2.4048, MinusLogProbMetric: 2.4048, val_loss: 2.3996, val_MinusLogProbMetric: 2.3996

Epoch 80: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4048 - MinusLogProbMetric: 2.4048 - val_loss: 2.3996 - val_MinusLogProbMetric: 2.3996 - lr: 0.0010 - 12s/epoch - 63ms/step
Epoch 81/1000
2023-09-11 21:09:38.032 
Epoch 81/1000 
	 loss: 2.4007, MinusLogProbMetric: 2.4007, val_loss: 2.4091, val_MinusLogProbMetric: 2.4091

Epoch 81: val_loss did not improve from 2.38141
196/196 - 11s - loss: 2.4007 - MinusLogProbMetric: 2.4007 - val_loss: 2.4091 - val_MinusLogProbMetric: 2.4091 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 82/1000
2023-09-11 21:09:48.993 
Epoch 82/1000 
	 loss: 2.4001, MinusLogProbMetric: 2.4001, val_loss: 2.3915, val_MinusLogProbMetric: 2.3915

Epoch 82: val_loss did not improve from 2.38141
196/196 - 11s - loss: 2.4001 - MinusLogProbMetric: 2.4001 - val_loss: 2.3915 - val_MinusLogProbMetric: 2.3915 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 83/1000
2023-09-11 21:09:58.798 
Epoch 83/1000 
	 loss: 2.3958, MinusLogProbMetric: 2.3958, val_loss: 2.4081, val_MinusLogProbMetric: 2.4081

Epoch 83: val_loss did not improve from 2.38141
196/196 - 10s - loss: 2.3958 - MinusLogProbMetric: 2.3958 - val_loss: 2.4081 - val_MinusLogProbMetric: 2.4081 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 84/1000
2023-09-11 21:10:09.980 
Epoch 84/1000 
	 loss: 2.3997, MinusLogProbMetric: 2.3997, val_loss: 2.3928, val_MinusLogProbMetric: 2.3928

Epoch 84: val_loss did not improve from 2.38141
196/196 - 11s - loss: 2.3997 - MinusLogProbMetric: 2.3997 - val_loss: 2.3928 - val_MinusLogProbMetric: 2.3928 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 85/1000
2023-09-11 21:10:21.579 
Epoch 85/1000 
	 loss: 2.3996, MinusLogProbMetric: 2.3996, val_loss: 2.3890, val_MinusLogProbMetric: 2.3890

Epoch 85: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3996 - MinusLogProbMetric: 2.3996 - val_loss: 2.3890 - val_MinusLogProbMetric: 2.3890 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-11 21:10:33.181 
Epoch 86/1000 
	 loss: 2.3960, MinusLogProbMetric: 2.3960, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 86: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3960 - MinusLogProbMetric: 2.3960 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-11 21:10:44.833 
Epoch 87/1000 
	 loss: 2.3942, MinusLogProbMetric: 2.3942, val_loss: 2.3865, val_MinusLogProbMetric: 2.3865

Epoch 87: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3942 - MinusLogProbMetric: 2.3942 - val_loss: 2.3865 - val_MinusLogProbMetric: 2.3865 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-11 21:10:56.458 
Epoch 88/1000 
	 loss: 2.3960, MinusLogProbMetric: 2.3960, val_loss: 2.3983, val_MinusLogProbMetric: 2.3983

Epoch 88: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3960 - MinusLogProbMetric: 2.3960 - val_loss: 2.3983 - val_MinusLogProbMetric: 2.3983 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-11 21:11:08.178 
Epoch 89/1000 
	 loss: 2.3972, MinusLogProbMetric: 2.3972, val_loss: 2.4002, val_MinusLogProbMetric: 2.4002

Epoch 89: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3972 - MinusLogProbMetric: 2.3972 - val_loss: 2.4002 - val_MinusLogProbMetric: 2.4002 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-11 21:11:19.974 
Epoch 90/1000 
	 loss: 2.4012, MinusLogProbMetric: 2.4012, val_loss: 2.4219, val_MinusLogProbMetric: 2.4219

Epoch 90: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4012 - MinusLogProbMetric: 2.4012 - val_loss: 2.4219 - val_MinusLogProbMetric: 2.4219 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-11 21:11:31.767 
Epoch 91/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.4123, val_MinusLogProbMetric: 2.4123

Epoch 91: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.4123 - val_MinusLogProbMetric: 2.4123 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-11 21:11:43.582 
Epoch 92/1000 
	 loss: 2.4193, MinusLogProbMetric: 2.4193, val_loss: 2.4184, val_MinusLogProbMetric: 2.4184

Epoch 92: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4193 - MinusLogProbMetric: 2.4193 - val_loss: 2.4184 - val_MinusLogProbMetric: 2.4184 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-11 21:11:55.254 
Epoch 93/1000 
	 loss: 2.4053, MinusLogProbMetric: 2.4053, val_loss: 2.3993, val_MinusLogProbMetric: 2.3993

Epoch 93: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4053 - MinusLogProbMetric: 2.4053 - val_loss: 2.3993 - val_MinusLogProbMetric: 2.3993 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-11 21:12:06.968 
Epoch 94/1000 
	 loss: 2.3989, MinusLogProbMetric: 2.3989, val_loss: 2.4080, val_MinusLogProbMetric: 2.4080

Epoch 94: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3989 - MinusLogProbMetric: 2.3989 - val_loss: 2.4080 - val_MinusLogProbMetric: 2.4080 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-11 21:12:18.643 
Epoch 95/1000 
	 loss: 2.3927, MinusLogProbMetric: 2.3927, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 95: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3927 - MinusLogProbMetric: 2.3927 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-11 21:12:30.384 
Epoch 96/1000 
	 loss: 2.3929, MinusLogProbMetric: 2.3929, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 96: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3929 - MinusLogProbMetric: 2.3929 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 97/1000
2023-09-11 21:12:42.366 
Epoch 97/1000 
	 loss: 2.3952, MinusLogProbMetric: 2.3952, val_loss: 2.3972, val_MinusLogProbMetric: 2.3972

Epoch 97: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3952 - MinusLogProbMetric: 2.3952 - val_loss: 2.3972 - val_MinusLogProbMetric: 2.3972 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 98/1000
2023-09-11 21:12:54.203 
Epoch 98/1000 
	 loss: 2.3978, MinusLogProbMetric: 2.3978, val_loss: 2.3987, val_MinusLogProbMetric: 2.3987

Epoch 98: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3978 - MinusLogProbMetric: 2.3978 - val_loss: 2.3987 - val_MinusLogProbMetric: 2.3987 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 99/1000
2023-09-11 21:13:05.995 
Epoch 99/1000 
	 loss: 2.4084, MinusLogProbMetric: 2.4084, val_loss: 2.3957, val_MinusLogProbMetric: 2.3957

Epoch 99: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4084 - MinusLogProbMetric: 2.4084 - val_loss: 2.3957 - val_MinusLogProbMetric: 2.3957 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 100/1000
2023-09-11 21:13:17.888 
Epoch 100/1000 
	 loss: 2.3970, MinusLogProbMetric: 2.3970, val_loss: 2.3845, val_MinusLogProbMetric: 2.3845

Epoch 100: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3970 - MinusLogProbMetric: 2.3970 - val_loss: 2.3845 - val_MinusLogProbMetric: 2.3845 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 101/1000
2023-09-11 21:13:29.811 
Epoch 101/1000 
	 loss: 2.3905, MinusLogProbMetric: 2.3905, val_loss: 2.3855, val_MinusLogProbMetric: 2.3855

Epoch 101: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3905 - MinusLogProbMetric: 2.3905 - val_loss: 2.3855 - val_MinusLogProbMetric: 2.3855 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 102/1000
2023-09-11 21:13:41.774 
Epoch 102/1000 
	 loss: 2.3980, MinusLogProbMetric: 2.3980, val_loss: 2.3981, val_MinusLogProbMetric: 2.3981

Epoch 102: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3980 - MinusLogProbMetric: 2.3980 - val_loss: 2.3981 - val_MinusLogProbMetric: 2.3981 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 103/1000
2023-09-11 21:13:53.491 
Epoch 103/1000 
	 loss: 2.4021, MinusLogProbMetric: 2.4021, val_loss: 2.3936, val_MinusLogProbMetric: 2.3936

Epoch 103: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.4021 - MinusLogProbMetric: 2.4021 - val_loss: 2.3936 - val_MinusLogProbMetric: 2.3936 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-11 21:14:05.173 
Epoch 104/1000 
	 loss: 2.3963, MinusLogProbMetric: 2.3963, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 104: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3963 - MinusLogProbMetric: 2.3963 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 105/1000
2023-09-11 21:14:16.933 
Epoch 105/1000 
	 loss: 2.3908, MinusLogProbMetric: 2.3908, val_loss: 2.3838, val_MinusLogProbMetric: 2.3838

Epoch 105: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3908 - MinusLogProbMetric: 2.3908 - val_loss: 2.3838 - val_MinusLogProbMetric: 2.3838 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-11 21:14:28.674 
Epoch 106/1000 
	 loss: 2.3957, MinusLogProbMetric: 2.3957, val_loss: 2.4131, val_MinusLogProbMetric: 2.4131

Epoch 106: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3957 - MinusLogProbMetric: 2.3957 - val_loss: 2.4131 - val_MinusLogProbMetric: 2.4131 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 107/1000
2023-09-11 21:14:40.352 
Epoch 107/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.4053, val_MinusLogProbMetric: 2.4053

Epoch 107: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.4053 - val_MinusLogProbMetric: 2.4053 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-11 21:14:52.086 
Epoch 108/1000 
	 loss: 2.3901, MinusLogProbMetric: 2.3901, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 108: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3901 - MinusLogProbMetric: 2.3901 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-11 21:15:03.792 
Epoch 109/1000 
	 loss: 2.3917, MinusLogProbMetric: 2.3917, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 109: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3917 - MinusLogProbMetric: 2.3917 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 110/1000
2023-09-11 21:15:15.454 
Epoch 110/1000 
	 loss: 2.3893, MinusLogProbMetric: 2.3893, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 110: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3893 - MinusLogProbMetric: 2.3893 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 111/1000
2023-09-11 21:15:27.161 
Epoch 111/1000 
	 loss: 2.3961, MinusLogProbMetric: 2.3961, val_loss: 2.4027, val_MinusLogProbMetric: 2.4027

Epoch 111: val_loss did not improve from 2.38141
196/196 - 12s - loss: 2.3961 - MinusLogProbMetric: 2.3961 - val_loss: 2.4027 - val_MinusLogProbMetric: 2.4027 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-11 21:15:38.990 
Epoch 112/1000 
	 loss: 2.3942, MinusLogProbMetric: 2.3942, val_loss: 2.3789, val_MinusLogProbMetric: 2.3789

Epoch 112: val_loss improved from 2.38141 to 2.37888, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3942 - MinusLogProbMetric: 2.3942 - val_loss: 2.3789 - val_MinusLogProbMetric: 2.3789 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 113/1000
2023-09-11 21:15:50.897 
Epoch 113/1000 
	 loss: 2.3947, MinusLogProbMetric: 2.3947, val_loss: 2.3852, val_MinusLogProbMetric: 2.3852

Epoch 113: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3947 - MinusLogProbMetric: 2.3947 - val_loss: 2.3852 - val_MinusLogProbMetric: 2.3852 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-11 21:16:02.707 
Epoch 114/1000 
	 loss: 2.3947, MinusLogProbMetric: 2.3947, val_loss: 2.3909, val_MinusLogProbMetric: 2.3909

Epoch 114: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3947 - MinusLogProbMetric: 2.3947 - val_loss: 2.3909 - val_MinusLogProbMetric: 2.3909 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 115/1000
2023-09-11 21:16:14.444 
Epoch 115/1000 
	 loss: 2.3904, MinusLogProbMetric: 2.3904, val_loss: 2.3943, val_MinusLogProbMetric: 2.3943

Epoch 115: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3904 - MinusLogProbMetric: 2.3904 - val_loss: 2.3943 - val_MinusLogProbMetric: 2.3943 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 116/1000
2023-09-11 21:16:26.096 
Epoch 116/1000 
	 loss: 2.3877, MinusLogProbMetric: 2.3877, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 116: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3877 - MinusLogProbMetric: 2.3877 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 117/1000
2023-09-11 21:16:37.761 
Epoch 117/1000 
	 loss: 2.3913, MinusLogProbMetric: 2.3913, val_loss: 2.4041, val_MinusLogProbMetric: 2.4041

Epoch 117: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3913 - MinusLogProbMetric: 2.3913 - val_loss: 2.4041 - val_MinusLogProbMetric: 2.4041 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 118/1000
2023-09-11 21:16:49.418 
Epoch 118/1000 
	 loss: 2.3932, MinusLogProbMetric: 2.3932, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 118: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3932 - MinusLogProbMetric: 2.3932 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-11 21:17:01.071 
Epoch 119/1000 
	 loss: 2.3924, MinusLogProbMetric: 2.3924, val_loss: 2.4262, val_MinusLogProbMetric: 2.4262

Epoch 119: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3924 - MinusLogProbMetric: 2.3924 - val_loss: 2.4262 - val_MinusLogProbMetric: 2.4262 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 120/1000
2023-09-11 21:17:12.838 
Epoch 120/1000 
	 loss: 2.3932, MinusLogProbMetric: 2.3932, val_loss: 2.3917, val_MinusLogProbMetric: 2.3917

Epoch 120: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3932 - MinusLogProbMetric: 2.3932 - val_loss: 2.3917 - val_MinusLogProbMetric: 2.3917 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-11 21:17:24.528 
Epoch 121/1000 
	 loss: 2.3925, MinusLogProbMetric: 2.3925, val_loss: 2.3926, val_MinusLogProbMetric: 2.3926

Epoch 121: val_loss did not improve from 2.37888
196/196 - 12s - loss: 2.3925 - MinusLogProbMetric: 2.3925 - val_loss: 2.3926 - val_MinusLogProbMetric: 2.3926 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-11 21:17:36.150 
Epoch 122/1000 
	 loss: 2.3921, MinusLogProbMetric: 2.3921, val_loss: 2.3786, val_MinusLogProbMetric: 2.3786

Epoch 122: val_loss improved from 2.37888 to 2.37858, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3921 - MinusLogProbMetric: 2.3921 - val_loss: 2.3786 - val_MinusLogProbMetric: 2.3786 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-11 21:17:47.524 
Epoch 123/1000 
	 loss: 2.3858, MinusLogProbMetric: 2.3858, val_loss: 2.3867, val_MinusLogProbMetric: 2.3867

Epoch 123: val_loss did not improve from 2.37858
196/196 - 11s - loss: 2.3858 - MinusLogProbMetric: 2.3858 - val_loss: 2.3867 - val_MinusLogProbMetric: 2.3867 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 124/1000
2023-09-11 21:17:58.321 
Epoch 124/1000 
	 loss: 2.3896, MinusLogProbMetric: 2.3896, val_loss: 2.3814, val_MinusLogProbMetric: 2.3814

Epoch 124: val_loss did not improve from 2.37858
196/196 - 11s - loss: 2.3896 - MinusLogProbMetric: 2.3896 - val_loss: 2.3814 - val_MinusLogProbMetric: 2.3814 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 125/1000
2023-09-11 21:18:08.989 
Epoch 125/1000 
	 loss: 2.3898, MinusLogProbMetric: 2.3898, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 125: val_loss did not improve from 2.37858
196/196 - 11s - loss: 2.3898 - MinusLogProbMetric: 2.3898 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 126/1000
2023-09-11 21:18:20.809 
Epoch 126/1000 
	 loss: 2.3874, MinusLogProbMetric: 2.3874, val_loss: 2.3869, val_MinusLogProbMetric: 2.3869

Epoch 126: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.3874 - MinusLogProbMetric: 2.3874 - val_loss: 2.3869 - val_MinusLogProbMetric: 2.3869 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-11 21:18:32.629 
Epoch 127/1000 
	 loss: 2.3925, MinusLogProbMetric: 2.3925, val_loss: 2.4213, val_MinusLogProbMetric: 2.4213

Epoch 127: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.3925 - MinusLogProbMetric: 2.3925 - val_loss: 2.4213 - val_MinusLogProbMetric: 2.4213 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 128/1000
2023-09-11 21:18:44.397 
Epoch 128/1000 
	 loss: 2.3946, MinusLogProbMetric: 2.3946, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 128: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.3946 - MinusLogProbMetric: 2.3946 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-11 21:18:56.089 
Epoch 129/1000 
	 loss: 2.3870, MinusLogProbMetric: 2.3870, val_loss: 2.4158, val_MinusLogProbMetric: 2.4158

Epoch 129: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.3870 - MinusLogProbMetric: 2.3870 - val_loss: 2.4158 - val_MinusLogProbMetric: 2.4158 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-11 21:19:07.807 
Epoch 130/1000 
	 loss: 2.6167, MinusLogProbMetric: 2.6167, val_loss: 2.4278, val_MinusLogProbMetric: 2.4278

Epoch 130: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.6167 - MinusLogProbMetric: 2.6167 - val_loss: 2.4278 - val_MinusLogProbMetric: 2.4278 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-11 21:19:19.501 
Epoch 131/1000 
	 loss: 2.4188, MinusLogProbMetric: 2.4188, val_loss: 2.4165, val_MinusLogProbMetric: 2.4165

Epoch 131: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.4188 - MinusLogProbMetric: 2.4188 - val_loss: 2.4165 - val_MinusLogProbMetric: 2.4165 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 132/1000
2023-09-11 21:19:31.151 
Epoch 132/1000 
	 loss: 2.4138, MinusLogProbMetric: 2.4138, val_loss: 2.3984, val_MinusLogProbMetric: 2.3984

Epoch 132: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.4138 - MinusLogProbMetric: 2.4138 - val_loss: 2.3984 - val_MinusLogProbMetric: 2.3984 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 133/1000
2023-09-11 21:19:42.850 
Epoch 133/1000 
	 loss: 2.4054, MinusLogProbMetric: 2.4054, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 133: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.4054 - MinusLogProbMetric: 2.4054 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-11 21:19:54.619 
Epoch 134/1000 
	 loss: 2.4001, MinusLogProbMetric: 2.4001, val_loss: 2.4053, val_MinusLogProbMetric: 2.4053

Epoch 134: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.4001 - MinusLogProbMetric: 2.4001 - val_loss: 2.4053 - val_MinusLogProbMetric: 2.4053 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-11 21:20:06.282 
Epoch 135/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 135: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 136/1000
2023-09-11 21:20:17.913 
Epoch 136/1000 
	 loss: 2.3987, MinusLogProbMetric: 2.3987, val_loss: 2.3867, val_MinusLogProbMetric: 2.3867

Epoch 136: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.3987 - MinusLogProbMetric: 2.3987 - val_loss: 2.3867 - val_MinusLogProbMetric: 2.3867 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 137/1000
2023-09-11 21:20:29.723 
Epoch 137/1000 
	 loss: 2.3937, MinusLogProbMetric: 2.3937, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 137: val_loss did not improve from 2.37858
196/196 - 12s - loss: 2.3937 - MinusLogProbMetric: 2.3937 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 138/1000
2023-09-11 21:20:41.470 
Epoch 138/1000 
	 loss: 2.3958, MinusLogProbMetric: 2.3958, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 138: val_loss improved from 2.37858 to 2.37846, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3958 - MinusLogProbMetric: 2.3958 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-11 21:20:53.284 
Epoch 139/1000 
	 loss: 2.3910, MinusLogProbMetric: 2.3910, val_loss: 2.4999, val_MinusLogProbMetric: 2.4999

Epoch 139: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3910 - MinusLogProbMetric: 2.3910 - val_loss: 2.4999 - val_MinusLogProbMetric: 2.4999 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-11 21:21:05.022 
Epoch 140/1000 
	 loss: 2.4097, MinusLogProbMetric: 2.4097, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 140: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.4097 - MinusLogProbMetric: 2.4097 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 141/1000
2023-09-11 21:21:16.824 
Epoch 141/1000 
	 loss: 2.3934, MinusLogProbMetric: 2.3934, val_loss: 2.4451, val_MinusLogProbMetric: 2.4451

Epoch 141: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3934 - MinusLogProbMetric: 2.3934 - val_loss: 2.4451 - val_MinusLogProbMetric: 2.4451 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 142/1000
2023-09-11 21:21:28.597 
Epoch 142/1000 
	 loss: 2.3961, MinusLogProbMetric: 2.3961, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 142: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3961 - MinusLogProbMetric: 2.3961 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 143/1000
2023-09-11 21:21:40.331 
Epoch 143/1000 
	 loss: 2.3905, MinusLogProbMetric: 2.3905, val_loss: 2.4180, val_MinusLogProbMetric: 2.4180

Epoch 143: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3905 - MinusLogProbMetric: 2.3905 - val_loss: 2.4180 - val_MinusLogProbMetric: 2.4180 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 144/1000
2023-09-11 21:21:52.074 
Epoch 144/1000 
	 loss: 2.3929, MinusLogProbMetric: 2.3929, val_loss: 2.3794, val_MinusLogProbMetric: 2.3794

Epoch 144: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3929 - MinusLogProbMetric: 2.3929 - val_loss: 2.3794 - val_MinusLogProbMetric: 2.3794 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 145/1000
2023-09-11 21:22:03.785 
Epoch 145/1000 
	 loss: 2.3901, MinusLogProbMetric: 2.3901, val_loss: 2.3931, val_MinusLogProbMetric: 2.3931

Epoch 145: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3901 - MinusLogProbMetric: 2.3901 - val_loss: 2.3931 - val_MinusLogProbMetric: 2.3931 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 146/1000
2023-09-11 21:22:15.542 
Epoch 146/1000 
	 loss: 2.3926, MinusLogProbMetric: 2.3926, val_loss: 2.3920, val_MinusLogProbMetric: 2.3920

Epoch 146: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3926 - MinusLogProbMetric: 2.3926 - val_loss: 2.3920 - val_MinusLogProbMetric: 2.3920 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-11 21:22:27.210 
Epoch 147/1000 
	 loss: 2.3919, MinusLogProbMetric: 2.3919, val_loss: 2.4064, val_MinusLogProbMetric: 2.4064

Epoch 147: val_loss did not improve from 2.37846
196/196 - 12s - loss: 2.3919 - MinusLogProbMetric: 2.3919 - val_loss: 2.4064 - val_MinusLogProbMetric: 2.4064 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 148/1000
2023-09-11 21:22:38.965 
Epoch 148/1000 
	 loss: 2.3928, MinusLogProbMetric: 2.3928, val_loss: 2.3778, val_MinusLogProbMetric: 2.3778

Epoch 148: val_loss improved from 2.37846 to 2.37778, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3928 - MinusLogProbMetric: 2.3928 - val_loss: 2.3778 - val_MinusLogProbMetric: 2.3778 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 149/1000
2023-09-11 21:22:50.781 
Epoch 149/1000 
	 loss: 2.3927, MinusLogProbMetric: 2.3927, val_loss: 2.3777, val_MinusLogProbMetric: 2.3777

Epoch 149: val_loss improved from 2.37778 to 2.37772, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3927 - MinusLogProbMetric: 2.3927 - val_loss: 2.3777 - val_MinusLogProbMetric: 2.3777 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-11 21:23:02.678 
Epoch 150/1000 
	 loss: 2.3949, MinusLogProbMetric: 2.3949, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 150: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3949 - MinusLogProbMetric: 2.3949 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-11 21:23:14.413 
Epoch 151/1000 
	 loss: 2.3885, MinusLogProbMetric: 2.3885, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 151: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3885 - MinusLogProbMetric: 2.3885 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-11 21:23:26.210 
Epoch 152/1000 
	 loss: 2.4057, MinusLogProbMetric: 2.4057, val_loss: 2.8482, val_MinusLogProbMetric: 2.8482

Epoch 152: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.4057 - MinusLogProbMetric: 2.4057 - val_loss: 2.8482 - val_MinusLogProbMetric: 2.8482 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-11 21:23:38.010 
Epoch 153/1000 
	 loss: 2.4175, MinusLogProbMetric: 2.4175, val_loss: 2.3864, val_MinusLogProbMetric: 2.3864

Epoch 153: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.4175 - MinusLogProbMetric: 2.4175 - val_loss: 2.3864 - val_MinusLogProbMetric: 2.3864 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 154/1000
2023-09-11 21:23:49.558 
Epoch 154/1000 
	 loss: 2.3910, MinusLogProbMetric: 2.3910, val_loss: 2.3804, val_MinusLogProbMetric: 2.3804

Epoch 154: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3910 - MinusLogProbMetric: 2.3910 - val_loss: 2.3804 - val_MinusLogProbMetric: 2.3804 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 155/1000
2023-09-11 21:24:01.246 
Epoch 155/1000 
	 loss: 2.3889, MinusLogProbMetric: 2.3889, val_loss: 2.4108, val_MinusLogProbMetric: 2.4108

Epoch 155: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3889 - MinusLogProbMetric: 2.3889 - val_loss: 2.4108 - val_MinusLogProbMetric: 2.4108 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 156/1000
2023-09-11 21:24:12.958 
Epoch 156/1000 
	 loss: 2.3883, MinusLogProbMetric: 2.3883, val_loss: 2.3806, val_MinusLogProbMetric: 2.3806

Epoch 156: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3883 - MinusLogProbMetric: 2.3883 - val_loss: 2.3806 - val_MinusLogProbMetric: 2.3806 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 157/1000
2023-09-11 21:24:24.706 
Epoch 157/1000 
	 loss: 2.3887, MinusLogProbMetric: 2.3887, val_loss: 2.4085, val_MinusLogProbMetric: 2.4085

Epoch 157: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3887 - MinusLogProbMetric: 2.3887 - val_loss: 2.4085 - val_MinusLogProbMetric: 2.4085 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-11 21:24:36.254 
Epoch 158/1000 
	 loss: 2.3889, MinusLogProbMetric: 2.3889, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 158: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3889 - MinusLogProbMetric: 2.3889 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 159/1000
2023-09-11 21:24:47.773 
Epoch 159/1000 
	 loss: 2.3838, MinusLogProbMetric: 2.3838, val_loss: 2.3818, val_MinusLogProbMetric: 2.3818

Epoch 159: val_loss did not improve from 2.37772
196/196 - 12s - loss: 2.3838 - MinusLogProbMetric: 2.3838 - val_loss: 2.3818 - val_MinusLogProbMetric: 2.3818 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 160/1000
2023-09-11 21:24:59.357 
Epoch 160/1000 
	 loss: 2.3856, MinusLogProbMetric: 2.3856, val_loss: 2.3752, val_MinusLogProbMetric: 2.3752

Epoch 160: val_loss improved from 2.37772 to 2.37517, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3856 - MinusLogProbMetric: 2.3856 - val_loss: 2.3752 - val_MinusLogProbMetric: 2.3752 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 161/1000
2023-09-11 21:25:10.996 
Epoch 161/1000 
	 loss: 2.3847, MinusLogProbMetric: 2.3847, val_loss: 2.3910, val_MinusLogProbMetric: 2.3910

Epoch 161: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3847 - MinusLogProbMetric: 2.3847 - val_loss: 2.3910 - val_MinusLogProbMetric: 2.3910 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 162/1000
2023-09-11 21:25:22.506 
Epoch 162/1000 
	 loss: 2.3879, MinusLogProbMetric: 2.3879, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 162: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3879 - MinusLogProbMetric: 2.3879 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 163/1000
2023-09-11 21:25:34.087 
Epoch 163/1000 
	 loss: 2.3851, MinusLogProbMetric: 2.3851, val_loss: 2.4104, val_MinusLogProbMetric: 2.4104

Epoch 163: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3851 - MinusLogProbMetric: 2.3851 - val_loss: 2.4104 - val_MinusLogProbMetric: 2.4104 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 164/1000
2023-09-11 21:25:45.913 
Epoch 164/1000 
	 loss: 2.3872, MinusLogProbMetric: 2.3872, val_loss: 2.3871, val_MinusLogProbMetric: 2.3871

Epoch 164: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3872 - MinusLogProbMetric: 2.3872 - val_loss: 2.3871 - val_MinusLogProbMetric: 2.3871 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 165/1000
2023-09-11 21:25:57.347 
Epoch 165/1000 
	 loss: 2.3855, MinusLogProbMetric: 2.3855, val_loss: 2.3852, val_MinusLogProbMetric: 2.3852

Epoch 165: val_loss did not improve from 2.37517
196/196 - 11s - loss: 2.3855 - MinusLogProbMetric: 2.3855 - val_loss: 2.3852 - val_MinusLogProbMetric: 2.3852 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 166/1000
2023-09-11 21:26:09.074 
Epoch 166/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.3918, val_MinusLogProbMetric: 2.3918

Epoch 166: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.3918 - val_MinusLogProbMetric: 2.3918 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 167/1000
2023-09-11 21:26:20.760 
Epoch 167/1000 
	 loss: 2.3840, MinusLogProbMetric: 2.3840, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 167: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3840 - MinusLogProbMetric: 2.3840 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 168/1000
2023-09-11 21:26:32.564 
Epoch 168/1000 
	 loss: 2.3873, MinusLogProbMetric: 2.3873, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 168: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3873 - MinusLogProbMetric: 2.3873 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-11 21:26:44.338 
Epoch 169/1000 
	 loss: 2.3823, MinusLogProbMetric: 2.3823, val_loss: 2.3815, val_MinusLogProbMetric: 2.3815

Epoch 169: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3823 - MinusLogProbMetric: 2.3823 - val_loss: 2.3815 - val_MinusLogProbMetric: 2.3815 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 170/1000
2023-09-11 21:26:56.097 
Epoch 170/1000 
	 loss: 2.3874, MinusLogProbMetric: 2.3874, val_loss: 2.3768, val_MinusLogProbMetric: 2.3768

Epoch 170: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3874 - MinusLogProbMetric: 2.3874 - val_loss: 2.3768 - val_MinusLogProbMetric: 2.3768 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 171/1000
2023-09-11 21:27:07.907 
Epoch 171/1000 
	 loss: 2.3867, MinusLogProbMetric: 2.3867, val_loss: 2.4008, val_MinusLogProbMetric: 2.4008

Epoch 171: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3867 - MinusLogProbMetric: 2.3867 - val_loss: 2.4008 - val_MinusLogProbMetric: 2.4008 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 172/1000
2023-09-11 21:27:19.627 
Epoch 172/1000 
	 loss: 2.3847, MinusLogProbMetric: 2.3847, val_loss: 2.4007, val_MinusLogProbMetric: 2.4007

Epoch 172: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3847 - MinusLogProbMetric: 2.3847 - val_loss: 2.4007 - val_MinusLogProbMetric: 2.4007 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 173/1000
2023-09-11 21:27:31.292 
Epoch 173/1000 
	 loss: 2.3836, MinusLogProbMetric: 2.3836, val_loss: 2.3889, val_MinusLogProbMetric: 2.3889

Epoch 173: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3836 - MinusLogProbMetric: 2.3836 - val_loss: 2.3889 - val_MinusLogProbMetric: 2.3889 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 174/1000
2023-09-11 21:27:42.963 
Epoch 174/1000 
	 loss: 2.3859, MinusLogProbMetric: 2.3859, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 174: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3859 - MinusLogProbMetric: 2.3859 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 175/1000
2023-09-11 21:27:54.661 
Epoch 175/1000 
	 loss: 2.3808, MinusLogProbMetric: 2.3808, val_loss: 2.3817, val_MinusLogProbMetric: 2.3817

Epoch 175: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3808 - MinusLogProbMetric: 2.3808 - val_loss: 2.3817 - val_MinusLogProbMetric: 2.3817 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 176/1000
2023-09-11 21:28:06.454 
Epoch 176/1000 
	 loss: 2.3841, MinusLogProbMetric: 2.3841, val_loss: 2.4083, val_MinusLogProbMetric: 2.4083

Epoch 176: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3841 - MinusLogProbMetric: 2.3841 - val_loss: 2.4083 - val_MinusLogProbMetric: 2.4083 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-11 21:28:18.102 
Epoch 177/1000 
	 loss: 2.3852, MinusLogProbMetric: 2.3852, val_loss: 2.3765, val_MinusLogProbMetric: 2.3765

Epoch 177: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3852 - MinusLogProbMetric: 2.3852 - val_loss: 2.3765 - val_MinusLogProbMetric: 2.3765 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 178/1000
2023-09-11 21:28:29.783 
Epoch 178/1000 
	 loss: 2.3834, MinusLogProbMetric: 2.3834, val_loss: 2.3946, val_MinusLogProbMetric: 2.3946

Epoch 178: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3834 - MinusLogProbMetric: 2.3834 - val_loss: 2.3946 - val_MinusLogProbMetric: 2.3946 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-11 21:28:41.529 
Epoch 179/1000 
	 loss: 2.3794, MinusLogProbMetric: 2.3794, val_loss: 2.3829, val_MinusLogProbMetric: 2.3829

Epoch 179: val_loss did not improve from 2.37517
196/196 - 12s - loss: 2.3794 - MinusLogProbMetric: 2.3794 - val_loss: 2.3829 - val_MinusLogProbMetric: 2.3829 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 180/1000
2023-09-11 21:28:53.214 
Epoch 180/1000 
	 loss: 2.3839, MinusLogProbMetric: 2.3839, val_loss: 2.3740, val_MinusLogProbMetric: 2.3740

Epoch 180: val_loss improved from 2.37517 to 2.37397, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3839 - MinusLogProbMetric: 2.3839 - val_loss: 2.3740 - val_MinusLogProbMetric: 2.3740 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 181/1000
2023-09-11 21:29:05.072 
Epoch 181/1000 
	 loss: 2.3837, MinusLogProbMetric: 2.3837, val_loss: 2.4104, val_MinusLogProbMetric: 2.4104

Epoch 181: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3837 - MinusLogProbMetric: 2.3837 - val_loss: 2.4104 - val_MinusLogProbMetric: 2.4104 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 182/1000
2023-09-11 21:29:16.663 
Epoch 182/1000 
	 loss: 2.3825, MinusLogProbMetric: 2.3825, val_loss: 2.3741, val_MinusLogProbMetric: 2.3741

Epoch 182: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3825 - MinusLogProbMetric: 2.3825 - val_loss: 2.3741 - val_MinusLogProbMetric: 2.3741 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 183/1000
2023-09-11 21:29:28.364 
Epoch 183/1000 
	 loss: 2.3837, MinusLogProbMetric: 2.3837, val_loss: 2.3768, val_MinusLogProbMetric: 2.3768

Epoch 183: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3837 - MinusLogProbMetric: 2.3837 - val_loss: 2.3768 - val_MinusLogProbMetric: 2.3768 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 184/1000
2023-09-11 21:29:40.026 
Epoch 184/1000 
	 loss: 2.3841, MinusLogProbMetric: 2.3841, val_loss: 2.3797, val_MinusLogProbMetric: 2.3797

Epoch 184: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3841 - MinusLogProbMetric: 2.3841 - val_loss: 2.3797 - val_MinusLogProbMetric: 2.3797 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 185/1000
2023-09-11 21:29:51.674 
Epoch 185/1000 
	 loss: 2.3880, MinusLogProbMetric: 2.3880, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 185: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3880 - MinusLogProbMetric: 2.3880 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 186/1000
2023-09-11 21:30:03.273 
Epoch 186/1000 
	 loss: 2.3847, MinusLogProbMetric: 2.3847, val_loss: 2.3780, val_MinusLogProbMetric: 2.3780

Epoch 186: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3847 - MinusLogProbMetric: 2.3847 - val_loss: 2.3780 - val_MinusLogProbMetric: 2.3780 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 187/1000
2023-09-11 21:30:14.926 
Epoch 187/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.4266, val_MinusLogProbMetric: 2.4266

Epoch 187: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.4266 - val_MinusLogProbMetric: 2.4266 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 188/1000
2023-09-11 21:30:26.545 
Epoch 188/1000 
	 loss: 2.3825, MinusLogProbMetric: 2.3825, val_loss: 2.3757, val_MinusLogProbMetric: 2.3757

Epoch 188: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3825 - MinusLogProbMetric: 2.3825 - val_loss: 2.3757 - val_MinusLogProbMetric: 2.3757 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 189/1000
2023-09-11 21:30:38.169 
Epoch 189/1000 
	 loss: 2.3799, MinusLogProbMetric: 2.3799, val_loss: 2.4242, val_MinusLogProbMetric: 2.4242

Epoch 189: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3799 - MinusLogProbMetric: 2.3799 - val_loss: 2.4242 - val_MinusLogProbMetric: 2.4242 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 190/1000
2023-09-11 21:30:49.998 
Epoch 190/1000 
	 loss: 2.3816, MinusLogProbMetric: 2.3816, val_loss: 2.3821, val_MinusLogProbMetric: 2.3821

Epoch 190: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3816 - MinusLogProbMetric: 2.3816 - val_loss: 2.3821 - val_MinusLogProbMetric: 2.3821 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-11 21:31:01.721 
Epoch 191/1000 
	 loss: 2.3813, MinusLogProbMetric: 2.3813, val_loss: 2.3761, val_MinusLogProbMetric: 2.3761

Epoch 191: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3813 - MinusLogProbMetric: 2.3813 - val_loss: 2.3761 - val_MinusLogProbMetric: 2.3761 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 192/1000
2023-09-11 21:31:13.429 
Epoch 192/1000 
	 loss: 2.3844, MinusLogProbMetric: 2.3844, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 192: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3844 - MinusLogProbMetric: 2.3844 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-11 21:31:25.162 
Epoch 193/1000 
	 loss: 2.3842, MinusLogProbMetric: 2.3842, val_loss: 2.3760, val_MinusLogProbMetric: 2.3760

Epoch 193: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3842 - MinusLogProbMetric: 2.3842 - val_loss: 2.3760 - val_MinusLogProbMetric: 2.3760 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-11 21:31:36.792 
Epoch 194/1000 
	 loss: 2.3835, MinusLogProbMetric: 2.3835, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 194: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3835 - MinusLogProbMetric: 2.3835 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 195/1000
2023-09-11 21:31:48.452 
Epoch 195/1000 
	 loss: 2.3813, MinusLogProbMetric: 2.3813, val_loss: 2.3996, val_MinusLogProbMetric: 2.3996

Epoch 195: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3813 - MinusLogProbMetric: 2.3813 - val_loss: 2.3996 - val_MinusLogProbMetric: 2.3996 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 196/1000
2023-09-11 21:32:00.238 
Epoch 196/1000 
	 loss: 2.3811, MinusLogProbMetric: 2.3811, val_loss: 2.3761, val_MinusLogProbMetric: 2.3761

Epoch 196: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3811 - MinusLogProbMetric: 2.3811 - val_loss: 2.3761 - val_MinusLogProbMetric: 2.3761 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-11 21:32:11.957 
Epoch 197/1000 
	 loss: 2.3808, MinusLogProbMetric: 2.3808, val_loss: 2.4048, val_MinusLogProbMetric: 2.4048

Epoch 197: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3808 - MinusLogProbMetric: 2.3808 - val_loss: 2.4048 - val_MinusLogProbMetric: 2.4048 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-11 21:32:23.555 
Epoch 198/1000 
	 loss: 2.3812, MinusLogProbMetric: 2.3812, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 198: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3812 - MinusLogProbMetric: 2.3812 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 199/1000
2023-09-11 21:32:35.318 
Epoch 199/1000 
	 loss: 2.3882, MinusLogProbMetric: 2.3882, val_loss: 2.3892, val_MinusLogProbMetric: 2.3892

Epoch 199: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3882 - MinusLogProbMetric: 2.3882 - val_loss: 2.3892 - val_MinusLogProbMetric: 2.3892 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-11 21:32:47.066 
Epoch 200/1000 
	 loss: 2.3812, MinusLogProbMetric: 2.3812, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 200: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3812 - MinusLogProbMetric: 2.3812 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-11 21:32:58.864 
Epoch 201/1000 
	 loss: 2.3788, MinusLogProbMetric: 2.3788, val_loss: 2.3763, val_MinusLogProbMetric: 2.3763

Epoch 201: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3788 - MinusLogProbMetric: 2.3788 - val_loss: 2.3763 - val_MinusLogProbMetric: 2.3763 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-11 21:33:10.589 
Epoch 202/1000 
	 loss: 2.3812, MinusLogProbMetric: 2.3812, val_loss: 2.3910, val_MinusLogProbMetric: 2.3910

Epoch 202: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3812 - MinusLogProbMetric: 2.3812 - val_loss: 2.3910 - val_MinusLogProbMetric: 2.3910 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-11 21:33:22.214 
Epoch 203/1000 
	 loss: 2.3778, MinusLogProbMetric: 2.3778, val_loss: 2.3775, val_MinusLogProbMetric: 2.3775

Epoch 203: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3778 - MinusLogProbMetric: 2.3778 - val_loss: 2.3775 - val_MinusLogProbMetric: 2.3775 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 204/1000
2023-09-11 21:33:33.906 
Epoch 204/1000 
	 loss: 2.3789, MinusLogProbMetric: 2.3789, val_loss: 2.3827, val_MinusLogProbMetric: 2.3827

Epoch 204: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3789 - MinusLogProbMetric: 2.3789 - val_loss: 2.3827 - val_MinusLogProbMetric: 2.3827 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-11 21:33:45.567 
Epoch 205/1000 
	 loss: 2.3802, MinusLogProbMetric: 2.3802, val_loss: 2.3908, val_MinusLogProbMetric: 2.3908

Epoch 205: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3802 - MinusLogProbMetric: 2.3802 - val_loss: 2.3908 - val_MinusLogProbMetric: 2.3908 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 206/1000
2023-09-11 21:33:57.298 
Epoch 206/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3810, val_MinusLogProbMetric: 2.3810

Epoch 206: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3810 - val_MinusLogProbMetric: 2.3810 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 207/1000
2023-09-11 21:34:08.892 
Epoch 207/1000 
	 loss: 2.3794, MinusLogProbMetric: 2.3794, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 207: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3794 - MinusLogProbMetric: 2.3794 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 208/1000
2023-09-11 21:34:20.604 
Epoch 208/1000 
	 loss: 2.3768, MinusLogProbMetric: 2.3768, val_loss: 2.4224, val_MinusLogProbMetric: 2.4224

Epoch 208: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3768 - MinusLogProbMetric: 2.3768 - val_loss: 2.4224 - val_MinusLogProbMetric: 2.4224 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 209/1000
2023-09-11 21:34:32.064 
Epoch 209/1000 
	 loss: 2.3785, MinusLogProbMetric: 2.3785, val_loss: 2.3745, val_MinusLogProbMetric: 2.3745

Epoch 209: val_loss did not improve from 2.37397
196/196 - 11s - loss: 2.3785 - MinusLogProbMetric: 2.3785 - val_loss: 2.3745 - val_MinusLogProbMetric: 2.3745 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 210/1000
2023-09-11 21:34:43.674 
Epoch 210/1000 
	 loss: 2.3798, MinusLogProbMetric: 2.3798, val_loss: 2.3948, val_MinusLogProbMetric: 2.3948

Epoch 210: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3798 - MinusLogProbMetric: 2.3798 - val_loss: 2.3948 - val_MinusLogProbMetric: 2.3948 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 211/1000
2023-09-11 21:34:55.182 
Epoch 211/1000 
	 loss: 2.3794, MinusLogProbMetric: 2.3794, val_loss: 2.3772, val_MinusLogProbMetric: 2.3772

Epoch 211: val_loss did not improve from 2.37397
196/196 - 12s - loss: 2.3794 - MinusLogProbMetric: 2.3794 - val_loss: 2.3772 - val_MinusLogProbMetric: 2.3772 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 212/1000
2023-09-11 21:35:05.661 
Epoch 212/1000 
	 loss: 2.3768, MinusLogProbMetric: 2.3768, val_loss: 2.3732, val_MinusLogProbMetric: 2.3732

Epoch 212: val_loss improved from 2.37397 to 2.37316, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 11s - loss: 2.3768 - MinusLogProbMetric: 2.3768 - val_loss: 2.3732 - val_MinusLogProbMetric: 2.3732 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 213/1000
2023-09-11 21:35:17.322 
Epoch 213/1000 
	 loss: 2.3824, MinusLogProbMetric: 2.3824, val_loss: 2.3805, val_MinusLogProbMetric: 2.3805

Epoch 213: val_loss did not improve from 2.37316
196/196 - 12s - loss: 2.3824 - MinusLogProbMetric: 2.3824 - val_loss: 2.3805 - val_MinusLogProbMetric: 2.3805 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 214/1000
2023-09-11 21:35:29.074 
Epoch 214/1000 
	 loss: 2.3797, MinusLogProbMetric: 2.3797, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 214: val_loss improved from 2.37316 to 2.37041, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3797 - MinusLogProbMetric: 2.3797 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-11 21:35:40.966 
Epoch 215/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3836, val_MinusLogProbMetric: 2.3836

Epoch 215: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3836 - val_MinusLogProbMetric: 2.3836 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 216/1000
2023-09-11 21:35:52.541 
Epoch 216/1000 
	 loss: 2.3815, MinusLogProbMetric: 2.3815, val_loss: 2.3771, val_MinusLogProbMetric: 2.3771

Epoch 216: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3815 - MinusLogProbMetric: 2.3815 - val_loss: 2.3771 - val_MinusLogProbMetric: 2.3771 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 217/1000
2023-09-11 21:36:04.253 
Epoch 217/1000 
	 loss: 2.3797, MinusLogProbMetric: 2.3797, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 217: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3797 - MinusLogProbMetric: 2.3797 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 218/1000
2023-09-11 21:36:15.966 
Epoch 218/1000 
	 loss: 2.3773, MinusLogProbMetric: 2.3773, val_loss: 2.3782, val_MinusLogProbMetric: 2.3782

Epoch 218: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3773 - MinusLogProbMetric: 2.3773 - val_loss: 2.3782 - val_MinusLogProbMetric: 2.3782 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-11 21:36:27.609 
Epoch 219/1000 
	 loss: 2.3836, MinusLogProbMetric: 2.3836, val_loss: 2.3862, val_MinusLogProbMetric: 2.3862

Epoch 219: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3836 - MinusLogProbMetric: 2.3836 - val_loss: 2.3862 - val_MinusLogProbMetric: 2.3862 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 220/1000
2023-09-11 21:36:39.368 
Epoch 220/1000 
	 loss: 2.3800, MinusLogProbMetric: 2.3800, val_loss: 2.3856, val_MinusLogProbMetric: 2.3856

Epoch 220: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3800 - MinusLogProbMetric: 2.3800 - val_loss: 2.3856 - val_MinusLogProbMetric: 2.3856 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 221/1000
2023-09-11 21:36:51.116 
Epoch 221/1000 
	 loss: 2.3804, MinusLogProbMetric: 2.3804, val_loss: 2.3803, val_MinusLogProbMetric: 2.3803

Epoch 221: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3804 - MinusLogProbMetric: 2.3804 - val_loss: 2.3803 - val_MinusLogProbMetric: 2.3803 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-11 21:37:02.749 
Epoch 222/1000 
	 loss: 2.3790, MinusLogProbMetric: 2.3790, val_loss: 2.3808, val_MinusLogProbMetric: 2.3808

Epoch 222: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3790 - MinusLogProbMetric: 2.3790 - val_loss: 2.3808 - val_MinusLogProbMetric: 2.3808 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 223/1000
2023-09-11 21:37:14.351 
Epoch 223/1000 
	 loss: 2.3842, MinusLogProbMetric: 2.3842, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 223: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3842 - MinusLogProbMetric: 2.3842 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 224/1000
2023-09-11 21:37:26.113 
Epoch 224/1000 
	 loss: 2.3753, MinusLogProbMetric: 2.3753, val_loss: 2.3860, val_MinusLogProbMetric: 2.3860

Epoch 224: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3753 - MinusLogProbMetric: 2.3753 - val_loss: 2.3860 - val_MinusLogProbMetric: 2.3860 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-11 21:37:37.864 
Epoch 225/1000 
	 loss: 2.3779, MinusLogProbMetric: 2.3779, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 225: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3779 - MinusLogProbMetric: 2.3779 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-11 21:37:49.572 
Epoch 226/1000 
	 loss: 2.3794, MinusLogProbMetric: 2.3794, val_loss: 2.3805, val_MinusLogProbMetric: 2.3805

Epoch 226: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3794 - MinusLogProbMetric: 2.3794 - val_loss: 2.3805 - val_MinusLogProbMetric: 2.3805 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 227/1000
2023-09-11 21:38:01.246 
Epoch 227/1000 
	 loss: 2.3765, MinusLogProbMetric: 2.3765, val_loss: 2.3851, val_MinusLogProbMetric: 2.3851

Epoch 227: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3765 - MinusLogProbMetric: 2.3765 - val_loss: 2.3851 - val_MinusLogProbMetric: 2.3851 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 228/1000
2023-09-11 21:38:12.953 
Epoch 228/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3972, val_MinusLogProbMetric: 2.3972

Epoch 228: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3972 - val_MinusLogProbMetric: 2.3972 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 229/1000
2023-09-11 21:38:24.796 
Epoch 229/1000 
	 loss: 2.3775, MinusLogProbMetric: 2.3775, val_loss: 2.3797, val_MinusLogProbMetric: 2.3797

Epoch 229: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3775 - MinusLogProbMetric: 2.3775 - val_loss: 2.3797 - val_MinusLogProbMetric: 2.3797 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-11 21:38:36.621 
Epoch 230/1000 
	 loss: 2.3761, MinusLogProbMetric: 2.3761, val_loss: 2.3781, val_MinusLogProbMetric: 2.3781

Epoch 230: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3761 - MinusLogProbMetric: 2.3761 - val_loss: 2.3781 - val_MinusLogProbMetric: 2.3781 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 231/1000
2023-09-11 21:38:48.564 
Epoch 231/1000 
	 loss: 2.3775, MinusLogProbMetric: 2.3775, val_loss: 2.3832, val_MinusLogProbMetric: 2.3832

Epoch 231: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3775 - MinusLogProbMetric: 2.3775 - val_loss: 2.3832 - val_MinusLogProbMetric: 2.3832 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 232/1000
2023-09-11 21:39:00.301 
Epoch 232/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.3837, val_MinusLogProbMetric: 2.3837

Epoch 232: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.3837 - val_MinusLogProbMetric: 2.3837 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 233/1000
2023-09-11 21:39:12.104 
Epoch 233/1000 
	 loss: 2.3782, MinusLogProbMetric: 2.3782, val_loss: 2.3747, val_MinusLogProbMetric: 2.3747

Epoch 233: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3782 - MinusLogProbMetric: 2.3782 - val_loss: 2.3747 - val_MinusLogProbMetric: 2.3747 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 234/1000
2023-09-11 21:39:23.896 
Epoch 234/1000 
	 loss: 2.3780, MinusLogProbMetric: 2.3780, val_loss: 2.4247, val_MinusLogProbMetric: 2.4247

Epoch 234: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3780 - MinusLogProbMetric: 2.3780 - val_loss: 2.4247 - val_MinusLogProbMetric: 2.4247 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-11 21:39:35.581 
Epoch 235/1000 
	 loss: 2.3788, MinusLogProbMetric: 2.3788, val_loss: 2.3768, val_MinusLogProbMetric: 2.3768

Epoch 235: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3788 - MinusLogProbMetric: 2.3788 - val_loss: 2.3768 - val_MinusLogProbMetric: 2.3768 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 236/1000
2023-09-11 21:39:47.245 
Epoch 236/1000 
	 loss: 2.3791, MinusLogProbMetric: 2.3791, val_loss: 2.3823, val_MinusLogProbMetric: 2.3823

Epoch 236: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3791 - MinusLogProbMetric: 2.3791 - val_loss: 2.3823 - val_MinusLogProbMetric: 2.3823 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 237/1000
2023-09-11 21:39:58.966 
Epoch 237/1000 
	 loss: 2.3764, MinusLogProbMetric: 2.3764, val_loss: 2.3841, val_MinusLogProbMetric: 2.3841

Epoch 237: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3764 - MinusLogProbMetric: 2.3764 - val_loss: 2.3841 - val_MinusLogProbMetric: 2.3841 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 238/1000
2023-09-11 21:40:10.714 
Epoch 238/1000 
	 loss: 2.3826, MinusLogProbMetric: 2.3826, val_loss: 2.3722, val_MinusLogProbMetric: 2.3722

Epoch 238: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3826 - MinusLogProbMetric: 2.3826 - val_loss: 2.3722 - val_MinusLogProbMetric: 2.3722 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-11 21:40:22.388 
Epoch 239/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3773, val_MinusLogProbMetric: 2.3773

Epoch 239: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3773 - val_MinusLogProbMetric: 2.3773 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 240/1000
2023-09-11 21:40:34.101 
Epoch 240/1000 
	 loss: 2.3786, MinusLogProbMetric: 2.3786, val_loss: 2.3749, val_MinusLogProbMetric: 2.3749

Epoch 240: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3786 - MinusLogProbMetric: 2.3786 - val_loss: 2.3749 - val_MinusLogProbMetric: 2.3749 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-11 21:40:45.818 
Epoch 241/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3844, val_MinusLogProbMetric: 2.3844

Epoch 241: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3844 - val_MinusLogProbMetric: 2.3844 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 242/1000
2023-09-11 21:40:57.433 
Epoch 242/1000 
	 loss: 2.3762, MinusLogProbMetric: 2.3762, val_loss: 2.3763, val_MinusLogProbMetric: 2.3763

Epoch 242: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3762 - MinusLogProbMetric: 2.3762 - val_loss: 2.3763 - val_MinusLogProbMetric: 2.3763 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 243/1000
2023-09-11 21:41:09.069 
Epoch 243/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3816, val_MinusLogProbMetric: 2.3816

Epoch 243: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3816 - val_MinusLogProbMetric: 2.3816 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 244/1000
2023-09-11 21:41:20.888 
Epoch 244/1000 
	 loss: 2.3748, MinusLogProbMetric: 2.3748, val_loss: 2.3805, val_MinusLogProbMetric: 2.3805

Epoch 244: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3748 - MinusLogProbMetric: 2.3748 - val_loss: 2.3805 - val_MinusLogProbMetric: 2.3805 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 245/1000
2023-09-11 21:41:32.524 
Epoch 245/1000 
	 loss: 2.3766, MinusLogProbMetric: 2.3766, val_loss: 2.3796, val_MinusLogProbMetric: 2.3796

Epoch 245: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3766 - MinusLogProbMetric: 2.3766 - val_loss: 2.3796 - val_MinusLogProbMetric: 2.3796 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 246/1000
2023-09-11 21:41:44.312 
Epoch 246/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3752, val_MinusLogProbMetric: 2.3752

Epoch 246: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3752 - val_MinusLogProbMetric: 2.3752 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 247/1000
2023-09-11 21:41:56.051 
Epoch 247/1000 
	 loss: 2.3779, MinusLogProbMetric: 2.3779, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 247: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3779 - MinusLogProbMetric: 2.3779 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-11 21:42:07.852 
Epoch 248/1000 
	 loss: 2.3759, MinusLogProbMetric: 2.3759, val_loss: 2.3777, val_MinusLogProbMetric: 2.3777

Epoch 248: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3759 - MinusLogProbMetric: 2.3759 - val_loss: 2.3777 - val_MinusLogProbMetric: 2.3777 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-11 21:42:19.618 
Epoch 249/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.3767, val_MinusLogProbMetric: 2.3767

Epoch 249: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.3767 - val_MinusLogProbMetric: 2.3767 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 250/1000
2023-09-11 21:42:31.313 
Epoch 250/1000 
	 loss: 2.3743, MinusLogProbMetric: 2.3743, val_loss: 2.3814, val_MinusLogProbMetric: 2.3814

Epoch 250: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3743 - MinusLogProbMetric: 2.3743 - val_loss: 2.3814 - val_MinusLogProbMetric: 2.3814 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-11 21:42:42.923 
Epoch 251/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3929, val_MinusLogProbMetric: 2.3929

Epoch 251: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3929 - val_MinusLogProbMetric: 2.3929 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 252/1000
2023-09-11 21:42:54.598 
Epoch 252/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 252: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-11 21:43:06.333 
Epoch 253/1000 
	 loss: 2.3792, MinusLogProbMetric: 2.3792, val_loss: 2.3714, val_MinusLogProbMetric: 2.3714

Epoch 253: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3792 - MinusLogProbMetric: 2.3792 - val_loss: 2.3714 - val_MinusLogProbMetric: 2.3714 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 254/1000
2023-09-11 21:43:18.086 
Epoch 254/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.3815, val_MinusLogProbMetric: 2.3815

Epoch 254: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.3815 - val_MinusLogProbMetric: 2.3815 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-11 21:43:29.858 
Epoch 255/1000 
	 loss: 2.3755, MinusLogProbMetric: 2.3755, val_loss: 2.3791, val_MinusLogProbMetric: 2.3791

Epoch 255: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3755 - MinusLogProbMetric: 2.3755 - val_loss: 2.3791 - val_MinusLogProbMetric: 2.3791 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 256/1000
2023-09-11 21:43:41.582 
Epoch 256/1000 
	 loss: 2.3745, MinusLogProbMetric: 2.3745, val_loss: 2.3966, val_MinusLogProbMetric: 2.3966

Epoch 256: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3745 - MinusLogProbMetric: 2.3745 - val_loss: 2.3966 - val_MinusLogProbMetric: 2.3966 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 257/1000
2023-09-11 21:43:53.318 
Epoch 257/1000 
	 loss: 2.3751, MinusLogProbMetric: 2.3751, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 257: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3751 - MinusLogProbMetric: 2.3751 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-11 21:44:05.039 
Epoch 258/1000 
	 loss: 2.3785, MinusLogProbMetric: 2.3785, val_loss: 2.4093, val_MinusLogProbMetric: 2.4093

Epoch 258: val_loss did not improve from 2.37041
196/196 - 12s - loss: 2.3785 - MinusLogProbMetric: 2.3785 - val_loss: 2.4093 - val_MinusLogProbMetric: 2.4093 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 259/1000
2023-09-11 21:44:16.750 
Epoch 259/1000 
	 loss: 2.3772, MinusLogProbMetric: 2.3772, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 259: val_loss improved from 2.37041 to 2.36931, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3772 - MinusLogProbMetric: 2.3772 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 260/1000
2023-09-11 21:44:28.520 
Epoch 260/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 260: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 261/1000
2023-09-11 21:44:40.199 
Epoch 261/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3732, val_MinusLogProbMetric: 2.3732

Epoch 261: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3732 - val_MinusLogProbMetric: 2.3732 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 262/1000
2023-09-11 21:44:51.935 
Epoch 262/1000 
	 loss: 2.3774, MinusLogProbMetric: 2.3774, val_loss: 2.3745, val_MinusLogProbMetric: 2.3745

Epoch 262: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3774 - MinusLogProbMetric: 2.3774 - val_loss: 2.3745 - val_MinusLogProbMetric: 2.3745 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-11 21:45:03.581 
Epoch 263/1000 
	 loss: 2.3748, MinusLogProbMetric: 2.3748, val_loss: 2.3866, val_MinusLogProbMetric: 2.3866

Epoch 263: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3748 - MinusLogProbMetric: 2.3748 - val_loss: 2.3866 - val_MinusLogProbMetric: 2.3866 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 264/1000
2023-09-11 21:45:15.380 
Epoch 264/1000 
	 loss: 2.3737, MinusLogProbMetric: 2.3737, val_loss: 2.3782, val_MinusLogProbMetric: 2.3782

Epoch 264: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3737 - MinusLogProbMetric: 2.3737 - val_loss: 2.3782 - val_MinusLogProbMetric: 2.3782 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 265/1000
2023-09-11 21:45:27.157 
Epoch 265/1000 
	 loss: 2.3763, MinusLogProbMetric: 2.3763, val_loss: 2.3725, val_MinusLogProbMetric: 2.3725

Epoch 265: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3763 - MinusLogProbMetric: 2.3763 - val_loss: 2.3725 - val_MinusLogProbMetric: 2.3725 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 266/1000
2023-09-11 21:45:38.836 
Epoch 266/1000 
	 loss: 2.3751, MinusLogProbMetric: 2.3751, val_loss: 2.3810, val_MinusLogProbMetric: 2.3810

Epoch 266: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3751 - MinusLogProbMetric: 2.3751 - val_loss: 2.3810 - val_MinusLogProbMetric: 2.3810 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 267/1000
2023-09-11 21:45:50.308 
Epoch 267/1000 
	 loss: 2.3736, MinusLogProbMetric: 2.3736, val_loss: 2.3895, val_MinusLogProbMetric: 2.3895

Epoch 267: val_loss did not improve from 2.36931
196/196 - 11s - loss: 2.3736 - MinusLogProbMetric: 2.3736 - val_loss: 2.3895 - val_MinusLogProbMetric: 2.3895 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 268/1000
2023-09-11 21:46:01.994 
Epoch 268/1000 
	 loss: 2.3785, MinusLogProbMetric: 2.3785, val_loss: 2.3733, val_MinusLogProbMetric: 2.3733

Epoch 268: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3785 - MinusLogProbMetric: 2.3785 - val_loss: 2.3733 - val_MinusLogProbMetric: 2.3733 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-11 21:46:13.225 
Epoch 269/1000 
	 loss: 2.3755, MinusLogProbMetric: 2.3755, val_loss: 2.3857, val_MinusLogProbMetric: 2.3857

Epoch 269: val_loss did not improve from 2.36931
196/196 - 11s - loss: 2.3755 - MinusLogProbMetric: 2.3755 - val_loss: 2.3857 - val_MinusLogProbMetric: 2.3857 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 270/1000
2023-09-11 21:46:24.985 
Epoch 270/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.3839, val_MinusLogProbMetric: 2.3839

Epoch 270: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.3839 - val_MinusLogProbMetric: 2.3839 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 271/1000
2023-09-11 21:46:36.739 
Epoch 271/1000 
	 loss: 2.3800, MinusLogProbMetric: 2.3800, val_loss: 2.3751, val_MinusLogProbMetric: 2.3751

Epoch 271: val_loss did not improve from 2.36931
196/196 - 12s - loss: 2.3800 - MinusLogProbMetric: 2.3800 - val_loss: 2.3751 - val_MinusLogProbMetric: 2.3751 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-11 21:46:48.497 
Epoch 272/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.3672, val_MinusLogProbMetric: 2.3672

Epoch 272: val_loss improved from 2.36931 to 2.36718, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.3672 - val_MinusLogProbMetric: 2.3672 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 273/1000
2023-09-11 21:47:00.214 
Epoch 273/1000 
	 loss: 2.3784, MinusLogProbMetric: 2.3784, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 273: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3784 - MinusLogProbMetric: 2.3784 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 274/1000
2023-09-11 21:47:11.961 
Epoch 274/1000 
	 loss: 2.3742, MinusLogProbMetric: 2.3742, val_loss: 2.3826, val_MinusLogProbMetric: 2.3826

Epoch 274: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3742 - MinusLogProbMetric: 2.3742 - val_loss: 2.3826 - val_MinusLogProbMetric: 2.3826 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 275/1000
2023-09-11 21:47:23.556 
Epoch 275/1000 
	 loss: 2.3748, MinusLogProbMetric: 2.3748, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 275: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3748 - MinusLogProbMetric: 2.3748 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 276/1000
2023-09-11 21:47:35.111 
Epoch 276/1000 
	 loss: 2.3754, MinusLogProbMetric: 2.3754, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 276: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3754 - MinusLogProbMetric: 2.3754 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 277/1000
2023-09-11 21:47:46.874 
Epoch 277/1000 
	 loss: 2.3752, MinusLogProbMetric: 2.3752, val_loss: 2.3743, val_MinusLogProbMetric: 2.3743

Epoch 277: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3752 - MinusLogProbMetric: 2.3752 - val_loss: 2.3743 - val_MinusLogProbMetric: 2.3743 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 278/1000
2023-09-11 21:47:58.827 
Epoch 278/1000 
	 loss: 2.3757, MinusLogProbMetric: 2.3757, val_loss: 2.3824, val_MinusLogProbMetric: 2.3824

Epoch 278: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3757 - MinusLogProbMetric: 2.3757 - val_loss: 2.3824 - val_MinusLogProbMetric: 2.3824 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 279/1000
2023-09-11 21:48:10.641 
Epoch 279/1000 
	 loss: 2.3741, MinusLogProbMetric: 2.3741, val_loss: 2.3778, val_MinusLogProbMetric: 2.3778

Epoch 279: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3741 - MinusLogProbMetric: 2.3741 - val_loss: 2.3778 - val_MinusLogProbMetric: 2.3778 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 280/1000
2023-09-11 21:48:22.340 
Epoch 280/1000 
	 loss: 2.3749, MinusLogProbMetric: 2.3749, val_loss: 2.3816, val_MinusLogProbMetric: 2.3816

Epoch 280: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3749 - MinusLogProbMetric: 2.3749 - val_loss: 2.3816 - val_MinusLogProbMetric: 2.3816 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-11 21:48:33.979 
Epoch 281/1000 
	 loss: 2.3758, MinusLogProbMetric: 2.3758, val_loss: 2.3761, val_MinusLogProbMetric: 2.3761

Epoch 281: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3758 - MinusLogProbMetric: 2.3758 - val_loss: 2.3761 - val_MinusLogProbMetric: 2.3761 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 282/1000
2023-09-11 21:48:45.749 
Epoch 282/1000 
	 loss: 2.3754, MinusLogProbMetric: 2.3754, val_loss: 2.3720, val_MinusLogProbMetric: 2.3720

Epoch 282: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3754 - MinusLogProbMetric: 2.3754 - val_loss: 2.3720 - val_MinusLogProbMetric: 2.3720 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 283/1000
2023-09-11 21:48:57.461 
Epoch 283/1000 
	 loss: 2.3752, MinusLogProbMetric: 2.3752, val_loss: 2.3785, val_MinusLogProbMetric: 2.3785

Epoch 283: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3752 - MinusLogProbMetric: 2.3752 - val_loss: 2.3785 - val_MinusLogProbMetric: 2.3785 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-11 21:49:09.273 
Epoch 284/1000 
	 loss: 2.3724, MinusLogProbMetric: 2.3724, val_loss: 2.3768, val_MinusLogProbMetric: 2.3768

Epoch 284: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3724 - MinusLogProbMetric: 2.3724 - val_loss: 2.3768 - val_MinusLogProbMetric: 2.3768 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 285/1000
2023-09-11 21:49:21.133 
Epoch 285/1000 
	 loss: 2.3777, MinusLogProbMetric: 2.3777, val_loss: 2.3692, val_MinusLogProbMetric: 2.3692

Epoch 285: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3777 - MinusLogProbMetric: 2.3777 - val_loss: 2.3692 - val_MinusLogProbMetric: 2.3692 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 286/1000
2023-09-11 21:49:32.944 
Epoch 286/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.3795, val_MinusLogProbMetric: 2.3795

Epoch 286: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.3795 - val_MinusLogProbMetric: 2.3795 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 287/1000
2023-09-11 21:49:44.681 
Epoch 287/1000 
	 loss: 2.3759, MinusLogProbMetric: 2.3759, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 287: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3759 - MinusLogProbMetric: 2.3759 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 288/1000
2023-09-11 21:49:56.588 
Epoch 288/1000 
	 loss: 2.3739, MinusLogProbMetric: 2.3739, val_loss: 2.3739, val_MinusLogProbMetric: 2.3739

Epoch 288: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3739 - MinusLogProbMetric: 2.3739 - val_loss: 2.3739 - val_MinusLogProbMetric: 2.3739 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 289/1000
2023-09-11 21:50:08.332 
Epoch 289/1000 
	 loss: 2.3759, MinusLogProbMetric: 2.3759, val_loss: 2.3682, val_MinusLogProbMetric: 2.3682

Epoch 289: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3759 - MinusLogProbMetric: 2.3759 - val_loss: 2.3682 - val_MinusLogProbMetric: 2.3682 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 290/1000
2023-09-11 21:50:20.060 
Epoch 290/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3773, val_MinusLogProbMetric: 2.3773

Epoch 290: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3773 - val_MinusLogProbMetric: 2.3773 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 291/1000
2023-09-11 21:50:31.842 
Epoch 291/1000 
	 loss: 2.3773, MinusLogProbMetric: 2.3773, val_loss: 2.3853, val_MinusLogProbMetric: 2.3853

Epoch 291: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3773 - MinusLogProbMetric: 2.3773 - val_loss: 2.3853 - val_MinusLogProbMetric: 2.3853 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 292/1000
2023-09-11 21:50:43.515 
Epoch 292/1000 
	 loss: 2.3735, MinusLogProbMetric: 2.3735, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 292: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3735 - MinusLogProbMetric: 2.3735 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 293/1000
2023-09-11 21:50:55.142 
Epoch 293/1000 
	 loss: 2.3710, MinusLogProbMetric: 2.3710, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 293: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3710 - MinusLogProbMetric: 2.3710 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 294/1000
2023-09-11 21:51:06.840 
Epoch 294/1000 
	 loss: 2.3710, MinusLogProbMetric: 2.3710, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 294: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3710 - MinusLogProbMetric: 2.3710 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 295/1000
2023-09-11 21:51:18.529 
Epoch 295/1000 
	 loss: 2.3726, MinusLogProbMetric: 2.3726, val_loss: 2.3782, val_MinusLogProbMetric: 2.3782

Epoch 295: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3726 - MinusLogProbMetric: 2.3726 - val_loss: 2.3782 - val_MinusLogProbMetric: 2.3782 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 296/1000
2023-09-11 21:51:30.179 
Epoch 296/1000 
	 loss: 2.3719, MinusLogProbMetric: 2.3719, val_loss: 2.3828, val_MinusLogProbMetric: 2.3828

Epoch 296: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3719 - MinusLogProbMetric: 2.3719 - val_loss: 2.3828 - val_MinusLogProbMetric: 2.3828 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 297/1000
2023-09-11 21:51:41.904 
Epoch 297/1000 
	 loss: 2.3744, MinusLogProbMetric: 2.3744, val_loss: 2.3834, val_MinusLogProbMetric: 2.3834

Epoch 297: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3744 - MinusLogProbMetric: 2.3744 - val_loss: 2.3834 - val_MinusLogProbMetric: 2.3834 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 298/1000
2023-09-11 21:51:53.498 
Epoch 298/1000 
	 loss: 2.3718, MinusLogProbMetric: 2.3718, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 298: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3718 - MinusLogProbMetric: 2.3718 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 299/1000
2023-09-11 21:52:05.204 
Epoch 299/1000 
	 loss: 2.3730, MinusLogProbMetric: 2.3730, val_loss: 2.3860, val_MinusLogProbMetric: 2.3860

Epoch 299: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3730 - MinusLogProbMetric: 2.3730 - val_loss: 2.3860 - val_MinusLogProbMetric: 2.3860 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 300/1000
2023-09-11 21:52:16.868 
Epoch 300/1000 
	 loss: 2.3728, MinusLogProbMetric: 2.3728, val_loss: 2.3779, val_MinusLogProbMetric: 2.3779

Epoch 300: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3728 - MinusLogProbMetric: 2.3728 - val_loss: 2.3779 - val_MinusLogProbMetric: 2.3779 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 301/1000
2023-09-11 21:52:28.664 
Epoch 301/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.3766, val_MinusLogProbMetric: 2.3766

Epoch 301: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.3766 - val_MinusLogProbMetric: 2.3766 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 302/1000
2023-09-11 21:52:40.379 
Epoch 302/1000 
	 loss: 2.3723, MinusLogProbMetric: 2.3723, val_loss: 2.3752, val_MinusLogProbMetric: 2.3752

Epoch 302: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3723 - MinusLogProbMetric: 2.3723 - val_loss: 2.3752 - val_MinusLogProbMetric: 2.3752 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 303/1000
2023-09-11 21:52:52.017 
Epoch 303/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.3803, val_MinusLogProbMetric: 2.3803

Epoch 303: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.3803 - val_MinusLogProbMetric: 2.3803 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 304/1000
2023-09-11 21:53:03.804 
Epoch 304/1000 
	 loss: 2.3734, MinusLogProbMetric: 2.3734, val_loss: 2.4159, val_MinusLogProbMetric: 2.4159

Epoch 304: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3734 - MinusLogProbMetric: 2.3734 - val_loss: 2.4159 - val_MinusLogProbMetric: 2.4159 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 305/1000
2023-09-11 21:53:15.489 
Epoch 305/1000 
	 loss: 2.3727, MinusLogProbMetric: 2.3727, val_loss: 2.3697, val_MinusLogProbMetric: 2.3697

Epoch 305: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3727 - MinusLogProbMetric: 2.3727 - val_loss: 2.3697 - val_MinusLogProbMetric: 2.3697 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 306/1000
2023-09-11 21:53:27.297 
Epoch 306/1000 
	 loss: 2.3732, MinusLogProbMetric: 2.3732, val_loss: 2.3772, val_MinusLogProbMetric: 2.3772

Epoch 306: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3732 - MinusLogProbMetric: 2.3732 - val_loss: 2.3772 - val_MinusLogProbMetric: 2.3772 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 307/1000
2023-09-11 21:53:38.963 
Epoch 307/1000 
	 loss: 2.3739, MinusLogProbMetric: 2.3739, val_loss: 2.3698, val_MinusLogProbMetric: 2.3698

Epoch 307: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3739 - MinusLogProbMetric: 2.3739 - val_loss: 2.3698 - val_MinusLogProbMetric: 2.3698 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 308/1000
2023-09-11 21:53:50.877 
Epoch 308/1000 
	 loss: 2.3716, MinusLogProbMetric: 2.3716, val_loss: 2.3842, val_MinusLogProbMetric: 2.3842

Epoch 308: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3716 - MinusLogProbMetric: 2.3716 - val_loss: 2.3842 - val_MinusLogProbMetric: 2.3842 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 309/1000
2023-09-11 21:54:02.645 
Epoch 309/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.3771, val_MinusLogProbMetric: 2.3771

Epoch 309: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.3771 - val_MinusLogProbMetric: 2.3771 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 310/1000
2023-09-11 21:54:14.569 
Epoch 310/1000 
	 loss: 2.3725, MinusLogProbMetric: 2.3725, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 310: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3725 - MinusLogProbMetric: 2.3725 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 311/1000
2023-09-11 21:54:26.465 
Epoch 311/1000 
	 loss: 2.3741, MinusLogProbMetric: 2.3741, val_loss: 2.3762, val_MinusLogProbMetric: 2.3762

Epoch 311: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3741 - MinusLogProbMetric: 2.3741 - val_loss: 2.3762 - val_MinusLogProbMetric: 2.3762 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 312/1000
2023-09-11 21:54:38.314 
Epoch 312/1000 
	 loss: 2.3726, MinusLogProbMetric: 2.3726, val_loss: 2.3744, val_MinusLogProbMetric: 2.3744

Epoch 312: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3726 - MinusLogProbMetric: 2.3726 - val_loss: 2.3744 - val_MinusLogProbMetric: 2.3744 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 313/1000
2023-09-11 21:54:50.224 
Epoch 313/1000 
	 loss: 2.3701, MinusLogProbMetric: 2.3701, val_loss: 2.3825, val_MinusLogProbMetric: 2.3825

Epoch 313: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3701 - MinusLogProbMetric: 2.3701 - val_loss: 2.3825 - val_MinusLogProbMetric: 2.3825 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 314/1000
2023-09-11 21:55:02.019 
Epoch 314/1000 
	 loss: 2.3712, MinusLogProbMetric: 2.3712, val_loss: 2.4055, val_MinusLogProbMetric: 2.4055

Epoch 314: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3712 - MinusLogProbMetric: 2.3712 - val_loss: 2.4055 - val_MinusLogProbMetric: 2.4055 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 315/1000
2023-09-11 21:55:13.799 
Epoch 315/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 315: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-11 21:55:25.594 
Epoch 316/1000 
	 loss: 2.3718, MinusLogProbMetric: 2.3718, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 316: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3718 - MinusLogProbMetric: 2.3718 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 317/1000
2023-09-11 21:55:37.325 
Epoch 317/1000 
	 loss: 2.3756, MinusLogProbMetric: 2.3756, val_loss: 2.3746, val_MinusLogProbMetric: 2.3746

Epoch 317: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3756 - MinusLogProbMetric: 2.3756 - val_loss: 2.3746 - val_MinusLogProbMetric: 2.3746 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 318/1000
2023-09-11 21:55:49.158 
Epoch 318/1000 
	 loss: 2.3728, MinusLogProbMetric: 2.3728, val_loss: 2.3743, val_MinusLogProbMetric: 2.3743

Epoch 318: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3728 - MinusLogProbMetric: 2.3728 - val_loss: 2.3743 - val_MinusLogProbMetric: 2.3743 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 319/1000
2023-09-11 21:56:01.036 
Epoch 319/1000 
	 loss: 2.3735, MinusLogProbMetric: 2.3735, val_loss: 2.3695, val_MinusLogProbMetric: 2.3695

Epoch 319: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3735 - MinusLogProbMetric: 2.3735 - val_loss: 2.3695 - val_MinusLogProbMetric: 2.3695 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 320/1000
2023-09-11 21:56:12.613 
Epoch 320/1000 
	 loss: 2.3723, MinusLogProbMetric: 2.3723, val_loss: 2.3703, val_MinusLogProbMetric: 2.3703

Epoch 320: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3723 - MinusLogProbMetric: 2.3723 - val_loss: 2.3703 - val_MinusLogProbMetric: 2.3703 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 321/1000
2023-09-11 21:56:24.303 
Epoch 321/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 321: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 322/1000
2023-09-11 21:56:36.067 
Epoch 322/1000 
	 loss: 2.3725, MinusLogProbMetric: 2.3725, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 322: val_loss did not improve from 2.36718
196/196 - 12s - loss: 2.3725 - MinusLogProbMetric: 2.3725 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 323/1000
2023-09-11 21:56:47.855 
Epoch 323/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3666, val_MinusLogProbMetric: 2.3666

Epoch 323: val_loss improved from 2.36718 to 2.36660, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3666 - val_MinusLogProbMetric: 2.3666 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 324/1000
2023-09-11 21:56:59.751 
Epoch 324/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 324: val_loss did not improve from 2.36660
196/196 - 12s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 325/1000
2023-09-11 21:57:11.582 
Epoch 325/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.3663, val_MinusLogProbMetric: 2.3663

Epoch 325: val_loss improved from 2.36660 to 2.36630, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.3663 - val_MinusLogProbMetric: 2.3663 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 326/1000
2023-09-11 21:57:23.461 
Epoch 326/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.3701, val_MinusLogProbMetric: 2.3701

Epoch 326: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.3701 - val_MinusLogProbMetric: 2.3701 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-11 21:57:35.067 
Epoch 327/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 327: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 328/1000
2023-09-11 21:57:46.827 
Epoch 328/1000 
	 loss: 2.3641, MinusLogProbMetric: 2.3641, val_loss: 2.3754, val_MinusLogProbMetric: 2.3754

Epoch 328: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3641 - MinusLogProbMetric: 2.3641 - val_loss: 2.3754 - val_MinusLogProbMetric: 2.3754 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 329/1000
2023-09-11 21:57:58.530 
Epoch 329/1000 
	 loss: 2.3642, MinusLogProbMetric: 2.3642, val_loss: 2.3716, val_MinusLogProbMetric: 2.3716

Epoch 329: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3642 - MinusLogProbMetric: 2.3642 - val_loss: 2.3716 - val_MinusLogProbMetric: 2.3716 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 330/1000
2023-09-11 21:58:10.215 
Epoch 330/1000 
	 loss: 2.3667, MinusLogProbMetric: 2.3667, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 330: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3667 - MinusLogProbMetric: 2.3667 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 331/1000
2023-09-11 21:58:21.963 
Epoch 331/1000 
	 loss: 2.3615, MinusLogProbMetric: 2.3615, val_loss: 2.3687, val_MinusLogProbMetric: 2.3687

Epoch 331: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3615 - MinusLogProbMetric: 2.3615 - val_loss: 2.3687 - val_MinusLogProbMetric: 2.3687 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 332/1000
2023-09-11 21:58:33.822 
Epoch 332/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 332: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 333/1000
2023-09-11 21:58:45.530 
Epoch 333/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 333: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 334/1000
2023-09-11 21:58:57.267 
Epoch 334/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3678, val_MinusLogProbMetric: 2.3678

Epoch 334: val_loss did not improve from 2.36630
196/196 - 12s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3678 - val_MinusLogProbMetric: 2.3678 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 335/1000
2023-09-11 21:59:08.821 
Epoch 335/1000 
	 loss: 2.3625, MinusLogProbMetric: 2.3625, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 335: val_loss improved from 2.36630 to 2.36471, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3625 - MinusLogProbMetric: 2.3625 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 336/1000
2023-09-11 21:59:20.628 
Epoch 336/1000 
	 loss: 2.3627, MinusLogProbMetric: 2.3627, val_loss: 2.3738, val_MinusLogProbMetric: 2.3738

Epoch 336: val_loss did not improve from 2.36471
196/196 - 12s - loss: 2.3627 - MinusLogProbMetric: 2.3627 - val_loss: 2.3738 - val_MinusLogProbMetric: 2.3738 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 337/1000
2023-09-11 21:59:32.448 
Epoch 337/1000 
	 loss: 2.3626, MinusLogProbMetric: 2.3626, val_loss: 2.3696, val_MinusLogProbMetric: 2.3696

Epoch 337: val_loss did not improve from 2.36471
196/196 - 12s - loss: 2.3626 - MinusLogProbMetric: 2.3626 - val_loss: 2.3696 - val_MinusLogProbMetric: 2.3696 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 338/1000
2023-09-11 21:59:44.185 
Epoch 338/1000 
	 loss: 2.3622, MinusLogProbMetric: 2.3622, val_loss: 2.3727, val_MinusLogProbMetric: 2.3727

Epoch 338: val_loss did not improve from 2.36471
196/196 - 12s - loss: 2.3622 - MinusLogProbMetric: 2.3622 - val_loss: 2.3727 - val_MinusLogProbMetric: 2.3727 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 339/1000
2023-09-11 21:59:55.850 
Epoch 339/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3675, val_MinusLogProbMetric: 2.3675

Epoch 339: val_loss did not improve from 2.36471
196/196 - 12s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3675 - val_MinusLogProbMetric: 2.3675 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 340/1000
2023-09-11 22:00:07.665 
Epoch 340/1000 
	 loss: 2.3629, MinusLogProbMetric: 2.3629, val_loss: 2.3661, val_MinusLogProbMetric: 2.3661

Epoch 340: val_loss did not improve from 2.36471
196/196 - 12s - loss: 2.3629 - MinusLogProbMetric: 2.3629 - val_loss: 2.3661 - val_MinusLogProbMetric: 2.3661 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 341/1000
2023-09-11 22:00:19.365 
Epoch 341/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3688, val_MinusLogProbMetric: 2.3688

Epoch 341: val_loss did not improve from 2.36471
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3688 - val_MinusLogProbMetric: 2.3688 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 342/1000
2023-09-11 22:00:31.080 
Epoch 342/1000 
	 loss: 2.3645, MinusLogProbMetric: 2.3645, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 342: val_loss improved from 2.36471 to 2.36403, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3645 - MinusLogProbMetric: 2.3645 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-11 22:00:42.982 
Epoch 343/1000 
	 loss: 2.3625, MinusLogProbMetric: 2.3625, val_loss: 2.3671, val_MinusLogProbMetric: 2.3671

Epoch 343: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3625 - MinusLogProbMetric: 2.3625 - val_loss: 2.3671 - val_MinusLogProbMetric: 2.3671 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 344/1000
2023-09-11 22:00:54.703 
Epoch 344/1000 
	 loss: 2.3627, MinusLogProbMetric: 2.3627, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 344: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3627 - MinusLogProbMetric: 2.3627 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 345/1000
2023-09-11 22:01:06.454 
Epoch 345/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3710, val_MinusLogProbMetric: 2.3710

Epoch 345: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3710 - val_MinusLogProbMetric: 2.3710 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 346/1000
2023-09-11 22:01:18.101 
Epoch 346/1000 
	 loss: 2.3628, MinusLogProbMetric: 2.3628, val_loss: 2.3721, val_MinusLogProbMetric: 2.3721

Epoch 346: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3628 - MinusLogProbMetric: 2.3628 - val_loss: 2.3721 - val_MinusLogProbMetric: 2.3721 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 347/1000
2023-09-11 22:01:29.878 
Epoch 347/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.3706, val_MinusLogProbMetric: 2.3706

Epoch 347: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.3706 - val_MinusLogProbMetric: 2.3706 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 348/1000
2023-09-11 22:01:41.530 
Epoch 348/1000 
	 loss: 2.3629, MinusLogProbMetric: 2.3629, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 348: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3629 - MinusLogProbMetric: 2.3629 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 349/1000
2023-09-11 22:01:53.146 
Epoch 349/1000 
	 loss: 2.3631, MinusLogProbMetric: 2.3631, val_loss: 2.3740, val_MinusLogProbMetric: 2.3740

Epoch 349: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3631 - MinusLogProbMetric: 2.3631 - val_loss: 2.3740 - val_MinusLogProbMetric: 2.3740 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 350/1000
2023-09-11 22:02:04.802 
Epoch 350/1000 
	 loss: 2.3621, MinusLogProbMetric: 2.3621, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 350: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3621 - MinusLogProbMetric: 2.3621 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 351/1000
2023-09-11 22:02:16.538 
Epoch 351/1000 
	 loss: 2.3624, MinusLogProbMetric: 2.3624, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 351: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3624 - MinusLogProbMetric: 2.3624 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 352/1000
2023-09-11 22:02:28.292 
Epoch 352/1000 
	 loss: 2.3635, MinusLogProbMetric: 2.3635, val_loss: 2.3695, val_MinusLogProbMetric: 2.3695

Epoch 352: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3635 - MinusLogProbMetric: 2.3635 - val_loss: 2.3695 - val_MinusLogProbMetric: 2.3695 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 353/1000
2023-09-11 22:02:40.047 
Epoch 353/1000 
	 loss: 2.3640, MinusLogProbMetric: 2.3640, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 353: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3640 - MinusLogProbMetric: 2.3640 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 354/1000
2023-09-11 22:02:51.759 
Epoch 354/1000 
	 loss: 2.3630, MinusLogProbMetric: 2.3630, val_loss: 2.3662, val_MinusLogProbMetric: 2.3662

Epoch 354: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3630 - MinusLogProbMetric: 2.3630 - val_loss: 2.3662 - val_MinusLogProbMetric: 2.3662 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 355/1000
2023-09-11 22:03:03.392 
Epoch 355/1000 
	 loss: 2.3619, MinusLogProbMetric: 2.3619, val_loss: 2.3683, val_MinusLogProbMetric: 2.3683

Epoch 355: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3619 - MinusLogProbMetric: 2.3619 - val_loss: 2.3683 - val_MinusLogProbMetric: 2.3683 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 356/1000
2023-09-11 22:03:15.102 
Epoch 356/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3657, val_MinusLogProbMetric: 2.3657

Epoch 356: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3657 - val_MinusLogProbMetric: 2.3657 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 357/1000
2023-09-11 22:03:26.810 
Epoch 357/1000 
	 loss: 2.3629, MinusLogProbMetric: 2.3629, val_loss: 2.3653, val_MinusLogProbMetric: 2.3653

Epoch 357: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3629 - MinusLogProbMetric: 2.3629 - val_loss: 2.3653 - val_MinusLogProbMetric: 2.3653 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 358/1000
2023-09-11 22:03:38.449 
Epoch 358/1000 
	 loss: 2.3626, MinusLogProbMetric: 2.3626, val_loss: 2.3668, val_MinusLogProbMetric: 2.3668

Epoch 358: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3626 - MinusLogProbMetric: 2.3626 - val_loss: 2.3668 - val_MinusLogProbMetric: 2.3668 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 359/1000
2023-09-11 22:03:50.040 
Epoch 359/1000 
	 loss: 2.3640, MinusLogProbMetric: 2.3640, val_loss: 2.3698, val_MinusLogProbMetric: 2.3698

Epoch 359: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3640 - MinusLogProbMetric: 2.3640 - val_loss: 2.3698 - val_MinusLogProbMetric: 2.3698 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 360/1000
2023-09-11 22:04:01.683 
Epoch 360/1000 
	 loss: 2.3629, MinusLogProbMetric: 2.3629, val_loss: 2.3718, val_MinusLogProbMetric: 2.3718

Epoch 360: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3629 - MinusLogProbMetric: 2.3629 - val_loss: 2.3718 - val_MinusLogProbMetric: 2.3718 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 361/1000
2023-09-11 22:04:13.263 
Epoch 361/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.3678, val_MinusLogProbMetric: 2.3678

Epoch 361: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.3678 - val_MinusLogProbMetric: 2.3678 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 362/1000
2023-09-11 22:04:24.999 
Epoch 362/1000 
	 loss: 2.4285, MinusLogProbMetric: 2.4285, val_loss: 2.3819, val_MinusLogProbMetric: 2.3819

Epoch 362: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.4285 - MinusLogProbMetric: 2.4285 - val_loss: 2.3819 - val_MinusLogProbMetric: 2.3819 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 363/1000
2023-09-11 22:04:36.614 
Epoch 363/1000 
	 loss: 2.3686, MinusLogProbMetric: 2.3686, val_loss: 2.3736, val_MinusLogProbMetric: 2.3736

Epoch 363: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3686 - MinusLogProbMetric: 2.3686 - val_loss: 2.3736 - val_MinusLogProbMetric: 2.3736 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 364/1000
2023-09-11 22:04:48.260 
Epoch 364/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3715, val_MinusLogProbMetric: 2.3715

Epoch 364: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3715 - val_MinusLogProbMetric: 2.3715 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 365/1000
2023-09-11 22:04:59.972 
Epoch 365/1000 
	 loss: 2.3658, MinusLogProbMetric: 2.3658, val_loss: 2.3707, val_MinusLogProbMetric: 2.3707

Epoch 365: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3658 - MinusLogProbMetric: 2.3658 - val_loss: 2.3707 - val_MinusLogProbMetric: 2.3707 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 366/1000
2023-09-11 22:05:11.629 
Epoch 366/1000 
	 loss: 2.3639, MinusLogProbMetric: 2.3639, val_loss: 2.3730, val_MinusLogProbMetric: 2.3730

Epoch 366: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3639 - MinusLogProbMetric: 2.3639 - val_loss: 2.3730 - val_MinusLogProbMetric: 2.3730 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 367/1000
2023-09-11 22:05:23.434 
Epoch 367/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 367: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 368/1000
2023-09-11 22:05:35.098 
Epoch 368/1000 
	 loss: 2.3637, MinusLogProbMetric: 2.3637, val_loss: 2.3708, val_MinusLogProbMetric: 2.3708

Epoch 368: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3637 - MinusLogProbMetric: 2.3637 - val_loss: 2.3708 - val_MinusLogProbMetric: 2.3708 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 369/1000
2023-09-11 22:05:46.784 
Epoch 369/1000 
	 loss: 2.3639, MinusLogProbMetric: 2.3639, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 369: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3639 - MinusLogProbMetric: 2.3639 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 370/1000
2023-09-11 22:05:58.474 
Epoch 370/1000 
	 loss: 2.3633, MinusLogProbMetric: 2.3633, val_loss: 2.3683, val_MinusLogProbMetric: 2.3683

Epoch 370: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3633 - MinusLogProbMetric: 2.3633 - val_loss: 2.3683 - val_MinusLogProbMetric: 2.3683 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 371/1000
2023-09-11 22:06:10.125 
Epoch 371/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3755, val_MinusLogProbMetric: 2.3755

Epoch 371: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3755 - val_MinusLogProbMetric: 2.3755 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 372/1000
2023-09-11 22:06:21.875 
Epoch 372/1000 
	 loss: 2.3636, MinusLogProbMetric: 2.3636, val_loss: 2.3725, val_MinusLogProbMetric: 2.3725

Epoch 372: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3636 - MinusLogProbMetric: 2.3636 - val_loss: 2.3725 - val_MinusLogProbMetric: 2.3725 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 373/1000
2023-09-11 22:06:33.502 
Epoch 373/1000 
	 loss: 2.3628, MinusLogProbMetric: 2.3628, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 373: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3628 - MinusLogProbMetric: 2.3628 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 374/1000
2023-09-11 22:06:45.151 
Epoch 374/1000 
	 loss: 2.3624, MinusLogProbMetric: 2.3624, val_loss: 2.3661, val_MinusLogProbMetric: 2.3661

Epoch 374: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3624 - MinusLogProbMetric: 2.3624 - val_loss: 2.3661 - val_MinusLogProbMetric: 2.3661 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 375/1000
2023-09-11 22:06:56.831 
Epoch 375/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.3793, val_MinusLogProbMetric: 2.3793

Epoch 375: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.3793 - val_MinusLogProbMetric: 2.3793 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 376/1000
2023-09-11 22:07:08.549 
Epoch 376/1000 
	 loss: 2.3630, MinusLogProbMetric: 2.3630, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 376: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3630 - MinusLogProbMetric: 2.3630 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-11 22:07:20.300 
Epoch 377/1000 
	 loss: 2.3619, MinusLogProbMetric: 2.3619, val_loss: 2.3684, val_MinusLogProbMetric: 2.3684

Epoch 377: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3619 - MinusLogProbMetric: 2.3619 - val_loss: 2.3684 - val_MinusLogProbMetric: 2.3684 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 378/1000
2023-09-11 22:07:31.974 
Epoch 378/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3686, val_MinusLogProbMetric: 2.3686

Epoch 378: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3686 - val_MinusLogProbMetric: 2.3686 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 379/1000
2023-09-11 22:07:43.740 
Epoch 379/1000 
	 loss: 2.3631, MinusLogProbMetric: 2.3631, val_loss: 2.3682, val_MinusLogProbMetric: 2.3682

Epoch 379: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3631 - MinusLogProbMetric: 2.3631 - val_loss: 2.3682 - val_MinusLogProbMetric: 2.3682 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-11 22:07:55.482 
Epoch 380/1000 
	 loss: 2.3611, MinusLogProbMetric: 2.3611, val_loss: 2.3681, val_MinusLogProbMetric: 2.3681

Epoch 380: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3611 - MinusLogProbMetric: 2.3611 - val_loss: 2.3681 - val_MinusLogProbMetric: 2.3681 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 381/1000
2023-09-11 22:08:07.108 
Epoch 381/1000 
	 loss: 2.3632, MinusLogProbMetric: 2.3632, val_loss: 2.3672, val_MinusLogProbMetric: 2.3672

Epoch 381: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3632 - MinusLogProbMetric: 2.3632 - val_loss: 2.3672 - val_MinusLogProbMetric: 2.3672 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 382/1000
2023-09-11 22:08:18.756 
Epoch 382/1000 
	 loss: 2.3625, MinusLogProbMetric: 2.3625, val_loss: 2.3685, val_MinusLogProbMetric: 2.3685

Epoch 382: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3625 - MinusLogProbMetric: 2.3625 - val_loss: 2.3685 - val_MinusLogProbMetric: 2.3685 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 383/1000
2023-09-11 22:08:30.517 
Epoch 383/1000 
	 loss: 2.3617, MinusLogProbMetric: 2.3617, val_loss: 2.3682, val_MinusLogProbMetric: 2.3682

Epoch 383: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3617 - MinusLogProbMetric: 2.3617 - val_loss: 2.3682 - val_MinusLogProbMetric: 2.3682 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 384/1000
2023-09-11 22:08:42.153 
Epoch 384/1000 
	 loss: 2.3627, MinusLogProbMetric: 2.3627, val_loss: 2.3650, val_MinusLogProbMetric: 2.3650

Epoch 384: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3627 - MinusLogProbMetric: 2.3627 - val_loss: 2.3650 - val_MinusLogProbMetric: 2.3650 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 385/1000
2023-09-11 22:08:53.840 
Epoch 385/1000 
	 loss: 2.3619, MinusLogProbMetric: 2.3619, val_loss: 2.3650, val_MinusLogProbMetric: 2.3650

Epoch 385: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3619 - MinusLogProbMetric: 2.3619 - val_loss: 2.3650 - val_MinusLogProbMetric: 2.3650 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 386/1000
2023-09-11 22:09:05.577 
Epoch 386/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 386: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 387/1000
2023-09-11 22:09:17.341 
Epoch 387/1000 
	 loss: 2.3644, MinusLogProbMetric: 2.3644, val_loss: 2.3717, val_MinusLogProbMetric: 2.3717

Epoch 387: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3644 - MinusLogProbMetric: 2.3644 - val_loss: 2.3717 - val_MinusLogProbMetric: 2.3717 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 388/1000
2023-09-11 22:09:28.958 
Epoch 388/1000 
	 loss: 2.3616, MinusLogProbMetric: 2.3616, val_loss: 2.3660, val_MinusLogProbMetric: 2.3660

Epoch 388: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3616 - MinusLogProbMetric: 2.3616 - val_loss: 2.3660 - val_MinusLogProbMetric: 2.3660 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 389/1000
2023-09-11 22:09:40.623 
Epoch 389/1000 
	 loss: 2.3615, MinusLogProbMetric: 2.3615, val_loss: 2.3693, val_MinusLogProbMetric: 2.3693

Epoch 389: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3615 - MinusLogProbMetric: 2.3615 - val_loss: 2.3693 - val_MinusLogProbMetric: 2.3693 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 390/1000
2023-09-11 22:09:52.370 
Epoch 390/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3712, val_MinusLogProbMetric: 2.3712

Epoch 390: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3712 - val_MinusLogProbMetric: 2.3712 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 391/1000
2023-09-11 22:10:04.197 
Epoch 391/1000 
	 loss: 2.3631, MinusLogProbMetric: 2.3631, val_loss: 2.3658, val_MinusLogProbMetric: 2.3658

Epoch 391: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3631 - MinusLogProbMetric: 2.3631 - val_loss: 2.3658 - val_MinusLogProbMetric: 2.3658 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 392/1000
2023-09-11 22:10:15.953 
Epoch 392/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3689, val_MinusLogProbMetric: 2.3689

Epoch 392: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3689 - val_MinusLogProbMetric: 2.3689 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 393/1000
2023-09-11 22:10:27.696 
Epoch 393/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3677, val_MinusLogProbMetric: 2.3677

Epoch 393: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3677 - val_MinusLogProbMetric: 2.3677 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 394/1000
2023-09-11 22:10:39.407 
Epoch 394/1000 
	 loss: 2.3607, MinusLogProbMetric: 2.3607, val_loss: 2.3661, val_MinusLogProbMetric: 2.3661

Epoch 394: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3607 - MinusLogProbMetric: 2.3607 - val_loss: 2.3661 - val_MinusLogProbMetric: 2.3661 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 395/1000
2023-09-11 22:10:51.116 
Epoch 395/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3643, val_MinusLogProbMetric: 2.3643

Epoch 395: val_loss did not improve from 2.36403
196/196 - 12s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3643 - val_MinusLogProbMetric: 2.3643 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 396/1000
2023-09-11 22:11:03.034 
Epoch 396/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 396: val_loss improved from 2.36403 to 2.36313, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 397/1000
2023-09-11 22:11:14.905 
Epoch 397/1000 
	 loss: 2.3578, MinusLogProbMetric: 2.3578, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 397: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3578 - MinusLogProbMetric: 2.3578 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 398/1000
2023-09-11 22:11:26.730 
Epoch 398/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 398: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 399/1000
2023-09-11 22:11:38.566 
Epoch 399/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 399: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 400/1000
2023-09-11 22:11:50.216 
Epoch 400/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3659, val_MinusLogProbMetric: 2.3659

Epoch 400: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3659 - val_MinusLogProbMetric: 2.3659 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 401/1000
2023-09-11 22:12:01.857 
Epoch 401/1000 
	 loss: 2.3578, MinusLogProbMetric: 2.3578, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 401: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3578 - MinusLogProbMetric: 2.3578 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 402/1000
2023-09-11 22:12:13.483 
Epoch 402/1000 
	 loss: 2.3576, MinusLogProbMetric: 2.3576, val_loss: 2.3656, val_MinusLogProbMetric: 2.3656

Epoch 402: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3576 - MinusLogProbMetric: 2.3576 - val_loss: 2.3656 - val_MinusLogProbMetric: 2.3656 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 403/1000
2023-09-11 22:12:25.256 
Epoch 403/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 403: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 404/1000
2023-09-11 22:12:36.964 
Epoch 404/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3680, val_MinusLogProbMetric: 2.3680

Epoch 404: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3680 - val_MinusLogProbMetric: 2.3680 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 405/1000
2023-09-11 22:12:48.758 
Epoch 405/1000 
	 loss: 2.3579, MinusLogProbMetric: 2.3579, val_loss: 2.3644, val_MinusLogProbMetric: 2.3644

Epoch 405: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3579 - MinusLogProbMetric: 2.3579 - val_loss: 2.3644 - val_MinusLogProbMetric: 2.3644 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 406/1000
2023-09-11 22:13:00.388 
Epoch 406/1000 
	 loss: 2.3577, MinusLogProbMetric: 2.3577, val_loss: 2.3660, val_MinusLogProbMetric: 2.3660

Epoch 406: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3577 - MinusLogProbMetric: 2.3577 - val_loss: 2.3660 - val_MinusLogProbMetric: 2.3660 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 407/1000
2023-09-11 22:13:12.148 
Epoch 407/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3662, val_MinusLogProbMetric: 2.3662

Epoch 407: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3662 - val_MinusLogProbMetric: 2.3662 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 408/1000
2023-09-11 22:13:23.854 
Epoch 408/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3665, val_MinusLogProbMetric: 2.3665

Epoch 408: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3665 - val_MinusLogProbMetric: 2.3665 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 409/1000
2023-09-11 22:13:35.552 
Epoch 409/1000 
	 loss: 2.3578, MinusLogProbMetric: 2.3578, val_loss: 2.3664, val_MinusLogProbMetric: 2.3664

Epoch 409: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3578 - MinusLogProbMetric: 2.3578 - val_loss: 2.3664 - val_MinusLogProbMetric: 2.3664 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 410/1000
2023-09-11 22:13:47.360 
Epoch 410/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 410: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 411/1000
2023-09-11 22:13:59.179 
Epoch 411/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3653, val_MinusLogProbMetric: 2.3653

Epoch 411: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3653 - val_MinusLogProbMetric: 2.3653 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 412/1000
2023-09-11 22:14:10.905 
Epoch 412/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 412: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 413/1000
2023-09-11 22:14:22.744 
Epoch 413/1000 
	 loss: 2.3585, MinusLogProbMetric: 2.3585, val_loss: 2.3659, val_MinusLogProbMetric: 2.3659

Epoch 413: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3585 - MinusLogProbMetric: 2.3585 - val_loss: 2.3659 - val_MinusLogProbMetric: 2.3659 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 414/1000
2023-09-11 22:14:34.717 
Epoch 414/1000 
	 loss: 2.3575, MinusLogProbMetric: 2.3575, val_loss: 2.3690, val_MinusLogProbMetric: 2.3690

Epoch 414: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3575 - MinusLogProbMetric: 2.3575 - val_loss: 2.3690 - val_MinusLogProbMetric: 2.3690 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 415/1000
2023-09-11 22:14:46.497 
Epoch 415/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3648, val_MinusLogProbMetric: 2.3648

Epoch 415: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3648 - val_MinusLogProbMetric: 2.3648 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 416/1000
2023-09-11 22:14:58.150 
Epoch 416/1000 
	 loss: 2.3564, MinusLogProbMetric: 2.3564, val_loss: 2.3665, val_MinusLogProbMetric: 2.3665

Epoch 416: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3564 - MinusLogProbMetric: 2.3564 - val_loss: 2.3665 - val_MinusLogProbMetric: 2.3665 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 417/1000
2023-09-11 22:15:09.861 
Epoch 417/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3705, val_MinusLogProbMetric: 2.3705

Epoch 417: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3705 - val_MinusLogProbMetric: 2.3705 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-11 22:15:21.517 
Epoch 418/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3681, val_MinusLogProbMetric: 2.3681

Epoch 418: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3681 - val_MinusLogProbMetric: 2.3681 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 419/1000
2023-09-11 22:15:33.216 
Epoch 419/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3676, val_MinusLogProbMetric: 2.3676

Epoch 419: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3676 - val_MinusLogProbMetric: 2.3676 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 420/1000
2023-09-11 22:15:44.941 
Epoch 420/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3649, val_MinusLogProbMetric: 2.3649

Epoch 420: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3649 - val_MinusLogProbMetric: 2.3649 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 421/1000
2023-09-11 22:15:56.651 
Epoch 421/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3655, val_MinusLogProbMetric: 2.3655

Epoch 421: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3655 - val_MinusLogProbMetric: 2.3655 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 422/1000
2023-09-11 22:16:08.877 
Epoch 422/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3670, val_MinusLogProbMetric: 2.3670

Epoch 422: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3670 - val_MinusLogProbMetric: 2.3670 - lr: 2.5000e-04 - 12s/epoch - 62ms/step
Epoch 423/1000
2023-09-11 22:16:20.791 
Epoch 423/1000 
	 loss: 2.3578, MinusLogProbMetric: 2.3578, val_loss: 2.3659, val_MinusLogProbMetric: 2.3659

Epoch 423: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3578 - MinusLogProbMetric: 2.3578 - val_loss: 2.3659 - val_MinusLogProbMetric: 2.3659 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 424/1000
2023-09-11 22:16:32.298 
Epoch 424/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3649, val_MinusLogProbMetric: 2.3649

Epoch 424: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3649 - val_MinusLogProbMetric: 2.3649 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 425/1000
2023-09-11 22:16:43.329 
Epoch 425/1000 
	 loss: 2.3579, MinusLogProbMetric: 2.3579, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 425: val_loss did not improve from 2.36313
196/196 - 11s - loss: 2.3579 - MinusLogProbMetric: 2.3579 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 426/1000
2023-09-11 22:16:54.169 
Epoch 426/1000 
	 loss: 2.3580, MinusLogProbMetric: 2.3580, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 426: val_loss did not improve from 2.36313
196/196 - 11s - loss: 2.3580 - MinusLogProbMetric: 2.3580 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 427/1000
2023-09-11 22:17:05.804 
Epoch 427/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 427: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 428/1000
2023-09-11 22:17:17.440 
Epoch 428/1000 
	 loss: 2.3573, MinusLogProbMetric: 2.3573, val_loss: 2.3662, val_MinusLogProbMetric: 2.3662

Epoch 428: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3573 - MinusLogProbMetric: 2.3573 - val_loss: 2.3662 - val_MinusLogProbMetric: 2.3662 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 429/1000
2023-09-11 22:17:29.170 
Epoch 429/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3658, val_MinusLogProbMetric: 2.3658

Epoch 429: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3658 - val_MinusLogProbMetric: 2.3658 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 430/1000
2023-09-11 22:17:40.812 
Epoch 430/1000 
	 loss: 2.3565, MinusLogProbMetric: 2.3565, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 430: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3565 - MinusLogProbMetric: 2.3565 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 431/1000
2023-09-11 22:17:52.413 
Epoch 431/1000 
	 loss: 2.3692, MinusLogProbMetric: 2.3692, val_loss: 2.4031, val_MinusLogProbMetric: 2.4031

Epoch 431: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3692 - MinusLogProbMetric: 2.3692 - val_loss: 2.4031 - val_MinusLogProbMetric: 2.4031 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 432/1000
2023-09-11 22:18:04.191 
Epoch 432/1000 
	 loss: 2.3634, MinusLogProbMetric: 2.3634, val_loss: 2.3667, val_MinusLogProbMetric: 2.3667

Epoch 432: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3634 - MinusLogProbMetric: 2.3634 - val_loss: 2.3667 - val_MinusLogProbMetric: 2.3667 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 433/1000
2023-09-11 22:18:15.985 
Epoch 433/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3650, val_MinusLogProbMetric: 2.3650

Epoch 433: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3650 - val_MinusLogProbMetric: 2.3650 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 434/1000
2023-09-11 22:18:27.694 
Epoch 434/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3660, val_MinusLogProbMetric: 2.3660

Epoch 434: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3660 - val_MinusLogProbMetric: 2.3660 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 435/1000
2023-09-11 22:18:39.421 
Epoch 435/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3663, val_MinusLogProbMetric: 2.3663

Epoch 435: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3663 - val_MinusLogProbMetric: 2.3663 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 436/1000
2023-09-11 22:18:51.146 
Epoch 436/1000 
	 loss: 2.3574, MinusLogProbMetric: 2.3574, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 436: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3574 - MinusLogProbMetric: 2.3574 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 437/1000
2023-09-11 22:19:02.786 
Epoch 437/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3707, val_MinusLogProbMetric: 2.3707

Epoch 437: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3707 - val_MinusLogProbMetric: 2.3707 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 438/1000
2023-09-11 22:19:14.394 
Epoch 438/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3686, val_MinusLogProbMetric: 2.3686

Epoch 438: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3686 - val_MinusLogProbMetric: 2.3686 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 439/1000
2023-09-11 22:19:26.102 
Epoch 439/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 439: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-11 22:19:37.918 
Epoch 440/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3674, val_MinusLogProbMetric: 2.3674

Epoch 440: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3674 - val_MinusLogProbMetric: 2.3674 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 441/1000
2023-09-11 22:19:49.616 
Epoch 441/1000 
	 loss: 2.3578, MinusLogProbMetric: 2.3578, val_loss: 2.3665, val_MinusLogProbMetric: 2.3665

Epoch 441: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3578 - MinusLogProbMetric: 2.3578 - val_loss: 2.3665 - val_MinusLogProbMetric: 2.3665 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 442/1000
2023-09-11 22:20:01.458 
Epoch 442/1000 
	 loss: 2.3570, MinusLogProbMetric: 2.3570, val_loss: 2.3651, val_MinusLogProbMetric: 2.3651

Epoch 442: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3570 - MinusLogProbMetric: 2.3570 - val_loss: 2.3651 - val_MinusLogProbMetric: 2.3651 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 443/1000
2023-09-11 22:20:13.174 
Epoch 443/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 443: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 444/1000
2023-09-11 22:20:24.810 
Epoch 444/1000 
	 loss: 2.3571, MinusLogProbMetric: 2.3571, val_loss: 2.3704, val_MinusLogProbMetric: 2.3704

Epoch 444: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3571 - MinusLogProbMetric: 2.3571 - val_loss: 2.3704 - val_MinusLogProbMetric: 2.3704 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 445/1000
2023-09-11 22:20:36.554 
Epoch 445/1000 
	 loss: 2.3577, MinusLogProbMetric: 2.3577, val_loss: 2.3665, val_MinusLogProbMetric: 2.3665

Epoch 445: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3577 - MinusLogProbMetric: 2.3577 - val_loss: 2.3665 - val_MinusLogProbMetric: 2.3665 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 446/1000
2023-09-11 22:20:48.351 
Epoch 446/1000 
	 loss: 2.3569, MinusLogProbMetric: 2.3569, val_loss: 2.3643, val_MinusLogProbMetric: 2.3643

Epoch 446: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3569 - MinusLogProbMetric: 2.3569 - val_loss: 2.3643 - val_MinusLogProbMetric: 2.3643 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 447/1000
2023-09-11 22:21:00.048 
Epoch 447/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 447: val_loss did not improve from 2.36313
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 448/1000
2023-09-11 22:21:11.774 
Epoch 448/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 448: val_loss improved from 2.36313 to 2.36308, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 449/1000
2023-09-11 22:21:23.429 
Epoch 449/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 449: val_loss did not improve from 2.36308
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 450/1000
2023-09-11 22:21:35.104 
Epoch 450/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 450: val_loss improved from 2.36308 to 2.36293, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 451/1000
2023-09-11 22:21:46.794 
Epoch 451/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 451: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 452/1000
2023-09-11 22:21:58.528 
Epoch 452/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 452: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 453/1000
2023-09-11 22:22:10.086 
Epoch 453/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 453: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 454/1000
2023-09-11 22:22:21.746 
Epoch 454/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 454: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 455/1000
2023-09-11 22:22:33.513 
Epoch 455/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 455: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 456/1000
2023-09-11 22:22:45.245 
Epoch 456/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3653, val_MinusLogProbMetric: 2.3653

Epoch 456: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3653 - val_MinusLogProbMetric: 2.3653 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 457/1000
2023-09-11 22:22:57.003 
Epoch 457/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 457: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 458/1000
2023-09-11 22:23:08.787 
Epoch 458/1000 
	 loss: 2.3572, MinusLogProbMetric: 2.3572, val_loss: 2.3652, val_MinusLogProbMetric: 2.3652

Epoch 458: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3572 - MinusLogProbMetric: 2.3572 - val_loss: 2.3652 - val_MinusLogProbMetric: 2.3652 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 459/1000
2023-09-11 22:23:20.592 
Epoch 459/1000 
	 loss: 2.3550, MinusLogProbMetric: 2.3550, val_loss: 2.3651, val_MinusLogProbMetric: 2.3651

Epoch 459: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3550 - MinusLogProbMetric: 2.3550 - val_loss: 2.3651 - val_MinusLogProbMetric: 2.3651 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 460/1000
2023-09-11 22:23:32.403 
Epoch 460/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 460: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 461/1000
2023-09-11 22:23:44.203 
Epoch 461/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 461: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 462/1000
2023-09-11 22:23:55.964 
Epoch 462/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 462: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 463/1000
2023-09-11 22:24:07.635 
Epoch 463/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3636, val_MinusLogProbMetric: 2.3636

Epoch 463: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3636 - val_MinusLogProbMetric: 2.3636 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 464/1000
2023-09-11 22:24:19.440 
Epoch 464/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 464: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 465/1000
2023-09-11 22:24:31.152 
Epoch 465/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 465: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 466/1000
2023-09-11 22:24:42.800 
Epoch 466/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 466: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 467/1000
2023-09-11 22:24:54.436 
Epoch 467/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 467: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 468/1000
2023-09-11 22:25:06.208 
Epoch 468/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 468: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 469/1000
2023-09-11 22:25:17.815 
Epoch 469/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 469: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 470/1000
2023-09-11 22:25:29.620 
Epoch 470/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 470: val_loss did not improve from 2.36293
196/196 - 12s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 471/1000
2023-09-11 22:25:41.449 
Epoch 471/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 471: val_loss improved from 2.36293 to 2.36290, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 472/1000
2023-09-11 22:25:53.113 
Epoch 472/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 472: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 473/1000
2023-09-11 22:26:04.896 
Epoch 473/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 473: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 474/1000
2023-09-11 22:26:16.681 
Epoch 474/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 474: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 475/1000
2023-09-11 22:26:28.453 
Epoch 475/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3673, val_MinusLogProbMetric: 2.3673

Epoch 475: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3673 - val_MinusLogProbMetric: 2.3673 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 476/1000
2023-09-11 22:26:40.239 
Epoch 476/1000 
	 loss: 2.3545, MinusLogProbMetric: 2.3545, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 476: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3545 - MinusLogProbMetric: 2.3545 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 477/1000
2023-09-11 22:26:51.876 
Epoch 477/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 477: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 478/1000
2023-09-11 22:27:03.626 
Epoch 478/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 478: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 479/1000
2023-09-11 22:27:15.400 
Epoch 479/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 479: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 480/1000
2023-09-11 22:27:27.170 
Epoch 480/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3639, val_MinusLogProbMetric: 2.3639

Epoch 480: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3639 - val_MinusLogProbMetric: 2.3639 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 481/1000
2023-09-11 22:27:39.036 
Epoch 481/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3645, val_MinusLogProbMetric: 2.3645

Epoch 481: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3645 - val_MinusLogProbMetric: 2.3645 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 482/1000
2023-09-11 22:27:50.674 
Epoch 482/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 482: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 483/1000
2023-09-11 22:28:02.315 
Epoch 483/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 483: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 484/1000
2023-09-11 22:28:14.088 
Epoch 484/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 484: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 485/1000
2023-09-11 22:28:25.836 
Epoch 485/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 485: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 486/1000
2023-09-11 22:28:37.591 
Epoch 486/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3647, val_MinusLogProbMetric: 2.3647

Epoch 486: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3647 - val_MinusLogProbMetric: 2.3647 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 487/1000
2023-09-11 22:28:49.396 
Epoch 487/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 487: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 488/1000
2023-09-11 22:29:01.284 
Epoch 488/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3637, val_MinusLogProbMetric: 2.3637

Epoch 488: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3637 - val_MinusLogProbMetric: 2.3637 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 489/1000
2023-09-11 22:29:13.215 
Epoch 489/1000 
	 loss: 2.3546, MinusLogProbMetric: 2.3546, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 489: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3546 - MinusLogProbMetric: 2.3546 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 490/1000
2023-09-11 22:29:25.069 
Epoch 490/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 490: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 491/1000
2023-09-11 22:29:36.940 
Epoch 491/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 491: val_loss did not improve from 2.36290
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 492/1000
2023-09-11 22:29:48.791 
Epoch 492/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 492: val_loss improved from 2.36290 to 2.36284, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 493/1000
2023-09-11 22:30:00.421 
Epoch 493/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 493: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 494/1000
2023-09-11 22:30:12.013 
Epoch 494/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 494: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 495/1000
2023-09-11 22:30:23.790 
Epoch 495/1000 
	 loss: 2.3540, MinusLogProbMetric: 2.3540, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 495: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3540 - MinusLogProbMetric: 2.3540 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 496/1000
2023-09-11 22:30:35.540 
Epoch 496/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 496: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 497/1000
2023-09-11 22:30:47.352 
Epoch 497/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3641, val_MinusLogProbMetric: 2.3641

Epoch 497: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3641 - val_MinusLogProbMetric: 2.3641 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 498/1000
2023-09-11 22:30:59.087 
Epoch 498/1000 
	 loss: 2.3542, MinusLogProbMetric: 2.3542, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 498: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3542 - MinusLogProbMetric: 2.3542 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 499/1000
2023-09-11 22:31:10.850 
Epoch 499/1000 
	 loss: 2.3539, MinusLogProbMetric: 2.3539, val_loss: 2.3646, val_MinusLogProbMetric: 2.3646

Epoch 499: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3539 - MinusLogProbMetric: 2.3539 - val_loss: 2.3646 - val_MinusLogProbMetric: 2.3646 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 500/1000
2023-09-11 22:31:22.629 
Epoch 500/1000 
	 loss: 2.3544, MinusLogProbMetric: 2.3544, val_loss: 2.3659, val_MinusLogProbMetric: 2.3659

Epoch 500: val_loss did not improve from 2.36284
196/196 - 12s - loss: 2.3544 - MinusLogProbMetric: 2.3544 - val_loss: 2.3659 - val_MinusLogProbMetric: 2.3659 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 501/1000
2023-09-11 22:31:34.420 
Epoch 501/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 501: val_loss improved from 2.36284 to 2.36269, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 502/1000
2023-09-11 22:31:46.312 
Epoch 502/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 502: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 503/1000
2023-09-11 22:31:58.046 
Epoch 503/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 503: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 504/1000
2023-09-11 22:32:09.819 
Epoch 504/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 504: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 505/1000
2023-09-11 22:32:21.588 
Epoch 505/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3642, val_MinusLogProbMetric: 2.3642

Epoch 505: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3642 - val_MinusLogProbMetric: 2.3642 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 506/1000
2023-09-11 22:32:33.257 
Epoch 506/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 506: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 507/1000
2023-09-11 22:32:44.938 
Epoch 507/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 507: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 508/1000
2023-09-11 22:32:56.585 
Epoch 508/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 508: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 509/1000
2023-09-11 22:33:08.234 
Epoch 509/1000 
	 loss: 2.3748, MinusLogProbMetric: 2.3748, val_loss: 2.3666, val_MinusLogProbMetric: 2.3666

Epoch 509: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3748 - MinusLogProbMetric: 2.3748 - val_loss: 2.3666 - val_MinusLogProbMetric: 2.3666 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 510/1000
2023-09-11 22:33:19.934 
Epoch 510/1000 
	 loss: 2.3577, MinusLogProbMetric: 2.3577, val_loss: 2.3655, val_MinusLogProbMetric: 2.3655

Epoch 510: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3577 - MinusLogProbMetric: 2.3577 - val_loss: 2.3655 - val_MinusLogProbMetric: 2.3655 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 511/1000
2023-09-11 22:33:31.720 
Epoch 511/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 511: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 512/1000
2023-09-11 22:33:43.467 
Epoch 512/1000 
	 loss: 2.3547, MinusLogProbMetric: 2.3547, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 512: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3547 - MinusLogProbMetric: 2.3547 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 513/1000
2023-09-11 22:33:55.294 
Epoch 513/1000 
	 loss: 2.3543, MinusLogProbMetric: 2.3543, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 513: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3543 - MinusLogProbMetric: 2.3543 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 514/1000
2023-09-11 22:34:06.948 
Epoch 514/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 514: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 515/1000
2023-09-11 22:34:18.578 
Epoch 515/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 515: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 516/1000
2023-09-11 22:34:30.229 
Epoch 516/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 516: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 517/1000
2023-09-11 22:34:41.908 
Epoch 517/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 517: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 518/1000
2023-09-11 22:34:53.519 
Epoch 518/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 518: val_loss did not improve from 2.36269
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 519/1000
2023-09-11 22:35:05.103 
Epoch 519/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 519: val_loss improved from 2.36269 to 2.36237, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 520/1000
2023-09-11 22:35:16.812 
Epoch 520/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 520: val_loss did not improve from 2.36237
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 521/1000
2023-09-11 22:35:28.370 
Epoch 521/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 521: val_loss did not improve from 2.36237
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 522/1000
2023-09-11 22:35:39.978 
Epoch 522/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 522: val_loss did not improve from 2.36237
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 523/1000
2023-09-11 22:35:51.720 
Epoch 523/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 523: val_loss did not improve from 2.36237
196/196 - 12s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 524/1000
2023-09-11 22:36:03.392 
Epoch 524/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 524: val_loss did not improve from 2.36237
196/196 - 12s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 525/1000
2023-09-11 22:36:15.121 
Epoch 525/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 525: val_loss did not improve from 2.36237
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 526/1000
2023-09-11 22:36:26.947 
Epoch 526/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 526: val_loss improved from 2.36237 to 2.36227, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 527/1000
2023-09-11 22:36:38.748 
Epoch 527/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 527: val_loss did not improve from 2.36227
196/196 - 12s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 528/1000
2023-09-11 22:36:50.406 
Epoch 528/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 528: val_loss did not improve from 2.36227
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 529/1000
2023-09-11 22:37:02.010 
Epoch 529/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 529: val_loss did not improve from 2.36227
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 530/1000
2023-09-11 22:37:13.707 
Epoch 530/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 530: val_loss did not improve from 2.36227
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 531/1000
2023-09-11 22:37:25.439 
Epoch 531/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3622, val_MinusLogProbMetric: 2.3622

Epoch 531: val_loss improved from 2.36227 to 2.36221, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_26/weights/best_weights.h5
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3622 - val_MinusLogProbMetric: 2.3622 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 532/1000
2023-09-11 22:37:37.310 
Epoch 532/1000 
	 loss: 2.3531, MinusLogProbMetric: 2.3531, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 532: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3531 - MinusLogProbMetric: 2.3531 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 533/1000
2023-09-11 22:37:49.037 
Epoch 533/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 533: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 534/1000
2023-09-11 22:38:00.834 
Epoch 534/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 534: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 535/1000
2023-09-11 22:38:12.557 
Epoch 535/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 535: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 536/1000
2023-09-11 22:38:24.281 
Epoch 536/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 536: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 537/1000
2023-09-11 22:38:36.039 
Epoch 537/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 537: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 538/1000
2023-09-11 22:38:47.846 
Epoch 538/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 538: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 539/1000
2023-09-11 22:38:59.469 
Epoch 539/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 539: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 540/1000
2023-09-11 22:39:11.231 
Epoch 540/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 540: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 541/1000
2023-09-11 22:39:22.845 
Epoch 541/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 541: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 542/1000
2023-09-11 22:39:34.570 
Epoch 542/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 542: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 543/1000
2023-09-11 22:39:46.328 
Epoch 543/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 543: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 544/1000
2023-09-11 22:39:58.142 
Epoch 544/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 544: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 545/1000
2023-09-11 22:40:09.830 
Epoch 545/1000 
	 loss: 2.3529, MinusLogProbMetric: 2.3529, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 545: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3529 - MinusLogProbMetric: 2.3529 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 546/1000
2023-09-11 22:40:21.645 
Epoch 546/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 546: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 547/1000
2023-09-11 22:40:33.470 
Epoch 547/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 547: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 548/1000
2023-09-11 22:40:45.136 
Epoch 548/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3623, val_MinusLogProbMetric: 2.3623

Epoch 548: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3623 - val_MinusLogProbMetric: 2.3623 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 549/1000
2023-09-11 22:40:56.918 
Epoch 549/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 549: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 550/1000
2023-09-11 22:41:08.632 
Epoch 550/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 550: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 551/1000
2023-09-11 22:41:20.418 
Epoch 551/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 551: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 552/1000
2023-09-11 22:41:31.993 
Epoch 552/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 552: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 553/1000
2023-09-11 22:41:43.609 
Epoch 553/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 553: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 554/1000
2023-09-11 22:41:55.317 
Epoch 554/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 554: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 555/1000
2023-09-11 22:42:06.982 
Epoch 555/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 555: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 556/1000
2023-09-11 22:42:18.847 
Epoch 556/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 556: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 557/1000
2023-09-11 22:42:30.542 
Epoch 557/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 557: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 558/1000
2023-09-11 22:42:42.206 
Epoch 558/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3638, val_MinusLogProbMetric: 2.3638

Epoch 558: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3638 - val_MinusLogProbMetric: 2.3638 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 559/1000
2023-09-11 22:42:53.936 
Epoch 559/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 559: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 560/1000
2023-09-11 22:43:05.639 
Epoch 560/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 560: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 561/1000
2023-09-11 22:43:17.357 
Epoch 561/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 561: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 562/1000
2023-09-11 22:43:29.020 
Epoch 562/1000 
	 loss: 2.3528, MinusLogProbMetric: 2.3528, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 562: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3528 - MinusLogProbMetric: 2.3528 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 563/1000
2023-09-11 22:43:40.777 
Epoch 563/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3636, val_MinusLogProbMetric: 2.3636

Epoch 563: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3636 - val_MinusLogProbMetric: 2.3636 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 564/1000
2023-09-11 22:43:52.578 
Epoch 564/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 564: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 565/1000
2023-09-11 22:44:04.329 
Epoch 565/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 565: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 566/1000
2023-09-11 22:44:16.069 
Epoch 566/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 566: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 567/1000
2023-09-11 22:44:27.577 
Epoch 567/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 567: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 568/1000
2023-09-11 22:44:39.180 
Epoch 568/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 568: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 569/1000
2023-09-11 22:44:50.480 
Epoch 569/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 569: val_loss did not improve from 2.36221
196/196 - 11s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 570/1000
2023-09-11 22:45:00.238 
Epoch 570/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 570: val_loss did not improve from 2.36221
196/196 - 10s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 6.2500e-05 - 10s/epoch - 50ms/step
Epoch 571/1000
2023-09-11 22:45:11.688 
Epoch 571/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 571: val_loss did not improve from 2.36221
196/196 - 11s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 572/1000
2023-09-11 22:45:23.297 
Epoch 572/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 572: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 573/1000
2023-09-11 22:45:35.006 
Epoch 573/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 573: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 574/1000
2023-09-11 22:45:46.745 
Epoch 574/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3636, val_MinusLogProbMetric: 2.3636

Epoch 574: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3636 - val_MinusLogProbMetric: 2.3636 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 575/1000
2023-09-11 22:45:58.353 
Epoch 575/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 575: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 576/1000
2023-09-11 22:46:10.058 
Epoch 576/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3643, val_MinusLogProbMetric: 2.3643

Epoch 576: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3643 - val_MinusLogProbMetric: 2.3643 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 577/1000
2023-09-11 22:46:21.809 
Epoch 577/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 577: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 578/1000
2023-09-11 22:46:33.444 
Epoch 578/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 578: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 579/1000
2023-09-11 22:46:45.202 
Epoch 579/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3635, val_MinusLogProbMetric: 2.3635

Epoch 579: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3635 - val_MinusLogProbMetric: 2.3635 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 580/1000
2023-09-11 22:46:56.979 
Epoch 580/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 580: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 581/1000
2023-09-11 22:47:08.670 
Epoch 581/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3640, val_MinusLogProbMetric: 2.3640

Epoch 581: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3640 - val_MinusLogProbMetric: 2.3640 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 582/1000
2023-09-11 22:47:20.234 
Epoch 582/1000 
	 loss: 2.3522, MinusLogProbMetric: 2.3522, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 582: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3522 - MinusLogProbMetric: 2.3522 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 583/1000
2023-09-11 22:47:31.855 
Epoch 583/1000 
	 loss: 2.3522, MinusLogProbMetric: 2.3522, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 583: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3522 - MinusLogProbMetric: 2.3522 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 584/1000
2023-09-11 22:47:43.530 
Epoch 584/1000 
	 loss: 2.3521, MinusLogProbMetric: 2.3521, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 584: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3521 - MinusLogProbMetric: 2.3521 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 585/1000
2023-09-11 22:47:55.286 
Epoch 585/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 585: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 586/1000
2023-09-11 22:48:07.001 
Epoch 586/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 586: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 587/1000
2023-09-11 22:48:18.834 
Epoch 587/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 587: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 588/1000
2023-09-11 22:48:30.647 
Epoch 588/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 588: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 589/1000
2023-09-11 22:48:42.306 
Epoch 589/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 589: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 590/1000
2023-09-11 22:48:54.005 
Epoch 590/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 590: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 591/1000
2023-09-11 22:49:05.688 
Epoch 591/1000 
	 loss: 2.3520, MinusLogProbMetric: 2.3520, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 591: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3520 - MinusLogProbMetric: 2.3520 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 592/1000
2023-09-11 22:49:17.415 
Epoch 592/1000 
	 loss: 2.3520, MinusLogProbMetric: 2.3520, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 592: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3520 - MinusLogProbMetric: 2.3520 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 593/1000
2023-09-11 22:49:29.258 
Epoch 593/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3624, val_MinusLogProbMetric: 2.3624

Epoch 593: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3624 - val_MinusLogProbMetric: 2.3624 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 594/1000
2023-09-11 22:49:40.977 
Epoch 594/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 594: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 595/1000
2023-09-11 22:49:52.789 
Epoch 595/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 595: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 596/1000
2023-09-11 22:50:04.357 
Epoch 596/1000 
	 loss: 2.3520, MinusLogProbMetric: 2.3520, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 596: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3520 - MinusLogProbMetric: 2.3520 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 597/1000
2023-09-11 22:50:16.056 
Epoch 597/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 597: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 598/1000
2023-09-11 22:50:27.815 
Epoch 598/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 598: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 599/1000
2023-09-11 22:50:39.631 
Epoch 599/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 599: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 600/1000
2023-09-11 22:50:51.221 
Epoch 600/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 600: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 601/1000
2023-09-11 22:51:02.848 
Epoch 601/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3625, val_MinusLogProbMetric: 2.3625

Epoch 601: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3625 - val_MinusLogProbMetric: 2.3625 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 602/1000
2023-09-11 22:51:14.685 
Epoch 602/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3626, val_MinusLogProbMetric: 2.3626

Epoch 602: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3626 - val_MinusLogProbMetric: 2.3626 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 603/1000
2023-09-11 22:51:26.406 
Epoch 603/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 603: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 604/1000
2023-09-11 22:51:38.111 
Epoch 604/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 604: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 605/1000
2023-09-11 22:51:49.858 
Epoch 605/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 605: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 606/1000
2023-09-11 22:52:01.494 
Epoch 606/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 606: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 607/1000
2023-09-11 22:52:13.120 
Epoch 607/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 607: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 608/1000
2023-09-11 22:52:24.755 
Epoch 608/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 608: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 609/1000
2023-09-11 22:52:36.392 
Epoch 609/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 609: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 610/1000
2023-09-11 22:52:48.131 
Epoch 610/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 610: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 611/1000
2023-09-11 22:52:59.747 
Epoch 611/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 611: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 612/1000
2023-09-11 22:53:11.529 
Epoch 612/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 612: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 613/1000
2023-09-11 22:53:23.352 
Epoch 613/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 613: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 614/1000
2023-09-11 22:53:35.182 
Epoch 614/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 614: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 615/1000
2023-09-11 22:53:46.844 
Epoch 615/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 615: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 616/1000
2023-09-11 22:53:58.520 
Epoch 616/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3627, val_MinusLogProbMetric: 2.3627

Epoch 616: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3627 - val_MinusLogProbMetric: 2.3627 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 617/1000
2023-09-11 22:54:09.812 
Epoch 617/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 617: val_loss did not improve from 2.36221
196/196 - 11s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 3.1250e-05 - 11s/epoch - 58ms/step
Epoch 618/1000
2023-09-11 22:54:19.907 
Epoch 618/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3633, val_MinusLogProbMetric: 2.3633

Epoch 618: val_loss did not improve from 2.36221
196/196 - 10s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3633 - val_MinusLogProbMetric: 2.3633 - lr: 3.1250e-05 - 10s/epoch - 51ms/step
Epoch 619/1000
2023-09-11 22:54:31.213 
Epoch 619/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3628, val_MinusLogProbMetric: 2.3628

Epoch 619: val_loss did not improve from 2.36221
196/196 - 11s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3628 - val_MinusLogProbMetric: 2.3628 - lr: 3.1250e-05 - 11s/epoch - 58ms/step
Epoch 620/1000
2023-09-11 22:54:43.009 
Epoch 620/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 620: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 621/1000
2023-09-11 22:54:54.692 
Epoch 621/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 621: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 622/1000
2023-09-11 22:55:06.529 
Epoch 622/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3629, val_MinusLogProbMetric: 2.3629

Epoch 622: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3629 - val_MinusLogProbMetric: 2.3629 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 623/1000
2023-09-11 22:55:18.312 
Epoch 623/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 623: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 624/1000
2023-09-11 22:55:29.974 
Epoch 624/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 624: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 625/1000
2023-09-11 22:55:41.573 
Epoch 625/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 625: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 626/1000
2023-09-11 22:55:53.445 
Epoch 626/1000 
	 loss: 2.3518, MinusLogProbMetric: 2.3518, val_loss: 2.3634, val_MinusLogProbMetric: 2.3634

Epoch 626: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3518 - MinusLogProbMetric: 2.3518 - val_loss: 2.3634 - val_MinusLogProbMetric: 2.3634 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 627/1000
2023-09-11 22:56:05.114 
Epoch 627/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 627: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 628/1000
2023-09-11 22:56:16.793 
Epoch 628/1000 
	 loss: 2.3519, MinusLogProbMetric: 2.3519, val_loss: 2.3631, val_MinusLogProbMetric: 2.3631

Epoch 628: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3519 - MinusLogProbMetric: 2.3519 - val_loss: 2.3631 - val_MinusLogProbMetric: 2.3631 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 629/1000
2023-09-11 22:56:28.498 
Epoch 629/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 629: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 630/1000
2023-09-11 22:56:40.231 
Epoch 630/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3632, val_MinusLogProbMetric: 2.3632

Epoch 630: val_loss did not improve from 2.36221
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3632 - val_MinusLogProbMetric: 2.3632 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 631/1000
2023-09-11 22:56:52.006 
Epoch 631/1000 
	 loss: 2.3517, MinusLogProbMetric: 2.3517, val_loss: 2.3630, val_MinusLogProbMetric: 2.3630

Epoch 631: val_loss did not improve from 2.36221
Restoring model weights from the end of the best epoch: 531.
196/196 - 12s - loss: 2.3517 - MinusLogProbMetric: 2.3517 - val_loss: 2.3630 - val_MinusLogProbMetric: 2.3630 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 631: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.433537837001495 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.289447181043215 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.7828502710908651 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.0208478049607947 seconds.
Training succeeded with seed 721.
Model trained in 7403.41 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 16.44 s.
Plots done in 2.01 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 18.45 s.
===========
Run 26/360 done in 7423.37 s.
===========

Directory ../../results/MsplineN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

===========
Generating train data for run 36.
===========
Train data generated in 0.10 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 4)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_36/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_36/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 9.036821 ,  4.7705116,  8.516701 ,  4.5271635],
       [ 4.2073317,  6.531003 ,  5.3180447,  9.38196  ],
       [ 4.238654 ,  4.98909  ,  4.2195296,  8.856048 ],
       ...,
       [ 4.236962 ,  7.949092 ,  5.112082 ,  8.334676 ],
       [ 4.2190785,  6.289809 ,  4.1673417,  9.976453 ],
       [10.736699 ,  2.9054773,  8.213886 ,  6.05053  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[4], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_36/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_36
self.data_kwargs: {'seed': 926}
self.x_data: [[4.240712  6.2412577 5.575936  8.372037 ]
 [6.461165  8.044901  6.0199018 5.3768544]
 [4.238709  7.4034963 3.406543  8.91474  ]
 ...
 [4.206514  6.1442623 4.08315   8.084269 ]
 [4.2575107 6.489152  3.5227385 9.106118 ]
 [4.5291443 8.208476  5.9955726 5.5052757]]
self.y_data: []
self.ndims: 4
Model defined.
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       [(None, 4)]               0         
                                                                 
 log_prob_layer_4 (LogProbLa  (None,)                  337688    
 yer)                                                            
                                                                 
=================================================================
Total params: 337,688
Trainable params: 337,688
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_4/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_4'")
self.model: <keras.engine.functional.Functional object at 0x7fc71876c8e0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc718703df0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc718703df0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc7187027d0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc7185affd0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc7185f4580>, <keras.callbacks.ModelCheckpoint object at 0x7fc7185f4640>, <keras.callbacks.EarlyStopping object at 0x7fc7185f48b0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc7185f48e0>, <keras.callbacks.TerminateOnNaN object at 0x7fc7185f4520>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 9.036821 ,  4.7705116,  8.516701 ,  4.5271635],
       [ 4.2073317,  6.531003 ,  5.3180447,  9.38196  ],
       [ 4.238654 ,  4.98909  ,  4.2195296,  8.856048 ],
       ...,
       [ 4.236962 ,  7.949092 ,  5.112082 ,  8.334676 ],
       [ 4.2190785,  6.289809 ,  4.1673417,  9.976453 ],
       [10.736699 ,  2.9054773,  8.213886 ,  6.05053  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_36/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 36/360 with hyperparameters:
timestamp = 2023-09-11 22:57:11.383864
ndims = 4
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 337688
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.240712  6.2412577 5.575936  8.372037 ]
Epoch 1/1000
2023-09-11 22:57:39.983 
Epoch 1/1000 
	 loss: 6.2626, MinusLogProbMetric: 6.2626, val_loss: 3.1741, val_MinusLogProbMetric: 3.1741

Epoch 1: val_loss improved from inf to 3.17410, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 29s - loss: 6.2626 - MinusLogProbMetric: 6.2626 - val_loss: 3.1741 - val_MinusLogProbMetric: 3.1741 - lr: 0.0010 - 29s/epoch - 146ms/step
Epoch 2/1000
2023-09-11 22:57:51.762 
Epoch 2/1000 
	 loss: 3.3565, MinusLogProbMetric: 3.3565, val_loss: 2.8955, val_MinusLogProbMetric: 2.8955

Epoch 2: val_loss improved from 3.17410 to 2.89550, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 3.3565 - MinusLogProbMetric: 3.3565 - val_loss: 2.8955 - val_MinusLogProbMetric: 2.8955 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 3/1000
2023-09-11 22:58:03.554 
Epoch 3/1000 
	 loss: 2.7817, MinusLogProbMetric: 2.7817, val_loss: 2.7298, val_MinusLogProbMetric: 2.7298

Epoch 3: val_loss improved from 2.89550 to 2.72977, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.7817 - MinusLogProbMetric: 2.7817 - val_loss: 2.7298 - val_MinusLogProbMetric: 2.7298 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-11 22:58:15.380 
Epoch 4/1000 
	 loss: 2.7122, MinusLogProbMetric: 2.7122, val_loss: 2.6772, val_MinusLogProbMetric: 2.6772

Epoch 4: val_loss improved from 2.72977 to 2.67715, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.7122 - MinusLogProbMetric: 2.7122 - val_loss: 2.6772 - val_MinusLogProbMetric: 2.6772 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-11 22:58:27.247 
Epoch 5/1000 
	 loss: 2.6448, MinusLogProbMetric: 2.6448, val_loss: 2.6307, val_MinusLogProbMetric: 2.6307

Epoch 5: val_loss improved from 2.67715 to 2.63066, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.6448 - MinusLogProbMetric: 2.6448 - val_loss: 2.6307 - val_MinusLogProbMetric: 2.6307 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 6/1000
2023-09-11 22:58:39.042 
Epoch 6/1000 
	 loss: 2.6179, MinusLogProbMetric: 2.6179, val_loss: 2.8840, val_MinusLogProbMetric: 2.8840

Epoch 6: val_loss did not improve from 2.63066
196/196 - 12s - loss: 2.6179 - MinusLogProbMetric: 2.6179 - val_loss: 2.8840 - val_MinusLogProbMetric: 2.8840 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-11 22:58:50.659 
Epoch 7/1000 
	 loss: 2.5859, MinusLogProbMetric: 2.5859, val_loss: 2.6495, val_MinusLogProbMetric: 2.6495

Epoch 7: val_loss did not improve from 2.63066
196/196 - 12s - loss: 2.5859 - MinusLogProbMetric: 2.5859 - val_loss: 2.6495 - val_MinusLogProbMetric: 2.6495 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 8/1000
2023-09-11 22:59:02.473 
Epoch 8/1000 
	 loss: 2.5709, MinusLogProbMetric: 2.5709, val_loss: 2.5874, val_MinusLogProbMetric: 2.5874

Epoch 8: val_loss improved from 2.63066 to 2.58735, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.5709 - MinusLogProbMetric: 2.5709 - val_loss: 2.5874 - val_MinusLogProbMetric: 2.5874 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 9/1000
2023-09-11 22:59:14.356 
Epoch 9/1000 
	 loss: 2.5407, MinusLogProbMetric: 2.5407, val_loss: 2.5724, val_MinusLogProbMetric: 2.5724

Epoch 9: val_loss improved from 2.58735 to 2.57239, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.5407 - MinusLogProbMetric: 2.5407 - val_loss: 2.5724 - val_MinusLogProbMetric: 2.5724 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-11 22:59:26.222 
Epoch 10/1000 
	 loss: 2.5267, MinusLogProbMetric: 2.5267, val_loss: 2.6499, val_MinusLogProbMetric: 2.6499

Epoch 10: val_loss did not improve from 2.57239
196/196 - 12s - loss: 2.5267 - MinusLogProbMetric: 2.5267 - val_loss: 2.6499 - val_MinusLogProbMetric: 2.6499 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-11 22:59:37.926 
Epoch 11/1000 
	 loss: 2.5310, MinusLogProbMetric: 2.5310, val_loss: 2.5746, val_MinusLogProbMetric: 2.5746

Epoch 11: val_loss did not improve from 2.57239
196/196 - 12s - loss: 2.5310 - MinusLogProbMetric: 2.5310 - val_loss: 2.5746 - val_MinusLogProbMetric: 2.5746 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-11 22:59:49.593 
Epoch 12/1000 
	 loss: 2.5072, MinusLogProbMetric: 2.5072, val_loss: 2.5067, val_MinusLogProbMetric: 2.5067

Epoch 12: val_loss improved from 2.57239 to 2.50668, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.5072 - MinusLogProbMetric: 2.5072 - val_loss: 2.5067 - val_MinusLogProbMetric: 2.5067 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-11 23:00:01.517 
Epoch 13/1000 
	 loss: 2.4828, MinusLogProbMetric: 2.4828, val_loss: 2.5144, val_MinusLogProbMetric: 2.5144

Epoch 13: val_loss did not improve from 2.50668
196/196 - 12s - loss: 2.4828 - MinusLogProbMetric: 2.4828 - val_loss: 2.5144 - val_MinusLogProbMetric: 2.5144 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-11 23:00:13.213 
Epoch 14/1000 
	 loss: 2.4735, MinusLogProbMetric: 2.4735, val_loss: 2.4528, val_MinusLogProbMetric: 2.4528

Epoch 14: val_loss improved from 2.50668 to 2.45276, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4735 - MinusLogProbMetric: 2.4735 - val_loss: 2.4528 - val_MinusLogProbMetric: 2.4528 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-11 23:00:24.929 
Epoch 15/1000 
	 loss: 2.4816, MinusLogProbMetric: 2.4816, val_loss: 2.4958, val_MinusLogProbMetric: 2.4958

Epoch 15: val_loss did not improve from 2.45276
196/196 - 12s - loss: 2.4816 - MinusLogProbMetric: 2.4816 - val_loss: 2.4958 - val_MinusLogProbMetric: 2.4958 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 16/1000
2023-09-11 23:00:36.724 
Epoch 16/1000 
	 loss: 2.4802, MinusLogProbMetric: 2.4802, val_loss: 2.6197, val_MinusLogProbMetric: 2.6197

Epoch 16: val_loss did not improve from 2.45276
196/196 - 12s - loss: 2.4802 - MinusLogProbMetric: 2.4802 - val_loss: 2.6197 - val_MinusLogProbMetric: 2.6197 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-11 23:00:48.329 
Epoch 17/1000 
	 loss: 2.4825, MinusLogProbMetric: 2.4825, val_loss: 2.4527, val_MinusLogProbMetric: 2.4527

Epoch 17: val_loss improved from 2.45276 to 2.45266, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4825 - MinusLogProbMetric: 2.4825 - val_loss: 2.4527 - val_MinusLogProbMetric: 2.4527 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-11 23:01:00.179 
Epoch 18/1000 
	 loss: 2.4666, MinusLogProbMetric: 2.4666, val_loss: 2.4702, val_MinusLogProbMetric: 2.4702

Epoch 18: val_loss did not improve from 2.45266
196/196 - 12s - loss: 2.4666 - MinusLogProbMetric: 2.4666 - val_loss: 2.4702 - val_MinusLogProbMetric: 2.4702 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-11 23:01:11.846 
Epoch 19/1000 
	 loss: 2.4665, MinusLogProbMetric: 2.4665, val_loss: 2.7044, val_MinusLogProbMetric: 2.7044

Epoch 19: val_loss did not improve from 2.45266
196/196 - 12s - loss: 2.4665 - MinusLogProbMetric: 2.4665 - val_loss: 2.7044 - val_MinusLogProbMetric: 2.7044 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-11 23:01:23.629 
Epoch 20/1000 
	 loss: 2.4756, MinusLogProbMetric: 2.4756, val_loss: 2.4905, val_MinusLogProbMetric: 2.4905

Epoch 20: val_loss did not improve from 2.45266
196/196 - 12s - loss: 2.4756 - MinusLogProbMetric: 2.4756 - val_loss: 2.4905 - val_MinusLogProbMetric: 2.4905 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 21/1000
2023-09-11 23:01:35.373 
Epoch 21/1000 
	 loss: 2.4540, MinusLogProbMetric: 2.4540, val_loss: 2.5183, val_MinusLogProbMetric: 2.5183

Epoch 21: val_loss did not improve from 2.45266
196/196 - 12s - loss: 2.4540 - MinusLogProbMetric: 2.4540 - val_loss: 2.5183 - val_MinusLogProbMetric: 2.5183 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 22/1000
2023-09-11 23:01:47.159 
Epoch 22/1000 
	 loss: 2.4688, MinusLogProbMetric: 2.4688, val_loss: 2.4490, val_MinusLogProbMetric: 2.4490

Epoch 22: val_loss improved from 2.45266 to 2.44902, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4688 - MinusLogProbMetric: 2.4688 - val_loss: 2.4490 - val_MinusLogProbMetric: 2.4490 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 23/1000
2023-09-11 23:01:58.940 
Epoch 23/1000 
	 loss: 2.4424, MinusLogProbMetric: 2.4424, val_loss: 2.4363, val_MinusLogProbMetric: 2.4363

Epoch 23: val_loss improved from 2.44902 to 2.43633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4424 - MinusLogProbMetric: 2.4424 - val_loss: 2.4363 - val_MinusLogProbMetric: 2.4363 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-11 23:02:10.732 
Epoch 24/1000 
	 loss: 2.4430, MinusLogProbMetric: 2.4430, val_loss: 2.4528, val_MinusLogProbMetric: 2.4528

Epoch 24: val_loss did not improve from 2.43633
196/196 - 12s - loss: 2.4430 - MinusLogProbMetric: 2.4430 - val_loss: 2.4528 - val_MinusLogProbMetric: 2.4528 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-11 23:02:22.465 
Epoch 25/1000 
	 loss: 2.4455, MinusLogProbMetric: 2.4455, val_loss: 2.4621, val_MinusLogProbMetric: 2.4621

Epoch 25: val_loss did not improve from 2.43633
196/196 - 12s - loss: 2.4455 - MinusLogProbMetric: 2.4455 - val_loss: 2.4621 - val_MinusLogProbMetric: 2.4621 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-11 23:02:34.178 
Epoch 26/1000 
	 loss: 2.4380, MinusLogProbMetric: 2.4380, val_loss: 2.4461, val_MinusLogProbMetric: 2.4461

Epoch 26: val_loss did not improve from 2.43633
196/196 - 12s - loss: 2.4380 - MinusLogProbMetric: 2.4380 - val_loss: 2.4461 - val_MinusLogProbMetric: 2.4461 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-11 23:02:45.929 
Epoch 27/1000 
	 loss: 2.4435, MinusLogProbMetric: 2.4435, val_loss: 2.4531, val_MinusLogProbMetric: 2.4531

Epoch 27: val_loss did not improve from 2.43633
196/196 - 12s - loss: 2.4435 - MinusLogProbMetric: 2.4435 - val_loss: 2.4531 - val_MinusLogProbMetric: 2.4531 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-11 23:02:57.174 
Epoch 28/1000 
	 loss: 2.4376, MinusLogProbMetric: 2.4376, val_loss: 2.4540, val_MinusLogProbMetric: 2.4540

Epoch 28: val_loss did not improve from 2.43633
196/196 - 11s - loss: 2.4376 - MinusLogProbMetric: 2.4376 - val_loss: 2.4540 - val_MinusLogProbMetric: 2.4540 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 29/1000
2023-09-11 23:03:08.937 
Epoch 29/1000 
	 loss: 2.4443, MinusLogProbMetric: 2.4443, val_loss: 2.4466, val_MinusLogProbMetric: 2.4466

Epoch 29: val_loss did not improve from 2.43633
196/196 - 12s - loss: 2.4443 - MinusLogProbMetric: 2.4443 - val_loss: 2.4466 - val_MinusLogProbMetric: 2.4466 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 30/1000
2023-09-11 23:03:20.712 
Epoch 30/1000 
	 loss: 2.4446, MinusLogProbMetric: 2.4446, val_loss: 2.4220, val_MinusLogProbMetric: 2.4220

Epoch 30: val_loss improved from 2.43633 to 2.42203, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4446 - MinusLogProbMetric: 2.4446 - val_loss: 2.4220 - val_MinusLogProbMetric: 2.4220 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 31/1000
2023-09-11 23:03:32.635 
Epoch 31/1000 
	 loss: 2.4262, MinusLogProbMetric: 2.4262, val_loss: 2.4315, val_MinusLogProbMetric: 2.4315

Epoch 31: val_loss did not improve from 2.42203
196/196 - 12s - loss: 2.4262 - MinusLogProbMetric: 2.4262 - val_loss: 2.4315 - val_MinusLogProbMetric: 2.4315 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-11 23:03:44.342 
Epoch 32/1000 
	 loss: 2.4276, MinusLogProbMetric: 2.4276, val_loss: 2.4401, val_MinusLogProbMetric: 2.4401

Epoch 32: val_loss did not improve from 2.42203
196/196 - 12s - loss: 2.4276 - MinusLogProbMetric: 2.4276 - val_loss: 2.4401 - val_MinusLogProbMetric: 2.4401 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-11 23:03:56.110 
Epoch 33/1000 
	 loss: 2.4207, MinusLogProbMetric: 2.4207, val_loss: 2.4304, val_MinusLogProbMetric: 2.4304

Epoch 33: val_loss did not improve from 2.42203
196/196 - 12s - loss: 2.4207 - MinusLogProbMetric: 2.4207 - val_loss: 2.4304 - val_MinusLogProbMetric: 2.4304 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-11 23:04:07.803 
Epoch 34/1000 
	 loss: 2.4374, MinusLogProbMetric: 2.4374, val_loss: 2.4347, val_MinusLogProbMetric: 2.4347

Epoch 34: val_loss did not improve from 2.42203
196/196 - 12s - loss: 2.4374 - MinusLogProbMetric: 2.4374 - val_loss: 2.4347 - val_MinusLogProbMetric: 2.4347 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-11 23:04:19.524 
Epoch 35/1000 
	 loss: 2.4223, MinusLogProbMetric: 2.4223, val_loss: 2.4277, val_MinusLogProbMetric: 2.4277

Epoch 35: val_loss did not improve from 2.42203
196/196 - 12s - loss: 2.4223 - MinusLogProbMetric: 2.4223 - val_loss: 2.4277 - val_MinusLogProbMetric: 2.4277 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-11 23:04:31.179 
Epoch 36/1000 
	 loss: 2.4252, MinusLogProbMetric: 2.4252, val_loss: 2.4990, val_MinusLogProbMetric: 2.4990

Epoch 36: val_loss did not improve from 2.42203
196/196 - 12s - loss: 2.4252 - MinusLogProbMetric: 2.4252 - val_loss: 2.4990 - val_MinusLogProbMetric: 2.4990 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 37/1000
2023-09-11 23:04:42.937 
Epoch 37/1000 
	 loss: 2.4262, MinusLogProbMetric: 2.4262, val_loss: 2.4402, val_MinusLogProbMetric: 2.4402

Epoch 37: val_loss did not improve from 2.42203
196/196 - 12s - loss: 2.4262 - MinusLogProbMetric: 2.4262 - val_loss: 2.4402 - val_MinusLogProbMetric: 2.4402 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 38/1000
2023-09-11 23:04:54.621 
Epoch 38/1000 
	 loss: 2.4245, MinusLogProbMetric: 2.4245, val_loss: 2.4161, val_MinusLogProbMetric: 2.4161

Epoch 38: val_loss improved from 2.42203 to 2.41609, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4245 - MinusLogProbMetric: 2.4245 - val_loss: 2.4161 - val_MinusLogProbMetric: 2.4161 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-11 23:05:06.344 
Epoch 39/1000 
	 loss: 2.4198, MinusLogProbMetric: 2.4198, val_loss: 2.4562, val_MinusLogProbMetric: 2.4562

Epoch 39: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4198 - MinusLogProbMetric: 2.4198 - val_loss: 2.4562 - val_MinusLogProbMetric: 2.4562 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-11 23:05:18.082 
Epoch 40/1000 
	 loss: 2.4185, MinusLogProbMetric: 2.4185, val_loss: 2.4516, val_MinusLogProbMetric: 2.4516

Epoch 40: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4185 - MinusLogProbMetric: 2.4185 - val_loss: 2.4516 - val_MinusLogProbMetric: 2.4516 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-11 23:05:29.791 
Epoch 41/1000 
	 loss: 2.4294, MinusLogProbMetric: 2.4294, val_loss: 2.4467, val_MinusLogProbMetric: 2.4467

Epoch 41: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4294 - MinusLogProbMetric: 2.4294 - val_loss: 2.4467 - val_MinusLogProbMetric: 2.4467 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-11 23:05:41.553 
Epoch 42/1000 
	 loss: 2.4179, MinusLogProbMetric: 2.4179, val_loss: 2.4278, val_MinusLogProbMetric: 2.4278

Epoch 42: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4179 - MinusLogProbMetric: 2.4179 - val_loss: 2.4278 - val_MinusLogProbMetric: 2.4278 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-11 23:05:53.264 
Epoch 43/1000 
	 loss: 2.4217, MinusLogProbMetric: 2.4217, val_loss: 2.4846, val_MinusLogProbMetric: 2.4846

Epoch 43: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4217 - MinusLogProbMetric: 2.4217 - val_loss: 2.4846 - val_MinusLogProbMetric: 2.4846 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 44/1000
2023-09-11 23:06:04.940 
Epoch 44/1000 
	 loss: 2.4193, MinusLogProbMetric: 2.4193, val_loss: 2.4349, val_MinusLogProbMetric: 2.4349

Epoch 44: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4193 - MinusLogProbMetric: 2.4193 - val_loss: 2.4349 - val_MinusLogProbMetric: 2.4349 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-11 23:06:16.721 
Epoch 45/1000 
	 loss: 2.4159, MinusLogProbMetric: 2.4159, val_loss: 2.5136, val_MinusLogProbMetric: 2.5136

Epoch 45: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4159 - MinusLogProbMetric: 2.4159 - val_loss: 2.5136 - val_MinusLogProbMetric: 2.5136 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-11 23:06:28.477 
Epoch 46/1000 
	 loss: 2.4268, MinusLogProbMetric: 2.4268, val_loss: 2.4900, val_MinusLogProbMetric: 2.4900

Epoch 46: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4268 - MinusLogProbMetric: 2.4268 - val_loss: 2.4900 - val_MinusLogProbMetric: 2.4900 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 47/1000
2023-09-11 23:06:40.158 
Epoch 47/1000 
	 loss: 2.4107, MinusLogProbMetric: 2.4107, val_loss: 2.4256, val_MinusLogProbMetric: 2.4256

Epoch 47: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4107 - MinusLogProbMetric: 2.4107 - val_loss: 2.4256 - val_MinusLogProbMetric: 2.4256 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-11 23:06:51.940 
Epoch 48/1000 
	 loss: 2.4014, MinusLogProbMetric: 2.4014, val_loss: 2.4534, val_MinusLogProbMetric: 2.4534

Epoch 48: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4014 - MinusLogProbMetric: 2.4014 - val_loss: 2.4534 - val_MinusLogProbMetric: 2.4534 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-11 23:07:03.662 
Epoch 49/1000 
	 loss: 2.4037, MinusLogProbMetric: 2.4037, val_loss: 2.4575, val_MinusLogProbMetric: 2.4575

Epoch 49: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4037 - MinusLogProbMetric: 2.4037 - val_loss: 2.4575 - val_MinusLogProbMetric: 2.4575 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-11 23:07:15.451 
Epoch 50/1000 
	 loss: 2.4106, MinusLogProbMetric: 2.4106, val_loss: 2.4421, val_MinusLogProbMetric: 2.4421

Epoch 50: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4106 - MinusLogProbMetric: 2.4106 - val_loss: 2.4421 - val_MinusLogProbMetric: 2.4421 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 51/1000
2023-09-11 23:07:27.283 
Epoch 51/1000 
	 loss: 2.4126, MinusLogProbMetric: 2.4126, val_loss: 2.4542, val_MinusLogProbMetric: 2.4542

Epoch 51: val_loss did not improve from 2.41609
196/196 - 12s - loss: 2.4126 - MinusLogProbMetric: 2.4126 - val_loss: 2.4542 - val_MinusLogProbMetric: 2.4542 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-11 23:07:39.006 
Epoch 52/1000 
	 loss: 2.4125, MinusLogProbMetric: 2.4125, val_loss: 2.4103, val_MinusLogProbMetric: 2.4103

Epoch 52: val_loss improved from 2.41609 to 2.41027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4125 - MinusLogProbMetric: 2.4125 - val_loss: 2.4103 - val_MinusLogProbMetric: 2.4103 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-11 23:07:50.809 
Epoch 53/1000 
	 loss: 2.4035, MinusLogProbMetric: 2.4035, val_loss: 2.5531, val_MinusLogProbMetric: 2.5531

Epoch 53: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4035 - MinusLogProbMetric: 2.4035 - val_loss: 2.5531 - val_MinusLogProbMetric: 2.5531 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-11 23:08:02.594 
Epoch 54/1000 
	 loss: 2.4060, MinusLogProbMetric: 2.4060, val_loss: 2.4295, val_MinusLogProbMetric: 2.4295

Epoch 54: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4060 - MinusLogProbMetric: 2.4060 - val_loss: 2.4295 - val_MinusLogProbMetric: 2.4295 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 55/1000
2023-09-11 23:08:14.383 
Epoch 55/1000 
	 loss: 2.4009, MinusLogProbMetric: 2.4009, val_loss: 2.4264, val_MinusLogProbMetric: 2.4264

Epoch 55: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4009 - MinusLogProbMetric: 2.4009 - val_loss: 2.4264 - val_MinusLogProbMetric: 2.4264 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-11 23:08:26.025 
Epoch 56/1000 
	 loss: 2.4044, MinusLogProbMetric: 2.4044, val_loss: 2.4289, val_MinusLogProbMetric: 2.4289

Epoch 56: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4044 - MinusLogProbMetric: 2.4044 - val_loss: 2.4289 - val_MinusLogProbMetric: 2.4289 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 57/1000
2023-09-11 23:08:37.717 
Epoch 57/1000 
	 loss: 2.4077, MinusLogProbMetric: 2.4077, val_loss: 2.4438, val_MinusLogProbMetric: 2.4438

Epoch 57: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4077 - MinusLogProbMetric: 2.4077 - val_loss: 2.4438 - val_MinusLogProbMetric: 2.4438 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-11 23:08:49.418 
Epoch 58/1000 
	 loss: 2.4032, MinusLogProbMetric: 2.4032, val_loss: 2.4322, val_MinusLogProbMetric: 2.4322

Epoch 58: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4032 - MinusLogProbMetric: 2.4032 - val_loss: 2.4322 - val_MinusLogProbMetric: 2.4322 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-11 23:09:01.006 
Epoch 59/1000 
	 loss: 2.4021, MinusLogProbMetric: 2.4021, val_loss: 2.4299, val_MinusLogProbMetric: 2.4299

Epoch 59: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4021 - MinusLogProbMetric: 2.4021 - val_loss: 2.4299 - val_MinusLogProbMetric: 2.4299 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 60/1000
2023-09-11 23:09:12.608 
Epoch 60/1000 
	 loss: 2.4037, MinusLogProbMetric: 2.4037, val_loss: 2.4715, val_MinusLogProbMetric: 2.4715

Epoch 60: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4037 - MinusLogProbMetric: 2.4037 - val_loss: 2.4715 - val_MinusLogProbMetric: 2.4715 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 61/1000
2023-09-11 23:09:24.262 
Epoch 61/1000 
	 loss: 2.4039, MinusLogProbMetric: 2.4039, val_loss: 2.4125, val_MinusLogProbMetric: 2.4125

Epoch 61: val_loss did not improve from 2.41027
196/196 - 12s - loss: 2.4039 - MinusLogProbMetric: 2.4039 - val_loss: 2.4125 - val_MinusLogProbMetric: 2.4125 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 62/1000
2023-09-11 23:09:35.861 
Epoch 62/1000 
	 loss: 2.4042, MinusLogProbMetric: 2.4042, val_loss: 2.4071, val_MinusLogProbMetric: 2.4071

Epoch 62: val_loss improved from 2.41027 to 2.40713, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4042 - MinusLogProbMetric: 2.4042 - val_loss: 2.4071 - val_MinusLogProbMetric: 2.4071 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-11 23:09:47.841 
Epoch 63/1000 
	 loss: 2.4042, MinusLogProbMetric: 2.4042, val_loss: 2.4183, val_MinusLogProbMetric: 2.4183

Epoch 63: val_loss did not improve from 2.40713
196/196 - 12s - loss: 2.4042 - MinusLogProbMetric: 2.4042 - val_loss: 2.4183 - val_MinusLogProbMetric: 2.4183 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 64/1000
2023-09-11 23:09:59.717 
Epoch 64/1000 
	 loss: 2.3970, MinusLogProbMetric: 2.3970, val_loss: 2.4064, val_MinusLogProbMetric: 2.4064

Epoch 64: val_loss improved from 2.40713 to 2.40643, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3970 - MinusLogProbMetric: 2.3970 - val_loss: 2.4064 - val_MinusLogProbMetric: 2.4064 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 65/1000
2023-09-11 23:10:11.753 
Epoch 65/1000 
	 loss: 2.3979, MinusLogProbMetric: 2.3979, val_loss: 2.4384, val_MinusLogProbMetric: 2.4384

Epoch 65: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.3979 - MinusLogProbMetric: 2.3979 - val_loss: 2.4384 - val_MinusLogProbMetric: 2.4384 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 66/1000
2023-09-11 23:10:23.628 
Epoch 66/1000 
	 loss: 2.3989, MinusLogProbMetric: 2.3989, val_loss: 2.4507, val_MinusLogProbMetric: 2.4507

Epoch 66: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.3989 - MinusLogProbMetric: 2.3989 - val_loss: 2.4507 - val_MinusLogProbMetric: 2.4507 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 67/1000
2023-09-11 23:10:35.390 
Epoch 67/1000 
	 loss: 2.4008, MinusLogProbMetric: 2.4008, val_loss: 2.4253, val_MinusLogProbMetric: 2.4253

Epoch 67: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.4008 - MinusLogProbMetric: 2.4008 - val_loss: 2.4253 - val_MinusLogProbMetric: 2.4253 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-11 23:10:47.184 
Epoch 68/1000 
	 loss: 2.4003, MinusLogProbMetric: 2.4003, val_loss: 2.4082, val_MinusLogProbMetric: 2.4082

Epoch 68: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.4003 - MinusLogProbMetric: 2.4003 - val_loss: 2.4082 - val_MinusLogProbMetric: 2.4082 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-11 23:10:59.105 
Epoch 69/1000 
	 loss: 2.3967, MinusLogProbMetric: 2.3967, val_loss: 2.4404, val_MinusLogProbMetric: 2.4404

Epoch 69: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.3967 - MinusLogProbMetric: 2.3967 - val_loss: 2.4404 - val_MinusLogProbMetric: 2.4404 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 70/1000
2023-09-11 23:11:11.133 
Epoch 70/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.4391, val_MinusLogProbMetric: 2.4391

Epoch 70: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.4391 - val_MinusLogProbMetric: 2.4391 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 71/1000
2023-09-11 23:11:22.987 
Epoch 71/1000 
	 loss: 2.4069, MinusLogProbMetric: 2.4069, val_loss: 2.4196, val_MinusLogProbMetric: 2.4196

Epoch 71: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.4069 - MinusLogProbMetric: 2.4069 - val_loss: 2.4196 - val_MinusLogProbMetric: 2.4196 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-11 23:11:34.800 
Epoch 72/1000 
	 loss: 2.3960, MinusLogProbMetric: 2.3960, val_loss: 2.4308, val_MinusLogProbMetric: 2.4308

Epoch 72: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.3960 - MinusLogProbMetric: 2.3960 - val_loss: 2.4308 - val_MinusLogProbMetric: 2.4308 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-11 23:11:46.581 
Epoch 73/1000 
	 loss: 2.4017, MinusLogProbMetric: 2.4017, val_loss: 2.4400, val_MinusLogProbMetric: 2.4400

Epoch 73: val_loss did not improve from 2.40643
196/196 - 12s - loss: 2.4017 - MinusLogProbMetric: 2.4017 - val_loss: 2.4400 - val_MinusLogProbMetric: 2.4400 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-11 23:11:58.399 
Epoch 74/1000 
	 loss: 2.4025, MinusLogProbMetric: 2.4025, val_loss: 2.4039, val_MinusLogProbMetric: 2.4039

Epoch 74: val_loss improved from 2.40643 to 2.40392, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4025 - MinusLogProbMetric: 2.4025 - val_loss: 2.4039 - val_MinusLogProbMetric: 2.4039 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 75/1000
2023-09-11 23:12:10.428 
Epoch 75/1000 
	 loss: 2.4068, MinusLogProbMetric: 2.4068, val_loss: 2.4005, val_MinusLogProbMetric: 2.4005

Epoch 75: val_loss improved from 2.40392 to 2.40045, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.4068 - MinusLogProbMetric: 2.4068 - val_loss: 2.4005 - val_MinusLogProbMetric: 2.4005 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 76/1000
2023-09-11 23:12:22.379 
Epoch 76/1000 
	 loss: 2.4000, MinusLogProbMetric: 2.4000, val_loss: 2.4390, val_MinusLogProbMetric: 2.4390

Epoch 76: val_loss did not improve from 2.40045
196/196 - 12s - loss: 2.4000 - MinusLogProbMetric: 2.4000 - val_loss: 2.4390 - val_MinusLogProbMetric: 2.4390 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-11 23:12:34.194 
Epoch 77/1000 
	 loss: 2.3983, MinusLogProbMetric: 2.3983, val_loss: 2.3980, val_MinusLogProbMetric: 2.3980

Epoch 77: val_loss improved from 2.40045 to 2.39804, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3983 - MinusLogProbMetric: 2.3983 - val_loss: 2.3980 - val_MinusLogProbMetric: 2.3980 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 78/1000
2023-09-11 23:12:46.056 
Epoch 78/1000 
	 loss: 2.3964, MinusLogProbMetric: 2.3964, val_loss: 2.4867, val_MinusLogProbMetric: 2.4867

Epoch 78: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3964 - MinusLogProbMetric: 2.3964 - val_loss: 2.4867 - val_MinusLogProbMetric: 2.4867 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-11 23:12:57.804 
Epoch 79/1000 
	 loss: 2.4010, MinusLogProbMetric: 2.4010, val_loss: 2.4381, val_MinusLogProbMetric: 2.4381

Epoch 79: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.4010 - MinusLogProbMetric: 2.4010 - val_loss: 2.4381 - val_MinusLogProbMetric: 2.4381 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-11 23:13:09.476 
Epoch 80/1000 
	 loss: 2.3977, MinusLogProbMetric: 2.3977, val_loss: 2.4080, val_MinusLogProbMetric: 2.4080

Epoch 80: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3977 - MinusLogProbMetric: 2.3977 - val_loss: 2.4080 - val_MinusLogProbMetric: 2.4080 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 81/1000
2023-09-11 23:13:21.319 
Epoch 81/1000 
	 loss: 2.3930, MinusLogProbMetric: 2.3930, val_loss: 2.4132, val_MinusLogProbMetric: 2.4132

Epoch 81: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3930 - MinusLogProbMetric: 2.3930 - val_loss: 2.4132 - val_MinusLogProbMetric: 2.4132 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 82/1000
2023-09-11 23:13:32.912 
Epoch 82/1000 
	 loss: 2.3891, MinusLogProbMetric: 2.3891, val_loss: 2.4398, val_MinusLogProbMetric: 2.4398

Epoch 82: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3891 - MinusLogProbMetric: 2.3891 - val_loss: 2.4398 - val_MinusLogProbMetric: 2.4398 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 83/1000
2023-09-11 23:13:44.570 
Epoch 83/1000 
	 loss: 2.3982, MinusLogProbMetric: 2.3982, val_loss: 2.4346, val_MinusLogProbMetric: 2.4346

Epoch 83: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3982 - MinusLogProbMetric: 2.3982 - val_loss: 2.4346 - val_MinusLogProbMetric: 2.4346 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-11 23:13:56.391 
Epoch 84/1000 
	 loss: 2.3931, MinusLogProbMetric: 2.3931, val_loss: 2.4321, val_MinusLogProbMetric: 2.4321

Epoch 84: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3931 - MinusLogProbMetric: 2.3931 - val_loss: 2.4321 - val_MinusLogProbMetric: 2.4321 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 85/1000
2023-09-11 23:14:08.092 
Epoch 85/1000 
	 loss: 2.3991, MinusLogProbMetric: 2.3991, val_loss: 2.4263, val_MinusLogProbMetric: 2.4263

Epoch 85: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3991 - MinusLogProbMetric: 2.3991 - val_loss: 2.4263 - val_MinusLogProbMetric: 2.4263 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-11 23:14:19.834 
Epoch 86/1000 
	 loss: 2.3892, MinusLogProbMetric: 2.3892, val_loss: 2.4352, val_MinusLogProbMetric: 2.4352

Epoch 86: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3892 - MinusLogProbMetric: 2.3892 - val_loss: 2.4352 - val_MinusLogProbMetric: 2.4352 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 87/1000
2023-09-11 23:14:31.509 
Epoch 87/1000 
	 loss: 2.3956, MinusLogProbMetric: 2.3956, val_loss: 2.4173, val_MinusLogProbMetric: 2.4173

Epoch 87: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3956 - MinusLogProbMetric: 2.3956 - val_loss: 2.4173 - val_MinusLogProbMetric: 2.4173 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 88/1000
2023-09-11 23:14:43.360 
Epoch 88/1000 
	 loss: 2.4007, MinusLogProbMetric: 2.4007, val_loss: 2.4091, val_MinusLogProbMetric: 2.4091

Epoch 88: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.4007 - MinusLogProbMetric: 2.4007 - val_loss: 2.4091 - val_MinusLogProbMetric: 2.4091 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-11 23:14:55.088 
Epoch 89/1000 
	 loss: 2.4003, MinusLogProbMetric: 2.4003, val_loss: 2.4185, val_MinusLogProbMetric: 2.4185

Epoch 89: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.4003 - MinusLogProbMetric: 2.4003 - val_loss: 2.4185 - val_MinusLogProbMetric: 2.4185 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-11 23:15:06.705 
Epoch 90/1000 
	 loss: 2.3902, MinusLogProbMetric: 2.3902, val_loss: 2.4100, val_MinusLogProbMetric: 2.4100

Epoch 90: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3902 - MinusLogProbMetric: 2.3902 - val_loss: 2.4100 - val_MinusLogProbMetric: 2.4100 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 91/1000
2023-09-11 23:15:18.434 
Epoch 91/1000 
	 loss: 2.3903, MinusLogProbMetric: 2.3903, val_loss: 2.4110, val_MinusLogProbMetric: 2.4110

Epoch 91: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3903 - MinusLogProbMetric: 2.3903 - val_loss: 2.4110 - val_MinusLogProbMetric: 2.4110 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-11 23:15:30.225 
Epoch 92/1000 
	 loss: 2.3880, MinusLogProbMetric: 2.3880, val_loss: 2.4419, val_MinusLogProbMetric: 2.4419

Epoch 92: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3880 - MinusLogProbMetric: 2.3880 - val_loss: 2.4419 - val_MinusLogProbMetric: 2.4419 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-11 23:15:41.907 
Epoch 93/1000 
	 loss: 2.3956, MinusLogProbMetric: 2.3956, val_loss: 2.4176, val_MinusLogProbMetric: 2.4176

Epoch 93: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3956 - MinusLogProbMetric: 2.3956 - val_loss: 2.4176 - val_MinusLogProbMetric: 2.4176 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-11 23:15:53.569 
Epoch 94/1000 
	 loss: 2.3916, MinusLogProbMetric: 2.3916, val_loss: 2.4151, val_MinusLogProbMetric: 2.4151

Epoch 94: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3916 - MinusLogProbMetric: 2.3916 - val_loss: 2.4151 - val_MinusLogProbMetric: 2.4151 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-11 23:16:05.408 
Epoch 95/1000 
	 loss: 2.3940, MinusLogProbMetric: 2.3940, val_loss: 2.4101, val_MinusLogProbMetric: 2.4101

Epoch 95: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3940 - MinusLogProbMetric: 2.3940 - val_loss: 2.4101 - val_MinusLogProbMetric: 2.4101 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-11 23:16:17.079 
Epoch 96/1000 
	 loss: 2.3840, MinusLogProbMetric: 2.3840, val_loss: 2.4069, val_MinusLogProbMetric: 2.4069

Epoch 96: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3840 - MinusLogProbMetric: 2.3840 - val_loss: 2.4069 - val_MinusLogProbMetric: 2.4069 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 97/1000
2023-09-11 23:16:28.891 
Epoch 97/1000 
	 loss: 2.3922, MinusLogProbMetric: 2.3922, val_loss: 2.4098, val_MinusLogProbMetric: 2.4098

Epoch 97: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3922 - MinusLogProbMetric: 2.3922 - val_loss: 2.4098 - val_MinusLogProbMetric: 2.4098 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 98/1000
2023-09-11 23:16:40.657 
Epoch 98/1000 
	 loss: 2.3907, MinusLogProbMetric: 2.3907, val_loss: 2.4244, val_MinusLogProbMetric: 2.4244

Epoch 98: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3907 - MinusLogProbMetric: 2.3907 - val_loss: 2.4244 - val_MinusLogProbMetric: 2.4244 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 99/1000
2023-09-11 23:16:52.352 
Epoch 99/1000 
	 loss: 2.3934, MinusLogProbMetric: 2.3934, val_loss: 2.4240, val_MinusLogProbMetric: 2.4240

Epoch 99: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3934 - MinusLogProbMetric: 2.3934 - val_loss: 2.4240 - val_MinusLogProbMetric: 2.4240 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 100/1000
2023-09-11 23:17:04.067 
Epoch 100/1000 
	 loss: 2.3924, MinusLogProbMetric: 2.3924, val_loss: 2.4111, val_MinusLogProbMetric: 2.4111

Epoch 100: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3924 - MinusLogProbMetric: 2.3924 - val_loss: 2.4111 - val_MinusLogProbMetric: 2.4111 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-11 23:17:15.840 
Epoch 101/1000 
	 loss: 2.3892, MinusLogProbMetric: 2.3892, val_loss: 2.4399, val_MinusLogProbMetric: 2.4399

Epoch 101: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3892 - MinusLogProbMetric: 2.3892 - val_loss: 2.4399 - val_MinusLogProbMetric: 2.4399 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 102/1000
2023-09-11 23:17:27.611 
Epoch 102/1000 
	 loss: 2.3928, MinusLogProbMetric: 2.3928, val_loss: 2.4201, val_MinusLogProbMetric: 2.4201

Epoch 102: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3928 - MinusLogProbMetric: 2.3928 - val_loss: 2.4201 - val_MinusLogProbMetric: 2.4201 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 103/1000
2023-09-11 23:17:39.468 
Epoch 103/1000 
	 loss: 2.3902, MinusLogProbMetric: 2.3902, val_loss: 2.4226, val_MinusLogProbMetric: 2.4226

Epoch 103: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3902 - MinusLogProbMetric: 2.3902 - val_loss: 2.4226 - val_MinusLogProbMetric: 2.4226 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-11 23:17:51.287 
Epoch 104/1000 
	 loss: 2.3920, MinusLogProbMetric: 2.3920, val_loss: 2.4024, val_MinusLogProbMetric: 2.4024

Epoch 104: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3920 - MinusLogProbMetric: 2.3920 - val_loss: 2.4024 - val_MinusLogProbMetric: 2.4024 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 105/1000
2023-09-11 23:18:03.023 
Epoch 105/1000 
	 loss: 2.3894, MinusLogProbMetric: 2.3894, val_loss: 2.4196, val_MinusLogProbMetric: 2.4196

Epoch 105: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3894 - MinusLogProbMetric: 2.3894 - val_loss: 2.4196 - val_MinusLogProbMetric: 2.4196 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-11 23:18:14.790 
Epoch 106/1000 
	 loss: 2.3884, MinusLogProbMetric: 2.3884, val_loss: 2.4051, val_MinusLogProbMetric: 2.4051

Epoch 106: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3884 - MinusLogProbMetric: 2.3884 - val_loss: 2.4051 - val_MinusLogProbMetric: 2.4051 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 107/1000
2023-09-11 23:18:26.584 
Epoch 107/1000 
	 loss: 2.3893, MinusLogProbMetric: 2.3893, val_loss: 2.4070, val_MinusLogProbMetric: 2.4070

Epoch 107: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3893 - MinusLogProbMetric: 2.3893 - val_loss: 2.4070 - val_MinusLogProbMetric: 2.4070 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-11 23:18:38.322 
Epoch 108/1000 
	 loss: 2.3956, MinusLogProbMetric: 2.3956, val_loss: 2.4192, val_MinusLogProbMetric: 2.4192

Epoch 108: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3956 - MinusLogProbMetric: 2.3956 - val_loss: 2.4192 - val_MinusLogProbMetric: 2.4192 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-11 23:18:50.229 
Epoch 109/1000 
	 loss: 2.3888, MinusLogProbMetric: 2.3888, val_loss: 2.4023, val_MinusLogProbMetric: 2.4023

Epoch 109: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3888 - MinusLogProbMetric: 2.3888 - val_loss: 2.4023 - val_MinusLogProbMetric: 2.4023 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 110/1000
2023-09-11 23:19:01.968 
Epoch 110/1000 
	 loss: 2.3900, MinusLogProbMetric: 2.3900, val_loss: 2.4739, val_MinusLogProbMetric: 2.4739

Epoch 110: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3900 - MinusLogProbMetric: 2.3900 - val_loss: 2.4739 - val_MinusLogProbMetric: 2.4739 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 111/1000
2023-09-11 23:19:13.755 
Epoch 111/1000 
	 loss: 2.3841, MinusLogProbMetric: 2.3841, val_loss: 2.4101, val_MinusLogProbMetric: 2.4101

Epoch 111: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3841 - MinusLogProbMetric: 2.3841 - val_loss: 2.4101 - val_MinusLogProbMetric: 2.4101 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-11 23:19:25.475 
Epoch 112/1000 
	 loss: 2.3841, MinusLogProbMetric: 2.3841, val_loss: 2.4159, val_MinusLogProbMetric: 2.4159

Epoch 112: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3841 - MinusLogProbMetric: 2.3841 - val_loss: 2.4159 - val_MinusLogProbMetric: 2.4159 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 113/1000
2023-09-11 23:19:37.186 
Epoch 113/1000 
	 loss: 2.3872, MinusLogProbMetric: 2.3872, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 113: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3872 - MinusLogProbMetric: 2.3872 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-11 23:19:48.912 
Epoch 114/1000 
	 loss: 2.3912, MinusLogProbMetric: 2.3912, val_loss: 2.4198, val_MinusLogProbMetric: 2.4198

Epoch 114: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3912 - MinusLogProbMetric: 2.3912 - val_loss: 2.4198 - val_MinusLogProbMetric: 2.4198 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 115/1000
2023-09-11 23:20:00.636 
Epoch 115/1000 
	 loss: 2.3877, MinusLogProbMetric: 2.3877, val_loss: 2.4512, val_MinusLogProbMetric: 2.4512

Epoch 115: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3877 - MinusLogProbMetric: 2.3877 - val_loss: 2.4512 - val_MinusLogProbMetric: 2.4512 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 116/1000
2023-09-11 23:20:12.448 
Epoch 116/1000 
	 loss: 2.3864, MinusLogProbMetric: 2.3864, val_loss: 2.4095, val_MinusLogProbMetric: 2.4095

Epoch 116: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3864 - MinusLogProbMetric: 2.3864 - val_loss: 2.4095 - val_MinusLogProbMetric: 2.4095 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 117/1000
2023-09-11 23:20:24.132 
Epoch 117/1000 
	 loss: 2.3850, MinusLogProbMetric: 2.3850, val_loss: 2.4087, val_MinusLogProbMetric: 2.4087

Epoch 117: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3850 - MinusLogProbMetric: 2.3850 - val_loss: 2.4087 - val_MinusLogProbMetric: 2.4087 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-11 23:20:35.953 
Epoch 118/1000 
	 loss: 2.3842, MinusLogProbMetric: 2.3842, val_loss: 2.4097, val_MinusLogProbMetric: 2.4097

Epoch 118: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3842 - MinusLogProbMetric: 2.3842 - val_loss: 2.4097 - val_MinusLogProbMetric: 2.4097 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-11 23:20:47.630 
Epoch 119/1000 
	 loss: 2.3876, MinusLogProbMetric: 2.3876, val_loss: 2.4253, val_MinusLogProbMetric: 2.4253

Epoch 119: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3876 - MinusLogProbMetric: 2.3876 - val_loss: 2.4253 - val_MinusLogProbMetric: 2.4253 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 120/1000
2023-09-11 23:20:59.385 
Epoch 120/1000 
	 loss: 2.3851, MinusLogProbMetric: 2.3851, val_loss: 2.4015, val_MinusLogProbMetric: 2.4015

Epoch 120: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3851 - MinusLogProbMetric: 2.3851 - val_loss: 2.4015 - val_MinusLogProbMetric: 2.4015 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-11 23:21:11.120 
Epoch 121/1000 
	 loss: 2.3831, MinusLogProbMetric: 2.3831, val_loss: 2.4182, val_MinusLogProbMetric: 2.4182

Epoch 121: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3831 - MinusLogProbMetric: 2.3831 - val_loss: 2.4182 - val_MinusLogProbMetric: 2.4182 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-11 23:21:22.761 
Epoch 122/1000 
	 loss: 2.3814, MinusLogProbMetric: 2.3814, val_loss: 2.4072, val_MinusLogProbMetric: 2.4072

Epoch 122: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3814 - MinusLogProbMetric: 2.3814 - val_loss: 2.4072 - val_MinusLogProbMetric: 2.4072 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 123/1000
2023-09-11 23:21:34.529 
Epoch 123/1000 
	 loss: 2.3854, MinusLogProbMetric: 2.3854, val_loss: 2.4552, val_MinusLogProbMetric: 2.4552

Epoch 123: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3854 - MinusLogProbMetric: 2.3854 - val_loss: 2.4552 - val_MinusLogProbMetric: 2.4552 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-11 23:21:46.285 
Epoch 124/1000 
	 loss: 2.3862, MinusLogProbMetric: 2.3862, val_loss: 2.4365, val_MinusLogProbMetric: 2.4365

Epoch 124: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3862 - MinusLogProbMetric: 2.3862 - val_loss: 2.4365 - val_MinusLogProbMetric: 2.4365 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-11 23:21:57.352 
Epoch 125/1000 
	 loss: 2.3841, MinusLogProbMetric: 2.3841, val_loss: 2.4019, val_MinusLogProbMetric: 2.4019

Epoch 125: val_loss did not improve from 2.39804
196/196 - 11s - loss: 2.3841 - MinusLogProbMetric: 2.3841 - val_loss: 2.4019 - val_MinusLogProbMetric: 2.4019 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 126/1000
2023-09-11 23:22:09.011 
Epoch 126/1000 
	 loss: 2.3879, MinusLogProbMetric: 2.3879, val_loss: 2.4163, val_MinusLogProbMetric: 2.4163

Epoch 126: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3879 - MinusLogProbMetric: 2.3879 - val_loss: 2.4163 - val_MinusLogProbMetric: 2.4163 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 127/1000
2023-09-11 23:22:20.677 
Epoch 127/1000 
	 loss: 2.3885, MinusLogProbMetric: 2.3885, val_loss: 2.4120, val_MinusLogProbMetric: 2.4120

Epoch 127: val_loss did not improve from 2.39804
196/196 - 12s - loss: 2.3885 - MinusLogProbMetric: 2.3885 - val_loss: 2.4120 - val_MinusLogProbMetric: 2.4120 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 128/1000
2023-09-11 23:22:32.344 
Epoch 128/1000 
	 loss: 2.3716, MinusLogProbMetric: 2.3716, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 128: val_loss improved from 2.39804 to 2.39639, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3716 - MinusLogProbMetric: 2.3716 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-11 23:22:44.213 
Epoch 129/1000 
	 loss: 2.3718, MinusLogProbMetric: 2.3718, val_loss: 2.3985, val_MinusLogProbMetric: 2.3985

Epoch 129: val_loss did not improve from 2.39639
196/196 - 12s - loss: 2.3718 - MinusLogProbMetric: 2.3718 - val_loss: 2.3985 - val_MinusLogProbMetric: 2.3985 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-11 23:22:55.892 
Epoch 130/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3931, val_MinusLogProbMetric: 2.3931

Epoch 130: val_loss improved from 2.39639 to 2.39305, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3931 - val_MinusLogProbMetric: 2.3931 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-11 23:23:07.756 
Epoch 131/1000 
	 loss: 2.3695, MinusLogProbMetric: 2.3695, val_loss: 2.4042, val_MinusLogProbMetric: 2.4042

Epoch 131: val_loss did not improve from 2.39305
196/196 - 12s - loss: 2.3695 - MinusLogProbMetric: 2.3695 - val_loss: 2.4042 - val_MinusLogProbMetric: 2.4042 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 132/1000
2023-09-11 23:23:19.608 
Epoch 132/1000 
	 loss: 2.3726, MinusLogProbMetric: 2.3726, val_loss: 2.3926, val_MinusLogProbMetric: 2.3926

Epoch 132: val_loss improved from 2.39305 to 2.39258, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3726 - MinusLogProbMetric: 2.3726 - val_loss: 2.3926 - val_MinusLogProbMetric: 2.3926 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 133/1000
2023-09-11 23:23:31.564 
Epoch 133/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.4039, val_MinusLogProbMetric: 2.4039

Epoch 133: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.4039 - val_MinusLogProbMetric: 2.4039 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-11 23:23:43.347 
Epoch 134/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 134: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-11 23:23:55.267 
Epoch 135/1000 
	 loss: 2.3709, MinusLogProbMetric: 2.3709, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 135: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3709 - MinusLogProbMetric: 2.3709 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 136/1000
2023-09-11 23:24:06.977 
Epoch 136/1000 
	 loss: 2.3699, MinusLogProbMetric: 2.3699, val_loss: 2.4095, val_MinusLogProbMetric: 2.4095

Epoch 136: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3699 - MinusLogProbMetric: 2.3699 - val_loss: 2.4095 - val_MinusLogProbMetric: 2.4095 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 137/1000
2023-09-11 23:24:18.850 
Epoch 137/1000 
	 loss: 2.3692, MinusLogProbMetric: 2.3692, val_loss: 2.4072, val_MinusLogProbMetric: 2.4072

Epoch 137: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3692 - MinusLogProbMetric: 2.3692 - val_loss: 2.4072 - val_MinusLogProbMetric: 2.4072 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 138/1000
2023-09-11 23:24:30.563 
Epoch 138/1000 
	 loss: 2.3713, MinusLogProbMetric: 2.3713, val_loss: 2.3938, val_MinusLogProbMetric: 2.3938

Epoch 138: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3713 - MinusLogProbMetric: 2.3713 - val_loss: 2.3938 - val_MinusLogProbMetric: 2.3938 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-11 23:24:42.351 
Epoch 139/1000 
	 loss: 2.3702, MinusLogProbMetric: 2.3702, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 139: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3702 - MinusLogProbMetric: 2.3702 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-11 23:24:54.277 
Epoch 140/1000 
	 loss: 2.3719, MinusLogProbMetric: 2.3719, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 140: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3719 - MinusLogProbMetric: 2.3719 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 141/1000
2023-09-11 23:25:05.548 
Epoch 141/1000 
	 loss: 2.3691, MinusLogProbMetric: 2.3691, val_loss: 2.3974, val_MinusLogProbMetric: 2.3974

Epoch 141: val_loss did not improve from 2.39258
196/196 - 11s - loss: 2.3691 - MinusLogProbMetric: 2.3691 - val_loss: 2.3974 - val_MinusLogProbMetric: 2.3974 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 142/1000
2023-09-11 23:25:16.054 
Epoch 142/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.4000, val_MinusLogProbMetric: 2.4000

Epoch 142: val_loss did not improve from 2.39258
196/196 - 11s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.4000 - val_MinusLogProbMetric: 2.4000 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 143/1000
2023-09-11 23:25:27.698 
Epoch 143/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 143: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 144/1000
2023-09-11 23:25:39.302 
Epoch 144/1000 
	 loss: 2.3699, MinusLogProbMetric: 2.3699, val_loss: 2.4077, val_MinusLogProbMetric: 2.4077

Epoch 144: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3699 - MinusLogProbMetric: 2.3699 - val_loss: 2.4077 - val_MinusLogProbMetric: 2.4077 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 145/1000
2023-09-11 23:25:50.994 
Epoch 145/1000 
	 loss: 2.3697, MinusLogProbMetric: 2.3697, val_loss: 2.3980, val_MinusLogProbMetric: 2.3980

Epoch 145: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3697 - MinusLogProbMetric: 2.3697 - val_loss: 2.3980 - val_MinusLogProbMetric: 2.3980 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 146/1000
2023-09-11 23:26:02.805 
Epoch 146/1000 
	 loss: 2.3719, MinusLogProbMetric: 2.3719, val_loss: 2.3994, val_MinusLogProbMetric: 2.3994

Epoch 146: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3719 - MinusLogProbMetric: 2.3719 - val_loss: 2.3994 - val_MinusLogProbMetric: 2.3994 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-11 23:26:14.563 
Epoch 147/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.3979, val_MinusLogProbMetric: 2.3979

Epoch 147: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.3979 - val_MinusLogProbMetric: 2.3979 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-11 23:26:26.291 
Epoch 148/1000 
	 loss: 2.3738, MinusLogProbMetric: 2.3738, val_loss: 2.4017, val_MinusLogProbMetric: 2.4017

Epoch 148: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3738 - MinusLogProbMetric: 2.3738 - val_loss: 2.4017 - val_MinusLogProbMetric: 2.4017 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-11 23:26:37.926 
Epoch 149/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.4014, val_MinusLogProbMetric: 2.4014

Epoch 149: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.4014 - val_MinusLogProbMetric: 2.4014 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 150/1000
2023-09-11 23:26:49.691 
Epoch 150/1000 
	 loss: 2.3693, MinusLogProbMetric: 2.3693, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 150: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3693 - MinusLogProbMetric: 2.3693 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-11 23:27:01.274 
Epoch 151/1000 
	 loss: 2.3685, MinusLogProbMetric: 2.3685, val_loss: 2.3976, val_MinusLogProbMetric: 2.3976

Epoch 151: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3685 - MinusLogProbMetric: 2.3685 - val_loss: 2.3976 - val_MinusLogProbMetric: 2.3976 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 152/1000
2023-09-11 23:27:13.103 
Epoch 152/1000 
	 loss: 2.3688, MinusLogProbMetric: 2.3688, val_loss: 2.3975, val_MinusLogProbMetric: 2.3975

Epoch 152: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3688 - MinusLogProbMetric: 2.3688 - val_loss: 2.3975 - val_MinusLogProbMetric: 2.3975 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-11 23:27:24.925 
Epoch 153/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.3947, val_MinusLogProbMetric: 2.3947

Epoch 153: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.3947 - val_MinusLogProbMetric: 2.3947 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 154/1000
2023-09-11 23:27:36.778 
Epoch 154/1000 
	 loss: 2.3703, MinusLogProbMetric: 2.3703, val_loss: 2.3973, val_MinusLogProbMetric: 2.3973

Epoch 154: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3703 - MinusLogProbMetric: 2.3703 - val_loss: 2.3973 - val_MinusLogProbMetric: 2.3973 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 155/1000
2023-09-11 23:27:48.696 
Epoch 155/1000 
	 loss: 2.3711, MinusLogProbMetric: 2.3711, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 155: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3711 - MinusLogProbMetric: 2.3711 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 156/1000
2023-09-11 23:28:00.704 
Epoch 156/1000 
	 loss: 2.3699, MinusLogProbMetric: 2.3699, val_loss: 2.3982, val_MinusLogProbMetric: 2.3982

Epoch 156: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3699 - MinusLogProbMetric: 2.3699 - val_loss: 2.3982 - val_MinusLogProbMetric: 2.3982 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 157/1000
2023-09-11 23:28:12.620 
Epoch 157/1000 
	 loss: 2.3694, MinusLogProbMetric: 2.3694, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 157: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3694 - MinusLogProbMetric: 2.3694 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 158/1000
2023-09-11 23:28:24.552 
Epoch 158/1000 
	 loss: 2.3729, MinusLogProbMetric: 2.3729, val_loss: 2.4000, val_MinusLogProbMetric: 2.4000

Epoch 158: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3729 - MinusLogProbMetric: 2.3729 - val_loss: 2.4000 - val_MinusLogProbMetric: 2.4000 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 159/1000
2023-09-11 23:28:36.387 
Epoch 159/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3992, val_MinusLogProbMetric: 2.3992

Epoch 159: val_loss did not improve from 2.39258
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3992 - val_MinusLogProbMetric: 2.3992 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-11 23:28:48.177 
Epoch 160/1000 
	 loss: 2.3687, MinusLogProbMetric: 2.3687, val_loss: 2.3922, val_MinusLogProbMetric: 2.3922

Epoch 160: val_loss improved from 2.39258 to 2.39216, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3687 - MinusLogProbMetric: 2.3687 - val_loss: 2.3922 - val_MinusLogProbMetric: 2.3922 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 161/1000
2023-09-11 23:29:00.258 
Epoch 161/1000 
	 loss: 2.3698, MinusLogProbMetric: 2.3698, val_loss: 2.4009, val_MinusLogProbMetric: 2.4009

Epoch 161: val_loss did not improve from 2.39216
196/196 - 12s - loss: 2.3698 - MinusLogProbMetric: 2.3698 - val_loss: 2.4009 - val_MinusLogProbMetric: 2.4009 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 162/1000
2023-09-11 23:29:12.136 
Epoch 162/1000 
	 loss: 2.3689, MinusLogProbMetric: 2.3689, val_loss: 2.3967, val_MinusLogProbMetric: 2.3967

Epoch 162: val_loss did not improve from 2.39216
196/196 - 12s - loss: 2.3689 - MinusLogProbMetric: 2.3689 - val_loss: 2.3967 - val_MinusLogProbMetric: 2.3967 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 163/1000
2023-09-11 23:29:24.133 
Epoch 163/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3997, val_MinusLogProbMetric: 2.3997

Epoch 163: val_loss did not improve from 2.39216
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3997 - val_MinusLogProbMetric: 2.3997 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 164/1000
2023-09-11 23:29:36.072 
Epoch 164/1000 
	 loss: 2.3710, MinusLogProbMetric: 2.3710, val_loss: 2.3960, val_MinusLogProbMetric: 2.3960

Epoch 164: val_loss did not improve from 2.39216
196/196 - 12s - loss: 2.3710 - MinusLogProbMetric: 2.3710 - val_loss: 2.3960 - val_MinusLogProbMetric: 2.3960 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 165/1000
2023-09-11 23:29:47.772 
Epoch 165/1000 
	 loss: 2.3690, MinusLogProbMetric: 2.3690, val_loss: 2.4081, val_MinusLogProbMetric: 2.4081

Epoch 165: val_loss did not improve from 2.39216
196/196 - 12s - loss: 2.3690 - MinusLogProbMetric: 2.3690 - val_loss: 2.4081 - val_MinusLogProbMetric: 2.4081 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 166/1000
2023-09-11 23:29:59.570 
Epoch 166/1000 
	 loss: 2.3696, MinusLogProbMetric: 2.3696, val_loss: 2.3958, val_MinusLogProbMetric: 2.3958

Epoch 166: val_loss did not improve from 2.39216
196/196 - 12s - loss: 2.3696 - MinusLogProbMetric: 2.3696 - val_loss: 2.3958 - val_MinusLogProbMetric: 2.3958 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 167/1000
2023-09-11 23:30:11.502 
Epoch 167/1000 
	 loss: 2.3687, MinusLogProbMetric: 2.3687, val_loss: 2.4019, val_MinusLogProbMetric: 2.4019

Epoch 167: val_loss did not improve from 2.39216
196/196 - 12s - loss: 2.3687 - MinusLogProbMetric: 2.3687 - val_loss: 2.4019 - val_MinusLogProbMetric: 2.4019 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 168/1000
2023-09-11 23:30:23.233 
Epoch 168/1000 
	 loss: 2.3690, MinusLogProbMetric: 2.3690, val_loss: 2.3917, val_MinusLogProbMetric: 2.3917

Epoch 168: val_loss improved from 2.39216 to 2.39174, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3690 - MinusLogProbMetric: 2.3690 - val_loss: 2.3917 - val_MinusLogProbMetric: 2.3917 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-11 23:30:35.034 
Epoch 169/1000 
	 loss: 2.3668, MinusLogProbMetric: 2.3668, val_loss: 2.3949, val_MinusLogProbMetric: 2.3949

Epoch 169: val_loss did not improve from 2.39174
196/196 - 12s - loss: 2.3668 - MinusLogProbMetric: 2.3668 - val_loss: 2.3949 - val_MinusLogProbMetric: 2.3949 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 170/1000
2023-09-11 23:30:46.822 
Epoch 170/1000 
	 loss: 2.3708, MinusLogProbMetric: 2.3708, val_loss: 2.3916, val_MinusLogProbMetric: 2.3916

Epoch 170: val_loss improved from 2.39174 to 2.39157, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3708 - MinusLogProbMetric: 2.3708 - val_loss: 2.3916 - val_MinusLogProbMetric: 2.3916 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 171/1000
2023-09-11 23:30:58.653 
Epoch 171/1000 
	 loss: 2.3702, MinusLogProbMetric: 2.3702, val_loss: 2.4000, val_MinusLogProbMetric: 2.4000

Epoch 171: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3702 - MinusLogProbMetric: 2.3702 - val_loss: 2.4000 - val_MinusLogProbMetric: 2.4000 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 172/1000
2023-09-11 23:31:10.489 
Epoch 172/1000 
	 loss: 2.3694, MinusLogProbMetric: 2.3694, val_loss: 2.4034, val_MinusLogProbMetric: 2.4034

Epoch 172: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3694 - MinusLogProbMetric: 2.3694 - val_loss: 2.4034 - val_MinusLogProbMetric: 2.4034 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 173/1000
2023-09-11 23:31:22.452 
Epoch 173/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3961, val_MinusLogProbMetric: 2.3961

Epoch 173: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3961 - val_MinusLogProbMetric: 2.3961 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 174/1000
2023-09-11 23:31:34.234 
Epoch 174/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3938, val_MinusLogProbMetric: 2.3938

Epoch 174: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3938 - val_MinusLogProbMetric: 2.3938 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 175/1000
2023-09-11 23:31:46.110 
Epoch 175/1000 
	 loss: 2.3688, MinusLogProbMetric: 2.3688, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 175: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3688 - MinusLogProbMetric: 2.3688 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 176/1000
2023-09-11 23:31:57.896 
Epoch 176/1000 
	 loss: 2.3673, MinusLogProbMetric: 2.3673, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 176: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3673 - MinusLogProbMetric: 2.3673 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-11 23:32:09.852 
Epoch 177/1000 
	 loss: 2.3675, MinusLogProbMetric: 2.3675, val_loss: 2.4009, val_MinusLogProbMetric: 2.4009

Epoch 177: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3675 - MinusLogProbMetric: 2.3675 - val_loss: 2.4009 - val_MinusLogProbMetric: 2.4009 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 178/1000
2023-09-11 23:32:21.656 
Epoch 178/1000 
	 loss: 2.3708, MinusLogProbMetric: 2.3708, val_loss: 2.3988, val_MinusLogProbMetric: 2.3988

Epoch 178: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3708 - MinusLogProbMetric: 2.3708 - val_loss: 2.3988 - val_MinusLogProbMetric: 2.3988 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-11 23:32:33.464 
Epoch 179/1000 
	 loss: 2.3671, MinusLogProbMetric: 2.3671, val_loss: 2.3989, val_MinusLogProbMetric: 2.3989

Epoch 179: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3671 - MinusLogProbMetric: 2.3671 - val_loss: 2.3989 - val_MinusLogProbMetric: 2.3989 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 180/1000
2023-09-11 23:32:45.105 
Epoch 180/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.3948, val_MinusLogProbMetric: 2.3948

Epoch 180: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.3948 - val_MinusLogProbMetric: 2.3948 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 181/1000
2023-09-11 23:32:56.847 
Epoch 181/1000 
	 loss: 2.3670, MinusLogProbMetric: 2.3670, val_loss: 2.3976, val_MinusLogProbMetric: 2.3976

Epoch 181: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3670 - MinusLogProbMetric: 2.3670 - val_loss: 2.3976 - val_MinusLogProbMetric: 2.3976 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 182/1000
2023-09-11 23:33:08.613 
Epoch 182/1000 
	 loss: 2.3676, MinusLogProbMetric: 2.3676, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 182: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3676 - MinusLogProbMetric: 2.3676 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 183/1000
2023-09-11 23:33:20.404 
Epoch 183/1000 
	 loss: 2.3695, MinusLogProbMetric: 2.3695, val_loss: 2.4043, val_MinusLogProbMetric: 2.4043

Epoch 183: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3695 - MinusLogProbMetric: 2.3695 - val_loss: 2.4043 - val_MinusLogProbMetric: 2.4043 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 184/1000
2023-09-11 23:33:32.118 
Epoch 184/1000 
	 loss: 2.3704, MinusLogProbMetric: 2.3704, val_loss: 2.3946, val_MinusLogProbMetric: 2.3946

Epoch 184: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3704 - MinusLogProbMetric: 2.3704 - val_loss: 2.3946 - val_MinusLogProbMetric: 2.3946 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 185/1000
2023-09-11 23:33:44.143 
Epoch 185/1000 
	 loss: 2.3662, MinusLogProbMetric: 2.3662, val_loss: 2.3967, val_MinusLogProbMetric: 2.3967

Epoch 185: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3662 - MinusLogProbMetric: 2.3662 - val_loss: 2.3967 - val_MinusLogProbMetric: 2.3967 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 186/1000
2023-09-11 23:33:56.034 
Epoch 186/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3941, val_MinusLogProbMetric: 2.3941

Epoch 186: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3941 - val_MinusLogProbMetric: 2.3941 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 187/1000
2023-09-11 23:34:08.019 
Epoch 187/1000 
	 loss: 2.3683, MinusLogProbMetric: 2.3683, val_loss: 2.3928, val_MinusLogProbMetric: 2.3928

Epoch 187: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3683 - MinusLogProbMetric: 2.3683 - val_loss: 2.3928 - val_MinusLogProbMetric: 2.3928 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 188/1000
2023-09-11 23:34:19.918 
Epoch 188/1000 
	 loss: 2.3658, MinusLogProbMetric: 2.3658, val_loss: 2.3923, val_MinusLogProbMetric: 2.3923

Epoch 188: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3658 - MinusLogProbMetric: 2.3658 - val_loss: 2.3923 - val_MinusLogProbMetric: 2.3923 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 189/1000
2023-09-11 23:34:31.686 
Epoch 189/1000 
	 loss: 2.3695, MinusLogProbMetric: 2.3695, val_loss: 2.4026, val_MinusLogProbMetric: 2.4026

Epoch 189: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3695 - MinusLogProbMetric: 2.3695 - val_loss: 2.4026 - val_MinusLogProbMetric: 2.4026 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 190/1000
2023-09-11 23:34:43.455 
Epoch 190/1000 
	 loss: 2.3700, MinusLogProbMetric: 2.3700, val_loss: 2.3955, val_MinusLogProbMetric: 2.3955

Epoch 190: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3700 - MinusLogProbMetric: 2.3700 - val_loss: 2.3955 - val_MinusLogProbMetric: 2.3955 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-11 23:34:55.207 
Epoch 191/1000 
	 loss: 2.3695, MinusLogProbMetric: 2.3695, val_loss: 2.3958, val_MinusLogProbMetric: 2.3958

Epoch 191: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3695 - MinusLogProbMetric: 2.3695 - val_loss: 2.3958 - val_MinusLogProbMetric: 2.3958 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 192/1000
2023-09-11 23:35:07.085 
Epoch 192/1000 
	 loss: 2.3677, MinusLogProbMetric: 2.3677, val_loss: 2.4001, val_MinusLogProbMetric: 2.4001

Epoch 192: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3677 - MinusLogProbMetric: 2.3677 - val_loss: 2.4001 - val_MinusLogProbMetric: 2.4001 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 193/1000
2023-09-11 23:35:18.909 
Epoch 193/1000 
	 loss: 2.3693, MinusLogProbMetric: 2.3693, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 193: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3693 - MinusLogProbMetric: 2.3693 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-11 23:35:30.660 
Epoch 194/1000 
	 loss: 2.3667, MinusLogProbMetric: 2.3667, val_loss: 2.3972, val_MinusLogProbMetric: 2.3972

Epoch 194: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3667 - MinusLogProbMetric: 2.3667 - val_loss: 2.3972 - val_MinusLogProbMetric: 2.3972 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 195/1000
2023-09-11 23:35:42.326 
Epoch 195/1000 
	 loss: 2.3670, MinusLogProbMetric: 2.3670, val_loss: 2.4008, val_MinusLogProbMetric: 2.4008

Epoch 195: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3670 - MinusLogProbMetric: 2.3670 - val_loss: 2.4008 - val_MinusLogProbMetric: 2.4008 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-11 23:35:54.116 
Epoch 196/1000 
	 loss: 2.3706, MinusLogProbMetric: 2.3706, val_loss: 2.4019, val_MinusLogProbMetric: 2.4019

Epoch 196: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3706 - MinusLogProbMetric: 2.3706 - val_loss: 2.4019 - val_MinusLogProbMetric: 2.4019 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-11 23:36:05.812 
Epoch 197/1000 
	 loss: 2.3684, MinusLogProbMetric: 2.3684, val_loss: 2.3935, val_MinusLogProbMetric: 2.3935

Epoch 197: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3684 - MinusLogProbMetric: 2.3684 - val_loss: 2.3935 - val_MinusLogProbMetric: 2.3935 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-11 23:36:17.613 
Epoch 198/1000 
	 loss: 2.3697, MinusLogProbMetric: 2.3697, val_loss: 2.3970, val_MinusLogProbMetric: 2.3970

Epoch 198: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3697 - MinusLogProbMetric: 2.3697 - val_loss: 2.3970 - val_MinusLogProbMetric: 2.3970 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 199/1000
2023-09-11 23:36:29.311 
Epoch 199/1000 
	 loss: 2.3674, MinusLogProbMetric: 2.3674, val_loss: 2.4016, val_MinusLogProbMetric: 2.4016

Epoch 199: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3674 - MinusLogProbMetric: 2.3674 - val_loss: 2.4016 - val_MinusLogProbMetric: 2.4016 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-11 23:36:41.097 
Epoch 200/1000 
	 loss: 2.3658, MinusLogProbMetric: 2.3658, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 200: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3658 - MinusLogProbMetric: 2.3658 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-11 23:36:52.776 
Epoch 201/1000 
	 loss: 2.3684, MinusLogProbMetric: 2.3684, val_loss: 2.4088, val_MinusLogProbMetric: 2.4088

Epoch 201: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3684 - MinusLogProbMetric: 2.3684 - val_loss: 2.4088 - val_MinusLogProbMetric: 2.4088 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-11 23:37:04.299 
Epoch 202/1000 
	 loss: 2.3664, MinusLogProbMetric: 2.3664, val_loss: 2.4005, val_MinusLogProbMetric: 2.4005

Epoch 202: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3664 - MinusLogProbMetric: 2.3664 - val_loss: 2.4005 - val_MinusLogProbMetric: 2.4005 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 203/1000
2023-09-11 23:37:15.705 
Epoch 203/1000 
	 loss: 2.3665, MinusLogProbMetric: 2.3665, val_loss: 2.3921, val_MinusLogProbMetric: 2.3921

Epoch 203: val_loss did not improve from 2.39157
196/196 - 11s - loss: 2.3665 - MinusLogProbMetric: 2.3665 - val_loss: 2.3921 - val_MinusLogProbMetric: 2.3921 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 204/1000
2023-09-11 23:37:27.252 
Epoch 204/1000 
	 loss: 2.3687, MinusLogProbMetric: 2.3687, val_loss: 2.3945, val_MinusLogProbMetric: 2.3945

Epoch 204: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3687 - MinusLogProbMetric: 2.3687 - val_loss: 2.3945 - val_MinusLogProbMetric: 2.3945 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 205/1000
2023-09-11 23:37:38.749 
Epoch 205/1000 
	 loss: 2.3689, MinusLogProbMetric: 2.3689, val_loss: 2.3991, val_MinusLogProbMetric: 2.3991

Epoch 205: val_loss did not improve from 2.39157
196/196 - 11s - loss: 2.3689 - MinusLogProbMetric: 2.3689 - val_loss: 2.3991 - val_MinusLogProbMetric: 2.3991 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 206/1000
2023-09-11 23:37:50.351 
Epoch 206/1000 
	 loss: 2.3685, MinusLogProbMetric: 2.3685, val_loss: 2.3996, val_MinusLogProbMetric: 2.3996

Epoch 206: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3685 - MinusLogProbMetric: 2.3685 - val_loss: 2.3996 - val_MinusLogProbMetric: 2.3996 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-11 23:38:02.292 
Epoch 207/1000 
	 loss: 2.3679, MinusLogProbMetric: 2.3679, val_loss: 2.4040, val_MinusLogProbMetric: 2.4040

Epoch 207: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3679 - MinusLogProbMetric: 2.3679 - val_loss: 2.4040 - val_MinusLogProbMetric: 2.4040 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 208/1000
2023-09-11 23:38:13.845 
Epoch 208/1000 
	 loss: 2.3686, MinusLogProbMetric: 2.3686, val_loss: 2.3966, val_MinusLogProbMetric: 2.3966

Epoch 208: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3686 - MinusLogProbMetric: 2.3686 - val_loss: 2.3966 - val_MinusLogProbMetric: 2.3966 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 209/1000
2023-09-11 23:38:25.567 
Epoch 209/1000 
	 loss: 2.3703, MinusLogProbMetric: 2.3703, val_loss: 2.4147, val_MinusLogProbMetric: 2.4147

Epoch 209: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3703 - MinusLogProbMetric: 2.3703 - val_loss: 2.4147 - val_MinusLogProbMetric: 2.4147 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 210/1000
2023-09-11 23:38:37.277 
Epoch 210/1000 
	 loss: 2.3684, MinusLogProbMetric: 2.3684, val_loss: 2.4011, val_MinusLogProbMetric: 2.4011

Epoch 210: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3684 - MinusLogProbMetric: 2.3684 - val_loss: 2.4011 - val_MinusLogProbMetric: 2.4011 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 211/1000
2023-09-11 23:38:48.976 
Epoch 211/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3956, val_MinusLogProbMetric: 2.3956

Epoch 211: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3956 - val_MinusLogProbMetric: 2.3956 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 212/1000
2023-09-11 23:39:00.767 
Epoch 212/1000 
	 loss: 2.3669, MinusLogProbMetric: 2.3669, val_loss: 2.3932, val_MinusLogProbMetric: 2.3932

Epoch 212: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3669 - MinusLogProbMetric: 2.3669 - val_loss: 2.3932 - val_MinusLogProbMetric: 2.3932 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 213/1000
2023-09-11 23:39:12.444 
Epoch 213/1000 
	 loss: 2.3663, MinusLogProbMetric: 2.3663, val_loss: 2.3963, val_MinusLogProbMetric: 2.3963

Epoch 213: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3663 - MinusLogProbMetric: 2.3663 - val_loss: 2.3963 - val_MinusLogProbMetric: 2.3963 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 214/1000
2023-09-11 23:39:24.163 
Epoch 214/1000 
	 loss: 2.3655, MinusLogProbMetric: 2.3655, val_loss: 2.4060, val_MinusLogProbMetric: 2.4060

Epoch 214: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3655 - MinusLogProbMetric: 2.3655 - val_loss: 2.4060 - val_MinusLogProbMetric: 2.4060 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-11 23:39:35.884 
Epoch 215/1000 
	 loss: 2.3674, MinusLogProbMetric: 2.3674, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 215: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3674 - MinusLogProbMetric: 2.3674 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 216/1000
2023-09-11 23:39:47.530 
Epoch 216/1000 
	 loss: 2.3660, MinusLogProbMetric: 2.3660, val_loss: 2.3934, val_MinusLogProbMetric: 2.3934

Epoch 216: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3660 - MinusLogProbMetric: 2.3660 - val_loss: 2.3934 - val_MinusLogProbMetric: 2.3934 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 217/1000
2023-09-11 23:39:59.271 
Epoch 217/1000 
	 loss: 2.3646, MinusLogProbMetric: 2.3646, val_loss: 2.4001, val_MinusLogProbMetric: 2.4001

Epoch 217: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3646 - MinusLogProbMetric: 2.3646 - val_loss: 2.4001 - val_MinusLogProbMetric: 2.4001 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 218/1000
2023-09-11 23:40:10.974 
Epoch 218/1000 
	 loss: 2.3681, MinusLogProbMetric: 2.3681, val_loss: 2.4013, val_MinusLogProbMetric: 2.4013

Epoch 218: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3681 - MinusLogProbMetric: 2.3681 - val_loss: 2.4013 - val_MinusLogProbMetric: 2.4013 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-11 23:40:22.601 
Epoch 219/1000 
	 loss: 2.3678, MinusLogProbMetric: 2.3678, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 219: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3678 - MinusLogProbMetric: 2.3678 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 220/1000
2023-09-11 23:40:34.284 
Epoch 220/1000 
	 loss: 2.3643, MinusLogProbMetric: 2.3643, val_loss: 2.3952, val_MinusLogProbMetric: 2.3952

Epoch 220: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3643 - MinusLogProbMetric: 2.3643 - val_loss: 2.3952 - val_MinusLogProbMetric: 2.3952 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 221/1000
2023-09-11 23:40:46.131 
Epoch 221/1000 
	 loss: 2.3609, MinusLogProbMetric: 2.3609, val_loss: 2.3980, val_MinusLogProbMetric: 2.3980

Epoch 221: val_loss did not improve from 2.39157
196/196 - 12s - loss: 2.3609 - MinusLogProbMetric: 2.3609 - val_loss: 2.3980 - val_MinusLogProbMetric: 2.3980 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-11 23:40:57.857 
Epoch 222/1000 
	 loss: 2.3600, MinusLogProbMetric: 2.3600, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 222: val_loss improved from 2.39157 to 2.38934, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3600 - MinusLogProbMetric: 2.3600 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-11 23:41:09.662 
Epoch 223/1000 
	 loss: 2.3609, MinusLogProbMetric: 2.3609, val_loss: 2.3931, val_MinusLogProbMetric: 2.3931

Epoch 223: val_loss did not improve from 2.38934
196/196 - 12s - loss: 2.3609 - MinusLogProbMetric: 2.3609 - val_loss: 2.3931 - val_MinusLogProbMetric: 2.3931 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 224/1000
2023-09-11 23:41:21.402 
Epoch 224/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 224: val_loss did not improve from 2.38934
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-11 23:41:33.079 
Epoch 225/1000 
	 loss: 2.3614, MinusLogProbMetric: 2.3614, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 225: val_loss improved from 2.38934 to 2.38878, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3614 - MinusLogProbMetric: 2.3614 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-11 23:41:44.846 
Epoch 226/1000 
	 loss: 2.3603, MinusLogProbMetric: 2.3603, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 226: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3603 - MinusLogProbMetric: 2.3603 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 227/1000
2023-09-11 23:41:56.423 
Epoch 227/1000 
	 loss: 2.3597, MinusLogProbMetric: 2.3597, val_loss: 2.3934, val_MinusLogProbMetric: 2.3934

Epoch 227: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3597 - MinusLogProbMetric: 2.3597 - val_loss: 2.3934 - val_MinusLogProbMetric: 2.3934 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-11 23:42:08.164 
Epoch 228/1000 
	 loss: 2.3620, MinusLogProbMetric: 2.3620, val_loss: 2.3917, val_MinusLogProbMetric: 2.3917

Epoch 228: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3620 - MinusLogProbMetric: 2.3620 - val_loss: 2.3917 - val_MinusLogProbMetric: 2.3917 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 229/1000
2023-09-11 23:42:19.886 
Epoch 229/1000 
	 loss: 2.3604, MinusLogProbMetric: 2.3604, val_loss: 2.4012, val_MinusLogProbMetric: 2.4012

Epoch 229: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3604 - MinusLogProbMetric: 2.3604 - val_loss: 2.4012 - val_MinusLogProbMetric: 2.4012 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-11 23:42:31.703 
Epoch 230/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3924, val_MinusLogProbMetric: 2.3924

Epoch 230: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3924 - val_MinusLogProbMetric: 2.3924 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 231/1000
2023-09-11 23:42:43.374 
Epoch 231/1000 
	 loss: 2.3606, MinusLogProbMetric: 2.3606, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 231: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3606 - MinusLogProbMetric: 2.3606 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 232/1000
2023-09-11 23:42:55.131 
Epoch 232/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 232: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 233/1000
2023-09-11 23:43:06.807 
Epoch 233/1000 
	 loss: 2.3623, MinusLogProbMetric: 2.3623, val_loss: 2.3897, val_MinusLogProbMetric: 2.3897

Epoch 233: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3623 - MinusLogProbMetric: 2.3623 - val_loss: 2.3897 - val_MinusLogProbMetric: 2.3897 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 234/1000
2023-09-11 23:43:18.466 
Epoch 234/1000 
	 loss: 2.3603, MinusLogProbMetric: 2.3603, val_loss: 2.3908, val_MinusLogProbMetric: 2.3908

Epoch 234: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3603 - MinusLogProbMetric: 2.3603 - val_loss: 2.3908 - val_MinusLogProbMetric: 2.3908 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 235/1000
2023-09-11 23:43:29.996 
Epoch 235/1000 
	 loss: 2.3603, MinusLogProbMetric: 2.3603, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 235: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3603 - MinusLogProbMetric: 2.3603 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 236/1000
2023-09-11 23:43:41.678 
Epoch 236/1000 
	 loss: 2.3603, MinusLogProbMetric: 2.3603, val_loss: 2.3912, val_MinusLogProbMetric: 2.3912

Epoch 236: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3603 - MinusLogProbMetric: 2.3603 - val_loss: 2.3912 - val_MinusLogProbMetric: 2.3912 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 237/1000
2023-09-11 23:43:53.285 
Epoch 237/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3949, val_MinusLogProbMetric: 2.3949

Epoch 237: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3949 - val_MinusLogProbMetric: 2.3949 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 238/1000
2023-09-11 23:44:04.983 
Epoch 238/1000 
	 loss: 2.3612, MinusLogProbMetric: 2.3612, val_loss: 2.3924, val_MinusLogProbMetric: 2.3924

Epoch 238: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3612 - MinusLogProbMetric: 2.3612 - val_loss: 2.3924 - val_MinusLogProbMetric: 2.3924 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-11 23:44:16.588 
Epoch 239/1000 
	 loss: 2.3604, MinusLogProbMetric: 2.3604, val_loss: 2.3959, val_MinusLogProbMetric: 2.3959

Epoch 239: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3604 - MinusLogProbMetric: 2.3604 - val_loss: 2.3959 - val_MinusLogProbMetric: 2.3959 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 240/1000
2023-09-11 23:44:28.204 
Epoch 240/1000 
	 loss: 2.3612, MinusLogProbMetric: 2.3612, val_loss: 2.3935, val_MinusLogProbMetric: 2.3935

Epoch 240: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3612 - MinusLogProbMetric: 2.3612 - val_loss: 2.3935 - val_MinusLogProbMetric: 2.3935 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 241/1000
2023-09-11 23:44:39.858 
Epoch 241/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3968, val_MinusLogProbMetric: 2.3968

Epoch 241: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3968 - val_MinusLogProbMetric: 2.3968 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 242/1000
2023-09-11 23:44:51.416 
Epoch 242/1000 
	 loss: 2.3606, MinusLogProbMetric: 2.3606, val_loss: 2.3923, val_MinusLogProbMetric: 2.3923

Epoch 242: val_loss did not improve from 2.38878
196/196 - 12s - loss: 2.3606 - MinusLogProbMetric: 2.3606 - val_loss: 2.3923 - val_MinusLogProbMetric: 2.3923 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 243/1000
2023-09-11 23:45:03.058 
Epoch 243/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 243: val_loss improved from 2.38878 to 2.38830, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 244/1000
2023-09-11 23:45:14.808 
Epoch 244/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3933, val_MinusLogProbMetric: 2.3933

Epoch 244: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3933 - val_MinusLogProbMetric: 2.3933 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 245/1000
2023-09-11 23:45:26.464 
Epoch 245/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3992, val_MinusLogProbMetric: 2.3992

Epoch 245: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3992 - val_MinusLogProbMetric: 2.3992 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 246/1000
2023-09-11 23:45:38.124 
Epoch 246/1000 
	 loss: 2.3607, MinusLogProbMetric: 2.3607, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 246: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3607 - MinusLogProbMetric: 2.3607 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 247/1000
2023-09-11 23:45:49.711 
Epoch 247/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3934, val_MinusLogProbMetric: 2.3934

Epoch 247: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3934 - val_MinusLogProbMetric: 2.3934 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 248/1000
2023-09-11 23:46:01.344 
Epoch 248/1000 
	 loss: 2.3603, MinusLogProbMetric: 2.3603, val_loss: 2.3890, val_MinusLogProbMetric: 2.3890

Epoch 248: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3603 - MinusLogProbMetric: 2.3603 - val_loss: 2.3890 - val_MinusLogProbMetric: 2.3890 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 249/1000
2023-09-11 23:46:13.093 
Epoch 249/1000 
	 loss: 2.3609, MinusLogProbMetric: 2.3609, val_loss: 2.3920, val_MinusLogProbMetric: 2.3920

Epoch 249: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3609 - MinusLogProbMetric: 2.3609 - val_loss: 2.3920 - val_MinusLogProbMetric: 2.3920 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 250/1000
2023-09-11 23:46:24.856 
Epoch 250/1000 
	 loss: 2.3607, MinusLogProbMetric: 2.3607, val_loss: 2.3914, val_MinusLogProbMetric: 2.3914

Epoch 250: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3607 - MinusLogProbMetric: 2.3607 - val_loss: 2.3914 - val_MinusLogProbMetric: 2.3914 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-11 23:46:36.586 
Epoch 251/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3913, val_MinusLogProbMetric: 2.3913

Epoch 251: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3913 - val_MinusLogProbMetric: 2.3913 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 252/1000
2023-09-11 23:46:48.216 
Epoch 252/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3920, val_MinusLogProbMetric: 2.3920

Epoch 252: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3920 - val_MinusLogProbMetric: 2.3920 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 253/1000
2023-09-11 23:46:59.754 
Epoch 253/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 253: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 254/1000
2023-09-11 23:47:11.620 
Epoch 254/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 254: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 255/1000
2023-09-11 23:47:23.351 
Epoch 255/1000 
	 loss: 2.3606, MinusLogProbMetric: 2.3606, val_loss: 2.3964, val_MinusLogProbMetric: 2.3964

Epoch 255: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3606 - MinusLogProbMetric: 2.3606 - val_loss: 2.3964 - val_MinusLogProbMetric: 2.3964 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 256/1000
2023-09-11 23:47:35.114 
Epoch 256/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3902, val_MinusLogProbMetric: 2.3902

Epoch 256: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3902 - val_MinusLogProbMetric: 2.3902 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 257/1000
2023-09-11 23:47:46.853 
Epoch 257/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 257: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-11 23:47:58.484 
Epoch 258/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 258: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 259/1000
2023-09-11 23:48:10.094 
Epoch 259/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3924, val_MinusLogProbMetric: 2.3924

Epoch 259: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3924 - val_MinusLogProbMetric: 2.3924 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 260/1000
2023-09-11 23:48:21.708 
Epoch 260/1000 
	 loss: 2.3597, MinusLogProbMetric: 2.3597, val_loss: 2.4037, val_MinusLogProbMetric: 2.4037

Epoch 260: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3597 - MinusLogProbMetric: 2.3597 - val_loss: 2.4037 - val_MinusLogProbMetric: 2.4037 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 261/1000
2023-09-11 23:48:33.362 
Epoch 261/1000 
	 loss: 2.3601, MinusLogProbMetric: 2.3601, val_loss: 2.3906, val_MinusLogProbMetric: 2.3906

Epoch 261: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3601 - MinusLogProbMetric: 2.3601 - val_loss: 2.3906 - val_MinusLogProbMetric: 2.3906 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 262/1000
2023-09-11 23:48:45.114 
Epoch 262/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3910, val_MinusLogProbMetric: 2.3910

Epoch 262: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3910 - val_MinusLogProbMetric: 2.3910 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-11 23:48:56.742 
Epoch 263/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3916, val_MinusLogProbMetric: 2.3916

Epoch 263: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3916 - val_MinusLogProbMetric: 2.3916 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 264/1000
2023-09-11 23:49:08.428 
Epoch 264/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3902, val_MinusLogProbMetric: 2.3902

Epoch 264: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3902 - val_MinusLogProbMetric: 2.3902 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 265/1000
2023-09-11 23:49:20.089 
Epoch 265/1000 
	 loss: 2.3601, MinusLogProbMetric: 2.3601, val_loss: 2.3914, val_MinusLogProbMetric: 2.3914

Epoch 265: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3601 - MinusLogProbMetric: 2.3601 - val_loss: 2.3914 - val_MinusLogProbMetric: 2.3914 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 266/1000
2023-09-11 23:49:31.869 
Epoch 266/1000 
	 loss: 2.3592, MinusLogProbMetric: 2.3592, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 266: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3592 - MinusLogProbMetric: 2.3592 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 267/1000
2023-09-11 23:49:43.562 
Epoch 267/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3895, val_MinusLogProbMetric: 2.3895

Epoch 267: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3895 - val_MinusLogProbMetric: 2.3895 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 268/1000
2023-09-11 23:49:55.366 
Epoch 268/1000 
	 loss: 2.3596, MinusLogProbMetric: 2.3596, val_loss: 2.3947, val_MinusLogProbMetric: 2.3947

Epoch 268: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3596 - MinusLogProbMetric: 2.3596 - val_loss: 2.3947 - val_MinusLogProbMetric: 2.3947 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-11 23:50:07.071 
Epoch 269/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3914, val_MinusLogProbMetric: 2.3914

Epoch 269: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3914 - val_MinusLogProbMetric: 2.3914 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 270/1000
2023-09-11 23:50:18.775 
Epoch 270/1000 
	 loss: 2.3604, MinusLogProbMetric: 2.3604, val_loss: 2.3916, val_MinusLogProbMetric: 2.3916

Epoch 270: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3604 - MinusLogProbMetric: 2.3604 - val_loss: 2.3916 - val_MinusLogProbMetric: 2.3916 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 271/1000
2023-09-11 23:50:30.484 
Epoch 271/1000 
	 loss: 2.3593, MinusLogProbMetric: 2.3593, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 271: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3593 - MinusLogProbMetric: 2.3593 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-11 23:50:42.201 
Epoch 272/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3939, val_MinusLogProbMetric: 2.3939

Epoch 272: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3939 - val_MinusLogProbMetric: 2.3939 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 273/1000
2023-09-11 23:50:53.924 
Epoch 273/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3920, val_MinusLogProbMetric: 2.3920

Epoch 273: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3920 - val_MinusLogProbMetric: 2.3920 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 274/1000
2023-09-11 23:51:05.541 
Epoch 274/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3954, val_MinusLogProbMetric: 2.3954

Epoch 274: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3954 - val_MinusLogProbMetric: 2.3954 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 275/1000
2023-09-11 23:51:17.255 
Epoch 275/1000 
	 loss: 2.3610, MinusLogProbMetric: 2.3610, val_loss: 2.3900, val_MinusLogProbMetric: 2.3900

Epoch 275: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3610 - MinusLogProbMetric: 2.3610 - val_loss: 2.3900 - val_MinusLogProbMetric: 2.3900 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 276/1000
2023-09-11 23:51:28.811 
Epoch 276/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 276: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 277/1000
2023-09-11 23:51:40.579 
Epoch 277/1000 
	 loss: 2.3594, MinusLogProbMetric: 2.3594, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 277: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3594 - MinusLogProbMetric: 2.3594 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 278/1000
2023-09-11 23:51:52.303 
Epoch 278/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3910, val_MinusLogProbMetric: 2.3910

Epoch 278: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3910 - val_MinusLogProbMetric: 2.3910 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 279/1000
2023-09-11 23:52:04.162 
Epoch 279/1000 
	 loss: 2.3589, MinusLogProbMetric: 2.3589, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 279: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3589 - MinusLogProbMetric: 2.3589 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 280/1000
2023-09-11 23:52:15.875 
Epoch 280/1000 
	 loss: 2.3599, MinusLogProbMetric: 2.3599, val_loss: 2.3945, val_MinusLogProbMetric: 2.3945

Epoch 280: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3599 - MinusLogProbMetric: 2.3599 - val_loss: 2.3945 - val_MinusLogProbMetric: 2.3945 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-11 23:52:27.459 
Epoch 281/1000 
	 loss: 2.3617, MinusLogProbMetric: 2.3617, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 281: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3617 - MinusLogProbMetric: 2.3617 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 282/1000
2023-09-11 23:52:39.266 
Epoch 282/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3889, val_MinusLogProbMetric: 2.3889

Epoch 282: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3889 - val_MinusLogProbMetric: 2.3889 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 283/1000
2023-09-11 23:52:51.002 
Epoch 283/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3951, val_MinusLogProbMetric: 2.3951

Epoch 283: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3951 - val_MinusLogProbMetric: 2.3951 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-11 23:53:02.604 
Epoch 284/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 284: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 285/1000
2023-09-11 23:53:14.473 
Epoch 285/1000 
	 loss: 2.3586, MinusLogProbMetric: 2.3586, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 285: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3586 - MinusLogProbMetric: 2.3586 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 286/1000
2023-09-11 23:53:26.170 
Epoch 286/1000 
	 loss: 2.3597, MinusLogProbMetric: 2.3597, val_loss: 2.3945, val_MinusLogProbMetric: 2.3945

Epoch 286: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3597 - MinusLogProbMetric: 2.3597 - val_loss: 2.3945 - val_MinusLogProbMetric: 2.3945 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 287/1000
2023-09-11 23:53:37.868 
Epoch 287/1000 
	 loss: 2.3587, MinusLogProbMetric: 2.3587, val_loss: 2.3946, val_MinusLogProbMetric: 2.3946

Epoch 287: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3587 - MinusLogProbMetric: 2.3587 - val_loss: 2.3946 - val_MinusLogProbMetric: 2.3946 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 288/1000
2023-09-11 23:53:49.602 
Epoch 288/1000 
	 loss: 2.3598, MinusLogProbMetric: 2.3598, val_loss: 2.3944, val_MinusLogProbMetric: 2.3944

Epoch 288: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3598 - MinusLogProbMetric: 2.3598 - val_loss: 2.3944 - val_MinusLogProbMetric: 2.3944 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 289/1000
2023-09-11 23:54:01.197 
Epoch 289/1000 
	 loss: 2.3590, MinusLogProbMetric: 2.3590, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 289: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3590 - MinusLogProbMetric: 2.3590 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 290/1000
2023-09-11 23:54:12.976 
Epoch 290/1000 
	 loss: 2.3591, MinusLogProbMetric: 2.3591, val_loss: 2.3899, val_MinusLogProbMetric: 2.3899

Epoch 290: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3591 - MinusLogProbMetric: 2.3591 - val_loss: 2.3899 - val_MinusLogProbMetric: 2.3899 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 291/1000
2023-09-11 23:54:24.664 
Epoch 291/1000 
	 loss: 2.3609, MinusLogProbMetric: 2.3609, val_loss: 2.3927, val_MinusLogProbMetric: 2.3927

Epoch 291: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3609 - MinusLogProbMetric: 2.3609 - val_loss: 2.3927 - val_MinusLogProbMetric: 2.3927 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 292/1000
2023-09-11 23:54:36.393 
Epoch 292/1000 
	 loss: 2.3595, MinusLogProbMetric: 2.3595, val_loss: 2.3924, val_MinusLogProbMetric: 2.3924

Epoch 292: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3595 - MinusLogProbMetric: 2.3595 - val_loss: 2.3924 - val_MinusLogProbMetric: 2.3924 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 293/1000
2023-09-11 23:54:48.098 
Epoch 293/1000 
	 loss: 2.3602, MinusLogProbMetric: 2.3602, val_loss: 2.3895, val_MinusLogProbMetric: 2.3895

Epoch 293: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3602 - MinusLogProbMetric: 2.3602 - val_loss: 2.3895 - val_MinusLogProbMetric: 2.3895 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 294/1000
2023-09-11 23:54:59.815 
Epoch 294/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 294: val_loss did not improve from 2.38830
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 295/1000
2023-09-11 23:55:11.525 
Epoch 295/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 295: val_loss improved from 2.38830 to 2.38797, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 296/1000
2023-09-11 23:55:23.561 
Epoch 296/1000 
	 loss: 2.3568, MinusLogProbMetric: 2.3568, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 296: val_loss improved from 2.38797 to 2.38772, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3568 - MinusLogProbMetric: 2.3568 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 297/1000
2023-09-11 23:55:35.373 
Epoch 297/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3902, val_MinusLogProbMetric: 2.3902

Epoch 297: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3902 - val_MinusLogProbMetric: 2.3902 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 298/1000
2023-09-11 23:55:47.113 
Epoch 298/1000 
	 loss: 2.3566, MinusLogProbMetric: 2.3566, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 298: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3566 - MinusLogProbMetric: 2.3566 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 299/1000
2023-09-11 23:55:58.848 
Epoch 299/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 299: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 300/1000
2023-09-11 23:56:10.527 
Epoch 300/1000 
	 loss: 2.3567, MinusLogProbMetric: 2.3567, val_loss: 2.3909, val_MinusLogProbMetric: 2.3909

Epoch 300: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3567 - MinusLogProbMetric: 2.3567 - val_loss: 2.3909 - val_MinusLogProbMetric: 2.3909 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 301/1000
2023-09-11 23:56:22.350 
Epoch 301/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 301: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 302/1000
2023-09-11 23:56:34.131 
Epoch 302/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3899, val_MinusLogProbMetric: 2.3899

Epoch 302: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3899 - val_MinusLogProbMetric: 2.3899 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 303/1000
2023-09-11 23:56:45.841 
Epoch 303/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 303: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 304/1000
2023-09-11 23:56:57.509 
Epoch 304/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3909, val_MinusLogProbMetric: 2.3909

Epoch 304: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3909 - val_MinusLogProbMetric: 2.3909 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 305/1000
2023-09-11 23:57:09.155 
Epoch 305/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 305: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 306/1000
2023-09-11 23:57:20.893 
Epoch 306/1000 
	 loss: 2.3553, MinusLogProbMetric: 2.3553, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 306: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3553 - MinusLogProbMetric: 2.3553 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 307/1000
2023-09-11 23:57:32.559 
Epoch 307/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 307: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 308/1000
2023-09-11 23:57:44.018 
Epoch 308/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 308: val_loss did not improve from 2.38772
196/196 - 11s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 309/1000
2023-09-11 23:57:55.718 
Epoch 309/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 309: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 310/1000
2023-09-11 23:58:07.462 
Epoch 310/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3889, val_MinusLogProbMetric: 2.3889

Epoch 310: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3889 - val_MinusLogProbMetric: 2.3889 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 311/1000
2023-09-11 23:58:19.144 
Epoch 311/1000 
	 loss: 2.3563, MinusLogProbMetric: 2.3563, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 311: val_loss did not improve from 2.38772
196/196 - 12s - loss: 2.3563 - MinusLogProbMetric: 2.3563 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 312/1000
2023-09-11 23:58:30.797 
Epoch 312/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 312: val_loss improved from 2.38772 to 2.38745, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 313/1000
2023-09-11 23:58:42.594 
Epoch 313/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 313: val_loss did not improve from 2.38745
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 314/1000
2023-09-11 23:58:54.321 
Epoch 314/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 314: val_loss did not improve from 2.38745
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 315/1000
2023-09-11 23:59:05.983 
Epoch 315/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 315: val_loss improved from 2.38745 to 2.38739, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-11 23:59:17.752 
Epoch 316/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3915, val_MinusLogProbMetric: 2.3915

Epoch 316: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3915 - val_MinusLogProbMetric: 2.3915 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 317/1000
2023-09-11 23:59:29.369 
Epoch 317/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 317: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 318/1000
2023-09-11 23:59:41.169 
Epoch 318/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3911, val_MinusLogProbMetric: 2.3911

Epoch 318: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3911 - val_MinusLogProbMetric: 2.3911 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 319/1000
2023-09-11 23:59:52.794 
Epoch 319/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 319: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 320/1000
2023-09-12 00:00:04.552 
Epoch 320/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 320: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 321/1000
2023-09-12 00:00:16.231 
Epoch 321/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 321: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 322/1000
2023-09-12 00:00:27.971 
Epoch 322/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 322: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 323/1000
2023-09-12 00:00:39.587 
Epoch 323/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3928, val_MinusLogProbMetric: 2.3928

Epoch 323: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3928 - val_MinusLogProbMetric: 2.3928 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 324/1000
2023-09-12 00:00:51.273 
Epoch 324/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 324: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 325/1000
2023-09-12 00:01:02.837 
Epoch 325/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 325: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 326/1000
2023-09-12 00:01:14.614 
Epoch 326/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 326: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-12 00:01:26.375 
Epoch 327/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3887, val_MinusLogProbMetric: 2.3887

Epoch 327: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3887 - val_MinusLogProbMetric: 2.3887 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 328/1000
2023-09-12 00:01:38.029 
Epoch 328/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 328: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 329/1000
2023-09-12 00:01:49.768 
Epoch 329/1000 
	 loss: 2.3560, MinusLogProbMetric: 2.3560, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 329: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3560 - MinusLogProbMetric: 2.3560 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 330/1000
2023-09-12 00:02:01.467 
Epoch 330/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3897, val_MinusLogProbMetric: 2.3897

Epoch 330: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3897 - val_MinusLogProbMetric: 2.3897 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 331/1000
2023-09-12 00:02:13.086 
Epoch 331/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 331: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 332/1000
2023-09-12 00:02:24.877 
Epoch 332/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 332: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 333/1000
2023-09-12 00:02:36.691 
Epoch 333/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 333: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 334/1000
2023-09-12 00:02:48.257 
Epoch 334/1000 
	 loss: 2.3557, MinusLogProbMetric: 2.3557, val_loss: 2.3900, val_MinusLogProbMetric: 2.3900

Epoch 334: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3557 - MinusLogProbMetric: 2.3557 - val_loss: 2.3900 - val_MinusLogProbMetric: 2.3900 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 335/1000
2023-09-12 00:02:59.867 
Epoch 335/1000 
	 loss: 2.3561, MinusLogProbMetric: 2.3561, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 335: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3561 - MinusLogProbMetric: 2.3561 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 336/1000
2023-09-12 00:03:11.626 
Epoch 336/1000 
	 loss: 2.3553, MinusLogProbMetric: 2.3553, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 336: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3553 - MinusLogProbMetric: 2.3553 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 337/1000
2023-09-12 00:03:23.399 
Epoch 337/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3925, val_MinusLogProbMetric: 2.3925

Epoch 337: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3925 - val_MinusLogProbMetric: 2.3925 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 338/1000
2023-09-12 00:03:34.953 
Epoch 338/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 338: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 339/1000
2023-09-12 00:03:46.619 
Epoch 339/1000 
	 loss: 2.3553, MinusLogProbMetric: 2.3553, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 339: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3553 - MinusLogProbMetric: 2.3553 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 340/1000
2023-09-12 00:03:58.217 
Epoch 340/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 340: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 341/1000
2023-09-12 00:04:09.867 
Epoch 341/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 341: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 342/1000
2023-09-12 00:04:21.637 
Epoch 342/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3878, val_MinusLogProbMetric: 2.3878

Epoch 342: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3878 - val_MinusLogProbMetric: 2.3878 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-12 00:04:33.433 
Epoch 343/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 343: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 344/1000
2023-09-12 00:04:44.992 
Epoch 344/1000 
	 loss: 2.3548, MinusLogProbMetric: 2.3548, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 344: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3548 - MinusLogProbMetric: 2.3548 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 345/1000
2023-09-12 00:04:56.761 
Epoch 345/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 345: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 346/1000
2023-09-12 00:05:08.497 
Epoch 346/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 346: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 347/1000
2023-09-12 00:05:20.168 
Epoch 347/1000 
	 loss: 2.3553, MinusLogProbMetric: 2.3553, val_loss: 2.3924, val_MinusLogProbMetric: 2.3924

Epoch 347: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3553 - MinusLogProbMetric: 2.3553 - val_loss: 2.3924 - val_MinusLogProbMetric: 2.3924 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 348/1000
2023-09-12 00:05:31.858 
Epoch 348/1000 
	 loss: 2.3552, MinusLogProbMetric: 2.3552, val_loss: 2.3895, val_MinusLogProbMetric: 2.3895

Epoch 348: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3552 - MinusLogProbMetric: 2.3552 - val_loss: 2.3895 - val_MinusLogProbMetric: 2.3895 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 349/1000
2023-09-12 00:05:43.677 
Epoch 349/1000 
	 loss: 2.3562, MinusLogProbMetric: 2.3562, val_loss: 2.3969, val_MinusLogProbMetric: 2.3969

Epoch 349: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3562 - MinusLogProbMetric: 2.3562 - val_loss: 2.3969 - val_MinusLogProbMetric: 2.3969 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 350/1000
2023-09-12 00:05:55.512 
Epoch 350/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3959, val_MinusLogProbMetric: 2.3959

Epoch 350: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3959 - val_MinusLogProbMetric: 2.3959 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 351/1000
2023-09-12 00:06:07.302 
Epoch 351/1000 
	 loss: 2.3555, MinusLogProbMetric: 2.3555, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 351: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3555 - MinusLogProbMetric: 2.3555 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 352/1000
2023-09-12 00:06:19.025 
Epoch 352/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3900, val_MinusLogProbMetric: 2.3900

Epoch 352: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3900 - val_MinusLogProbMetric: 2.3900 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 353/1000
2023-09-12 00:06:30.615 
Epoch 353/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3921, val_MinusLogProbMetric: 2.3921

Epoch 353: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3921 - val_MinusLogProbMetric: 2.3921 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 354/1000
2023-09-12 00:06:42.459 
Epoch 354/1000 
	 loss: 2.3559, MinusLogProbMetric: 2.3559, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 354: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3559 - MinusLogProbMetric: 2.3559 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 355/1000
2023-09-12 00:06:54.121 
Epoch 355/1000 
	 loss: 2.3554, MinusLogProbMetric: 2.3554, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 355: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3554 - MinusLogProbMetric: 2.3554 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 356/1000
2023-09-12 00:07:05.955 
Epoch 356/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3914, val_MinusLogProbMetric: 2.3914

Epoch 356: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3914 - val_MinusLogProbMetric: 2.3914 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 357/1000
2023-09-12 00:07:17.597 
Epoch 357/1000 
	 loss: 2.3556, MinusLogProbMetric: 2.3556, val_loss: 2.3915, val_MinusLogProbMetric: 2.3915

Epoch 357: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3556 - MinusLogProbMetric: 2.3556 - val_loss: 2.3915 - val_MinusLogProbMetric: 2.3915 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 358/1000
2023-09-12 00:07:29.288 
Epoch 358/1000 
	 loss: 2.3553, MinusLogProbMetric: 2.3553, val_loss: 2.3905, val_MinusLogProbMetric: 2.3905

Epoch 358: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3553 - MinusLogProbMetric: 2.3553 - val_loss: 2.3905 - val_MinusLogProbMetric: 2.3905 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 359/1000
2023-09-12 00:07:40.960 
Epoch 359/1000 
	 loss: 2.3549, MinusLogProbMetric: 2.3549, val_loss: 2.3895, val_MinusLogProbMetric: 2.3895

Epoch 359: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3549 - MinusLogProbMetric: 2.3549 - val_loss: 2.3895 - val_MinusLogProbMetric: 2.3895 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 360/1000
2023-09-12 00:07:52.697 
Epoch 360/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 360: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 361/1000
2023-09-12 00:08:04.305 
Epoch 361/1000 
	 loss: 2.3558, MinusLogProbMetric: 2.3558, val_loss: 2.3925, val_MinusLogProbMetric: 2.3925

Epoch 361: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3558 - MinusLogProbMetric: 2.3558 - val_loss: 2.3925 - val_MinusLogProbMetric: 2.3925 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 362/1000
2023-09-12 00:08:15.974 
Epoch 362/1000 
	 loss: 2.3551, MinusLogProbMetric: 2.3551, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 362: val_loss did not improve from 2.38739
196/196 - 12s - loss: 2.3551 - MinusLogProbMetric: 2.3551 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 363/1000
2023-09-12 00:08:27.738 
Epoch 363/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3873, val_MinusLogProbMetric: 2.3873

Epoch 363: val_loss improved from 2.38739 to 2.38735, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3873 - val_MinusLogProbMetric: 2.3873 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 364/1000
2023-09-12 00:08:39.514 
Epoch 364/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 364: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 365/1000
2023-09-12 00:08:51.347 
Epoch 365/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3890, val_MinusLogProbMetric: 2.3890

Epoch 365: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3890 - val_MinusLogProbMetric: 2.3890 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 366/1000
2023-09-12 00:09:03.142 
Epoch 366/1000 
	 loss: 2.3538, MinusLogProbMetric: 2.3538, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 366: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3538 - MinusLogProbMetric: 2.3538 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 367/1000
2023-09-12 00:09:14.785 
Epoch 367/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 367: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 368/1000
2023-09-12 00:09:26.541 
Epoch 368/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3898, val_MinusLogProbMetric: 2.3898

Epoch 368: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3898 - val_MinusLogProbMetric: 2.3898 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 369/1000
2023-09-12 00:09:38.238 
Epoch 369/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 369: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 370/1000
2023-09-12 00:09:49.923 
Epoch 370/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3885, val_MinusLogProbMetric: 2.3885

Epoch 370: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3885 - val_MinusLogProbMetric: 2.3885 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 371/1000
2023-09-12 00:10:01.675 
Epoch 371/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 371: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 372/1000
2023-09-12 00:10:13.297 
Epoch 372/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 372: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 373/1000
2023-09-12 00:10:24.935 
Epoch 373/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 373: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 374/1000
2023-09-12 00:10:36.698 
Epoch 374/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3897, val_MinusLogProbMetric: 2.3897

Epoch 374: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3897 - val_MinusLogProbMetric: 2.3897 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 375/1000
2023-09-12 00:10:48.501 
Epoch 375/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 375: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 376/1000
2023-09-12 00:11:00.182 
Epoch 376/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 376: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-12 00:11:11.834 
Epoch 377/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3887, val_MinusLogProbMetric: 2.3887

Epoch 377: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3887 - val_MinusLogProbMetric: 2.3887 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 378/1000
2023-09-12 00:11:23.425 
Epoch 378/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 378: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 379/1000
2023-09-12 00:11:35.228 
Epoch 379/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 379: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-12 00:11:47.051 
Epoch 380/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3895, val_MinusLogProbMetric: 2.3895

Epoch 380: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3895 - val_MinusLogProbMetric: 2.3895 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 381/1000
2023-09-12 00:11:58.794 
Epoch 381/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 381: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 382/1000
2023-09-12 00:12:10.492 
Epoch 382/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3878, val_MinusLogProbMetric: 2.3878

Epoch 382: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3878 - val_MinusLogProbMetric: 2.3878 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 383/1000
2023-09-12 00:12:22.250 
Epoch 383/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 383: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 384/1000
2023-09-12 00:12:33.937 
Epoch 384/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 384: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 385/1000
2023-09-12 00:12:45.528 
Epoch 385/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3892, val_MinusLogProbMetric: 2.3892

Epoch 385: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3892 - val_MinusLogProbMetric: 2.3892 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 386/1000
2023-09-12 00:12:57.244 
Epoch 386/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 386: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 387/1000
2023-09-12 00:13:08.916 
Epoch 387/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 387: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 388/1000
2023-09-12 00:13:20.466 
Epoch 388/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 388: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 389/1000
2023-09-12 00:13:32.179 
Epoch 389/1000 
	 loss: 2.3541, MinusLogProbMetric: 2.3541, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 389: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3541 - MinusLogProbMetric: 2.3541 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 390/1000
2023-09-12 00:13:43.819 
Epoch 390/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3887, val_MinusLogProbMetric: 2.3887

Epoch 390: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3887 - val_MinusLogProbMetric: 2.3887 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 391/1000
2023-09-12 00:13:55.615 
Epoch 391/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3921, val_MinusLogProbMetric: 2.3921

Epoch 391: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3921 - val_MinusLogProbMetric: 2.3921 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 392/1000
2023-09-12 00:14:07.277 
Epoch 392/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3887, val_MinusLogProbMetric: 2.3887

Epoch 392: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3887 - val_MinusLogProbMetric: 2.3887 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 393/1000
2023-09-12 00:14:18.951 
Epoch 393/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3901, val_MinusLogProbMetric: 2.3901

Epoch 393: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3901 - val_MinusLogProbMetric: 2.3901 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 394/1000
2023-09-12 00:14:30.780 
Epoch 394/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 394: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 395/1000
2023-09-12 00:14:42.497 
Epoch 395/1000 
	 loss: 2.3530, MinusLogProbMetric: 2.3530, val_loss: 2.3896, val_MinusLogProbMetric: 2.3896

Epoch 395: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3530 - MinusLogProbMetric: 2.3530 - val_loss: 2.3896 - val_MinusLogProbMetric: 2.3896 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 396/1000
2023-09-12 00:14:54.150 
Epoch 396/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 396: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 397/1000
2023-09-12 00:15:05.915 
Epoch 397/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3904, val_MinusLogProbMetric: 2.3904

Epoch 397: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3904 - val_MinusLogProbMetric: 2.3904 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 398/1000
2023-09-12 00:15:17.629 
Epoch 398/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 398: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 399/1000
2023-09-12 00:15:29.431 
Epoch 399/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 399: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 400/1000
2023-09-12 00:15:41.095 
Epoch 400/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 400: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 401/1000
2023-09-12 00:15:52.683 
Epoch 401/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 401: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 402/1000
2023-09-12 00:16:04.435 
Epoch 402/1000 
	 loss: 2.3537, MinusLogProbMetric: 2.3537, val_loss: 2.3887, val_MinusLogProbMetric: 2.3887

Epoch 402: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3537 - MinusLogProbMetric: 2.3537 - val_loss: 2.3887 - val_MinusLogProbMetric: 2.3887 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 403/1000
2023-09-12 00:16:16.032 
Epoch 403/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 403: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 404/1000
2023-09-12 00:16:27.674 
Epoch 404/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 404: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 405/1000
2023-09-12 00:16:39.248 
Epoch 405/1000 
	 loss: 2.3532, MinusLogProbMetric: 2.3532, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 405: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3532 - MinusLogProbMetric: 2.3532 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 406/1000
2023-09-12 00:16:50.961 
Epoch 406/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3878, val_MinusLogProbMetric: 2.3878

Epoch 406: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3878 - val_MinusLogProbMetric: 2.3878 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 407/1000
2023-09-12 00:17:02.695 
Epoch 407/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 407: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 408/1000
2023-09-12 00:17:14.567 
Epoch 408/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 408: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 409/1000
2023-09-12 00:17:26.348 
Epoch 409/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 409: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 410/1000
2023-09-12 00:17:38.279 
Epoch 410/1000 
	 loss: 2.3535, MinusLogProbMetric: 2.3535, val_loss: 2.3875, val_MinusLogProbMetric: 2.3875

Epoch 410: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3535 - MinusLogProbMetric: 2.3535 - val_loss: 2.3875 - val_MinusLogProbMetric: 2.3875 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 411/1000
2023-09-12 00:17:49.929 
Epoch 411/1000 
	 loss: 2.3533, MinusLogProbMetric: 2.3533, val_loss: 2.3893, val_MinusLogProbMetric: 2.3893

Epoch 411: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3533 - MinusLogProbMetric: 2.3533 - val_loss: 2.3893 - val_MinusLogProbMetric: 2.3893 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 412/1000
2023-09-12 00:18:01.023 
Epoch 412/1000 
	 loss: 2.3536, MinusLogProbMetric: 2.3536, val_loss: 2.3907, val_MinusLogProbMetric: 2.3907

Epoch 412: val_loss did not improve from 2.38735
196/196 - 11s - loss: 2.3536 - MinusLogProbMetric: 2.3536 - val_loss: 2.3907 - val_MinusLogProbMetric: 2.3907 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 413/1000
2023-09-12 00:18:11.603 
Epoch 413/1000 
	 loss: 2.3534, MinusLogProbMetric: 2.3534, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 413: val_loss did not improve from 2.38735
196/196 - 11s - loss: 2.3534 - MinusLogProbMetric: 2.3534 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 414/1000
2023-09-12 00:18:23.284 
Epoch 414/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 414: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 415/1000
2023-09-12 00:18:34.991 
Epoch 415/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 415: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 416/1000
2023-09-12 00:18:46.575 
Epoch 416/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 416: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 417/1000
2023-09-12 00:18:58.349 
Epoch 417/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 417: val_loss did not improve from 2.38735
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-12 00:19:10.090 
Epoch 418/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3873, val_MinusLogProbMetric: 2.3873

Epoch 418: val_loss improved from 2.38735 to 2.38725, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_36/weights/best_weights.h5
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3873 - val_MinusLogProbMetric: 2.3873 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 419/1000
2023-09-12 00:19:21.823 
Epoch 419/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 419: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 420/1000
2023-09-12 00:19:33.540 
Epoch 420/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 420: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 421/1000
2023-09-12 00:19:45.278 
Epoch 421/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3875, val_MinusLogProbMetric: 2.3875

Epoch 421: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3875 - val_MinusLogProbMetric: 2.3875 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 422/1000
2023-09-12 00:19:57.011 
Epoch 422/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 422: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 423/1000
2023-09-12 00:20:08.584 
Epoch 423/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 423: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 424/1000
2023-09-12 00:20:20.377 
Epoch 424/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 424: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 425/1000
2023-09-12 00:20:32.175 
Epoch 425/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 425: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 426/1000
2023-09-12 00:20:43.924 
Epoch 426/1000 
	 loss: 2.3527, MinusLogProbMetric: 2.3527, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 426: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3527 - MinusLogProbMetric: 2.3527 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 427/1000
2023-09-12 00:20:55.686 
Epoch 427/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3878, val_MinusLogProbMetric: 2.3878

Epoch 427: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3878 - val_MinusLogProbMetric: 2.3878 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 428/1000
2023-09-12 00:21:07.588 
Epoch 428/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 428: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 429/1000
2023-09-12 00:21:19.225 
Epoch 429/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 429: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 430/1000
2023-09-12 00:21:31.057 
Epoch 430/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 430: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 431/1000
2023-09-12 00:21:42.923 
Epoch 431/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3891, val_MinusLogProbMetric: 2.3891

Epoch 431: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3891 - val_MinusLogProbMetric: 2.3891 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 432/1000
2023-09-12 00:21:54.624 
Epoch 432/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 432: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 433/1000
2023-09-12 00:22:06.099 
Epoch 433/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 433: val_loss did not improve from 2.38725
196/196 - 11s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 3.1250e-05 - 11s/epoch - 59ms/step
Epoch 434/1000
2023-09-12 00:22:16.694 
Epoch 434/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 434: val_loss did not improve from 2.38725
196/196 - 11s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 3.1250e-05 - 11s/epoch - 54ms/step
Epoch 435/1000
2023-09-12 00:22:27.099 
Epoch 435/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 435: val_loss did not improve from 2.38725
196/196 - 10s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 10s/epoch - 53ms/step
Epoch 436/1000
2023-09-12 00:22:38.694 
Epoch 436/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3878, val_MinusLogProbMetric: 2.3878

Epoch 436: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3878 - val_MinusLogProbMetric: 2.3878 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 437/1000
2023-09-12 00:22:50.353 
Epoch 437/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 437: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 438/1000
2023-09-12 00:23:01.963 
Epoch 438/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 438: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 439/1000
2023-09-12 00:23:13.635 
Epoch 439/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 439: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-12 00:23:25.352 
Epoch 440/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 440: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 441/1000
2023-09-12 00:23:37.069 
Epoch 441/1000 
	 loss: 2.3526, MinusLogProbMetric: 2.3526, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 441: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3526 - MinusLogProbMetric: 2.3526 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 442/1000
2023-09-12 00:23:48.785 
Epoch 442/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 442: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 443/1000
2023-09-12 00:24:00.402 
Epoch 443/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 443: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 444/1000
2023-09-12 00:24:12.149 
Epoch 444/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 444: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 445/1000
2023-09-12 00:24:23.823 
Epoch 445/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 445: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 446/1000
2023-09-12 00:24:35.576 
Epoch 446/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3888, val_MinusLogProbMetric: 2.3888

Epoch 446: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3888 - val_MinusLogProbMetric: 2.3888 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 447/1000
2023-09-12 00:24:47.189 
Epoch 447/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3877, val_MinusLogProbMetric: 2.3877

Epoch 447: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3877 - val_MinusLogProbMetric: 2.3877 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 448/1000
2023-09-12 00:24:58.865 
Epoch 448/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3878, val_MinusLogProbMetric: 2.3878

Epoch 448: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3878 - val_MinusLogProbMetric: 2.3878 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 449/1000
2023-09-12 00:25:10.454 
Epoch 449/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3880, val_MinusLogProbMetric: 2.3880

Epoch 449: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3880 - val_MinusLogProbMetric: 2.3880 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 450/1000
2023-09-12 00:25:22.200 
Epoch 450/1000 
	 loss: 2.3522, MinusLogProbMetric: 2.3522, val_loss: 2.3884, val_MinusLogProbMetric: 2.3884

Epoch 450: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3522 - MinusLogProbMetric: 2.3522 - val_loss: 2.3884 - val_MinusLogProbMetric: 2.3884 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 451/1000
2023-09-12 00:25:33.986 
Epoch 451/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3878, val_MinusLogProbMetric: 2.3878

Epoch 451: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3878 - val_MinusLogProbMetric: 2.3878 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 452/1000
2023-09-12 00:25:45.694 
Epoch 452/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3894, val_MinusLogProbMetric: 2.3894

Epoch 452: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3894 - val_MinusLogProbMetric: 2.3894 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 453/1000
2023-09-12 00:25:57.429 
Epoch 453/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 453: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 454/1000
2023-09-12 00:26:09.124 
Epoch 454/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3883, val_MinusLogProbMetric: 2.3883

Epoch 454: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3883 - val_MinusLogProbMetric: 2.3883 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 455/1000
2023-09-12 00:26:20.851 
Epoch 455/1000 
	 loss: 2.3522, MinusLogProbMetric: 2.3522, val_loss: 2.3879, val_MinusLogProbMetric: 2.3879

Epoch 455: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3522 - MinusLogProbMetric: 2.3522 - val_loss: 2.3879 - val_MinusLogProbMetric: 2.3879 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 456/1000
2023-09-12 00:26:32.593 
Epoch 456/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3876, val_MinusLogProbMetric: 2.3876

Epoch 456: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3876 - val_MinusLogProbMetric: 2.3876 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 457/1000
2023-09-12 00:26:44.332 
Epoch 457/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 457: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 458/1000
2023-09-12 00:26:55.975 
Epoch 458/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3881, val_MinusLogProbMetric: 2.3881

Epoch 458: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3881 - val_MinusLogProbMetric: 2.3881 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 459/1000
2023-09-12 00:27:07.722 
Epoch 459/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 459: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 460/1000
2023-09-12 00:27:19.463 
Epoch 460/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3882, val_MinusLogProbMetric: 2.3882

Epoch 460: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3882 - val_MinusLogProbMetric: 2.3882 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 461/1000
2023-09-12 00:27:31.150 
Epoch 461/1000 
	 loss: 2.3525, MinusLogProbMetric: 2.3525, val_loss: 2.3886, val_MinusLogProbMetric: 2.3886

Epoch 461: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3525 - MinusLogProbMetric: 2.3525 - val_loss: 2.3886 - val_MinusLogProbMetric: 2.3886 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 462/1000
2023-09-12 00:27:42.831 
Epoch 462/1000 
	 loss: 2.3524, MinusLogProbMetric: 2.3524, val_loss: 2.3874, val_MinusLogProbMetric: 2.3874

Epoch 462: val_loss did not improve from 2.38725
196/196 - 12s - loss: 2.3524 - MinusLogProbMetric: 2.3524 - val_loss: 2.3874 - val_MinusLogProbMetric: 2.3874 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 463/1000
2023-09-12 00:27:54.551 
Epoch 463/1000 
	 loss: 2.3523, MinusLogProbMetric: 2.3523, val_loss: 2.3890, val_MinusLogProbMetric: 2.3890

Epoch 463: val_loss did not improve from 2.38725
Restoring model weights from the end of the best epoch: 363.
196/196 - 12s - loss: 2.3523 - MinusLogProbMetric: 2.3523 - val_loss: 2.3890 - val_MinusLogProbMetric: 2.3890 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 463: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function LRMetric.Test_tf.<locals>.compute_test at 0x7fc7ac409f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
LR metric calculation completed in 4.769546691910364 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function KSTest.Test_tf.<locals>.compute_test at 0x7fc7ac409000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
KS tests calculation completed in 4.183403184986673 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function SWDMetric.Test_tf.<locals>.compute_test at 0x7fc7ac409990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
SWD metric calculation completed in 1.6161696090130135 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function FNMetric.Test_tf.<locals>.compute_test at 0x7fc7ac409630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
FN metric calculation completed in 1.9610929799964651 seconds.
Training succeeded with seed 926.
Model trained in 5443.25 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 16.26 s.
Plots done in 2.84 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 19.10 s.
===========
Run 36/360 done in 5463.18 s.
===========

Directory ../../results/MsplineN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

===========
Generating train data for run 43.
===========
Train data generated in 0.10 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_43/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_43/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.7135963 ,  6.9714103 ,  5.917921  , ...,  6.7739086 ,
         4.099491  ,  8.431494  ],
       [-0.01668072,  7.6713176 ,  8.707254  , ...,  8.091555  ,
         4.5760894 ,  7.7627635 ],
       [ 0.29024127,  8.388893  ,  8.132805  , ...,  7.935079  ,
         4.9752636 ,  7.888364  ],
       ...,
       [ 5.4464097 ,  8.765936  ,  5.857853  , ...,  6.480112  ,
         4.305537  ,  7.909903  ],
       [ 5.518208  ,  7.1176395 ,  6.024134  , ...,  6.214646  ,
         4.7054005 ,  8.5493145 ],
       [ 5.512709  ,  6.5989957 ,  5.9819336 , ...,  6.746342  ,
         4.7090354 ,  9.244418  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_43/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_43
self.data_kwargs: {'seed': 0}
self.x_data: [[ 0.29589212  7.7359915   7.409011   ...  7.511878    5.070296
   7.624635  ]
 [10.330838    3.0214188   7.9118695  ... 10.494211    1.2083023
   0.31532502]
 [ 5.403638    6.9306173   6.011932   ...  6.0492454   4.050036
  10.446038  ]
 ...
 [ 9.159434    4.8038816   7.887702   ...  9.787064    0.8411516
   1.798116  ]
 [ 9.515072    3.5633762   7.911226   ...  8.74153     1.1274126
  -0.02024943]
 [-0.34747946  8.762619    7.3980746  ...  8.953457    4.9630375
   8.033434  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_5 (LogProbLa  (None,)                  140592    
 yer)                                                            
                                                                 
=================================================================
Total params: 140,592
Trainable params: 140,592
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_5/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_5'")
self.model: <keras.engine.functional.Functional object at 0x7fcd80d92b30>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc7fc4fd0c0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc7fc4fd0c0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc7fc4ff010>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc7fc4fd900>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc7fc4fe440>, <keras.callbacks.ModelCheckpoint object at 0x7fc7fc4fe170>, <keras.callbacks.EarlyStopping object at 0x7fc7fc4fdf00>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc7fc4fd450>, <keras.callbacks.TerminateOnNaN object at 0x7fc7fc4fe0e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.7135963 ,  6.9714103 ,  5.917921  , ...,  6.7739086 ,
         4.099491  ,  8.431494  ],
       [-0.01668072,  7.6713176 ,  8.707254  , ...,  8.091555  ,
         4.5760894 ,  7.7627635 ],
       [ 0.29024127,  8.388893  ,  8.132805  , ...,  7.935079  ,
         4.9752636 ,  7.888364  ],
       ...,
       [ 5.4464097 ,  8.765936  ,  5.857853  , ...,  6.480112  ,
         4.305537  ,  7.909903  ],
       [ 5.518208  ,  7.1176395 ,  6.024134  , ...,  6.214646  ,
         4.7054005 ,  8.5493145 ],
       [ 5.512709  ,  6.5989957 ,  5.9819336 , ...,  6.746342  ,
         4.7090354 ,  9.244418  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_43/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 43/360 with hyperparameters:
timestamp = 2023-09-12 00:28:14.576758
ndims = 8
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 140592
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 0.29589212  7.7359915   7.409011    8.7586775  10.321777    7.511878
  5.070296    7.624635  ]
Epoch 1/1000
2023-09-12 00:28:42.460 
Epoch 1/1000 
	 loss: 17.0847, MinusLogProbMetric: 17.0847, val_loss: 5.7230, val_MinusLogProbMetric: 5.7230

Epoch 1: val_loss improved from inf to 5.72304, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 28s - loss: 17.0847 - MinusLogProbMetric: 17.0847 - val_loss: 5.7230 - val_MinusLogProbMetric: 5.7230 - lr: 0.0010 - 28s/epoch - 142ms/step
Epoch 2/1000
2023-09-12 00:28:54.199 
Epoch 2/1000 
	 loss: 5.0957, MinusLogProbMetric: 5.0957, val_loss: 4.8701, val_MinusLogProbMetric: 4.8701

Epoch 2: val_loss improved from 5.72304 to 4.87006, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 5.0957 - MinusLogProbMetric: 5.0957 - val_loss: 4.8701 - val_MinusLogProbMetric: 4.8701 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 3/1000
2023-09-12 00:29:06.080 
Epoch 3/1000 
	 loss: 4.6606, MinusLogProbMetric: 4.6606, val_loss: 4.5849, val_MinusLogProbMetric: 4.5849

Epoch 3: val_loss improved from 4.87006 to 4.58493, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.6606 - MinusLogProbMetric: 4.6606 - val_loss: 4.5849 - val_MinusLogProbMetric: 4.5849 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 4/1000
2023-09-12 00:29:17.892 
Epoch 4/1000 
	 loss: 4.4947, MinusLogProbMetric: 4.4947, val_loss: 4.3686, val_MinusLogProbMetric: 4.3686

Epoch 4: val_loss improved from 4.58493 to 4.36863, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.4947 - MinusLogProbMetric: 4.4947 - val_loss: 4.3686 - val_MinusLogProbMetric: 4.3686 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-12 00:29:29.767 
Epoch 5/1000 
	 loss: 4.3886, MinusLogProbMetric: 4.3886, val_loss: 4.4203, val_MinusLogProbMetric: 4.4203

Epoch 5: val_loss did not improve from 4.36863
196/196 - 12s - loss: 4.3886 - MinusLogProbMetric: 4.3886 - val_loss: 4.4203 - val_MinusLogProbMetric: 4.4203 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 6/1000
2023-09-12 00:29:41.460 
Epoch 6/1000 
	 loss: 4.3466, MinusLogProbMetric: 4.3466, val_loss: 4.4505, val_MinusLogProbMetric: 4.4505

Epoch 6: val_loss did not improve from 4.36863
196/196 - 12s - loss: 4.3466 - MinusLogProbMetric: 4.3466 - val_loss: 4.4505 - val_MinusLogProbMetric: 4.4505 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-12 00:29:53.059 
Epoch 7/1000 
	 loss: 4.2913, MinusLogProbMetric: 4.2913, val_loss: 4.2513, val_MinusLogProbMetric: 4.2513

Epoch 7: val_loss improved from 4.36863 to 4.25133, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.2913 - MinusLogProbMetric: 4.2913 - val_loss: 4.2513 - val_MinusLogProbMetric: 4.2513 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 8/1000
2023-09-12 00:30:04.411 
Epoch 8/1000 
	 loss: 4.2869, MinusLogProbMetric: 4.2869, val_loss: 4.2758, val_MinusLogProbMetric: 4.2758

Epoch 8: val_loss did not improve from 4.25133
196/196 - 11s - loss: 4.2869 - MinusLogProbMetric: 4.2869 - val_loss: 4.2758 - val_MinusLogProbMetric: 4.2758 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 9/1000
2023-09-12 00:30:15.106 
Epoch 9/1000 
	 loss: 4.2584, MinusLogProbMetric: 4.2584, val_loss: 4.2812, val_MinusLogProbMetric: 4.2812

Epoch 9: val_loss did not improve from 4.25133
196/196 - 11s - loss: 4.2584 - MinusLogProbMetric: 4.2584 - val_loss: 4.2812 - val_MinusLogProbMetric: 4.2812 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 10/1000
2023-09-12 00:30:26.813 
Epoch 10/1000 
	 loss: 4.2374, MinusLogProbMetric: 4.2374, val_loss: 4.2821, val_MinusLogProbMetric: 4.2821

Epoch 10: val_loss did not improve from 4.25133
196/196 - 12s - loss: 4.2374 - MinusLogProbMetric: 4.2374 - val_loss: 4.2821 - val_MinusLogProbMetric: 4.2821 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-12 00:30:38.461 
Epoch 11/1000 
	 loss: 4.2385, MinusLogProbMetric: 4.2385, val_loss: 4.3069, val_MinusLogProbMetric: 4.3069

Epoch 11: val_loss did not improve from 4.25133
196/196 - 12s - loss: 4.2385 - MinusLogProbMetric: 4.2385 - val_loss: 4.3069 - val_MinusLogProbMetric: 4.3069 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 12/1000
2023-09-12 00:30:50.112 
Epoch 12/1000 
	 loss: 4.2499, MinusLogProbMetric: 4.2499, val_loss: 4.3260, val_MinusLogProbMetric: 4.3260

Epoch 12: val_loss did not improve from 4.25133
196/196 - 12s - loss: 4.2499 - MinusLogProbMetric: 4.2499 - val_loss: 4.3260 - val_MinusLogProbMetric: 4.3260 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 13/1000
2023-09-12 00:31:01.840 
Epoch 13/1000 
	 loss: 4.2159, MinusLogProbMetric: 4.2159, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 13: val_loss improved from 4.25133 to 4.20467, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.2159 - MinusLogProbMetric: 4.2159 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 00:31:13.766 
Epoch 14/1000 
	 loss: 4.2122, MinusLogProbMetric: 4.2122, val_loss: 4.2745, val_MinusLogProbMetric: 4.2745

Epoch 14: val_loss did not improve from 4.20467
196/196 - 12s - loss: 4.2122 - MinusLogProbMetric: 4.2122 - val_loss: 4.2745 - val_MinusLogProbMetric: 4.2745 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-12 00:31:25.586 
Epoch 15/1000 
	 loss: 4.2345, MinusLogProbMetric: 4.2345, val_loss: 4.1704, val_MinusLogProbMetric: 4.1704

Epoch 15: val_loss improved from 4.20467 to 4.17039, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.2345 - MinusLogProbMetric: 4.2345 - val_loss: 4.1704 - val_MinusLogProbMetric: 4.1704 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 16/1000
2023-09-12 00:31:37.329 
Epoch 16/1000 
	 loss: 4.2070, MinusLogProbMetric: 4.2070, val_loss: 4.2059, val_MinusLogProbMetric: 4.2059

Epoch 16: val_loss did not improve from 4.17039
196/196 - 12s - loss: 4.2070 - MinusLogProbMetric: 4.2070 - val_loss: 4.2059 - val_MinusLogProbMetric: 4.2059 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 17/1000
2023-09-12 00:31:49.027 
Epoch 17/1000 
	 loss: 4.2102, MinusLogProbMetric: 4.2102, val_loss: 4.2774, val_MinusLogProbMetric: 4.2774

Epoch 17: val_loss did not improve from 4.17039
196/196 - 12s - loss: 4.2102 - MinusLogProbMetric: 4.2102 - val_loss: 4.2774 - val_MinusLogProbMetric: 4.2774 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-12 00:32:00.857 
Epoch 18/1000 
	 loss: 4.1970, MinusLogProbMetric: 4.1970, val_loss: 4.2243, val_MinusLogProbMetric: 4.2243

Epoch 18: val_loss did not improve from 4.17039
196/196 - 12s - loss: 4.1970 - MinusLogProbMetric: 4.1970 - val_loss: 4.2243 - val_MinusLogProbMetric: 4.2243 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 00:32:12.682 
Epoch 19/1000 
	 loss: 4.1867, MinusLogProbMetric: 4.1867, val_loss: 4.1626, val_MinusLogProbMetric: 4.1626

Epoch 19: val_loss improved from 4.17039 to 4.16260, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1867 - MinusLogProbMetric: 4.1867 - val_loss: 4.1626 - val_MinusLogProbMetric: 4.1626 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 20/1000
2023-09-12 00:32:24.606 
Epoch 20/1000 
	 loss: 4.1974, MinusLogProbMetric: 4.1974, val_loss: 4.2286, val_MinusLogProbMetric: 4.2286

Epoch 20: val_loss did not improve from 4.16260
196/196 - 12s - loss: 4.1974 - MinusLogProbMetric: 4.1974 - val_loss: 4.2286 - val_MinusLogProbMetric: 4.2286 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 21/1000
2023-09-12 00:32:36.264 
Epoch 21/1000 
	 loss: 4.1920, MinusLogProbMetric: 4.1920, val_loss: 4.1713, val_MinusLogProbMetric: 4.1713

Epoch 21: val_loss did not improve from 4.16260
196/196 - 12s - loss: 4.1920 - MinusLogProbMetric: 4.1920 - val_loss: 4.1713 - val_MinusLogProbMetric: 4.1713 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 00:32:48.044 
Epoch 22/1000 
	 loss: 4.1971, MinusLogProbMetric: 4.1971, val_loss: 4.2294, val_MinusLogProbMetric: 4.2294

Epoch 22: val_loss did not improve from 4.16260
196/196 - 12s - loss: 4.1971 - MinusLogProbMetric: 4.1971 - val_loss: 4.2294 - val_MinusLogProbMetric: 4.2294 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 00:32:59.956 
Epoch 23/1000 
	 loss: 4.1768, MinusLogProbMetric: 4.1768, val_loss: 4.1975, val_MinusLogProbMetric: 4.1975

Epoch 23: val_loss did not improve from 4.16260
196/196 - 12s - loss: 4.1768 - MinusLogProbMetric: 4.1768 - val_loss: 4.1975 - val_MinusLogProbMetric: 4.1975 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 24/1000
2023-09-12 00:33:11.668 
Epoch 24/1000 
	 loss: 4.1818, MinusLogProbMetric: 4.1818, val_loss: 4.1576, val_MinusLogProbMetric: 4.1576

Epoch 24: val_loss improved from 4.16260 to 4.15758, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1818 - MinusLogProbMetric: 4.1818 - val_loss: 4.1576 - val_MinusLogProbMetric: 4.1576 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-12 00:33:23.454 
Epoch 25/1000 
	 loss: 4.1650, MinusLogProbMetric: 4.1650, val_loss: 4.1818, val_MinusLogProbMetric: 4.1818

Epoch 25: val_loss did not improve from 4.15758
196/196 - 12s - loss: 4.1650 - MinusLogProbMetric: 4.1650 - val_loss: 4.1818 - val_MinusLogProbMetric: 4.1818 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 00:33:35.305 
Epoch 26/1000 
	 loss: 4.1623, MinusLogProbMetric: 4.1623, val_loss: 4.1855, val_MinusLogProbMetric: 4.1855

Epoch 26: val_loss did not improve from 4.15758
196/196 - 12s - loss: 4.1623 - MinusLogProbMetric: 4.1623 - val_loss: 4.1855 - val_MinusLogProbMetric: 4.1855 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 00:33:47.119 
Epoch 27/1000 
	 loss: 4.1610, MinusLogProbMetric: 4.1610, val_loss: 4.1754, val_MinusLogProbMetric: 4.1754

Epoch 27: val_loss did not improve from 4.15758
196/196 - 12s - loss: 4.1610 - MinusLogProbMetric: 4.1610 - val_loss: 4.1754 - val_MinusLogProbMetric: 4.1754 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-12 00:33:58.701 
Epoch 28/1000 
	 loss: 4.1680, MinusLogProbMetric: 4.1680, val_loss: 4.1670, val_MinusLogProbMetric: 4.1670

Epoch 28: val_loss did not improve from 4.15758
196/196 - 12s - loss: 4.1680 - MinusLogProbMetric: 4.1680 - val_loss: 4.1670 - val_MinusLogProbMetric: 4.1670 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 00:34:10.416 
Epoch 29/1000 
	 loss: 4.1608, MinusLogProbMetric: 4.1608, val_loss: 4.1712, val_MinusLogProbMetric: 4.1712

Epoch 29: val_loss did not improve from 4.15758
196/196 - 12s - loss: 4.1608 - MinusLogProbMetric: 4.1608 - val_loss: 4.1712 - val_MinusLogProbMetric: 4.1712 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 30/1000
2023-09-12 00:34:22.271 
Epoch 30/1000 
	 loss: 4.1598, MinusLogProbMetric: 4.1598, val_loss: 4.1491, val_MinusLogProbMetric: 4.1491

Epoch 30: val_loss improved from 4.15758 to 4.14915, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1598 - MinusLogProbMetric: 4.1598 - val_loss: 4.1491 - val_MinusLogProbMetric: 4.1491 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 31/1000
2023-09-12 00:34:34.084 
Epoch 31/1000 
	 loss: 4.1613, MinusLogProbMetric: 4.1613, val_loss: 4.2108, val_MinusLogProbMetric: 4.2108

Epoch 31: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1613 - MinusLogProbMetric: 4.1613 - val_loss: 4.2108 - val_MinusLogProbMetric: 4.2108 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-12 00:34:45.696 
Epoch 32/1000 
	 loss: 4.1662, MinusLogProbMetric: 4.1662, val_loss: 4.1830, val_MinusLogProbMetric: 4.1830

Epoch 32: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1662 - MinusLogProbMetric: 4.1662 - val_loss: 4.1830 - val_MinusLogProbMetric: 4.1830 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 33/1000
2023-09-12 00:34:57.483 
Epoch 33/1000 
	 loss: 4.1578, MinusLogProbMetric: 4.1578, val_loss: 4.1601, val_MinusLogProbMetric: 4.1601

Epoch 33: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1578 - MinusLogProbMetric: 4.1578 - val_loss: 4.1601 - val_MinusLogProbMetric: 4.1601 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-12 00:35:09.282 
Epoch 34/1000 
	 loss: 4.1534, MinusLogProbMetric: 4.1534, val_loss: 4.2777, val_MinusLogProbMetric: 4.2777

Epoch 34: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1534 - MinusLogProbMetric: 4.1534 - val_loss: 4.2777 - val_MinusLogProbMetric: 4.2777 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-12 00:35:21.003 
Epoch 35/1000 
	 loss: 4.1601, MinusLogProbMetric: 4.1601, val_loss: 4.2002, val_MinusLogProbMetric: 4.2002

Epoch 35: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1601 - MinusLogProbMetric: 4.1601 - val_loss: 4.2002 - val_MinusLogProbMetric: 4.2002 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-12 00:35:32.753 
Epoch 36/1000 
	 loss: 4.1564, MinusLogProbMetric: 4.1564, val_loss: 4.1786, val_MinusLogProbMetric: 4.1786

Epoch 36: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1564 - MinusLogProbMetric: 4.1564 - val_loss: 4.1786 - val_MinusLogProbMetric: 4.1786 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 00:35:44.555 
Epoch 37/1000 
	 loss: 4.1509, MinusLogProbMetric: 4.1509, val_loss: 4.1495, val_MinusLogProbMetric: 4.1495

Epoch 37: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1509 - MinusLogProbMetric: 4.1509 - val_loss: 4.1495 - val_MinusLogProbMetric: 4.1495 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 38/1000
2023-09-12 00:35:56.366 
Epoch 38/1000 
	 loss: 4.1627, MinusLogProbMetric: 4.1627, val_loss: 4.1937, val_MinusLogProbMetric: 4.1937

Epoch 38: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1627 - MinusLogProbMetric: 4.1627 - val_loss: 4.1937 - val_MinusLogProbMetric: 4.1937 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 00:36:08.055 
Epoch 39/1000 
	 loss: 4.1595, MinusLogProbMetric: 4.1595, val_loss: 4.2951, val_MinusLogProbMetric: 4.2951

Epoch 39: val_loss did not improve from 4.14915
196/196 - 12s - loss: 4.1595 - MinusLogProbMetric: 4.1595 - val_loss: 4.2951 - val_MinusLogProbMetric: 4.2951 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-12 00:36:19.776 
Epoch 40/1000 
	 loss: 4.1428, MinusLogProbMetric: 4.1428, val_loss: 4.1424, val_MinusLogProbMetric: 4.1424

Epoch 40: val_loss improved from 4.14915 to 4.14238, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1428 - MinusLogProbMetric: 4.1428 - val_loss: 4.1424 - val_MinusLogProbMetric: 4.1424 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-12 00:36:31.608 
Epoch 41/1000 
	 loss: 4.1435, MinusLogProbMetric: 4.1435, val_loss: 4.2648, val_MinusLogProbMetric: 4.2648

Epoch 41: val_loss did not improve from 4.14238
196/196 - 12s - loss: 4.1435 - MinusLogProbMetric: 4.1435 - val_loss: 4.2648 - val_MinusLogProbMetric: 4.2648 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-12 00:36:43.270 
Epoch 42/1000 
	 loss: 4.1416, MinusLogProbMetric: 4.1416, val_loss: 4.1326, val_MinusLogProbMetric: 4.1326

Epoch 42: val_loss improved from 4.14238 to 4.13258, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1416 - MinusLogProbMetric: 4.1416 - val_loss: 4.1326 - val_MinusLogProbMetric: 4.1326 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-12 00:36:55.033 
Epoch 43/1000 
	 loss: 4.1538, MinusLogProbMetric: 4.1538, val_loss: 4.1378, val_MinusLogProbMetric: 4.1378

Epoch 43: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1538 - MinusLogProbMetric: 4.1538 - val_loss: 4.1378 - val_MinusLogProbMetric: 4.1378 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-12 00:37:06.777 
Epoch 44/1000 
	 loss: 4.1460, MinusLogProbMetric: 4.1460, val_loss: 4.1346, val_MinusLogProbMetric: 4.1346

Epoch 44: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1460 - MinusLogProbMetric: 4.1460 - val_loss: 4.1346 - val_MinusLogProbMetric: 4.1346 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-12 00:37:18.463 
Epoch 45/1000 
	 loss: 4.1375, MinusLogProbMetric: 4.1375, val_loss: 4.1901, val_MinusLogProbMetric: 4.1901

Epoch 45: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1375 - MinusLogProbMetric: 4.1375 - val_loss: 4.1901 - val_MinusLogProbMetric: 4.1901 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-12 00:37:30.219 
Epoch 46/1000 
	 loss: 4.1376, MinusLogProbMetric: 4.1376, val_loss: 4.1373, val_MinusLogProbMetric: 4.1373

Epoch 46: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1376 - MinusLogProbMetric: 4.1376 - val_loss: 4.1373 - val_MinusLogProbMetric: 4.1373 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 47/1000
2023-09-12 00:37:41.913 
Epoch 47/1000 
	 loss: 4.1357, MinusLogProbMetric: 4.1357, val_loss: 4.2641, val_MinusLogProbMetric: 4.2641

Epoch 47: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1357 - MinusLogProbMetric: 4.1357 - val_loss: 4.2641 - val_MinusLogProbMetric: 4.2641 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-12 00:37:53.587 
Epoch 48/1000 
	 loss: 4.1466, MinusLogProbMetric: 4.1466, val_loss: 4.1668, val_MinusLogProbMetric: 4.1668

Epoch 48: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1466 - MinusLogProbMetric: 4.1466 - val_loss: 4.1668 - val_MinusLogProbMetric: 4.1668 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-12 00:38:05.108 
Epoch 49/1000 
	 loss: 4.1480, MinusLogProbMetric: 4.1480, val_loss: 4.1750, val_MinusLogProbMetric: 4.1750

Epoch 49: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1480 - MinusLogProbMetric: 4.1480 - val_loss: 4.1750 - val_MinusLogProbMetric: 4.1750 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-12 00:38:16.914 
Epoch 50/1000 
	 loss: 4.1428, MinusLogProbMetric: 4.1428, val_loss: 4.1429, val_MinusLogProbMetric: 4.1429

Epoch 50: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1428 - MinusLogProbMetric: 4.1428 - val_loss: 4.1429 - val_MinusLogProbMetric: 4.1429 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 51/1000
2023-09-12 00:38:28.534 
Epoch 51/1000 
	 loss: 4.1324, MinusLogProbMetric: 4.1324, val_loss: 4.1960, val_MinusLogProbMetric: 4.1960

Epoch 51: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1324 - MinusLogProbMetric: 4.1324 - val_loss: 4.1960 - val_MinusLogProbMetric: 4.1960 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 52/1000
2023-09-12 00:38:40.242 
Epoch 52/1000 
	 loss: 4.1283, MinusLogProbMetric: 4.1283, val_loss: 4.1858, val_MinusLogProbMetric: 4.1858

Epoch 52: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1283 - MinusLogProbMetric: 4.1283 - val_loss: 4.1858 - val_MinusLogProbMetric: 4.1858 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-12 00:38:51.984 
Epoch 53/1000 
	 loss: 4.1374, MinusLogProbMetric: 4.1374, val_loss: 4.1534, val_MinusLogProbMetric: 4.1534

Epoch 53: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1374 - MinusLogProbMetric: 4.1374 - val_loss: 4.1534 - val_MinusLogProbMetric: 4.1534 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-12 00:39:03.632 
Epoch 54/1000 
	 loss: 4.1256, MinusLogProbMetric: 4.1256, val_loss: 4.1747, val_MinusLogProbMetric: 4.1747

Epoch 54: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1256 - MinusLogProbMetric: 4.1256 - val_loss: 4.1747 - val_MinusLogProbMetric: 4.1747 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 55/1000
2023-09-12 00:39:15.326 
Epoch 55/1000 
	 loss: 4.1420, MinusLogProbMetric: 4.1420, val_loss: 4.1683, val_MinusLogProbMetric: 4.1683

Epoch 55: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1420 - MinusLogProbMetric: 4.1420 - val_loss: 4.1683 - val_MinusLogProbMetric: 4.1683 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-12 00:39:27.016 
Epoch 56/1000 
	 loss: 4.1339, MinusLogProbMetric: 4.1339, val_loss: 4.2889, val_MinusLogProbMetric: 4.2889

Epoch 56: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1339 - MinusLogProbMetric: 4.1339 - val_loss: 4.2889 - val_MinusLogProbMetric: 4.2889 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-12 00:39:38.745 
Epoch 57/1000 
	 loss: 4.1458, MinusLogProbMetric: 4.1458, val_loss: 4.1530, val_MinusLogProbMetric: 4.1530

Epoch 57: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1458 - MinusLogProbMetric: 4.1458 - val_loss: 4.1530 - val_MinusLogProbMetric: 4.1530 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-12 00:39:50.422 
Epoch 58/1000 
	 loss: 4.1458, MinusLogProbMetric: 4.1458, val_loss: 4.1588, val_MinusLogProbMetric: 4.1588

Epoch 58: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1458 - MinusLogProbMetric: 4.1458 - val_loss: 4.1588 - val_MinusLogProbMetric: 4.1588 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-12 00:40:02.199 
Epoch 59/1000 
	 loss: 4.1373, MinusLogProbMetric: 4.1373, val_loss: 4.1636, val_MinusLogProbMetric: 4.1636

Epoch 59: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1373 - MinusLogProbMetric: 4.1373 - val_loss: 4.1636 - val_MinusLogProbMetric: 4.1636 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-12 00:40:13.832 
Epoch 60/1000 
	 loss: 4.1350, MinusLogProbMetric: 4.1350, val_loss: 4.1541, val_MinusLogProbMetric: 4.1541

Epoch 60: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1350 - MinusLogProbMetric: 4.1350 - val_loss: 4.1541 - val_MinusLogProbMetric: 4.1541 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 61/1000
2023-09-12 00:40:25.545 
Epoch 61/1000 
	 loss: 4.1374, MinusLogProbMetric: 4.1374, val_loss: 4.1426, val_MinusLogProbMetric: 4.1426

Epoch 61: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1374 - MinusLogProbMetric: 4.1374 - val_loss: 4.1426 - val_MinusLogProbMetric: 4.1426 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-12 00:40:37.269 
Epoch 62/1000 
	 loss: 4.1286, MinusLogProbMetric: 4.1286, val_loss: 4.1911, val_MinusLogProbMetric: 4.1911

Epoch 62: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1286 - MinusLogProbMetric: 4.1286 - val_loss: 4.1911 - val_MinusLogProbMetric: 4.1911 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-12 00:40:49.014 
Epoch 63/1000 
	 loss: 4.1311, MinusLogProbMetric: 4.1311, val_loss: 4.1431, val_MinusLogProbMetric: 4.1431

Epoch 63: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1311 - MinusLogProbMetric: 4.1311 - val_loss: 4.1431 - val_MinusLogProbMetric: 4.1431 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-12 00:41:00.725 
Epoch 64/1000 
	 loss: 4.1270, MinusLogProbMetric: 4.1270, val_loss: 4.1592, val_MinusLogProbMetric: 4.1592

Epoch 64: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1270 - MinusLogProbMetric: 4.1270 - val_loss: 4.1592 - val_MinusLogProbMetric: 4.1592 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-12 00:41:12.349 
Epoch 65/1000 
	 loss: 4.1302, MinusLogProbMetric: 4.1302, val_loss: 4.2179, val_MinusLogProbMetric: 4.2179

Epoch 65: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1302 - MinusLogProbMetric: 4.1302 - val_loss: 4.2179 - val_MinusLogProbMetric: 4.2179 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 66/1000
2023-09-12 00:41:24.138 
Epoch 66/1000 
	 loss: 4.1250, MinusLogProbMetric: 4.1250, val_loss: 4.1455, val_MinusLogProbMetric: 4.1455

Epoch 66: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1250 - MinusLogProbMetric: 4.1250 - val_loss: 4.1455 - val_MinusLogProbMetric: 4.1455 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-12 00:41:35.995 
Epoch 67/1000 
	 loss: 4.1299, MinusLogProbMetric: 4.1299, val_loss: 4.1632, val_MinusLogProbMetric: 4.1632

Epoch 67: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1299 - MinusLogProbMetric: 4.1299 - val_loss: 4.1632 - val_MinusLogProbMetric: 4.1632 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-12 00:41:47.668 
Epoch 68/1000 
	 loss: 4.1281, MinusLogProbMetric: 4.1281, val_loss: 4.1607, val_MinusLogProbMetric: 4.1607

Epoch 68: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1281 - MinusLogProbMetric: 4.1281 - val_loss: 4.1607 - val_MinusLogProbMetric: 4.1607 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-12 00:41:59.451 
Epoch 69/1000 
	 loss: 4.1275, MinusLogProbMetric: 4.1275, val_loss: 4.1855, val_MinusLogProbMetric: 4.1855

Epoch 69: val_loss did not improve from 4.13258
196/196 - 12s - loss: 4.1275 - MinusLogProbMetric: 4.1275 - val_loss: 4.1855 - val_MinusLogProbMetric: 4.1855 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 00:42:11.165 
Epoch 70/1000 
	 loss: 4.1288, MinusLogProbMetric: 4.1288, val_loss: 4.1294, val_MinusLogProbMetric: 4.1294

Epoch 70: val_loss improved from 4.13258 to 4.12936, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1288 - MinusLogProbMetric: 4.1288 - val_loss: 4.1294 - val_MinusLogProbMetric: 4.1294 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-12 00:42:22.924 
Epoch 71/1000 
	 loss: 4.1250, MinusLogProbMetric: 4.1250, val_loss: 4.1497, val_MinusLogProbMetric: 4.1497

Epoch 71: val_loss did not improve from 4.12936
196/196 - 12s - loss: 4.1250 - MinusLogProbMetric: 4.1250 - val_loss: 4.1497 - val_MinusLogProbMetric: 4.1497 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 72/1000
2023-09-12 00:42:34.754 
Epoch 72/1000 
	 loss: 4.1378, MinusLogProbMetric: 4.1378, val_loss: 4.1890, val_MinusLogProbMetric: 4.1890

Epoch 72: val_loss did not improve from 4.12936
196/196 - 12s - loss: 4.1378 - MinusLogProbMetric: 4.1378 - val_loss: 4.1890 - val_MinusLogProbMetric: 4.1890 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-12 00:42:46.455 
Epoch 73/1000 
	 loss: 4.1274, MinusLogProbMetric: 4.1274, val_loss: 4.1305, val_MinusLogProbMetric: 4.1305

Epoch 73: val_loss did not improve from 4.12936
196/196 - 12s - loss: 4.1274 - MinusLogProbMetric: 4.1274 - val_loss: 4.1305 - val_MinusLogProbMetric: 4.1305 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-12 00:42:58.127 
Epoch 74/1000 
	 loss: 4.1278, MinusLogProbMetric: 4.1278, val_loss: 4.1235, val_MinusLogProbMetric: 4.1235

Epoch 74: val_loss improved from 4.12936 to 4.12347, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1278 - MinusLogProbMetric: 4.1278 - val_loss: 4.1235 - val_MinusLogProbMetric: 4.1235 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-12 00:43:09.983 
Epoch 75/1000 
	 loss: 4.1183, MinusLogProbMetric: 4.1183, val_loss: 4.1241, val_MinusLogProbMetric: 4.1241

Epoch 75: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1183 - MinusLogProbMetric: 4.1183 - val_loss: 4.1241 - val_MinusLogProbMetric: 4.1241 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-12 00:43:21.720 
Epoch 76/1000 
	 loss: 4.1282, MinusLogProbMetric: 4.1282, val_loss: 4.1364, val_MinusLogProbMetric: 4.1364

Epoch 76: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1282 - MinusLogProbMetric: 4.1282 - val_loss: 4.1364 - val_MinusLogProbMetric: 4.1364 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-12 00:43:33.389 
Epoch 77/1000 
	 loss: 4.1276, MinusLogProbMetric: 4.1276, val_loss: 4.1370, val_MinusLogProbMetric: 4.1370

Epoch 77: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1276 - MinusLogProbMetric: 4.1276 - val_loss: 4.1370 - val_MinusLogProbMetric: 4.1370 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-12 00:43:45.076 
Epoch 78/1000 
	 loss: 4.1261, MinusLogProbMetric: 4.1261, val_loss: 4.1780, val_MinusLogProbMetric: 4.1780

Epoch 78: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1261 - MinusLogProbMetric: 4.1261 - val_loss: 4.1780 - val_MinusLogProbMetric: 4.1780 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-12 00:43:56.830 
Epoch 79/1000 
	 loss: 4.1212, MinusLogProbMetric: 4.1212, val_loss: 4.1681, val_MinusLogProbMetric: 4.1681

Epoch 79: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1212 - MinusLogProbMetric: 4.1212 - val_loss: 4.1681 - val_MinusLogProbMetric: 4.1681 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 00:44:08.449 
Epoch 80/1000 
	 loss: 4.1235, MinusLogProbMetric: 4.1235, val_loss: 4.1514, val_MinusLogProbMetric: 4.1514

Epoch 80: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1235 - MinusLogProbMetric: 4.1235 - val_loss: 4.1514 - val_MinusLogProbMetric: 4.1514 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-12 00:44:20.127 
Epoch 81/1000 
	 loss: 4.1315, MinusLogProbMetric: 4.1315, val_loss: 4.1877, val_MinusLogProbMetric: 4.1877

Epoch 81: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1315 - MinusLogProbMetric: 4.1315 - val_loss: 4.1877 - val_MinusLogProbMetric: 4.1877 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 82/1000
2023-09-12 00:44:31.777 
Epoch 82/1000 
	 loss: 4.1204, MinusLogProbMetric: 4.1204, val_loss: 4.1573, val_MinusLogProbMetric: 4.1573

Epoch 82: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1204 - MinusLogProbMetric: 4.1204 - val_loss: 4.1573 - val_MinusLogProbMetric: 4.1573 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 83/1000
2023-09-12 00:44:43.422 
Epoch 83/1000 
	 loss: 4.1222, MinusLogProbMetric: 4.1222, val_loss: 4.1710, val_MinusLogProbMetric: 4.1710

Epoch 83: val_loss did not improve from 4.12347
196/196 - 12s - loss: 4.1222 - MinusLogProbMetric: 4.1222 - val_loss: 4.1710 - val_MinusLogProbMetric: 4.1710 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-12 00:44:55.019 
Epoch 84/1000 
	 loss: 4.1188, MinusLogProbMetric: 4.1188, val_loss: 4.1203, val_MinusLogProbMetric: 4.1203

Epoch 84: val_loss improved from 4.12347 to 4.12030, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1188 - MinusLogProbMetric: 4.1188 - val_loss: 4.1203 - val_MinusLogProbMetric: 4.1203 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 85/1000
2023-09-12 00:45:06.888 
Epoch 85/1000 
	 loss: 4.1166, MinusLogProbMetric: 4.1166, val_loss: 4.1547, val_MinusLogProbMetric: 4.1547

Epoch 85: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1166 - MinusLogProbMetric: 4.1166 - val_loss: 4.1547 - val_MinusLogProbMetric: 4.1547 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-12 00:45:18.593 
Epoch 86/1000 
	 loss: 4.1188, MinusLogProbMetric: 4.1188, val_loss: 4.1466, val_MinusLogProbMetric: 4.1466

Epoch 86: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1188 - MinusLogProbMetric: 4.1188 - val_loss: 4.1466 - val_MinusLogProbMetric: 4.1466 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 87/1000
2023-09-12 00:45:30.141 
Epoch 87/1000 
	 loss: 4.1177, MinusLogProbMetric: 4.1177, val_loss: 4.1306, val_MinusLogProbMetric: 4.1306

Epoch 87: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1177 - MinusLogProbMetric: 4.1177 - val_loss: 4.1306 - val_MinusLogProbMetric: 4.1306 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-12 00:45:41.932 
Epoch 88/1000 
	 loss: 4.1165, MinusLogProbMetric: 4.1165, val_loss: 4.1641, val_MinusLogProbMetric: 4.1641

Epoch 88: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1165 - MinusLogProbMetric: 4.1165 - val_loss: 4.1641 - val_MinusLogProbMetric: 4.1641 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-12 00:45:53.532 
Epoch 89/1000 
	 loss: 4.1174, MinusLogProbMetric: 4.1174, val_loss: 4.1339, val_MinusLogProbMetric: 4.1339

Epoch 89: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1174 - MinusLogProbMetric: 4.1174 - val_loss: 4.1339 - val_MinusLogProbMetric: 4.1339 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 90/1000
2023-09-12 00:46:05.267 
Epoch 90/1000 
	 loss: 4.1214, MinusLogProbMetric: 4.1214, val_loss: 4.1283, val_MinusLogProbMetric: 4.1283

Epoch 90: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1214 - MinusLogProbMetric: 4.1214 - val_loss: 4.1283 - val_MinusLogProbMetric: 4.1283 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-12 00:46:16.971 
Epoch 91/1000 
	 loss: 4.1199, MinusLogProbMetric: 4.1199, val_loss: 4.1527, val_MinusLogProbMetric: 4.1527

Epoch 91: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1199 - MinusLogProbMetric: 4.1199 - val_loss: 4.1527 - val_MinusLogProbMetric: 4.1527 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 00:46:28.794 
Epoch 92/1000 
	 loss: 4.1186, MinusLogProbMetric: 4.1186, val_loss: 4.1687, val_MinusLogProbMetric: 4.1687

Epoch 92: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1186 - MinusLogProbMetric: 4.1186 - val_loss: 4.1687 - val_MinusLogProbMetric: 4.1687 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-12 00:46:40.513 
Epoch 93/1000 
	 loss: 4.1252, MinusLogProbMetric: 4.1252, val_loss: 4.1528, val_MinusLogProbMetric: 4.1528

Epoch 93: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1252 - MinusLogProbMetric: 4.1252 - val_loss: 4.1528 - val_MinusLogProbMetric: 4.1528 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-12 00:46:52.184 
Epoch 94/1000 
	 loss: 4.1174, MinusLogProbMetric: 4.1174, val_loss: 4.1689, val_MinusLogProbMetric: 4.1689

Epoch 94: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1174 - MinusLogProbMetric: 4.1174 - val_loss: 4.1689 - val_MinusLogProbMetric: 4.1689 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-12 00:47:03.813 
Epoch 95/1000 
	 loss: 4.1297, MinusLogProbMetric: 4.1297, val_loss: 4.1602, val_MinusLogProbMetric: 4.1602

Epoch 95: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1297 - MinusLogProbMetric: 4.1297 - val_loss: 4.1602 - val_MinusLogProbMetric: 4.1602 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 96/1000
2023-09-12 00:47:15.675 
Epoch 96/1000 
	 loss: 4.1211, MinusLogProbMetric: 4.1211, val_loss: 4.1247, val_MinusLogProbMetric: 4.1247

Epoch 96: val_loss did not improve from 4.12030
196/196 - 12s - loss: 4.1211 - MinusLogProbMetric: 4.1211 - val_loss: 4.1247 - val_MinusLogProbMetric: 4.1247 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 97/1000
2023-09-12 00:47:27.341 
Epoch 97/1000 
	 loss: 4.1291, MinusLogProbMetric: 4.1291, val_loss: 4.1160, val_MinusLogProbMetric: 4.1160

Epoch 97: val_loss improved from 4.12030 to 4.11604, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1291 - MinusLogProbMetric: 4.1291 - val_loss: 4.1160 - val_MinusLogProbMetric: 4.1160 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 98/1000
2023-09-12 00:47:39.134 
Epoch 98/1000 
	 loss: 4.1145, MinusLogProbMetric: 4.1145, val_loss: 4.1736, val_MinusLogProbMetric: 4.1736

Epoch 98: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1145 - MinusLogProbMetric: 4.1145 - val_loss: 4.1736 - val_MinusLogProbMetric: 4.1736 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 99/1000
2023-09-12 00:47:50.751 
Epoch 99/1000 
	 loss: 4.1274, MinusLogProbMetric: 4.1274, val_loss: 4.1289, val_MinusLogProbMetric: 4.1289

Epoch 99: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1274 - MinusLogProbMetric: 4.1274 - val_loss: 4.1289 - val_MinusLogProbMetric: 4.1289 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 00:48:02.439 
Epoch 100/1000 
	 loss: 4.1139, MinusLogProbMetric: 4.1139, val_loss: 4.1277, val_MinusLogProbMetric: 4.1277

Epoch 100: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1139 - MinusLogProbMetric: 4.1139 - val_loss: 4.1277 - val_MinusLogProbMetric: 4.1277 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-12 00:48:14.061 
Epoch 101/1000 
	 loss: 4.1118, MinusLogProbMetric: 4.1118, val_loss: 4.1176, val_MinusLogProbMetric: 4.1176

Epoch 101: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1118 - MinusLogProbMetric: 4.1118 - val_loss: 4.1176 - val_MinusLogProbMetric: 4.1176 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 102/1000
2023-09-12 00:48:25.659 
Epoch 102/1000 
	 loss: 4.1144, MinusLogProbMetric: 4.1144, val_loss: 4.1219, val_MinusLogProbMetric: 4.1219

Epoch 102: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1144 - MinusLogProbMetric: 4.1144 - val_loss: 4.1219 - val_MinusLogProbMetric: 4.1219 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 103/1000
2023-09-12 00:48:37.277 
Epoch 103/1000 
	 loss: 4.1127, MinusLogProbMetric: 4.1127, val_loss: 4.1272, val_MinusLogProbMetric: 4.1272

Epoch 103: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1127 - MinusLogProbMetric: 4.1127 - val_loss: 4.1272 - val_MinusLogProbMetric: 4.1272 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 104/1000
2023-09-12 00:48:48.874 
Epoch 104/1000 
	 loss: 4.1124, MinusLogProbMetric: 4.1124, val_loss: 4.1180, val_MinusLogProbMetric: 4.1180

Epoch 104: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1124 - MinusLogProbMetric: 4.1124 - val_loss: 4.1180 - val_MinusLogProbMetric: 4.1180 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 105/1000
2023-09-12 00:49:00.615 
Epoch 105/1000 
	 loss: 4.1236, MinusLogProbMetric: 4.1236, val_loss: 4.1346, val_MinusLogProbMetric: 4.1346

Epoch 105: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1236 - MinusLogProbMetric: 4.1236 - val_loss: 4.1346 - val_MinusLogProbMetric: 4.1346 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-12 00:49:12.305 
Epoch 106/1000 
	 loss: 4.1119, MinusLogProbMetric: 4.1119, val_loss: 4.1229, val_MinusLogProbMetric: 4.1229

Epoch 106: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1119 - MinusLogProbMetric: 4.1119 - val_loss: 4.1229 - val_MinusLogProbMetric: 4.1229 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 107/1000
2023-09-12 00:49:23.947 
Epoch 107/1000 
	 loss: 4.1162, MinusLogProbMetric: 4.1162, val_loss: 4.1605, val_MinusLogProbMetric: 4.1605

Epoch 107: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1162 - MinusLogProbMetric: 4.1162 - val_loss: 4.1605 - val_MinusLogProbMetric: 4.1605 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 108/1000
2023-09-12 00:49:35.564 
Epoch 108/1000 
	 loss: 4.1188, MinusLogProbMetric: 4.1188, val_loss: 4.1329, val_MinusLogProbMetric: 4.1329

Epoch 108: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1188 - MinusLogProbMetric: 4.1188 - val_loss: 4.1329 - val_MinusLogProbMetric: 4.1329 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 109/1000
2023-09-12 00:49:47.364 
Epoch 109/1000 
	 loss: 4.1181, MinusLogProbMetric: 4.1181, val_loss: 4.1309, val_MinusLogProbMetric: 4.1309

Epoch 109: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1181 - MinusLogProbMetric: 4.1181 - val_loss: 4.1309 - val_MinusLogProbMetric: 4.1309 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 110/1000
2023-09-12 00:49:59.098 
Epoch 110/1000 
	 loss: 4.1101, MinusLogProbMetric: 4.1101, val_loss: 4.1375, val_MinusLogProbMetric: 4.1375

Epoch 110: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1101 - MinusLogProbMetric: 4.1101 - val_loss: 4.1375 - val_MinusLogProbMetric: 4.1375 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 111/1000
2023-09-12 00:50:10.845 
Epoch 111/1000 
	 loss: 4.1198, MinusLogProbMetric: 4.1198, val_loss: 4.1467, val_MinusLogProbMetric: 4.1467

Epoch 111: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1198 - MinusLogProbMetric: 4.1198 - val_loss: 4.1467 - val_MinusLogProbMetric: 4.1467 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-12 00:50:22.500 
Epoch 112/1000 
	 loss: 4.1172, MinusLogProbMetric: 4.1172, val_loss: 4.1315, val_MinusLogProbMetric: 4.1315

Epoch 112: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1172 - MinusLogProbMetric: 4.1172 - val_loss: 4.1315 - val_MinusLogProbMetric: 4.1315 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 113/1000
2023-09-12 00:50:34.239 
Epoch 113/1000 
	 loss: 4.1201, MinusLogProbMetric: 4.1201, val_loss: 4.1311, val_MinusLogProbMetric: 4.1311

Epoch 113: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1201 - MinusLogProbMetric: 4.1201 - val_loss: 4.1311 - val_MinusLogProbMetric: 4.1311 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-12 00:50:45.940 
Epoch 114/1000 
	 loss: 4.1204, MinusLogProbMetric: 4.1204, val_loss: 4.1362, val_MinusLogProbMetric: 4.1362

Epoch 114: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1204 - MinusLogProbMetric: 4.1204 - val_loss: 4.1362 - val_MinusLogProbMetric: 4.1362 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 115/1000
2023-09-12 00:50:57.676 
Epoch 115/1000 
	 loss: 4.1102, MinusLogProbMetric: 4.1102, val_loss: 4.1401, val_MinusLogProbMetric: 4.1401

Epoch 115: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1102 - MinusLogProbMetric: 4.1102 - val_loss: 4.1401 - val_MinusLogProbMetric: 4.1401 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 116/1000
2023-09-12 00:51:09.401 
Epoch 116/1000 
	 loss: 4.1089, MinusLogProbMetric: 4.1089, val_loss: 4.1192, val_MinusLogProbMetric: 4.1192

Epoch 116: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1089 - MinusLogProbMetric: 4.1089 - val_loss: 4.1192 - val_MinusLogProbMetric: 4.1192 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 117/1000
2023-09-12 00:51:21.027 
Epoch 117/1000 
	 loss: 4.1086, MinusLogProbMetric: 4.1086, val_loss: 4.2808, val_MinusLogProbMetric: 4.2808

Epoch 117: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1086 - MinusLogProbMetric: 4.1086 - val_loss: 4.2808 - val_MinusLogProbMetric: 4.2808 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 118/1000
2023-09-12 00:51:32.764 
Epoch 118/1000 
	 loss: 4.1154, MinusLogProbMetric: 4.1154, val_loss: 4.1367, val_MinusLogProbMetric: 4.1367

Epoch 118: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1154 - MinusLogProbMetric: 4.1154 - val_loss: 4.1367 - val_MinusLogProbMetric: 4.1367 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-12 00:51:44.528 
Epoch 119/1000 
	 loss: 4.1109, MinusLogProbMetric: 4.1109, val_loss: 4.1182, val_MinusLogProbMetric: 4.1182

Epoch 119: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1109 - MinusLogProbMetric: 4.1109 - val_loss: 4.1182 - val_MinusLogProbMetric: 4.1182 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 120/1000
2023-09-12 00:51:56.284 
Epoch 120/1000 
	 loss: 4.1304, MinusLogProbMetric: 4.1304, val_loss: 4.1305, val_MinusLogProbMetric: 4.1305

Epoch 120: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1304 - MinusLogProbMetric: 4.1304 - val_loss: 4.1305 - val_MinusLogProbMetric: 4.1305 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-12 00:52:07.849 
Epoch 121/1000 
	 loss: 4.1217, MinusLogProbMetric: 4.1217, val_loss: 4.1591, val_MinusLogProbMetric: 4.1591

Epoch 121: val_loss did not improve from 4.11604
196/196 - 12s - loss: 4.1217 - MinusLogProbMetric: 4.1217 - val_loss: 4.1591 - val_MinusLogProbMetric: 4.1591 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 122/1000
2023-09-12 00:52:19.553 
Epoch 122/1000 
	 loss: 4.1118, MinusLogProbMetric: 4.1118, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 122: val_loss improved from 4.11604 to 4.11544, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1118 - MinusLogProbMetric: 4.1118 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-12 00:52:31.363 
Epoch 123/1000 
	 loss: 4.1258, MinusLogProbMetric: 4.1258, val_loss: 4.1295, val_MinusLogProbMetric: 4.1295

Epoch 123: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1258 - MinusLogProbMetric: 4.1258 - val_loss: 4.1295 - val_MinusLogProbMetric: 4.1295 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-12 00:52:43.134 
Epoch 124/1000 
	 loss: 4.1186, MinusLogProbMetric: 4.1186, val_loss: 4.1745, val_MinusLogProbMetric: 4.1745

Epoch 124: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1186 - MinusLogProbMetric: 4.1186 - val_loss: 4.1745 - val_MinusLogProbMetric: 4.1745 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-12 00:52:54.776 
Epoch 125/1000 
	 loss: 4.1223, MinusLogProbMetric: 4.1223, val_loss: 4.1282, val_MinusLogProbMetric: 4.1282

Epoch 125: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1223 - MinusLogProbMetric: 4.1223 - val_loss: 4.1282 - val_MinusLogProbMetric: 4.1282 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 126/1000
2023-09-12 00:53:06.482 
Epoch 126/1000 
	 loss: 4.1149, MinusLogProbMetric: 4.1149, val_loss: 4.1240, val_MinusLogProbMetric: 4.1240

Epoch 126: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1149 - MinusLogProbMetric: 4.1149 - val_loss: 4.1240 - val_MinusLogProbMetric: 4.1240 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-12 00:53:18.162 
Epoch 127/1000 
	 loss: 4.1108, MinusLogProbMetric: 4.1108, val_loss: 4.1362, val_MinusLogProbMetric: 4.1362

Epoch 127: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1108 - MinusLogProbMetric: 4.1108 - val_loss: 4.1362 - val_MinusLogProbMetric: 4.1362 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 128/1000
2023-09-12 00:53:29.906 
Epoch 128/1000 
	 loss: 4.1094, MinusLogProbMetric: 4.1094, val_loss: 4.1288, val_MinusLogProbMetric: 4.1288

Epoch 128: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1094 - MinusLogProbMetric: 4.1094 - val_loss: 4.1288 - val_MinusLogProbMetric: 4.1288 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-12 00:53:41.561 
Epoch 129/1000 
	 loss: 4.1082, MinusLogProbMetric: 4.1082, val_loss: 4.1353, val_MinusLogProbMetric: 4.1353

Epoch 129: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1082 - MinusLogProbMetric: 4.1082 - val_loss: 4.1353 - val_MinusLogProbMetric: 4.1353 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 130/1000
2023-09-12 00:53:53.085 
Epoch 130/1000 
	 loss: 4.1049, MinusLogProbMetric: 4.1049, val_loss: 4.2773, val_MinusLogProbMetric: 4.2773

Epoch 130: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1049 - MinusLogProbMetric: 4.1049 - val_loss: 4.2773 - val_MinusLogProbMetric: 4.2773 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 131/1000
2023-09-12 00:54:04.740 
Epoch 131/1000 
	 loss: 4.1155, MinusLogProbMetric: 4.1155, val_loss: 4.1276, val_MinusLogProbMetric: 4.1276

Epoch 131: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1155 - MinusLogProbMetric: 4.1155 - val_loss: 4.1276 - val_MinusLogProbMetric: 4.1276 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 132/1000
2023-09-12 00:54:16.316 
Epoch 132/1000 
	 loss: 4.1120, MinusLogProbMetric: 4.1120, val_loss: 4.1173, val_MinusLogProbMetric: 4.1173

Epoch 132: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1120 - MinusLogProbMetric: 4.1120 - val_loss: 4.1173 - val_MinusLogProbMetric: 4.1173 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 133/1000
2023-09-12 00:54:28.050 
Epoch 133/1000 
	 loss: 4.1051, MinusLogProbMetric: 4.1051, val_loss: 4.1314, val_MinusLogProbMetric: 4.1314

Epoch 133: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1051 - MinusLogProbMetric: 4.1051 - val_loss: 4.1314 - val_MinusLogProbMetric: 4.1314 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-12 00:54:39.764 
Epoch 134/1000 
	 loss: 4.1043, MinusLogProbMetric: 4.1043, val_loss: 4.1256, val_MinusLogProbMetric: 4.1256

Epoch 134: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1043 - MinusLogProbMetric: 4.1043 - val_loss: 4.1256 - val_MinusLogProbMetric: 4.1256 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-12 00:54:51.606 
Epoch 135/1000 
	 loss: 4.1075, MinusLogProbMetric: 4.1075, val_loss: 4.1354, val_MinusLogProbMetric: 4.1354

Epoch 135: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1075 - MinusLogProbMetric: 4.1075 - val_loss: 4.1354 - val_MinusLogProbMetric: 4.1354 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-12 00:55:03.437 
Epoch 136/1000 
	 loss: 4.1125, MinusLogProbMetric: 4.1125, val_loss: 4.1257, val_MinusLogProbMetric: 4.1257

Epoch 136: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1125 - MinusLogProbMetric: 4.1125 - val_loss: 4.1257 - val_MinusLogProbMetric: 4.1257 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 137/1000
2023-09-12 00:55:14.989 
Epoch 137/1000 
	 loss: 4.1123, MinusLogProbMetric: 4.1123, val_loss: 4.1274, val_MinusLogProbMetric: 4.1274

Epoch 137: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1123 - MinusLogProbMetric: 4.1123 - val_loss: 4.1274 - val_MinusLogProbMetric: 4.1274 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 138/1000
2023-09-12 00:55:26.698 
Epoch 138/1000 
	 loss: 4.1084, MinusLogProbMetric: 4.1084, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 138: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1084 - MinusLogProbMetric: 4.1084 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-12 00:55:38.456 
Epoch 139/1000 
	 loss: 4.1097, MinusLogProbMetric: 4.1097, val_loss: 4.1201, val_MinusLogProbMetric: 4.1201

Epoch 139: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1097 - MinusLogProbMetric: 4.1097 - val_loss: 4.1201 - val_MinusLogProbMetric: 4.1201 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-12 00:55:50.217 
Epoch 140/1000 
	 loss: 4.1136, MinusLogProbMetric: 4.1136, val_loss: 4.1742, val_MinusLogProbMetric: 4.1742

Epoch 140: val_loss did not improve from 4.11544
196/196 - 12s - loss: 4.1136 - MinusLogProbMetric: 4.1136 - val_loss: 4.1742 - val_MinusLogProbMetric: 4.1742 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 141/1000
2023-09-12 00:56:01.955 
Epoch 141/1000 
	 loss: 4.1138, MinusLogProbMetric: 4.1138, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 141: val_loss improved from 4.11544 to 4.11336, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1138 - MinusLogProbMetric: 4.1138 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 142/1000
2023-09-12 00:56:13.795 
Epoch 142/1000 
	 loss: 4.1015, MinusLogProbMetric: 4.1015, val_loss: 4.1322, val_MinusLogProbMetric: 4.1322

Epoch 142: val_loss did not improve from 4.11336
196/196 - 12s - loss: 4.1015 - MinusLogProbMetric: 4.1015 - val_loss: 4.1322 - val_MinusLogProbMetric: 4.1322 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 143/1000
2023-09-12 00:56:25.451 
Epoch 143/1000 
	 loss: 4.1067, MinusLogProbMetric: 4.1067, val_loss: 4.1224, val_MinusLogProbMetric: 4.1224

Epoch 143: val_loss did not improve from 4.11336
196/196 - 12s - loss: 4.1067 - MinusLogProbMetric: 4.1067 - val_loss: 4.1224 - val_MinusLogProbMetric: 4.1224 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 144/1000
2023-09-12 00:56:37.159 
Epoch 144/1000 
	 loss: 4.1028, MinusLogProbMetric: 4.1028, val_loss: 4.1105, val_MinusLogProbMetric: 4.1105

Epoch 144: val_loss improved from 4.11336 to 4.11048, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1028 - MinusLogProbMetric: 4.1028 - val_loss: 4.1105 - val_MinusLogProbMetric: 4.1105 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 145/1000
2023-09-12 00:56:48.838 
Epoch 145/1000 
	 loss: 4.1183, MinusLogProbMetric: 4.1183, val_loss: 4.1256, val_MinusLogProbMetric: 4.1256

Epoch 145: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1183 - MinusLogProbMetric: 4.1183 - val_loss: 4.1256 - val_MinusLogProbMetric: 4.1256 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 146/1000
2023-09-12 00:57:00.602 
Epoch 146/1000 
	 loss: 4.1016, MinusLogProbMetric: 4.1016, val_loss: 4.1318, val_MinusLogProbMetric: 4.1318

Epoch 146: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1016 - MinusLogProbMetric: 4.1016 - val_loss: 4.1318 - val_MinusLogProbMetric: 4.1318 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-12 00:57:12.282 
Epoch 147/1000 
	 loss: 4.1121, MinusLogProbMetric: 4.1121, val_loss: 4.1444, val_MinusLogProbMetric: 4.1444

Epoch 147: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1121 - MinusLogProbMetric: 4.1121 - val_loss: 4.1444 - val_MinusLogProbMetric: 4.1444 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-12 00:57:24.047 
Epoch 148/1000 
	 loss: 4.1030, MinusLogProbMetric: 4.1030, val_loss: 4.1242, val_MinusLogProbMetric: 4.1242

Epoch 148: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1030 - MinusLogProbMetric: 4.1030 - val_loss: 4.1242 - val_MinusLogProbMetric: 4.1242 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-12 00:57:35.710 
Epoch 149/1000 
	 loss: 4.1103, MinusLogProbMetric: 4.1103, val_loss: 4.1150, val_MinusLogProbMetric: 4.1150

Epoch 149: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1103 - MinusLogProbMetric: 4.1103 - val_loss: 4.1150 - val_MinusLogProbMetric: 4.1150 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 150/1000
2023-09-12 00:57:47.415 
Epoch 150/1000 
	 loss: 4.1085, MinusLogProbMetric: 4.1085, val_loss: 4.1335, val_MinusLogProbMetric: 4.1335

Epoch 150: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1085 - MinusLogProbMetric: 4.1085 - val_loss: 4.1335 - val_MinusLogProbMetric: 4.1335 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-12 00:57:59.087 
Epoch 151/1000 
	 loss: 4.1086, MinusLogProbMetric: 4.1086, val_loss: 4.1423, val_MinusLogProbMetric: 4.1423

Epoch 151: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1086 - MinusLogProbMetric: 4.1086 - val_loss: 4.1423 - val_MinusLogProbMetric: 4.1423 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-12 00:58:10.818 
Epoch 152/1000 
	 loss: 4.1101, MinusLogProbMetric: 4.1101, val_loss: 4.1244, val_MinusLogProbMetric: 4.1244

Epoch 152: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1101 - MinusLogProbMetric: 4.1101 - val_loss: 4.1244 - val_MinusLogProbMetric: 4.1244 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-12 00:58:22.419 
Epoch 153/1000 
	 loss: 4.1042, MinusLogProbMetric: 4.1042, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 153: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1042 - MinusLogProbMetric: 4.1042 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-12 00:58:34.177 
Epoch 154/1000 
	 loss: 4.1034, MinusLogProbMetric: 4.1034, val_loss: 4.1226, val_MinusLogProbMetric: 4.1226

Epoch 154: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1034 - MinusLogProbMetric: 4.1034 - val_loss: 4.1226 - val_MinusLogProbMetric: 4.1226 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 155/1000
2023-09-12 00:58:45.825 
Epoch 155/1000 
	 loss: 4.1028, MinusLogProbMetric: 4.1028, val_loss: 4.1363, val_MinusLogProbMetric: 4.1363

Epoch 155: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1028 - MinusLogProbMetric: 4.1028 - val_loss: 4.1363 - val_MinusLogProbMetric: 4.1363 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 156/1000
2023-09-12 00:58:57.508 
Epoch 156/1000 
	 loss: 4.1021, MinusLogProbMetric: 4.1021, val_loss: 4.1314, val_MinusLogProbMetric: 4.1314

Epoch 156: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1021 - MinusLogProbMetric: 4.1021 - val_loss: 4.1314 - val_MinusLogProbMetric: 4.1314 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 157/1000
2023-09-12 00:59:09.196 
Epoch 157/1000 
	 loss: 4.1069, MinusLogProbMetric: 4.1069, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 157: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1069 - MinusLogProbMetric: 4.1069 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-12 00:59:20.862 
Epoch 158/1000 
	 loss: 4.1072, MinusLogProbMetric: 4.1072, val_loss: 4.1303, val_MinusLogProbMetric: 4.1303

Epoch 158: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1072 - MinusLogProbMetric: 4.1072 - val_loss: 4.1303 - val_MinusLogProbMetric: 4.1303 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 159/1000
2023-09-12 00:59:32.538 
Epoch 159/1000 
	 loss: 4.1025, MinusLogProbMetric: 4.1025, val_loss: 4.1250, val_MinusLogProbMetric: 4.1250

Epoch 159: val_loss did not improve from 4.11048
196/196 - 12s - loss: 4.1025 - MinusLogProbMetric: 4.1025 - val_loss: 4.1250 - val_MinusLogProbMetric: 4.1250 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-12 00:59:44.209 
Epoch 160/1000 
	 loss: 4.1027, MinusLogProbMetric: 4.1027, val_loss: 4.1099, val_MinusLogProbMetric: 4.1099

Epoch 160: val_loss improved from 4.11048 to 4.10991, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1027 - MinusLogProbMetric: 4.1027 - val_loss: 4.1099 - val_MinusLogProbMetric: 4.1099 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 161/1000
2023-09-12 00:59:55.998 
Epoch 161/1000 
	 loss: 4.1049, MinusLogProbMetric: 4.1049, val_loss: 4.1250, val_MinusLogProbMetric: 4.1250

Epoch 161: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1049 - MinusLogProbMetric: 4.1049 - val_loss: 4.1250 - val_MinusLogProbMetric: 4.1250 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 162/1000
2023-09-12 01:00:07.618 
Epoch 162/1000 
	 loss: 4.1036, MinusLogProbMetric: 4.1036, val_loss: 4.1215, val_MinusLogProbMetric: 4.1215

Epoch 162: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1036 - MinusLogProbMetric: 4.1036 - val_loss: 4.1215 - val_MinusLogProbMetric: 4.1215 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 163/1000
2023-09-12 01:00:18.297 
Epoch 163/1000 
	 loss: 4.0998, MinusLogProbMetric: 4.0998, val_loss: 4.1228, val_MinusLogProbMetric: 4.1228

Epoch 163: val_loss did not improve from 4.10991
196/196 - 11s - loss: 4.0998 - MinusLogProbMetric: 4.0998 - val_loss: 4.1228 - val_MinusLogProbMetric: 4.1228 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 164/1000
2023-09-12 01:00:29.802 
Epoch 164/1000 
	 loss: 4.1037, MinusLogProbMetric: 4.1037, val_loss: 4.1566, val_MinusLogProbMetric: 4.1566

Epoch 164: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1037 - MinusLogProbMetric: 4.1037 - val_loss: 4.1566 - val_MinusLogProbMetric: 4.1566 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-12 01:00:41.366 
Epoch 165/1000 
	 loss: 4.1068, MinusLogProbMetric: 4.1068, val_loss: 4.1315, val_MinusLogProbMetric: 4.1315

Epoch 165: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1068 - MinusLogProbMetric: 4.1068 - val_loss: 4.1315 - val_MinusLogProbMetric: 4.1315 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 166/1000
2023-09-12 01:00:52.384 
Epoch 166/1000 
	 loss: 4.1052, MinusLogProbMetric: 4.1052, val_loss: 4.1163, val_MinusLogProbMetric: 4.1163

Epoch 166: val_loss did not improve from 4.10991
196/196 - 11s - loss: 4.1052 - MinusLogProbMetric: 4.1052 - val_loss: 4.1163 - val_MinusLogProbMetric: 4.1163 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 167/1000
2023-09-12 01:01:03.858 
Epoch 167/1000 
	 loss: 4.1043, MinusLogProbMetric: 4.1043, val_loss: 4.1161, val_MinusLogProbMetric: 4.1161

Epoch 167: val_loss did not improve from 4.10991
196/196 - 11s - loss: 4.1043 - MinusLogProbMetric: 4.1043 - val_loss: 4.1161 - val_MinusLogProbMetric: 4.1161 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 168/1000
2023-09-12 01:01:15.585 
Epoch 168/1000 
	 loss: 4.1003, MinusLogProbMetric: 4.1003, val_loss: 4.2076, val_MinusLogProbMetric: 4.2076

Epoch 168: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1003 - MinusLogProbMetric: 4.1003 - val_loss: 4.2076 - val_MinusLogProbMetric: 4.2076 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-12 01:01:27.228 
Epoch 169/1000 
	 loss: 4.1317, MinusLogProbMetric: 4.1317, val_loss: 4.1256, val_MinusLogProbMetric: 4.1256

Epoch 169: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1317 - MinusLogProbMetric: 4.1317 - val_loss: 4.1256 - val_MinusLogProbMetric: 4.1256 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 170/1000
2023-09-12 01:01:38.887 
Epoch 170/1000 
	 loss: 4.0978, MinusLogProbMetric: 4.0978, val_loss: 4.1145, val_MinusLogProbMetric: 4.1145

Epoch 170: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.0978 - MinusLogProbMetric: 4.0978 - val_loss: 4.1145 - val_MinusLogProbMetric: 4.1145 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 171/1000
2023-09-12 01:01:50.520 
Epoch 171/1000 
	 loss: 4.1032, MinusLogProbMetric: 4.1032, val_loss: 4.1378, val_MinusLogProbMetric: 4.1378

Epoch 171: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1032 - MinusLogProbMetric: 4.1032 - val_loss: 4.1378 - val_MinusLogProbMetric: 4.1378 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 172/1000
2023-09-12 01:02:02.178 
Epoch 172/1000 
	 loss: 4.1018, MinusLogProbMetric: 4.1018, val_loss: 4.1186, val_MinusLogProbMetric: 4.1186

Epoch 172: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1018 - MinusLogProbMetric: 4.1018 - val_loss: 4.1186 - val_MinusLogProbMetric: 4.1186 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 01:02:13.829 
Epoch 173/1000 
	 loss: 4.1064, MinusLogProbMetric: 4.1064, val_loss: 4.1191, val_MinusLogProbMetric: 4.1191

Epoch 173: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1064 - MinusLogProbMetric: 4.1064 - val_loss: 4.1191 - val_MinusLogProbMetric: 4.1191 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 174/1000
2023-09-12 01:02:25.442 
Epoch 174/1000 
	 loss: 4.0994, MinusLogProbMetric: 4.0994, val_loss: 4.1274, val_MinusLogProbMetric: 4.1274

Epoch 174: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.0994 - MinusLogProbMetric: 4.0994 - val_loss: 4.1274 - val_MinusLogProbMetric: 4.1274 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 175/1000
2023-09-12 01:02:37.041 
Epoch 175/1000 
	 loss: 4.0986, MinusLogProbMetric: 4.0986, val_loss: 4.1911, val_MinusLogProbMetric: 4.1911

Epoch 175: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.0986 - MinusLogProbMetric: 4.0986 - val_loss: 4.1911 - val_MinusLogProbMetric: 4.1911 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-12 01:02:48.792 
Epoch 176/1000 
	 loss: 4.1223, MinusLogProbMetric: 4.1223, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 176: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1223 - MinusLogProbMetric: 4.1223 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-12 01:03:00.420 
Epoch 177/1000 
	 loss: 4.1016, MinusLogProbMetric: 4.1016, val_loss: 4.1506, val_MinusLogProbMetric: 4.1506

Epoch 177: val_loss did not improve from 4.10991
196/196 - 12s - loss: 4.1016 - MinusLogProbMetric: 4.1016 - val_loss: 4.1506 - val_MinusLogProbMetric: 4.1506 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 178/1000
2023-09-12 01:03:12.073 
Epoch 178/1000 
	 loss: 4.1035, MinusLogProbMetric: 4.1035, val_loss: 4.1097, val_MinusLogProbMetric: 4.1097

Epoch 178: val_loss improved from 4.10991 to 4.10972, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1035 - MinusLogProbMetric: 4.1035 - val_loss: 4.1097 - val_MinusLogProbMetric: 4.1097 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-12 01:03:23.901 
Epoch 179/1000 
	 loss: 4.1050, MinusLogProbMetric: 4.1050, val_loss: 4.1416, val_MinusLogProbMetric: 4.1416

Epoch 179: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1050 - MinusLogProbMetric: 4.1050 - val_loss: 4.1416 - val_MinusLogProbMetric: 4.1416 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 180/1000
2023-09-12 01:03:35.612 
Epoch 180/1000 
	 loss: 4.0992, MinusLogProbMetric: 4.0992, val_loss: 4.1338, val_MinusLogProbMetric: 4.1338

Epoch 180: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0992 - MinusLogProbMetric: 4.0992 - val_loss: 4.1338 - val_MinusLogProbMetric: 4.1338 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 181/1000
2023-09-12 01:03:47.391 
Epoch 181/1000 
	 loss: 4.0975, MinusLogProbMetric: 4.0975, val_loss: 4.1331, val_MinusLogProbMetric: 4.1331

Epoch 181: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0975 - MinusLogProbMetric: 4.0975 - val_loss: 4.1331 - val_MinusLogProbMetric: 4.1331 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 182/1000
2023-09-12 01:03:59.059 
Epoch 182/1000 
	 loss: 4.0993, MinusLogProbMetric: 4.0993, val_loss: 4.1335, val_MinusLogProbMetric: 4.1335

Epoch 182: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0993 - MinusLogProbMetric: 4.0993 - val_loss: 4.1335 - val_MinusLogProbMetric: 4.1335 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 183/1000
2023-09-12 01:04:10.727 
Epoch 183/1000 
	 loss: 4.1025, MinusLogProbMetric: 4.1025, val_loss: 4.1109, val_MinusLogProbMetric: 4.1109

Epoch 183: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1025 - MinusLogProbMetric: 4.1025 - val_loss: 4.1109 - val_MinusLogProbMetric: 4.1109 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 184/1000
2023-09-12 01:04:22.441 
Epoch 184/1000 
	 loss: 4.1039, MinusLogProbMetric: 4.1039, val_loss: 4.1582, val_MinusLogProbMetric: 4.1582

Epoch 184: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1039 - MinusLogProbMetric: 4.1039 - val_loss: 4.1582 - val_MinusLogProbMetric: 4.1582 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 185/1000
2023-09-12 01:04:34.105 
Epoch 185/1000 
	 loss: 4.1004, MinusLogProbMetric: 4.1004, val_loss: 4.1758, val_MinusLogProbMetric: 4.1758

Epoch 185: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1004 - MinusLogProbMetric: 4.1004 - val_loss: 4.1758 - val_MinusLogProbMetric: 4.1758 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 186/1000
2023-09-12 01:04:45.768 
Epoch 186/1000 
	 loss: 4.1024, MinusLogProbMetric: 4.1024, val_loss: 4.1477, val_MinusLogProbMetric: 4.1477

Epoch 186: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1024 - MinusLogProbMetric: 4.1024 - val_loss: 4.1477 - val_MinusLogProbMetric: 4.1477 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 187/1000
2023-09-12 01:04:57.478 
Epoch 187/1000 
	 loss: 4.0961, MinusLogProbMetric: 4.0961, val_loss: 4.1704, val_MinusLogProbMetric: 4.1704

Epoch 187: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0961 - MinusLogProbMetric: 4.0961 - val_loss: 4.1704 - val_MinusLogProbMetric: 4.1704 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 188/1000
2023-09-12 01:05:09.138 
Epoch 188/1000 
	 loss: 4.1042, MinusLogProbMetric: 4.1042, val_loss: 4.1214, val_MinusLogProbMetric: 4.1214

Epoch 188: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1042 - MinusLogProbMetric: 4.1042 - val_loss: 4.1214 - val_MinusLogProbMetric: 4.1214 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 189/1000
2023-09-12 01:05:20.731 
Epoch 189/1000 
	 loss: 4.1055, MinusLogProbMetric: 4.1055, val_loss: 4.1392, val_MinusLogProbMetric: 4.1392

Epoch 189: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1055 - MinusLogProbMetric: 4.1055 - val_loss: 4.1392 - val_MinusLogProbMetric: 4.1392 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 190/1000
2023-09-12 01:05:32.523 
Epoch 190/1000 
	 loss: 4.1158, MinusLogProbMetric: 4.1158, val_loss: 4.1310, val_MinusLogProbMetric: 4.1310

Epoch 190: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1158 - MinusLogProbMetric: 4.1158 - val_loss: 4.1310 - val_MinusLogProbMetric: 4.1310 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-12 01:05:44.191 
Epoch 191/1000 
	 loss: 4.0973, MinusLogProbMetric: 4.0973, val_loss: 4.1453, val_MinusLogProbMetric: 4.1453

Epoch 191: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0973 - MinusLogProbMetric: 4.0973 - val_loss: 4.1453 - val_MinusLogProbMetric: 4.1453 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 192/1000
2023-09-12 01:05:55.913 
Epoch 192/1000 
	 loss: 4.1030, MinusLogProbMetric: 4.1030, val_loss: 4.1200, val_MinusLogProbMetric: 4.1200

Epoch 192: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1030 - MinusLogProbMetric: 4.1030 - val_loss: 4.1200 - val_MinusLogProbMetric: 4.1200 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-12 01:06:07.528 
Epoch 193/1000 
	 loss: 4.0989, MinusLogProbMetric: 4.0989, val_loss: 4.1323, val_MinusLogProbMetric: 4.1323

Epoch 193: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0989 - MinusLogProbMetric: 4.0989 - val_loss: 4.1323 - val_MinusLogProbMetric: 4.1323 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 194/1000
2023-09-12 01:06:19.289 
Epoch 194/1000 
	 loss: 4.1135, MinusLogProbMetric: 4.1135, val_loss: 4.1238, val_MinusLogProbMetric: 4.1238

Epoch 194: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1135 - MinusLogProbMetric: 4.1135 - val_loss: 4.1238 - val_MinusLogProbMetric: 4.1238 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 195/1000
2023-09-12 01:06:31.096 
Epoch 195/1000 
	 loss: 4.1021, MinusLogProbMetric: 4.1021, val_loss: 4.1268, val_MinusLogProbMetric: 4.1268

Epoch 195: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1021 - MinusLogProbMetric: 4.1021 - val_loss: 4.1268 - val_MinusLogProbMetric: 4.1268 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-12 01:06:42.793 
Epoch 196/1000 
	 loss: 4.0976, MinusLogProbMetric: 4.0976, val_loss: 4.1305, val_MinusLogProbMetric: 4.1305

Epoch 196: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0976 - MinusLogProbMetric: 4.0976 - val_loss: 4.1305 - val_MinusLogProbMetric: 4.1305 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-12 01:06:54.507 
Epoch 197/1000 
	 loss: 4.0968, MinusLogProbMetric: 4.0968, val_loss: 4.1106, val_MinusLogProbMetric: 4.1106

Epoch 197: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.0968 - MinusLogProbMetric: 4.0968 - val_loss: 4.1106 - val_MinusLogProbMetric: 4.1106 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-12 01:07:06.148 
Epoch 198/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.1141, val_MinusLogProbMetric: 4.1141

Epoch 198: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.1141 - val_MinusLogProbMetric: 4.1141 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 199/1000
2023-09-12 01:07:17.854 
Epoch 199/1000 
	 loss: 4.1178, MinusLogProbMetric: 4.1178, val_loss: 4.1515, val_MinusLogProbMetric: 4.1515

Epoch 199: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1178 - MinusLogProbMetric: 4.1178 - val_loss: 4.1515 - val_MinusLogProbMetric: 4.1515 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-12 01:07:29.575 
Epoch 200/1000 
	 loss: 4.1088, MinusLogProbMetric: 4.1088, val_loss: 4.1176, val_MinusLogProbMetric: 4.1176

Epoch 200: val_loss did not improve from 4.10972
196/196 - 12s - loss: 4.1088 - MinusLogProbMetric: 4.1088 - val_loss: 4.1176 - val_MinusLogProbMetric: 4.1176 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-12 01:07:41.266 
Epoch 201/1000 
	 loss: 4.1056, MinusLogProbMetric: 4.1056, val_loss: 4.1096, val_MinusLogProbMetric: 4.1096

Epoch 201: val_loss improved from 4.10972 to 4.10961, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.1056 - MinusLogProbMetric: 4.1056 - val_loss: 4.1096 - val_MinusLogProbMetric: 4.1096 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-12 01:07:53.045 
Epoch 202/1000 
	 loss: 4.1064, MinusLogProbMetric: 4.1064, val_loss: 4.1408, val_MinusLogProbMetric: 4.1408

Epoch 202: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.1064 - MinusLogProbMetric: 4.1064 - val_loss: 4.1408 - val_MinusLogProbMetric: 4.1408 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 203/1000
2023-09-12 01:08:04.957 
Epoch 203/1000 
	 loss: 4.1019, MinusLogProbMetric: 4.1019, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 203: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.1019 - MinusLogProbMetric: 4.1019 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 204/1000
2023-09-12 01:08:15.174 
Epoch 204/1000 
	 loss: 4.0992, MinusLogProbMetric: 4.0992, val_loss: 4.1201, val_MinusLogProbMetric: 4.1201

Epoch 204: val_loss did not improve from 4.10961
196/196 - 10s - loss: 4.0992 - MinusLogProbMetric: 4.0992 - val_loss: 4.1201 - val_MinusLogProbMetric: 4.1201 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 205/1000
2023-09-12 01:08:25.161 
Epoch 205/1000 
	 loss: 4.0964, MinusLogProbMetric: 4.0964, val_loss: 4.1133, val_MinusLogProbMetric: 4.1133

Epoch 205: val_loss did not improve from 4.10961
196/196 - 10s - loss: 4.0964 - MinusLogProbMetric: 4.0964 - val_loss: 4.1133 - val_MinusLogProbMetric: 4.1133 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 206/1000
2023-09-12 01:08:35.701 
Epoch 206/1000 
	 loss: 4.0996, MinusLogProbMetric: 4.0996, val_loss: 4.1192, val_MinusLogProbMetric: 4.1192

Epoch 206: val_loss did not improve from 4.10961
196/196 - 11s - loss: 4.0996 - MinusLogProbMetric: 4.0996 - val_loss: 4.1192 - val_MinusLogProbMetric: 4.1192 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 207/1000
2023-09-12 01:08:46.418 
Epoch 207/1000 
	 loss: 4.0984, MinusLogProbMetric: 4.0984, val_loss: 4.1182, val_MinusLogProbMetric: 4.1182

Epoch 207: val_loss did not improve from 4.10961
196/196 - 11s - loss: 4.0984 - MinusLogProbMetric: 4.0984 - val_loss: 4.1182 - val_MinusLogProbMetric: 4.1182 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 208/1000
2023-09-12 01:08:56.972 
Epoch 208/1000 
	 loss: 4.1002, MinusLogProbMetric: 4.1002, val_loss: 4.1234, val_MinusLogProbMetric: 4.1234

Epoch 208: val_loss did not improve from 4.10961
196/196 - 11s - loss: 4.1002 - MinusLogProbMetric: 4.1002 - val_loss: 4.1234 - val_MinusLogProbMetric: 4.1234 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 209/1000
2023-09-12 01:09:07.746 
Epoch 209/1000 
	 loss: 4.1058, MinusLogProbMetric: 4.1058, val_loss: 4.1248, val_MinusLogProbMetric: 4.1248

Epoch 209: val_loss did not improve from 4.10961
196/196 - 11s - loss: 4.1058 - MinusLogProbMetric: 4.1058 - val_loss: 4.1248 - val_MinusLogProbMetric: 4.1248 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 210/1000
2023-09-12 01:09:19.038 
Epoch 210/1000 
	 loss: 4.1069, MinusLogProbMetric: 4.1069, val_loss: 4.1268, val_MinusLogProbMetric: 4.1268

Epoch 210: val_loss did not improve from 4.10961
196/196 - 11s - loss: 4.1069 - MinusLogProbMetric: 4.1069 - val_loss: 4.1268 - val_MinusLogProbMetric: 4.1268 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 211/1000
2023-09-12 01:09:30.612 
Epoch 211/1000 
	 loss: 4.0946, MinusLogProbMetric: 4.0946, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 211: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.0946 - MinusLogProbMetric: 4.0946 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 212/1000
2023-09-12 01:09:42.230 
Epoch 212/1000 
	 loss: 4.0925, MinusLogProbMetric: 4.0925, val_loss: 4.1263, val_MinusLogProbMetric: 4.1263

Epoch 212: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.0925 - MinusLogProbMetric: 4.0925 - val_loss: 4.1263 - val_MinusLogProbMetric: 4.1263 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 213/1000
2023-09-12 01:09:53.944 
Epoch 213/1000 
	 loss: 4.1154, MinusLogProbMetric: 4.1154, val_loss: 4.1531, val_MinusLogProbMetric: 4.1531

Epoch 213: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.1154 - MinusLogProbMetric: 4.1154 - val_loss: 4.1531 - val_MinusLogProbMetric: 4.1531 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 214/1000
2023-09-12 01:10:05.522 
Epoch 214/1000 
	 loss: 4.1027, MinusLogProbMetric: 4.1027, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 214: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.1027 - MinusLogProbMetric: 4.1027 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 215/1000
2023-09-12 01:10:17.183 
Epoch 215/1000 
	 loss: 4.0980, MinusLogProbMetric: 4.0980, val_loss: 4.1235, val_MinusLogProbMetric: 4.1235

Epoch 215: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.0980 - MinusLogProbMetric: 4.0980 - val_loss: 4.1235 - val_MinusLogProbMetric: 4.1235 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 216/1000
2023-09-12 01:10:28.773 
Epoch 216/1000 
	 loss: 4.0990, MinusLogProbMetric: 4.0990, val_loss: 4.1205, val_MinusLogProbMetric: 4.1205

Epoch 216: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.0990 - MinusLogProbMetric: 4.0990 - val_loss: 4.1205 - val_MinusLogProbMetric: 4.1205 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 217/1000
2023-09-12 01:10:40.417 
Epoch 217/1000 
	 loss: 4.1063, MinusLogProbMetric: 4.1063, val_loss: 4.1138, val_MinusLogProbMetric: 4.1138

Epoch 217: val_loss did not improve from 4.10961
196/196 - 12s - loss: 4.1063 - MinusLogProbMetric: 4.1063 - val_loss: 4.1138 - val_MinusLogProbMetric: 4.1138 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 218/1000
2023-09-12 01:10:51.959 
Epoch 218/1000 
	 loss: 4.0971, MinusLogProbMetric: 4.0971, val_loss: 4.1079, val_MinusLogProbMetric: 4.1079

Epoch 218: val_loss improved from 4.10961 to 4.10786, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0971 - MinusLogProbMetric: 4.0971 - val_loss: 4.1079 - val_MinusLogProbMetric: 4.1079 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-12 01:11:03.857 
Epoch 219/1000 
	 loss: 4.0940, MinusLogProbMetric: 4.0940, val_loss: 4.1157, val_MinusLogProbMetric: 4.1157

Epoch 219: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0940 - MinusLogProbMetric: 4.0940 - val_loss: 4.1157 - val_MinusLogProbMetric: 4.1157 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 220/1000
2023-09-12 01:11:15.522 
Epoch 220/1000 
	 loss: 4.0933, MinusLogProbMetric: 4.0933, val_loss: 4.1103, val_MinusLogProbMetric: 4.1103

Epoch 220: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0933 - MinusLogProbMetric: 4.0933 - val_loss: 4.1103 - val_MinusLogProbMetric: 4.1103 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 221/1000
2023-09-12 01:11:27.193 
Epoch 221/1000 
	 loss: 4.0993, MinusLogProbMetric: 4.0993, val_loss: 4.1255, val_MinusLogProbMetric: 4.1255

Epoch 221: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0993 - MinusLogProbMetric: 4.0993 - val_loss: 4.1255 - val_MinusLogProbMetric: 4.1255 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-12 01:11:38.938 
Epoch 222/1000 
	 loss: 4.0939, MinusLogProbMetric: 4.0939, val_loss: 4.1656, val_MinusLogProbMetric: 4.1656

Epoch 222: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0939 - MinusLogProbMetric: 4.0939 - val_loss: 4.1656 - val_MinusLogProbMetric: 4.1656 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-12 01:11:50.511 
Epoch 223/1000 
	 loss: 4.0946, MinusLogProbMetric: 4.0946, val_loss: 4.1198, val_MinusLogProbMetric: 4.1198

Epoch 223: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0946 - MinusLogProbMetric: 4.0946 - val_loss: 4.1198 - val_MinusLogProbMetric: 4.1198 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 224/1000
2023-09-12 01:12:02.198 
Epoch 224/1000 
	 loss: 4.0883, MinusLogProbMetric: 4.0883, val_loss: 4.1220, val_MinusLogProbMetric: 4.1220

Epoch 224: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0883 - MinusLogProbMetric: 4.0883 - val_loss: 4.1220 - val_MinusLogProbMetric: 4.1220 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-12 01:12:13.832 
Epoch 225/1000 
	 loss: 4.0941, MinusLogProbMetric: 4.0941, val_loss: 4.1359, val_MinusLogProbMetric: 4.1359

Epoch 225: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0941 - MinusLogProbMetric: 4.0941 - val_loss: 4.1359 - val_MinusLogProbMetric: 4.1359 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 226/1000
2023-09-12 01:12:25.411 
Epoch 226/1000 
	 loss: 4.0948, MinusLogProbMetric: 4.0948, val_loss: 4.1168, val_MinusLogProbMetric: 4.1168

Epoch 226: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0948 - MinusLogProbMetric: 4.0948 - val_loss: 4.1168 - val_MinusLogProbMetric: 4.1168 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 227/1000
2023-09-12 01:12:37.059 
Epoch 227/1000 
	 loss: 4.0941, MinusLogProbMetric: 4.0941, val_loss: 4.1156, val_MinusLogProbMetric: 4.1156

Epoch 227: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0941 - MinusLogProbMetric: 4.0941 - val_loss: 4.1156 - val_MinusLogProbMetric: 4.1156 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-12 01:12:48.664 
Epoch 228/1000 
	 loss: 4.0950, MinusLogProbMetric: 4.0950, val_loss: 4.1615, val_MinusLogProbMetric: 4.1615

Epoch 228: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0950 - MinusLogProbMetric: 4.0950 - val_loss: 4.1615 - val_MinusLogProbMetric: 4.1615 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 229/1000
2023-09-12 01:13:00.478 
Epoch 229/1000 
	 loss: 4.0977, MinusLogProbMetric: 4.0977, val_loss: 4.1705, val_MinusLogProbMetric: 4.1705

Epoch 229: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0977 - MinusLogProbMetric: 4.0977 - val_loss: 4.1705 - val_MinusLogProbMetric: 4.1705 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-12 01:13:12.153 
Epoch 230/1000 
	 loss: 4.0983, MinusLogProbMetric: 4.0983, val_loss: 4.1361, val_MinusLogProbMetric: 4.1361

Epoch 230: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0983 - MinusLogProbMetric: 4.0983 - val_loss: 4.1361 - val_MinusLogProbMetric: 4.1361 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 231/1000
2023-09-12 01:13:23.801 
Epoch 231/1000 
	 loss: 4.0911, MinusLogProbMetric: 4.0911, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 231: val_loss did not improve from 4.10786
196/196 - 12s - loss: 4.0911 - MinusLogProbMetric: 4.0911 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 232/1000
2023-09-12 01:13:35.411 
Epoch 232/1000 
	 loss: 4.0920, MinusLogProbMetric: 4.0920, val_loss: 4.1072, val_MinusLogProbMetric: 4.1072

Epoch 232: val_loss improved from 4.10786 to 4.10719, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0920 - MinusLogProbMetric: 4.0920 - val_loss: 4.1072 - val_MinusLogProbMetric: 4.1072 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 233/1000
2023-09-12 01:13:47.272 
Epoch 233/1000 
	 loss: 4.1004, MinusLogProbMetric: 4.1004, val_loss: 4.1147, val_MinusLogProbMetric: 4.1147

Epoch 233: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.1004 - MinusLogProbMetric: 4.1004 - val_loss: 4.1147 - val_MinusLogProbMetric: 4.1147 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 234/1000
2023-09-12 01:13:58.979 
Epoch 234/1000 
	 loss: 4.0893, MinusLogProbMetric: 4.0893, val_loss: 4.1113, val_MinusLogProbMetric: 4.1113

Epoch 234: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0893 - MinusLogProbMetric: 4.0893 - val_loss: 4.1113 - val_MinusLogProbMetric: 4.1113 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-12 01:14:10.603 
Epoch 235/1000 
	 loss: 4.0965, MinusLogProbMetric: 4.0965, val_loss: 4.1239, val_MinusLogProbMetric: 4.1239

Epoch 235: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0965 - MinusLogProbMetric: 4.0965 - val_loss: 4.1239 - val_MinusLogProbMetric: 4.1239 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 236/1000
2023-09-12 01:14:22.248 
Epoch 236/1000 
	 loss: 4.0969, MinusLogProbMetric: 4.0969, val_loss: 4.1097, val_MinusLogProbMetric: 4.1097

Epoch 236: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0969 - MinusLogProbMetric: 4.0969 - val_loss: 4.1097 - val_MinusLogProbMetric: 4.1097 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 237/1000
2023-09-12 01:14:33.870 
Epoch 237/1000 
	 loss: 4.0918, MinusLogProbMetric: 4.0918, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 237: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0918 - MinusLogProbMetric: 4.0918 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 238/1000
2023-09-12 01:14:45.487 
Epoch 238/1000 
	 loss: 4.0963, MinusLogProbMetric: 4.0963, val_loss: 4.1300, val_MinusLogProbMetric: 4.1300

Epoch 238: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0963 - MinusLogProbMetric: 4.0963 - val_loss: 4.1300 - val_MinusLogProbMetric: 4.1300 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 239/1000
2023-09-12 01:14:57.332 
Epoch 239/1000 
	 loss: 4.0949, MinusLogProbMetric: 4.0949, val_loss: 4.1267, val_MinusLogProbMetric: 4.1267

Epoch 239: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0949 - MinusLogProbMetric: 4.0949 - val_loss: 4.1267 - val_MinusLogProbMetric: 4.1267 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 240/1000
2023-09-12 01:15:08.991 
Epoch 240/1000 
	 loss: 4.0933, MinusLogProbMetric: 4.0933, val_loss: 4.1179, val_MinusLogProbMetric: 4.1179

Epoch 240: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0933 - MinusLogProbMetric: 4.0933 - val_loss: 4.1179 - val_MinusLogProbMetric: 4.1179 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 241/1000
2023-09-12 01:15:20.605 
Epoch 241/1000 
	 loss: 4.0988, MinusLogProbMetric: 4.0988, val_loss: 4.1104, val_MinusLogProbMetric: 4.1104

Epoch 241: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0988 - MinusLogProbMetric: 4.0988 - val_loss: 4.1104 - val_MinusLogProbMetric: 4.1104 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 242/1000
2023-09-12 01:15:32.238 
Epoch 242/1000 
	 loss: 4.0946, MinusLogProbMetric: 4.0946, val_loss: 4.1406, val_MinusLogProbMetric: 4.1406

Epoch 242: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0946 - MinusLogProbMetric: 4.0946 - val_loss: 4.1406 - val_MinusLogProbMetric: 4.1406 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 243/1000
2023-09-12 01:15:43.872 
Epoch 243/1000 
	 loss: 4.1028, MinusLogProbMetric: 4.1028, val_loss: 4.1272, val_MinusLogProbMetric: 4.1272

Epoch 243: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.1028 - MinusLogProbMetric: 4.1028 - val_loss: 4.1272 - val_MinusLogProbMetric: 4.1272 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 244/1000
2023-09-12 01:15:55.548 
Epoch 244/1000 
	 loss: 4.1035, MinusLogProbMetric: 4.1035, val_loss: 4.1175, val_MinusLogProbMetric: 4.1175

Epoch 244: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.1035 - MinusLogProbMetric: 4.1035 - val_loss: 4.1175 - val_MinusLogProbMetric: 4.1175 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 245/1000
2023-09-12 01:16:07.187 
Epoch 245/1000 
	 loss: 4.0906, MinusLogProbMetric: 4.0906, val_loss: 4.1072, val_MinusLogProbMetric: 4.1072

Epoch 245: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0906 - MinusLogProbMetric: 4.0906 - val_loss: 4.1072 - val_MinusLogProbMetric: 4.1072 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 246/1000
2023-09-12 01:16:18.782 
Epoch 246/1000 
	 loss: 4.0939, MinusLogProbMetric: 4.0939, val_loss: 4.1113, val_MinusLogProbMetric: 4.1113

Epoch 246: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0939 - MinusLogProbMetric: 4.0939 - val_loss: 4.1113 - val_MinusLogProbMetric: 4.1113 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 247/1000
2023-09-12 01:16:30.603 
Epoch 247/1000 
	 loss: 4.0958, MinusLogProbMetric: 4.0958, val_loss: 4.1364, val_MinusLogProbMetric: 4.1364

Epoch 247: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0958 - MinusLogProbMetric: 4.0958 - val_loss: 4.1364 - val_MinusLogProbMetric: 4.1364 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-12 01:16:42.349 
Epoch 248/1000 
	 loss: 4.0976, MinusLogProbMetric: 4.0976, val_loss: 4.1365, val_MinusLogProbMetric: 4.1365

Epoch 248: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0976 - MinusLogProbMetric: 4.0976 - val_loss: 4.1365 - val_MinusLogProbMetric: 4.1365 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-12 01:16:53.946 
Epoch 249/1000 
	 loss: 4.1054, MinusLogProbMetric: 4.1054, val_loss: 4.1288, val_MinusLogProbMetric: 4.1288

Epoch 249: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.1054 - MinusLogProbMetric: 4.1054 - val_loss: 4.1288 - val_MinusLogProbMetric: 4.1288 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 250/1000
2023-09-12 01:17:05.692 
Epoch 250/1000 
	 loss: 4.0959, MinusLogProbMetric: 4.0959, val_loss: 4.1490, val_MinusLogProbMetric: 4.1490

Epoch 250: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0959 - MinusLogProbMetric: 4.0959 - val_loss: 4.1490 - val_MinusLogProbMetric: 4.1490 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-12 01:17:17.451 
Epoch 251/1000 
	 loss: 4.0958, MinusLogProbMetric: 4.0958, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 251: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0958 - MinusLogProbMetric: 4.0958 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 252/1000
2023-09-12 01:17:29.125 
Epoch 252/1000 
	 loss: 4.0923, MinusLogProbMetric: 4.0923, val_loss: 4.1250, val_MinusLogProbMetric: 4.1250

Epoch 252: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0923 - MinusLogProbMetric: 4.0923 - val_loss: 4.1250 - val_MinusLogProbMetric: 4.1250 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-12 01:17:40.696 
Epoch 253/1000 
	 loss: 4.0927, MinusLogProbMetric: 4.0927, val_loss: 4.1140, val_MinusLogProbMetric: 4.1140

Epoch 253: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0927 - MinusLogProbMetric: 4.0927 - val_loss: 4.1140 - val_MinusLogProbMetric: 4.1140 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 254/1000
2023-09-12 01:17:52.393 
Epoch 254/1000 
	 loss: 4.0942, MinusLogProbMetric: 4.0942, val_loss: 4.1241, val_MinusLogProbMetric: 4.1241

Epoch 254: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0942 - MinusLogProbMetric: 4.0942 - val_loss: 4.1241 - val_MinusLogProbMetric: 4.1241 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-12 01:18:04.100 
Epoch 255/1000 
	 loss: 4.0889, MinusLogProbMetric: 4.0889, val_loss: 4.1387, val_MinusLogProbMetric: 4.1387

Epoch 255: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0889 - MinusLogProbMetric: 4.0889 - val_loss: 4.1387 - val_MinusLogProbMetric: 4.1387 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 256/1000
2023-09-12 01:18:15.762 
Epoch 256/1000 
	 loss: 4.0881, MinusLogProbMetric: 4.0881, val_loss: 4.1249, val_MinusLogProbMetric: 4.1249

Epoch 256: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0881 - MinusLogProbMetric: 4.0881 - val_loss: 4.1249 - val_MinusLogProbMetric: 4.1249 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 257/1000
2023-09-12 01:18:27.441 
Epoch 257/1000 
	 loss: 4.0979, MinusLogProbMetric: 4.0979, val_loss: 4.1309, val_MinusLogProbMetric: 4.1309

Epoch 257: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0979 - MinusLogProbMetric: 4.0979 - val_loss: 4.1309 - val_MinusLogProbMetric: 4.1309 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-12 01:18:39.115 
Epoch 258/1000 
	 loss: 4.0878, MinusLogProbMetric: 4.0878, val_loss: 4.1248, val_MinusLogProbMetric: 4.1248

Epoch 258: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0878 - MinusLogProbMetric: 4.0878 - val_loss: 4.1248 - val_MinusLogProbMetric: 4.1248 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 259/1000
2023-09-12 01:18:50.846 
Epoch 259/1000 
	 loss: 4.0901, MinusLogProbMetric: 4.0901, val_loss: 4.1251, val_MinusLogProbMetric: 4.1251

Epoch 259: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0901 - MinusLogProbMetric: 4.0901 - val_loss: 4.1251 - val_MinusLogProbMetric: 4.1251 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 260/1000
2023-09-12 01:19:02.569 
Epoch 260/1000 
	 loss: 4.0984, MinusLogProbMetric: 4.0984, val_loss: 4.1247, val_MinusLogProbMetric: 4.1247

Epoch 260: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0984 - MinusLogProbMetric: 4.0984 - val_loss: 4.1247 - val_MinusLogProbMetric: 4.1247 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 261/1000
2023-09-12 01:19:14.168 
Epoch 261/1000 
	 loss: 4.0933, MinusLogProbMetric: 4.0933, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 261: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0933 - MinusLogProbMetric: 4.0933 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 262/1000
2023-09-12 01:19:25.955 
Epoch 262/1000 
	 loss: 4.0923, MinusLogProbMetric: 4.0923, val_loss: 4.1094, val_MinusLogProbMetric: 4.1094

Epoch 262: val_loss did not improve from 4.10719
196/196 - 12s - loss: 4.0923 - MinusLogProbMetric: 4.0923 - val_loss: 4.1094 - val_MinusLogProbMetric: 4.1094 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-12 01:19:37.581 
Epoch 263/1000 
	 loss: 4.0907, MinusLogProbMetric: 4.0907, val_loss: 4.1057, val_MinusLogProbMetric: 4.1057

Epoch 263: val_loss improved from 4.10719 to 4.10570, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0907 - MinusLogProbMetric: 4.0907 - val_loss: 4.1057 - val_MinusLogProbMetric: 4.1057 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 264/1000
2023-09-12 01:19:49.342 
Epoch 264/1000 
	 loss: 4.0934, MinusLogProbMetric: 4.0934, val_loss: 4.1168, val_MinusLogProbMetric: 4.1168

Epoch 264: val_loss did not improve from 4.10570
196/196 - 12s - loss: 4.0934 - MinusLogProbMetric: 4.0934 - val_loss: 4.1168 - val_MinusLogProbMetric: 4.1168 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 265/1000
2023-09-12 01:20:01.023 
Epoch 265/1000 
	 loss: 4.0902, MinusLogProbMetric: 4.0902, val_loss: 4.1150, val_MinusLogProbMetric: 4.1150

Epoch 265: val_loss did not improve from 4.10570
196/196 - 12s - loss: 4.0902 - MinusLogProbMetric: 4.0902 - val_loss: 4.1150 - val_MinusLogProbMetric: 4.1150 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 266/1000
2023-09-12 01:20:12.664 
Epoch 266/1000 
	 loss: 4.0905, MinusLogProbMetric: 4.0905, val_loss: 4.1339, val_MinusLogProbMetric: 4.1339

Epoch 266: val_loss did not improve from 4.10570
196/196 - 12s - loss: 4.0905 - MinusLogProbMetric: 4.0905 - val_loss: 4.1339 - val_MinusLogProbMetric: 4.1339 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 267/1000
2023-09-12 01:20:24.418 
Epoch 267/1000 
	 loss: 4.0903, MinusLogProbMetric: 4.0903, val_loss: 4.1163, val_MinusLogProbMetric: 4.1163

Epoch 267: val_loss did not improve from 4.10570
196/196 - 12s - loss: 4.0903 - MinusLogProbMetric: 4.0903 - val_loss: 4.1163 - val_MinusLogProbMetric: 4.1163 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 268/1000
2023-09-12 01:20:36.113 
Epoch 268/1000 
	 loss: 4.0886, MinusLogProbMetric: 4.0886, val_loss: 4.1104, val_MinusLogProbMetric: 4.1104

Epoch 268: val_loss did not improve from 4.10570
196/196 - 12s - loss: 4.0886 - MinusLogProbMetric: 4.0886 - val_loss: 4.1104 - val_MinusLogProbMetric: 4.1104 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-12 01:20:47.627 
Epoch 269/1000 
	 loss: 4.0893, MinusLogProbMetric: 4.0893, val_loss: 4.1216, val_MinusLogProbMetric: 4.1216

Epoch 269: val_loss did not improve from 4.10570
196/196 - 12s - loss: 4.0893 - MinusLogProbMetric: 4.0893 - val_loss: 4.1216 - val_MinusLogProbMetric: 4.1216 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 270/1000
2023-09-12 01:20:59.376 
Epoch 270/1000 
	 loss: 4.0881, MinusLogProbMetric: 4.0881, val_loss: 4.1043, val_MinusLogProbMetric: 4.1043

Epoch 270: val_loss improved from 4.10570 to 4.10432, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0881 - MinusLogProbMetric: 4.0881 - val_loss: 4.1043 - val_MinusLogProbMetric: 4.1043 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 271/1000
2023-09-12 01:21:11.231 
Epoch 271/1000 
	 loss: 4.1200, MinusLogProbMetric: 4.1200, val_loss: 4.1152, val_MinusLogProbMetric: 4.1152

Epoch 271: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.1200 - MinusLogProbMetric: 4.1200 - val_loss: 4.1152 - val_MinusLogProbMetric: 4.1152 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-12 01:21:22.899 
Epoch 272/1000 
	 loss: 4.0955, MinusLogProbMetric: 4.0955, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 272: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0955 - MinusLogProbMetric: 4.0955 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 273/1000
2023-09-12 01:21:34.499 
Epoch 273/1000 
	 loss: 4.0912, MinusLogProbMetric: 4.0912, val_loss: 4.1415, val_MinusLogProbMetric: 4.1415

Epoch 273: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0912 - MinusLogProbMetric: 4.0912 - val_loss: 4.1415 - val_MinusLogProbMetric: 4.1415 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 274/1000
2023-09-12 01:21:46.171 
Epoch 274/1000 
	 loss: 4.0886, MinusLogProbMetric: 4.0886, val_loss: 4.1162, val_MinusLogProbMetric: 4.1162

Epoch 274: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0886 - MinusLogProbMetric: 4.0886 - val_loss: 4.1162 - val_MinusLogProbMetric: 4.1162 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 275/1000
2023-09-12 01:21:57.900 
Epoch 275/1000 
	 loss: 4.0920, MinusLogProbMetric: 4.0920, val_loss: 4.1319, val_MinusLogProbMetric: 4.1319

Epoch 275: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0920 - MinusLogProbMetric: 4.0920 - val_loss: 4.1319 - val_MinusLogProbMetric: 4.1319 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 276/1000
2023-09-12 01:22:09.503 
Epoch 276/1000 
	 loss: 4.0894, MinusLogProbMetric: 4.0894, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 276: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0894 - MinusLogProbMetric: 4.0894 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 277/1000
2023-09-12 01:22:21.224 
Epoch 277/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.1332, val_MinusLogProbMetric: 4.1332

Epoch 277: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.1332 - val_MinusLogProbMetric: 4.1332 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 278/1000
2023-09-12 01:22:32.859 
Epoch 278/1000 
	 loss: 4.0895, MinusLogProbMetric: 4.0895, val_loss: 4.1239, val_MinusLogProbMetric: 4.1239

Epoch 278: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0895 - MinusLogProbMetric: 4.0895 - val_loss: 4.1239 - val_MinusLogProbMetric: 4.1239 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 279/1000
2023-09-12 01:22:44.377 
Epoch 279/1000 
	 loss: 4.0928, MinusLogProbMetric: 4.0928, val_loss: 4.1138, val_MinusLogProbMetric: 4.1138

Epoch 279: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0928 - MinusLogProbMetric: 4.0928 - val_loss: 4.1138 - val_MinusLogProbMetric: 4.1138 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 280/1000
2023-09-12 01:22:56.163 
Epoch 280/1000 
	 loss: 4.0900, MinusLogProbMetric: 4.0900, val_loss: 4.1177, val_MinusLogProbMetric: 4.1177

Epoch 280: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0900 - MinusLogProbMetric: 4.0900 - val_loss: 4.1177 - val_MinusLogProbMetric: 4.1177 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-12 01:23:07.843 
Epoch 281/1000 
	 loss: 4.0910, MinusLogProbMetric: 4.0910, val_loss: 4.1302, val_MinusLogProbMetric: 4.1302

Epoch 281: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0910 - MinusLogProbMetric: 4.0910 - val_loss: 4.1302 - val_MinusLogProbMetric: 4.1302 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 282/1000
2023-09-12 01:23:19.481 
Epoch 282/1000 
	 loss: 4.0923, MinusLogProbMetric: 4.0923, val_loss: 4.1326, val_MinusLogProbMetric: 4.1326

Epoch 282: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0923 - MinusLogProbMetric: 4.0923 - val_loss: 4.1326 - val_MinusLogProbMetric: 4.1326 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 283/1000
2023-09-12 01:23:31.250 
Epoch 283/1000 
	 loss: 4.0968, MinusLogProbMetric: 4.0968, val_loss: 4.1347, val_MinusLogProbMetric: 4.1347

Epoch 283: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0968 - MinusLogProbMetric: 4.0968 - val_loss: 4.1347 - val_MinusLogProbMetric: 4.1347 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-12 01:23:42.835 
Epoch 284/1000 
	 loss: 4.0925, MinusLogProbMetric: 4.0925, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 284: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0925 - MinusLogProbMetric: 4.0925 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 285/1000
2023-09-12 01:23:54.474 
Epoch 285/1000 
	 loss: 4.0912, MinusLogProbMetric: 4.0912, val_loss: 4.1319, val_MinusLogProbMetric: 4.1319

Epoch 285: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0912 - MinusLogProbMetric: 4.0912 - val_loss: 4.1319 - val_MinusLogProbMetric: 4.1319 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 286/1000
2023-09-12 01:24:06.232 
Epoch 286/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.1079, val_MinusLogProbMetric: 4.1079

Epoch 286: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.1079 - val_MinusLogProbMetric: 4.1079 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 287/1000
2023-09-12 01:24:17.883 
Epoch 287/1000 
	 loss: 4.0923, MinusLogProbMetric: 4.0923, val_loss: 4.1204, val_MinusLogProbMetric: 4.1204

Epoch 287: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0923 - MinusLogProbMetric: 4.0923 - val_loss: 4.1204 - val_MinusLogProbMetric: 4.1204 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 288/1000
2023-09-12 01:24:29.510 
Epoch 288/1000 
	 loss: 4.0940, MinusLogProbMetric: 4.0940, val_loss: 4.1158, val_MinusLogProbMetric: 4.1158

Epoch 288: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0940 - MinusLogProbMetric: 4.0940 - val_loss: 4.1158 - val_MinusLogProbMetric: 4.1158 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 289/1000
2023-09-12 01:24:41.037 
Epoch 289/1000 
	 loss: 4.0888, MinusLogProbMetric: 4.0888, val_loss: 4.1240, val_MinusLogProbMetric: 4.1240

Epoch 289: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0888 - MinusLogProbMetric: 4.0888 - val_loss: 4.1240 - val_MinusLogProbMetric: 4.1240 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 290/1000
2023-09-12 01:24:52.737 
Epoch 290/1000 
	 loss: 4.0899, MinusLogProbMetric: 4.0899, val_loss: 4.1089, val_MinusLogProbMetric: 4.1089

Epoch 290: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0899 - MinusLogProbMetric: 4.0899 - val_loss: 4.1089 - val_MinusLogProbMetric: 4.1089 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 291/1000
2023-09-12 01:25:04.494 
Epoch 291/1000 
	 loss: 4.0886, MinusLogProbMetric: 4.0886, val_loss: 4.1087, val_MinusLogProbMetric: 4.1087

Epoch 291: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0886 - MinusLogProbMetric: 4.0886 - val_loss: 4.1087 - val_MinusLogProbMetric: 4.1087 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 292/1000
2023-09-12 01:25:16.168 
Epoch 292/1000 
	 loss: 4.0916, MinusLogProbMetric: 4.0916, val_loss: 4.1060, val_MinusLogProbMetric: 4.1060

Epoch 292: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0916 - MinusLogProbMetric: 4.0916 - val_loss: 4.1060 - val_MinusLogProbMetric: 4.1060 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 293/1000
2023-09-12 01:25:27.806 
Epoch 293/1000 
	 loss: 4.0879, MinusLogProbMetric: 4.0879, val_loss: 4.1235, val_MinusLogProbMetric: 4.1235

Epoch 293: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0879 - MinusLogProbMetric: 4.0879 - val_loss: 4.1235 - val_MinusLogProbMetric: 4.1235 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 294/1000
2023-09-12 01:25:39.164 
Epoch 294/1000 
	 loss: 4.0929, MinusLogProbMetric: 4.0929, val_loss: 4.1189, val_MinusLogProbMetric: 4.1189

Epoch 294: val_loss did not improve from 4.10432
196/196 - 11s - loss: 4.0929 - MinusLogProbMetric: 4.0929 - val_loss: 4.1189 - val_MinusLogProbMetric: 4.1189 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 295/1000
2023-09-12 01:25:49.989 
Epoch 295/1000 
	 loss: 4.0879, MinusLogProbMetric: 4.0879, val_loss: 4.1148, val_MinusLogProbMetric: 4.1148

Epoch 295: val_loss did not improve from 4.10432
196/196 - 11s - loss: 4.0879 - MinusLogProbMetric: 4.0879 - val_loss: 4.1148 - val_MinusLogProbMetric: 4.1148 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 296/1000
2023-09-12 01:26:00.373 
Epoch 296/1000 
	 loss: 4.0860, MinusLogProbMetric: 4.0860, val_loss: 4.1191, val_MinusLogProbMetric: 4.1191

Epoch 296: val_loss did not improve from 4.10432
196/196 - 10s - loss: 4.0860 - MinusLogProbMetric: 4.0860 - val_loss: 4.1191 - val_MinusLogProbMetric: 4.1191 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 297/1000
2023-09-12 01:26:12.006 
Epoch 297/1000 
	 loss: 4.0980, MinusLogProbMetric: 4.0980, val_loss: 4.1206, val_MinusLogProbMetric: 4.1206

Epoch 297: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0980 - MinusLogProbMetric: 4.0980 - val_loss: 4.1206 - val_MinusLogProbMetric: 4.1206 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 298/1000
2023-09-12 01:26:23.670 
Epoch 298/1000 
	 loss: 4.0851, MinusLogProbMetric: 4.0851, val_loss: 4.1144, val_MinusLogProbMetric: 4.1144

Epoch 298: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0851 - MinusLogProbMetric: 4.0851 - val_loss: 4.1144 - val_MinusLogProbMetric: 4.1144 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 299/1000
2023-09-12 01:26:35.264 
Epoch 299/1000 
	 loss: 4.0850, MinusLogProbMetric: 4.0850, val_loss: 4.1193, val_MinusLogProbMetric: 4.1193

Epoch 299: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0850 - MinusLogProbMetric: 4.0850 - val_loss: 4.1193 - val_MinusLogProbMetric: 4.1193 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 300/1000
2023-09-12 01:26:46.926 
Epoch 300/1000 
	 loss: 4.0897, MinusLogProbMetric: 4.0897, val_loss: 4.1212, val_MinusLogProbMetric: 4.1212

Epoch 300: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0897 - MinusLogProbMetric: 4.0897 - val_loss: 4.1212 - val_MinusLogProbMetric: 4.1212 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 301/1000
2023-09-12 01:26:58.620 
Epoch 301/1000 
	 loss: 4.0882, MinusLogProbMetric: 4.0882, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 301: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0882 - MinusLogProbMetric: 4.0882 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 302/1000
2023-09-12 01:27:10.123 
Epoch 302/1000 
	 loss: 4.0882, MinusLogProbMetric: 4.0882, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 302: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0882 - MinusLogProbMetric: 4.0882 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 303/1000
2023-09-12 01:27:21.402 
Epoch 303/1000 
	 loss: 4.0913, MinusLogProbMetric: 4.0913, val_loss: 4.1176, val_MinusLogProbMetric: 4.1176

Epoch 303: val_loss did not improve from 4.10432
196/196 - 11s - loss: 4.0913 - MinusLogProbMetric: 4.0913 - val_loss: 4.1176 - val_MinusLogProbMetric: 4.1176 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 304/1000
2023-09-12 01:27:32.894 
Epoch 304/1000 
	 loss: 4.1010, MinusLogProbMetric: 4.1010, val_loss: 4.1170, val_MinusLogProbMetric: 4.1170

Epoch 304: val_loss did not improve from 4.10432
196/196 - 11s - loss: 4.1010 - MinusLogProbMetric: 4.1010 - val_loss: 4.1170 - val_MinusLogProbMetric: 4.1170 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 305/1000
2023-09-12 01:27:43.877 
Epoch 305/1000 
	 loss: 4.0919, MinusLogProbMetric: 4.0919, val_loss: 4.1082, val_MinusLogProbMetric: 4.1082

Epoch 305: val_loss did not improve from 4.10432
196/196 - 11s - loss: 4.0919 - MinusLogProbMetric: 4.0919 - val_loss: 4.1082 - val_MinusLogProbMetric: 4.1082 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 306/1000
2023-09-12 01:27:54.267 
Epoch 306/1000 
	 loss: 4.0859, MinusLogProbMetric: 4.0859, val_loss: 4.1175, val_MinusLogProbMetric: 4.1175

Epoch 306: val_loss did not improve from 4.10432
196/196 - 10s - loss: 4.0859 - MinusLogProbMetric: 4.0859 - val_loss: 4.1175 - val_MinusLogProbMetric: 4.1175 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 307/1000
2023-09-12 01:28:04.255 
Epoch 307/1000 
	 loss: 4.0905, MinusLogProbMetric: 4.0905, val_loss: 4.1220, val_MinusLogProbMetric: 4.1220

Epoch 307: val_loss did not improve from 4.10432
196/196 - 10s - loss: 4.0905 - MinusLogProbMetric: 4.0905 - val_loss: 4.1220 - val_MinusLogProbMetric: 4.1220 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 308/1000
2023-09-12 01:28:15.794 
Epoch 308/1000 
	 loss: 4.0853, MinusLogProbMetric: 4.0853, val_loss: 4.1080, val_MinusLogProbMetric: 4.1080

Epoch 308: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0853 - MinusLogProbMetric: 4.0853 - val_loss: 4.1080 - val_MinusLogProbMetric: 4.1080 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 309/1000
2023-09-12 01:28:27.492 
Epoch 309/1000 
	 loss: 4.0942, MinusLogProbMetric: 4.0942, val_loss: 4.1059, val_MinusLogProbMetric: 4.1059

Epoch 309: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0942 - MinusLogProbMetric: 4.0942 - val_loss: 4.1059 - val_MinusLogProbMetric: 4.1059 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 310/1000
2023-09-12 01:28:39.131 
Epoch 310/1000 
	 loss: 4.0886, MinusLogProbMetric: 4.0886, val_loss: 4.1176, val_MinusLogProbMetric: 4.1176

Epoch 310: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0886 - MinusLogProbMetric: 4.0886 - val_loss: 4.1176 - val_MinusLogProbMetric: 4.1176 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 311/1000
2023-09-12 01:28:50.687 
Epoch 311/1000 
	 loss: 4.0900, MinusLogProbMetric: 4.0900, val_loss: 4.1140, val_MinusLogProbMetric: 4.1140

Epoch 311: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0900 - MinusLogProbMetric: 4.0900 - val_loss: 4.1140 - val_MinusLogProbMetric: 4.1140 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 312/1000
2023-09-12 01:29:02.373 
Epoch 312/1000 
	 loss: 4.0888, MinusLogProbMetric: 4.0888, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 312: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0888 - MinusLogProbMetric: 4.0888 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 313/1000
2023-09-12 01:29:14.136 
Epoch 313/1000 
	 loss: 4.0858, MinusLogProbMetric: 4.0858, val_loss: 4.1319, val_MinusLogProbMetric: 4.1319

Epoch 313: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0858 - MinusLogProbMetric: 4.0858 - val_loss: 4.1319 - val_MinusLogProbMetric: 4.1319 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 314/1000
2023-09-12 01:29:25.769 
Epoch 314/1000 
	 loss: 4.0855, MinusLogProbMetric: 4.0855, val_loss: 4.1099, val_MinusLogProbMetric: 4.1099

Epoch 314: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0855 - MinusLogProbMetric: 4.0855 - val_loss: 4.1099 - val_MinusLogProbMetric: 4.1099 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 315/1000
2023-09-12 01:29:37.508 
Epoch 315/1000 
	 loss: 4.0964, MinusLogProbMetric: 4.0964, val_loss: 4.1162, val_MinusLogProbMetric: 4.1162

Epoch 315: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0964 - MinusLogProbMetric: 4.0964 - val_loss: 4.1162 - val_MinusLogProbMetric: 4.1162 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-12 01:29:49.075 
Epoch 316/1000 
	 loss: 4.0816, MinusLogProbMetric: 4.0816, val_loss: 4.1070, val_MinusLogProbMetric: 4.1070

Epoch 316: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0816 - MinusLogProbMetric: 4.0816 - val_loss: 4.1070 - val_MinusLogProbMetric: 4.1070 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 317/1000
2023-09-12 01:30:00.728 
Epoch 317/1000 
	 loss: 4.0954, MinusLogProbMetric: 4.0954, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 317: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0954 - MinusLogProbMetric: 4.0954 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 318/1000
2023-09-12 01:30:12.425 
Epoch 318/1000 
	 loss: 4.0836, MinusLogProbMetric: 4.0836, val_loss: 4.1188, val_MinusLogProbMetric: 4.1188

Epoch 318: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0836 - MinusLogProbMetric: 4.0836 - val_loss: 4.1188 - val_MinusLogProbMetric: 4.1188 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 319/1000
2023-09-12 01:30:24.195 
Epoch 319/1000 
	 loss: 4.0953, MinusLogProbMetric: 4.0953, val_loss: 4.1328, val_MinusLogProbMetric: 4.1328

Epoch 319: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0953 - MinusLogProbMetric: 4.0953 - val_loss: 4.1328 - val_MinusLogProbMetric: 4.1328 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 320/1000
2023-09-12 01:30:36.018 
Epoch 320/1000 
	 loss: 4.0862, MinusLogProbMetric: 4.0862, val_loss: 4.1168, val_MinusLogProbMetric: 4.1168

Epoch 320: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0862 - MinusLogProbMetric: 4.0862 - val_loss: 4.1168 - val_MinusLogProbMetric: 4.1168 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 321/1000
2023-09-12 01:30:47.665 
Epoch 321/1000 
	 loss: 4.0734, MinusLogProbMetric: 4.0734, val_loss: 4.1065, val_MinusLogProbMetric: 4.1065

Epoch 321: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0734 - MinusLogProbMetric: 4.0734 - val_loss: 4.1065 - val_MinusLogProbMetric: 4.1065 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 322/1000
2023-09-12 01:30:59.238 
Epoch 322/1000 
	 loss: 4.0808, MinusLogProbMetric: 4.0808, val_loss: 4.1069, val_MinusLogProbMetric: 4.1069

Epoch 322: val_loss did not improve from 4.10432
196/196 - 12s - loss: 4.0808 - MinusLogProbMetric: 4.0808 - val_loss: 4.1069 - val_MinusLogProbMetric: 4.1069 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 323/1000
2023-09-12 01:31:10.893 
Epoch 323/1000 
	 loss: 4.0730, MinusLogProbMetric: 4.0730, val_loss: 4.1042, val_MinusLogProbMetric: 4.1042

Epoch 323: val_loss improved from 4.10432 to 4.10423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0730 - MinusLogProbMetric: 4.0730 - val_loss: 4.1042 - val_MinusLogProbMetric: 4.1042 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 324/1000
2023-09-12 01:31:22.641 
Epoch 324/1000 
	 loss: 4.0741, MinusLogProbMetric: 4.0741, val_loss: 4.1058, val_MinusLogProbMetric: 4.1058

Epoch 324: val_loss did not improve from 4.10423
196/196 - 12s - loss: 4.0741 - MinusLogProbMetric: 4.0741 - val_loss: 4.1058 - val_MinusLogProbMetric: 4.1058 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 325/1000
2023-09-12 01:31:34.385 
Epoch 325/1000 
	 loss: 4.0743, MinusLogProbMetric: 4.0743, val_loss: 4.1029, val_MinusLogProbMetric: 4.1029

Epoch 325: val_loss improved from 4.10423 to 4.10287, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0743 - MinusLogProbMetric: 4.0743 - val_loss: 4.1029 - val_MinusLogProbMetric: 4.1029 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 326/1000
2023-09-12 01:31:46.143 
Epoch 326/1000 
	 loss: 4.0771, MinusLogProbMetric: 4.0771, val_loss: 4.1022, val_MinusLogProbMetric: 4.1022

Epoch 326: val_loss improved from 4.10287 to 4.10216, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0771 - MinusLogProbMetric: 4.0771 - val_loss: 4.1022 - val_MinusLogProbMetric: 4.1022 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-12 01:31:57.925 
Epoch 327/1000 
	 loss: 4.0814, MinusLogProbMetric: 4.0814, val_loss: 4.1095, val_MinusLogProbMetric: 4.1095

Epoch 327: val_loss did not improve from 4.10216
196/196 - 12s - loss: 4.0814 - MinusLogProbMetric: 4.0814 - val_loss: 4.1095 - val_MinusLogProbMetric: 4.1095 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 328/1000
2023-09-12 01:32:09.475 
Epoch 328/1000 
	 loss: 4.0743, MinusLogProbMetric: 4.0743, val_loss: 4.1015, val_MinusLogProbMetric: 4.1015

Epoch 328: val_loss improved from 4.10216 to 4.10149, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0743 - MinusLogProbMetric: 4.0743 - val_loss: 4.1015 - val_MinusLogProbMetric: 4.1015 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 329/1000
2023-09-12 01:32:21.230 
Epoch 329/1000 
	 loss: 4.0721, MinusLogProbMetric: 4.0721, val_loss: 4.1169, val_MinusLogProbMetric: 4.1169

Epoch 329: val_loss did not improve from 4.10149
196/196 - 12s - loss: 4.0721 - MinusLogProbMetric: 4.0721 - val_loss: 4.1169 - val_MinusLogProbMetric: 4.1169 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 330/1000
2023-09-12 01:32:32.984 
Epoch 330/1000 
	 loss: 4.0743, MinusLogProbMetric: 4.0743, val_loss: 4.1110, val_MinusLogProbMetric: 4.1110

Epoch 330: val_loss did not improve from 4.10149
196/196 - 12s - loss: 4.0743 - MinusLogProbMetric: 4.0743 - val_loss: 4.1110 - val_MinusLogProbMetric: 4.1110 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 331/1000
2023-09-12 01:32:44.555 
Epoch 331/1000 
	 loss: 4.0758, MinusLogProbMetric: 4.0758, val_loss: 4.1111, val_MinusLogProbMetric: 4.1111

Epoch 331: val_loss did not improve from 4.10149
196/196 - 12s - loss: 4.0758 - MinusLogProbMetric: 4.0758 - val_loss: 4.1111 - val_MinusLogProbMetric: 4.1111 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 332/1000
2023-09-12 01:32:56.170 
Epoch 332/1000 
	 loss: 4.0753, MinusLogProbMetric: 4.0753, val_loss: 4.0998, val_MinusLogProbMetric: 4.0998

Epoch 332: val_loss improved from 4.10149 to 4.09978, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0753 - MinusLogProbMetric: 4.0753 - val_loss: 4.0998 - val_MinusLogProbMetric: 4.0998 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 333/1000
2023-09-12 01:33:07.946 
Epoch 333/1000 
	 loss: 4.0748, MinusLogProbMetric: 4.0748, val_loss: 4.1104, val_MinusLogProbMetric: 4.1104

Epoch 333: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0748 - MinusLogProbMetric: 4.0748 - val_loss: 4.1104 - val_MinusLogProbMetric: 4.1104 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 334/1000
2023-09-12 01:33:19.605 
Epoch 334/1000 
	 loss: 4.0759, MinusLogProbMetric: 4.0759, val_loss: 4.1041, val_MinusLogProbMetric: 4.1041

Epoch 334: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0759 - MinusLogProbMetric: 4.0759 - val_loss: 4.1041 - val_MinusLogProbMetric: 4.1041 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 335/1000
2023-09-12 01:33:31.222 
Epoch 335/1000 
	 loss: 4.0773, MinusLogProbMetric: 4.0773, val_loss: 4.1051, val_MinusLogProbMetric: 4.1051

Epoch 335: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0773 - MinusLogProbMetric: 4.0773 - val_loss: 4.1051 - val_MinusLogProbMetric: 4.1051 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 336/1000
2023-09-12 01:33:42.837 
Epoch 336/1000 
	 loss: 4.0730, MinusLogProbMetric: 4.0730, val_loss: 4.1089, val_MinusLogProbMetric: 4.1089

Epoch 336: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0730 - MinusLogProbMetric: 4.0730 - val_loss: 4.1089 - val_MinusLogProbMetric: 4.1089 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 337/1000
2023-09-12 01:33:54.465 
Epoch 337/1000 
	 loss: 4.0731, MinusLogProbMetric: 4.0731, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 337: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0731 - MinusLogProbMetric: 4.0731 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 338/1000
2023-09-12 01:34:06.116 
Epoch 338/1000 
	 loss: 4.0728, MinusLogProbMetric: 4.0728, val_loss: 4.1239, val_MinusLogProbMetric: 4.1239

Epoch 338: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0728 - MinusLogProbMetric: 4.0728 - val_loss: 4.1239 - val_MinusLogProbMetric: 4.1239 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 339/1000
2023-09-12 01:34:17.772 
Epoch 339/1000 
	 loss: 4.0775, MinusLogProbMetric: 4.0775, val_loss: 4.1037, val_MinusLogProbMetric: 4.1037

Epoch 339: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0775 - MinusLogProbMetric: 4.0775 - val_loss: 4.1037 - val_MinusLogProbMetric: 4.1037 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 340/1000
2023-09-12 01:34:29.305 
Epoch 340/1000 
	 loss: 4.0762, MinusLogProbMetric: 4.0762, val_loss: 4.1081, val_MinusLogProbMetric: 4.1081

Epoch 340: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0762 - MinusLogProbMetric: 4.0762 - val_loss: 4.1081 - val_MinusLogProbMetric: 4.1081 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 341/1000
2023-09-12 01:34:41.015 
Epoch 341/1000 
	 loss: 4.0737, MinusLogProbMetric: 4.0737, val_loss: 4.1083, val_MinusLogProbMetric: 4.1083

Epoch 341: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0737 - MinusLogProbMetric: 4.0737 - val_loss: 4.1083 - val_MinusLogProbMetric: 4.1083 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 342/1000
2023-09-12 01:34:52.681 
Epoch 342/1000 
	 loss: 4.0735, MinusLogProbMetric: 4.0735, val_loss: 4.1040, val_MinusLogProbMetric: 4.1040

Epoch 342: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0735 - MinusLogProbMetric: 4.0735 - val_loss: 4.1040 - val_MinusLogProbMetric: 4.1040 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-12 01:35:04.301 
Epoch 343/1000 
	 loss: 4.0744, MinusLogProbMetric: 4.0744, val_loss: 4.1142, val_MinusLogProbMetric: 4.1142

Epoch 343: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0744 - MinusLogProbMetric: 4.0744 - val_loss: 4.1142 - val_MinusLogProbMetric: 4.1142 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 344/1000
2023-09-12 01:35:15.894 
Epoch 344/1000 
	 loss: 4.0776, MinusLogProbMetric: 4.0776, val_loss: 4.1024, val_MinusLogProbMetric: 4.1024

Epoch 344: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0776 - MinusLogProbMetric: 4.0776 - val_loss: 4.1024 - val_MinusLogProbMetric: 4.1024 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 345/1000
2023-09-12 01:35:27.493 
Epoch 345/1000 
	 loss: 4.0760, MinusLogProbMetric: 4.0760, val_loss: 4.1035, val_MinusLogProbMetric: 4.1035

Epoch 345: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0760 - MinusLogProbMetric: 4.0760 - val_loss: 4.1035 - val_MinusLogProbMetric: 4.1035 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 346/1000
2023-09-12 01:35:39.056 
Epoch 346/1000 
	 loss: 4.0730, MinusLogProbMetric: 4.0730, val_loss: 4.1073, val_MinusLogProbMetric: 4.1073

Epoch 346: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0730 - MinusLogProbMetric: 4.0730 - val_loss: 4.1073 - val_MinusLogProbMetric: 4.1073 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 347/1000
2023-09-12 01:35:50.692 
Epoch 347/1000 
	 loss: 4.0725, MinusLogProbMetric: 4.0725, val_loss: 4.1020, val_MinusLogProbMetric: 4.1020

Epoch 347: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0725 - MinusLogProbMetric: 4.0725 - val_loss: 4.1020 - val_MinusLogProbMetric: 4.1020 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 348/1000
2023-09-12 01:36:02.363 
Epoch 348/1000 
	 loss: 4.0761, MinusLogProbMetric: 4.0761, val_loss: 4.1090, val_MinusLogProbMetric: 4.1090

Epoch 348: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0761 - MinusLogProbMetric: 4.0761 - val_loss: 4.1090 - val_MinusLogProbMetric: 4.1090 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 349/1000
2023-09-12 01:36:13.873 
Epoch 349/1000 
	 loss: 4.0712, MinusLogProbMetric: 4.0712, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 349: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0712 - MinusLogProbMetric: 4.0712 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 350/1000
2023-09-12 01:36:25.508 
Epoch 350/1000 
	 loss: 4.0724, MinusLogProbMetric: 4.0724, val_loss: 4.1070, val_MinusLogProbMetric: 4.1070

Epoch 350: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0724 - MinusLogProbMetric: 4.0724 - val_loss: 4.1070 - val_MinusLogProbMetric: 4.1070 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 351/1000
2023-09-12 01:36:37.264 
Epoch 351/1000 
	 loss: 4.0722, MinusLogProbMetric: 4.0722, val_loss: 4.1377, val_MinusLogProbMetric: 4.1377

Epoch 351: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0722 - MinusLogProbMetric: 4.0722 - val_loss: 4.1377 - val_MinusLogProbMetric: 4.1377 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 352/1000
2023-09-12 01:36:49.015 
Epoch 352/1000 
	 loss: 4.0752, MinusLogProbMetric: 4.0752, val_loss: 4.1119, val_MinusLogProbMetric: 4.1119

Epoch 352: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0752 - MinusLogProbMetric: 4.0752 - val_loss: 4.1119 - val_MinusLogProbMetric: 4.1119 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 353/1000
2023-09-12 01:37:00.698 
Epoch 353/1000 
	 loss: 4.0771, MinusLogProbMetric: 4.0771, val_loss: 4.1042, val_MinusLogProbMetric: 4.1042

Epoch 353: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0771 - MinusLogProbMetric: 4.0771 - val_loss: 4.1042 - val_MinusLogProbMetric: 4.1042 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 354/1000
2023-09-12 01:37:12.348 
Epoch 354/1000 
	 loss: 4.0722, MinusLogProbMetric: 4.0722, val_loss: 4.1162, val_MinusLogProbMetric: 4.1162

Epoch 354: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0722 - MinusLogProbMetric: 4.0722 - val_loss: 4.1162 - val_MinusLogProbMetric: 4.1162 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 355/1000
2023-09-12 01:37:24.109 
Epoch 355/1000 
	 loss: 4.0715, MinusLogProbMetric: 4.0715, val_loss: 4.1059, val_MinusLogProbMetric: 4.1059

Epoch 355: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0715 - MinusLogProbMetric: 4.0715 - val_loss: 4.1059 - val_MinusLogProbMetric: 4.1059 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 356/1000
2023-09-12 01:37:35.798 
Epoch 356/1000 
	 loss: 4.0788, MinusLogProbMetric: 4.0788, val_loss: 4.1030, val_MinusLogProbMetric: 4.1030

Epoch 356: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0788 - MinusLogProbMetric: 4.0788 - val_loss: 4.1030 - val_MinusLogProbMetric: 4.1030 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 357/1000
2023-09-12 01:37:47.366 
Epoch 357/1000 
	 loss: 4.0731, MinusLogProbMetric: 4.0731, val_loss: 4.1016, val_MinusLogProbMetric: 4.1016

Epoch 357: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0731 - MinusLogProbMetric: 4.0731 - val_loss: 4.1016 - val_MinusLogProbMetric: 4.1016 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 358/1000
2023-09-12 01:37:58.998 
Epoch 358/1000 
	 loss: 4.0718, MinusLogProbMetric: 4.0718, val_loss: 4.1112, val_MinusLogProbMetric: 4.1112

Epoch 358: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0718 - MinusLogProbMetric: 4.0718 - val_loss: 4.1112 - val_MinusLogProbMetric: 4.1112 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 359/1000
2023-09-12 01:38:10.551 
Epoch 359/1000 
	 loss: 4.0748, MinusLogProbMetric: 4.0748, val_loss: 4.1047, val_MinusLogProbMetric: 4.1047

Epoch 359: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0748 - MinusLogProbMetric: 4.0748 - val_loss: 4.1047 - val_MinusLogProbMetric: 4.1047 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 360/1000
2023-09-12 01:38:22.231 
Epoch 360/1000 
	 loss: 4.0716, MinusLogProbMetric: 4.0716, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 360: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0716 - MinusLogProbMetric: 4.0716 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 361/1000
2023-09-12 01:38:33.908 
Epoch 361/1000 
	 loss: 4.0718, MinusLogProbMetric: 4.0718, val_loss: 4.1033, val_MinusLogProbMetric: 4.1033

Epoch 361: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0718 - MinusLogProbMetric: 4.0718 - val_loss: 4.1033 - val_MinusLogProbMetric: 4.1033 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 362/1000
2023-09-12 01:38:45.697 
Epoch 362/1000 
	 loss: 4.0742, MinusLogProbMetric: 4.0742, val_loss: 4.1073, val_MinusLogProbMetric: 4.1073

Epoch 362: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0742 - MinusLogProbMetric: 4.0742 - val_loss: 4.1073 - val_MinusLogProbMetric: 4.1073 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 363/1000
2023-09-12 01:38:57.363 
Epoch 363/1000 
	 loss: 4.0744, MinusLogProbMetric: 4.0744, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 363: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0744 - MinusLogProbMetric: 4.0744 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 364/1000
2023-09-12 01:39:08.985 
Epoch 364/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1017, val_MinusLogProbMetric: 4.1017

Epoch 364: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1017 - val_MinusLogProbMetric: 4.1017 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 365/1000
2023-09-12 01:39:20.633 
Epoch 365/1000 
	 loss: 4.0735, MinusLogProbMetric: 4.0735, val_loss: 4.1264, val_MinusLogProbMetric: 4.1264

Epoch 365: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0735 - MinusLogProbMetric: 4.0735 - val_loss: 4.1264 - val_MinusLogProbMetric: 4.1264 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 366/1000
2023-09-12 01:39:32.215 
Epoch 366/1000 
	 loss: 4.0724, MinusLogProbMetric: 4.0724, val_loss: 4.1147, val_MinusLogProbMetric: 4.1147

Epoch 366: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0724 - MinusLogProbMetric: 4.0724 - val_loss: 4.1147 - val_MinusLogProbMetric: 4.1147 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 367/1000
2023-09-12 01:39:43.713 
Epoch 367/1000 
	 loss: 4.0751, MinusLogProbMetric: 4.0751, val_loss: 4.1070, val_MinusLogProbMetric: 4.1070

Epoch 367: val_loss did not improve from 4.09978
196/196 - 11s - loss: 4.0751 - MinusLogProbMetric: 4.0751 - val_loss: 4.1070 - val_MinusLogProbMetric: 4.1070 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 368/1000
2023-09-12 01:39:55.479 
Epoch 368/1000 
	 loss: 4.0741, MinusLogProbMetric: 4.0741, val_loss: 4.1074, val_MinusLogProbMetric: 4.1074

Epoch 368: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0741 - MinusLogProbMetric: 4.0741 - val_loss: 4.1074 - val_MinusLogProbMetric: 4.1074 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 369/1000
2023-09-12 01:40:07.029 
Epoch 369/1000 
	 loss: 4.0721, MinusLogProbMetric: 4.0721, val_loss: 4.1032, val_MinusLogProbMetric: 4.1032

Epoch 369: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0721 - MinusLogProbMetric: 4.0721 - val_loss: 4.1032 - val_MinusLogProbMetric: 4.1032 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 370/1000
2023-09-12 01:40:18.732 
Epoch 370/1000 
	 loss: 4.0739, MinusLogProbMetric: 4.0739, val_loss: 4.1083, val_MinusLogProbMetric: 4.1083

Epoch 370: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0739 - MinusLogProbMetric: 4.0739 - val_loss: 4.1083 - val_MinusLogProbMetric: 4.1083 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 371/1000
2023-09-12 01:40:30.396 
Epoch 371/1000 
	 loss: 4.0756, MinusLogProbMetric: 4.0756, val_loss: 4.1169, val_MinusLogProbMetric: 4.1169

Epoch 371: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0756 - MinusLogProbMetric: 4.0756 - val_loss: 4.1169 - val_MinusLogProbMetric: 4.1169 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 372/1000
2023-09-12 01:40:42.090 
Epoch 372/1000 
	 loss: 4.0765, MinusLogProbMetric: 4.0765, val_loss: 4.1073, val_MinusLogProbMetric: 4.1073

Epoch 372: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0765 - MinusLogProbMetric: 4.0765 - val_loss: 4.1073 - val_MinusLogProbMetric: 4.1073 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 373/1000
2023-09-12 01:40:53.694 
Epoch 373/1000 
	 loss: 4.0725, MinusLogProbMetric: 4.0725, val_loss: 4.1098, val_MinusLogProbMetric: 4.1098

Epoch 373: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0725 - MinusLogProbMetric: 4.0725 - val_loss: 4.1098 - val_MinusLogProbMetric: 4.1098 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 374/1000
2023-09-12 01:41:05.225 
Epoch 374/1000 
	 loss: 4.0801, MinusLogProbMetric: 4.0801, val_loss: 4.1078, val_MinusLogProbMetric: 4.1078

Epoch 374: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0801 - MinusLogProbMetric: 4.0801 - val_loss: 4.1078 - val_MinusLogProbMetric: 4.1078 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 375/1000
2023-09-12 01:41:16.806 
Epoch 375/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1053, val_MinusLogProbMetric: 4.1053

Epoch 375: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1053 - val_MinusLogProbMetric: 4.1053 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 376/1000
2023-09-12 01:41:28.621 
Epoch 376/1000 
	 loss: 4.0761, MinusLogProbMetric: 4.0761, val_loss: 4.1125, val_MinusLogProbMetric: 4.1125

Epoch 376: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0761 - MinusLogProbMetric: 4.0761 - val_loss: 4.1125 - val_MinusLogProbMetric: 4.1125 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-12 01:41:40.140 
Epoch 377/1000 
	 loss: 4.0738, MinusLogProbMetric: 4.0738, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 377: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0738 - MinusLogProbMetric: 4.0738 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 378/1000
2023-09-12 01:41:51.846 
Epoch 378/1000 
	 loss: 4.0713, MinusLogProbMetric: 4.0713, val_loss: 4.1091, val_MinusLogProbMetric: 4.1091

Epoch 378: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0713 - MinusLogProbMetric: 4.0713 - val_loss: 4.1091 - val_MinusLogProbMetric: 4.1091 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 379/1000
2023-09-12 01:42:03.607 
Epoch 379/1000 
	 loss: 4.0717, MinusLogProbMetric: 4.0717, val_loss: 4.1086, val_MinusLogProbMetric: 4.1086

Epoch 379: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0717 - MinusLogProbMetric: 4.0717 - val_loss: 4.1086 - val_MinusLogProbMetric: 4.1086 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-12 01:42:15.262 
Epoch 380/1000 
	 loss: 4.0722, MinusLogProbMetric: 4.0722, val_loss: 4.1039, val_MinusLogProbMetric: 4.1039

Epoch 380: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0722 - MinusLogProbMetric: 4.0722 - val_loss: 4.1039 - val_MinusLogProbMetric: 4.1039 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 381/1000
2023-09-12 01:42:26.972 
Epoch 381/1000 
	 loss: 4.0735, MinusLogProbMetric: 4.0735, val_loss: 4.1302, val_MinusLogProbMetric: 4.1302

Epoch 381: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0735 - MinusLogProbMetric: 4.0735 - val_loss: 4.1302 - val_MinusLogProbMetric: 4.1302 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 382/1000
2023-09-12 01:42:38.724 
Epoch 382/1000 
	 loss: 4.0729, MinusLogProbMetric: 4.0729, val_loss: 4.1074, val_MinusLogProbMetric: 4.1074

Epoch 382: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0729 - MinusLogProbMetric: 4.0729 - val_loss: 4.1074 - val_MinusLogProbMetric: 4.1074 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 383/1000
2023-09-12 01:42:50.289 
Epoch 383/1000 
	 loss: 4.0663, MinusLogProbMetric: 4.0663, val_loss: 4.1027, val_MinusLogProbMetric: 4.1027

Epoch 383: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0663 - MinusLogProbMetric: 4.0663 - val_loss: 4.1027 - val_MinusLogProbMetric: 4.1027 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 384/1000
2023-09-12 01:43:01.939 
Epoch 384/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 384: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 385/1000
2023-09-12 01:43:13.561 
Epoch 385/1000 
	 loss: 4.0679, MinusLogProbMetric: 4.0679, val_loss: 4.1022, val_MinusLogProbMetric: 4.1022

Epoch 385: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0679 - MinusLogProbMetric: 4.0679 - val_loss: 4.1022 - val_MinusLogProbMetric: 4.1022 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 386/1000
2023-09-12 01:43:25.263 
Epoch 386/1000 
	 loss: 4.0667, MinusLogProbMetric: 4.0667, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 386: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0667 - MinusLogProbMetric: 4.0667 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 387/1000
2023-09-12 01:43:36.926 
Epoch 387/1000 
	 loss: 4.0657, MinusLogProbMetric: 4.0657, val_loss: 4.1017, val_MinusLogProbMetric: 4.1017

Epoch 387: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0657 - MinusLogProbMetric: 4.0657 - val_loss: 4.1017 - val_MinusLogProbMetric: 4.1017 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 388/1000
2023-09-12 01:43:48.610 
Epoch 388/1000 
	 loss: 4.0664, MinusLogProbMetric: 4.0664, val_loss: 4.1015, val_MinusLogProbMetric: 4.1015

Epoch 388: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0664 - MinusLogProbMetric: 4.0664 - val_loss: 4.1015 - val_MinusLogProbMetric: 4.1015 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 389/1000
2023-09-12 01:44:00.098 
Epoch 389/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 389: val_loss did not improve from 4.09978
196/196 - 11s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 390/1000
2023-09-12 01:44:11.663 
Epoch 390/1000 
	 loss: 4.0696, MinusLogProbMetric: 4.0696, val_loss: 4.1084, val_MinusLogProbMetric: 4.1084

Epoch 390: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0696 - MinusLogProbMetric: 4.0696 - val_loss: 4.1084 - val_MinusLogProbMetric: 4.1084 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 391/1000
2023-09-12 01:44:23.356 
Epoch 391/1000 
	 loss: 4.0658, MinusLogProbMetric: 4.0658, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 391: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0658 - MinusLogProbMetric: 4.0658 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 392/1000
2023-09-12 01:44:34.907 
Epoch 392/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1029, val_MinusLogProbMetric: 4.1029

Epoch 392: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1029 - val_MinusLogProbMetric: 4.1029 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 393/1000
2023-09-12 01:44:46.492 
Epoch 393/1000 
	 loss: 4.0659, MinusLogProbMetric: 4.0659, val_loss: 4.1018, val_MinusLogProbMetric: 4.1018

Epoch 393: val_loss did not improve from 4.09978
196/196 - 12s - loss: 4.0659 - MinusLogProbMetric: 4.0659 - val_loss: 4.1018 - val_MinusLogProbMetric: 4.1018 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 394/1000
2023-09-12 01:44:58.005 
Epoch 394/1000 
	 loss: 4.0664, MinusLogProbMetric: 4.0664, val_loss: 4.0993, val_MinusLogProbMetric: 4.0993

Epoch 394: val_loss improved from 4.09978 to 4.09927, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0664 - MinusLogProbMetric: 4.0664 - val_loss: 4.0993 - val_MinusLogProbMetric: 4.0993 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 395/1000
2023-09-12 01:45:09.925 
Epoch 395/1000 
	 loss: 4.0660, MinusLogProbMetric: 4.0660, val_loss: 4.1016, val_MinusLogProbMetric: 4.1016

Epoch 395: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0660 - MinusLogProbMetric: 4.0660 - val_loss: 4.1016 - val_MinusLogProbMetric: 4.1016 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 396/1000
2023-09-12 01:45:21.559 
Epoch 396/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1034, val_MinusLogProbMetric: 4.1034

Epoch 396: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1034 - val_MinusLogProbMetric: 4.1034 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 397/1000
2023-09-12 01:45:33.191 
Epoch 397/1000 
	 loss: 4.0667, MinusLogProbMetric: 4.0667, val_loss: 4.1022, val_MinusLogProbMetric: 4.1022

Epoch 397: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0667 - MinusLogProbMetric: 4.0667 - val_loss: 4.1022 - val_MinusLogProbMetric: 4.1022 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 398/1000
2023-09-12 01:45:44.712 
Epoch 398/1000 
	 loss: 4.0644, MinusLogProbMetric: 4.0644, val_loss: 4.1043, val_MinusLogProbMetric: 4.1043

Epoch 398: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0644 - MinusLogProbMetric: 4.0644 - val_loss: 4.1043 - val_MinusLogProbMetric: 4.1043 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 399/1000
2023-09-12 01:45:56.369 
Epoch 399/1000 
	 loss: 4.0649, MinusLogProbMetric: 4.0649, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 399: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0649 - MinusLogProbMetric: 4.0649 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 400/1000
2023-09-12 01:46:07.919 
Epoch 400/1000 
	 loss: 4.0657, MinusLogProbMetric: 4.0657, val_loss: 4.1045, val_MinusLogProbMetric: 4.1045

Epoch 400: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0657 - MinusLogProbMetric: 4.0657 - val_loss: 4.1045 - val_MinusLogProbMetric: 4.1045 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 401/1000
2023-09-12 01:46:19.571 
Epoch 401/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1036, val_MinusLogProbMetric: 4.1036

Epoch 401: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1036 - val_MinusLogProbMetric: 4.1036 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 402/1000
2023-09-12 01:46:31.319 
Epoch 402/1000 
	 loss: 4.0655, MinusLogProbMetric: 4.0655, val_loss: 4.1027, val_MinusLogProbMetric: 4.1027

Epoch 402: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0655 - MinusLogProbMetric: 4.0655 - val_loss: 4.1027 - val_MinusLogProbMetric: 4.1027 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 403/1000
2023-09-12 01:46:43.048 
Epoch 403/1000 
	 loss: 4.0644, MinusLogProbMetric: 4.0644, val_loss: 4.1015, val_MinusLogProbMetric: 4.1015

Epoch 403: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0644 - MinusLogProbMetric: 4.0644 - val_loss: 4.1015 - val_MinusLogProbMetric: 4.1015 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 404/1000
2023-09-12 01:46:54.762 
Epoch 404/1000 
	 loss: 4.0656, MinusLogProbMetric: 4.0656, val_loss: 4.1028, val_MinusLogProbMetric: 4.1028

Epoch 404: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0656 - MinusLogProbMetric: 4.0656 - val_loss: 4.1028 - val_MinusLogProbMetric: 4.1028 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 405/1000
2023-09-12 01:47:06.380 
Epoch 405/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.0999, val_MinusLogProbMetric: 4.0999

Epoch 405: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.0999 - val_MinusLogProbMetric: 4.0999 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 406/1000
2023-09-12 01:47:18.019 
Epoch 406/1000 
	 loss: 4.0663, MinusLogProbMetric: 4.0663, val_loss: 4.1056, val_MinusLogProbMetric: 4.1056

Epoch 406: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0663 - MinusLogProbMetric: 4.0663 - val_loss: 4.1056 - val_MinusLogProbMetric: 4.1056 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 407/1000
2023-09-12 01:47:29.586 
Epoch 407/1000 
	 loss: 4.0642, MinusLogProbMetric: 4.0642, val_loss: 4.1046, val_MinusLogProbMetric: 4.1046

Epoch 407: val_loss did not improve from 4.09927
196/196 - 12s - loss: 4.0642 - MinusLogProbMetric: 4.0642 - val_loss: 4.1046 - val_MinusLogProbMetric: 4.1046 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 408/1000
2023-09-12 01:47:41.160 
Epoch 408/1000 
	 loss: 4.0646, MinusLogProbMetric: 4.0646, val_loss: 4.0992, val_MinusLogProbMetric: 4.0992

Epoch 408: val_loss improved from 4.09927 to 4.09922, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0646 - MinusLogProbMetric: 4.0646 - val_loss: 4.0992 - val_MinusLogProbMetric: 4.0992 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 409/1000
2023-09-12 01:47:52.875 
Epoch 409/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1026, val_MinusLogProbMetric: 4.1026

Epoch 409: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1026 - val_MinusLogProbMetric: 4.1026 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 410/1000
2023-09-12 01:48:04.581 
Epoch 410/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1043, val_MinusLogProbMetric: 4.1043

Epoch 410: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1043 - val_MinusLogProbMetric: 4.1043 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 411/1000
2023-09-12 01:48:16.297 
Epoch 411/1000 
	 loss: 4.0649, MinusLogProbMetric: 4.0649, val_loss: 4.1011, val_MinusLogProbMetric: 4.1011

Epoch 411: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0649 - MinusLogProbMetric: 4.0649 - val_loss: 4.1011 - val_MinusLogProbMetric: 4.1011 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 412/1000
2023-09-12 01:48:27.929 
Epoch 412/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1012, val_MinusLogProbMetric: 4.1012

Epoch 412: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1012 - val_MinusLogProbMetric: 4.1012 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 413/1000
2023-09-12 01:48:39.693 
Epoch 413/1000 
	 loss: 4.0643, MinusLogProbMetric: 4.0643, val_loss: 4.0997, val_MinusLogProbMetric: 4.0997

Epoch 413: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0643 - MinusLogProbMetric: 4.0643 - val_loss: 4.0997 - val_MinusLogProbMetric: 4.0997 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 414/1000
2023-09-12 01:48:51.358 
Epoch 414/1000 
	 loss: 4.0666, MinusLogProbMetric: 4.0666, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 414: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0666 - MinusLogProbMetric: 4.0666 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 415/1000
2023-09-12 01:49:03.066 
Epoch 415/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1011, val_MinusLogProbMetric: 4.1011

Epoch 415: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1011 - val_MinusLogProbMetric: 4.1011 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 416/1000
2023-09-12 01:49:14.815 
Epoch 416/1000 
	 loss: 4.0662, MinusLogProbMetric: 4.0662, val_loss: 4.0998, val_MinusLogProbMetric: 4.0998

Epoch 416: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0662 - MinusLogProbMetric: 4.0662 - val_loss: 4.0998 - val_MinusLogProbMetric: 4.0998 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 417/1000
2023-09-12 01:49:26.490 
Epoch 417/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1065, val_MinusLogProbMetric: 4.1065

Epoch 417: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1065 - val_MinusLogProbMetric: 4.1065 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-12 01:49:38.210 
Epoch 418/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1125, val_MinusLogProbMetric: 4.1125

Epoch 418: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1125 - val_MinusLogProbMetric: 4.1125 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 419/1000
2023-09-12 01:49:49.931 
Epoch 419/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1021, val_MinusLogProbMetric: 4.1021

Epoch 419: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1021 - val_MinusLogProbMetric: 4.1021 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 420/1000
2023-09-12 01:50:01.544 
Epoch 420/1000 
	 loss: 4.0648, MinusLogProbMetric: 4.0648, val_loss: 4.1004, val_MinusLogProbMetric: 4.1004

Epoch 420: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0648 - MinusLogProbMetric: 4.0648 - val_loss: 4.1004 - val_MinusLogProbMetric: 4.1004 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 421/1000
2023-09-12 01:50:13.330 
Epoch 421/1000 
	 loss: 4.0643, MinusLogProbMetric: 4.0643, val_loss: 4.1033, val_MinusLogProbMetric: 4.1033

Epoch 421: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0643 - MinusLogProbMetric: 4.0643 - val_loss: 4.1033 - val_MinusLogProbMetric: 4.1033 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 422/1000
2023-09-12 01:50:25.007 
Epoch 422/1000 
	 loss: 4.0643, MinusLogProbMetric: 4.0643, val_loss: 4.1036, val_MinusLogProbMetric: 4.1036

Epoch 422: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0643 - MinusLogProbMetric: 4.0643 - val_loss: 4.1036 - val_MinusLogProbMetric: 4.1036 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 423/1000
2023-09-12 01:50:36.650 
Epoch 423/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 423: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 424/1000
2023-09-12 01:50:48.340 
Epoch 424/1000 
	 loss: 4.0642, MinusLogProbMetric: 4.0642, val_loss: 4.1041, val_MinusLogProbMetric: 4.1041

Epoch 424: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0642 - MinusLogProbMetric: 4.0642 - val_loss: 4.1041 - val_MinusLogProbMetric: 4.1041 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 425/1000
2023-09-12 01:50:59.718 
Epoch 425/1000 
	 loss: 4.0641, MinusLogProbMetric: 4.0641, val_loss: 4.1026, val_MinusLogProbMetric: 4.1026

Epoch 425: val_loss did not improve from 4.09922
196/196 - 11s - loss: 4.0641 - MinusLogProbMetric: 4.0641 - val_loss: 4.1026 - val_MinusLogProbMetric: 4.1026 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 426/1000
2023-09-12 01:51:11.063 
Epoch 426/1000 
	 loss: 4.0647, MinusLogProbMetric: 4.0647, val_loss: 4.1037, val_MinusLogProbMetric: 4.1037

Epoch 426: val_loss did not improve from 4.09922
196/196 - 11s - loss: 4.0647 - MinusLogProbMetric: 4.0647 - val_loss: 4.1037 - val_MinusLogProbMetric: 4.1037 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 427/1000
2023-09-12 01:51:21.419 
Epoch 427/1000 
	 loss: 4.0645, MinusLogProbMetric: 4.0645, val_loss: 4.1209, val_MinusLogProbMetric: 4.1209

Epoch 427: val_loss did not improve from 4.09922
196/196 - 10s - loss: 4.0645 - MinusLogProbMetric: 4.0645 - val_loss: 4.1209 - val_MinusLogProbMetric: 4.1209 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 428/1000
2023-09-12 01:51:32.850 
Epoch 428/1000 
	 loss: 4.0647, MinusLogProbMetric: 4.0647, val_loss: 4.0997, val_MinusLogProbMetric: 4.0997

Epoch 428: val_loss did not improve from 4.09922
196/196 - 11s - loss: 4.0647 - MinusLogProbMetric: 4.0647 - val_loss: 4.0997 - val_MinusLogProbMetric: 4.0997 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 429/1000
2023-09-12 01:51:44.584 
Epoch 429/1000 
	 loss: 4.0658, MinusLogProbMetric: 4.0658, val_loss: 4.1011, val_MinusLogProbMetric: 4.1011

Epoch 429: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0658 - MinusLogProbMetric: 4.0658 - val_loss: 4.1011 - val_MinusLogProbMetric: 4.1011 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 430/1000
2023-09-12 01:51:56.294 
Epoch 430/1000 
	 loss: 4.0647, MinusLogProbMetric: 4.0647, val_loss: 4.1019, val_MinusLogProbMetric: 4.1019

Epoch 430: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0647 - MinusLogProbMetric: 4.0647 - val_loss: 4.1019 - val_MinusLogProbMetric: 4.1019 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 431/1000
2023-09-12 01:52:08.117 
Epoch 431/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1032, val_MinusLogProbMetric: 4.1032

Epoch 431: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1032 - val_MinusLogProbMetric: 4.1032 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 432/1000
2023-09-12 01:52:19.811 
Epoch 432/1000 
	 loss: 4.0643, MinusLogProbMetric: 4.0643, val_loss: 4.1049, val_MinusLogProbMetric: 4.1049

Epoch 432: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0643 - MinusLogProbMetric: 4.0643 - val_loss: 4.1049 - val_MinusLogProbMetric: 4.1049 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 433/1000
2023-09-12 01:52:31.441 
Epoch 433/1000 
	 loss: 4.0670, MinusLogProbMetric: 4.0670, val_loss: 4.1035, val_MinusLogProbMetric: 4.1035

Epoch 433: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0670 - MinusLogProbMetric: 4.0670 - val_loss: 4.1035 - val_MinusLogProbMetric: 4.1035 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 434/1000
2023-09-12 01:52:42.995 
Epoch 434/1000 
	 loss: 4.0640, MinusLogProbMetric: 4.0640, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 434: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0640 - MinusLogProbMetric: 4.0640 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 435/1000
2023-09-12 01:52:54.753 
Epoch 435/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1009, val_MinusLogProbMetric: 4.1009

Epoch 435: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1009 - val_MinusLogProbMetric: 4.1009 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 436/1000
2023-09-12 01:53:06.460 
Epoch 436/1000 
	 loss: 4.0643, MinusLogProbMetric: 4.0643, val_loss: 4.1019, val_MinusLogProbMetric: 4.1019

Epoch 436: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0643 - MinusLogProbMetric: 4.0643 - val_loss: 4.1019 - val_MinusLogProbMetric: 4.1019 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 437/1000
2023-09-12 01:53:18.069 
Epoch 437/1000 
	 loss: 4.0658, MinusLogProbMetric: 4.0658, val_loss: 4.1004, val_MinusLogProbMetric: 4.1004

Epoch 437: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0658 - MinusLogProbMetric: 4.0658 - val_loss: 4.1004 - val_MinusLogProbMetric: 4.1004 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 438/1000
2023-09-12 01:53:29.864 
Epoch 438/1000 
	 loss: 4.0639, MinusLogProbMetric: 4.0639, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 438: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0639 - MinusLogProbMetric: 4.0639 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 439/1000
2023-09-12 01:53:41.654 
Epoch 439/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 439: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-12 01:53:53.438 
Epoch 440/1000 
	 loss: 4.0644, MinusLogProbMetric: 4.0644, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 440: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0644 - MinusLogProbMetric: 4.0644 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 441/1000
2023-09-12 01:54:05.071 
Epoch 441/1000 
	 loss: 4.0640, MinusLogProbMetric: 4.0640, val_loss: 4.1025, val_MinusLogProbMetric: 4.1025

Epoch 441: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0640 - MinusLogProbMetric: 4.0640 - val_loss: 4.1025 - val_MinusLogProbMetric: 4.1025 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 442/1000
2023-09-12 01:54:16.719 
Epoch 442/1000 
	 loss: 4.0680, MinusLogProbMetric: 4.0680, val_loss: 4.1099, val_MinusLogProbMetric: 4.1099

Epoch 442: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0680 - MinusLogProbMetric: 4.0680 - val_loss: 4.1099 - val_MinusLogProbMetric: 4.1099 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 443/1000
2023-09-12 01:54:28.479 
Epoch 443/1000 
	 loss: 4.0639, MinusLogProbMetric: 4.0639, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 443: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0639 - MinusLogProbMetric: 4.0639 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 444/1000
2023-09-12 01:54:40.182 
Epoch 444/1000 
	 loss: 4.0642, MinusLogProbMetric: 4.0642, val_loss: 4.1038, val_MinusLogProbMetric: 4.1038

Epoch 444: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0642 - MinusLogProbMetric: 4.0642 - val_loss: 4.1038 - val_MinusLogProbMetric: 4.1038 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 445/1000
2023-09-12 01:54:51.797 
Epoch 445/1000 
	 loss: 4.0622, MinusLogProbMetric: 4.0622, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 445: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0622 - MinusLogProbMetric: 4.0622 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 446/1000
2023-09-12 01:55:03.533 
Epoch 446/1000 
	 loss: 4.0633, MinusLogProbMetric: 4.0633, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 446: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0633 - MinusLogProbMetric: 4.0633 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 447/1000
2023-09-12 01:55:15.229 
Epoch 447/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 447: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 448/1000
2023-09-12 01:55:26.911 
Epoch 448/1000 
	 loss: 4.0619, MinusLogProbMetric: 4.0619, val_loss: 4.1017, val_MinusLogProbMetric: 4.1017

Epoch 448: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0619 - MinusLogProbMetric: 4.0619 - val_loss: 4.1017 - val_MinusLogProbMetric: 4.1017 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 449/1000
2023-09-12 01:55:38.597 
Epoch 449/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.0995, val_MinusLogProbMetric: 4.0995

Epoch 449: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.0995 - val_MinusLogProbMetric: 4.0995 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 450/1000
2023-09-12 01:55:50.352 
Epoch 450/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 450: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 451/1000
2023-09-12 01:56:02.128 
Epoch 451/1000 
	 loss: 4.0630, MinusLogProbMetric: 4.0630, val_loss: 4.1023, val_MinusLogProbMetric: 4.1023

Epoch 451: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0630 - MinusLogProbMetric: 4.0630 - val_loss: 4.1023 - val_MinusLogProbMetric: 4.1023 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 452/1000
2023-09-12 01:56:13.779 
Epoch 452/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 452: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 453/1000
2023-09-12 01:56:25.475 
Epoch 453/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1023, val_MinusLogProbMetric: 4.1023

Epoch 453: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1023 - val_MinusLogProbMetric: 4.1023 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 454/1000
2023-09-12 01:56:37.341 
Epoch 454/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.0995, val_MinusLogProbMetric: 4.0995

Epoch 454: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.0995 - val_MinusLogProbMetric: 4.0995 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 455/1000
2023-09-12 01:56:48.923 
Epoch 455/1000 
	 loss: 4.0620, MinusLogProbMetric: 4.0620, val_loss: 4.1015, val_MinusLogProbMetric: 4.1015

Epoch 455: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0620 - MinusLogProbMetric: 4.0620 - val_loss: 4.1015 - val_MinusLogProbMetric: 4.1015 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 456/1000
2023-09-12 01:57:00.641 
Epoch 456/1000 
	 loss: 4.0629, MinusLogProbMetric: 4.0629, val_loss: 4.1057, val_MinusLogProbMetric: 4.1057

Epoch 456: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0629 - MinusLogProbMetric: 4.0629 - val_loss: 4.1057 - val_MinusLogProbMetric: 4.1057 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 457/1000
2023-09-12 01:57:12.296 
Epoch 457/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.0999, val_MinusLogProbMetric: 4.0999

Epoch 457: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.0999 - val_MinusLogProbMetric: 4.0999 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 458/1000
2023-09-12 01:57:24.049 
Epoch 458/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 458: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 459/1000
2023-09-12 01:57:35.755 
Epoch 459/1000 
	 loss: 4.0616, MinusLogProbMetric: 4.0616, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 459: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0616 - MinusLogProbMetric: 4.0616 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 460/1000
2023-09-12 01:57:47.431 
Epoch 460/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 460: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 461/1000
2023-09-12 01:57:59.187 
Epoch 461/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1016, val_MinusLogProbMetric: 4.1016

Epoch 461: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1016 - val_MinusLogProbMetric: 4.1016 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 462/1000
2023-09-12 01:58:10.894 
Epoch 462/1000 
	 loss: 4.0613, MinusLogProbMetric: 4.0613, val_loss: 4.1032, val_MinusLogProbMetric: 4.1032

Epoch 462: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0613 - MinusLogProbMetric: 4.0613 - val_loss: 4.1032 - val_MinusLogProbMetric: 4.1032 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 463/1000
2023-09-12 01:58:22.517 
Epoch 463/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 463: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 464/1000
2023-09-12 01:58:34.271 
Epoch 464/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 464: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 465/1000
2023-09-12 01:58:46.001 
Epoch 465/1000 
	 loss: 4.0607, MinusLogProbMetric: 4.0607, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 465: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0607 - MinusLogProbMetric: 4.0607 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 466/1000
2023-09-12 01:58:57.646 
Epoch 466/1000 
	 loss: 4.0615, MinusLogProbMetric: 4.0615, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 466: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0615 - MinusLogProbMetric: 4.0615 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 467/1000
2023-09-12 01:59:09.296 
Epoch 467/1000 
	 loss: 4.0613, MinusLogProbMetric: 4.0613, val_loss: 4.1004, val_MinusLogProbMetric: 4.1004

Epoch 467: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0613 - MinusLogProbMetric: 4.0613 - val_loss: 4.1004 - val_MinusLogProbMetric: 4.1004 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 468/1000
2023-09-12 01:59:21.101 
Epoch 468/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1028, val_MinusLogProbMetric: 4.1028

Epoch 468: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1028 - val_MinusLogProbMetric: 4.1028 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 469/1000
2023-09-12 01:59:32.891 
Epoch 469/1000 
	 loss: 4.0683, MinusLogProbMetric: 4.0683, val_loss: 4.1021, val_MinusLogProbMetric: 4.1021

Epoch 469: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0683 - MinusLogProbMetric: 4.0683 - val_loss: 4.1021 - val_MinusLogProbMetric: 4.1021 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 470/1000
2023-09-12 01:59:44.635 
Epoch 470/1000 
	 loss: 4.0621, MinusLogProbMetric: 4.0621, val_loss: 4.1021, val_MinusLogProbMetric: 4.1021

Epoch 470: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0621 - MinusLogProbMetric: 4.0621 - val_loss: 4.1021 - val_MinusLogProbMetric: 4.1021 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 471/1000
2023-09-12 01:59:56.301 
Epoch 471/1000 
	 loss: 4.0620, MinusLogProbMetric: 4.0620, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 471: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0620 - MinusLogProbMetric: 4.0620 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 472/1000
2023-09-12 02:00:08.083 
Epoch 472/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.1023, val_MinusLogProbMetric: 4.1023

Epoch 472: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.1023 - val_MinusLogProbMetric: 4.1023 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 473/1000
2023-09-12 02:00:19.733 
Epoch 473/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1026, val_MinusLogProbMetric: 4.1026

Epoch 473: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1026 - val_MinusLogProbMetric: 4.1026 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 474/1000
2023-09-12 02:00:31.363 
Epoch 474/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.0999, val_MinusLogProbMetric: 4.0999

Epoch 474: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.0999 - val_MinusLogProbMetric: 4.0999 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 475/1000
2023-09-12 02:00:43.219 
Epoch 475/1000 
	 loss: 4.0603, MinusLogProbMetric: 4.0603, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 475: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0603 - MinusLogProbMetric: 4.0603 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 476/1000
2023-09-12 02:00:54.918 
Epoch 476/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 476: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 477/1000
2023-09-12 02:01:06.635 
Epoch 477/1000 
	 loss: 4.0619, MinusLogProbMetric: 4.0619, val_loss: 4.0994, val_MinusLogProbMetric: 4.0994

Epoch 477: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0619 - MinusLogProbMetric: 4.0619 - val_loss: 4.0994 - val_MinusLogProbMetric: 4.0994 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 478/1000
2023-09-12 02:01:18.394 
Epoch 478/1000 
	 loss: 4.0621, MinusLogProbMetric: 4.0621, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 478: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0621 - MinusLogProbMetric: 4.0621 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 479/1000
2023-09-12 02:01:30.031 
Epoch 479/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 479: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 480/1000
2023-09-12 02:01:41.711 
Epoch 480/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 480: val_loss did not improve from 4.09922
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 481/1000
2023-09-12 02:01:53.294 
Epoch 481/1000 
	 loss: 4.0617, MinusLogProbMetric: 4.0617, val_loss: 4.0989, val_MinusLogProbMetric: 4.0989

Epoch 481: val_loss improved from 4.09922 to 4.09892, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_43/weights/best_weights.h5
196/196 - 12s - loss: 4.0617 - MinusLogProbMetric: 4.0617 - val_loss: 4.0989 - val_MinusLogProbMetric: 4.0989 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 482/1000
2023-09-12 02:02:05.098 
Epoch 482/1000 
	 loss: 4.0606, MinusLogProbMetric: 4.0606, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 482: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0606 - MinusLogProbMetric: 4.0606 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 483/1000
2023-09-12 02:02:16.814 
Epoch 483/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.0995, val_MinusLogProbMetric: 4.0995

Epoch 483: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.0995 - val_MinusLogProbMetric: 4.0995 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 484/1000
2023-09-12 02:02:28.661 
Epoch 484/1000 
	 loss: 4.0607, MinusLogProbMetric: 4.0607, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 484: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0607 - MinusLogProbMetric: 4.0607 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 485/1000
2023-09-12 02:02:40.473 
Epoch 485/1000 
	 loss: 4.0631, MinusLogProbMetric: 4.0631, val_loss: 4.1097, val_MinusLogProbMetric: 4.1097

Epoch 485: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0631 - MinusLogProbMetric: 4.0631 - val_loss: 4.1097 - val_MinusLogProbMetric: 4.1097 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 486/1000
2023-09-12 02:02:52.229 
Epoch 486/1000 
	 loss: 4.0614, MinusLogProbMetric: 4.0614, val_loss: 4.1009, val_MinusLogProbMetric: 4.1009

Epoch 486: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0614 - MinusLogProbMetric: 4.0614 - val_loss: 4.1009 - val_MinusLogProbMetric: 4.1009 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 487/1000
2023-09-12 02:03:03.908 
Epoch 487/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1021, val_MinusLogProbMetric: 4.1021

Epoch 487: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1021 - val_MinusLogProbMetric: 4.1021 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 488/1000
2023-09-12 02:03:15.559 
Epoch 488/1000 
	 loss: 4.0603, MinusLogProbMetric: 4.0603, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 488: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0603 - MinusLogProbMetric: 4.0603 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 489/1000
2023-09-12 02:03:27.234 
Epoch 489/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1019, val_MinusLogProbMetric: 4.1019

Epoch 489: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1019 - val_MinusLogProbMetric: 4.1019 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 490/1000
2023-09-12 02:03:38.994 
Epoch 490/1000 
	 loss: 4.0614, MinusLogProbMetric: 4.0614, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 490: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0614 - MinusLogProbMetric: 4.0614 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 491/1000
2023-09-12 02:03:50.678 
Epoch 491/1000 
	 loss: 4.0606, MinusLogProbMetric: 4.0606, val_loss: 4.1011, val_MinusLogProbMetric: 4.1011

Epoch 491: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0606 - MinusLogProbMetric: 4.0606 - val_loss: 4.1011 - val_MinusLogProbMetric: 4.1011 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 492/1000
2023-09-12 02:04:02.396 
Epoch 492/1000 
	 loss: 4.0615, MinusLogProbMetric: 4.0615, val_loss: 4.1024, val_MinusLogProbMetric: 4.1024

Epoch 492: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0615 - MinusLogProbMetric: 4.0615 - val_loss: 4.1024 - val_MinusLogProbMetric: 4.1024 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 493/1000
2023-09-12 02:04:14.204 
Epoch 493/1000 
	 loss: 4.0607, MinusLogProbMetric: 4.0607, val_loss: 4.1043, val_MinusLogProbMetric: 4.1043

Epoch 493: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0607 - MinusLogProbMetric: 4.0607 - val_loss: 4.1043 - val_MinusLogProbMetric: 4.1043 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 494/1000
2023-09-12 02:04:26.054 
Epoch 494/1000 
	 loss: 4.0618, MinusLogProbMetric: 4.0618, val_loss: 4.1068, val_MinusLogProbMetric: 4.1068

Epoch 494: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0618 - MinusLogProbMetric: 4.0618 - val_loss: 4.1068 - val_MinusLogProbMetric: 4.1068 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 495/1000
2023-09-12 02:04:37.714 
Epoch 495/1000 
	 loss: 4.0604, MinusLogProbMetric: 4.0604, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 495: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0604 - MinusLogProbMetric: 4.0604 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 496/1000
2023-09-12 02:04:49.431 
Epoch 496/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 496: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 497/1000
2023-09-12 02:05:01.160 
Epoch 497/1000 
	 loss: 4.0607, MinusLogProbMetric: 4.0607, val_loss: 4.1021, val_MinusLogProbMetric: 4.1021

Epoch 497: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0607 - MinusLogProbMetric: 4.0607 - val_loss: 4.1021 - val_MinusLogProbMetric: 4.1021 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 498/1000
2023-09-12 02:05:12.759 
Epoch 498/1000 
	 loss: 4.0603, MinusLogProbMetric: 4.0603, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 498: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0603 - MinusLogProbMetric: 4.0603 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 499/1000
2023-09-12 02:05:24.374 
Epoch 499/1000 
	 loss: 4.0644, MinusLogProbMetric: 4.0644, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 499: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0644 - MinusLogProbMetric: 4.0644 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 500/1000
2023-09-12 02:05:36.082 
Epoch 500/1000 
	 loss: 4.0605, MinusLogProbMetric: 4.0605, val_loss: 4.1015, val_MinusLogProbMetric: 4.1015

Epoch 500: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0605 - MinusLogProbMetric: 4.0605 - val_loss: 4.1015 - val_MinusLogProbMetric: 4.1015 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 501/1000
2023-09-12 02:05:47.806 
Epoch 501/1000 
	 loss: 4.0606, MinusLogProbMetric: 4.0606, val_loss: 4.1002, val_MinusLogProbMetric: 4.1002

Epoch 501: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0606 - MinusLogProbMetric: 4.0606 - val_loss: 4.1002 - val_MinusLogProbMetric: 4.1002 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 502/1000
2023-09-12 02:05:59.496 
Epoch 502/1000 
	 loss: 4.0601, MinusLogProbMetric: 4.0601, val_loss: 4.0998, val_MinusLogProbMetric: 4.0998

Epoch 502: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0601 - MinusLogProbMetric: 4.0601 - val_loss: 4.0998 - val_MinusLogProbMetric: 4.0998 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 503/1000
2023-09-12 02:06:11.258 
Epoch 503/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1047, val_MinusLogProbMetric: 4.1047

Epoch 503: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1047 - val_MinusLogProbMetric: 4.1047 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 504/1000
2023-09-12 02:06:22.881 
Epoch 504/1000 
	 loss: 4.0604, MinusLogProbMetric: 4.0604, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 504: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0604 - MinusLogProbMetric: 4.0604 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 505/1000
2023-09-12 02:06:34.607 
Epoch 505/1000 
	 loss: 4.0665, MinusLogProbMetric: 4.0665, val_loss: 4.1060, val_MinusLogProbMetric: 4.1060

Epoch 505: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0665 - MinusLogProbMetric: 4.0665 - val_loss: 4.1060 - val_MinusLogProbMetric: 4.1060 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 506/1000
2023-09-12 02:06:46.405 
Epoch 506/1000 
	 loss: 4.0615, MinusLogProbMetric: 4.0615, val_loss: 4.1004, val_MinusLogProbMetric: 4.1004

Epoch 506: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0615 - MinusLogProbMetric: 4.0615 - val_loss: 4.1004 - val_MinusLogProbMetric: 4.1004 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 507/1000
2023-09-12 02:06:58.812 
Epoch 507/1000 
	 loss: 4.0601, MinusLogProbMetric: 4.0601, val_loss: 4.0997, val_MinusLogProbMetric: 4.0997

Epoch 507: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0601 - MinusLogProbMetric: 4.0601 - val_loss: 4.0997 - val_MinusLogProbMetric: 4.0997 - lr: 1.2500e-04 - 12s/epoch - 63ms/step
Epoch 508/1000
2023-09-12 02:07:10.481 
Epoch 508/1000 
	 loss: 4.0602, MinusLogProbMetric: 4.0602, val_loss: 4.1013, val_MinusLogProbMetric: 4.1013

Epoch 508: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0602 - MinusLogProbMetric: 4.0602 - val_loss: 4.1013 - val_MinusLogProbMetric: 4.1013 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 509/1000
2023-09-12 02:07:21.284 
Epoch 509/1000 
	 loss: 4.0614, MinusLogProbMetric: 4.0614, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 509: val_loss did not improve from 4.09892
196/196 - 11s - loss: 4.0614 - MinusLogProbMetric: 4.0614 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 510/1000
2023-09-12 02:07:32.010 
Epoch 510/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 510: val_loss did not improve from 4.09892
196/196 - 11s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 511/1000
2023-09-12 02:07:42.401 
Epoch 511/1000 
	 loss: 4.0604, MinusLogProbMetric: 4.0604, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 511: val_loss did not improve from 4.09892
196/196 - 10s - loss: 4.0604 - MinusLogProbMetric: 4.0604 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 512/1000
2023-09-12 02:07:53.955 
Epoch 512/1000 
	 loss: 4.0606, MinusLogProbMetric: 4.0606, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 512: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0606 - MinusLogProbMetric: 4.0606 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 513/1000
2023-09-12 02:08:05.682 
Epoch 513/1000 
	 loss: 4.0620, MinusLogProbMetric: 4.0620, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 513: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0620 - MinusLogProbMetric: 4.0620 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 514/1000
2023-09-12 02:08:17.409 
Epoch 514/1000 
	 loss: 4.0607, MinusLogProbMetric: 4.0607, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 514: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0607 - MinusLogProbMetric: 4.0607 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 515/1000
2023-09-12 02:08:29.162 
Epoch 515/1000 
	 loss: 4.0606, MinusLogProbMetric: 4.0606, val_loss: 4.1030, val_MinusLogProbMetric: 4.1030

Epoch 515: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0606 - MinusLogProbMetric: 4.0606 - val_loss: 4.1030 - val_MinusLogProbMetric: 4.1030 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 516/1000
2023-09-12 02:08:40.985 
Epoch 516/1000 
	 loss: 4.0605, MinusLogProbMetric: 4.0605, val_loss: 4.1018, val_MinusLogProbMetric: 4.1018

Epoch 516: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0605 - MinusLogProbMetric: 4.0605 - val_loss: 4.1018 - val_MinusLogProbMetric: 4.1018 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 517/1000
2023-09-12 02:08:52.698 
Epoch 517/1000 
	 loss: 4.0606, MinusLogProbMetric: 4.0606, val_loss: 4.1024, val_MinusLogProbMetric: 4.1024

Epoch 517: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0606 - MinusLogProbMetric: 4.0606 - val_loss: 4.1024 - val_MinusLogProbMetric: 4.1024 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 518/1000
2023-09-12 02:09:04.338 
Epoch 518/1000 
	 loss: 4.0602, MinusLogProbMetric: 4.0602, val_loss: 4.1002, val_MinusLogProbMetric: 4.1002

Epoch 518: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0602 - MinusLogProbMetric: 4.0602 - val_loss: 4.1002 - val_MinusLogProbMetric: 4.1002 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 519/1000
2023-09-12 02:09:16.137 
Epoch 519/1000 
	 loss: 4.0599, MinusLogProbMetric: 4.0599, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 519: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0599 - MinusLogProbMetric: 4.0599 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 520/1000
2023-09-12 02:09:27.746 
Epoch 520/1000 
	 loss: 4.0601, MinusLogProbMetric: 4.0601, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 520: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0601 - MinusLogProbMetric: 4.0601 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 521/1000
2023-09-12 02:09:39.537 
Epoch 521/1000 
	 loss: 4.0604, MinusLogProbMetric: 4.0604, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 521: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0604 - MinusLogProbMetric: 4.0604 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 522/1000
2023-09-12 02:09:51.268 
Epoch 522/1000 
	 loss: 4.0603, MinusLogProbMetric: 4.0603, val_loss: 4.1016, val_MinusLogProbMetric: 4.1016

Epoch 522: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0603 - MinusLogProbMetric: 4.0603 - val_loss: 4.1016 - val_MinusLogProbMetric: 4.1016 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 523/1000
2023-09-12 02:10:02.982 
Epoch 523/1000 
	 loss: 4.0602, MinusLogProbMetric: 4.0602, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 523: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0602 - MinusLogProbMetric: 4.0602 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 524/1000
2023-09-12 02:10:14.699 
Epoch 524/1000 
	 loss: 4.0603, MinusLogProbMetric: 4.0603, val_loss: 4.0999, val_MinusLogProbMetric: 4.0999

Epoch 524: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0603 - MinusLogProbMetric: 4.0603 - val_loss: 4.0999 - val_MinusLogProbMetric: 4.0999 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 525/1000
2023-09-12 02:10:26.439 
Epoch 525/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1018, val_MinusLogProbMetric: 4.1018

Epoch 525: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1018 - val_MinusLogProbMetric: 4.1018 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 526/1000
2023-09-12 02:10:38.230 
Epoch 526/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 526: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 527/1000
2023-09-12 02:10:50.054 
Epoch 527/1000 
	 loss: 4.0601, MinusLogProbMetric: 4.0601, val_loss: 4.1023, val_MinusLogProbMetric: 4.1023

Epoch 527: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0601 - MinusLogProbMetric: 4.0601 - val_loss: 4.1023 - val_MinusLogProbMetric: 4.1023 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 528/1000
2023-09-12 02:11:01.741 
Epoch 528/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1015, val_MinusLogProbMetric: 4.1015

Epoch 528: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1015 - val_MinusLogProbMetric: 4.1015 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 529/1000
2023-09-12 02:11:13.290 
Epoch 529/1000 
	 loss: 4.0604, MinusLogProbMetric: 4.0604, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 529: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0604 - MinusLogProbMetric: 4.0604 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 530/1000
2023-09-12 02:11:24.977 
Epoch 530/1000 
	 loss: 4.0600, MinusLogProbMetric: 4.0600, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 530: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0600 - MinusLogProbMetric: 4.0600 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 531/1000
2023-09-12 02:11:36.704 
Epoch 531/1000 
	 loss: 4.0602, MinusLogProbMetric: 4.0602, val_loss: 4.1012, val_MinusLogProbMetric: 4.1012

Epoch 531: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0602 - MinusLogProbMetric: 4.0602 - val_loss: 4.1012 - val_MinusLogProbMetric: 4.1012 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 532/1000
2023-09-12 02:11:48.481 
Epoch 532/1000 
	 loss: 4.0589, MinusLogProbMetric: 4.0589, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 532: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0589 - MinusLogProbMetric: 4.0589 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 533/1000
2023-09-12 02:12:00.164 
Epoch 533/1000 
	 loss: 4.0593, MinusLogProbMetric: 4.0593, val_loss: 4.1020, val_MinusLogProbMetric: 4.1020

Epoch 533: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0593 - MinusLogProbMetric: 4.0593 - val_loss: 4.1020 - val_MinusLogProbMetric: 4.1020 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 534/1000
2023-09-12 02:12:11.877 
Epoch 534/1000 
	 loss: 4.0586, MinusLogProbMetric: 4.0586, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 534: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0586 - MinusLogProbMetric: 4.0586 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 535/1000
2023-09-12 02:12:23.528 
Epoch 535/1000 
	 loss: 4.0592, MinusLogProbMetric: 4.0592, val_loss: 4.1004, val_MinusLogProbMetric: 4.1004

Epoch 535: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0592 - MinusLogProbMetric: 4.0592 - val_loss: 4.1004 - val_MinusLogProbMetric: 4.1004 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 536/1000
2023-09-12 02:12:35.146 
Epoch 536/1000 
	 loss: 4.0590, MinusLogProbMetric: 4.0590, val_loss: 4.0999, val_MinusLogProbMetric: 4.0999

Epoch 536: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0590 - MinusLogProbMetric: 4.0590 - val_loss: 4.0999 - val_MinusLogProbMetric: 4.0999 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 537/1000
2023-09-12 02:12:46.721 
Epoch 537/1000 
	 loss: 4.0592, MinusLogProbMetric: 4.0592, val_loss: 4.1033, val_MinusLogProbMetric: 4.1033

Epoch 537: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0592 - MinusLogProbMetric: 4.0592 - val_loss: 4.1033 - val_MinusLogProbMetric: 4.1033 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 538/1000
2023-09-12 02:12:58.401 
Epoch 538/1000 
	 loss: 4.0599, MinusLogProbMetric: 4.0599, val_loss: 4.0996, val_MinusLogProbMetric: 4.0996

Epoch 538: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0599 - MinusLogProbMetric: 4.0599 - val_loss: 4.0996 - val_MinusLogProbMetric: 4.0996 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 539/1000
2023-09-12 02:13:10.202 
Epoch 539/1000 
	 loss: 4.0586, MinusLogProbMetric: 4.0586, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 539: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0586 - MinusLogProbMetric: 4.0586 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 540/1000
2023-09-12 02:13:21.907 
Epoch 540/1000 
	 loss: 4.0583, MinusLogProbMetric: 4.0583, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 540: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0583 - MinusLogProbMetric: 4.0583 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 541/1000
2023-09-12 02:13:33.546 
Epoch 541/1000 
	 loss: 4.0589, MinusLogProbMetric: 4.0589, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 541: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0589 - MinusLogProbMetric: 4.0589 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 542/1000
2023-09-12 02:13:45.289 
Epoch 542/1000 
	 loss: 4.0583, MinusLogProbMetric: 4.0583, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 542: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0583 - MinusLogProbMetric: 4.0583 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 543/1000
2023-09-12 02:13:56.421 
Epoch 543/1000 
	 loss: 4.0585, MinusLogProbMetric: 4.0585, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 543: val_loss did not improve from 4.09892
196/196 - 11s - loss: 4.0585 - MinusLogProbMetric: 4.0585 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 544/1000
2023-09-12 02:14:07.587 
Epoch 544/1000 
	 loss: 4.0587, MinusLogProbMetric: 4.0587, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 544: val_loss did not improve from 4.09892
196/196 - 11s - loss: 4.0587 - MinusLogProbMetric: 4.0587 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 545/1000
2023-09-12 02:14:17.903 
Epoch 545/1000 
	 loss: 4.0583, MinusLogProbMetric: 4.0583, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 545: val_loss did not improve from 4.09892
196/196 - 10s - loss: 4.0583 - MinusLogProbMetric: 4.0583 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 546/1000
2023-09-12 02:14:29.611 
Epoch 546/1000 
	 loss: 4.0602, MinusLogProbMetric: 4.0602, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 546: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0602 - MinusLogProbMetric: 4.0602 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 547/1000
2023-09-12 02:14:41.270 
Epoch 547/1000 
	 loss: 4.0587, MinusLogProbMetric: 4.0587, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 547: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0587 - MinusLogProbMetric: 4.0587 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 548/1000
2023-09-12 02:14:53.109 
Epoch 548/1000 
	 loss: 4.0588, MinusLogProbMetric: 4.0588, val_loss: 4.1045, val_MinusLogProbMetric: 4.1045

Epoch 548: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0588 - MinusLogProbMetric: 4.0588 - val_loss: 4.1045 - val_MinusLogProbMetric: 4.1045 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 549/1000
2023-09-12 02:15:04.876 
Epoch 549/1000 
	 loss: 4.0591, MinusLogProbMetric: 4.0591, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 549: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0591 - MinusLogProbMetric: 4.0591 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 550/1000
2023-09-12 02:15:16.540 
Epoch 550/1000 
	 loss: 4.0583, MinusLogProbMetric: 4.0583, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 550: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0583 - MinusLogProbMetric: 4.0583 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 551/1000
2023-09-12 02:15:28.241 
Epoch 551/1000 
	 loss: 4.0587, MinusLogProbMetric: 4.0587, val_loss: 4.0999, val_MinusLogProbMetric: 4.0999

Epoch 551: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0587 - MinusLogProbMetric: 4.0587 - val_loss: 4.0999 - val_MinusLogProbMetric: 4.0999 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 552/1000
2023-09-12 02:15:39.882 
Epoch 552/1000 
	 loss: 4.0585, MinusLogProbMetric: 4.0585, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 552: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0585 - MinusLogProbMetric: 4.0585 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 553/1000
2023-09-12 02:15:51.655 
Epoch 553/1000 
	 loss: 4.0586, MinusLogProbMetric: 4.0586, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 553: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0586 - MinusLogProbMetric: 4.0586 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 554/1000
2023-09-12 02:16:03.260 
Epoch 554/1000 
	 loss: 4.0583, MinusLogProbMetric: 4.0583, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 554: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0583 - MinusLogProbMetric: 4.0583 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 555/1000
2023-09-12 02:16:15.007 
Epoch 555/1000 
	 loss: 4.0585, MinusLogProbMetric: 4.0585, val_loss: 4.1018, val_MinusLogProbMetric: 4.1018

Epoch 555: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0585 - MinusLogProbMetric: 4.0585 - val_loss: 4.1018 - val_MinusLogProbMetric: 4.1018 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 556/1000
2023-09-12 02:16:26.669 
Epoch 556/1000 
	 loss: 4.0593, MinusLogProbMetric: 4.0593, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 556: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0593 - MinusLogProbMetric: 4.0593 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 557/1000
2023-09-12 02:16:38.404 
Epoch 557/1000 
	 loss: 4.0583, MinusLogProbMetric: 4.0583, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 557: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0583 - MinusLogProbMetric: 4.0583 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 558/1000
2023-09-12 02:16:50.124 
Epoch 558/1000 
	 loss: 4.0584, MinusLogProbMetric: 4.0584, val_loss: 4.1004, val_MinusLogProbMetric: 4.1004

Epoch 558: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0584 - MinusLogProbMetric: 4.0584 - val_loss: 4.1004 - val_MinusLogProbMetric: 4.1004 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 559/1000
2023-09-12 02:17:01.858 
Epoch 559/1000 
	 loss: 4.0583, MinusLogProbMetric: 4.0583, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 559: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0583 - MinusLogProbMetric: 4.0583 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 560/1000
2023-09-12 02:17:13.724 
Epoch 560/1000 
	 loss: 4.0585, MinusLogProbMetric: 4.0585, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 560: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0585 - MinusLogProbMetric: 4.0585 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 561/1000
2023-09-12 02:17:25.451 
Epoch 561/1000 
	 loss: 4.0585, MinusLogProbMetric: 4.0585, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 561: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0585 - MinusLogProbMetric: 4.0585 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 562/1000
2023-09-12 02:17:37.271 
Epoch 562/1000 
	 loss: 4.0585, MinusLogProbMetric: 4.0585, val_loss: 4.1002, val_MinusLogProbMetric: 4.1002

Epoch 562: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0585 - MinusLogProbMetric: 4.0585 - val_loss: 4.1002 - val_MinusLogProbMetric: 4.1002 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 563/1000
2023-09-12 02:17:48.960 
Epoch 563/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 563: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 564/1000
2023-09-12 02:18:00.699 
Epoch 564/1000 
	 loss: 4.0587, MinusLogProbMetric: 4.0587, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 564: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0587 - MinusLogProbMetric: 4.0587 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 565/1000
2023-09-12 02:18:12.425 
Epoch 565/1000 
	 loss: 4.0593, MinusLogProbMetric: 4.0593, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 565: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0593 - MinusLogProbMetric: 4.0593 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 566/1000
2023-09-12 02:18:23.965 
Epoch 566/1000 
	 loss: 4.0590, MinusLogProbMetric: 4.0590, val_loss: 4.1000, val_MinusLogProbMetric: 4.1000

Epoch 566: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0590 - MinusLogProbMetric: 4.0590 - val_loss: 4.1000 - val_MinusLogProbMetric: 4.1000 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 567/1000
2023-09-12 02:18:35.617 
Epoch 567/1000 
	 loss: 4.0586, MinusLogProbMetric: 4.0586, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 567: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0586 - MinusLogProbMetric: 4.0586 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 568/1000
2023-09-12 02:18:47.397 
Epoch 568/1000 
	 loss: 4.0584, MinusLogProbMetric: 4.0584, val_loss: 4.1001, val_MinusLogProbMetric: 4.1001

Epoch 568: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0584 - MinusLogProbMetric: 4.0584 - val_loss: 4.1001 - val_MinusLogProbMetric: 4.1001 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 569/1000
2023-09-12 02:18:59.091 
Epoch 569/1000 
	 loss: 4.0598, MinusLogProbMetric: 4.0598, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 569: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0598 - MinusLogProbMetric: 4.0598 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 570/1000
2023-09-12 02:19:10.702 
Epoch 570/1000 
	 loss: 4.0588, MinusLogProbMetric: 4.0588, val_loss: 4.1002, val_MinusLogProbMetric: 4.1002

Epoch 570: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0588 - MinusLogProbMetric: 4.0588 - val_loss: 4.1002 - val_MinusLogProbMetric: 4.1002 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 571/1000
2023-09-12 02:19:22.335 
Epoch 571/1000 
	 loss: 4.0586, MinusLogProbMetric: 4.0586, val_loss: 4.1011, val_MinusLogProbMetric: 4.1011

Epoch 571: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0586 - MinusLogProbMetric: 4.0586 - val_loss: 4.1011 - val_MinusLogProbMetric: 4.1011 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 572/1000
2023-09-12 02:19:34.045 
Epoch 572/1000 
	 loss: 4.0584, MinusLogProbMetric: 4.0584, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 572: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0584 - MinusLogProbMetric: 4.0584 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 573/1000
2023-09-12 02:19:45.726 
Epoch 573/1000 
	 loss: 4.0582, MinusLogProbMetric: 4.0582, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 573: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0582 - MinusLogProbMetric: 4.0582 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 574/1000
2023-09-12 02:19:57.492 
Epoch 574/1000 
	 loss: 4.0584, MinusLogProbMetric: 4.0584, val_loss: 4.1007, val_MinusLogProbMetric: 4.1007

Epoch 574: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0584 - MinusLogProbMetric: 4.0584 - val_loss: 4.1007 - val_MinusLogProbMetric: 4.1007 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 575/1000
2023-09-12 02:20:09.193 
Epoch 575/1000 
	 loss: 4.0584, MinusLogProbMetric: 4.0584, val_loss: 4.1002, val_MinusLogProbMetric: 4.1002

Epoch 575: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0584 - MinusLogProbMetric: 4.0584 - val_loss: 4.1002 - val_MinusLogProbMetric: 4.1002 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 576/1000
2023-09-12 02:20:20.920 
Epoch 576/1000 
	 loss: 4.0584, MinusLogProbMetric: 4.0584, val_loss: 4.1013, val_MinusLogProbMetric: 4.1013

Epoch 576: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0584 - MinusLogProbMetric: 4.0584 - val_loss: 4.1013 - val_MinusLogProbMetric: 4.1013 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 577/1000
2023-09-12 02:20:32.604 
Epoch 577/1000 
	 loss: 4.0581, MinusLogProbMetric: 4.0581, val_loss: 4.1009, val_MinusLogProbMetric: 4.1009

Epoch 577: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0581 - MinusLogProbMetric: 4.0581 - val_loss: 4.1009 - val_MinusLogProbMetric: 4.1009 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 578/1000
2023-09-12 02:20:44.357 
Epoch 578/1000 
	 loss: 4.0582, MinusLogProbMetric: 4.0582, val_loss: 4.1008, val_MinusLogProbMetric: 4.1008

Epoch 578: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0582 - MinusLogProbMetric: 4.0582 - val_loss: 4.1008 - val_MinusLogProbMetric: 4.1008 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 579/1000
2023-09-12 02:20:56.031 
Epoch 579/1000 
	 loss: 4.0585, MinusLogProbMetric: 4.0585, val_loss: 4.1004, val_MinusLogProbMetric: 4.1004

Epoch 579: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0585 - MinusLogProbMetric: 4.0585 - val_loss: 4.1004 - val_MinusLogProbMetric: 4.1004 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 580/1000
2023-09-12 02:21:07.813 
Epoch 580/1000 
	 loss: 4.0584, MinusLogProbMetric: 4.0584, val_loss: 4.1009, val_MinusLogProbMetric: 4.1009

Epoch 580: val_loss did not improve from 4.09892
196/196 - 12s - loss: 4.0584 - MinusLogProbMetric: 4.0584 - val_loss: 4.1009 - val_MinusLogProbMetric: 4.1009 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 581/1000
2023-09-12 02:21:19.567 
Epoch 581/1000 
	 loss: 4.0582, MinusLogProbMetric: 4.0582, val_loss: 4.1010, val_MinusLogProbMetric: 4.1010

Epoch 581: val_loss did not improve from 4.09892
Restoring model weights from the end of the best epoch: 481.
196/196 - 12s - loss: 4.0582 - MinusLogProbMetric: 4.0582 - val_loss: 4.1010 - val_MinusLogProbMetric: 4.1010 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 581: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:6 out of the last 6 calls to <function LRMetric.Test_tf.<locals>.compute_test at 0x7fc7dc2d5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
LR metric calculation completed in 4.703985325992107 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
WARNING:tensorflow:6 out of the last 6 calls to <function KSTest.Test_tf.<locals>.compute_test at 0x7fc7dc2d5900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
KS tests calculation completed in 4.655960498959757 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:6 out of the last 6 calls to <function SWDMetric.Test_tf.<locals>.compute_test at 0x7fc7dc2d60e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
SWD metric calculation completed in 2.108339293044992 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:6 out of the last 6 calls to <function FNMetric.Test_tf.<locals>.compute_test at 0x7fc7dc2d6320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
FN metric calculation completed in 4.936772738001309 seconds.
Training succeeded with seed 0.
Model trained in 6785.07 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 25.17 s.
Plots done in 10.28 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 35.44 s.
===========
Run 43/360 done in 6821.32 s.
===========

Directory ../../results/MsplineN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

===========
Generating train data for run 54.
===========
Train data generated in 0.16 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_54/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_54/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.65712   ,  6.182868  ,  6.320793  , ...,  6.224411  ,
         4.407977  ,  8.273342  ],
       [ 5.6647167 ,  7.6784825 ,  6.103832  , ...,  6.9132586 ,
         4.0071416 ,  9.627362  ],
       [ 0.0757564 ,  8.787646  ,  9.654894  , ...,  7.7624927 ,
         4.59853   ,  7.8518796 ],
       ...,
       [ 8.965884  ,  3.0239487 ,  7.898685  , ...,  9.606702  ,
         1.019942  ,  1.8909395 ],
       [ 0.66036737,  8.391064  ,  7.9419107 , ...,  8.014944  ,
         4.8080764 ,  7.7307167 ],
       [-0.07102557,  8.791537  ,  7.5852127 , ...,  8.631427  ,
         4.910859  ,  7.877132  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_54/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_54
self.data_kwargs: {'seed': 440}
self.x_data: [[ 9.710083    3.9211245   7.8928385  ...  9.772914    0.22835314
   1.7858514 ]
 [-0.06894769  8.409845    7.820752   ...  7.9066367   4.669789
   7.6796193 ]
 [10.280643    4.250588    7.9206114  ... 10.173959    1.6905015
   1.7195234 ]
 ...
 [ 0.2729339   7.4083323   8.085693   ...  7.883582    4.7593393
   7.733472  ]
 [-0.36202502  7.93172     8.479606   ...  7.927877    5.080957
   7.6926637 ]
 [ 9.848026    4.719975    7.9264145  ...  9.937142    2.2071612
   0.98272586]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_6 (LogProbLa  (None,)                  362352    
 yer)                                                            
                                                                 
=================================================================
Total params: 362,352
Trainable params: 362,352
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_6/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_6'")
self.model: <keras.engine.functional.Functional object at 0x7fc8757b6fb0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc6a5e06da0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc6a5e06da0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc6a5e07670>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc6a5e24370>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc6a5e248e0>, <keras.callbacks.ModelCheckpoint object at 0x7fc6a5e249a0>, <keras.callbacks.EarlyStopping object at 0x7fc6a5e24c10>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc6a5e24c40>, <keras.callbacks.TerminateOnNaN object at 0x7fc6a5e24880>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.65712   ,  6.182868  ,  6.320793  , ...,  6.224411  ,
         4.407977  ,  8.273342  ],
       [ 5.6647167 ,  7.6784825 ,  6.103832  , ...,  6.9132586 ,
         4.0071416 ,  9.627362  ],
       [ 0.0757564 ,  8.787646  ,  9.654894  , ...,  7.7624927 ,
         4.59853   ,  7.8518796 ],
       ...,
       [ 8.965884  ,  3.0239487 ,  7.898685  , ...,  9.606702  ,
         1.019942  ,  1.8909395 ],
       [ 0.66036737,  8.391064  ,  7.9419107 , ...,  8.014944  ,
         4.8080764 ,  7.7307167 ],
       [-0.07102557,  8.791537  ,  7.5852127 , ...,  8.631427  ,
         4.910859  ,  7.877132  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_54/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 54/360 with hyperparameters:
timestamp = 2023-09-12 02:21:56.456723
ndims = 8
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 362352
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [9.710083   3.9211245  7.8928385  5.807563   6.354877   9.772914
 0.22835314 1.7858514 ]
Epoch 1/1000
2023-09-12 02:22:28.987 
Epoch 1/1000 
	 loss: 12.8443, MinusLogProbMetric: 12.8443, val_loss: 5.5615, val_MinusLogProbMetric: 5.5615

Epoch 1: val_loss improved from inf to 5.56147, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 32s - loss: 12.8443 - MinusLogProbMetric: 12.8443 - val_loss: 5.5615 - val_MinusLogProbMetric: 5.5615 - lr: 0.0010 - 32s/epoch - 166ms/step
Epoch 2/1000
2023-09-12 02:22:40.739 
Epoch 2/1000 
	 loss: 5.1775, MinusLogProbMetric: 5.1775, val_loss: 4.9162, val_MinusLogProbMetric: 4.9162

Epoch 2: val_loss improved from 5.56147 to 4.91616, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 5.1775 - MinusLogProbMetric: 5.1775 - val_loss: 4.9162 - val_MinusLogProbMetric: 4.9162 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 3/1000
2023-09-12 02:22:52.538 
Epoch 3/1000 
	 loss: 4.8777, MinusLogProbMetric: 4.8777, val_loss: 4.8603, val_MinusLogProbMetric: 4.8603

Epoch 3: val_loss improved from 4.91616 to 4.86028, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.8777 - MinusLogProbMetric: 4.8777 - val_loss: 4.8603 - val_MinusLogProbMetric: 4.8603 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-12 02:23:04.391 
Epoch 4/1000 
	 loss: 4.7201, MinusLogProbMetric: 4.7201, val_loss: 4.5198, val_MinusLogProbMetric: 4.5198

Epoch 4: val_loss improved from 4.86028 to 4.51983, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.7201 - MinusLogProbMetric: 4.7201 - val_loss: 4.5198 - val_MinusLogProbMetric: 4.5198 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-12 02:23:15.983 
Epoch 5/1000 
	 loss: 4.5726, MinusLogProbMetric: 4.5726, val_loss: 4.5277, val_MinusLogProbMetric: 4.5277

Epoch 5: val_loss did not improve from 4.51983
196/196 - 11s - loss: 4.5726 - MinusLogProbMetric: 4.5726 - val_loss: 4.5277 - val_MinusLogProbMetric: 4.5277 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 6/1000
2023-09-12 02:23:27.663 
Epoch 6/1000 
	 loss: 4.5158, MinusLogProbMetric: 4.5158, val_loss: 4.8079, val_MinusLogProbMetric: 4.8079

Epoch 6: val_loss did not improve from 4.51983
196/196 - 12s - loss: 4.5158 - MinusLogProbMetric: 4.5158 - val_loss: 4.8079 - val_MinusLogProbMetric: 4.8079 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-12 02:23:39.360 
Epoch 7/1000 
	 loss: 4.4714, MinusLogProbMetric: 4.4714, val_loss: 4.4391, val_MinusLogProbMetric: 4.4391

Epoch 7: val_loss improved from 4.51983 to 4.43906, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.4714 - MinusLogProbMetric: 4.4714 - val_loss: 4.4391 - val_MinusLogProbMetric: 4.4391 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 8/1000
2023-09-12 02:23:51.280 
Epoch 8/1000 
	 loss: 4.4401, MinusLogProbMetric: 4.4401, val_loss: 4.3677, val_MinusLogProbMetric: 4.3677

Epoch 8: val_loss improved from 4.43906 to 4.36769, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.4401 - MinusLogProbMetric: 4.4401 - val_loss: 4.3677 - val_MinusLogProbMetric: 4.3677 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 9/1000
2023-09-12 02:24:03.154 
Epoch 9/1000 
	 loss: 4.3851, MinusLogProbMetric: 4.3851, val_loss: 4.4693, val_MinusLogProbMetric: 4.4693

Epoch 9: val_loss did not improve from 4.36769
196/196 - 12s - loss: 4.3851 - MinusLogProbMetric: 4.3851 - val_loss: 4.4693 - val_MinusLogProbMetric: 4.4693 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 10/1000
2023-09-12 02:24:15.009 
Epoch 10/1000 
	 loss: 4.3308, MinusLogProbMetric: 4.3308, val_loss: 4.4003, val_MinusLogProbMetric: 4.4003

Epoch 10: val_loss did not improve from 4.36769
196/196 - 12s - loss: 4.3308 - MinusLogProbMetric: 4.3308 - val_loss: 4.4003 - val_MinusLogProbMetric: 4.4003 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-12 02:24:26.660 
Epoch 11/1000 
	 loss: 4.3062, MinusLogProbMetric: 4.3062, val_loss: 4.3675, val_MinusLogProbMetric: 4.3675

Epoch 11: val_loss improved from 4.36769 to 4.36748, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.3062 - MinusLogProbMetric: 4.3062 - val_loss: 4.3675 - val_MinusLogProbMetric: 4.3675 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-12 02:24:38.474 
Epoch 12/1000 
	 loss: 4.2598, MinusLogProbMetric: 4.2598, val_loss: 4.2411, val_MinusLogProbMetric: 4.2411

Epoch 12: val_loss improved from 4.36748 to 4.24112, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.2598 - MinusLogProbMetric: 4.2598 - val_loss: 4.2411 - val_MinusLogProbMetric: 4.2411 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-12 02:24:50.336 
Epoch 13/1000 
	 loss: 4.2683, MinusLogProbMetric: 4.2683, val_loss: 4.3371, val_MinusLogProbMetric: 4.3371

Epoch 13: val_loss did not improve from 4.24112
196/196 - 12s - loss: 4.2683 - MinusLogProbMetric: 4.2683 - val_loss: 4.3371 - val_MinusLogProbMetric: 4.3371 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 02:25:01.851 
Epoch 14/1000 
	 loss: 4.2377, MinusLogProbMetric: 4.2377, val_loss: 4.2445, val_MinusLogProbMetric: 4.2445

Epoch 14: val_loss did not improve from 4.24112
196/196 - 12s - loss: 4.2377 - MinusLogProbMetric: 4.2377 - val_loss: 4.2445 - val_MinusLogProbMetric: 4.2445 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-12 02:25:13.380 
Epoch 15/1000 
	 loss: 4.2233, MinusLogProbMetric: 4.2233, val_loss: 4.2358, val_MinusLogProbMetric: 4.2358

Epoch 15: val_loss improved from 4.24112 to 4.23582, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.2233 - MinusLogProbMetric: 4.2233 - val_loss: 4.2358 - val_MinusLogProbMetric: 4.2358 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-12 02:25:25.168 
Epoch 16/1000 
	 loss: 4.2407, MinusLogProbMetric: 4.2407, val_loss: 4.2885, val_MinusLogProbMetric: 4.2885

Epoch 16: val_loss did not improve from 4.23582
196/196 - 12s - loss: 4.2407 - MinusLogProbMetric: 4.2407 - val_loss: 4.2885 - val_MinusLogProbMetric: 4.2885 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 17/1000
2023-09-12 02:25:36.104 
Epoch 17/1000 
	 loss: 4.2228, MinusLogProbMetric: 4.2228, val_loss: 4.2390, val_MinusLogProbMetric: 4.2390

Epoch 17: val_loss did not improve from 4.23582
196/196 - 11s - loss: 4.2228 - MinusLogProbMetric: 4.2228 - val_loss: 4.2390 - val_MinusLogProbMetric: 4.2390 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 18/1000
2023-09-12 02:25:45.798 
Epoch 18/1000 
	 loss: 4.2086, MinusLogProbMetric: 4.2086, val_loss: 4.2316, val_MinusLogProbMetric: 4.2316

Epoch 18: val_loss improved from 4.23582 to 4.23156, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 10s - loss: 4.2086 - MinusLogProbMetric: 4.2086 - val_loss: 4.2316 - val_MinusLogProbMetric: 4.2316 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 19/1000
2023-09-12 02:25:57.448 
Epoch 19/1000 
	 loss: 4.2362, MinusLogProbMetric: 4.2362, val_loss: 4.2377, val_MinusLogProbMetric: 4.2377

Epoch 19: val_loss did not improve from 4.23156
196/196 - 12s - loss: 4.2362 - MinusLogProbMetric: 4.2362 - val_loss: 4.2377 - val_MinusLogProbMetric: 4.2377 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 20/1000
2023-09-12 02:26:09.102 
Epoch 20/1000 
	 loss: 4.1929, MinusLogProbMetric: 4.1929, val_loss: 4.2373, val_MinusLogProbMetric: 4.2373

Epoch 20: val_loss did not improve from 4.23156
196/196 - 12s - loss: 4.1929 - MinusLogProbMetric: 4.1929 - val_loss: 4.2373 - val_MinusLogProbMetric: 4.2373 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 02:26:20.764 
Epoch 21/1000 
	 loss: 4.1939, MinusLogProbMetric: 4.1939, val_loss: 4.2482, val_MinusLogProbMetric: 4.2482

Epoch 21: val_loss did not improve from 4.23156
196/196 - 12s - loss: 4.1939 - MinusLogProbMetric: 4.1939 - val_loss: 4.2482 - val_MinusLogProbMetric: 4.2482 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 02:26:32.477 
Epoch 22/1000 
	 loss: 4.1985, MinusLogProbMetric: 4.1985, val_loss: 4.2343, val_MinusLogProbMetric: 4.2343

Epoch 22: val_loss did not improve from 4.23156
196/196 - 12s - loss: 4.1985 - MinusLogProbMetric: 4.1985 - val_loss: 4.2343 - val_MinusLogProbMetric: 4.2343 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 02:26:44.093 
Epoch 23/1000 
	 loss: 4.1820, MinusLogProbMetric: 4.1820, val_loss: 4.4115, val_MinusLogProbMetric: 4.4115

Epoch 23: val_loss did not improve from 4.23156
196/196 - 12s - loss: 4.1820 - MinusLogProbMetric: 4.1820 - val_loss: 4.4115 - val_MinusLogProbMetric: 4.4115 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 24/1000
2023-09-12 02:26:55.655 
Epoch 24/1000 
	 loss: 4.2015, MinusLogProbMetric: 4.2015, val_loss: 4.2448, val_MinusLogProbMetric: 4.2448

Epoch 24: val_loss did not improve from 4.23156
196/196 - 12s - loss: 4.2015 - MinusLogProbMetric: 4.2015 - val_loss: 4.2448 - val_MinusLogProbMetric: 4.2448 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 25/1000
2023-09-12 02:27:07.235 
Epoch 25/1000 
	 loss: 4.1849, MinusLogProbMetric: 4.1849, val_loss: 4.2237, val_MinusLogProbMetric: 4.2237

Epoch 25: val_loss improved from 4.23156 to 4.22369, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1849 - MinusLogProbMetric: 4.1849 - val_loss: 4.2237 - val_MinusLogProbMetric: 4.2237 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 02:27:19.092 
Epoch 26/1000 
	 loss: 4.1845, MinusLogProbMetric: 4.1845, val_loss: 4.1915, val_MinusLogProbMetric: 4.1915

Epoch 26: val_loss improved from 4.22369 to 4.19149, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1845 - MinusLogProbMetric: 4.1845 - val_loss: 4.1915 - val_MinusLogProbMetric: 4.1915 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 27/1000
2023-09-12 02:27:31.021 
Epoch 27/1000 
	 loss: 4.1754, MinusLogProbMetric: 4.1754, val_loss: 4.1728, val_MinusLogProbMetric: 4.1728

Epoch 27: val_loss improved from 4.19149 to 4.17283, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1754 - MinusLogProbMetric: 4.1754 - val_loss: 4.1728 - val_MinusLogProbMetric: 4.1728 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 28/1000
2023-09-12 02:27:42.775 
Epoch 28/1000 
	 loss: 4.1892, MinusLogProbMetric: 4.1892, val_loss: 4.2351, val_MinusLogProbMetric: 4.2351

Epoch 28: val_loss did not improve from 4.17283
196/196 - 12s - loss: 4.1892 - MinusLogProbMetric: 4.1892 - val_loss: 4.2351 - val_MinusLogProbMetric: 4.2351 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 02:27:54.488 
Epoch 29/1000 
	 loss: 4.1654, MinusLogProbMetric: 4.1654, val_loss: 4.2040, val_MinusLogProbMetric: 4.2040

Epoch 29: val_loss did not improve from 4.17283
196/196 - 12s - loss: 4.1654 - MinusLogProbMetric: 4.1654 - val_loss: 4.2040 - val_MinusLogProbMetric: 4.2040 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 30/1000
2023-09-12 02:28:06.187 
Epoch 30/1000 
	 loss: 4.1736, MinusLogProbMetric: 4.1736, val_loss: 4.2454, val_MinusLogProbMetric: 4.2454

Epoch 30: val_loss did not improve from 4.17283
196/196 - 12s - loss: 4.1736 - MinusLogProbMetric: 4.1736 - val_loss: 4.2454 - val_MinusLogProbMetric: 4.2454 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-12 02:28:17.983 
Epoch 31/1000 
	 loss: 4.1766, MinusLogProbMetric: 4.1766, val_loss: 4.1929, val_MinusLogProbMetric: 4.1929

Epoch 31: val_loss did not improve from 4.17283
196/196 - 12s - loss: 4.1766 - MinusLogProbMetric: 4.1766 - val_loss: 4.1929 - val_MinusLogProbMetric: 4.1929 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-12 02:28:29.682 
Epoch 32/1000 
	 loss: 4.1696, MinusLogProbMetric: 4.1696, val_loss: 4.1916, val_MinusLogProbMetric: 4.1916

Epoch 32: val_loss did not improve from 4.17283
196/196 - 12s - loss: 4.1696 - MinusLogProbMetric: 4.1696 - val_loss: 4.1916 - val_MinusLogProbMetric: 4.1916 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-12 02:28:41.398 
Epoch 33/1000 
	 loss: 4.1717, MinusLogProbMetric: 4.1717, val_loss: 4.2524, val_MinusLogProbMetric: 4.2524

Epoch 33: val_loss did not improve from 4.17283
196/196 - 12s - loss: 4.1717 - MinusLogProbMetric: 4.1717 - val_loss: 4.2524 - val_MinusLogProbMetric: 4.2524 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-12 02:28:53.061 
Epoch 34/1000 
	 loss: 4.1545, MinusLogProbMetric: 4.1545, val_loss: 4.1609, val_MinusLogProbMetric: 4.1609

Epoch 34: val_loss improved from 4.17283 to 4.16086, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1545 - MinusLogProbMetric: 4.1545 - val_loss: 4.1609 - val_MinusLogProbMetric: 4.1609 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-12 02:29:04.810 
Epoch 35/1000 
	 loss: 4.1618, MinusLogProbMetric: 4.1618, val_loss: 4.2216, val_MinusLogProbMetric: 4.2216

Epoch 35: val_loss did not improve from 4.16086
196/196 - 12s - loss: 4.1618 - MinusLogProbMetric: 4.1618 - val_loss: 4.2216 - val_MinusLogProbMetric: 4.2216 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 36/1000
2023-09-12 02:29:16.607 
Epoch 36/1000 
	 loss: 4.1504, MinusLogProbMetric: 4.1504, val_loss: 4.1792, val_MinusLogProbMetric: 4.1792

Epoch 36: val_loss did not improve from 4.16086
196/196 - 12s - loss: 4.1504 - MinusLogProbMetric: 4.1504 - val_loss: 4.1792 - val_MinusLogProbMetric: 4.1792 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 02:29:28.404 
Epoch 37/1000 
	 loss: 4.1588, MinusLogProbMetric: 4.1588, val_loss: 4.1799, val_MinusLogProbMetric: 4.1799

Epoch 37: val_loss did not improve from 4.16086
196/196 - 12s - loss: 4.1588 - MinusLogProbMetric: 4.1588 - val_loss: 4.1799 - val_MinusLogProbMetric: 4.1799 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 38/1000
2023-09-12 02:29:40.143 
Epoch 38/1000 
	 loss: 4.1500, MinusLogProbMetric: 4.1500, val_loss: 4.1750, val_MinusLogProbMetric: 4.1750

Epoch 38: val_loss did not improve from 4.16086
196/196 - 12s - loss: 4.1500 - MinusLogProbMetric: 4.1500 - val_loss: 4.1750 - val_MinusLogProbMetric: 4.1750 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 02:29:51.815 
Epoch 39/1000 
	 loss: 4.1482, MinusLogProbMetric: 4.1482, val_loss: 4.1858, val_MinusLogProbMetric: 4.1858

Epoch 39: val_loss did not improve from 4.16086
196/196 - 12s - loss: 4.1482 - MinusLogProbMetric: 4.1482 - val_loss: 4.1858 - val_MinusLogProbMetric: 4.1858 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-12 02:30:03.719 
Epoch 40/1000 
	 loss: 4.1553, MinusLogProbMetric: 4.1553, val_loss: 4.1574, val_MinusLogProbMetric: 4.1574

Epoch 40: val_loss improved from 4.16086 to 4.15743, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1553 - MinusLogProbMetric: 4.1553 - val_loss: 4.1574 - val_MinusLogProbMetric: 4.1574 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 41/1000
2023-09-12 02:30:15.640 
Epoch 41/1000 
	 loss: 4.1511, MinusLogProbMetric: 4.1511, val_loss: 4.1643, val_MinusLogProbMetric: 4.1643

Epoch 41: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1511 - MinusLogProbMetric: 4.1511 - val_loss: 4.1643 - val_MinusLogProbMetric: 4.1643 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-12 02:30:27.366 
Epoch 42/1000 
	 loss: 4.1465, MinusLogProbMetric: 4.1465, val_loss: 4.1827, val_MinusLogProbMetric: 4.1827

Epoch 42: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1465 - MinusLogProbMetric: 4.1465 - val_loss: 4.1827 - val_MinusLogProbMetric: 4.1827 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-12 02:30:39.155 
Epoch 43/1000 
	 loss: 4.1453, MinusLogProbMetric: 4.1453, val_loss: 4.1696, val_MinusLogProbMetric: 4.1696

Epoch 43: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1453 - MinusLogProbMetric: 4.1453 - val_loss: 4.1696 - val_MinusLogProbMetric: 4.1696 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 44/1000
2023-09-12 02:30:50.895 
Epoch 44/1000 
	 loss: 4.1483, MinusLogProbMetric: 4.1483, val_loss: 4.1963, val_MinusLogProbMetric: 4.1963

Epoch 44: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1483 - MinusLogProbMetric: 4.1483 - val_loss: 4.1963 - val_MinusLogProbMetric: 4.1963 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-12 02:31:02.600 
Epoch 45/1000 
	 loss: 4.1473, MinusLogProbMetric: 4.1473, val_loss: 4.1875, val_MinusLogProbMetric: 4.1875

Epoch 45: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1473 - MinusLogProbMetric: 4.1473 - val_loss: 4.1875 - val_MinusLogProbMetric: 4.1875 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-12 02:31:14.222 
Epoch 46/1000 
	 loss: 4.1381, MinusLogProbMetric: 4.1381, val_loss: 4.1781, val_MinusLogProbMetric: 4.1781

Epoch 46: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1381 - MinusLogProbMetric: 4.1381 - val_loss: 4.1781 - val_MinusLogProbMetric: 4.1781 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 02:31:25.797 
Epoch 47/1000 
	 loss: 4.1404, MinusLogProbMetric: 4.1404, val_loss: 4.1599, val_MinusLogProbMetric: 4.1599

Epoch 47: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1404 - MinusLogProbMetric: 4.1404 - val_loss: 4.1599 - val_MinusLogProbMetric: 4.1599 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 48/1000
2023-09-12 02:31:37.504 
Epoch 48/1000 
	 loss: 4.1377, MinusLogProbMetric: 4.1377, val_loss: 4.2128, val_MinusLogProbMetric: 4.2128

Epoch 48: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1377 - MinusLogProbMetric: 4.1377 - val_loss: 4.2128 - val_MinusLogProbMetric: 4.2128 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-12 02:31:49.115 
Epoch 49/1000 
	 loss: 4.1433, MinusLogProbMetric: 4.1433, val_loss: 4.2403, val_MinusLogProbMetric: 4.2403

Epoch 49: val_loss did not improve from 4.15743
196/196 - 12s - loss: 4.1433 - MinusLogProbMetric: 4.1433 - val_loss: 4.2403 - val_MinusLogProbMetric: 4.2403 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-12 02:32:00.842 
Epoch 50/1000 
	 loss: 4.1337, MinusLogProbMetric: 4.1337, val_loss: 4.1505, val_MinusLogProbMetric: 4.1505

Epoch 50: val_loss improved from 4.15743 to 4.15053, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1337 - MinusLogProbMetric: 4.1337 - val_loss: 4.1505 - val_MinusLogProbMetric: 4.1505 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 51/1000
2023-09-12 02:32:12.755 
Epoch 51/1000 
	 loss: 4.2419, MinusLogProbMetric: 4.2419, val_loss: 4.1722, val_MinusLogProbMetric: 4.1722

Epoch 51: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.2419 - MinusLogProbMetric: 4.2419 - val_loss: 4.1722 - val_MinusLogProbMetric: 4.1722 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-12 02:32:24.470 
Epoch 52/1000 
	 loss: 4.1534, MinusLogProbMetric: 4.1534, val_loss: 4.1833, val_MinusLogProbMetric: 4.1833

Epoch 52: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1534 - MinusLogProbMetric: 4.1534 - val_loss: 4.1833 - val_MinusLogProbMetric: 4.1833 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-12 02:32:36.172 
Epoch 53/1000 
	 loss: 4.1433, MinusLogProbMetric: 4.1433, val_loss: 4.1547, val_MinusLogProbMetric: 4.1547

Epoch 53: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1433 - MinusLogProbMetric: 4.1433 - val_loss: 4.1547 - val_MinusLogProbMetric: 4.1547 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-12 02:32:47.799 
Epoch 54/1000 
	 loss: 4.1419, MinusLogProbMetric: 4.1419, val_loss: 4.1853, val_MinusLogProbMetric: 4.1853

Epoch 54: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1419 - MinusLogProbMetric: 4.1419 - val_loss: 4.1853 - val_MinusLogProbMetric: 4.1853 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 55/1000
2023-09-12 02:32:59.511 
Epoch 55/1000 
	 loss: 4.2765, MinusLogProbMetric: 4.2765, val_loss: 4.2575, val_MinusLogProbMetric: 4.2575

Epoch 55: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.2765 - MinusLogProbMetric: 4.2765 - val_loss: 4.2575 - val_MinusLogProbMetric: 4.2575 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-12 02:33:11.234 
Epoch 56/1000 
	 loss: 4.1596, MinusLogProbMetric: 4.1596, val_loss: 4.1693, val_MinusLogProbMetric: 4.1693

Epoch 56: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1596 - MinusLogProbMetric: 4.1596 - val_loss: 4.1693 - val_MinusLogProbMetric: 4.1693 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-12 02:33:22.932 
Epoch 57/1000 
	 loss: 4.1401, MinusLogProbMetric: 4.1401, val_loss: 4.1636, val_MinusLogProbMetric: 4.1636

Epoch 57: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1401 - MinusLogProbMetric: 4.1401 - val_loss: 4.1636 - val_MinusLogProbMetric: 4.1636 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-12 02:33:34.562 
Epoch 58/1000 
	 loss: 4.1395, MinusLogProbMetric: 4.1395, val_loss: 4.1548, val_MinusLogProbMetric: 4.1548

Epoch 58: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1395 - MinusLogProbMetric: 4.1395 - val_loss: 4.1548 - val_MinusLogProbMetric: 4.1548 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 59/1000
2023-09-12 02:33:46.226 
Epoch 59/1000 
	 loss: 4.1358, MinusLogProbMetric: 4.1358, val_loss: 4.1999, val_MinusLogProbMetric: 4.1999

Epoch 59: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1358 - MinusLogProbMetric: 4.1358 - val_loss: 4.1999 - val_MinusLogProbMetric: 4.1999 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 60/1000
2023-09-12 02:33:57.879 
Epoch 60/1000 
	 loss: 4.1354, MinusLogProbMetric: 4.1354, val_loss: 4.3171, val_MinusLogProbMetric: 4.3171

Epoch 60: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1354 - MinusLogProbMetric: 4.1354 - val_loss: 4.3171 - val_MinusLogProbMetric: 4.3171 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 61/1000
2023-09-12 02:34:09.531 
Epoch 61/1000 
	 loss: 4.1312, MinusLogProbMetric: 4.1312, val_loss: 4.1873, val_MinusLogProbMetric: 4.1873

Epoch 61: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1312 - MinusLogProbMetric: 4.1312 - val_loss: 4.1873 - val_MinusLogProbMetric: 4.1873 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 62/1000
2023-09-12 02:34:21.139 
Epoch 62/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.1570, val_MinusLogProbMetric: 4.1570

Epoch 62: val_loss did not improve from 4.15053
196/196 - 12s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.1570 - val_MinusLogProbMetric: 4.1570 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 63/1000
2023-09-12 02:34:32.981 
Epoch 63/1000 
	 loss: 4.1282, MinusLogProbMetric: 4.1282, val_loss: 4.1432, val_MinusLogProbMetric: 4.1432

Epoch 63: val_loss improved from 4.15053 to 4.14324, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1282 - MinusLogProbMetric: 4.1282 - val_loss: 4.1432 - val_MinusLogProbMetric: 4.1432 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 64/1000
2023-09-12 02:34:44.840 
Epoch 64/1000 
	 loss: 4.1265, MinusLogProbMetric: 4.1265, val_loss: 4.1413, val_MinusLogProbMetric: 4.1413

Epoch 64: val_loss improved from 4.14324 to 4.14134, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1265 - MinusLogProbMetric: 4.1265 - val_loss: 4.1413 - val_MinusLogProbMetric: 4.1413 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-12 02:34:56.645 
Epoch 65/1000 
	 loss: 4.1233, MinusLogProbMetric: 4.1233, val_loss: 4.2136, val_MinusLogProbMetric: 4.2136

Epoch 65: val_loss did not improve from 4.14134
196/196 - 12s - loss: 4.1233 - MinusLogProbMetric: 4.1233 - val_loss: 4.2136 - val_MinusLogProbMetric: 4.2136 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-12 02:35:08.471 
Epoch 66/1000 
	 loss: 4.1226, MinusLogProbMetric: 4.1226, val_loss: 4.1409, val_MinusLogProbMetric: 4.1409

Epoch 66: val_loss improved from 4.14134 to 4.14086, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1226 - MinusLogProbMetric: 4.1226 - val_loss: 4.1409 - val_MinusLogProbMetric: 4.1409 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 67/1000
2023-09-12 02:35:20.190 
Epoch 67/1000 
	 loss: 4.1746, MinusLogProbMetric: 4.1746, val_loss: 4.1561, val_MinusLogProbMetric: 4.1561

Epoch 67: val_loss did not improve from 4.14086
196/196 - 12s - loss: 4.1746 - MinusLogProbMetric: 4.1746 - val_loss: 4.1561 - val_MinusLogProbMetric: 4.1561 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 68/1000
2023-09-12 02:35:31.889 
Epoch 68/1000 
	 loss: 4.1326, MinusLogProbMetric: 4.1326, val_loss: 4.1509, val_MinusLogProbMetric: 4.1509

Epoch 68: val_loss did not improve from 4.14086
196/196 - 12s - loss: 4.1326 - MinusLogProbMetric: 4.1326 - val_loss: 4.1509 - val_MinusLogProbMetric: 4.1509 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-12 02:35:43.668 
Epoch 69/1000 
	 loss: 4.1216, MinusLogProbMetric: 4.1216, val_loss: 4.1678, val_MinusLogProbMetric: 4.1678

Epoch 69: val_loss did not improve from 4.14086
196/196 - 12s - loss: 4.1216 - MinusLogProbMetric: 4.1216 - val_loss: 4.1678 - val_MinusLogProbMetric: 4.1678 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 02:35:55.492 
Epoch 70/1000 
	 loss: 4.1271, MinusLogProbMetric: 4.1271, val_loss: 4.1556, val_MinusLogProbMetric: 4.1556

Epoch 70: val_loss did not improve from 4.14086
196/196 - 12s - loss: 4.1271 - MinusLogProbMetric: 4.1271 - val_loss: 4.1556 - val_MinusLogProbMetric: 4.1556 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-12 02:36:07.323 
Epoch 71/1000 
	 loss: 4.1263, MinusLogProbMetric: 4.1263, val_loss: 4.1367, val_MinusLogProbMetric: 4.1367

Epoch 71: val_loss improved from 4.14086 to 4.13667, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1263 - MinusLogProbMetric: 4.1263 - val_loss: 4.1367 - val_MinusLogProbMetric: 4.1367 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 72/1000
2023-09-12 02:36:19.227 
Epoch 72/1000 
	 loss: 4.1241, MinusLogProbMetric: 4.1241, val_loss: 4.1469, val_MinusLogProbMetric: 4.1469

Epoch 72: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1241 - MinusLogProbMetric: 4.1241 - val_loss: 4.1469 - val_MinusLogProbMetric: 4.1469 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-12 02:36:30.982 
Epoch 73/1000 
	 loss: 4.1164, MinusLogProbMetric: 4.1164, val_loss: 4.1598, val_MinusLogProbMetric: 4.1598

Epoch 73: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1164 - MinusLogProbMetric: 4.1164 - val_loss: 4.1598 - val_MinusLogProbMetric: 4.1598 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-12 02:36:42.696 
Epoch 74/1000 
	 loss: 4.1190, MinusLogProbMetric: 4.1190, val_loss: 4.1723, val_MinusLogProbMetric: 4.1723

Epoch 74: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1190 - MinusLogProbMetric: 4.1190 - val_loss: 4.1723 - val_MinusLogProbMetric: 4.1723 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-12 02:36:54.498 
Epoch 75/1000 
	 loss: 4.1175, MinusLogProbMetric: 4.1175, val_loss: 4.1471, val_MinusLogProbMetric: 4.1471

Epoch 75: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1175 - MinusLogProbMetric: 4.1175 - val_loss: 4.1471 - val_MinusLogProbMetric: 4.1471 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-12 02:37:06.198 
Epoch 76/1000 
	 loss: 4.1252, MinusLogProbMetric: 4.1252, val_loss: 4.1556, val_MinusLogProbMetric: 4.1556

Epoch 76: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1252 - MinusLogProbMetric: 4.1252 - val_loss: 4.1556 - val_MinusLogProbMetric: 4.1556 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-12 02:37:17.887 
Epoch 77/1000 
	 loss: 4.1133, MinusLogProbMetric: 4.1133, val_loss: 4.1437, val_MinusLogProbMetric: 4.1437

Epoch 77: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1133 - MinusLogProbMetric: 4.1133 - val_loss: 4.1437 - val_MinusLogProbMetric: 4.1437 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-12 02:37:29.590 
Epoch 78/1000 
	 loss: 4.1236, MinusLogProbMetric: 4.1236, val_loss: 4.1459, val_MinusLogProbMetric: 4.1459

Epoch 78: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1236 - MinusLogProbMetric: 4.1236 - val_loss: 4.1459 - val_MinusLogProbMetric: 4.1459 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-12 02:37:41.347 
Epoch 79/1000 
	 loss: 4.1151, MinusLogProbMetric: 4.1151, val_loss: 4.1524, val_MinusLogProbMetric: 4.1524

Epoch 79: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1151 - MinusLogProbMetric: 4.1151 - val_loss: 4.1524 - val_MinusLogProbMetric: 4.1524 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 02:37:53.104 
Epoch 80/1000 
	 loss: 4.1262, MinusLogProbMetric: 4.1262, val_loss: 4.1410, val_MinusLogProbMetric: 4.1410

Epoch 80: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1262 - MinusLogProbMetric: 4.1262 - val_loss: 4.1410 - val_MinusLogProbMetric: 4.1410 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 81/1000
2023-09-12 02:38:04.948 
Epoch 81/1000 
	 loss: 4.1125, MinusLogProbMetric: 4.1125, val_loss: 4.1692, val_MinusLogProbMetric: 4.1692

Epoch 81: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1125 - MinusLogProbMetric: 4.1125 - val_loss: 4.1692 - val_MinusLogProbMetric: 4.1692 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 82/1000
2023-09-12 02:38:16.887 
Epoch 82/1000 
	 loss: 4.1142, MinusLogProbMetric: 4.1142, val_loss: 4.1444, val_MinusLogProbMetric: 4.1444

Epoch 82: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1142 - MinusLogProbMetric: 4.1142 - val_loss: 4.1444 - val_MinusLogProbMetric: 4.1444 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 83/1000
2023-09-12 02:38:28.559 
Epoch 83/1000 
	 loss: 4.1168, MinusLogProbMetric: 4.1168, val_loss: 4.2191, val_MinusLogProbMetric: 4.2191

Epoch 83: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1168 - MinusLogProbMetric: 4.1168 - val_loss: 4.2191 - val_MinusLogProbMetric: 4.2191 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 84/1000
2023-09-12 02:38:40.260 
Epoch 84/1000 
	 loss: 4.1150, MinusLogProbMetric: 4.1150, val_loss: 4.1471, val_MinusLogProbMetric: 4.1471

Epoch 84: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1150 - MinusLogProbMetric: 4.1150 - val_loss: 4.1471 - val_MinusLogProbMetric: 4.1471 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 85/1000
2023-09-12 02:38:51.968 
Epoch 85/1000 
	 loss: 4.1185, MinusLogProbMetric: 4.1185, val_loss: 4.2349, val_MinusLogProbMetric: 4.2349

Epoch 85: val_loss did not improve from 4.13667
196/196 - 12s - loss: 4.1185 - MinusLogProbMetric: 4.1185 - val_loss: 4.2349 - val_MinusLogProbMetric: 4.2349 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-12 02:39:03.661 
Epoch 86/1000 
	 loss: 4.1135, MinusLogProbMetric: 4.1135, val_loss: 4.1270, val_MinusLogProbMetric: 4.1270

Epoch 86: val_loss improved from 4.13667 to 4.12702, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1135 - MinusLogProbMetric: 4.1135 - val_loss: 4.1270 - val_MinusLogProbMetric: 4.1270 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 87/1000
2023-09-12 02:39:15.446 
Epoch 87/1000 
	 loss: 4.1142, MinusLogProbMetric: 4.1142, val_loss: 4.1336, val_MinusLogProbMetric: 4.1336

Epoch 87: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1142 - MinusLogProbMetric: 4.1142 - val_loss: 4.1336 - val_MinusLogProbMetric: 4.1336 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-12 02:39:27.208 
Epoch 88/1000 
	 loss: 4.1087, MinusLogProbMetric: 4.1087, val_loss: 4.1387, val_MinusLogProbMetric: 4.1387

Epoch 88: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1087 - MinusLogProbMetric: 4.1087 - val_loss: 4.1387 - val_MinusLogProbMetric: 4.1387 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-12 02:39:38.855 
Epoch 89/1000 
	 loss: 4.1143, MinusLogProbMetric: 4.1143, val_loss: 4.1356, val_MinusLogProbMetric: 4.1356

Epoch 89: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1143 - MinusLogProbMetric: 4.1143 - val_loss: 4.1356 - val_MinusLogProbMetric: 4.1356 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 90/1000
2023-09-12 02:39:50.743 
Epoch 90/1000 
	 loss: 4.1137, MinusLogProbMetric: 4.1137, val_loss: 4.1429, val_MinusLogProbMetric: 4.1429

Epoch 90: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1137 - MinusLogProbMetric: 4.1137 - val_loss: 4.1429 - val_MinusLogProbMetric: 4.1429 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 91/1000
2023-09-12 02:40:02.407 
Epoch 91/1000 
	 loss: 4.1153, MinusLogProbMetric: 4.1153, val_loss: 4.1447, val_MinusLogProbMetric: 4.1447

Epoch 91: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1153 - MinusLogProbMetric: 4.1153 - val_loss: 4.1447 - val_MinusLogProbMetric: 4.1447 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 02:40:13.609 
Epoch 92/1000 
	 loss: 4.1089, MinusLogProbMetric: 4.1089, val_loss: 4.1379, val_MinusLogProbMetric: 4.1379

Epoch 92: val_loss did not improve from 4.12702
196/196 - 11s - loss: 4.1089 - MinusLogProbMetric: 4.1089 - val_loss: 4.1379 - val_MinusLogProbMetric: 4.1379 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 93/1000
2023-09-12 02:40:24.464 
Epoch 93/1000 
	 loss: 4.1111, MinusLogProbMetric: 4.1111, val_loss: 4.1429, val_MinusLogProbMetric: 4.1429

Epoch 93: val_loss did not improve from 4.12702
196/196 - 11s - loss: 4.1111 - MinusLogProbMetric: 4.1111 - val_loss: 4.1429 - val_MinusLogProbMetric: 4.1429 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 94/1000
2023-09-12 02:40:34.629 
Epoch 94/1000 
	 loss: 4.1091, MinusLogProbMetric: 4.1091, val_loss: 4.1435, val_MinusLogProbMetric: 4.1435

Epoch 94: val_loss did not improve from 4.12702
196/196 - 10s - loss: 4.1091 - MinusLogProbMetric: 4.1091 - val_loss: 4.1435 - val_MinusLogProbMetric: 4.1435 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 95/1000
2023-09-12 02:40:46.372 
Epoch 95/1000 
	 loss: 4.1088, MinusLogProbMetric: 4.1088, val_loss: 4.1445, val_MinusLogProbMetric: 4.1445

Epoch 95: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1088 - MinusLogProbMetric: 4.1088 - val_loss: 4.1445 - val_MinusLogProbMetric: 4.1445 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-12 02:40:57.954 
Epoch 96/1000 
	 loss: 4.1126, MinusLogProbMetric: 4.1126, val_loss: 4.1984, val_MinusLogProbMetric: 4.1984

Epoch 96: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1126 - MinusLogProbMetric: 4.1126 - val_loss: 4.1984 - val_MinusLogProbMetric: 4.1984 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 97/1000
2023-09-12 02:41:09.745 
Epoch 97/1000 
	 loss: 4.1070, MinusLogProbMetric: 4.1070, val_loss: 4.1326, val_MinusLogProbMetric: 4.1326

Epoch 97: val_loss did not improve from 4.12702
196/196 - 12s - loss: 4.1070 - MinusLogProbMetric: 4.1070 - val_loss: 4.1326 - val_MinusLogProbMetric: 4.1326 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 98/1000
2023-09-12 02:41:21.440 
Epoch 98/1000 
	 loss: 4.1096, MinusLogProbMetric: 4.1096, val_loss: 4.1267, val_MinusLogProbMetric: 4.1267

Epoch 98: val_loss improved from 4.12702 to 4.12668, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1096 - MinusLogProbMetric: 4.1096 - val_loss: 4.1267 - val_MinusLogProbMetric: 4.1267 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 99/1000
2023-09-12 02:41:33.245 
Epoch 99/1000 
	 loss: 4.1107, MinusLogProbMetric: 4.1107, val_loss: 4.1708, val_MinusLogProbMetric: 4.1708

Epoch 99: val_loss did not improve from 4.12668
196/196 - 12s - loss: 4.1107 - MinusLogProbMetric: 4.1107 - val_loss: 4.1708 - val_MinusLogProbMetric: 4.1708 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 100/1000
2023-09-12 02:41:44.934 
Epoch 100/1000 
	 loss: 4.1106, MinusLogProbMetric: 4.1106, val_loss: 4.1612, val_MinusLogProbMetric: 4.1612

Epoch 100: val_loss did not improve from 4.12668
196/196 - 12s - loss: 4.1106 - MinusLogProbMetric: 4.1106 - val_loss: 4.1612 - val_MinusLogProbMetric: 4.1612 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-12 02:41:56.697 
Epoch 101/1000 
	 loss: 4.1158, MinusLogProbMetric: 4.1158, val_loss: 4.1405, val_MinusLogProbMetric: 4.1405

Epoch 101: val_loss did not improve from 4.12668
196/196 - 12s - loss: 4.1158 - MinusLogProbMetric: 4.1158 - val_loss: 4.1405 - val_MinusLogProbMetric: 4.1405 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 102/1000
2023-09-12 02:42:08.432 
Epoch 102/1000 
	 loss: 4.1090, MinusLogProbMetric: 4.1090, val_loss: 4.1433, val_MinusLogProbMetric: 4.1433

Epoch 102: val_loss did not improve from 4.12668
196/196 - 12s - loss: 4.1090 - MinusLogProbMetric: 4.1090 - val_loss: 4.1433 - val_MinusLogProbMetric: 4.1433 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 103/1000
2023-09-12 02:42:20.102 
Epoch 103/1000 
	 loss: 4.1030, MinusLogProbMetric: 4.1030, val_loss: 4.1244, val_MinusLogProbMetric: 4.1244

Epoch 103: val_loss improved from 4.12668 to 4.12440, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1030 - MinusLogProbMetric: 4.1030 - val_loss: 4.1244 - val_MinusLogProbMetric: 4.1244 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-12 02:42:31.860 
Epoch 104/1000 
	 loss: 4.1108, MinusLogProbMetric: 4.1108, val_loss: 4.1350, val_MinusLogProbMetric: 4.1350

Epoch 104: val_loss did not improve from 4.12440
196/196 - 12s - loss: 4.1108 - MinusLogProbMetric: 4.1108 - val_loss: 4.1350 - val_MinusLogProbMetric: 4.1350 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 105/1000
2023-09-12 02:42:43.573 
Epoch 105/1000 
	 loss: 4.1079, MinusLogProbMetric: 4.1079, val_loss: 4.1320, val_MinusLogProbMetric: 4.1320

Epoch 105: val_loss did not improve from 4.12440
196/196 - 12s - loss: 4.1079 - MinusLogProbMetric: 4.1079 - val_loss: 4.1320 - val_MinusLogProbMetric: 4.1320 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-12 02:42:55.185 
Epoch 106/1000 
	 loss: 4.1053, MinusLogProbMetric: 4.1053, val_loss: 4.1253, val_MinusLogProbMetric: 4.1253

Epoch 106: val_loss did not improve from 4.12440
196/196 - 12s - loss: 4.1053 - MinusLogProbMetric: 4.1053 - val_loss: 4.1253 - val_MinusLogProbMetric: 4.1253 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 107/1000
2023-09-12 02:43:07.005 
Epoch 107/1000 
	 loss: 4.1060, MinusLogProbMetric: 4.1060, val_loss: 4.1332, val_MinusLogProbMetric: 4.1332

Epoch 107: val_loss did not improve from 4.12440
196/196 - 12s - loss: 4.1060 - MinusLogProbMetric: 4.1060 - val_loss: 4.1332 - val_MinusLogProbMetric: 4.1332 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-12 02:43:18.777 
Epoch 108/1000 
	 loss: 4.1045, MinusLogProbMetric: 4.1045, val_loss: 4.1227, val_MinusLogProbMetric: 4.1227

Epoch 108: val_loss improved from 4.12440 to 4.12268, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.1045 - MinusLogProbMetric: 4.1045 - val_loss: 4.1227 - val_MinusLogProbMetric: 4.1227 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 109/1000
2023-09-12 02:43:30.557 
Epoch 109/1000 
	 loss: 4.1053, MinusLogProbMetric: 4.1053, val_loss: 4.1413, val_MinusLogProbMetric: 4.1413

Epoch 109: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1053 - MinusLogProbMetric: 4.1053 - val_loss: 4.1413 - val_MinusLogProbMetric: 4.1413 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-12 02:43:42.252 
Epoch 110/1000 
	 loss: 4.1007, MinusLogProbMetric: 4.1007, val_loss: 4.1326, val_MinusLogProbMetric: 4.1326

Epoch 110: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1007 - MinusLogProbMetric: 4.1007 - val_loss: 4.1326 - val_MinusLogProbMetric: 4.1326 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 111/1000
2023-09-12 02:43:53.933 
Epoch 111/1000 
	 loss: 4.1027, MinusLogProbMetric: 4.1027, val_loss: 4.1411, val_MinusLogProbMetric: 4.1411

Epoch 111: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1027 - MinusLogProbMetric: 4.1027 - val_loss: 4.1411 - val_MinusLogProbMetric: 4.1411 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-12 02:44:05.680 
Epoch 112/1000 
	 loss: 4.0981, MinusLogProbMetric: 4.0981, val_loss: 4.1636, val_MinusLogProbMetric: 4.1636

Epoch 112: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0981 - MinusLogProbMetric: 4.0981 - val_loss: 4.1636 - val_MinusLogProbMetric: 4.1636 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 113/1000
2023-09-12 02:44:17.322 
Epoch 113/1000 
	 loss: 4.1051, MinusLogProbMetric: 4.1051, val_loss: 4.1510, val_MinusLogProbMetric: 4.1510

Epoch 113: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1051 - MinusLogProbMetric: 4.1051 - val_loss: 4.1510 - val_MinusLogProbMetric: 4.1510 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 114/1000
2023-09-12 02:44:28.982 
Epoch 114/1000 
	 loss: 4.0971, MinusLogProbMetric: 4.0971, val_loss: 4.1329, val_MinusLogProbMetric: 4.1329

Epoch 114: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0971 - MinusLogProbMetric: 4.0971 - val_loss: 4.1329 - val_MinusLogProbMetric: 4.1329 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 115/1000
2023-09-12 02:44:40.537 
Epoch 115/1000 
	 loss: 4.1144, MinusLogProbMetric: 4.1144, val_loss: 4.1562, val_MinusLogProbMetric: 4.1562

Epoch 115: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1144 - MinusLogProbMetric: 4.1144 - val_loss: 4.1562 - val_MinusLogProbMetric: 4.1562 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 116/1000
2023-09-12 02:44:52.233 
Epoch 116/1000 
	 loss: 4.1011, MinusLogProbMetric: 4.1011, val_loss: 4.1318, val_MinusLogProbMetric: 4.1318

Epoch 116: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1011 - MinusLogProbMetric: 4.1011 - val_loss: 4.1318 - val_MinusLogProbMetric: 4.1318 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 117/1000
2023-09-12 02:45:03.980 
Epoch 117/1000 
	 loss: 4.1012, MinusLogProbMetric: 4.1012, val_loss: 4.1351, val_MinusLogProbMetric: 4.1351

Epoch 117: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1012 - MinusLogProbMetric: 4.1012 - val_loss: 4.1351 - val_MinusLogProbMetric: 4.1351 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-12 02:45:15.735 
Epoch 118/1000 
	 loss: 4.0977, MinusLogProbMetric: 4.0977, val_loss: 4.1491, val_MinusLogProbMetric: 4.1491

Epoch 118: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0977 - MinusLogProbMetric: 4.0977 - val_loss: 4.1491 - val_MinusLogProbMetric: 4.1491 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-12 02:45:27.443 
Epoch 119/1000 
	 loss: 4.1020, MinusLogProbMetric: 4.1020, val_loss: 4.1712, val_MinusLogProbMetric: 4.1712

Epoch 119: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1020 - MinusLogProbMetric: 4.1020 - val_loss: 4.1712 - val_MinusLogProbMetric: 4.1712 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 120/1000
2023-09-12 02:45:39.179 
Epoch 120/1000 
	 loss: 4.0972, MinusLogProbMetric: 4.0972, val_loss: 4.1397, val_MinusLogProbMetric: 4.1397

Epoch 120: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0972 - MinusLogProbMetric: 4.0972 - val_loss: 4.1397 - val_MinusLogProbMetric: 4.1397 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-12 02:45:51.008 
Epoch 121/1000 
	 loss: 4.1065, MinusLogProbMetric: 4.1065, val_loss: 4.1289, val_MinusLogProbMetric: 4.1289

Epoch 121: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1065 - MinusLogProbMetric: 4.1065 - val_loss: 4.1289 - val_MinusLogProbMetric: 4.1289 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-12 02:46:02.686 
Epoch 122/1000 
	 loss: 4.0992, MinusLogProbMetric: 4.0992, val_loss: 4.1490, val_MinusLogProbMetric: 4.1490

Epoch 122: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0992 - MinusLogProbMetric: 4.0992 - val_loss: 4.1490 - val_MinusLogProbMetric: 4.1490 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-12 02:46:14.414 
Epoch 123/1000 
	 loss: 4.1019, MinusLogProbMetric: 4.1019, val_loss: 4.1284, val_MinusLogProbMetric: 4.1284

Epoch 123: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1019 - MinusLogProbMetric: 4.1019 - val_loss: 4.1284 - val_MinusLogProbMetric: 4.1284 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-12 02:46:26.013 
Epoch 124/1000 
	 loss: 4.0967, MinusLogProbMetric: 4.0967, val_loss: 4.1476, val_MinusLogProbMetric: 4.1476

Epoch 124: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0967 - MinusLogProbMetric: 4.0967 - val_loss: 4.1476 - val_MinusLogProbMetric: 4.1476 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 125/1000
2023-09-12 02:46:37.798 
Epoch 125/1000 
	 loss: 4.1009, MinusLogProbMetric: 4.1009, val_loss: 4.1358, val_MinusLogProbMetric: 4.1358

Epoch 125: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1009 - MinusLogProbMetric: 4.1009 - val_loss: 4.1358 - val_MinusLogProbMetric: 4.1358 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 126/1000
2023-09-12 02:46:49.564 
Epoch 126/1000 
	 loss: 4.0968, MinusLogProbMetric: 4.0968, val_loss: 4.1789, val_MinusLogProbMetric: 4.1789

Epoch 126: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0968 - MinusLogProbMetric: 4.0968 - val_loss: 4.1789 - val_MinusLogProbMetric: 4.1789 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-12 02:47:01.229 
Epoch 127/1000 
	 loss: 4.0954, MinusLogProbMetric: 4.0954, val_loss: 4.1353, val_MinusLogProbMetric: 4.1353

Epoch 127: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0954 - MinusLogProbMetric: 4.0954 - val_loss: 4.1353 - val_MinusLogProbMetric: 4.1353 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 128/1000
2023-09-12 02:47:12.852 
Epoch 128/1000 
	 loss: 4.1024, MinusLogProbMetric: 4.1024, val_loss: 4.1469, val_MinusLogProbMetric: 4.1469

Epoch 128: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1024 - MinusLogProbMetric: 4.1024 - val_loss: 4.1469 - val_MinusLogProbMetric: 4.1469 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 129/1000
2023-09-12 02:47:24.615 
Epoch 129/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.1560, val_MinusLogProbMetric: 4.1560

Epoch 129: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.1560 - val_MinusLogProbMetric: 4.1560 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-12 02:47:36.454 
Epoch 130/1000 
	 loss: 4.1037, MinusLogProbMetric: 4.1037, val_loss: 4.1428, val_MinusLogProbMetric: 4.1428

Epoch 130: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1037 - MinusLogProbMetric: 4.1037 - val_loss: 4.1428 - val_MinusLogProbMetric: 4.1428 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-12 02:47:48.149 
Epoch 131/1000 
	 loss: 4.0909, MinusLogProbMetric: 4.0909, val_loss: 4.1710, val_MinusLogProbMetric: 4.1710

Epoch 131: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0909 - MinusLogProbMetric: 4.0909 - val_loss: 4.1710 - val_MinusLogProbMetric: 4.1710 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 132/1000
2023-09-12 02:47:59.891 
Epoch 132/1000 
	 loss: 4.2403, MinusLogProbMetric: 4.2403, val_loss: 4.1790, val_MinusLogProbMetric: 4.1790

Epoch 132: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.2403 - MinusLogProbMetric: 4.2403 - val_loss: 4.1790 - val_MinusLogProbMetric: 4.1790 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 133/1000
2023-09-12 02:48:11.511 
Epoch 133/1000 
	 loss: 4.1175, MinusLogProbMetric: 4.1175, val_loss: 4.1836, val_MinusLogProbMetric: 4.1836

Epoch 133: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1175 - MinusLogProbMetric: 4.1175 - val_loss: 4.1836 - val_MinusLogProbMetric: 4.1836 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 134/1000
2023-09-12 02:48:23.237 
Epoch 134/1000 
	 loss: 4.1095, MinusLogProbMetric: 4.1095, val_loss: 4.1352, val_MinusLogProbMetric: 4.1352

Epoch 134: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1095 - MinusLogProbMetric: 4.1095 - val_loss: 4.1352 - val_MinusLogProbMetric: 4.1352 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-12 02:48:34.939 
Epoch 135/1000 
	 loss: 4.1026, MinusLogProbMetric: 4.1026, val_loss: 4.1575, val_MinusLogProbMetric: 4.1575

Epoch 135: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1026 - MinusLogProbMetric: 4.1026 - val_loss: 4.1575 - val_MinusLogProbMetric: 4.1575 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-12 02:48:46.671 
Epoch 136/1000 
	 loss: 4.0980, MinusLogProbMetric: 4.0980, val_loss: 4.1312, val_MinusLogProbMetric: 4.1312

Epoch 136: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0980 - MinusLogProbMetric: 4.0980 - val_loss: 4.1312 - val_MinusLogProbMetric: 4.1312 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 137/1000
2023-09-12 02:48:58.342 
Epoch 137/1000 
	 loss: 4.0986, MinusLogProbMetric: 4.0986, val_loss: 4.1409, val_MinusLogProbMetric: 4.1409

Epoch 137: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0986 - MinusLogProbMetric: 4.0986 - val_loss: 4.1409 - val_MinusLogProbMetric: 4.1409 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 138/1000
2023-09-12 02:49:10.074 
Epoch 138/1000 
	 loss: 4.1046, MinusLogProbMetric: 4.1046, val_loss: 4.1642, val_MinusLogProbMetric: 4.1642

Epoch 138: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1046 - MinusLogProbMetric: 4.1046 - val_loss: 4.1642 - val_MinusLogProbMetric: 4.1642 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-12 02:49:21.897 
Epoch 139/1000 
	 loss: 4.0989, MinusLogProbMetric: 4.0989, val_loss: 4.1259, val_MinusLogProbMetric: 4.1259

Epoch 139: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0989 - MinusLogProbMetric: 4.0989 - val_loss: 4.1259 - val_MinusLogProbMetric: 4.1259 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-12 02:49:33.535 
Epoch 140/1000 
	 loss: 4.0975, MinusLogProbMetric: 4.0975, val_loss: 4.1353, val_MinusLogProbMetric: 4.1353

Epoch 140: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0975 - MinusLogProbMetric: 4.0975 - val_loss: 4.1353 - val_MinusLogProbMetric: 4.1353 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 141/1000
2023-09-12 02:49:45.144 
Epoch 141/1000 
	 loss: 4.0980, MinusLogProbMetric: 4.0980, val_loss: 4.1588, val_MinusLogProbMetric: 4.1588

Epoch 141: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0980 - MinusLogProbMetric: 4.0980 - val_loss: 4.1588 - val_MinusLogProbMetric: 4.1588 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 142/1000
2023-09-12 02:49:56.872 
Epoch 142/1000 
	 loss: 4.1016, MinusLogProbMetric: 4.1016, val_loss: 4.1545, val_MinusLogProbMetric: 4.1545

Epoch 142: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1016 - MinusLogProbMetric: 4.1016 - val_loss: 4.1545 - val_MinusLogProbMetric: 4.1545 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 143/1000
2023-09-12 02:50:08.532 
Epoch 143/1000 
	 loss: 4.0920, MinusLogProbMetric: 4.0920, val_loss: 4.1318, val_MinusLogProbMetric: 4.1318

Epoch 143: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0920 - MinusLogProbMetric: 4.0920 - val_loss: 4.1318 - val_MinusLogProbMetric: 4.1318 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 144/1000
2023-09-12 02:50:20.007 
Epoch 144/1000 
	 loss: 4.0988, MinusLogProbMetric: 4.0988, val_loss: 4.1676, val_MinusLogProbMetric: 4.1676

Epoch 144: val_loss did not improve from 4.12268
196/196 - 11s - loss: 4.0988 - MinusLogProbMetric: 4.0988 - val_loss: 4.1676 - val_MinusLogProbMetric: 4.1676 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 145/1000
2023-09-12 02:50:31.378 
Epoch 145/1000 
	 loss: 4.0931, MinusLogProbMetric: 4.0931, val_loss: 4.1385, val_MinusLogProbMetric: 4.1385

Epoch 145: val_loss did not improve from 4.12268
196/196 - 11s - loss: 4.0931 - MinusLogProbMetric: 4.0931 - val_loss: 4.1385 - val_MinusLogProbMetric: 4.1385 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 146/1000
2023-09-12 02:50:42.922 
Epoch 146/1000 
	 loss: 4.0998, MinusLogProbMetric: 4.0998, val_loss: 4.1521, val_MinusLogProbMetric: 4.1521

Epoch 146: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0998 - MinusLogProbMetric: 4.0998 - val_loss: 4.1521 - val_MinusLogProbMetric: 4.1521 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 147/1000
2023-09-12 02:50:54.355 
Epoch 147/1000 
	 loss: 4.0966, MinusLogProbMetric: 4.0966, val_loss: 4.1719, val_MinusLogProbMetric: 4.1719

Epoch 147: val_loss did not improve from 4.12268
196/196 - 11s - loss: 4.0966 - MinusLogProbMetric: 4.0966 - val_loss: 4.1719 - val_MinusLogProbMetric: 4.1719 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 148/1000
2023-09-12 02:51:05.647 
Epoch 148/1000 
	 loss: 4.0926, MinusLogProbMetric: 4.0926, val_loss: 4.1448, val_MinusLogProbMetric: 4.1448

Epoch 148: val_loss did not improve from 4.12268
196/196 - 11s - loss: 4.0926 - MinusLogProbMetric: 4.0926 - val_loss: 4.1448 - val_MinusLogProbMetric: 4.1448 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 149/1000
2023-09-12 02:51:17.190 
Epoch 149/1000 
	 loss: 4.0972, MinusLogProbMetric: 4.0972, val_loss: 4.2013, val_MinusLogProbMetric: 4.2013

Epoch 149: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0972 - MinusLogProbMetric: 4.0972 - val_loss: 4.2013 - val_MinusLogProbMetric: 4.2013 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 150/1000
2023-09-12 02:51:28.494 
Epoch 150/1000 
	 loss: 4.0962, MinusLogProbMetric: 4.0962, val_loss: 4.1384, val_MinusLogProbMetric: 4.1384

Epoch 150: val_loss did not improve from 4.12268
196/196 - 11s - loss: 4.0962 - MinusLogProbMetric: 4.0962 - val_loss: 4.1384 - val_MinusLogProbMetric: 4.1384 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 151/1000
2023-09-12 02:51:39.961 
Epoch 151/1000 
	 loss: 4.0953, MinusLogProbMetric: 4.0953, val_loss: 4.1457, val_MinusLogProbMetric: 4.1457

Epoch 151: val_loss did not improve from 4.12268
196/196 - 11s - loss: 4.0953 - MinusLogProbMetric: 4.0953 - val_loss: 4.1457 - val_MinusLogProbMetric: 4.1457 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 152/1000
2023-09-12 02:51:49.769 
Epoch 152/1000 
	 loss: 4.0948, MinusLogProbMetric: 4.0948, val_loss: 4.1560, val_MinusLogProbMetric: 4.1560

Epoch 152: val_loss did not improve from 4.12268
196/196 - 10s - loss: 4.0948 - MinusLogProbMetric: 4.0948 - val_loss: 4.1560 - val_MinusLogProbMetric: 4.1560 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 153/1000
2023-09-12 02:52:01.423 
Epoch 153/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.2266, val_MinusLogProbMetric: 4.2266

Epoch 153: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.2266 - val_MinusLogProbMetric: 4.2266 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-12 02:52:13.138 
Epoch 154/1000 
	 loss: 4.1009, MinusLogProbMetric: 4.1009, val_loss: 4.1483, val_MinusLogProbMetric: 4.1483

Epoch 154: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.1009 - MinusLogProbMetric: 4.1009 - val_loss: 4.1483 - val_MinusLogProbMetric: 4.1483 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 155/1000
2023-09-12 02:52:24.802 
Epoch 155/1000 
	 loss: 4.0953, MinusLogProbMetric: 4.0953, val_loss: 4.1577, val_MinusLogProbMetric: 4.1577

Epoch 155: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0953 - MinusLogProbMetric: 4.0953 - val_loss: 4.1577 - val_MinusLogProbMetric: 4.1577 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 156/1000
2023-09-12 02:52:36.625 
Epoch 156/1000 
	 loss: 4.0902, MinusLogProbMetric: 4.0902, val_loss: 4.1396, val_MinusLogProbMetric: 4.1396

Epoch 156: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0902 - MinusLogProbMetric: 4.0902 - val_loss: 4.1396 - val_MinusLogProbMetric: 4.1396 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 157/1000
2023-09-12 02:52:48.425 
Epoch 157/1000 
	 loss: 4.0952, MinusLogProbMetric: 4.0952, val_loss: 4.1492, val_MinusLogProbMetric: 4.1492

Epoch 157: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0952 - MinusLogProbMetric: 4.0952 - val_loss: 4.1492 - val_MinusLogProbMetric: 4.1492 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-12 02:53:00.126 
Epoch 158/1000 
	 loss: 4.0903, MinusLogProbMetric: 4.0903, val_loss: 4.1480, val_MinusLogProbMetric: 4.1480

Epoch 158: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0903 - MinusLogProbMetric: 4.0903 - val_loss: 4.1480 - val_MinusLogProbMetric: 4.1480 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 159/1000
2023-09-12 02:53:11.775 
Epoch 159/1000 
	 loss: 4.0777, MinusLogProbMetric: 4.0777, val_loss: 4.1329, val_MinusLogProbMetric: 4.1329

Epoch 159: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0777 - MinusLogProbMetric: 4.0777 - val_loss: 4.1329 - val_MinusLogProbMetric: 4.1329 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 160/1000
2023-09-12 02:53:23.493 
Epoch 160/1000 
	 loss: 4.0735, MinusLogProbMetric: 4.0735, val_loss: 4.1259, val_MinusLogProbMetric: 4.1259

Epoch 160: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0735 - MinusLogProbMetric: 4.0735 - val_loss: 4.1259 - val_MinusLogProbMetric: 4.1259 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 161/1000
2023-09-12 02:53:35.229 
Epoch 161/1000 
	 loss: 4.0755, MinusLogProbMetric: 4.0755, val_loss: 4.1264, val_MinusLogProbMetric: 4.1264

Epoch 161: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0755 - MinusLogProbMetric: 4.0755 - val_loss: 4.1264 - val_MinusLogProbMetric: 4.1264 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 162/1000
2023-09-12 02:53:47.097 
Epoch 162/1000 
	 loss: 4.0736, MinusLogProbMetric: 4.0736, val_loss: 4.1275, val_MinusLogProbMetric: 4.1275

Epoch 162: val_loss did not improve from 4.12268
196/196 - 12s - loss: 4.0736 - MinusLogProbMetric: 4.0736 - val_loss: 4.1275 - val_MinusLogProbMetric: 4.1275 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 163/1000
2023-09-12 02:53:58.954 
Epoch 163/1000 
	 loss: 4.0704, MinusLogProbMetric: 4.0704, val_loss: 4.1182, val_MinusLogProbMetric: 4.1182

Epoch 163: val_loss improved from 4.12268 to 4.11816, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 12s - loss: 4.0704 - MinusLogProbMetric: 4.0704 - val_loss: 4.1182 - val_MinusLogProbMetric: 4.1182 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 164/1000
2023-09-12 02:54:10.772 
Epoch 164/1000 
	 loss: 4.0735, MinusLogProbMetric: 4.0735, val_loss: 4.1257, val_MinusLogProbMetric: 4.1257

Epoch 164: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0735 - MinusLogProbMetric: 4.0735 - val_loss: 4.1257 - val_MinusLogProbMetric: 4.1257 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 165/1000
2023-09-12 02:54:22.457 
Epoch 165/1000 
	 loss: 4.0731, MinusLogProbMetric: 4.0731, val_loss: 4.1259, val_MinusLogProbMetric: 4.1259

Epoch 165: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0731 - MinusLogProbMetric: 4.0731 - val_loss: 4.1259 - val_MinusLogProbMetric: 4.1259 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 166/1000
2023-09-12 02:54:34.219 
Epoch 166/1000 
	 loss: 4.0719, MinusLogProbMetric: 4.0719, val_loss: 4.1204, val_MinusLogProbMetric: 4.1204

Epoch 166: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0719 - MinusLogProbMetric: 4.0719 - val_loss: 4.1204 - val_MinusLogProbMetric: 4.1204 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 167/1000
2023-09-12 02:54:45.962 
Epoch 167/1000 
	 loss: 4.0730, MinusLogProbMetric: 4.0730, val_loss: 4.1564, val_MinusLogProbMetric: 4.1564

Epoch 167: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0730 - MinusLogProbMetric: 4.0730 - val_loss: 4.1564 - val_MinusLogProbMetric: 4.1564 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 168/1000
2023-09-12 02:54:57.650 
Epoch 168/1000 
	 loss: 4.0743, MinusLogProbMetric: 4.0743, val_loss: 4.1316, val_MinusLogProbMetric: 4.1316

Epoch 168: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0743 - MinusLogProbMetric: 4.0743 - val_loss: 4.1316 - val_MinusLogProbMetric: 4.1316 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-12 02:55:09.248 
Epoch 169/1000 
	 loss: 4.0742, MinusLogProbMetric: 4.0742, val_loss: 4.1236, val_MinusLogProbMetric: 4.1236

Epoch 169: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0742 - MinusLogProbMetric: 4.0742 - val_loss: 4.1236 - val_MinusLogProbMetric: 4.1236 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 170/1000
2023-09-12 02:55:20.891 
Epoch 170/1000 
	 loss: 4.0718, MinusLogProbMetric: 4.0718, val_loss: 4.1242, val_MinusLogProbMetric: 4.1242

Epoch 170: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0718 - MinusLogProbMetric: 4.0718 - val_loss: 4.1242 - val_MinusLogProbMetric: 4.1242 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 171/1000
2023-09-12 02:55:32.590 
Epoch 171/1000 
	 loss: 4.0724, MinusLogProbMetric: 4.0724, val_loss: 4.1350, val_MinusLogProbMetric: 4.1350

Epoch 171: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0724 - MinusLogProbMetric: 4.0724 - val_loss: 4.1350 - val_MinusLogProbMetric: 4.1350 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 172/1000
2023-09-12 02:55:44.247 
Epoch 172/1000 
	 loss: 4.0719, MinusLogProbMetric: 4.0719, val_loss: 4.1209, val_MinusLogProbMetric: 4.1209

Epoch 172: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0719 - MinusLogProbMetric: 4.0719 - val_loss: 4.1209 - val_MinusLogProbMetric: 4.1209 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 02:55:55.986 
Epoch 173/1000 
	 loss: 4.0715, MinusLogProbMetric: 4.0715, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 173: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0715 - MinusLogProbMetric: 4.0715 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 174/1000
2023-09-12 02:56:07.698 
Epoch 174/1000 
	 loss: 4.0719, MinusLogProbMetric: 4.0719, val_loss: 4.1206, val_MinusLogProbMetric: 4.1206

Epoch 174: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0719 - MinusLogProbMetric: 4.0719 - val_loss: 4.1206 - val_MinusLogProbMetric: 4.1206 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 175/1000
2023-09-12 02:56:19.473 
Epoch 175/1000 
	 loss: 4.0728, MinusLogProbMetric: 4.0728, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 175: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0728 - MinusLogProbMetric: 4.0728 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 176/1000
2023-09-12 02:56:31.220 
Epoch 176/1000 
	 loss: 4.0721, MinusLogProbMetric: 4.0721, val_loss: 4.1239, val_MinusLogProbMetric: 4.1239

Epoch 176: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0721 - MinusLogProbMetric: 4.0721 - val_loss: 4.1239 - val_MinusLogProbMetric: 4.1239 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-12 02:56:42.941 
Epoch 177/1000 
	 loss: 4.0703, MinusLogProbMetric: 4.0703, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 177: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0703 - MinusLogProbMetric: 4.0703 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 178/1000
2023-09-12 02:56:54.673 
Epoch 178/1000 
	 loss: 4.0734, MinusLogProbMetric: 4.0734, val_loss: 4.1336, val_MinusLogProbMetric: 4.1336

Epoch 178: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0734 - MinusLogProbMetric: 4.0734 - val_loss: 4.1336 - val_MinusLogProbMetric: 4.1336 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-12 02:57:06.504 
Epoch 179/1000 
	 loss: 4.0705, MinusLogProbMetric: 4.0705, val_loss: 4.1192, val_MinusLogProbMetric: 4.1192

Epoch 179: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0705 - MinusLogProbMetric: 4.0705 - val_loss: 4.1192 - val_MinusLogProbMetric: 4.1192 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 180/1000
2023-09-12 02:57:18.413 
Epoch 180/1000 
	 loss: 4.0702, MinusLogProbMetric: 4.0702, val_loss: 4.1281, val_MinusLogProbMetric: 4.1281

Epoch 180: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0702 - MinusLogProbMetric: 4.0702 - val_loss: 4.1281 - val_MinusLogProbMetric: 4.1281 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 181/1000
2023-09-12 02:57:29.981 
Epoch 181/1000 
	 loss: 4.0752, MinusLogProbMetric: 4.0752, val_loss: 4.1246, val_MinusLogProbMetric: 4.1246

Epoch 181: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0752 - MinusLogProbMetric: 4.0752 - val_loss: 4.1246 - val_MinusLogProbMetric: 4.1246 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 182/1000
2023-09-12 02:57:42.039 
Epoch 182/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1263, val_MinusLogProbMetric: 4.1263

Epoch 182: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1263 - val_MinusLogProbMetric: 4.1263 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 183/1000
2023-09-12 02:57:53.553 
Epoch 183/1000 
	 loss: 4.0706, MinusLogProbMetric: 4.0706, val_loss: 4.1584, val_MinusLogProbMetric: 4.1584

Epoch 183: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0706 - MinusLogProbMetric: 4.0706 - val_loss: 4.1584 - val_MinusLogProbMetric: 4.1584 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 184/1000
2023-09-12 02:58:05.670 
Epoch 184/1000 
	 loss: 4.0709, MinusLogProbMetric: 4.0709, val_loss: 4.1251, val_MinusLogProbMetric: 4.1251

Epoch 184: val_loss did not improve from 4.11816
196/196 - 12s - loss: 4.0709 - MinusLogProbMetric: 4.0709 - val_loss: 4.1251 - val_MinusLogProbMetric: 4.1251 - lr: 5.0000e-04 - 12s/epoch - 62ms/step
Epoch 185/1000
2023-09-12 02:58:17.016 
Epoch 185/1000 
	 loss: 4.0701, MinusLogProbMetric: 4.0701, val_loss: 4.1240, val_MinusLogProbMetric: 4.1240

Epoch 185: val_loss did not improve from 4.11816
196/196 - 11s - loss: 4.0701 - MinusLogProbMetric: 4.0701 - val_loss: 4.1240 - val_MinusLogProbMetric: 4.1240 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 186/1000
2023-09-12 02:58:27.232 
Epoch 186/1000 
	 loss: 4.0706, MinusLogProbMetric: 4.0706, val_loss: 4.1176, val_MinusLogProbMetric: 4.1176

Epoch 186: val_loss improved from 4.11816 to 4.11764, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_54/weights/best_weights.h5
196/196 - 10s - loss: 4.0706 - MinusLogProbMetric: 4.0706 - val_loss: 4.1176 - val_MinusLogProbMetric: 4.1176 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 187/1000
2023-09-12 02:58:36.983 
Epoch 187/1000 
	 loss: 4.0694, MinusLogProbMetric: 4.0694, val_loss: 4.1318, val_MinusLogProbMetric: 4.1318

Epoch 187: val_loss did not improve from 4.11764
196/196 - 10s - loss: 4.0694 - MinusLogProbMetric: 4.0694 - val_loss: 4.1318 - val_MinusLogProbMetric: 4.1318 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 188/1000
2023-09-12 02:58:47.777 
Epoch 188/1000 
	 loss: 4.0684, MinusLogProbMetric: 4.0684, val_loss: 4.1460, val_MinusLogProbMetric: 4.1460

Epoch 188: val_loss did not improve from 4.11764
196/196 - 11s - loss: 4.0684 - MinusLogProbMetric: 4.0684 - val_loss: 4.1460 - val_MinusLogProbMetric: 4.1460 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 189/1000
2023-09-12 02:58:59.515 
Epoch 189/1000 
	 loss: 4.0792, MinusLogProbMetric: 4.0792, val_loss: 4.1284, val_MinusLogProbMetric: 4.1284

Epoch 189: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0792 - MinusLogProbMetric: 4.0792 - val_loss: 4.1284 - val_MinusLogProbMetric: 4.1284 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 190/1000
2023-09-12 02:59:11.179 
Epoch 190/1000 
	 loss: 4.0688, MinusLogProbMetric: 4.0688, val_loss: 4.1241, val_MinusLogProbMetric: 4.1241

Epoch 190: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0688 - MinusLogProbMetric: 4.0688 - val_loss: 4.1241 - val_MinusLogProbMetric: 4.1241 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 191/1000
2023-09-12 02:59:22.977 
Epoch 191/1000 
	 loss: 4.0722, MinusLogProbMetric: 4.0722, val_loss: 4.1251, val_MinusLogProbMetric: 4.1251

Epoch 191: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0722 - MinusLogProbMetric: 4.0722 - val_loss: 4.1251 - val_MinusLogProbMetric: 4.1251 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 192/1000
2023-09-12 02:59:34.746 
Epoch 192/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1259, val_MinusLogProbMetric: 4.1259

Epoch 192: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1259 - val_MinusLogProbMetric: 4.1259 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-12 02:59:46.423 
Epoch 193/1000 
	 loss: 4.0691, MinusLogProbMetric: 4.0691, val_loss: 4.1295, val_MinusLogProbMetric: 4.1295

Epoch 193: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0691 - MinusLogProbMetric: 4.0691 - val_loss: 4.1295 - val_MinusLogProbMetric: 4.1295 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-12 02:59:58.101 
Epoch 194/1000 
	 loss: 4.0694, MinusLogProbMetric: 4.0694, val_loss: 4.1244, val_MinusLogProbMetric: 4.1244

Epoch 194: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0694 - MinusLogProbMetric: 4.0694 - val_loss: 4.1244 - val_MinusLogProbMetric: 4.1244 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 195/1000
2023-09-12 03:00:09.817 
Epoch 195/1000 
	 loss: 4.0675, MinusLogProbMetric: 4.0675, val_loss: 4.1239, val_MinusLogProbMetric: 4.1239

Epoch 195: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0675 - MinusLogProbMetric: 4.0675 - val_loss: 4.1239 - val_MinusLogProbMetric: 4.1239 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-12 03:00:21.530 
Epoch 196/1000 
	 loss: 4.0678, MinusLogProbMetric: 4.0678, val_loss: 4.1359, val_MinusLogProbMetric: 4.1359

Epoch 196: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0678 - MinusLogProbMetric: 4.0678 - val_loss: 4.1359 - val_MinusLogProbMetric: 4.1359 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-12 03:00:33.223 
Epoch 197/1000 
	 loss: 4.0697, MinusLogProbMetric: 4.0697, val_loss: 4.1200, val_MinusLogProbMetric: 4.1200

Epoch 197: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0697 - MinusLogProbMetric: 4.0697 - val_loss: 4.1200 - val_MinusLogProbMetric: 4.1200 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-12 03:00:45.090 
Epoch 198/1000 
	 loss: 4.0696, MinusLogProbMetric: 4.0696, val_loss: 4.1244, val_MinusLogProbMetric: 4.1244

Epoch 198: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0696 - MinusLogProbMetric: 4.0696 - val_loss: 4.1244 - val_MinusLogProbMetric: 4.1244 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 199/1000
2023-09-12 03:00:56.877 
Epoch 199/1000 
	 loss: 4.0718, MinusLogProbMetric: 4.0718, val_loss: 4.1349, val_MinusLogProbMetric: 4.1349

Epoch 199: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0718 - MinusLogProbMetric: 4.0718 - val_loss: 4.1349 - val_MinusLogProbMetric: 4.1349 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-12 03:01:08.566 
Epoch 200/1000 
	 loss: 4.0695, MinusLogProbMetric: 4.0695, val_loss: 4.1195, val_MinusLogProbMetric: 4.1195

Epoch 200: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0695 - MinusLogProbMetric: 4.0695 - val_loss: 4.1195 - val_MinusLogProbMetric: 4.1195 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-12 03:01:20.310 
Epoch 201/1000 
	 loss: 4.0706, MinusLogProbMetric: 4.0706, val_loss: 4.1263, val_MinusLogProbMetric: 4.1263

Epoch 201: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0706 - MinusLogProbMetric: 4.0706 - val_loss: 4.1263 - val_MinusLogProbMetric: 4.1263 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-12 03:01:31.921 
Epoch 202/1000 
	 loss: 4.0692, MinusLogProbMetric: 4.0692, val_loss: 4.1332, val_MinusLogProbMetric: 4.1332

Epoch 202: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0692 - MinusLogProbMetric: 4.0692 - val_loss: 4.1332 - val_MinusLogProbMetric: 4.1332 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 203/1000
2023-09-12 03:01:43.575 
Epoch 203/1000 
	 loss: 4.0711, MinusLogProbMetric: 4.0711, val_loss: 4.1244, val_MinusLogProbMetric: 4.1244

Epoch 203: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0711 - MinusLogProbMetric: 4.0711 - val_loss: 4.1244 - val_MinusLogProbMetric: 4.1244 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 204/1000
2023-09-12 03:01:55.384 
Epoch 204/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1232, val_MinusLogProbMetric: 4.1232

Epoch 204: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1232 - val_MinusLogProbMetric: 4.1232 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-12 03:02:07.103 
Epoch 205/1000 
	 loss: 4.0667, MinusLogProbMetric: 4.0667, val_loss: 4.1266, val_MinusLogProbMetric: 4.1266

Epoch 205: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0667 - MinusLogProbMetric: 4.0667 - val_loss: 4.1266 - val_MinusLogProbMetric: 4.1266 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 206/1000
2023-09-12 03:02:18.805 
Epoch 206/1000 
	 loss: 4.0684, MinusLogProbMetric: 4.0684, val_loss: 4.1369, val_MinusLogProbMetric: 4.1369

Epoch 206: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0684 - MinusLogProbMetric: 4.0684 - val_loss: 4.1369 - val_MinusLogProbMetric: 4.1369 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 207/1000
2023-09-12 03:02:30.545 
Epoch 207/1000 
	 loss: 4.0685, MinusLogProbMetric: 4.0685, val_loss: 4.1177, val_MinusLogProbMetric: 4.1177

Epoch 207: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0685 - MinusLogProbMetric: 4.0685 - val_loss: 4.1177 - val_MinusLogProbMetric: 4.1177 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-12 03:02:42.170 
Epoch 208/1000 
	 loss: 4.0694, MinusLogProbMetric: 4.0694, val_loss: 4.1262, val_MinusLogProbMetric: 4.1262

Epoch 208: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0694 - MinusLogProbMetric: 4.0694 - val_loss: 4.1262 - val_MinusLogProbMetric: 4.1262 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 209/1000
2023-09-12 03:02:53.817 
Epoch 209/1000 
	 loss: 4.0687, MinusLogProbMetric: 4.0687, val_loss: 4.1260, val_MinusLogProbMetric: 4.1260

Epoch 209: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0687 - MinusLogProbMetric: 4.0687 - val_loss: 4.1260 - val_MinusLogProbMetric: 4.1260 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-12 03:03:05.593 
Epoch 210/1000 
	 loss: 4.0730, MinusLogProbMetric: 4.0730, val_loss: 4.1328, val_MinusLogProbMetric: 4.1328

Epoch 210: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0730 - MinusLogProbMetric: 4.0730 - val_loss: 4.1328 - val_MinusLogProbMetric: 4.1328 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 211/1000
2023-09-12 03:03:17.293 
Epoch 211/1000 
	 loss: 4.0726, MinusLogProbMetric: 4.0726, val_loss: 4.1185, val_MinusLogProbMetric: 4.1185

Epoch 211: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0726 - MinusLogProbMetric: 4.0726 - val_loss: 4.1185 - val_MinusLogProbMetric: 4.1185 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 212/1000
2023-09-12 03:03:29.075 
Epoch 212/1000 
	 loss: 4.0670, MinusLogProbMetric: 4.0670, val_loss: 4.1267, val_MinusLogProbMetric: 4.1267

Epoch 212: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0670 - MinusLogProbMetric: 4.0670 - val_loss: 4.1267 - val_MinusLogProbMetric: 4.1267 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 213/1000
2023-09-12 03:03:40.877 
Epoch 213/1000 
	 loss: 4.0699, MinusLogProbMetric: 4.0699, val_loss: 4.1202, val_MinusLogProbMetric: 4.1202

Epoch 213: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0699 - MinusLogProbMetric: 4.0699 - val_loss: 4.1202 - val_MinusLogProbMetric: 4.1202 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 214/1000
2023-09-12 03:03:52.570 
Epoch 214/1000 
	 loss: 4.0707, MinusLogProbMetric: 4.0707, val_loss: 4.1376, val_MinusLogProbMetric: 4.1376

Epoch 214: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0707 - MinusLogProbMetric: 4.0707 - val_loss: 4.1376 - val_MinusLogProbMetric: 4.1376 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-12 03:04:04.421 
Epoch 215/1000 
	 loss: 4.0684, MinusLogProbMetric: 4.0684, val_loss: 4.1310, val_MinusLogProbMetric: 4.1310

Epoch 215: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0684 - MinusLogProbMetric: 4.0684 - val_loss: 4.1310 - val_MinusLogProbMetric: 4.1310 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 216/1000
2023-09-12 03:04:15.962 
Epoch 216/1000 
	 loss: 4.0693, MinusLogProbMetric: 4.0693, val_loss: 4.1288, val_MinusLogProbMetric: 4.1288

Epoch 216: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0693 - MinusLogProbMetric: 4.0693 - val_loss: 4.1288 - val_MinusLogProbMetric: 4.1288 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 217/1000
2023-09-12 03:04:27.708 
Epoch 217/1000 
	 loss: 4.0686, MinusLogProbMetric: 4.0686, val_loss: 4.1196, val_MinusLogProbMetric: 4.1196

Epoch 217: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0686 - MinusLogProbMetric: 4.0686 - val_loss: 4.1196 - val_MinusLogProbMetric: 4.1196 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 218/1000
2023-09-12 03:04:39.555 
Epoch 218/1000 
	 loss: 4.0675, MinusLogProbMetric: 4.0675, val_loss: 4.1355, val_MinusLogProbMetric: 4.1355

Epoch 218: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0675 - MinusLogProbMetric: 4.0675 - val_loss: 4.1355 - val_MinusLogProbMetric: 4.1355 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-12 03:04:51.261 
Epoch 219/1000 
	 loss: 4.0662, MinusLogProbMetric: 4.0662, val_loss: 4.1234, val_MinusLogProbMetric: 4.1234

Epoch 219: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0662 - MinusLogProbMetric: 4.0662 - val_loss: 4.1234 - val_MinusLogProbMetric: 4.1234 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 220/1000
2023-09-12 03:05:02.989 
Epoch 220/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1286, val_MinusLogProbMetric: 4.1286

Epoch 220: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1286 - val_MinusLogProbMetric: 4.1286 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 221/1000
2023-09-12 03:05:14.727 
Epoch 221/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1228, val_MinusLogProbMetric: 4.1228

Epoch 221: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1228 - val_MinusLogProbMetric: 4.1228 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-12 03:05:26.495 
Epoch 222/1000 
	 loss: 4.0675, MinusLogProbMetric: 4.0675, val_loss: 4.1232, val_MinusLogProbMetric: 4.1232

Epoch 222: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0675 - MinusLogProbMetric: 4.0675 - val_loss: 4.1232 - val_MinusLogProbMetric: 4.1232 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-12 03:05:38.117 
Epoch 223/1000 
	 loss: 4.0683, MinusLogProbMetric: 4.0683, val_loss: 4.1373, val_MinusLogProbMetric: 4.1373

Epoch 223: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0683 - MinusLogProbMetric: 4.0683 - val_loss: 4.1373 - val_MinusLogProbMetric: 4.1373 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 224/1000
2023-09-12 03:05:49.886 
Epoch 224/1000 
	 loss: 4.0681, MinusLogProbMetric: 4.0681, val_loss: 4.1378, val_MinusLogProbMetric: 4.1378

Epoch 224: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0681 - MinusLogProbMetric: 4.0681 - val_loss: 4.1378 - val_MinusLogProbMetric: 4.1378 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-12 03:06:01.449 
Epoch 225/1000 
	 loss: 4.0664, MinusLogProbMetric: 4.0664, val_loss: 4.1251, val_MinusLogProbMetric: 4.1251

Epoch 225: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0664 - MinusLogProbMetric: 4.0664 - val_loss: 4.1251 - val_MinusLogProbMetric: 4.1251 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 226/1000
2023-09-12 03:06:13.064 
Epoch 226/1000 
	 loss: 4.0666, MinusLogProbMetric: 4.0666, val_loss: 4.1283, val_MinusLogProbMetric: 4.1283

Epoch 226: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0666 - MinusLogProbMetric: 4.0666 - val_loss: 4.1283 - val_MinusLogProbMetric: 4.1283 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 227/1000
2023-09-12 03:06:24.881 
Epoch 227/1000 
	 loss: 4.0659, MinusLogProbMetric: 4.0659, val_loss: 4.1252, val_MinusLogProbMetric: 4.1252

Epoch 227: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0659 - MinusLogProbMetric: 4.0659 - val_loss: 4.1252 - val_MinusLogProbMetric: 4.1252 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 228/1000
2023-09-12 03:06:36.467 
Epoch 228/1000 
	 loss: 4.0675, MinusLogProbMetric: 4.0675, val_loss: 4.1439, val_MinusLogProbMetric: 4.1439

Epoch 228: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0675 - MinusLogProbMetric: 4.0675 - val_loss: 4.1439 - val_MinusLogProbMetric: 4.1439 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 229/1000
2023-09-12 03:06:48.198 
Epoch 229/1000 
	 loss: 4.0659, MinusLogProbMetric: 4.0659, val_loss: 4.1428, val_MinusLogProbMetric: 4.1428

Epoch 229: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0659 - MinusLogProbMetric: 4.0659 - val_loss: 4.1428 - val_MinusLogProbMetric: 4.1428 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-12 03:06:59.888 
Epoch 230/1000 
	 loss: 4.0682, MinusLogProbMetric: 4.0682, val_loss: 4.1322, val_MinusLogProbMetric: 4.1322

Epoch 230: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0682 - MinusLogProbMetric: 4.0682 - val_loss: 4.1322 - val_MinusLogProbMetric: 4.1322 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 231/1000
2023-09-12 03:07:11.677 
Epoch 231/1000 
	 loss: 4.0664, MinusLogProbMetric: 4.0664, val_loss: 4.1228, val_MinusLogProbMetric: 4.1228

Epoch 231: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0664 - MinusLogProbMetric: 4.0664 - val_loss: 4.1228 - val_MinusLogProbMetric: 4.1228 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 232/1000
2023-09-12 03:07:23.369 
Epoch 232/1000 
	 loss: 4.0656, MinusLogProbMetric: 4.0656, val_loss: 4.1275, val_MinusLogProbMetric: 4.1275

Epoch 232: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0656 - MinusLogProbMetric: 4.0656 - val_loss: 4.1275 - val_MinusLogProbMetric: 4.1275 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 233/1000
2023-09-12 03:07:35.020 
Epoch 233/1000 
	 loss: 4.0753, MinusLogProbMetric: 4.0753, val_loss: 4.1295, val_MinusLogProbMetric: 4.1295

Epoch 233: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0753 - MinusLogProbMetric: 4.0753 - val_loss: 4.1295 - val_MinusLogProbMetric: 4.1295 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 234/1000
2023-09-12 03:07:46.776 
Epoch 234/1000 
	 loss: 4.0655, MinusLogProbMetric: 4.0655, val_loss: 4.1286, val_MinusLogProbMetric: 4.1286

Epoch 234: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0655 - MinusLogProbMetric: 4.0655 - val_loss: 4.1286 - val_MinusLogProbMetric: 4.1286 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-12 03:07:58.573 
Epoch 235/1000 
	 loss: 4.0670, MinusLogProbMetric: 4.0670, val_loss: 4.1257, val_MinusLogProbMetric: 4.1257

Epoch 235: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0670 - MinusLogProbMetric: 4.0670 - val_loss: 4.1257 - val_MinusLogProbMetric: 4.1257 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 236/1000
2023-09-12 03:08:10.262 
Epoch 236/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1296, val_MinusLogProbMetric: 4.1296

Epoch 236: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1296 - val_MinusLogProbMetric: 4.1296 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 237/1000
2023-09-12 03:08:22.028 
Epoch 237/1000 
	 loss: 4.0569, MinusLogProbMetric: 4.0569, val_loss: 4.1216, val_MinusLogProbMetric: 4.1216

Epoch 237: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0569 - MinusLogProbMetric: 4.0569 - val_loss: 4.1216 - val_MinusLogProbMetric: 4.1216 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 238/1000
2023-09-12 03:08:33.834 
Epoch 238/1000 
	 loss: 4.0579, MinusLogProbMetric: 4.0579, val_loss: 4.1202, val_MinusLogProbMetric: 4.1202

Epoch 238: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0579 - MinusLogProbMetric: 4.0579 - val_loss: 4.1202 - val_MinusLogProbMetric: 4.1202 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-12 03:08:45.633 
Epoch 239/1000 
	 loss: 4.0577, MinusLogProbMetric: 4.0577, val_loss: 4.1214, val_MinusLogProbMetric: 4.1214

Epoch 239: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0577 - MinusLogProbMetric: 4.0577 - val_loss: 4.1214 - val_MinusLogProbMetric: 4.1214 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 240/1000
2023-09-12 03:08:57.314 
Epoch 240/1000 
	 loss: 4.0568, MinusLogProbMetric: 4.0568, val_loss: 4.1222, val_MinusLogProbMetric: 4.1222

Epoch 240: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0568 - MinusLogProbMetric: 4.0568 - val_loss: 4.1222 - val_MinusLogProbMetric: 4.1222 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-12 03:09:09.016 
Epoch 241/1000 
	 loss: 4.0568, MinusLogProbMetric: 4.0568, val_loss: 4.1303, val_MinusLogProbMetric: 4.1303

Epoch 241: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0568 - MinusLogProbMetric: 4.0568 - val_loss: 4.1303 - val_MinusLogProbMetric: 4.1303 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 242/1000
2023-09-12 03:09:20.773 
Epoch 242/1000 
	 loss: 4.0561, MinusLogProbMetric: 4.0561, val_loss: 4.1213, val_MinusLogProbMetric: 4.1213

Epoch 242: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0561 - MinusLogProbMetric: 4.0561 - val_loss: 4.1213 - val_MinusLogProbMetric: 4.1213 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 243/1000
2023-09-12 03:09:32.509 
Epoch 243/1000 
	 loss: 4.0571, MinusLogProbMetric: 4.0571, val_loss: 4.1219, val_MinusLogProbMetric: 4.1219

Epoch 243: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0571 - MinusLogProbMetric: 4.0571 - val_loss: 4.1219 - val_MinusLogProbMetric: 4.1219 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 244/1000
2023-09-12 03:09:44.245 
Epoch 244/1000 
	 loss: 4.0575, MinusLogProbMetric: 4.0575, val_loss: 4.1245, val_MinusLogProbMetric: 4.1245

Epoch 244: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0575 - MinusLogProbMetric: 4.0575 - val_loss: 4.1245 - val_MinusLogProbMetric: 4.1245 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 245/1000
2023-09-12 03:09:55.911 
Epoch 245/1000 
	 loss: 4.0574, MinusLogProbMetric: 4.0574, val_loss: 4.1286, val_MinusLogProbMetric: 4.1286

Epoch 245: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0574 - MinusLogProbMetric: 4.0574 - val_loss: 4.1286 - val_MinusLogProbMetric: 4.1286 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 246/1000
2023-09-12 03:10:07.655 
Epoch 246/1000 
	 loss: 4.0596, MinusLogProbMetric: 4.0596, val_loss: 4.1252, val_MinusLogProbMetric: 4.1252

Epoch 246: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0596 - MinusLogProbMetric: 4.0596 - val_loss: 4.1252 - val_MinusLogProbMetric: 4.1252 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 247/1000
2023-09-12 03:10:19.380 
Epoch 247/1000 
	 loss: 4.0560, MinusLogProbMetric: 4.0560, val_loss: 4.1269, val_MinusLogProbMetric: 4.1269

Epoch 247: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0560 - MinusLogProbMetric: 4.0560 - val_loss: 4.1269 - val_MinusLogProbMetric: 4.1269 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-12 03:10:31.138 
Epoch 248/1000 
	 loss: 4.0567, MinusLogProbMetric: 4.0567, val_loss: 4.1206, val_MinusLogProbMetric: 4.1206

Epoch 248: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0567 - MinusLogProbMetric: 4.0567 - val_loss: 4.1206 - val_MinusLogProbMetric: 4.1206 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-12 03:10:43.000 
Epoch 249/1000 
	 loss: 4.0559, MinusLogProbMetric: 4.0559, val_loss: 4.1260, val_MinusLogProbMetric: 4.1260

Epoch 249: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0559 - MinusLogProbMetric: 4.0559 - val_loss: 4.1260 - val_MinusLogProbMetric: 4.1260 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 250/1000
2023-09-12 03:10:54.820 
Epoch 250/1000 
	 loss: 4.0564, MinusLogProbMetric: 4.0564, val_loss: 4.1184, val_MinusLogProbMetric: 4.1184

Epoch 250: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0564 - MinusLogProbMetric: 4.0564 - val_loss: 4.1184 - val_MinusLogProbMetric: 4.1184 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-12 03:11:06.538 
Epoch 251/1000 
	 loss: 4.0586, MinusLogProbMetric: 4.0586, val_loss: 4.1243, val_MinusLogProbMetric: 4.1243

Epoch 251: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0586 - MinusLogProbMetric: 4.0586 - val_loss: 4.1243 - val_MinusLogProbMetric: 4.1243 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 252/1000
2023-09-12 03:11:18.211 
Epoch 252/1000 
	 loss: 4.0554, MinusLogProbMetric: 4.0554, val_loss: 4.1202, val_MinusLogProbMetric: 4.1202

Epoch 252: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0554 - MinusLogProbMetric: 4.0554 - val_loss: 4.1202 - val_MinusLogProbMetric: 4.1202 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-12 03:11:29.971 
Epoch 253/1000 
	 loss: 4.0566, MinusLogProbMetric: 4.0566, val_loss: 4.1236, val_MinusLogProbMetric: 4.1236

Epoch 253: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0566 - MinusLogProbMetric: 4.0566 - val_loss: 4.1236 - val_MinusLogProbMetric: 4.1236 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 254/1000
2023-09-12 03:11:41.729 
Epoch 254/1000 
	 loss: 4.0549, MinusLogProbMetric: 4.0549, val_loss: 4.1203, val_MinusLogProbMetric: 4.1203

Epoch 254: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0549 - MinusLogProbMetric: 4.0549 - val_loss: 4.1203 - val_MinusLogProbMetric: 4.1203 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-12 03:11:53.335 
Epoch 255/1000 
	 loss: 4.0560, MinusLogProbMetric: 4.0560, val_loss: 4.1265, val_MinusLogProbMetric: 4.1265

Epoch 255: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0560 - MinusLogProbMetric: 4.0560 - val_loss: 4.1265 - val_MinusLogProbMetric: 4.1265 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 256/1000
2023-09-12 03:12:05.017 
Epoch 256/1000 
	 loss: 4.0557, MinusLogProbMetric: 4.0557, val_loss: 4.1229, val_MinusLogProbMetric: 4.1229

Epoch 256: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0557 - MinusLogProbMetric: 4.0557 - val_loss: 4.1229 - val_MinusLogProbMetric: 4.1229 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 257/1000
2023-09-12 03:12:16.632 
Epoch 257/1000 
	 loss: 4.0551, MinusLogProbMetric: 4.0551, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 257: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0551 - MinusLogProbMetric: 4.0551 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 258/1000
2023-09-12 03:12:28.369 
Epoch 258/1000 
	 loss: 4.0559, MinusLogProbMetric: 4.0559, val_loss: 4.1274, val_MinusLogProbMetric: 4.1274

Epoch 258: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0559 - MinusLogProbMetric: 4.0559 - val_loss: 4.1274 - val_MinusLogProbMetric: 4.1274 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 259/1000
2023-09-12 03:12:40.146 
Epoch 259/1000 
	 loss: 4.0552, MinusLogProbMetric: 4.0552, val_loss: 4.1224, val_MinusLogProbMetric: 4.1224

Epoch 259: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0552 - MinusLogProbMetric: 4.0552 - val_loss: 4.1224 - val_MinusLogProbMetric: 4.1224 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 260/1000
2023-09-12 03:12:51.803 
Epoch 260/1000 
	 loss: 4.0554, MinusLogProbMetric: 4.0554, val_loss: 4.1240, val_MinusLogProbMetric: 4.1240

Epoch 260: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0554 - MinusLogProbMetric: 4.0554 - val_loss: 4.1240 - val_MinusLogProbMetric: 4.1240 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 261/1000
2023-09-12 03:13:03.562 
Epoch 261/1000 
	 loss: 4.0558, MinusLogProbMetric: 4.0558, val_loss: 4.1295, val_MinusLogProbMetric: 4.1295

Epoch 261: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0558 - MinusLogProbMetric: 4.0558 - val_loss: 4.1295 - val_MinusLogProbMetric: 4.1295 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 262/1000
2023-09-12 03:13:15.243 
Epoch 262/1000 
	 loss: 4.0590, MinusLogProbMetric: 4.0590, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 262: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0590 - MinusLogProbMetric: 4.0590 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-12 03:13:26.931 
Epoch 263/1000 
	 loss: 4.0556, MinusLogProbMetric: 4.0556, val_loss: 4.1258, val_MinusLogProbMetric: 4.1258

Epoch 263: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0556 - MinusLogProbMetric: 4.0556 - val_loss: 4.1258 - val_MinusLogProbMetric: 4.1258 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 264/1000
2023-09-12 03:13:38.691 
Epoch 264/1000 
	 loss: 4.0562, MinusLogProbMetric: 4.0562, val_loss: 4.1190, val_MinusLogProbMetric: 4.1190

Epoch 264: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0562 - MinusLogProbMetric: 4.0562 - val_loss: 4.1190 - val_MinusLogProbMetric: 4.1190 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 265/1000
2023-09-12 03:13:50.399 
Epoch 265/1000 
	 loss: 4.0562, MinusLogProbMetric: 4.0562, val_loss: 4.1209, val_MinusLogProbMetric: 4.1209

Epoch 265: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0562 - MinusLogProbMetric: 4.0562 - val_loss: 4.1209 - val_MinusLogProbMetric: 4.1209 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 266/1000
2023-09-12 03:14:02.091 
Epoch 266/1000 
	 loss: 4.0553, MinusLogProbMetric: 4.0553, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 266: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0553 - MinusLogProbMetric: 4.0553 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 267/1000
2023-09-12 03:14:13.725 
Epoch 267/1000 
	 loss: 4.0555, MinusLogProbMetric: 4.0555, val_loss: 4.1256, val_MinusLogProbMetric: 4.1256

Epoch 267: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0555 - MinusLogProbMetric: 4.0555 - val_loss: 4.1256 - val_MinusLogProbMetric: 4.1256 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 268/1000
2023-09-12 03:14:25.470 
Epoch 268/1000 
	 loss: 4.0546, MinusLogProbMetric: 4.0546, val_loss: 4.1252, val_MinusLogProbMetric: 4.1252

Epoch 268: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0546 - MinusLogProbMetric: 4.0546 - val_loss: 4.1252 - val_MinusLogProbMetric: 4.1252 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-12 03:14:37.097 
Epoch 269/1000 
	 loss: 4.0544, MinusLogProbMetric: 4.0544, val_loss: 4.1230, val_MinusLogProbMetric: 4.1230

Epoch 269: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0544 - MinusLogProbMetric: 4.0544 - val_loss: 4.1230 - val_MinusLogProbMetric: 4.1230 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 270/1000
2023-09-12 03:14:48.766 
Epoch 270/1000 
	 loss: 4.0552, MinusLogProbMetric: 4.0552, val_loss: 4.1203, val_MinusLogProbMetric: 4.1203

Epoch 270: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0552 - MinusLogProbMetric: 4.0552 - val_loss: 4.1203 - val_MinusLogProbMetric: 4.1203 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 271/1000
2023-09-12 03:15:00.462 
Epoch 271/1000 
	 loss: 4.0557, MinusLogProbMetric: 4.0557, val_loss: 4.1414, val_MinusLogProbMetric: 4.1414

Epoch 271: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0557 - MinusLogProbMetric: 4.0557 - val_loss: 4.1414 - val_MinusLogProbMetric: 4.1414 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-12 03:15:12.218 
Epoch 272/1000 
	 loss: 4.0568, MinusLogProbMetric: 4.0568, val_loss: 4.1209, val_MinusLogProbMetric: 4.1209

Epoch 272: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0568 - MinusLogProbMetric: 4.0568 - val_loss: 4.1209 - val_MinusLogProbMetric: 4.1209 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 273/1000
2023-09-12 03:15:23.977 
Epoch 273/1000 
	 loss: 4.0545, MinusLogProbMetric: 4.0545, val_loss: 4.1279, val_MinusLogProbMetric: 4.1279

Epoch 273: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0545 - MinusLogProbMetric: 4.0545 - val_loss: 4.1279 - val_MinusLogProbMetric: 4.1279 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 274/1000
2023-09-12 03:15:35.629 
Epoch 274/1000 
	 loss: 4.0561, MinusLogProbMetric: 4.0561, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 274: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0561 - MinusLogProbMetric: 4.0561 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 275/1000
2023-09-12 03:15:47.341 
Epoch 275/1000 
	 loss: 4.0547, MinusLogProbMetric: 4.0547, val_loss: 4.1276, val_MinusLogProbMetric: 4.1276

Epoch 275: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0547 - MinusLogProbMetric: 4.0547 - val_loss: 4.1276 - val_MinusLogProbMetric: 4.1276 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 276/1000
2023-09-12 03:15:59.158 
Epoch 276/1000 
	 loss: 4.0543, MinusLogProbMetric: 4.0543, val_loss: 4.1243, val_MinusLogProbMetric: 4.1243

Epoch 276: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0543 - MinusLogProbMetric: 4.0543 - val_loss: 4.1243 - val_MinusLogProbMetric: 4.1243 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 277/1000
2023-09-12 03:16:10.900 
Epoch 277/1000 
	 loss: 4.0581, MinusLogProbMetric: 4.0581, val_loss: 4.1251, val_MinusLogProbMetric: 4.1251

Epoch 277: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0581 - MinusLogProbMetric: 4.0581 - val_loss: 4.1251 - val_MinusLogProbMetric: 4.1251 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 278/1000
2023-09-12 03:16:22.672 
Epoch 278/1000 
	 loss: 4.0543, MinusLogProbMetric: 4.0543, val_loss: 4.1212, val_MinusLogProbMetric: 4.1212

Epoch 278: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0543 - MinusLogProbMetric: 4.0543 - val_loss: 4.1212 - val_MinusLogProbMetric: 4.1212 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 279/1000
2023-09-12 03:16:34.445 
Epoch 279/1000 
	 loss: 4.0552, MinusLogProbMetric: 4.0552, val_loss: 4.1294, val_MinusLogProbMetric: 4.1294

Epoch 279: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0552 - MinusLogProbMetric: 4.0552 - val_loss: 4.1294 - val_MinusLogProbMetric: 4.1294 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 280/1000
2023-09-12 03:16:46.137 
Epoch 280/1000 
	 loss: 4.0555, MinusLogProbMetric: 4.0555, val_loss: 4.1309, val_MinusLogProbMetric: 4.1309

Epoch 280: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0555 - MinusLogProbMetric: 4.0555 - val_loss: 4.1309 - val_MinusLogProbMetric: 4.1309 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-12 03:16:57.829 
Epoch 281/1000 
	 loss: 4.0553, MinusLogProbMetric: 4.0553, val_loss: 4.1205, val_MinusLogProbMetric: 4.1205

Epoch 281: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0553 - MinusLogProbMetric: 4.0553 - val_loss: 4.1205 - val_MinusLogProbMetric: 4.1205 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 282/1000
2023-09-12 03:17:09.445 
Epoch 282/1000 
	 loss: 4.0546, MinusLogProbMetric: 4.0546, val_loss: 4.1320, val_MinusLogProbMetric: 4.1320

Epoch 282: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0546 - MinusLogProbMetric: 4.0546 - val_loss: 4.1320 - val_MinusLogProbMetric: 4.1320 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 283/1000
2023-09-12 03:17:21.204 
Epoch 283/1000 
	 loss: 4.0543, MinusLogProbMetric: 4.0543, val_loss: 4.1261, val_MinusLogProbMetric: 4.1261

Epoch 283: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0543 - MinusLogProbMetric: 4.0543 - val_loss: 4.1261 - val_MinusLogProbMetric: 4.1261 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-12 03:17:32.925 
Epoch 284/1000 
	 loss: 4.0537, MinusLogProbMetric: 4.0537, val_loss: 4.1274, val_MinusLogProbMetric: 4.1274

Epoch 284: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0537 - MinusLogProbMetric: 4.0537 - val_loss: 4.1274 - val_MinusLogProbMetric: 4.1274 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 285/1000
2023-09-12 03:17:44.592 
Epoch 285/1000 
	 loss: 4.0544, MinusLogProbMetric: 4.0544, val_loss: 4.1234, val_MinusLogProbMetric: 4.1234

Epoch 285: val_loss did not improve from 4.11764
196/196 - 12s - loss: 4.0544 - MinusLogProbMetric: 4.0544 - val_loss: 4.1234 - val_MinusLogProbMetric: 4.1234 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 286/1000
2023-09-12 03:17:56.161 
Epoch 286/1000 
	 loss: 4.0540, MinusLogProbMetric: 4.0540, val_loss: 4.1233, val_MinusLogProbMetric: 4.1233

Epoch 286: val_loss did not improve from 4.11764
Restoring model weights from the end of the best epoch: 186.
196/196 - 12s - loss: 4.0540 - MinusLogProbMetric: 4.0540 - val_loss: 4.1233 - val_MinusLogProbMetric: 4.1233 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 286: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.585115358931944 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.415203085052781 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.991607847972773 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.086472579045221 seconds.
Training succeeded with seed 440.
Model trained in 3359.79 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 22.72 s.
Plots done in 10.37 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 33.09 s.
===========
Run 54/360 done in 3394.24 s.
===========

Directory ../../results/MsplineN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

===========
Generating train data for run 60.
===========
Train data generated in 0.23 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_60/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_60/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[10.049758  ,  4.268385  ,  7.926563  , ...,  9.30884   ,
         0.8377404 ,  1.4002337 ],
       [ 0.8883975 ,  8.264331  ,  8.186552  , ...,  7.562158  ,
         4.5833206 ,  7.646627  ],
       [ 9.455839  ,  4.437851  ,  7.931938  , ..., 10.117145  ,
         1.5715699 ,  1.667325  ],
       ...,
       [-0.0213912 ,  7.4854965 ,  8.31225   , ...,  7.0570807 ,
         4.387896  ,  7.8744864 ],
       [ 9.783626  ,  3.9129486 ,  7.941707  , ...,  9.4071455 ,
         0.9804493 ,  1.4779084 ],
       [ 0.09697292,  9.003742  ,  6.7814546 , ...,  7.649544  ,
         4.3774447 ,  7.836157  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_60/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_60
self.data_kwargs: {'seed': 520}
self.x_data: [[ 9.807922    4.0352354   7.8932676  ...  9.471432   -0.28331584
   1.3571403 ]
 [ 0.32675052  8.673955    8.208642   ...  8.794708    4.7731004
   7.736645  ]
 [ 0.21370578  8.460088    8.035857   ...  9.266987    4.615468
   7.978693  ]
 ...
 [ 0.03638138  7.8445787   7.0564733  ...  8.316563    4.394707
   7.6804276 ]
 [ 5.456363    6.464849    5.8161635  ...  6.1865835   4.5304494
   8.093089  ]
 [ 0.28881437  7.741578    7.9390054  ...  7.438477    4.385378
   8.055629  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_7 (LogProbLa  (None,)                  411696    
 yer)                                                            
                                                                 
=================================================================
Total params: 411,696
Trainable params: 411,696
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_7/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_7'")
self.model: <keras.engine.functional.Functional object at 0x7fc6c42ebb80>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc6c42cbd90>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc6c42cbd90>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc6c427e590>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc6ec7d2710>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc6ec7d2c80>, <keras.callbacks.ModelCheckpoint object at 0x7fc6ec7d2d40>, <keras.callbacks.EarlyStopping object at 0x7fc6ec7d2fb0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc6ec7d2fe0>, <keras.callbacks.TerminateOnNaN object at 0x7fc6ec7d2c20>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[10.049758  ,  4.268385  ,  7.926563  , ...,  9.30884   ,
         0.8377404 ,  1.4002337 ],
       [ 0.8883975 ,  8.264331  ,  8.186552  , ...,  7.562158  ,
         4.5833206 ,  7.646627  ],
       [ 9.455839  ,  4.437851  ,  7.931938  , ..., 10.117145  ,
         1.5715699 ,  1.667325  ],
       ...,
       [-0.0213912 ,  7.4854965 ,  8.31225   , ...,  7.0570807 ,
         4.387896  ,  7.8744864 ],
       [ 9.783626  ,  3.9129486 ,  7.941707  , ...,  9.4071455 ,
         0.9804493 ,  1.4779084 ],
       [ 0.09697292,  9.003742  ,  6.7814546 , ...,  7.649544  ,
         4.3774447 ,  7.836157  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_60/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 60/360 with hyperparameters:
timestamp = 2023-09-12 03:18:30.503006
ndims = 8
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 411696
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 9.807922    4.0352354   7.8932676   6.2930956   6.419638    9.471432
 -0.28331584  1.3571403 ]
Epoch 1/1000
2023-09-12 03:19:01.518 
Epoch 1/1000 
	 loss: 13.8034, MinusLogProbMetric: 13.8034, val_loss: 5.2905, val_MinusLogProbMetric: 5.2905

Epoch 1: val_loss improved from inf to 5.29050, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 31s - loss: 13.8034 - MinusLogProbMetric: 13.8034 - val_loss: 5.2905 - val_MinusLogProbMetric: 5.2905 - lr: 0.0010 - 31s/epoch - 158ms/step
Epoch 2/1000
2023-09-12 03:19:13.138 
Epoch 2/1000 
	 loss: 4.9298, MinusLogProbMetric: 4.9298, val_loss: 4.7780, val_MinusLogProbMetric: 4.7780

Epoch 2: val_loss improved from 5.29050 to 4.77799, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.9298 - MinusLogProbMetric: 4.9298 - val_loss: 4.7780 - val_MinusLogProbMetric: 4.7780 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 3/1000
2023-09-12 03:19:24.682 
Epoch 3/1000 
	 loss: 4.5433, MinusLogProbMetric: 4.5433, val_loss: 4.3592, val_MinusLogProbMetric: 4.3592

Epoch 3: val_loss improved from 4.77799 to 4.35923, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.5433 - MinusLogProbMetric: 4.5433 - val_loss: 4.3592 - val_MinusLogProbMetric: 4.3592 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 4/1000
2023-09-12 03:19:36.210 
Epoch 4/1000 
	 loss: 4.4247, MinusLogProbMetric: 4.4247, val_loss: 4.3382, val_MinusLogProbMetric: 4.3382

Epoch 4: val_loss improved from 4.35923 to 4.33815, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.4247 - MinusLogProbMetric: 4.4247 - val_loss: 4.3382 - val_MinusLogProbMetric: 4.3382 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 5/1000
2023-09-12 03:19:47.817 
Epoch 5/1000 
	 loss: 4.3839, MinusLogProbMetric: 4.3839, val_loss: 4.2764, val_MinusLogProbMetric: 4.2764

Epoch 5: val_loss improved from 4.33815 to 4.27642, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.3839 - MinusLogProbMetric: 4.3839 - val_loss: 4.2764 - val_MinusLogProbMetric: 4.2764 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 6/1000
2023-09-12 03:19:59.562 
Epoch 6/1000 
	 loss: 4.3485, MinusLogProbMetric: 4.3485, val_loss: 4.3517, val_MinusLogProbMetric: 4.3517

Epoch 6: val_loss did not improve from 4.27642
196/196 - 12s - loss: 4.3485 - MinusLogProbMetric: 4.3485 - val_loss: 4.3517 - val_MinusLogProbMetric: 4.3517 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 7/1000
2023-09-12 03:20:10.860 
Epoch 7/1000 
	 loss: 4.3205, MinusLogProbMetric: 4.3205, val_loss: 4.2935, val_MinusLogProbMetric: 4.2935

Epoch 7: val_loss did not improve from 4.27642
196/196 - 11s - loss: 4.3205 - MinusLogProbMetric: 4.3205 - val_loss: 4.2935 - val_MinusLogProbMetric: 4.2935 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 8/1000
2023-09-12 03:20:22.378 
Epoch 8/1000 
	 loss: 4.3133, MinusLogProbMetric: 4.3133, val_loss: 4.2353, val_MinusLogProbMetric: 4.2353

Epoch 8: val_loss improved from 4.27642 to 4.23531, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.3133 - MinusLogProbMetric: 4.3133 - val_loss: 4.2353 - val_MinusLogProbMetric: 4.2353 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-12 03:20:33.898 
Epoch 9/1000 
	 loss: 4.2993, MinusLogProbMetric: 4.2993, val_loss: 4.3131, val_MinusLogProbMetric: 4.3131

Epoch 9: val_loss did not improve from 4.23531
196/196 - 11s - loss: 4.2993 - MinusLogProbMetric: 4.2993 - val_loss: 4.3131 - val_MinusLogProbMetric: 4.3131 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 10/1000
2023-09-12 03:20:45.344 
Epoch 10/1000 
	 loss: 4.2462, MinusLogProbMetric: 4.2462, val_loss: 4.2670, val_MinusLogProbMetric: 4.2670

Epoch 10: val_loss did not improve from 4.23531
196/196 - 11s - loss: 4.2462 - MinusLogProbMetric: 4.2462 - val_loss: 4.2670 - val_MinusLogProbMetric: 4.2670 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 11/1000
2023-09-12 03:20:56.840 
Epoch 11/1000 
	 loss: 4.2553, MinusLogProbMetric: 4.2553, val_loss: 4.1697, val_MinusLogProbMetric: 4.1697

Epoch 11: val_loss improved from 4.23531 to 4.16966, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.2553 - MinusLogProbMetric: 4.2553 - val_loss: 4.1697 - val_MinusLogProbMetric: 4.1697 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 12/1000
2023-09-12 03:21:08.477 
Epoch 12/1000 
	 loss: 4.2567, MinusLogProbMetric: 4.2567, val_loss: 4.2189, val_MinusLogProbMetric: 4.2189

Epoch 12: val_loss did not improve from 4.16966
196/196 - 11s - loss: 4.2567 - MinusLogProbMetric: 4.2567 - val_loss: 4.2189 - val_MinusLogProbMetric: 4.2189 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 13/1000
2023-09-12 03:21:19.776 
Epoch 13/1000 
	 loss: 4.2243, MinusLogProbMetric: 4.2243, val_loss: 4.2266, val_MinusLogProbMetric: 4.2266

Epoch 13: val_loss did not improve from 4.16966
196/196 - 11s - loss: 4.2243 - MinusLogProbMetric: 4.2243 - val_loss: 4.2266 - val_MinusLogProbMetric: 4.2266 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 14/1000
2023-09-12 03:21:30.328 
Epoch 14/1000 
	 loss: 4.2258, MinusLogProbMetric: 4.2258, val_loss: 4.2423, val_MinusLogProbMetric: 4.2423

Epoch 14: val_loss did not improve from 4.16966
196/196 - 11s - loss: 4.2258 - MinusLogProbMetric: 4.2258 - val_loss: 4.2423 - val_MinusLogProbMetric: 4.2423 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 15/1000
2023-09-12 03:21:39.202 
Epoch 15/1000 
	 loss: 4.3079, MinusLogProbMetric: 4.3079, val_loss: 4.1916, val_MinusLogProbMetric: 4.1916

Epoch 15: val_loss did not improve from 4.16966
196/196 - 9s - loss: 4.3079 - MinusLogProbMetric: 4.3079 - val_loss: 4.1916 - val_MinusLogProbMetric: 4.1916 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 16/1000
2023-09-12 03:21:48.502 
Epoch 16/1000 
	 loss: 4.2199, MinusLogProbMetric: 4.2199, val_loss: 4.1770, val_MinusLogProbMetric: 4.1770

Epoch 16: val_loss did not improve from 4.16966
196/196 - 9s - loss: 4.2199 - MinusLogProbMetric: 4.2199 - val_loss: 4.1770 - val_MinusLogProbMetric: 4.1770 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 17/1000
2023-09-12 03:21:58.519 
Epoch 17/1000 
	 loss: 4.2251, MinusLogProbMetric: 4.2251, val_loss: 4.2343, val_MinusLogProbMetric: 4.2343

Epoch 17: val_loss did not improve from 4.16966
196/196 - 10s - loss: 4.2251 - MinusLogProbMetric: 4.2251 - val_loss: 4.2343 - val_MinusLogProbMetric: 4.2343 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 18/1000
2023-09-12 03:22:09.946 
Epoch 18/1000 
	 loss: 4.2080, MinusLogProbMetric: 4.2080, val_loss: 4.2046, val_MinusLogProbMetric: 4.2046

Epoch 18: val_loss did not improve from 4.16966
196/196 - 11s - loss: 4.2080 - MinusLogProbMetric: 4.2080 - val_loss: 4.2046 - val_MinusLogProbMetric: 4.2046 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 19/1000
2023-09-12 03:22:21.410 
Epoch 19/1000 
	 loss: 4.2051, MinusLogProbMetric: 4.2051, val_loss: 4.2109, val_MinusLogProbMetric: 4.2109

Epoch 19: val_loss did not improve from 4.16966
196/196 - 11s - loss: 4.2051 - MinusLogProbMetric: 4.2051 - val_loss: 4.2109 - val_MinusLogProbMetric: 4.2109 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 20/1000
2023-09-12 03:22:32.866 
Epoch 20/1000 
	 loss: 4.1990, MinusLogProbMetric: 4.1990, val_loss: 4.2782, val_MinusLogProbMetric: 4.2782

Epoch 20: val_loss did not improve from 4.16966
196/196 - 11s - loss: 4.1990 - MinusLogProbMetric: 4.1990 - val_loss: 4.2782 - val_MinusLogProbMetric: 4.2782 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 21/1000
2023-09-12 03:22:44.385 
Epoch 21/1000 
	 loss: 4.1916, MinusLogProbMetric: 4.1916, val_loss: 4.1736, val_MinusLogProbMetric: 4.1736

Epoch 21: val_loss did not improve from 4.16966
196/196 - 12s - loss: 4.1916 - MinusLogProbMetric: 4.1916 - val_loss: 4.1736 - val_MinusLogProbMetric: 4.1736 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 03:22:55.918 
Epoch 22/1000 
	 loss: 4.1984, MinusLogProbMetric: 4.1984, val_loss: 4.2279, val_MinusLogProbMetric: 4.2279

Epoch 22: val_loss did not improve from 4.16966
196/196 - 12s - loss: 4.1984 - MinusLogProbMetric: 4.1984 - val_loss: 4.2279 - val_MinusLogProbMetric: 4.2279 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 23/1000
2023-09-12 03:23:07.393 
Epoch 23/1000 
	 loss: 4.1907, MinusLogProbMetric: 4.1907, val_loss: 4.1653, val_MinusLogProbMetric: 4.1653

Epoch 23: val_loss improved from 4.16966 to 4.16528, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1907 - MinusLogProbMetric: 4.1907 - val_loss: 4.1653 - val_MinusLogProbMetric: 4.1653 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 24/1000
2023-09-12 03:23:19.031 
Epoch 24/1000 
	 loss: 4.1897, MinusLogProbMetric: 4.1897, val_loss: 4.2589, val_MinusLogProbMetric: 4.2589

Epoch 24: val_loss did not improve from 4.16528
196/196 - 11s - loss: 4.1897 - MinusLogProbMetric: 4.1897 - val_loss: 4.2589 - val_MinusLogProbMetric: 4.2589 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 25/1000
2023-09-12 03:23:30.526 
Epoch 25/1000 
	 loss: 4.1878, MinusLogProbMetric: 4.1878, val_loss: 4.2476, val_MinusLogProbMetric: 4.2476

Epoch 25: val_loss did not improve from 4.16528
196/196 - 11s - loss: 4.1878 - MinusLogProbMetric: 4.1878 - val_loss: 4.2476 - val_MinusLogProbMetric: 4.2476 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 26/1000
2023-09-12 03:23:42.078 
Epoch 26/1000 
	 loss: 4.2008, MinusLogProbMetric: 4.2008, val_loss: 4.1447, val_MinusLogProbMetric: 4.1447

Epoch 26: val_loss improved from 4.16528 to 4.14470, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.2008 - MinusLogProbMetric: 4.2008 - val_loss: 4.1447 - val_MinusLogProbMetric: 4.1447 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 03:23:53.766 
Epoch 27/1000 
	 loss: 4.1744, MinusLogProbMetric: 4.1744, val_loss: 4.2065, val_MinusLogProbMetric: 4.2065

Epoch 27: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1744 - MinusLogProbMetric: 4.1744 - val_loss: 4.2065 - val_MinusLogProbMetric: 4.2065 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 28/1000
2023-09-12 03:24:05.225 
Epoch 28/1000 
	 loss: 4.9840, MinusLogProbMetric: 4.9840, val_loss: 4.6198, val_MinusLogProbMetric: 4.6198

Epoch 28: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.9840 - MinusLogProbMetric: 4.9840 - val_loss: 4.6198 - val_MinusLogProbMetric: 4.6198 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 29/1000
2023-09-12 03:24:16.794 
Epoch 29/1000 
	 loss: 4.4592, MinusLogProbMetric: 4.4592, val_loss: 4.3064, val_MinusLogProbMetric: 4.3064

Epoch 29: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.4592 - MinusLogProbMetric: 4.4592 - val_loss: 4.3064 - val_MinusLogProbMetric: 4.3064 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 30/1000
2023-09-12 03:24:28.144 
Epoch 30/1000 
	 loss: 4.2690, MinusLogProbMetric: 4.2690, val_loss: 4.2271, val_MinusLogProbMetric: 4.2271

Epoch 30: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.2690 - MinusLogProbMetric: 4.2690 - val_loss: 4.2271 - val_MinusLogProbMetric: 4.2271 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 31/1000
2023-09-12 03:24:39.731 
Epoch 31/1000 
	 loss: 4.2580, MinusLogProbMetric: 4.2580, val_loss: 4.1964, val_MinusLogProbMetric: 4.1964

Epoch 31: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.2580 - MinusLogProbMetric: 4.2580 - val_loss: 4.1964 - val_MinusLogProbMetric: 4.1964 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 32/1000
2023-09-12 03:24:51.232 
Epoch 32/1000 
	 loss: 4.2144, MinusLogProbMetric: 4.2144, val_loss: 4.1818, val_MinusLogProbMetric: 4.1818

Epoch 32: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.2144 - MinusLogProbMetric: 4.2144 - val_loss: 4.1818 - val_MinusLogProbMetric: 4.1818 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 33/1000
2023-09-12 03:25:02.710 
Epoch 33/1000 
	 loss: 4.2169, MinusLogProbMetric: 4.2169, val_loss: 4.1883, val_MinusLogProbMetric: 4.1883

Epoch 33: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.2169 - MinusLogProbMetric: 4.2169 - val_loss: 4.1883 - val_MinusLogProbMetric: 4.1883 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 34/1000
2023-09-12 03:25:14.244 
Epoch 34/1000 
	 loss: 4.1953, MinusLogProbMetric: 4.1953, val_loss: 4.1913, val_MinusLogProbMetric: 4.1913

Epoch 34: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1953 - MinusLogProbMetric: 4.1953 - val_loss: 4.1913 - val_MinusLogProbMetric: 4.1913 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 35/1000
2023-09-12 03:25:25.583 
Epoch 35/1000 
	 loss: 4.1974, MinusLogProbMetric: 4.1974, val_loss: 4.1962, val_MinusLogProbMetric: 4.1962

Epoch 35: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.1974 - MinusLogProbMetric: 4.1974 - val_loss: 4.1962 - val_MinusLogProbMetric: 4.1962 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 36/1000
2023-09-12 03:25:37.144 
Epoch 36/1000 
	 loss: 4.1943, MinusLogProbMetric: 4.1943, val_loss: 4.2022, val_MinusLogProbMetric: 4.2022

Epoch 36: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1943 - MinusLogProbMetric: 4.1943 - val_loss: 4.2022 - val_MinusLogProbMetric: 4.2022 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 37/1000
2023-09-12 03:25:48.611 
Epoch 37/1000 
	 loss: 4.1780, MinusLogProbMetric: 4.1780, val_loss: 4.1679, val_MinusLogProbMetric: 4.1679

Epoch 37: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.1780 - MinusLogProbMetric: 4.1780 - val_loss: 4.1679 - val_MinusLogProbMetric: 4.1679 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 38/1000
2023-09-12 03:26:00.098 
Epoch 38/1000 
	 loss: 4.1890, MinusLogProbMetric: 4.1890, val_loss: 4.1841, val_MinusLogProbMetric: 4.1841

Epoch 38: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.1890 - MinusLogProbMetric: 4.1890 - val_loss: 4.1841 - val_MinusLogProbMetric: 4.1841 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 39/1000
2023-09-12 03:26:11.657 
Epoch 39/1000 
	 loss: 4.1849, MinusLogProbMetric: 4.1849, val_loss: 4.1547, val_MinusLogProbMetric: 4.1547

Epoch 39: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1849 - MinusLogProbMetric: 4.1849 - val_loss: 4.1547 - val_MinusLogProbMetric: 4.1547 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-12 03:26:23.235 
Epoch 40/1000 
	 loss: 4.1775, MinusLogProbMetric: 4.1775, val_loss: 4.1841, val_MinusLogProbMetric: 4.1841

Epoch 40: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1775 - MinusLogProbMetric: 4.1775 - val_loss: 4.1841 - val_MinusLogProbMetric: 4.1841 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 41/1000
2023-09-12 03:26:34.799 
Epoch 41/1000 
	 loss: 4.1888, MinusLogProbMetric: 4.1888, val_loss: 4.1790, val_MinusLogProbMetric: 4.1790

Epoch 41: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1888 - MinusLogProbMetric: 4.1888 - val_loss: 4.1790 - val_MinusLogProbMetric: 4.1790 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 42/1000
2023-09-12 03:26:46.316 
Epoch 42/1000 
	 loss: 4.1676, MinusLogProbMetric: 4.1676, val_loss: 4.1744, val_MinusLogProbMetric: 4.1744

Epoch 42: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1676 - MinusLogProbMetric: 4.1676 - val_loss: 4.1744 - val_MinusLogProbMetric: 4.1744 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 43/1000
2023-09-12 03:26:57.769 
Epoch 43/1000 
	 loss: 4.1714, MinusLogProbMetric: 4.1714, val_loss: 4.1501, val_MinusLogProbMetric: 4.1501

Epoch 43: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.1714 - MinusLogProbMetric: 4.1714 - val_loss: 4.1501 - val_MinusLogProbMetric: 4.1501 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 44/1000
2023-09-12 03:27:09.198 
Epoch 44/1000 
	 loss: 4.1748, MinusLogProbMetric: 4.1748, val_loss: 4.1782, val_MinusLogProbMetric: 4.1782

Epoch 44: val_loss did not improve from 4.14470
196/196 - 11s - loss: 4.1748 - MinusLogProbMetric: 4.1748 - val_loss: 4.1782 - val_MinusLogProbMetric: 4.1782 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 45/1000
2023-09-12 03:27:20.725 
Epoch 45/1000 
	 loss: 4.1720, MinusLogProbMetric: 4.1720, val_loss: 4.2072, val_MinusLogProbMetric: 4.2072

Epoch 45: val_loss did not improve from 4.14470
196/196 - 12s - loss: 4.1720 - MinusLogProbMetric: 4.1720 - val_loss: 4.2072 - val_MinusLogProbMetric: 4.2072 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 46/1000
2023-09-12 03:27:32.164 
Epoch 46/1000 
	 loss: 4.1634, MinusLogProbMetric: 4.1634, val_loss: 4.1347, val_MinusLogProbMetric: 4.1347

Epoch 46: val_loss improved from 4.14470 to 4.13471, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1634 - MinusLogProbMetric: 4.1634 - val_loss: 4.1347 - val_MinusLogProbMetric: 4.1347 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 03:27:43.668 
Epoch 47/1000 
	 loss: 4.1679, MinusLogProbMetric: 4.1679, val_loss: 4.1646, val_MinusLogProbMetric: 4.1646

Epoch 47: val_loss did not improve from 4.13471
196/196 - 11s - loss: 4.1679 - MinusLogProbMetric: 4.1679 - val_loss: 4.1646 - val_MinusLogProbMetric: 4.1646 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 48/1000
2023-09-12 03:27:55.251 
Epoch 48/1000 
	 loss: 4.1547, MinusLogProbMetric: 4.1547, val_loss: 4.1487, val_MinusLogProbMetric: 4.1487

Epoch 48: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1547 - MinusLogProbMetric: 4.1547 - val_loss: 4.1487 - val_MinusLogProbMetric: 4.1487 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 49/1000
2023-09-12 03:28:06.824 
Epoch 49/1000 
	 loss: 4.1608, MinusLogProbMetric: 4.1608, val_loss: 4.1572, val_MinusLogProbMetric: 4.1572

Epoch 49: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1608 - MinusLogProbMetric: 4.1608 - val_loss: 4.1572 - val_MinusLogProbMetric: 4.1572 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-12 03:28:18.396 
Epoch 50/1000 
	 loss: 4.1647, MinusLogProbMetric: 4.1647, val_loss: 4.1880, val_MinusLogProbMetric: 4.1880

Epoch 50: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1647 - MinusLogProbMetric: 4.1647 - val_loss: 4.1880 - val_MinusLogProbMetric: 4.1880 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 51/1000
2023-09-12 03:28:29.960 
Epoch 51/1000 
	 loss: 4.1586, MinusLogProbMetric: 4.1586, val_loss: 4.1769, val_MinusLogProbMetric: 4.1769

Epoch 51: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1586 - MinusLogProbMetric: 4.1586 - val_loss: 4.1769 - val_MinusLogProbMetric: 4.1769 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 52/1000
2023-09-12 03:28:41.510 
Epoch 52/1000 
	 loss: 4.1594, MinusLogProbMetric: 4.1594, val_loss: 4.1646, val_MinusLogProbMetric: 4.1646

Epoch 52: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1594 - MinusLogProbMetric: 4.1594 - val_loss: 4.1646 - val_MinusLogProbMetric: 4.1646 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 53/1000
2023-09-12 03:28:52.958 
Epoch 53/1000 
	 loss: 4.1608, MinusLogProbMetric: 4.1608, val_loss: 4.1533, val_MinusLogProbMetric: 4.1533

Epoch 53: val_loss did not improve from 4.13471
196/196 - 11s - loss: 4.1608 - MinusLogProbMetric: 4.1608 - val_loss: 4.1533 - val_MinusLogProbMetric: 4.1533 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 54/1000
2023-09-12 03:29:04.419 
Epoch 54/1000 
	 loss: 4.1540, MinusLogProbMetric: 4.1540, val_loss: 4.1576, val_MinusLogProbMetric: 4.1576

Epoch 54: val_loss did not improve from 4.13471
196/196 - 11s - loss: 4.1540 - MinusLogProbMetric: 4.1540 - val_loss: 4.1576 - val_MinusLogProbMetric: 4.1576 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 55/1000
2023-09-12 03:29:16.088 
Epoch 55/1000 
	 loss: 4.1568, MinusLogProbMetric: 4.1568, val_loss: 4.1373, val_MinusLogProbMetric: 4.1373

Epoch 55: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1568 - MinusLogProbMetric: 4.1568 - val_loss: 4.1373 - val_MinusLogProbMetric: 4.1373 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-12 03:29:27.623 
Epoch 56/1000 
	 loss: 4.1494, MinusLogProbMetric: 4.1494, val_loss: 4.2083, val_MinusLogProbMetric: 4.2083

Epoch 56: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1494 - MinusLogProbMetric: 4.1494 - val_loss: 4.2083 - val_MinusLogProbMetric: 4.2083 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 57/1000
2023-09-12 03:29:38.997 
Epoch 57/1000 
	 loss: 4.1514, MinusLogProbMetric: 4.1514, val_loss: 4.1439, val_MinusLogProbMetric: 4.1439

Epoch 57: val_loss did not improve from 4.13471
196/196 - 11s - loss: 4.1514 - MinusLogProbMetric: 4.1514 - val_loss: 4.1439 - val_MinusLogProbMetric: 4.1439 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 58/1000
2023-09-12 03:29:50.466 
Epoch 58/1000 
	 loss: 4.1500, MinusLogProbMetric: 4.1500, val_loss: 4.1557, val_MinusLogProbMetric: 4.1557

Epoch 58: val_loss did not improve from 4.13471
196/196 - 11s - loss: 4.1500 - MinusLogProbMetric: 4.1500 - val_loss: 4.1557 - val_MinusLogProbMetric: 4.1557 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 59/1000
2023-09-12 03:30:02.084 
Epoch 59/1000 
	 loss: 4.1465, MinusLogProbMetric: 4.1465, val_loss: 4.1361, val_MinusLogProbMetric: 4.1361

Epoch 59: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1465 - MinusLogProbMetric: 4.1465 - val_loss: 4.1361 - val_MinusLogProbMetric: 4.1361 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 60/1000
2023-09-12 03:30:13.603 
Epoch 60/1000 
	 loss: 4.1521, MinusLogProbMetric: 4.1521, val_loss: 4.1371, val_MinusLogProbMetric: 4.1371

Epoch 60: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1521 - MinusLogProbMetric: 4.1521 - val_loss: 4.1371 - val_MinusLogProbMetric: 4.1371 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 61/1000
2023-09-12 03:30:25.120 
Epoch 61/1000 
	 loss: 4.1521, MinusLogProbMetric: 4.1521, val_loss: 4.1429, val_MinusLogProbMetric: 4.1429

Epoch 61: val_loss did not improve from 4.13471
196/196 - 12s - loss: 4.1521 - MinusLogProbMetric: 4.1521 - val_loss: 4.1429 - val_MinusLogProbMetric: 4.1429 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 62/1000
2023-09-12 03:30:36.584 
Epoch 62/1000 
	 loss: 4.1453, MinusLogProbMetric: 4.1453, val_loss: 4.1377, val_MinusLogProbMetric: 4.1377

Epoch 62: val_loss did not improve from 4.13471
196/196 - 11s - loss: 4.1453 - MinusLogProbMetric: 4.1453 - val_loss: 4.1377 - val_MinusLogProbMetric: 4.1377 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 63/1000
2023-09-12 03:30:48.137 
Epoch 63/1000 
	 loss: 4.1387, MinusLogProbMetric: 4.1387, val_loss: 4.1258, val_MinusLogProbMetric: 4.1258

Epoch 63: val_loss improved from 4.13471 to 4.12580, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1387 - MinusLogProbMetric: 4.1387 - val_loss: 4.1258 - val_MinusLogProbMetric: 4.1258 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-12 03:30:59.809 
Epoch 64/1000 
	 loss: 4.1483, MinusLogProbMetric: 4.1483, val_loss: 4.1626, val_MinusLogProbMetric: 4.1626

Epoch 64: val_loss did not improve from 4.12580
196/196 - 12s - loss: 4.1483 - MinusLogProbMetric: 4.1483 - val_loss: 4.1626 - val_MinusLogProbMetric: 4.1626 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 65/1000
2023-09-12 03:31:11.366 
Epoch 65/1000 
	 loss: 4.1384, MinusLogProbMetric: 4.1384, val_loss: 4.1474, val_MinusLogProbMetric: 4.1474

Epoch 65: val_loss did not improve from 4.12580
196/196 - 12s - loss: 4.1384 - MinusLogProbMetric: 4.1384 - val_loss: 4.1474 - val_MinusLogProbMetric: 4.1474 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 66/1000
2023-09-12 03:31:22.945 
Epoch 66/1000 
	 loss: 4.1424, MinusLogProbMetric: 4.1424, val_loss: 4.1651, val_MinusLogProbMetric: 4.1651

Epoch 66: val_loss did not improve from 4.12580
196/196 - 12s - loss: 4.1424 - MinusLogProbMetric: 4.1424 - val_loss: 4.1651 - val_MinusLogProbMetric: 4.1651 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-12 03:31:34.359 
Epoch 67/1000 
	 loss: 4.1398, MinusLogProbMetric: 4.1398, val_loss: 4.1300, val_MinusLogProbMetric: 4.1300

Epoch 67: val_loss did not improve from 4.12580
196/196 - 11s - loss: 4.1398 - MinusLogProbMetric: 4.1398 - val_loss: 4.1300 - val_MinusLogProbMetric: 4.1300 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 68/1000
2023-09-12 03:31:45.939 
Epoch 68/1000 
	 loss: 4.1349, MinusLogProbMetric: 4.1349, val_loss: 4.1240, val_MinusLogProbMetric: 4.1240

Epoch 68: val_loss improved from 4.12580 to 4.12399, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1349 - MinusLogProbMetric: 4.1349 - val_loss: 4.1240 - val_MinusLogProbMetric: 4.1240 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-12 03:31:57.461 
Epoch 69/1000 
	 loss: 4.1326, MinusLogProbMetric: 4.1326, val_loss: 4.1229, val_MinusLogProbMetric: 4.1229

Epoch 69: val_loss improved from 4.12399 to 4.12287, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1326 - MinusLogProbMetric: 4.1326 - val_loss: 4.1229 - val_MinusLogProbMetric: 4.1229 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 70/1000
2023-09-12 03:32:08.781 
Epoch 70/1000 
	 loss: 4.1373, MinusLogProbMetric: 4.1373, val_loss: 4.1200, val_MinusLogProbMetric: 4.1200

Epoch 70: val_loss improved from 4.12287 to 4.12001, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 11s - loss: 4.1373 - MinusLogProbMetric: 4.1373 - val_loss: 4.1200 - val_MinusLogProbMetric: 4.1200 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 71/1000
2023-09-12 03:32:19.666 
Epoch 71/1000 
	 loss: 4.1401, MinusLogProbMetric: 4.1401, val_loss: 4.1542, val_MinusLogProbMetric: 4.1542

Epoch 71: val_loss did not improve from 4.12001
196/196 - 11s - loss: 4.1401 - MinusLogProbMetric: 4.1401 - val_loss: 4.1542 - val_MinusLogProbMetric: 4.1542 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 72/1000
2023-09-12 03:32:30.842 
Epoch 72/1000 
	 loss: 4.1391, MinusLogProbMetric: 4.1391, val_loss: 4.1450, val_MinusLogProbMetric: 4.1450

Epoch 72: val_loss did not improve from 4.12001
196/196 - 11s - loss: 4.1391 - MinusLogProbMetric: 4.1391 - val_loss: 4.1450 - val_MinusLogProbMetric: 4.1450 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 73/1000
2023-09-12 03:32:41.217 
Epoch 73/1000 
	 loss: 4.1340, MinusLogProbMetric: 4.1340, val_loss: 4.1272, val_MinusLogProbMetric: 4.1272

Epoch 73: val_loss did not improve from 4.12001
196/196 - 10s - loss: 4.1340 - MinusLogProbMetric: 4.1340 - val_loss: 4.1272 - val_MinusLogProbMetric: 4.1272 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 74/1000
2023-09-12 03:32:52.427 
Epoch 74/1000 
	 loss: 4.1402, MinusLogProbMetric: 4.1402, val_loss: 4.1523, val_MinusLogProbMetric: 4.1523

Epoch 74: val_loss did not improve from 4.12001
196/196 - 11s - loss: 4.1402 - MinusLogProbMetric: 4.1402 - val_loss: 4.1523 - val_MinusLogProbMetric: 4.1523 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 75/1000
2023-09-12 03:33:03.882 
Epoch 75/1000 
	 loss: 4.1559, MinusLogProbMetric: 4.1559, val_loss: 4.1497, val_MinusLogProbMetric: 4.1497

Epoch 75: val_loss did not improve from 4.12001
196/196 - 11s - loss: 4.1559 - MinusLogProbMetric: 4.1559 - val_loss: 4.1497 - val_MinusLogProbMetric: 4.1497 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 76/1000
2023-09-12 03:33:15.361 
Epoch 76/1000 
	 loss: 4.1378, MinusLogProbMetric: 4.1378, val_loss: 4.1231, val_MinusLogProbMetric: 4.1231

Epoch 76: val_loss did not improve from 4.12001
196/196 - 11s - loss: 4.1378 - MinusLogProbMetric: 4.1378 - val_loss: 4.1231 - val_MinusLogProbMetric: 4.1231 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 77/1000
2023-09-12 03:33:26.907 
Epoch 77/1000 
	 loss: 4.1298, MinusLogProbMetric: 4.1298, val_loss: 4.1150, val_MinusLogProbMetric: 4.1150

Epoch 77: val_loss improved from 4.12001 to 4.11496, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1298 - MinusLogProbMetric: 4.1298 - val_loss: 4.1150 - val_MinusLogProbMetric: 4.1150 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-12 03:33:38.489 
Epoch 78/1000 
	 loss: 4.1247, MinusLogProbMetric: 4.1247, val_loss: 4.1146, val_MinusLogProbMetric: 4.1146

Epoch 78: val_loss improved from 4.11496 to 4.11460, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1247 - MinusLogProbMetric: 4.1247 - val_loss: 4.1146 - val_MinusLogProbMetric: 4.1146 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 79/1000
2023-09-12 03:33:50.037 
Epoch 79/1000 
	 loss: 4.1270, MinusLogProbMetric: 4.1270, val_loss: 4.1532, val_MinusLogProbMetric: 4.1532

Epoch 79: val_loss did not improve from 4.11460
196/196 - 11s - loss: 4.1270 - MinusLogProbMetric: 4.1270 - val_loss: 4.1532 - val_MinusLogProbMetric: 4.1532 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 80/1000
2023-09-12 03:34:01.537 
Epoch 80/1000 
	 loss: 4.1308, MinusLogProbMetric: 4.1308, val_loss: 4.1774, val_MinusLogProbMetric: 4.1774

Epoch 80: val_loss did not improve from 4.11460
196/196 - 11s - loss: 4.1308 - MinusLogProbMetric: 4.1308 - val_loss: 4.1774 - val_MinusLogProbMetric: 4.1774 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 81/1000
2023-09-12 03:34:13.029 
Epoch 81/1000 
	 loss: 4.1322, MinusLogProbMetric: 4.1322, val_loss: 4.1381, val_MinusLogProbMetric: 4.1381

Epoch 81: val_loss did not improve from 4.11460
196/196 - 11s - loss: 4.1322 - MinusLogProbMetric: 4.1322 - val_loss: 4.1381 - val_MinusLogProbMetric: 4.1381 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 82/1000
2023-09-12 03:34:24.507 
Epoch 82/1000 
	 loss: 4.1324, MinusLogProbMetric: 4.1324, val_loss: 4.1443, val_MinusLogProbMetric: 4.1443

Epoch 82: val_loss did not improve from 4.11460
196/196 - 11s - loss: 4.1324 - MinusLogProbMetric: 4.1324 - val_loss: 4.1443 - val_MinusLogProbMetric: 4.1443 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 83/1000
2023-09-12 03:34:35.878 
Epoch 83/1000 
	 loss: 4.1299, MinusLogProbMetric: 4.1299, val_loss: 4.1494, val_MinusLogProbMetric: 4.1494

Epoch 83: val_loss did not improve from 4.11460
196/196 - 11s - loss: 4.1299 - MinusLogProbMetric: 4.1299 - val_loss: 4.1494 - val_MinusLogProbMetric: 4.1494 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 84/1000
2023-09-12 03:34:47.470 
Epoch 84/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.1173, val_MinusLogProbMetric: 4.1173

Epoch 84: val_loss did not improve from 4.11460
196/196 - 12s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.1173 - val_MinusLogProbMetric: 4.1173 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 85/1000
2023-09-12 03:34:58.929 
Epoch 85/1000 
	 loss: 4.1311, MinusLogProbMetric: 4.1311, val_loss: 4.1391, val_MinusLogProbMetric: 4.1391

Epoch 85: val_loss did not improve from 4.11460
196/196 - 11s - loss: 4.1311 - MinusLogProbMetric: 4.1311 - val_loss: 4.1391 - val_MinusLogProbMetric: 4.1391 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 86/1000
2023-09-12 03:35:10.381 
Epoch 86/1000 
	 loss: 4.1323, MinusLogProbMetric: 4.1323, val_loss: 4.1541, val_MinusLogProbMetric: 4.1541

Epoch 86: val_loss did not improve from 4.11460
196/196 - 11s - loss: 4.1323 - MinusLogProbMetric: 4.1323 - val_loss: 4.1541 - val_MinusLogProbMetric: 4.1541 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 87/1000
2023-09-12 03:35:21.809 
Epoch 87/1000 
	 loss: 4.1263, MinusLogProbMetric: 4.1263, val_loss: 4.1054, val_MinusLogProbMetric: 4.1054

Epoch 87: val_loss improved from 4.11460 to 4.10544, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1263 - MinusLogProbMetric: 4.1263 - val_loss: 4.1054 - val_MinusLogProbMetric: 4.1054 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-12 03:35:33.477 
Epoch 88/1000 
	 loss: 4.1254, MinusLogProbMetric: 4.1254, val_loss: 4.1287, val_MinusLogProbMetric: 4.1287

Epoch 88: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1254 - MinusLogProbMetric: 4.1254 - val_loss: 4.1287 - val_MinusLogProbMetric: 4.1287 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-12 03:35:44.887 
Epoch 89/1000 
	 loss: 4.1290, MinusLogProbMetric: 4.1290, val_loss: 4.1299, val_MinusLogProbMetric: 4.1299

Epoch 89: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1290 - MinusLogProbMetric: 4.1290 - val_loss: 4.1299 - val_MinusLogProbMetric: 4.1299 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 90/1000
2023-09-12 03:35:56.387 
Epoch 90/1000 
	 loss: 4.1297, MinusLogProbMetric: 4.1297, val_loss: 4.1351, val_MinusLogProbMetric: 4.1351

Epoch 90: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1297 - MinusLogProbMetric: 4.1297 - val_loss: 4.1351 - val_MinusLogProbMetric: 4.1351 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 91/1000
2023-09-12 03:36:07.850 
Epoch 91/1000 
	 loss: 4.1307, MinusLogProbMetric: 4.1307, val_loss: 4.1332, val_MinusLogProbMetric: 4.1332

Epoch 91: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1307 - MinusLogProbMetric: 4.1307 - val_loss: 4.1332 - val_MinusLogProbMetric: 4.1332 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 92/1000
2023-09-12 03:36:19.415 
Epoch 92/1000 
	 loss: 4.1268, MinusLogProbMetric: 4.1268, val_loss: 4.1869, val_MinusLogProbMetric: 4.1869

Epoch 92: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1268 - MinusLogProbMetric: 4.1268 - val_loss: 4.1869 - val_MinusLogProbMetric: 4.1869 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 93/1000
2023-09-12 03:36:30.890 
Epoch 93/1000 
	 loss: 4.1306, MinusLogProbMetric: 4.1306, val_loss: 4.1173, val_MinusLogProbMetric: 4.1173

Epoch 93: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1306 - MinusLogProbMetric: 4.1306 - val_loss: 4.1173 - val_MinusLogProbMetric: 4.1173 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 94/1000
2023-09-12 03:36:42.293 
Epoch 94/1000 
	 loss: 4.1237, MinusLogProbMetric: 4.1237, val_loss: 4.1199, val_MinusLogProbMetric: 4.1199

Epoch 94: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1237 - MinusLogProbMetric: 4.1237 - val_loss: 4.1199 - val_MinusLogProbMetric: 4.1199 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 95/1000
2023-09-12 03:36:53.791 
Epoch 95/1000 
	 loss: 4.1296, MinusLogProbMetric: 4.1296, val_loss: 4.1408, val_MinusLogProbMetric: 4.1408

Epoch 95: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1296 - MinusLogProbMetric: 4.1296 - val_loss: 4.1408 - val_MinusLogProbMetric: 4.1408 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 96/1000
2023-09-12 03:37:05.216 
Epoch 96/1000 
	 loss: 4.1296, MinusLogProbMetric: 4.1296, val_loss: 4.1075, val_MinusLogProbMetric: 4.1075

Epoch 96: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1296 - MinusLogProbMetric: 4.1296 - val_loss: 4.1075 - val_MinusLogProbMetric: 4.1075 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 97/1000
2023-09-12 03:37:16.911 
Epoch 97/1000 
	 loss: 4.1246, MinusLogProbMetric: 4.1246, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 97: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1246 - MinusLogProbMetric: 4.1246 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 98/1000
2023-09-12 03:37:28.315 
Epoch 98/1000 
	 loss: 4.1300, MinusLogProbMetric: 4.1300, val_loss: 4.1443, val_MinusLogProbMetric: 4.1443

Epoch 98: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1300 - MinusLogProbMetric: 4.1300 - val_loss: 4.1443 - val_MinusLogProbMetric: 4.1443 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 99/1000
2023-09-12 03:37:39.881 
Epoch 99/1000 
	 loss: 4.1259, MinusLogProbMetric: 4.1259, val_loss: 4.1092, val_MinusLogProbMetric: 4.1092

Epoch 99: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1259 - MinusLogProbMetric: 4.1259 - val_loss: 4.1092 - val_MinusLogProbMetric: 4.1092 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 03:37:51.426 
Epoch 100/1000 
	 loss: 4.1295, MinusLogProbMetric: 4.1295, val_loss: 4.2047, val_MinusLogProbMetric: 4.2047

Epoch 100: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1295 - MinusLogProbMetric: 4.1295 - val_loss: 4.2047 - val_MinusLogProbMetric: 4.2047 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 101/1000
2023-09-12 03:38:02.929 
Epoch 101/1000 
	 loss: 4.1245, MinusLogProbMetric: 4.1245, val_loss: 4.4338, val_MinusLogProbMetric: 4.4338

Epoch 101: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1245 - MinusLogProbMetric: 4.1245 - val_loss: 4.4338 - val_MinusLogProbMetric: 4.4338 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 102/1000
2023-09-12 03:38:14.391 
Epoch 102/1000 
	 loss: 4.1618, MinusLogProbMetric: 4.1618, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 102: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1618 - MinusLogProbMetric: 4.1618 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 103/1000
2023-09-12 03:38:25.857 
Epoch 103/1000 
	 loss: 4.1208, MinusLogProbMetric: 4.1208, val_loss: 4.1258, val_MinusLogProbMetric: 4.1258

Epoch 103: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1208 - MinusLogProbMetric: 4.1208 - val_loss: 4.1258 - val_MinusLogProbMetric: 4.1258 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 104/1000
2023-09-12 03:38:36.379 
Epoch 104/1000 
	 loss: 4.1166, MinusLogProbMetric: 4.1166, val_loss: 4.1501, val_MinusLogProbMetric: 4.1501

Epoch 104: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1166 - MinusLogProbMetric: 4.1166 - val_loss: 4.1501 - val_MinusLogProbMetric: 4.1501 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 105/1000
2023-09-12 03:38:45.949 
Epoch 105/1000 
	 loss: 4.1172, MinusLogProbMetric: 4.1172, val_loss: 4.1091, val_MinusLogProbMetric: 4.1091

Epoch 105: val_loss did not improve from 4.10544
196/196 - 10s - loss: 4.1172 - MinusLogProbMetric: 4.1172 - val_loss: 4.1091 - val_MinusLogProbMetric: 4.1091 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 106/1000
2023-09-12 03:38:56.951 
Epoch 106/1000 
	 loss: 4.1267, MinusLogProbMetric: 4.1267, val_loss: 4.1501, val_MinusLogProbMetric: 4.1501

Epoch 106: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1267 - MinusLogProbMetric: 4.1267 - val_loss: 4.1501 - val_MinusLogProbMetric: 4.1501 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 107/1000
2023-09-12 03:39:08.360 
Epoch 107/1000 
	 loss: 4.1386, MinusLogProbMetric: 4.1386, val_loss: 4.1364, val_MinusLogProbMetric: 4.1364

Epoch 107: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1386 - MinusLogProbMetric: 4.1386 - val_loss: 4.1364 - val_MinusLogProbMetric: 4.1364 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 108/1000
2023-09-12 03:39:19.838 
Epoch 108/1000 
	 loss: 4.1192, MinusLogProbMetric: 4.1192, val_loss: 4.1234, val_MinusLogProbMetric: 4.1234

Epoch 108: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1192 - MinusLogProbMetric: 4.1192 - val_loss: 4.1234 - val_MinusLogProbMetric: 4.1234 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 109/1000
2023-09-12 03:39:31.269 
Epoch 109/1000 
	 loss: 4.1267, MinusLogProbMetric: 4.1267, val_loss: 4.1408, val_MinusLogProbMetric: 4.1408

Epoch 109: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1267 - MinusLogProbMetric: 4.1267 - val_loss: 4.1408 - val_MinusLogProbMetric: 4.1408 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 03:39:42.775 
Epoch 110/1000 
	 loss: 4.1227, MinusLogProbMetric: 4.1227, val_loss: 4.1327, val_MinusLogProbMetric: 4.1327

Epoch 110: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1227 - MinusLogProbMetric: 4.1227 - val_loss: 4.1327 - val_MinusLogProbMetric: 4.1327 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 111/1000
2023-09-12 03:39:54.210 
Epoch 111/1000 
	 loss: 4.1178, MinusLogProbMetric: 4.1178, val_loss: 4.1211, val_MinusLogProbMetric: 4.1211

Epoch 111: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1178 - MinusLogProbMetric: 4.1178 - val_loss: 4.1211 - val_MinusLogProbMetric: 4.1211 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 112/1000
2023-09-12 03:40:05.672 
Epoch 112/1000 
	 loss: 4.1718, MinusLogProbMetric: 4.1718, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 112: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1718 - MinusLogProbMetric: 4.1718 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-12 03:40:17.133 
Epoch 113/1000 
	 loss: 4.1223, MinusLogProbMetric: 4.1223, val_loss: 4.1105, val_MinusLogProbMetric: 4.1105

Epoch 113: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1223 - MinusLogProbMetric: 4.1223 - val_loss: 4.1105 - val_MinusLogProbMetric: 4.1105 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 114/1000
2023-09-12 03:40:28.025 
Epoch 114/1000 
	 loss: 4.1192, MinusLogProbMetric: 4.1192, val_loss: 4.1401, val_MinusLogProbMetric: 4.1401

Epoch 114: val_loss did not improve from 4.10544
196/196 - 11s - loss: 4.1192 - MinusLogProbMetric: 4.1192 - val_loss: 4.1401 - val_MinusLogProbMetric: 4.1401 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 115/1000
2023-09-12 03:40:39.534 
Epoch 115/1000 
	 loss: 4.1171, MinusLogProbMetric: 4.1171, val_loss: 4.1101, val_MinusLogProbMetric: 4.1101

Epoch 115: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1171 - MinusLogProbMetric: 4.1171 - val_loss: 4.1101 - val_MinusLogProbMetric: 4.1101 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 116/1000
2023-09-12 03:40:51.200 
Epoch 116/1000 
	 loss: 4.1175, MinusLogProbMetric: 4.1175, val_loss: 4.1438, val_MinusLogProbMetric: 4.1438

Epoch 116: val_loss did not improve from 4.10544
196/196 - 12s - loss: 4.1175 - MinusLogProbMetric: 4.1175 - val_loss: 4.1438 - val_MinusLogProbMetric: 4.1438 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 117/1000
2023-09-12 03:41:02.664 
Epoch 117/1000 
	 loss: 4.1134, MinusLogProbMetric: 4.1134, val_loss: 4.1040, val_MinusLogProbMetric: 4.1040

Epoch 117: val_loss improved from 4.10544 to 4.10396, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1134 - MinusLogProbMetric: 4.1134 - val_loss: 4.1040 - val_MinusLogProbMetric: 4.1040 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 118/1000
2023-09-12 03:41:14.351 
Epoch 118/1000 
	 loss: 4.1136, MinusLogProbMetric: 4.1136, val_loss: 4.1142, val_MinusLogProbMetric: 4.1142

Epoch 118: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1136 - MinusLogProbMetric: 4.1136 - val_loss: 4.1142 - val_MinusLogProbMetric: 4.1142 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-12 03:41:25.791 
Epoch 119/1000 
	 loss: 4.1158, MinusLogProbMetric: 4.1158, val_loss: 4.1629, val_MinusLogProbMetric: 4.1629

Epoch 119: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1158 - MinusLogProbMetric: 4.1158 - val_loss: 4.1629 - val_MinusLogProbMetric: 4.1629 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 120/1000
2023-09-12 03:41:37.299 
Epoch 120/1000 
	 loss: 4.1119, MinusLogProbMetric: 4.1119, val_loss: 4.1223, val_MinusLogProbMetric: 4.1223

Epoch 120: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1119 - MinusLogProbMetric: 4.1119 - val_loss: 4.1223 - val_MinusLogProbMetric: 4.1223 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 121/1000
2023-09-12 03:41:48.819 
Epoch 121/1000 
	 loss: 4.1120, MinusLogProbMetric: 4.1120, val_loss: 4.1235, val_MinusLogProbMetric: 4.1235

Epoch 121: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1120 - MinusLogProbMetric: 4.1120 - val_loss: 4.1235 - val_MinusLogProbMetric: 4.1235 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 122/1000
2023-09-12 03:42:00.300 
Epoch 122/1000 
	 loss: 4.1181, MinusLogProbMetric: 4.1181, val_loss: 4.1328, val_MinusLogProbMetric: 4.1328

Epoch 122: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1181 - MinusLogProbMetric: 4.1181 - val_loss: 4.1328 - val_MinusLogProbMetric: 4.1328 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 123/1000
2023-09-12 03:42:11.735 
Epoch 123/1000 
	 loss: 4.2125, MinusLogProbMetric: 4.2125, val_loss: 4.1261, val_MinusLogProbMetric: 4.1261

Epoch 123: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.2125 - MinusLogProbMetric: 4.2125 - val_loss: 4.1261 - val_MinusLogProbMetric: 4.1261 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 124/1000
2023-09-12 03:42:23.264 
Epoch 124/1000 
	 loss: 4.1221, MinusLogProbMetric: 4.1221, val_loss: 4.1847, val_MinusLogProbMetric: 4.1847

Epoch 124: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1221 - MinusLogProbMetric: 4.1221 - val_loss: 4.1847 - val_MinusLogProbMetric: 4.1847 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 125/1000
2023-09-12 03:42:34.697 
Epoch 125/1000 
	 loss: 4.1168, MinusLogProbMetric: 4.1168, val_loss: 4.1179, val_MinusLogProbMetric: 4.1179

Epoch 125: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1168 - MinusLogProbMetric: 4.1168 - val_loss: 4.1179 - val_MinusLogProbMetric: 4.1179 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 126/1000
2023-09-12 03:42:46.245 
Epoch 126/1000 
	 loss: 4.1218, MinusLogProbMetric: 4.1218, val_loss: 4.1247, val_MinusLogProbMetric: 4.1247

Epoch 126: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1218 - MinusLogProbMetric: 4.1218 - val_loss: 4.1247 - val_MinusLogProbMetric: 4.1247 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 127/1000
2023-09-12 03:42:57.812 
Epoch 127/1000 
	 loss: 4.1150, MinusLogProbMetric: 4.1150, val_loss: 4.1212, val_MinusLogProbMetric: 4.1212

Epoch 127: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1150 - MinusLogProbMetric: 4.1150 - val_loss: 4.1212 - val_MinusLogProbMetric: 4.1212 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 128/1000
2023-09-12 03:43:09.293 
Epoch 128/1000 
	 loss: 4.1150, MinusLogProbMetric: 4.1150, val_loss: 4.1288, val_MinusLogProbMetric: 4.1288

Epoch 128: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1150 - MinusLogProbMetric: 4.1150 - val_loss: 4.1288 - val_MinusLogProbMetric: 4.1288 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 129/1000
2023-09-12 03:43:20.804 
Epoch 129/1000 
	 loss: 4.1177, MinusLogProbMetric: 4.1177, val_loss: 4.1415, val_MinusLogProbMetric: 4.1415

Epoch 129: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1177 - MinusLogProbMetric: 4.1177 - val_loss: 4.1415 - val_MinusLogProbMetric: 4.1415 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 130/1000
2023-09-12 03:43:32.339 
Epoch 130/1000 
	 loss: 4.1232, MinusLogProbMetric: 4.1232, val_loss: 4.1164, val_MinusLogProbMetric: 4.1164

Epoch 130: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1232 - MinusLogProbMetric: 4.1232 - val_loss: 4.1164 - val_MinusLogProbMetric: 4.1164 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 131/1000
2023-09-12 03:43:43.831 
Epoch 131/1000 
	 loss: 4.1103, MinusLogProbMetric: 4.1103, val_loss: 4.1399, val_MinusLogProbMetric: 4.1399

Epoch 131: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1103 - MinusLogProbMetric: 4.1103 - val_loss: 4.1399 - val_MinusLogProbMetric: 4.1399 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 132/1000
2023-09-12 03:43:55.266 
Epoch 132/1000 
	 loss: 4.1117, MinusLogProbMetric: 4.1117, val_loss: 4.1116, val_MinusLogProbMetric: 4.1116

Epoch 132: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1117 - MinusLogProbMetric: 4.1117 - val_loss: 4.1116 - val_MinusLogProbMetric: 4.1116 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 133/1000
2023-09-12 03:44:06.728 
Epoch 133/1000 
	 loss: 4.1134, MinusLogProbMetric: 4.1134, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 133: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1134 - MinusLogProbMetric: 4.1134 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 134/1000
2023-09-12 03:44:18.326 
Epoch 134/1000 
	 loss: 4.1100, MinusLogProbMetric: 4.1100, val_loss: 4.1104, val_MinusLogProbMetric: 4.1104

Epoch 134: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1100 - MinusLogProbMetric: 4.1100 - val_loss: 4.1104 - val_MinusLogProbMetric: 4.1104 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 135/1000
2023-09-12 03:44:29.738 
Epoch 135/1000 
	 loss: 4.1141, MinusLogProbMetric: 4.1141, val_loss: 4.4146, val_MinusLogProbMetric: 4.4146

Epoch 135: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1141 - MinusLogProbMetric: 4.1141 - val_loss: 4.4146 - val_MinusLogProbMetric: 4.4146 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 136/1000
2023-09-12 03:44:41.313 
Epoch 136/1000 
	 loss: 4.3423, MinusLogProbMetric: 4.3423, val_loss: 4.1275, val_MinusLogProbMetric: 4.1275

Epoch 136: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.3423 - MinusLogProbMetric: 4.3423 - val_loss: 4.1275 - val_MinusLogProbMetric: 4.1275 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 137/1000
2023-09-12 03:44:52.443 
Epoch 137/1000 
	 loss: 4.1267, MinusLogProbMetric: 4.1267, val_loss: 4.1119, val_MinusLogProbMetric: 4.1119

Epoch 137: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1267 - MinusLogProbMetric: 4.1267 - val_loss: 4.1119 - val_MinusLogProbMetric: 4.1119 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 138/1000
2023-09-12 03:45:03.645 
Epoch 138/1000 
	 loss: 4.1204, MinusLogProbMetric: 4.1204, val_loss: 4.1226, val_MinusLogProbMetric: 4.1226

Epoch 138: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1204 - MinusLogProbMetric: 4.1204 - val_loss: 4.1226 - val_MinusLogProbMetric: 4.1226 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 139/1000
2023-09-12 03:45:14.805 
Epoch 139/1000 
	 loss: 4.1151, MinusLogProbMetric: 4.1151, val_loss: 4.1207, val_MinusLogProbMetric: 4.1207

Epoch 139: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1151 - MinusLogProbMetric: 4.1151 - val_loss: 4.1207 - val_MinusLogProbMetric: 4.1207 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 140/1000
2023-09-12 03:45:25.881 
Epoch 140/1000 
	 loss: 4.1164, MinusLogProbMetric: 4.1164, val_loss: 4.1369, val_MinusLogProbMetric: 4.1369

Epoch 140: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1164 - MinusLogProbMetric: 4.1164 - val_loss: 4.1369 - val_MinusLogProbMetric: 4.1369 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 141/1000
2023-09-12 03:45:36.943 
Epoch 141/1000 
	 loss: 4.1111, MinusLogProbMetric: 4.1111, val_loss: 4.1338, val_MinusLogProbMetric: 4.1338

Epoch 141: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1111 - MinusLogProbMetric: 4.1111 - val_loss: 4.1338 - val_MinusLogProbMetric: 4.1338 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 142/1000
2023-09-12 03:45:48.024 
Epoch 142/1000 
	 loss: 4.1132, MinusLogProbMetric: 4.1132, val_loss: 4.1219, val_MinusLogProbMetric: 4.1219

Epoch 142: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1132 - MinusLogProbMetric: 4.1132 - val_loss: 4.1219 - val_MinusLogProbMetric: 4.1219 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 143/1000
2023-09-12 03:45:59.158 
Epoch 143/1000 
	 loss: 4.1134, MinusLogProbMetric: 4.1134, val_loss: 4.1075, val_MinusLogProbMetric: 4.1075

Epoch 143: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1134 - MinusLogProbMetric: 4.1134 - val_loss: 4.1075 - val_MinusLogProbMetric: 4.1075 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 144/1000
2023-09-12 03:46:10.413 
Epoch 144/1000 
	 loss: 4.1108, MinusLogProbMetric: 4.1108, val_loss: 4.1311, val_MinusLogProbMetric: 4.1311

Epoch 144: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1108 - MinusLogProbMetric: 4.1108 - val_loss: 4.1311 - val_MinusLogProbMetric: 4.1311 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 145/1000
2023-09-12 03:46:21.632 
Epoch 145/1000 
	 loss: 4.1122, MinusLogProbMetric: 4.1122, val_loss: 4.1335, val_MinusLogProbMetric: 4.1335

Epoch 145: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1122 - MinusLogProbMetric: 4.1122 - val_loss: 4.1335 - val_MinusLogProbMetric: 4.1335 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 146/1000
2023-09-12 03:46:32.783 
Epoch 146/1000 
	 loss: 4.1089, MinusLogProbMetric: 4.1089, val_loss: 4.1207, val_MinusLogProbMetric: 4.1207

Epoch 146: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1089 - MinusLogProbMetric: 4.1089 - val_loss: 4.1207 - val_MinusLogProbMetric: 4.1207 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 147/1000
2023-09-12 03:46:42.303 
Epoch 147/1000 
	 loss: 4.1087, MinusLogProbMetric: 4.1087, val_loss: 4.1482, val_MinusLogProbMetric: 4.1482

Epoch 147: val_loss did not improve from 4.10396
196/196 - 10s - loss: 4.1087 - MinusLogProbMetric: 4.1087 - val_loss: 4.1482 - val_MinusLogProbMetric: 4.1482 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 148/1000
2023-09-12 03:46:53.295 
Epoch 148/1000 
	 loss: 4.1034, MinusLogProbMetric: 4.1034, val_loss: 4.1273, val_MinusLogProbMetric: 4.1273

Epoch 148: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1034 - MinusLogProbMetric: 4.1034 - val_loss: 4.1273 - val_MinusLogProbMetric: 4.1273 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 149/1000
2023-09-12 03:47:04.642 
Epoch 149/1000 
	 loss: 4.1104, MinusLogProbMetric: 4.1104, val_loss: 4.1292, val_MinusLogProbMetric: 4.1292

Epoch 149: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1104 - MinusLogProbMetric: 4.1104 - val_loss: 4.1292 - val_MinusLogProbMetric: 4.1292 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-12 03:47:16.104 
Epoch 150/1000 
	 loss: 4.1085, MinusLogProbMetric: 4.1085, val_loss: 4.1252, val_MinusLogProbMetric: 4.1252

Epoch 150: val_loss did not improve from 4.10396
196/196 - 11s - loss: 4.1085 - MinusLogProbMetric: 4.1085 - val_loss: 4.1252 - val_MinusLogProbMetric: 4.1252 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 151/1000
2023-09-12 03:47:27.651 
Epoch 151/1000 
	 loss: 4.1154, MinusLogProbMetric: 4.1154, val_loss: 4.1218, val_MinusLogProbMetric: 4.1218

Epoch 151: val_loss did not improve from 4.10396
196/196 - 12s - loss: 4.1154 - MinusLogProbMetric: 4.1154 - val_loss: 4.1218 - val_MinusLogProbMetric: 4.1218 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 152/1000
2023-09-12 03:47:39.136 
Epoch 152/1000 
	 loss: 4.1088, MinusLogProbMetric: 4.1088, val_loss: 4.1036, val_MinusLogProbMetric: 4.1036

Epoch 152: val_loss improved from 4.10396 to 4.10359, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1088 - MinusLogProbMetric: 4.1088 - val_loss: 4.1036 - val_MinusLogProbMetric: 4.1036 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-12 03:47:50.821 
Epoch 153/1000 
	 loss: 4.1049, MinusLogProbMetric: 4.1049, val_loss: 4.1266, val_MinusLogProbMetric: 4.1266

Epoch 153: val_loss did not improve from 4.10359
196/196 - 11s - loss: 4.1049 - MinusLogProbMetric: 4.1049 - val_loss: 4.1266 - val_MinusLogProbMetric: 4.1266 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 154/1000
2023-09-12 03:48:02.337 
Epoch 154/1000 
	 loss: 4.1061, MinusLogProbMetric: 4.1061, val_loss: 4.1068, val_MinusLogProbMetric: 4.1068

Epoch 154: val_loss did not improve from 4.10359
196/196 - 12s - loss: 4.1061 - MinusLogProbMetric: 4.1061 - val_loss: 4.1068 - val_MinusLogProbMetric: 4.1068 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 155/1000
2023-09-12 03:48:13.879 
Epoch 155/1000 
	 loss: 4.1083, MinusLogProbMetric: 4.1083, val_loss: 4.1017, val_MinusLogProbMetric: 4.1017

Epoch 155: val_loss improved from 4.10359 to 4.10171, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1083 - MinusLogProbMetric: 4.1083 - val_loss: 4.1017 - val_MinusLogProbMetric: 4.1017 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 156/1000
2023-09-12 03:48:25.511 
Epoch 156/1000 
	 loss: 4.1026, MinusLogProbMetric: 4.1026, val_loss: 4.1017, val_MinusLogProbMetric: 4.1017

Epoch 156: val_loss improved from 4.10171 to 4.10171, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_60/weights/best_weights.h5
196/196 - 12s - loss: 4.1026 - MinusLogProbMetric: 4.1026 - val_loss: 4.1017 - val_MinusLogProbMetric: 4.1017 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 157/1000
2023-09-12 03:48:37.036 
Epoch 157/1000 
	 loss: 4.1092, MinusLogProbMetric: 4.1092, val_loss: 4.1152, val_MinusLogProbMetric: 4.1152

Epoch 157: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1092 - MinusLogProbMetric: 4.1092 - val_loss: 4.1152 - val_MinusLogProbMetric: 4.1152 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 158/1000
2023-09-12 03:48:48.494 
Epoch 158/1000 
	 loss: 4.1089, MinusLogProbMetric: 4.1089, val_loss: 4.1133, val_MinusLogProbMetric: 4.1133

Epoch 158: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1089 - MinusLogProbMetric: 4.1089 - val_loss: 4.1133 - val_MinusLogProbMetric: 4.1133 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 159/1000
2023-09-12 03:48:59.929 
Epoch 159/1000 
	 loss: 4.1087, MinusLogProbMetric: 4.1087, val_loss: 4.1251, val_MinusLogProbMetric: 4.1251

Epoch 159: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1087 - MinusLogProbMetric: 4.1087 - val_loss: 4.1251 - val_MinusLogProbMetric: 4.1251 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 160/1000
2023-09-12 03:49:11.513 
Epoch 160/1000 
	 loss: 4.1069, MinusLogProbMetric: 4.1069, val_loss: 4.1311, val_MinusLogProbMetric: 4.1311

Epoch 160: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1069 - MinusLogProbMetric: 4.1069 - val_loss: 4.1311 - val_MinusLogProbMetric: 4.1311 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 161/1000
2023-09-12 03:49:22.986 
Epoch 161/1000 
	 loss: 4.1086, MinusLogProbMetric: 4.1086, val_loss: 4.1079, val_MinusLogProbMetric: 4.1079

Epoch 161: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1086 - MinusLogProbMetric: 4.1086 - val_loss: 4.1079 - val_MinusLogProbMetric: 4.1079 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 162/1000
2023-09-12 03:49:34.434 
Epoch 162/1000 
	 loss: 4.1107, MinusLogProbMetric: 4.1107, val_loss: 4.1166, val_MinusLogProbMetric: 4.1166

Epoch 162: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1107 - MinusLogProbMetric: 4.1107 - val_loss: 4.1166 - val_MinusLogProbMetric: 4.1166 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 163/1000
2023-09-12 03:49:45.806 
Epoch 163/1000 
	 loss: 4.1045, MinusLogProbMetric: 4.1045, val_loss: 4.1608, val_MinusLogProbMetric: 4.1608

Epoch 163: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1045 - MinusLogProbMetric: 4.1045 - val_loss: 4.1608 - val_MinusLogProbMetric: 4.1608 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 164/1000
2023-09-12 03:49:57.403 
Epoch 164/1000 
	 loss: 4.1094, MinusLogProbMetric: 4.1094, val_loss: 4.1206, val_MinusLogProbMetric: 4.1206

Epoch 164: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1094 - MinusLogProbMetric: 4.1094 - val_loss: 4.1206 - val_MinusLogProbMetric: 4.1206 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-12 03:50:08.969 
Epoch 165/1000 
	 loss: 4.1072, MinusLogProbMetric: 4.1072, val_loss: 4.1057, val_MinusLogProbMetric: 4.1057

Epoch 165: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1072 - MinusLogProbMetric: 4.1072 - val_loss: 4.1057 - val_MinusLogProbMetric: 4.1057 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 166/1000
2023-09-12 03:50:20.516 
Epoch 166/1000 
	 loss: 4.1071, MinusLogProbMetric: 4.1071, val_loss: 4.1520, val_MinusLogProbMetric: 4.1520

Epoch 166: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1071 - MinusLogProbMetric: 4.1071 - val_loss: 4.1520 - val_MinusLogProbMetric: 4.1520 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-12 03:50:32.076 
Epoch 167/1000 
	 loss: 4.1064, MinusLogProbMetric: 4.1064, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 167: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1064 - MinusLogProbMetric: 4.1064 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 168/1000
2023-09-12 03:50:43.626 
Epoch 168/1000 
	 loss: 4.1019, MinusLogProbMetric: 4.1019, val_loss: 4.1147, val_MinusLogProbMetric: 4.1147

Epoch 168: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1019 - MinusLogProbMetric: 4.1019 - val_loss: 4.1147 - val_MinusLogProbMetric: 4.1147 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 169/1000
2023-09-12 03:50:55.034 
Epoch 169/1000 
	 loss: 4.1006, MinusLogProbMetric: 4.1006, val_loss: 4.1156, val_MinusLogProbMetric: 4.1156

Epoch 169: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1006 - MinusLogProbMetric: 4.1006 - val_loss: 4.1156 - val_MinusLogProbMetric: 4.1156 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 170/1000
2023-09-12 03:51:06.711 
Epoch 170/1000 
	 loss: 4.1018, MinusLogProbMetric: 4.1018, val_loss: 4.1539, val_MinusLogProbMetric: 4.1539

Epoch 170: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1018 - MinusLogProbMetric: 4.1018 - val_loss: 4.1539 - val_MinusLogProbMetric: 4.1539 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 171/1000
2023-09-12 03:51:18.206 
Epoch 171/1000 
	 loss: 4.1028, MinusLogProbMetric: 4.1028, val_loss: 4.1288, val_MinusLogProbMetric: 4.1288

Epoch 171: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1028 - MinusLogProbMetric: 4.1028 - val_loss: 4.1288 - val_MinusLogProbMetric: 4.1288 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 172/1000
2023-09-12 03:51:29.702 
Epoch 172/1000 
	 loss: 4.1060, MinusLogProbMetric: 4.1060, val_loss: 4.1199, val_MinusLogProbMetric: 4.1199

Epoch 172: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1060 - MinusLogProbMetric: 4.1060 - val_loss: 4.1199 - val_MinusLogProbMetric: 4.1199 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 03:51:41.190 
Epoch 173/1000 
	 loss: 4.1031, MinusLogProbMetric: 4.1031, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 173: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1031 - MinusLogProbMetric: 4.1031 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 174/1000
2023-09-12 03:51:52.681 
Epoch 174/1000 
	 loss: 4.1034, MinusLogProbMetric: 4.1034, val_loss: 4.1162, val_MinusLogProbMetric: 4.1162

Epoch 174: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1034 - MinusLogProbMetric: 4.1034 - val_loss: 4.1162 - val_MinusLogProbMetric: 4.1162 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 175/1000
2023-09-12 03:52:04.274 
Epoch 175/1000 
	 loss: 4.1056, MinusLogProbMetric: 4.1056, val_loss: 4.1301, val_MinusLogProbMetric: 4.1301

Epoch 175: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1056 - MinusLogProbMetric: 4.1056 - val_loss: 4.1301 - val_MinusLogProbMetric: 4.1301 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-12 03:52:15.725 
Epoch 176/1000 
	 loss: 4.1074, MinusLogProbMetric: 4.1074, val_loss: 4.1276, val_MinusLogProbMetric: 4.1276

Epoch 176: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1074 - MinusLogProbMetric: 4.1074 - val_loss: 4.1276 - val_MinusLogProbMetric: 4.1276 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 177/1000
2023-09-12 03:52:27.241 
Epoch 177/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.1162, val_MinusLogProbMetric: 4.1162

Epoch 177: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.1162 - val_MinusLogProbMetric: 4.1162 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 178/1000
2023-09-12 03:52:38.699 
Epoch 178/1000 
	 loss: 4.1005, MinusLogProbMetric: 4.1005, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 178: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1005 - MinusLogProbMetric: 4.1005 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 179/1000
2023-09-12 03:52:50.051 
Epoch 179/1000 
	 loss: 4.1016, MinusLogProbMetric: 4.1016, val_loss: 4.1189, val_MinusLogProbMetric: 4.1189

Epoch 179: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1016 - MinusLogProbMetric: 4.1016 - val_loss: 4.1189 - val_MinusLogProbMetric: 4.1189 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 180/1000
2023-09-12 03:53:01.374 
Epoch 180/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.1103, val_MinusLogProbMetric: 4.1103

Epoch 180: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.1103 - val_MinusLogProbMetric: 4.1103 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 181/1000
2023-09-12 03:53:12.926 
Epoch 181/1000 
	 loss: 4.1020, MinusLogProbMetric: 4.1020, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 181: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1020 - MinusLogProbMetric: 4.1020 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 182/1000
2023-09-12 03:53:24.516 
Epoch 182/1000 
	 loss: 4.1030, MinusLogProbMetric: 4.1030, val_loss: 4.1158, val_MinusLogProbMetric: 4.1158

Epoch 182: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1030 - MinusLogProbMetric: 4.1030 - val_loss: 4.1158 - val_MinusLogProbMetric: 4.1158 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 183/1000
2023-09-12 03:53:35.985 
Epoch 183/1000 
	 loss: 4.1047, MinusLogProbMetric: 4.1047, val_loss: 4.1231, val_MinusLogProbMetric: 4.1231

Epoch 183: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1047 - MinusLogProbMetric: 4.1047 - val_loss: 4.1231 - val_MinusLogProbMetric: 4.1231 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 184/1000
2023-09-12 03:53:47.495 
Epoch 184/1000 
	 loss: 4.1018, MinusLogProbMetric: 4.1018, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 184: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1018 - MinusLogProbMetric: 4.1018 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 185/1000
2023-09-12 03:53:59.021 
Epoch 185/1000 
	 loss: 4.1012, MinusLogProbMetric: 4.1012, val_loss: 4.1138, val_MinusLogProbMetric: 4.1138

Epoch 185: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1012 - MinusLogProbMetric: 4.1012 - val_loss: 4.1138 - val_MinusLogProbMetric: 4.1138 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 186/1000
2023-09-12 03:54:10.541 
Epoch 186/1000 
	 loss: 4.1929, MinusLogProbMetric: 4.1929, val_loss: 4.3801, val_MinusLogProbMetric: 4.3801

Epoch 186: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1929 - MinusLogProbMetric: 4.1929 - val_loss: 4.3801 - val_MinusLogProbMetric: 4.3801 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 187/1000
2023-09-12 03:54:22.056 
Epoch 187/1000 
	 loss: 4.1391, MinusLogProbMetric: 4.1391, val_loss: 4.1330, val_MinusLogProbMetric: 4.1330

Epoch 187: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1391 - MinusLogProbMetric: 4.1391 - val_loss: 4.1330 - val_MinusLogProbMetric: 4.1330 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 188/1000
2023-09-12 03:54:33.436 
Epoch 188/1000 
	 loss: 4.1084, MinusLogProbMetric: 4.1084, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 188: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1084 - MinusLogProbMetric: 4.1084 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 189/1000
2023-09-12 03:54:44.889 
Epoch 189/1000 
	 loss: 4.1000, MinusLogProbMetric: 4.1000, val_loss: 4.1174, val_MinusLogProbMetric: 4.1174

Epoch 189: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1000 - MinusLogProbMetric: 4.1000 - val_loss: 4.1174 - val_MinusLogProbMetric: 4.1174 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 190/1000
2023-09-12 03:54:56.349 
Epoch 190/1000 
	 loss: 4.0986, MinusLogProbMetric: 4.0986, val_loss: 4.1192, val_MinusLogProbMetric: 4.1192

Epoch 190: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0986 - MinusLogProbMetric: 4.0986 - val_loss: 4.1192 - val_MinusLogProbMetric: 4.1192 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 191/1000
2023-09-12 03:55:07.780 
Epoch 191/1000 
	 loss: 4.0998, MinusLogProbMetric: 4.0998, val_loss: 4.1165, val_MinusLogProbMetric: 4.1165

Epoch 191: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0998 - MinusLogProbMetric: 4.0998 - val_loss: 4.1165 - val_MinusLogProbMetric: 4.1165 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 192/1000
2023-09-12 03:55:19.356 
Epoch 192/1000 
	 loss: 4.1016, MinusLogProbMetric: 4.1016, val_loss: 4.1234, val_MinusLogProbMetric: 4.1234

Epoch 192: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1016 - MinusLogProbMetric: 4.1016 - val_loss: 4.1234 - val_MinusLogProbMetric: 4.1234 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 193/1000
2023-09-12 03:55:30.885 
Epoch 193/1000 
	 loss: 4.0992, MinusLogProbMetric: 4.0992, val_loss: 4.1323, val_MinusLogProbMetric: 4.1323

Epoch 193: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0992 - MinusLogProbMetric: 4.0992 - val_loss: 4.1323 - val_MinusLogProbMetric: 4.1323 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 194/1000
2023-09-12 03:55:42.364 
Epoch 194/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 194: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 195/1000
2023-09-12 03:55:53.836 
Epoch 195/1000 
	 loss: 4.0966, MinusLogProbMetric: 4.0966, val_loss: 4.1054, val_MinusLogProbMetric: 4.1054

Epoch 195: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0966 - MinusLogProbMetric: 4.0966 - val_loss: 4.1054 - val_MinusLogProbMetric: 4.1054 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 196/1000
2023-09-12 03:56:05.212 
Epoch 196/1000 
	 loss: 4.0972, MinusLogProbMetric: 4.0972, val_loss: 4.1193, val_MinusLogProbMetric: 4.1193

Epoch 196: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0972 - MinusLogProbMetric: 4.0972 - val_loss: 4.1193 - val_MinusLogProbMetric: 4.1193 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 197/1000
2023-09-12 03:56:16.509 
Epoch 197/1000 
	 loss: 4.1020, MinusLogProbMetric: 4.1020, val_loss: 4.1198, val_MinusLogProbMetric: 4.1198

Epoch 197: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1020 - MinusLogProbMetric: 4.1020 - val_loss: 4.1198 - val_MinusLogProbMetric: 4.1198 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 198/1000
2023-09-12 03:56:27.925 
Epoch 198/1000 
	 loss: 4.1060, MinusLogProbMetric: 4.1060, val_loss: 4.1181, val_MinusLogProbMetric: 4.1181

Epoch 198: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.1060 - MinusLogProbMetric: 4.1060 - val_loss: 4.1181 - val_MinusLogProbMetric: 4.1181 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 199/1000
2023-09-12 03:56:39.454 
Epoch 199/1000 
	 loss: 4.0993, MinusLogProbMetric: 4.0993, val_loss: 4.1207, val_MinusLogProbMetric: 4.1207

Epoch 199: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0993 - MinusLogProbMetric: 4.0993 - val_loss: 4.1207 - val_MinusLogProbMetric: 4.1207 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 200/1000
2023-09-12 03:56:51.088 
Epoch 200/1000 
	 loss: 4.1037, MinusLogProbMetric: 4.1037, val_loss: 4.1201, val_MinusLogProbMetric: 4.1201

Epoch 200: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1037 - MinusLogProbMetric: 4.1037 - val_loss: 4.1201 - val_MinusLogProbMetric: 4.1201 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 201/1000
2023-09-12 03:57:02.523 
Epoch 201/1000 
	 loss: 4.0976, MinusLogProbMetric: 4.0976, val_loss: 4.1192, val_MinusLogProbMetric: 4.1192

Epoch 201: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0976 - MinusLogProbMetric: 4.0976 - val_loss: 4.1192 - val_MinusLogProbMetric: 4.1192 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 202/1000
2023-09-12 03:57:14.110 
Epoch 202/1000 
	 loss: 4.0971, MinusLogProbMetric: 4.0971, val_loss: 4.1310, val_MinusLogProbMetric: 4.1310

Epoch 202: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0971 - MinusLogProbMetric: 4.0971 - val_loss: 4.1310 - val_MinusLogProbMetric: 4.1310 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 203/1000
2023-09-12 03:57:25.704 
Epoch 203/1000 
	 loss: 4.1008, MinusLogProbMetric: 4.1008, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 203: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.1008 - MinusLogProbMetric: 4.1008 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 204/1000
2023-09-12 03:57:37.251 
Epoch 204/1000 
	 loss: 4.0975, MinusLogProbMetric: 4.0975, val_loss: 4.1111, val_MinusLogProbMetric: 4.1111

Epoch 204: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0975 - MinusLogProbMetric: 4.0975 - val_loss: 4.1111 - val_MinusLogProbMetric: 4.1111 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 205/1000
2023-09-12 03:57:48.674 
Epoch 205/1000 
	 loss: 4.0996, MinusLogProbMetric: 4.0996, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 205: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0996 - MinusLogProbMetric: 4.0996 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-12 03:58:00.231 
Epoch 206/1000 
	 loss: 4.0825, MinusLogProbMetric: 4.0825, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 206: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0825 - MinusLogProbMetric: 4.0825 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-12 03:58:11.811 
Epoch 207/1000 
	 loss: 4.0821, MinusLogProbMetric: 4.0821, val_loss: 4.1046, val_MinusLogProbMetric: 4.1046

Epoch 207: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0821 - MinusLogProbMetric: 4.0821 - val_loss: 4.1046 - val_MinusLogProbMetric: 4.1046 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 208/1000
2023-09-12 03:58:23.238 
Epoch 208/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1069, val_MinusLogProbMetric: 4.1069

Epoch 208: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1069 - val_MinusLogProbMetric: 4.1069 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 209/1000
2023-09-12 03:58:34.755 
Epoch 209/1000 
	 loss: 4.0812, MinusLogProbMetric: 4.0812, val_loss: 4.1110, val_MinusLogProbMetric: 4.1110

Epoch 209: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0812 - MinusLogProbMetric: 4.0812 - val_loss: 4.1110 - val_MinusLogProbMetric: 4.1110 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-12 03:58:46.216 
Epoch 210/1000 
	 loss: 4.0883, MinusLogProbMetric: 4.0883, val_loss: 4.1048, val_MinusLogProbMetric: 4.1048

Epoch 210: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0883 - MinusLogProbMetric: 4.0883 - val_loss: 4.1048 - val_MinusLogProbMetric: 4.1048 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 211/1000
2023-09-12 03:58:57.815 
Epoch 211/1000 
	 loss: 4.0825, MinusLogProbMetric: 4.0825, val_loss: 4.1076, val_MinusLogProbMetric: 4.1076

Epoch 211: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0825 - MinusLogProbMetric: 4.0825 - val_loss: 4.1076 - val_MinusLogProbMetric: 4.1076 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 212/1000
2023-09-12 03:59:09.314 
Epoch 212/1000 
	 loss: 4.0820, MinusLogProbMetric: 4.0820, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 212: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0820 - MinusLogProbMetric: 4.0820 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 213/1000
2023-09-12 03:59:20.785 
Epoch 213/1000 
	 loss: 4.0815, MinusLogProbMetric: 4.0815, val_loss: 4.1042, val_MinusLogProbMetric: 4.1042

Epoch 213: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0815 - MinusLogProbMetric: 4.0815 - val_loss: 4.1042 - val_MinusLogProbMetric: 4.1042 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 214/1000
2023-09-12 03:59:32.488 
Epoch 214/1000 
	 loss: 4.0791, MinusLogProbMetric: 4.0791, val_loss: 4.1178, val_MinusLogProbMetric: 4.1178

Epoch 214: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0791 - MinusLogProbMetric: 4.0791 - val_loss: 4.1178 - val_MinusLogProbMetric: 4.1178 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-12 03:59:43.953 
Epoch 215/1000 
	 loss: 4.0856, MinusLogProbMetric: 4.0856, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 215: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0856 - MinusLogProbMetric: 4.0856 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 216/1000
2023-09-12 03:59:55.526 
Epoch 216/1000 
	 loss: 4.0810, MinusLogProbMetric: 4.0810, val_loss: 4.1157, val_MinusLogProbMetric: 4.1157

Epoch 216: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0810 - MinusLogProbMetric: 4.0810 - val_loss: 4.1157 - val_MinusLogProbMetric: 4.1157 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 217/1000
2023-09-12 04:00:07.059 
Epoch 217/1000 
	 loss: 4.0819, MinusLogProbMetric: 4.0819, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 217: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0819 - MinusLogProbMetric: 4.0819 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 218/1000
2023-09-12 04:00:18.739 
Epoch 218/1000 
	 loss: 4.0841, MinusLogProbMetric: 4.0841, val_loss: 4.1069, val_MinusLogProbMetric: 4.1069

Epoch 218: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0841 - MinusLogProbMetric: 4.0841 - val_loss: 4.1069 - val_MinusLogProbMetric: 4.1069 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-12 04:00:30.287 
Epoch 219/1000 
	 loss: 4.0805, MinusLogProbMetric: 4.0805, val_loss: 4.1158, val_MinusLogProbMetric: 4.1158

Epoch 219: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0805 - MinusLogProbMetric: 4.0805 - val_loss: 4.1158 - val_MinusLogProbMetric: 4.1158 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 220/1000
2023-09-12 04:00:41.729 
Epoch 220/1000 
	 loss: 4.0854, MinusLogProbMetric: 4.0854, val_loss: 4.1203, val_MinusLogProbMetric: 4.1203

Epoch 220: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0854 - MinusLogProbMetric: 4.0854 - val_loss: 4.1203 - val_MinusLogProbMetric: 4.1203 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 221/1000
2023-09-12 04:00:53.244 
Epoch 221/1000 
	 loss: 4.0808, MinusLogProbMetric: 4.0808, val_loss: 4.1066, val_MinusLogProbMetric: 4.1066

Epoch 221: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0808 - MinusLogProbMetric: 4.0808 - val_loss: 4.1066 - val_MinusLogProbMetric: 4.1066 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 222/1000
2023-09-12 04:01:04.802 
Epoch 222/1000 
	 loss: 4.0801, MinusLogProbMetric: 4.0801, val_loss: 4.1146, val_MinusLogProbMetric: 4.1146

Epoch 222: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0801 - MinusLogProbMetric: 4.0801 - val_loss: 4.1146 - val_MinusLogProbMetric: 4.1146 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 223/1000
2023-09-12 04:01:16.299 
Epoch 223/1000 
	 loss: 4.0804, MinusLogProbMetric: 4.0804, val_loss: 4.1687, val_MinusLogProbMetric: 4.1687

Epoch 223: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0804 - MinusLogProbMetric: 4.0804 - val_loss: 4.1687 - val_MinusLogProbMetric: 4.1687 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 224/1000
2023-09-12 04:01:27.833 
Epoch 224/1000 
	 loss: 4.0866, MinusLogProbMetric: 4.0866, val_loss: 4.1079, val_MinusLogProbMetric: 4.1079

Epoch 224: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0866 - MinusLogProbMetric: 4.0866 - val_loss: 4.1079 - val_MinusLogProbMetric: 4.1079 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 225/1000
2023-09-12 04:01:39.286 
Epoch 225/1000 
	 loss: 4.0783, MinusLogProbMetric: 4.0783, val_loss: 4.1053, val_MinusLogProbMetric: 4.1053

Epoch 225: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0783 - MinusLogProbMetric: 4.0783 - val_loss: 4.1053 - val_MinusLogProbMetric: 4.1053 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 226/1000
2023-09-12 04:01:50.732 
Epoch 226/1000 
	 loss: 4.0802, MinusLogProbMetric: 4.0802, val_loss: 4.1116, val_MinusLogProbMetric: 4.1116

Epoch 226: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0802 - MinusLogProbMetric: 4.0802 - val_loss: 4.1116 - val_MinusLogProbMetric: 4.1116 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 227/1000
2023-09-12 04:02:02.149 
Epoch 227/1000 
	 loss: 4.0789, MinusLogProbMetric: 4.0789, val_loss: 4.1137, val_MinusLogProbMetric: 4.1137

Epoch 227: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0789 - MinusLogProbMetric: 4.0789 - val_loss: 4.1137 - val_MinusLogProbMetric: 4.1137 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 228/1000
2023-09-12 04:02:13.537 
Epoch 228/1000 
	 loss: 4.0797, MinusLogProbMetric: 4.0797, val_loss: 4.1140, val_MinusLogProbMetric: 4.1140

Epoch 228: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0797 - MinusLogProbMetric: 4.0797 - val_loss: 4.1140 - val_MinusLogProbMetric: 4.1140 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 229/1000
2023-09-12 04:02:25.096 
Epoch 229/1000 
	 loss: 4.0803, MinusLogProbMetric: 4.0803, val_loss: 4.1132, val_MinusLogProbMetric: 4.1132

Epoch 229: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0803 - MinusLogProbMetric: 4.0803 - val_loss: 4.1132 - val_MinusLogProbMetric: 4.1132 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 230/1000
2023-09-12 04:02:36.648 
Epoch 230/1000 
	 loss: 4.0810, MinusLogProbMetric: 4.0810, val_loss: 4.1093, val_MinusLogProbMetric: 4.1093

Epoch 230: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0810 - MinusLogProbMetric: 4.0810 - val_loss: 4.1093 - val_MinusLogProbMetric: 4.1093 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 231/1000
2023-09-12 04:02:48.122 
Epoch 231/1000 
	 loss: 4.0819, MinusLogProbMetric: 4.0819, val_loss: 4.1200, val_MinusLogProbMetric: 4.1200

Epoch 231: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0819 - MinusLogProbMetric: 4.0819 - val_loss: 4.1200 - val_MinusLogProbMetric: 4.1200 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 232/1000
2023-09-12 04:02:59.596 
Epoch 232/1000 
	 loss: 4.0796, MinusLogProbMetric: 4.0796, val_loss: 4.1100, val_MinusLogProbMetric: 4.1100

Epoch 232: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0796 - MinusLogProbMetric: 4.0796 - val_loss: 4.1100 - val_MinusLogProbMetric: 4.1100 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 233/1000
2023-09-12 04:03:11.112 
Epoch 233/1000 
	 loss: 4.0803, MinusLogProbMetric: 4.0803, val_loss: 4.1145, val_MinusLogProbMetric: 4.1145

Epoch 233: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0803 - MinusLogProbMetric: 4.0803 - val_loss: 4.1145 - val_MinusLogProbMetric: 4.1145 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 234/1000
2023-09-12 04:03:22.617 
Epoch 234/1000 
	 loss: 4.0808, MinusLogProbMetric: 4.0808, val_loss: 4.1215, val_MinusLogProbMetric: 4.1215

Epoch 234: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0808 - MinusLogProbMetric: 4.0808 - val_loss: 4.1215 - val_MinusLogProbMetric: 4.1215 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 235/1000
2023-09-12 04:03:34.123 
Epoch 235/1000 
	 loss: 4.0802, MinusLogProbMetric: 4.0802, val_loss: 4.1172, val_MinusLogProbMetric: 4.1172

Epoch 235: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0802 - MinusLogProbMetric: 4.0802 - val_loss: 4.1172 - val_MinusLogProbMetric: 4.1172 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 236/1000
2023-09-12 04:03:45.667 
Epoch 236/1000 
	 loss: 4.0803, MinusLogProbMetric: 4.0803, val_loss: 4.1085, val_MinusLogProbMetric: 4.1085

Epoch 236: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0803 - MinusLogProbMetric: 4.0803 - val_loss: 4.1085 - val_MinusLogProbMetric: 4.1085 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 237/1000
2023-09-12 04:03:57.195 
Epoch 237/1000 
	 loss: 4.0775, MinusLogProbMetric: 4.0775, val_loss: 4.1142, val_MinusLogProbMetric: 4.1142

Epoch 237: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0775 - MinusLogProbMetric: 4.0775 - val_loss: 4.1142 - val_MinusLogProbMetric: 4.1142 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 238/1000
2023-09-12 04:04:08.774 
Epoch 238/1000 
	 loss: 4.0788, MinusLogProbMetric: 4.0788, val_loss: 4.1133, val_MinusLogProbMetric: 4.1133

Epoch 238: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0788 - MinusLogProbMetric: 4.0788 - val_loss: 4.1133 - val_MinusLogProbMetric: 4.1133 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 239/1000
2023-09-12 04:04:20.191 
Epoch 239/1000 
	 loss: 4.0796, MinusLogProbMetric: 4.0796, val_loss: 4.1181, val_MinusLogProbMetric: 4.1181

Epoch 239: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0796 - MinusLogProbMetric: 4.0796 - val_loss: 4.1181 - val_MinusLogProbMetric: 4.1181 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 240/1000
2023-09-12 04:04:31.792 
Epoch 240/1000 
	 loss: 4.0802, MinusLogProbMetric: 4.0802, val_loss: 4.1229, val_MinusLogProbMetric: 4.1229

Epoch 240: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0802 - MinusLogProbMetric: 4.0802 - val_loss: 4.1229 - val_MinusLogProbMetric: 4.1229 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 241/1000
2023-09-12 04:04:43.339 
Epoch 241/1000 
	 loss: 4.0795, MinusLogProbMetric: 4.0795, val_loss: 4.1261, val_MinusLogProbMetric: 4.1261

Epoch 241: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0795 - MinusLogProbMetric: 4.0795 - val_loss: 4.1261 - val_MinusLogProbMetric: 4.1261 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 242/1000
2023-09-12 04:04:54.828 
Epoch 242/1000 
	 loss: 4.0783, MinusLogProbMetric: 4.0783, val_loss: 4.1119, val_MinusLogProbMetric: 4.1119

Epoch 242: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0783 - MinusLogProbMetric: 4.0783 - val_loss: 4.1119 - val_MinusLogProbMetric: 4.1119 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 243/1000
2023-09-12 04:05:06.227 
Epoch 243/1000 
	 loss: 4.0854, MinusLogProbMetric: 4.0854, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 243: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0854 - MinusLogProbMetric: 4.0854 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 244/1000
2023-09-12 04:05:17.864 
Epoch 244/1000 
	 loss: 4.0771, MinusLogProbMetric: 4.0771, val_loss: 4.1144, val_MinusLogProbMetric: 4.1144

Epoch 244: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0771 - MinusLogProbMetric: 4.0771 - val_loss: 4.1144 - val_MinusLogProbMetric: 4.1144 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 245/1000
2023-09-12 04:05:29.306 
Epoch 245/1000 
	 loss: 4.0803, MinusLogProbMetric: 4.0803, val_loss: 4.1153, val_MinusLogProbMetric: 4.1153

Epoch 245: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0803 - MinusLogProbMetric: 4.0803 - val_loss: 4.1153 - val_MinusLogProbMetric: 4.1153 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 246/1000
2023-09-12 04:05:40.766 
Epoch 246/1000 
	 loss: 4.0794, MinusLogProbMetric: 4.0794, val_loss: 4.1097, val_MinusLogProbMetric: 4.1097

Epoch 246: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0794 - MinusLogProbMetric: 4.0794 - val_loss: 4.1097 - val_MinusLogProbMetric: 4.1097 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 247/1000
2023-09-12 04:05:52.464 
Epoch 247/1000 
	 loss: 4.0834, MinusLogProbMetric: 4.0834, val_loss: 4.1314, val_MinusLogProbMetric: 4.1314

Epoch 247: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0834 - MinusLogProbMetric: 4.0834 - val_loss: 4.1314 - val_MinusLogProbMetric: 4.1314 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-12 04:06:03.872 
Epoch 248/1000 
	 loss: 4.0778, MinusLogProbMetric: 4.0778, val_loss: 4.1125, val_MinusLogProbMetric: 4.1125

Epoch 248: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0778 - MinusLogProbMetric: 4.0778 - val_loss: 4.1125 - val_MinusLogProbMetric: 4.1125 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 249/1000
2023-09-12 04:06:15.467 
Epoch 249/1000 
	 loss: 4.0997, MinusLogProbMetric: 4.0997, val_loss: 4.1168, val_MinusLogProbMetric: 4.1168

Epoch 249: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0997 - MinusLogProbMetric: 4.0997 - val_loss: 4.1168 - val_MinusLogProbMetric: 4.1168 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 250/1000
2023-09-12 04:06:27.217 
Epoch 250/1000 
	 loss: 4.0794, MinusLogProbMetric: 4.0794, val_loss: 4.1228, val_MinusLogProbMetric: 4.1228

Epoch 250: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0794 - MinusLogProbMetric: 4.0794 - val_loss: 4.1228 - val_MinusLogProbMetric: 4.1228 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-12 04:06:38.649 
Epoch 251/1000 
	 loss: 4.0769, MinusLogProbMetric: 4.0769, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 251: val_loss did not improve from 4.10171
196/196 - 11s - loss: 4.0769 - MinusLogProbMetric: 4.0769 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 252/1000
2023-09-12 04:06:50.432 
Epoch 252/1000 
	 loss: 4.0767, MinusLogProbMetric: 4.0767, val_loss: 4.1247, val_MinusLogProbMetric: 4.1247

Epoch 252: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0767 - MinusLogProbMetric: 4.0767 - val_loss: 4.1247 - val_MinusLogProbMetric: 4.1247 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-12 04:07:01.974 
Epoch 253/1000 
	 loss: 4.0770, MinusLogProbMetric: 4.0770, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 253: val_loss did not improve from 4.10171
196/196 - 12s - loss: 4.0770 - MinusLogProbMetric: 4.0770 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 254/1000
2023-09-12 04:07:12.469 
Epoch 254/1000 
	 loss: 4.0785, MinusLogProbMetric: 4.0785, val_loss: 4.1105, val_MinusLogProbMetric: 4.1105

Epoch 254: val_loss did not improve from 4.10171
196/196 - 10s - loss: 4.0785 - MinusLogProbMetric: 4.0785 - val_loss: 4.1105 - val_MinusLogProbMetric: 4.1105 - lr: 5.0000e-04 - 10s/epoch - 54ms/step
Epoch 255/1000
2023-09-12 04:07:22.448 
Epoch 255/1000 
	 loss: 4.0772, MinusLogProbMetric: 4.0772, val_loss: 4.1159, val_MinusLogProbMetric: 4.1159

Epoch 255: val_loss did not improve from 4.10171
Restoring model weights from the end of the best epoch: 155.
196/196 - 10s - loss: 4.0772 - MinusLogProbMetric: 4.0772 - val_loss: 4.1159 - val_MinusLogProbMetric: 4.1159 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 255: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.819275017944165 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.411375679075718 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.9224282129434869 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.1726014990126714 seconds.
Training succeeded with seed 520.
Model trained in 2932.02 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 22.59 s.
Plots done in 10.67 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 33.26 s.
===========
Run 60/360 done in 2966.45 s.
===========

Directory ../../results/MsplineN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

===========
Generating train data for run 67.
===========
Train data generated in 0.31 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_67/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 721}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_67/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 8.804371  ,  3.807026  ,  7.926363  , ...,  8.890652  ,
        -0.01515055,  0.42122346],
       [ 0.19449875,  9.236196  ,  7.1441216 , ...,  8.085008  ,
         4.4651775 ,  7.791838  ],
       [-0.2335621 ,  7.8624144 ,  6.6901736 , ...,  6.2223573 ,
         4.849373  ,  7.7959633 ],
       ...,
       [ 5.4243345 ,  6.841882  ,  6.0056496 , ...,  6.2472315 ,
         4.5194373 ,  8.535404  ],
       [10.215379  ,  3.3462677 ,  7.8975973 , ...,  8.886582  ,
         1.7115161 ,  1.1975231 ],
       [ 5.414481  ,  7.505999  ,  6.109645  , ...,  6.001549  ,
         4.006048  ,  9.525265  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_67/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_67
self.data_kwargs: {'seed': 721}
self.x_data: [[ 5.480023    7.4803424   6.137239   ...  6.604075    4.4518204
   8.41896   ]
 [ 0.08449081  8.2597065   7.795495   ...  7.9264755   4.832592
   7.768828  ]
 [-0.12104045  8.112266    7.4020762  ...  7.9569516   4.728532
   7.827146  ]
 ...
 [ 5.3315587   7.739991    5.999712   ...  6.760911    4.350139
   8.508973  ]
 [ 5.458622    7.204903    5.739224   ...  6.743127    4.4224305
   9.3740425 ]
 [10.526193    4.2140837   7.9248996  ...  9.897478    2.6511695
   1.0296785 ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_25 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_8 (LogProbLa  (None,)                  140592    
 yer)                                                            
                                                                 
=================================================================
Total params: 140,592
Trainable params: 140,592
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_8/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_8'")
self.model: <keras.engine.functional.Functional object at 0x7fc6c47f0fa0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc6c4a2dbd0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc6c4a2dbd0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc6c4ad0730>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc6c4b6c310>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc6c4b6c880>, <keras.callbacks.ModelCheckpoint object at 0x7fc6c4b6c940>, <keras.callbacks.EarlyStopping object at 0x7fc6c4b6cbb0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc6c4b6cbe0>, <keras.callbacks.TerminateOnNaN object at 0x7fc6c4b6c820>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 8.804371  ,  3.807026  ,  7.926363  , ...,  8.890652  ,
        -0.01515055,  0.42122346],
       [ 0.19449875,  9.236196  ,  7.1441216 , ...,  8.085008  ,
         4.4651775 ,  7.791838  ],
       [-0.2335621 ,  7.8624144 ,  6.6901736 , ...,  6.2223573 ,
         4.849373  ,  7.7959633 ],
       ...,
       [ 5.4243345 ,  6.841882  ,  6.0056496 , ...,  6.2472315 ,
         4.5194373 ,  8.535404  ],
       [10.215379  ,  3.3462677 ,  7.8975973 , ...,  8.886582  ,
         1.7115161 ,  1.1975231 ],
       [ 5.414481  ,  7.505999  ,  6.109645  , ...,  6.001549  ,
         4.006048  ,  9.525265  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_67/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 67/360 with hyperparameters:
timestamp = 2023-09-12 04:07:57.171874
ndims = 8
seed_train = 721
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 140592
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.480023  7.4803424 6.137239  5.010707  4.577454  6.604075  4.4518204
 8.41896  ]
Epoch 1/1000
2023-09-12 04:08:28.386 
Epoch 1/1000 
	 loss: 15.7203, MinusLogProbMetric: 15.7203, val_loss: 5.6822, val_MinusLogProbMetric: 5.6822

Epoch 1: val_loss improved from inf to 5.68224, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 31s - loss: 15.7203 - MinusLogProbMetric: 15.7203 - val_loss: 5.6822 - val_MinusLogProbMetric: 5.6822 - lr: 0.0010 - 31s/epoch - 159ms/step
Epoch 2/1000
2023-09-12 04:08:40.116 
Epoch 2/1000 
	 loss: 5.1091, MinusLogProbMetric: 5.1091, val_loss: 4.7762, val_MinusLogProbMetric: 4.7762

Epoch 2: val_loss improved from 5.68224 to 4.77625, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 5.1091 - MinusLogProbMetric: 5.1091 - val_loss: 4.7762 - val_MinusLogProbMetric: 4.7762 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 3/1000
2023-09-12 04:08:51.850 
Epoch 3/1000 
	 loss: 4.6585, MinusLogProbMetric: 4.6585, val_loss: 4.5720, val_MinusLogProbMetric: 4.5720

Epoch 3: val_loss improved from 4.77625 to 4.57198, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.6585 - MinusLogProbMetric: 4.6585 - val_loss: 4.5720 - val_MinusLogProbMetric: 4.5720 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-12 04:09:03.738 
Epoch 4/1000 
	 loss: 4.4606, MinusLogProbMetric: 4.4606, val_loss: 4.4550, val_MinusLogProbMetric: 4.4550

Epoch 4: val_loss improved from 4.57198 to 4.45501, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.4606 - MinusLogProbMetric: 4.4606 - val_loss: 4.4550 - val_MinusLogProbMetric: 4.4550 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 5/1000
2023-09-12 04:09:15.464 
Epoch 5/1000 
	 loss: 4.3540, MinusLogProbMetric: 4.3540, val_loss: 4.3442, val_MinusLogProbMetric: 4.3442

Epoch 5: val_loss improved from 4.45501 to 4.34425, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.3540 - MinusLogProbMetric: 4.3540 - val_loss: 4.3442 - val_MinusLogProbMetric: 4.3442 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 6/1000
2023-09-12 04:09:26.954 
Epoch 6/1000 
	 loss: 4.3423, MinusLogProbMetric: 4.3423, val_loss: 4.5104, val_MinusLogProbMetric: 4.5104

Epoch 6: val_loss did not improve from 4.34425
196/196 - 11s - loss: 4.3423 - MinusLogProbMetric: 4.3423 - val_loss: 4.5104 - val_MinusLogProbMetric: 4.5104 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 7/1000
2023-09-12 04:09:37.032 
Epoch 7/1000 
	 loss: 4.2814, MinusLogProbMetric: 4.2814, val_loss: 4.2652, val_MinusLogProbMetric: 4.2652

Epoch 7: val_loss improved from 4.34425 to 4.26521, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 10s - loss: 4.2814 - MinusLogProbMetric: 4.2814 - val_loss: 4.2652 - val_MinusLogProbMetric: 4.2652 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 8/1000
2023-09-12 04:09:47.151 
Epoch 8/1000 
	 loss: 4.2806, MinusLogProbMetric: 4.2806, val_loss: 4.2464, val_MinusLogProbMetric: 4.2464

Epoch 8: val_loss improved from 4.26521 to 4.24637, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 10s - loss: 4.2806 - MinusLogProbMetric: 4.2806 - val_loss: 4.2464 - val_MinusLogProbMetric: 4.2464 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 9/1000
2023-09-12 04:09:58.114 
Epoch 9/1000 
	 loss: 4.2554, MinusLogProbMetric: 4.2554, val_loss: 4.4278, val_MinusLogProbMetric: 4.4278

Epoch 9: val_loss did not improve from 4.24637
196/196 - 11s - loss: 4.2554 - MinusLogProbMetric: 4.2554 - val_loss: 4.4278 - val_MinusLogProbMetric: 4.4278 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 10/1000
2023-09-12 04:10:09.702 
Epoch 10/1000 
	 loss: 4.2567, MinusLogProbMetric: 4.2567, val_loss: 4.2455, val_MinusLogProbMetric: 4.2455

Epoch 10: val_loss improved from 4.24637 to 4.24548, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.2567 - MinusLogProbMetric: 4.2567 - val_loss: 4.2455 - val_MinusLogProbMetric: 4.2455 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-12 04:10:21.538 
Epoch 11/1000 
	 loss: 4.2361, MinusLogProbMetric: 4.2361, val_loss: 4.2063, val_MinusLogProbMetric: 4.2063

Epoch 11: val_loss improved from 4.24548 to 4.20626, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.2361 - MinusLogProbMetric: 4.2361 - val_loss: 4.2063 - val_MinusLogProbMetric: 4.2063 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-12 04:10:33.325 
Epoch 12/1000 
	 loss: 4.2374, MinusLogProbMetric: 4.2374, val_loss: 4.3529, val_MinusLogProbMetric: 4.3529

Epoch 12: val_loss did not improve from 4.20626
196/196 - 12s - loss: 4.2374 - MinusLogProbMetric: 4.2374 - val_loss: 4.3529 - val_MinusLogProbMetric: 4.3529 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 13/1000
2023-09-12 04:10:45.122 
Epoch 13/1000 
	 loss: 4.2147, MinusLogProbMetric: 4.2147, val_loss: 4.2260, val_MinusLogProbMetric: 4.2260

Epoch 13: val_loss did not improve from 4.20626
196/196 - 12s - loss: 4.2147 - MinusLogProbMetric: 4.2147 - val_loss: 4.2260 - val_MinusLogProbMetric: 4.2260 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 04:10:56.815 
Epoch 14/1000 
	 loss: 4.2216, MinusLogProbMetric: 4.2216, val_loss: 4.3354, val_MinusLogProbMetric: 4.3354

Epoch 14: val_loss did not improve from 4.20626
196/196 - 12s - loss: 4.2216 - MinusLogProbMetric: 4.2216 - val_loss: 4.3354 - val_MinusLogProbMetric: 4.3354 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-12 04:11:08.607 
Epoch 15/1000 
	 loss: 4.2085, MinusLogProbMetric: 4.2085, val_loss: 4.1936, val_MinusLogProbMetric: 4.1936

Epoch 15: val_loss improved from 4.20626 to 4.19356, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.2085 - MinusLogProbMetric: 4.2085 - val_loss: 4.1936 - val_MinusLogProbMetric: 4.1936 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 16/1000
2023-09-12 04:11:20.469 
Epoch 16/1000 
	 loss: 4.1983, MinusLogProbMetric: 4.1983, val_loss: 4.2484, val_MinusLogProbMetric: 4.2484

Epoch 16: val_loss did not improve from 4.19356
196/196 - 12s - loss: 4.1983 - MinusLogProbMetric: 4.1983 - val_loss: 4.2484 - val_MinusLogProbMetric: 4.2484 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 04:11:32.156 
Epoch 17/1000 
	 loss: 4.1938, MinusLogProbMetric: 4.1938, val_loss: 4.2028, val_MinusLogProbMetric: 4.2028

Epoch 17: val_loss did not improve from 4.19356
196/196 - 12s - loss: 4.1938 - MinusLogProbMetric: 4.1938 - val_loss: 4.2028 - val_MinusLogProbMetric: 4.2028 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-12 04:11:43.765 
Epoch 18/1000 
	 loss: 4.1989, MinusLogProbMetric: 4.1989, val_loss: 4.1913, val_MinusLogProbMetric: 4.1913

Epoch 18: val_loss improved from 4.19356 to 4.19133, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1989 - MinusLogProbMetric: 4.1989 - val_loss: 4.1913 - val_MinusLogProbMetric: 4.1913 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 04:11:55.566 
Epoch 19/1000 
	 loss: 4.1952, MinusLogProbMetric: 4.1952, val_loss: 4.2127, val_MinusLogProbMetric: 4.2127

Epoch 19: val_loss did not improve from 4.19133
196/196 - 12s - loss: 4.1952 - MinusLogProbMetric: 4.1952 - val_loss: 4.2127 - val_MinusLogProbMetric: 4.2127 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-12 04:12:07.188 
Epoch 20/1000 
	 loss: 4.2035, MinusLogProbMetric: 4.2035, val_loss: 4.2117, val_MinusLogProbMetric: 4.2117

Epoch 20: val_loss did not improve from 4.19133
196/196 - 12s - loss: 4.2035 - MinusLogProbMetric: 4.2035 - val_loss: 4.2117 - val_MinusLogProbMetric: 4.2117 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 04:12:18.894 
Epoch 21/1000 
	 loss: 4.1748, MinusLogProbMetric: 4.1748, val_loss: 4.2012, val_MinusLogProbMetric: 4.2012

Epoch 21: val_loss did not improve from 4.19133
196/196 - 12s - loss: 4.1748 - MinusLogProbMetric: 4.1748 - val_loss: 4.2012 - val_MinusLogProbMetric: 4.2012 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 22/1000
2023-09-12 04:12:30.610 
Epoch 22/1000 
	 loss: 4.1909, MinusLogProbMetric: 4.1909, val_loss: 4.1909, val_MinusLogProbMetric: 4.1909

Epoch 22: val_loss improved from 4.19133 to 4.19085, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1909 - MinusLogProbMetric: 4.1909 - val_loss: 4.1909 - val_MinusLogProbMetric: 4.1909 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 04:12:42.436 
Epoch 23/1000 
	 loss: 4.1783, MinusLogProbMetric: 4.1783, val_loss: 4.1879, val_MinusLogProbMetric: 4.1879

Epoch 23: val_loss improved from 4.19085 to 4.18793, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1783 - MinusLogProbMetric: 4.1783 - val_loss: 4.1879 - val_MinusLogProbMetric: 4.1879 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-12 04:12:54.254 
Epoch 24/1000 
	 loss: 4.1745, MinusLogProbMetric: 4.1745, val_loss: 4.2262, val_MinusLogProbMetric: 4.2262

Epoch 24: val_loss did not improve from 4.18793
196/196 - 12s - loss: 4.1745 - MinusLogProbMetric: 4.1745 - val_loss: 4.2262 - val_MinusLogProbMetric: 4.2262 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-12 04:13:05.953 
Epoch 25/1000 
	 loss: 4.2063, MinusLogProbMetric: 4.2063, val_loss: 4.1829, val_MinusLogProbMetric: 4.1829

Epoch 25: val_loss improved from 4.18793 to 4.18295, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.2063 - MinusLogProbMetric: 4.2063 - val_loss: 4.1829 - val_MinusLogProbMetric: 4.1829 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 04:13:17.776 
Epoch 26/1000 
	 loss: 4.1821, MinusLogProbMetric: 4.1821, val_loss: 4.2502, val_MinusLogProbMetric: 4.2502

Epoch 26: val_loss did not improve from 4.18295
196/196 - 12s - loss: 4.1821 - MinusLogProbMetric: 4.1821 - val_loss: 4.2502 - val_MinusLogProbMetric: 4.2502 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 04:13:29.446 
Epoch 27/1000 
	 loss: 4.1706, MinusLogProbMetric: 4.1706, val_loss: 4.1720, val_MinusLogProbMetric: 4.1720

Epoch 27: val_loss improved from 4.18295 to 4.17198, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1706 - MinusLogProbMetric: 4.1706 - val_loss: 4.1720 - val_MinusLogProbMetric: 4.1720 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-12 04:13:41.144 
Epoch 28/1000 
	 loss: 4.1608, MinusLogProbMetric: 4.1608, val_loss: 4.2199, val_MinusLogProbMetric: 4.2199

Epoch 28: val_loss did not improve from 4.17198
196/196 - 12s - loss: 4.1608 - MinusLogProbMetric: 4.1608 - val_loss: 4.2199 - val_MinusLogProbMetric: 4.2199 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 04:13:52.909 
Epoch 29/1000 
	 loss: 4.1655, MinusLogProbMetric: 4.1655, val_loss: 4.1667, val_MinusLogProbMetric: 4.1667

Epoch 29: val_loss improved from 4.17198 to 4.16671, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1655 - MinusLogProbMetric: 4.1655 - val_loss: 4.1667 - val_MinusLogProbMetric: 4.1667 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 30/1000
2023-09-12 04:14:04.806 
Epoch 30/1000 
	 loss: 4.1585, MinusLogProbMetric: 4.1585, val_loss: 4.2175, val_MinusLogProbMetric: 4.2175

Epoch 30: val_loss did not improve from 4.16671
196/196 - 12s - loss: 4.1585 - MinusLogProbMetric: 4.1585 - val_loss: 4.2175 - val_MinusLogProbMetric: 4.2175 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-12 04:14:16.462 
Epoch 31/1000 
	 loss: 4.1608, MinusLogProbMetric: 4.1608, val_loss: 4.1927, val_MinusLogProbMetric: 4.1927

Epoch 31: val_loss did not improve from 4.16671
196/196 - 12s - loss: 4.1608 - MinusLogProbMetric: 4.1608 - val_loss: 4.1927 - val_MinusLogProbMetric: 4.1927 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 32/1000
2023-09-12 04:14:28.218 
Epoch 32/1000 
	 loss: 4.1660, MinusLogProbMetric: 4.1660, val_loss: 4.1890, val_MinusLogProbMetric: 4.1890

Epoch 32: val_loss did not improve from 4.16671
196/196 - 12s - loss: 4.1660 - MinusLogProbMetric: 4.1660 - val_loss: 4.1890 - val_MinusLogProbMetric: 4.1890 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-12 04:14:39.884 
Epoch 33/1000 
	 loss: 4.1570, MinusLogProbMetric: 4.1570, val_loss: 4.1697, val_MinusLogProbMetric: 4.1697

Epoch 33: val_loss did not improve from 4.16671
196/196 - 12s - loss: 4.1570 - MinusLogProbMetric: 4.1570 - val_loss: 4.1697 - val_MinusLogProbMetric: 4.1697 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-12 04:14:51.521 
Epoch 34/1000 
	 loss: 4.1616, MinusLogProbMetric: 4.1616, val_loss: 4.2202, val_MinusLogProbMetric: 4.2202

Epoch 34: val_loss did not improve from 4.16671
196/196 - 12s - loss: 4.1616 - MinusLogProbMetric: 4.1616 - val_loss: 4.2202 - val_MinusLogProbMetric: 4.2202 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 35/1000
2023-09-12 04:15:03.312 
Epoch 35/1000 
	 loss: 4.1592, MinusLogProbMetric: 4.1592, val_loss: 4.1532, val_MinusLogProbMetric: 4.1532

Epoch 35: val_loss improved from 4.16671 to 4.15316, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1592 - MinusLogProbMetric: 4.1592 - val_loss: 4.1532 - val_MinusLogProbMetric: 4.1532 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 36/1000
2023-09-12 04:15:15.109 
Epoch 36/1000 
	 loss: 4.1555, MinusLogProbMetric: 4.1555, val_loss: 4.1885, val_MinusLogProbMetric: 4.1885

Epoch 36: val_loss did not improve from 4.15316
196/196 - 12s - loss: 4.1555 - MinusLogProbMetric: 4.1555 - val_loss: 4.1885 - val_MinusLogProbMetric: 4.1885 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 04:15:26.715 
Epoch 37/1000 
	 loss: 4.1536, MinusLogProbMetric: 4.1536, val_loss: 4.1589, val_MinusLogProbMetric: 4.1589

Epoch 37: val_loss did not improve from 4.15316
196/196 - 12s - loss: 4.1536 - MinusLogProbMetric: 4.1536 - val_loss: 4.1589 - val_MinusLogProbMetric: 4.1589 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 38/1000
2023-09-12 04:15:38.459 
Epoch 38/1000 
	 loss: 4.1573, MinusLogProbMetric: 4.1573, val_loss: 4.2571, val_MinusLogProbMetric: 4.2571

Epoch 38: val_loss did not improve from 4.15316
196/196 - 12s - loss: 4.1573 - MinusLogProbMetric: 4.1573 - val_loss: 4.2571 - val_MinusLogProbMetric: 4.2571 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 04:15:50.145 
Epoch 39/1000 
	 loss: 4.1500, MinusLogProbMetric: 4.1500, val_loss: 4.1512, val_MinusLogProbMetric: 4.1512

Epoch 39: val_loss improved from 4.15316 to 4.15124, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1500 - MinusLogProbMetric: 4.1500 - val_loss: 4.1512 - val_MinusLogProbMetric: 4.1512 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-12 04:16:02.006 
Epoch 40/1000 
	 loss: 4.1488, MinusLogProbMetric: 4.1488, val_loss: 4.1792, val_MinusLogProbMetric: 4.1792

Epoch 40: val_loss did not improve from 4.15124
196/196 - 12s - loss: 4.1488 - MinusLogProbMetric: 4.1488 - val_loss: 4.1792 - val_MinusLogProbMetric: 4.1792 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-12 04:16:13.677 
Epoch 41/1000 
	 loss: 4.1497, MinusLogProbMetric: 4.1497, val_loss: 4.1746, val_MinusLogProbMetric: 4.1746

Epoch 41: val_loss did not improve from 4.15124
196/196 - 12s - loss: 4.1497 - MinusLogProbMetric: 4.1497 - val_loss: 4.1746 - val_MinusLogProbMetric: 4.1746 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-12 04:16:25.397 
Epoch 42/1000 
	 loss: 4.1532, MinusLogProbMetric: 4.1532, val_loss: 4.2119, val_MinusLogProbMetric: 4.2119

Epoch 42: val_loss did not improve from 4.15124
196/196 - 12s - loss: 4.1532 - MinusLogProbMetric: 4.1532 - val_loss: 4.2119 - val_MinusLogProbMetric: 4.2119 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-12 04:16:37.048 
Epoch 43/1000 
	 loss: 4.1539, MinusLogProbMetric: 4.1539, val_loss: 4.1515, val_MinusLogProbMetric: 4.1515

Epoch 43: val_loss did not improve from 4.15124
196/196 - 12s - loss: 4.1539 - MinusLogProbMetric: 4.1539 - val_loss: 4.1515 - val_MinusLogProbMetric: 4.1515 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-12 04:16:48.796 
Epoch 44/1000 
	 loss: 4.1452, MinusLogProbMetric: 4.1452, val_loss: 4.2573, val_MinusLogProbMetric: 4.2573

Epoch 44: val_loss did not improve from 4.15124
196/196 - 12s - loss: 4.1452 - MinusLogProbMetric: 4.1452 - val_loss: 4.2573 - val_MinusLogProbMetric: 4.2573 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-12 04:17:00.502 
Epoch 45/1000 
	 loss: 4.1391, MinusLogProbMetric: 4.1391, val_loss: 4.1455, val_MinusLogProbMetric: 4.1455

Epoch 45: val_loss improved from 4.15124 to 4.14548, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1391 - MinusLogProbMetric: 4.1391 - val_loss: 4.1455 - val_MinusLogProbMetric: 4.1455 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-12 04:17:12.232 
Epoch 46/1000 
	 loss: 4.1360, MinusLogProbMetric: 4.1360, val_loss: 4.1646, val_MinusLogProbMetric: 4.1646

Epoch 46: val_loss did not improve from 4.14548
196/196 - 12s - loss: 4.1360 - MinusLogProbMetric: 4.1360 - val_loss: 4.1646 - val_MinusLogProbMetric: 4.1646 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 04:17:23.990 
Epoch 47/1000 
	 loss: 4.1419, MinusLogProbMetric: 4.1419, val_loss: 4.1758, val_MinusLogProbMetric: 4.1758

Epoch 47: val_loss did not improve from 4.14548
196/196 - 12s - loss: 4.1419 - MinusLogProbMetric: 4.1419 - val_loss: 4.1758 - val_MinusLogProbMetric: 4.1758 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-12 04:17:35.666 
Epoch 48/1000 
	 loss: 4.1511, MinusLogProbMetric: 4.1511, val_loss: 4.1540, val_MinusLogProbMetric: 4.1540

Epoch 48: val_loss did not improve from 4.14548
196/196 - 12s - loss: 4.1511 - MinusLogProbMetric: 4.1511 - val_loss: 4.1540 - val_MinusLogProbMetric: 4.1540 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-12 04:17:47.480 
Epoch 49/1000 
	 loss: 4.1458, MinusLogProbMetric: 4.1458, val_loss: 4.1436, val_MinusLogProbMetric: 4.1436

Epoch 49: val_loss improved from 4.14548 to 4.14356, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1458 - MinusLogProbMetric: 4.1458 - val_loss: 4.1436 - val_MinusLogProbMetric: 4.1436 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 50/1000
2023-09-12 04:17:59.243 
Epoch 50/1000 
	 loss: 4.1418, MinusLogProbMetric: 4.1418, val_loss: 4.1525, val_MinusLogProbMetric: 4.1525

Epoch 50: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1418 - MinusLogProbMetric: 4.1418 - val_loss: 4.1525 - val_MinusLogProbMetric: 4.1525 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 51/1000
2023-09-12 04:18:11.005 
Epoch 51/1000 
	 loss: 4.1469, MinusLogProbMetric: 4.1469, val_loss: 4.1662, val_MinusLogProbMetric: 4.1662

Epoch 51: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1469 - MinusLogProbMetric: 4.1469 - val_loss: 4.1662 - val_MinusLogProbMetric: 4.1662 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-12 04:18:22.801 
Epoch 52/1000 
	 loss: 4.1286, MinusLogProbMetric: 4.1286, val_loss: 4.2068, val_MinusLogProbMetric: 4.2068

Epoch 52: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1286 - MinusLogProbMetric: 4.1286 - val_loss: 4.2068 - val_MinusLogProbMetric: 4.2068 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-12 04:18:34.540 
Epoch 53/1000 
	 loss: 4.1457, MinusLogProbMetric: 4.1457, val_loss: 4.2096, val_MinusLogProbMetric: 4.2096

Epoch 53: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1457 - MinusLogProbMetric: 4.1457 - val_loss: 4.2096 - val_MinusLogProbMetric: 4.2096 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-12 04:18:46.223 
Epoch 54/1000 
	 loss: 4.1380, MinusLogProbMetric: 4.1380, val_loss: 4.1661, val_MinusLogProbMetric: 4.1661

Epoch 54: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1380 - MinusLogProbMetric: 4.1380 - val_loss: 4.1661 - val_MinusLogProbMetric: 4.1661 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 55/1000
2023-09-12 04:18:57.854 
Epoch 55/1000 
	 loss: 4.1425, MinusLogProbMetric: 4.1425, val_loss: 4.1633, val_MinusLogProbMetric: 4.1633

Epoch 55: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1425 - MinusLogProbMetric: 4.1425 - val_loss: 4.1633 - val_MinusLogProbMetric: 4.1633 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 56/1000
2023-09-12 04:19:09.635 
Epoch 56/1000 
	 loss: 4.1305, MinusLogProbMetric: 4.1305, val_loss: 4.1991, val_MinusLogProbMetric: 4.1991

Epoch 56: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1305 - MinusLogProbMetric: 4.1305 - val_loss: 4.1991 - val_MinusLogProbMetric: 4.1991 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-12 04:19:21.327 
Epoch 57/1000 
	 loss: 4.1379, MinusLogProbMetric: 4.1379, val_loss: 4.1741, val_MinusLogProbMetric: 4.1741

Epoch 57: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1379 - MinusLogProbMetric: 4.1379 - val_loss: 4.1741 - val_MinusLogProbMetric: 4.1741 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-12 04:19:33.093 
Epoch 58/1000 
	 loss: 4.1310, MinusLogProbMetric: 4.1310, val_loss: 4.1480, val_MinusLogProbMetric: 4.1480

Epoch 58: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1310 - MinusLogProbMetric: 4.1310 - val_loss: 4.1480 - val_MinusLogProbMetric: 4.1480 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-12 04:19:44.830 
Epoch 59/1000 
	 loss: 4.1320, MinusLogProbMetric: 4.1320, val_loss: 4.1922, val_MinusLogProbMetric: 4.1922

Epoch 59: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1320 - MinusLogProbMetric: 4.1320 - val_loss: 4.1922 - val_MinusLogProbMetric: 4.1922 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-12 04:19:56.484 
Epoch 60/1000 
	 loss: 4.1282, MinusLogProbMetric: 4.1282, val_loss: 4.1514, val_MinusLogProbMetric: 4.1514

Epoch 60: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1282 - MinusLogProbMetric: 4.1282 - val_loss: 4.1514 - val_MinusLogProbMetric: 4.1514 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 61/1000
2023-09-12 04:20:08.169 
Epoch 61/1000 
	 loss: 4.1304, MinusLogProbMetric: 4.1304, val_loss: 4.1652, val_MinusLogProbMetric: 4.1652

Epoch 61: val_loss did not improve from 4.14356
196/196 - 12s - loss: 4.1304 - MinusLogProbMetric: 4.1304 - val_loss: 4.1652 - val_MinusLogProbMetric: 4.1652 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-12 04:20:19.783 
Epoch 62/1000 
	 loss: 4.1372, MinusLogProbMetric: 4.1372, val_loss: 4.1344, val_MinusLogProbMetric: 4.1344

Epoch 62: val_loss improved from 4.14356 to 4.13445, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1372 - MinusLogProbMetric: 4.1372 - val_loss: 4.1344 - val_MinusLogProbMetric: 4.1344 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-12 04:20:31.644 
Epoch 63/1000 
	 loss: 4.1261, MinusLogProbMetric: 4.1261, val_loss: 4.1356, val_MinusLogProbMetric: 4.1356

Epoch 63: val_loss did not improve from 4.13445
196/196 - 12s - loss: 4.1261 - MinusLogProbMetric: 4.1261 - val_loss: 4.1356 - val_MinusLogProbMetric: 4.1356 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-12 04:20:43.390 
Epoch 64/1000 
	 loss: 4.1298, MinusLogProbMetric: 4.1298, val_loss: 4.1416, val_MinusLogProbMetric: 4.1416

Epoch 64: val_loss did not improve from 4.13445
196/196 - 12s - loss: 4.1298 - MinusLogProbMetric: 4.1298 - val_loss: 4.1416 - val_MinusLogProbMetric: 4.1416 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-12 04:20:55.126 
Epoch 65/1000 
	 loss: 4.1247, MinusLogProbMetric: 4.1247, val_loss: 4.1476, val_MinusLogProbMetric: 4.1476

Epoch 65: val_loss did not improve from 4.13445
196/196 - 12s - loss: 4.1247 - MinusLogProbMetric: 4.1247 - val_loss: 4.1476 - val_MinusLogProbMetric: 4.1476 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-12 04:21:06.864 
Epoch 66/1000 
	 loss: 4.1272, MinusLogProbMetric: 4.1272, val_loss: 4.1473, val_MinusLogProbMetric: 4.1473

Epoch 66: val_loss did not improve from 4.13445
196/196 - 12s - loss: 4.1272 - MinusLogProbMetric: 4.1272 - val_loss: 4.1473 - val_MinusLogProbMetric: 4.1473 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-12 04:21:18.578 
Epoch 67/1000 
	 loss: 4.1284, MinusLogProbMetric: 4.1284, val_loss: 4.1410, val_MinusLogProbMetric: 4.1410

Epoch 67: val_loss did not improve from 4.13445
196/196 - 12s - loss: 4.1284 - MinusLogProbMetric: 4.1284 - val_loss: 4.1410 - val_MinusLogProbMetric: 4.1410 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-12 04:21:30.293 
Epoch 68/1000 
	 loss: 4.1314, MinusLogProbMetric: 4.1314, val_loss: 4.1607, val_MinusLogProbMetric: 4.1607

Epoch 68: val_loss did not improve from 4.13445
196/196 - 12s - loss: 4.1314 - MinusLogProbMetric: 4.1314 - val_loss: 4.1607 - val_MinusLogProbMetric: 4.1607 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-12 04:21:41.953 
Epoch 69/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.1337, val_MinusLogProbMetric: 4.1337

Epoch 69: val_loss improved from 4.13445 to 4.13373, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.1337 - val_MinusLogProbMetric: 4.1337 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 04:21:53.964 
Epoch 70/1000 
	 loss: 4.1275, MinusLogProbMetric: 4.1275, val_loss: 4.1792, val_MinusLogProbMetric: 4.1792

Epoch 70: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1275 - MinusLogProbMetric: 4.1275 - val_loss: 4.1792 - val_MinusLogProbMetric: 4.1792 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 71/1000
2023-09-12 04:22:05.572 
Epoch 71/1000 
	 loss: 4.1279, MinusLogProbMetric: 4.1279, val_loss: 4.1682, val_MinusLogProbMetric: 4.1682

Epoch 71: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1279 - MinusLogProbMetric: 4.1279 - val_loss: 4.1682 - val_MinusLogProbMetric: 4.1682 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 72/1000
2023-09-12 04:22:17.310 
Epoch 72/1000 
	 loss: 4.1210, MinusLogProbMetric: 4.1210, val_loss: 4.1501, val_MinusLogProbMetric: 4.1501

Epoch 72: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1210 - MinusLogProbMetric: 4.1210 - val_loss: 4.1501 - val_MinusLogProbMetric: 4.1501 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-12 04:22:29.070 
Epoch 73/1000 
	 loss: 4.1293, MinusLogProbMetric: 4.1293, val_loss: 4.1542, val_MinusLogProbMetric: 4.1542

Epoch 73: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1293 - MinusLogProbMetric: 4.1293 - val_loss: 4.1542 - val_MinusLogProbMetric: 4.1542 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-12 04:22:40.722 
Epoch 74/1000 
	 loss: 4.1243, MinusLogProbMetric: 4.1243, val_loss: 4.1547, val_MinusLogProbMetric: 4.1547

Epoch 74: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1243 - MinusLogProbMetric: 4.1243 - val_loss: 4.1547 - val_MinusLogProbMetric: 4.1547 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 75/1000
2023-09-12 04:22:52.421 
Epoch 75/1000 
	 loss: 4.1333, MinusLogProbMetric: 4.1333, val_loss: 4.1785, val_MinusLogProbMetric: 4.1785

Epoch 75: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1333 - MinusLogProbMetric: 4.1333 - val_loss: 4.1785 - val_MinusLogProbMetric: 4.1785 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-12 04:23:04.209 
Epoch 76/1000 
	 loss: 4.1233, MinusLogProbMetric: 4.1233, val_loss: 4.1504, val_MinusLogProbMetric: 4.1504

Epoch 76: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1233 - MinusLogProbMetric: 4.1233 - val_loss: 4.1504 - val_MinusLogProbMetric: 4.1504 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-12 04:23:15.835 
Epoch 77/1000 
	 loss: 4.1296, MinusLogProbMetric: 4.1296, val_loss: 4.1853, val_MinusLogProbMetric: 4.1853

Epoch 77: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1296 - MinusLogProbMetric: 4.1296 - val_loss: 4.1853 - val_MinusLogProbMetric: 4.1853 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 78/1000
2023-09-12 04:23:27.509 
Epoch 78/1000 
	 loss: 4.1224, MinusLogProbMetric: 4.1224, val_loss: 4.1737, val_MinusLogProbMetric: 4.1737

Epoch 78: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1224 - MinusLogProbMetric: 4.1224 - val_loss: 4.1737 - val_MinusLogProbMetric: 4.1737 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-12 04:23:39.227 
Epoch 79/1000 
	 loss: 4.1230, MinusLogProbMetric: 4.1230, val_loss: 4.1504, val_MinusLogProbMetric: 4.1504

Epoch 79: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1230 - MinusLogProbMetric: 4.1230 - val_loss: 4.1504 - val_MinusLogProbMetric: 4.1504 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 04:23:50.987 
Epoch 80/1000 
	 loss: 4.1221, MinusLogProbMetric: 4.1221, val_loss: 4.1419, val_MinusLogProbMetric: 4.1419

Epoch 80: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1221 - MinusLogProbMetric: 4.1221 - val_loss: 4.1419 - val_MinusLogProbMetric: 4.1419 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 81/1000
2023-09-12 04:24:02.677 
Epoch 81/1000 
	 loss: 4.1211, MinusLogProbMetric: 4.1211, val_loss: 4.1587, val_MinusLogProbMetric: 4.1587

Epoch 81: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1211 - MinusLogProbMetric: 4.1211 - val_loss: 4.1587 - val_MinusLogProbMetric: 4.1587 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 82/1000
2023-09-12 04:24:14.506 
Epoch 82/1000 
	 loss: 4.1202, MinusLogProbMetric: 4.1202, val_loss: 4.1584, val_MinusLogProbMetric: 4.1584

Epoch 82: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1202 - MinusLogProbMetric: 4.1202 - val_loss: 4.1584 - val_MinusLogProbMetric: 4.1584 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-12 04:24:26.244 
Epoch 83/1000 
	 loss: 4.1176, MinusLogProbMetric: 4.1176, val_loss: 4.1568, val_MinusLogProbMetric: 4.1568

Epoch 83: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1176 - MinusLogProbMetric: 4.1176 - val_loss: 4.1568 - val_MinusLogProbMetric: 4.1568 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 84/1000
2023-09-12 04:24:37.906 
Epoch 84/1000 
	 loss: 4.1222, MinusLogProbMetric: 4.1222, val_loss: 4.1518, val_MinusLogProbMetric: 4.1518

Epoch 84: val_loss did not improve from 4.13373
196/196 - 12s - loss: 4.1222 - MinusLogProbMetric: 4.1222 - val_loss: 4.1518 - val_MinusLogProbMetric: 4.1518 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 85/1000
2023-09-12 04:24:49.702 
Epoch 85/1000 
	 loss: 4.1170, MinusLogProbMetric: 4.1170, val_loss: 4.1327, val_MinusLogProbMetric: 4.1327

Epoch 85: val_loss improved from 4.13373 to 4.13271, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1170 - MinusLogProbMetric: 4.1170 - val_loss: 4.1327 - val_MinusLogProbMetric: 4.1327 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 86/1000
2023-09-12 04:25:01.576 
Epoch 86/1000 
	 loss: 4.1176, MinusLogProbMetric: 4.1176, val_loss: 4.1505, val_MinusLogProbMetric: 4.1505

Epoch 86: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1176 - MinusLogProbMetric: 4.1176 - val_loss: 4.1505 - val_MinusLogProbMetric: 4.1505 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 87/1000
2023-09-12 04:25:13.264 
Epoch 87/1000 
	 loss: 4.1190, MinusLogProbMetric: 4.1190, val_loss: 4.1505, val_MinusLogProbMetric: 4.1505

Epoch 87: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1190 - MinusLogProbMetric: 4.1190 - val_loss: 4.1505 - val_MinusLogProbMetric: 4.1505 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 88/1000
2023-09-12 04:25:24.825 
Epoch 88/1000 
	 loss: 4.1155, MinusLogProbMetric: 4.1155, val_loss: 4.1728, val_MinusLogProbMetric: 4.1728

Epoch 88: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1155 - MinusLogProbMetric: 4.1155 - val_loss: 4.1728 - val_MinusLogProbMetric: 4.1728 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-12 04:25:36.500 
Epoch 89/1000 
	 loss: 4.1291, MinusLogProbMetric: 4.1291, val_loss: 4.2037, val_MinusLogProbMetric: 4.2037

Epoch 89: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1291 - MinusLogProbMetric: 4.1291 - val_loss: 4.2037 - val_MinusLogProbMetric: 4.2037 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-12 04:25:48.224 
Epoch 90/1000 
	 loss: 4.1239, MinusLogProbMetric: 4.1239, val_loss: 4.1560, val_MinusLogProbMetric: 4.1560

Epoch 90: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1239 - MinusLogProbMetric: 4.1239 - val_loss: 4.1560 - val_MinusLogProbMetric: 4.1560 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-12 04:25:59.929 
Epoch 91/1000 
	 loss: 4.1158, MinusLogProbMetric: 4.1158, val_loss: 4.1434, val_MinusLogProbMetric: 4.1434

Epoch 91: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1158 - MinusLogProbMetric: 4.1158 - val_loss: 4.1434 - val_MinusLogProbMetric: 4.1434 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 04:26:11.597 
Epoch 92/1000 
	 loss: 4.1149, MinusLogProbMetric: 4.1149, val_loss: 4.1560, val_MinusLogProbMetric: 4.1560

Epoch 92: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1149 - MinusLogProbMetric: 4.1149 - val_loss: 4.1560 - val_MinusLogProbMetric: 4.1560 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 93/1000
2023-09-12 04:26:23.255 
Epoch 93/1000 
	 loss: 4.1219, MinusLogProbMetric: 4.1219, val_loss: 4.1733, val_MinusLogProbMetric: 4.1733

Epoch 93: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1219 - MinusLogProbMetric: 4.1219 - val_loss: 4.1733 - val_MinusLogProbMetric: 4.1733 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 94/1000
2023-09-12 04:26:35.030 
Epoch 94/1000 
	 loss: 4.1160, MinusLogProbMetric: 4.1160, val_loss: 4.1334, val_MinusLogProbMetric: 4.1334

Epoch 94: val_loss did not improve from 4.13271
196/196 - 12s - loss: 4.1160 - MinusLogProbMetric: 4.1160 - val_loss: 4.1334 - val_MinusLogProbMetric: 4.1334 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-12 04:26:46.771 
Epoch 95/1000 
	 loss: 4.1185, MinusLogProbMetric: 4.1185, val_loss: 4.1316, val_MinusLogProbMetric: 4.1316

Epoch 95: val_loss improved from 4.13271 to 4.13161, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1185 - MinusLogProbMetric: 4.1185 - val_loss: 4.1316 - val_MinusLogProbMetric: 4.1316 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-12 04:26:58.454 
Epoch 96/1000 
	 loss: 4.1174, MinusLogProbMetric: 4.1174, val_loss: 4.1418, val_MinusLogProbMetric: 4.1418

Epoch 96: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1174 - MinusLogProbMetric: 4.1174 - val_loss: 4.1418 - val_MinusLogProbMetric: 4.1418 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 97/1000
2023-09-12 04:27:09.993 
Epoch 97/1000 
	 loss: 4.1128, MinusLogProbMetric: 4.1128, val_loss: 4.1541, val_MinusLogProbMetric: 4.1541

Epoch 97: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1128 - MinusLogProbMetric: 4.1128 - val_loss: 4.1541 - val_MinusLogProbMetric: 4.1541 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 98/1000
2023-09-12 04:27:21.654 
Epoch 98/1000 
	 loss: 4.1134, MinusLogProbMetric: 4.1134, val_loss: 4.1451, val_MinusLogProbMetric: 4.1451

Epoch 98: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1134 - MinusLogProbMetric: 4.1134 - val_loss: 4.1451 - val_MinusLogProbMetric: 4.1451 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 99/1000
2023-09-12 04:27:33.251 
Epoch 99/1000 
	 loss: 4.1150, MinusLogProbMetric: 4.1150, val_loss: 4.1320, val_MinusLogProbMetric: 4.1320

Epoch 99: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1150 - MinusLogProbMetric: 4.1150 - val_loss: 4.1320 - val_MinusLogProbMetric: 4.1320 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 04:27:44.982 
Epoch 100/1000 
	 loss: 4.1107, MinusLogProbMetric: 4.1107, val_loss: 4.1916, val_MinusLogProbMetric: 4.1916

Epoch 100: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1107 - MinusLogProbMetric: 4.1107 - val_loss: 4.1916 - val_MinusLogProbMetric: 4.1916 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-12 04:27:56.700 
Epoch 101/1000 
	 loss: 4.1166, MinusLogProbMetric: 4.1166, val_loss: 4.1340, val_MinusLogProbMetric: 4.1340

Epoch 101: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1166 - MinusLogProbMetric: 4.1166 - val_loss: 4.1340 - val_MinusLogProbMetric: 4.1340 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 102/1000
2023-09-12 04:28:08.352 
Epoch 102/1000 
	 loss: 4.1148, MinusLogProbMetric: 4.1148, val_loss: 4.1353, val_MinusLogProbMetric: 4.1353

Epoch 102: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1148 - MinusLogProbMetric: 4.1148 - val_loss: 4.1353 - val_MinusLogProbMetric: 4.1353 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 103/1000
2023-09-12 04:28:19.956 
Epoch 103/1000 
	 loss: 4.1147, MinusLogProbMetric: 4.1147, val_loss: 4.1390, val_MinusLogProbMetric: 4.1390

Epoch 103: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1147 - MinusLogProbMetric: 4.1147 - val_loss: 4.1390 - val_MinusLogProbMetric: 4.1390 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 104/1000
2023-09-12 04:28:31.755 
Epoch 104/1000 
	 loss: 4.1153, MinusLogProbMetric: 4.1153, val_loss: 4.1408, val_MinusLogProbMetric: 4.1408

Epoch 104: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1153 - MinusLogProbMetric: 4.1153 - val_loss: 4.1408 - val_MinusLogProbMetric: 4.1408 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 105/1000
2023-09-12 04:28:43.419 
Epoch 105/1000 
	 loss: 4.1169, MinusLogProbMetric: 4.1169, val_loss: 4.1543, val_MinusLogProbMetric: 4.1543

Epoch 105: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1169 - MinusLogProbMetric: 4.1169 - val_loss: 4.1543 - val_MinusLogProbMetric: 4.1543 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 106/1000
2023-09-12 04:28:55.072 
Epoch 106/1000 
	 loss: 4.1113, MinusLogProbMetric: 4.1113, val_loss: 4.1494, val_MinusLogProbMetric: 4.1494

Epoch 106: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1113 - MinusLogProbMetric: 4.1113 - val_loss: 4.1494 - val_MinusLogProbMetric: 4.1494 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 107/1000
2023-09-12 04:29:06.749 
Epoch 107/1000 
	 loss: 4.1134, MinusLogProbMetric: 4.1134, val_loss: 4.1790, val_MinusLogProbMetric: 4.1790

Epoch 107: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1134 - MinusLogProbMetric: 4.1134 - val_loss: 4.1790 - val_MinusLogProbMetric: 4.1790 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-12 04:29:18.355 
Epoch 108/1000 
	 loss: 4.1140, MinusLogProbMetric: 4.1140, val_loss: 4.1605, val_MinusLogProbMetric: 4.1605

Epoch 108: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1140 - MinusLogProbMetric: 4.1140 - val_loss: 4.1605 - val_MinusLogProbMetric: 4.1605 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 109/1000
2023-09-12 04:29:29.916 
Epoch 109/1000 
	 loss: 4.1218, MinusLogProbMetric: 4.1218, val_loss: 4.1741, val_MinusLogProbMetric: 4.1741

Epoch 109: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1218 - MinusLogProbMetric: 4.1218 - val_loss: 4.1741 - val_MinusLogProbMetric: 4.1741 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-12 04:29:41.655 
Epoch 110/1000 
	 loss: 4.1116, MinusLogProbMetric: 4.1116, val_loss: 4.1535, val_MinusLogProbMetric: 4.1535

Epoch 110: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1116 - MinusLogProbMetric: 4.1116 - val_loss: 4.1535 - val_MinusLogProbMetric: 4.1535 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 111/1000
2023-09-12 04:29:53.434 
Epoch 111/1000 
	 loss: 4.1081, MinusLogProbMetric: 4.1081, val_loss: 4.1430, val_MinusLogProbMetric: 4.1430

Epoch 111: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1081 - MinusLogProbMetric: 4.1081 - val_loss: 4.1430 - val_MinusLogProbMetric: 4.1430 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-12 04:30:05.126 
Epoch 112/1000 
	 loss: 4.1098, MinusLogProbMetric: 4.1098, val_loss: 4.1627, val_MinusLogProbMetric: 4.1627

Epoch 112: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1098 - MinusLogProbMetric: 4.1098 - val_loss: 4.1627 - val_MinusLogProbMetric: 4.1627 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 113/1000
2023-09-12 04:30:16.879 
Epoch 113/1000 
	 loss: 4.1154, MinusLogProbMetric: 4.1154, val_loss: 4.1462, val_MinusLogProbMetric: 4.1462

Epoch 113: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1154 - MinusLogProbMetric: 4.1154 - val_loss: 4.1462 - val_MinusLogProbMetric: 4.1462 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-12 04:30:28.680 
Epoch 114/1000 
	 loss: 4.1133, MinusLogProbMetric: 4.1133, val_loss: 4.1681, val_MinusLogProbMetric: 4.1681

Epoch 114: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1133 - MinusLogProbMetric: 4.1133 - val_loss: 4.1681 - val_MinusLogProbMetric: 4.1681 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 115/1000
2023-09-12 04:30:40.315 
Epoch 115/1000 
	 loss: 4.1122, MinusLogProbMetric: 4.1122, val_loss: 4.1378, val_MinusLogProbMetric: 4.1378

Epoch 115: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1122 - MinusLogProbMetric: 4.1122 - val_loss: 4.1378 - val_MinusLogProbMetric: 4.1378 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 116/1000
2023-09-12 04:30:52.020 
Epoch 116/1000 
	 loss: 4.1119, MinusLogProbMetric: 4.1119, val_loss: 4.1571, val_MinusLogProbMetric: 4.1571

Epoch 116: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1119 - MinusLogProbMetric: 4.1119 - val_loss: 4.1571 - val_MinusLogProbMetric: 4.1571 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 117/1000
2023-09-12 04:31:03.730 
Epoch 117/1000 
	 loss: 4.1096, MinusLogProbMetric: 4.1096, val_loss: 4.1357, val_MinusLogProbMetric: 4.1357

Epoch 117: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1096 - MinusLogProbMetric: 4.1096 - val_loss: 4.1357 - val_MinusLogProbMetric: 4.1357 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-12 04:31:15.509 
Epoch 118/1000 
	 loss: 4.1092, MinusLogProbMetric: 4.1092, val_loss: 4.1431, val_MinusLogProbMetric: 4.1431

Epoch 118: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1092 - MinusLogProbMetric: 4.1092 - val_loss: 4.1431 - val_MinusLogProbMetric: 4.1431 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-12 04:31:27.114 
Epoch 119/1000 
	 loss: 4.1136, MinusLogProbMetric: 4.1136, val_loss: 4.1568, val_MinusLogProbMetric: 4.1568

Epoch 119: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1136 - MinusLogProbMetric: 4.1136 - val_loss: 4.1568 - val_MinusLogProbMetric: 4.1568 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 120/1000
2023-09-12 04:31:38.891 
Epoch 120/1000 
	 loss: 4.1065, MinusLogProbMetric: 4.1065, val_loss: 4.1602, val_MinusLogProbMetric: 4.1602

Epoch 120: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1065 - MinusLogProbMetric: 4.1065 - val_loss: 4.1602 - val_MinusLogProbMetric: 4.1602 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-12 04:31:50.456 
Epoch 121/1000 
	 loss: 4.1137, MinusLogProbMetric: 4.1137, val_loss: 4.1545, val_MinusLogProbMetric: 4.1545

Epoch 121: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1137 - MinusLogProbMetric: 4.1137 - val_loss: 4.1545 - val_MinusLogProbMetric: 4.1545 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 122/1000
2023-09-12 04:32:02.202 
Epoch 122/1000 
	 loss: 4.1096, MinusLogProbMetric: 4.1096, val_loss: 4.1477, val_MinusLogProbMetric: 4.1477

Epoch 122: val_loss did not improve from 4.13161
196/196 - 12s - loss: 4.1096 - MinusLogProbMetric: 4.1096 - val_loss: 4.1477 - val_MinusLogProbMetric: 4.1477 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-12 04:32:13.871 
Epoch 123/1000 
	 loss: 4.1009, MinusLogProbMetric: 4.1009, val_loss: 4.1271, val_MinusLogProbMetric: 4.1271

Epoch 123: val_loss improved from 4.13161 to 4.12712, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1009 - MinusLogProbMetric: 4.1009 - val_loss: 4.1271 - val_MinusLogProbMetric: 4.1271 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-12 04:32:25.593 
Epoch 124/1000 
	 loss: 4.1074, MinusLogProbMetric: 4.1074, val_loss: 4.1455, val_MinusLogProbMetric: 4.1455

Epoch 124: val_loss did not improve from 4.12712
196/196 - 12s - loss: 4.1074 - MinusLogProbMetric: 4.1074 - val_loss: 4.1455 - val_MinusLogProbMetric: 4.1455 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 125/1000
2023-09-12 04:32:37.217 
Epoch 125/1000 
	 loss: 4.1092, MinusLogProbMetric: 4.1092, val_loss: 4.1584, val_MinusLogProbMetric: 4.1584

Epoch 125: val_loss did not improve from 4.12712
196/196 - 12s - loss: 4.1092 - MinusLogProbMetric: 4.1092 - val_loss: 4.1584 - val_MinusLogProbMetric: 4.1584 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 126/1000
2023-09-12 04:32:48.978 
Epoch 126/1000 
	 loss: 4.1078, MinusLogProbMetric: 4.1078, val_loss: 4.1432, val_MinusLogProbMetric: 4.1432

Epoch 126: val_loss did not improve from 4.12712
196/196 - 12s - loss: 4.1078 - MinusLogProbMetric: 4.1078 - val_loss: 4.1432 - val_MinusLogProbMetric: 4.1432 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-12 04:33:00.620 
Epoch 127/1000 
	 loss: 4.1069, MinusLogProbMetric: 4.1069, val_loss: 4.1229, val_MinusLogProbMetric: 4.1229

Epoch 127: val_loss improved from 4.12712 to 4.12294, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.1069 - MinusLogProbMetric: 4.1069 - val_loss: 4.1229 - val_MinusLogProbMetric: 4.1229 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 128/1000
2023-09-12 04:33:12.456 
Epoch 128/1000 
	 loss: 4.1000, MinusLogProbMetric: 4.1000, val_loss: 4.1316, val_MinusLogProbMetric: 4.1316

Epoch 128: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1000 - MinusLogProbMetric: 4.1000 - val_loss: 4.1316 - val_MinusLogProbMetric: 4.1316 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-12 04:33:24.145 
Epoch 129/1000 
	 loss: 4.1047, MinusLogProbMetric: 4.1047, val_loss: 4.1398, val_MinusLogProbMetric: 4.1398

Epoch 129: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1047 - MinusLogProbMetric: 4.1047 - val_loss: 4.1398 - val_MinusLogProbMetric: 4.1398 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-12 04:33:35.825 
Epoch 130/1000 
	 loss: 4.1077, MinusLogProbMetric: 4.1077, val_loss: 4.1539, val_MinusLogProbMetric: 4.1539

Epoch 130: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1077 - MinusLogProbMetric: 4.1077 - val_loss: 4.1539 - val_MinusLogProbMetric: 4.1539 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-12 04:33:47.643 
Epoch 131/1000 
	 loss: 4.1057, MinusLogProbMetric: 4.1057, val_loss: 4.1308, val_MinusLogProbMetric: 4.1308

Epoch 131: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1057 - MinusLogProbMetric: 4.1057 - val_loss: 4.1308 - val_MinusLogProbMetric: 4.1308 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 132/1000
2023-09-12 04:33:59.395 
Epoch 132/1000 
	 loss: 4.1042, MinusLogProbMetric: 4.1042, val_loss: 4.1263, val_MinusLogProbMetric: 4.1263

Epoch 132: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1042 - MinusLogProbMetric: 4.1042 - val_loss: 4.1263 - val_MinusLogProbMetric: 4.1263 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 133/1000
2023-09-12 04:34:11.014 
Epoch 133/1000 
	 loss: 4.1048, MinusLogProbMetric: 4.1048, val_loss: 4.1540, val_MinusLogProbMetric: 4.1540

Epoch 133: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1048 - MinusLogProbMetric: 4.1048 - val_loss: 4.1540 - val_MinusLogProbMetric: 4.1540 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 134/1000
2023-09-12 04:34:22.795 
Epoch 134/1000 
	 loss: 4.1085, MinusLogProbMetric: 4.1085, val_loss: 4.1296, val_MinusLogProbMetric: 4.1296

Epoch 134: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1085 - MinusLogProbMetric: 4.1085 - val_loss: 4.1296 - val_MinusLogProbMetric: 4.1296 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-12 04:34:34.498 
Epoch 135/1000 
	 loss: 4.1017, MinusLogProbMetric: 4.1017, val_loss: 4.1324, val_MinusLogProbMetric: 4.1324

Epoch 135: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1017 - MinusLogProbMetric: 4.1017 - val_loss: 4.1324 - val_MinusLogProbMetric: 4.1324 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-12 04:34:46.200 
Epoch 136/1000 
	 loss: 4.1048, MinusLogProbMetric: 4.1048, val_loss: 4.1459, val_MinusLogProbMetric: 4.1459

Epoch 136: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1048 - MinusLogProbMetric: 4.1048 - val_loss: 4.1459 - val_MinusLogProbMetric: 4.1459 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 137/1000
2023-09-12 04:34:57.955 
Epoch 137/1000 
	 loss: 4.1064, MinusLogProbMetric: 4.1064, val_loss: 4.1408, val_MinusLogProbMetric: 4.1408

Epoch 137: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1064 - MinusLogProbMetric: 4.1064 - val_loss: 4.1408 - val_MinusLogProbMetric: 4.1408 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 138/1000
2023-09-12 04:35:09.639 
Epoch 138/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.1381, val_MinusLogProbMetric: 4.1381

Epoch 138: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.1381 - val_MinusLogProbMetric: 4.1381 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-12 04:35:21.277 
Epoch 139/1000 
	 loss: 4.1052, MinusLogProbMetric: 4.1052, val_loss: 4.1363, val_MinusLogProbMetric: 4.1363

Epoch 139: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1052 - MinusLogProbMetric: 4.1052 - val_loss: 4.1363 - val_MinusLogProbMetric: 4.1363 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 140/1000
2023-09-12 04:35:32.867 
Epoch 140/1000 
	 loss: 4.1091, MinusLogProbMetric: 4.1091, val_loss: 4.1349, val_MinusLogProbMetric: 4.1349

Epoch 140: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1091 - MinusLogProbMetric: 4.1091 - val_loss: 4.1349 - val_MinusLogProbMetric: 4.1349 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 141/1000
2023-09-12 04:35:44.515 
Epoch 141/1000 
	 loss: 4.1050, MinusLogProbMetric: 4.1050, val_loss: 4.1284, val_MinusLogProbMetric: 4.1284

Epoch 141: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1050 - MinusLogProbMetric: 4.1050 - val_loss: 4.1284 - val_MinusLogProbMetric: 4.1284 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 142/1000
2023-09-12 04:35:56.066 
Epoch 142/1000 
	 loss: 4.1049, MinusLogProbMetric: 4.1049, val_loss: 4.1317, val_MinusLogProbMetric: 4.1317

Epoch 142: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1049 - MinusLogProbMetric: 4.1049 - val_loss: 4.1317 - val_MinusLogProbMetric: 4.1317 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 143/1000
2023-09-12 04:36:07.760 
Epoch 143/1000 
	 loss: 4.1028, MinusLogProbMetric: 4.1028, val_loss: 4.1424, val_MinusLogProbMetric: 4.1424

Epoch 143: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1028 - MinusLogProbMetric: 4.1028 - val_loss: 4.1424 - val_MinusLogProbMetric: 4.1424 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 144/1000
2023-09-12 04:36:19.358 
Epoch 144/1000 
	 loss: 4.1047, MinusLogProbMetric: 4.1047, val_loss: 4.1496, val_MinusLogProbMetric: 4.1496

Epoch 144: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1047 - MinusLogProbMetric: 4.1047 - val_loss: 4.1496 - val_MinusLogProbMetric: 4.1496 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 145/1000
2023-09-12 04:36:31.012 
Epoch 145/1000 
	 loss: 4.1006, MinusLogProbMetric: 4.1006, val_loss: 4.1396, val_MinusLogProbMetric: 4.1396

Epoch 145: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1006 - MinusLogProbMetric: 4.1006 - val_loss: 4.1396 - val_MinusLogProbMetric: 4.1396 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 146/1000
2023-09-12 04:36:42.759 
Epoch 146/1000 
	 loss: 4.1017, MinusLogProbMetric: 4.1017, val_loss: 4.1286, val_MinusLogProbMetric: 4.1286

Epoch 146: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1017 - MinusLogProbMetric: 4.1017 - val_loss: 4.1286 - val_MinusLogProbMetric: 4.1286 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-12 04:36:54.494 
Epoch 147/1000 
	 loss: 4.0997, MinusLogProbMetric: 4.0997, val_loss: 4.1512, val_MinusLogProbMetric: 4.1512

Epoch 147: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0997 - MinusLogProbMetric: 4.0997 - val_loss: 4.1512 - val_MinusLogProbMetric: 4.1512 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-12 04:37:06.285 
Epoch 148/1000 
	 loss: 4.1005, MinusLogProbMetric: 4.1005, val_loss: 4.1403, val_MinusLogProbMetric: 4.1403

Epoch 148: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1005 - MinusLogProbMetric: 4.1005 - val_loss: 4.1403 - val_MinusLogProbMetric: 4.1403 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-12 04:37:17.952 
Epoch 149/1000 
	 loss: 4.1080, MinusLogProbMetric: 4.1080, val_loss: 4.1324, val_MinusLogProbMetric: 4.1324

Epoch 149: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1080 - MinusLogProbMetric: 4.1080 - val_loss: 4.1324 - val_MinusLogProbMetric: 4.1324 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-12 04:37:29.712 
Epoch 150/1000 
	 loss: 4.1043, MinusLogProbMetric: 4.1043, val_loss: 4.1545, val_MinusLogProbMetric: 4.1545

Epoch 150: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1043 - MinusLogProbMetric: 4.1043 - val_loss: 4.1545 - val_MinusLogProbMetric: 4.1545 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-12 04:37:41.383 
Epoch 151/1000 
	 loss: 4.1084, MinusLogProbMetric: 4.1084, val_loss: 4.1259, val_MinusLogProbMetric: 4.1259

Epoch 151: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1084 - MinusLogProbMetric: 4.1084 - val_loss: 4.1259 - val_MinusLogProbMetric: 4.1259 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-12 04:37:53.210 
Epoch 152/1000 
	 loss: 4.1025, MinusLogProbMetric: 4.1025, val_loss: 4.1533, val_MinusLogProbMetric: 4.1533

Epoch 152: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1025 - MinusLogProbMetric: 4.1025 - val_loss: 4.1533 - val_MinusLogProbMetric: 4.1533 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-12 04:38:04.850 
Epoch 153/1000 
	 loss: 4.0989, MinusLogProbMetric: 4.0989, val_loss: 4.1367, val_MinusLogProbMetric: 4.1367

Epoch 153: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0989 - MinusLogProbMetric: 4.0989 - val_loss: 4.1367 - val_MinusLogProbMetric: 4.1367 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-12 04:38:16.690 
Epoch 154/1000 
	 loss: 4.1025, MinusLogProbMetric: 4.1025, val_loss: 4.1367, val_MinusLogProbMetric: 4.1367

Epoch 154: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1025 - MinusLogProbMetric: 4.1025 - val_loss: 4.1367 - val_MinusLogProbMetric: 4.1367 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 155/1000
2023-09-12 04:38:28.385 
Epoch 155/1000 
	 loss: 4.1012, MinusLogProbMetric: 4.1012, val_loss: 4.1361, val_MinusLogProbMetric: 4.1361

Epoch 155: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1012 - MinusLogProbMetric: 4.1012 - val_loss: 4.1361 - val_MinusLogProbMetric: 4.1361 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 156/1000
2023-09-12 04:38:40.147 
Epoch 156/1000 
	 loss: 4.1020, MinusLogProbMetric: 4.1020, val_loss: 4.1419, val_MinusLogProbMetric: 4.1419

Epoch 156: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1020 - MinusLogProbMetric: 4.1020 - val_loss: 4.1419 - val_MinusLogProbMetric: 4.1419 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 157/1000
2023-09-12 04:38:51.972 
Epoch 157/1000 
	 loss: 4.1052, MinusLogProbMetric: 4.1052, val_loss: 4.1517, val_MinusLogProbMetric: 4.1517

Epoch 157: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1052 - MinusLogProbMetric: 4.1052 - val_loss: 4.1517 - val_MinusLogProbMetric: 4.1517 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-12 04:39:03.674 
Epoch 158/1000 
	 loss: 4.0999, MinusLogProbMetric: 4.0999, val_loss: 4.1253, val_MinusLogProbMetric: 4.1253

Epoch 158: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0999 - MinusLogProbMetric: 4.0999 - val_loss: 4.1253 - val_MinusLogProbMetric: 4.1253 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 159/1000
2023-09-12 04:39:15.402 
Epoch 159/1000 
	 loss: 4.1003, MinusLogProbMetric: 4.1003, val_loss: 4.1369, val_MinusLogProbMetric: 4.1369

Epoch 159: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1003 - MinusLogProbMetric: 4.1003 - val_loss: 4.1369 - val_MinusLogProbMetric: 4.1369 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-12 04:39:27.172 
Epoch 160/1000 
	 loss: 4.0971, MinusLogProbMetric: 4.0971, val_loss: 4.1518, val_MinusLogProbMetric: 4.1518

Epoch 160: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0971 - MinusLogProbMetric: 4.0971 - val_loss: 4.1518 - val_MinusLogProbMetric: 4.1518 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 161/1000
2023-09-12 04:39:38.805 
Epoch 161/1000 
	 loss: 4.1025, MinusLogProbMetric: 4.1025, val_loss: 4.1591, val_MinusLogProbMetric: 4.1591

Epoch 161: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1025 - MinusLogProbMetric: 4.1025 - val_loss: 4.1591 - val_MinusLogProbMetric: 4.1591 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 162/1000
2023-09-12 04:39:50.492 
Epoch 162/1000 
	 loss: 4.1022, MinusLogProbMetric: 4.1022, val_loss: 4.1497, val_MinusLogProbMetric: 4.1497

Epoch 162: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1022 - MinusLogProbMetric: 4.1022 - val_loss: 4.1497 - val_MinusLogProbMetric: 4.1497 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 163/1000
2023-09-12 04:40:02.131 
Epoch 163/1000 
	 loss: 4.1050, MinusLogProbMetric: 4.1050, val_loss: 4.1488, val_MinusLogProbMetric: 4.1488

Epoch 163: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1050 - MinusLogProbMetric: 4.1050 - val_loss: 4.1488 - val_MinusLogProbMetric: 4.1488 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 164/1000
2023-09-12 04:40:13.730 
Epoch 164/1000 
	 loss: 4.1002, MinusLogProbMetric: 4.1002, val_loss: 4.1414, val_MinusLogProbMetric: 4.1414

Epoch 164: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1002 - MinusLogProbMetric: 4.1002 - val_loss: 4.1414 - val_MinusLogProbMetric: 4.1414 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-12 04:40:25.411 
Epoch 165/1000 
	 loss: 4.1028, MinusLogProbMetric: 4.1028, val_loss: 4.1367, val_MinusLogProbMetric: 4.1367

Epoch 165: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1028 - MinusLogProbMetric: 4.1028 - val_loss: 4.1367 - val_MinusLogProbMetric: 4.1367 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 166/1000
2023-09-12 04:40:37.023 
Epoch 166/1000 
	 loss: 4.0990, MinusLogProbMetric: 4.0990, val_loss: 4.1423, val_MinusLogProbMetric: 4.1423

Epoch 166: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0990 - MinusLogProbMetric: 4.0990 - val_loss: 4.1423 - val_MinusLogProbMetric: 4.1423 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-12 04:40:48.828 
Epoch 167/1000 
	 loss: 4.1030, MinusLogProbMetric: 4.1030, val_loss: 4.1357, val_MinusLogProbMetric: 4.1357

Epoch 167: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1030 - MinusLogProbMetric: 4.1030 - val_loss: 4.1357 - val_MinusLogProbMetric: 4.1357 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 168/1000
2023-09-12 04:41:00.470 
Epoch 168/1000 
	 loss: 4.0983, MinusLogProbMetric: 4.0983, val_loss: 4.1334, val_MinusLogProbMetric: 4.1334

Epoch 168: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0983 - MinusLogProbMetric: 4.0983 - val_loss: 4.1334 - val_MinusLogProbMetric: 4.1334 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 169/1000
2023-09-12 04:41:12.158 
Epoch 169/1000 
	 loss: 4.0957, MinusLogProbMetric: 4.0957, val_loss: 4.1675, val_MinusLogProbMetric: 4.1675

Epoch 169: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0957 - MinusLogProbMetric: 4.0957 - val_loss: 4.1675 - val_MinusLogProbMetric: 4.1675 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 170/1000
2023-09-12 04:41:23.800 
Epoch 170/1000 
	 loss: 4.1043, MinusLogProbMetric: 4.1043, val_loss: 4.1334, val_MinusLogProbMetric: 4.1334

Epoch 170: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1043 - MinusLogProbMetric: 4.1043 - val_loss: 4.1334 - val_MinusLogProbMetric: 4.1334 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 171/1000
2023-09-12 04:41:35.478 
Epoch 171/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.1273, val_MinusLogProbMetric: 4.1273

Epoch 171: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.1273 - val_MinusLogProbMetric: 4.1273 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 172/1000
2023-09-12 04:41:47.228 
Epoch 172/1000 
	 loss: 4.1008, MinusLogProbMetric: 4.1008, val_loss: 4.1342, val_MinusLogProbMetric: 4.1342

Epoch 172: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1008 - MinusLogProbMetric: 4.1008 - val_loss: 4.1342 - val_MinusLogProbMetric: 4.1342 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 173/1000
2023-09-12 04:41:58.939 
Epoch 173/1000 
	 loss: 4.1018, MinusLogProbMetric: 4.1018, val_loss: 4.1245, val_MinusLogProbMetric: 4.1245

Epoch 173: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1018 - MinusLogProbMetric: 4.1018 - val_loss: 4.1245 - val_MinusLogProbMetric: 4.1245 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 174/1000
2023-09-12 04:42:10.655 
Epoch 174/1000 
	 loss: 4.1011, MinusLogProbMetric: 4.1011, val_loss: 4.1440, val_MinusLogProbMetric: 4.1440

Epoch 174: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1011 - MinusLogProbMetric: 4.1011 - val_loss: 4.1440 - val_MinusLogProbMetric: 4.1440 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 175/1000
2023-09-12 04:42:22.372 
Epoch 175/1000 
	 loss: 4.0983, MinusLogProbMetric: 4.0983, val_loss: 4.1376, val_MinusLogProbMetric: 4.1376

Epoch 175: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0983 - MinusLogProbMetric: 4.0983 - val_loss: 4.1376 - val_MinusLogProbMetric: 4.1376 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 176/1000
2023-09-12 04:42:34.135 
Epoch 176/1000 
	 loss: 4.1066, MinusLogProbMetric: 4.1066, val_loss: 4.1534, val_MinusLogProbMetric: 4.1534

Epoch 176: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.1066 - MinusLogProbMetric: 4.1066 - val_loss: 4.1534 - val_MinusLogProbMetric: 4.1534 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-12 04:42:45.946 
Epoch 177/1000 
	 loss: 4.0996, MinusLogProbMetric: 4.0996, val_loss: 4.1609, val_MinusLogProbMetric: 4.1609

Epoch 177: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0996 - MinusLogProbMetric: 4.0996 - val_loss: 4.1609 - val_MinusLogProbMetric: 4.1609 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 178/1000
2023-09-12 04:42:57.616 
Epoch 178/1000 
	 loss: 4.0877, MinusLogProbMetric: 4.0877, val_loss: 4.1280, val_MinusLogProbMetric: 4.1280

Epoch 178: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0877 - MinusLogProbMetric: 4.0877 - val_loss: 4.1280 - val_MinusLogProbMetric: 4.1280 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-12 04:43:09.286 
Epoch 179/1000 
	 loss: 4.0844, MinusLogProbMetric: 4.0844, val_loss: 4.1329, val_MinusLogProbMetric: 4.1329

Epoch 179: val_loss did not improve from 4.12294
196/196 - 12s - loss: 4.0844 - MinusLogProbMetric: 4.0844 - val_loss: 4.1329 - val_MinusLogProbMetric: 4.1329 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 180/1000
2023-09-12 04:43:20.914 
Epoch 180/1000 
	 loss: 4.0814, MinusLogProbMetric: 4.0814, val_loss: 4.1181, val_MinusLogProbMetric: 4.1181

Epoch 180: val_loss improved from 4.12294 to 4.11812, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0814 - MinusLogProbMetric: 4.0814 - val_loss: 4.1181 - val_MinusLogProbMetric: 4.1181 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 181/1000
2023-09-12 04:43:32.636 
Epoch 181/1000 
	 loss: 4.0849, MinusLogProbMetric: 4.0849, val_loss: 4.1281, val_MinusLogProbMetric: 4.1281

Epoch 181: val_loss did not improve from 4.11812
196/196 - 12s - loss: 4.0849 - MinusLogProbMetric: 4.0849 - val_loss: 4.1281 - val_MinusLogProbMetric: 4.1281 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 182/1000
2023-09-12 04:43:44.171 
Epoch 182/1000 
	 loss: 4.0842, MinusLogProbMetric: 4.0842, val_loss: 4.1244, val_MinusLogProbMetric: 4.1244

Epoch 182: val_loss did not improve from 4.11812
196/196 - 12s - loss: 4.0842 - MinusLogProbMetric: 4.0842 - val_loss: 4.1244 - val_MinusLogProbMetric: 4.1244 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 183/1000
2023-09-12 04:43:55.993 
Epoch 183/1000 
	 loss: 4.0819, MinusLogProbMetric: 4.0819, val_loss: 4.1179, val_MinusLogProbMetric: 4.1179

Epoch 183: val_loss improved from 4.11812 to 4.11786, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0819 - MinusLogProbMetric: 4.0819 - val_loss: 4.1179 - val_MinusLogProbMetric: 4.1179 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 184/1000
2023-09-12 04:44:07.922 
Epoch 184/1000 
	 loss: 4.0821, MinusLogProbMetric: 4.0821, val_loss: 4.1247, val_MinusLogProbMetric: 4.1247

Epoch 184: val_loss did not improve from 4.11786
196/196 - 12s - loss: 4.0821 - MinusLogProbMetric: 4.0821 - val_loss: 4.1247 - val_MinusLogProbMetric: 4.1247 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 185/1000
2023-09-12 04:44:19.632 
Epoch 185/1000 
	 loss: 4.0826, MinusLogProbMetric: 4.0826, val_loss: 4.1283, val_MinusLogProbMetric: 4.1283

Epoch 185: val_loss did not improve from 4.11786
196/196 - 12s - loss: 4.0826 - MinusLogProbMetric: 4.0826 - val_loss: 4.1283 - val_MinusLogProbMetric: 4.1283 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 186/1000
2023-09-12 04:44:31.389 
Epoch 186/1000 
	 loss: 4.0817, MinusLogProbMetric: 4.0817, val_loss: 4.1246, val_MinusLogProbMetric: 4.1246

Epoch 186: val_loss did not improve from 4.11786
196/196 - 12s - loss: 4.0817 - MinusLogProbMetric: 4.0817 - val_loss: 4.1246 - val_MinusLogProbMetric: 4.1246 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 187/1000
2023-09-12 04:44:43.180 
Epoch 187/1000 
	 loss: 4.0832, MinusLogProbMetric: 4.0832, val_loss: 4.1289, val_MinusLogProbMetric: 4.1289

Epoch 187: val_loss did not improve from 4.11786
196/196 - 12s - loss: 4.0832 - MinusLogProbMetric: 4.0832 - val_loss: 4.1289 - val_MinusLogProbMetric: 4.1289 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 188/1000
2023-09-12 04:44:54.811 
Epoch 188/1000 
	 loss: 4.0829, MinusLogProbMetric: 4.0829, val_loss: 4.1243, val_MinusLogProbMetric: 4.1243

Epoch 188: val_loss did not improve from 4.11786
196/196 - 12s - loss: 4.0829 - MinusLogProbMetric: 4.0829 - val_loss: 4.1243 - val_MinusLogProbMetric: 4.1243 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 189/1000
2023-09-12 04:45:06.480 
Epoch 189/1000 
	 loss: 4.0820, MinusLogProbMetric: 4.0820, val_loss: 4.1177, val_MinusLogProbMetric: 4.1177

Epoch 189: val_loss improved from 4.11786 to 4.11775, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0820 - MinusLogProbMetric: 4.0820 - val_loss: 4.1177 - val_MinusLogProbMetric: 4.1177 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 190/1000
2023-09-12 04:45:18.211 
Epoch 190/1000 
	 loss: 4.0825, MinusLogProbMetric: 4.0825, val_loss: 4.1229, val_MinusLogProbMetric: 4.1229

Epoch 190: val_loss did not improve from 4.11775
196/196 - 12s - loss: 4.0825 - MinusLogProbMetric: 4.0825 - val_loss: 4.1229 - val_MinusLogProbMetric: 4.1229 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 191/1000
2023-09-12 04:45:30.018 
Epoch 191/1000 
	 loss: 4.0867, MinusLogProbMetric: 4.0867, val_loss: 4.1336, val_MinusLogProbMetric: 4.1336

Epoch 191: val_loss did not improve from 4.11775
196/196 - 12s - loss: 4.0867 - MinusLogProbMetric: 4.0867 - val_loss: 4.1336 - val_MinusLogProbMetric: 4.1336 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 192/1000
2023-09-12 04:45:41.702 
Epoch 192/1000 
	 loss: 4.0834, MinusLogProbMetric: 4.0834, val_loss: 4.1168, val_MinusLogProbMetric: 4.1168

Epoch 192: val_loss improved from 4.11775 to 4.11678, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0834 - MinusLogProbMetric: 4.0834 - val_loss: 4.1168 - val_MinusLogProbMetric: 4.1168 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-12 04:45:53.662 
Epoch 193/1000 
	 loss: 4.0808, MinusLogProbMetric: 4.0808, val_loss: 4.1165, val_MinusLogProbMetric: 4.1165

Epoch 193: val_loss improved from 4.11678 to 4.11649, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0808 - MinusLogProbMetric: 4.0808 - val_loss: 4.1165 - val_MinusLogProbMetric: 4.1165 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 194/1000
2023-09-12 04:46:05.372 
Epoch 194/1000 
	 loss: 4.0826, MinusLogProbMetric: 4.0826, val_loss: 4.1167, val_MinusLogProbMetric: 4.1167

Epoch 194: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0826 - MinusLogProbMetric: 4.0826 - val_loss: 4.1167 - val_MinusLogProbMetric: 4.1167 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 195/1000
2023-09-12 04:46:17.140 
Epoch 195/1000 
	 loss: 4.0831, MinusLogProbMetric: 4.0831, val_loss: 4.1203, val_MinusLogProbMetric: 4.1203

Epoch 195: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0831 - MinusLogProbMetric: 4.0831 - val_loss: 4.1203 - val_MinusLogProbMetric: 4.1203 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-12 04:46:28.910 
Epoch 196/1000 
	 loss: 4.0810, MinusLogProbMetric: 4.0810, val_loss: 4.1324, val_MinusLogProbMetric: 4.1324

Epoch 196: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0810 - MinusLogProbMetric: 4.0810 - val_loss: 4.1324 - val_MinusLogProbMetric: 4.1324 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-12 04:46:40.686 
Epoch 197/1000 
	 loss: 4.0826, MinusLogProbMetric: 4.0826, val_loss: 4.1263, val_MinusLogProbMetric: 4.1263

Epoch 197: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0826 - MinusLogProbMetric: 4.0826 - val_loss: 4.1263 - val_MinusLogProbMetric: 4.1263 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-12 04:46:51.809 
Epoch 198/1000 
	 loss: 4.0821, MinusLogProbMetric: 4.0821, val_loss: 4.1276, val_MinusLogProbMetric: 4.1276

Epoch 198: val_loss did not improve from 4.11649
196/196 - 11s - loss: 4.0821 - MinusLogProbMetric: 4.0821 - val_loss: 4.1276 - val_MinusLogProbMetric: 4.1276 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 199/1000
2023-09-12 04:47:02.006 
Epoch 199/1000 
	 loss: 4.0835, MinusLogProbMetric: 4.0835, val_loss: 4.1212, val_MinusLogProbMetric: 4.1212

Epoch 199: val_loss did not improve from 4.11649
196/196 - 10s - loss: 4.0835 - MinusLogProbMetric: 4.0835 - val_loss: 4.1212 - val_MinusLogProbMetric: 4.1212 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 200/1000
2023-09-12 04:47:12.061 
Epoch 200/1000 
	 loss: 4.0808, MinusLogProbMetric: 4.0808, val_loss: 4.1236, val_MinusLogProbMetric: 4.1236

Epoch 200: val_loss did not improve from 4.11649
196/196 - 10s - loss: 4.0808 - MinusLogProbMetric: 4.0808 - val_loss: 4.1236 - val_MinusLogProbMetric: 4.1236 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 201/1000
2023-09-12 04:47:23.776 
Epoch 201/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1226, val_MinusLogProbMetric: 4.1226

Epoch 201: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1226 - val_MinusLogProbMetric: 4.1226 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-12 04:47:35.458 
Epoch 202/1000 
	 loss: 4.0806, MinusLogProbMetric: 4.0806, val_loss: 4.1224, val_MinusLogProbMetric: 4.1224

Epoch 202: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0806 - MinusLogProbMetric: 4.0806 - val_loss: 4.1224 - val_MinusLogProbMetric: 4.1224 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-12 04:47:47.165 
Epoch 203/1000 
	 loss: 4.0790, MinusLogProbMetric: 4.0790, val_loss: 4.1302, val_MinusLogProbMetric: 4.1302

Epoch 203: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0790 - MinusLogProbMetric: 4.0790 - val_loss: 4.1302 - val_MinusLogProbMetric: 4.1302 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 204/1000
2023-09-12 04:47:59.004 
Epoch 204/1000 
	 loss: 4.0814, MinusLogProbMetric: 4.0814, val_loss: 4.1207, val_MinusLogProbMetric: 4.1207

Epoch 204: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0814 - MinusLogProbMetric: 4.0814 - val_loss: 4.1207 - val_MinusLogProbMetric: 4.1207 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-12 04:48:10.818 
Epoch 205/1000 
	 loss: 4.0873, MinusLogProbMetric: 4.0873, val_loss: 4.1210, val_MinusLogProbMetric: 4.1210

Epoch 205: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0873 - MinusLogProbMetric: 4.0873 - val_loss: 4.1210 - val_MinusLogProbMetric: 4.1210 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 206/1000
2023-09-12 04:48:22.621 
Epoch 206/1000 
	 loss: 4.0809, MinusLogProbMetric: 4.0809, val_loss: 4.1186, val_MinusLogProbMetric: 4.1186

Epoch 206: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0809 - MinusLogProbMetric: 4.0809 - val_loss: 4.1186 - val_MinusLogProbMetric: 4.1186 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 207/1000
2023-09-12 04:48:34.374 
Epoch 207/1000 
	 loss: 4.0809, MinusLogProbMetric: 4.0809, val_loss: 4.1243, val_MinusLogProbMetric: 4.1243

Epoch 207: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0809 - MinusLogProbMetric: 4.0809 - val_loss: 4.1243 - val_MinusLogProbMetric: 4.1243 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-12 04:48:46.170 
Epoch 208/1000 
	 loss: 4.0812, MinusLogProbMetric: 4.0812, val_loss: 4.1260, val_MinusLogProbMetric: 4.1260

Epoch 208: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0812 - MinusLogProbMetric: 4.0812 - val_loss: 4.1260 - val_MinusLogProbMetric: 4.1260 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 209/1000
2023-09-12 04:48:57.973 
Epoch 209/1000 
	 loss: 4.0829, MinusLogProbMetric: 4.0829, val_loss: 4.1258, val_MinusLogProbMetric: 4.1258

Epoch 209: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0829 - MinusLogProbMetric: 4.0829 - val_loss: 4.1258 - val_MinusLogProbMetric: 4.1258 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 210/1000
2023-09-12 04:49:09.697 
Epoch 210/1000 
	 loss: 4.0863, MinusLogProbMetric: 4.0863, val_loss: 4.1209, val_MinusLogProbMetric: 4.1209

Epoch 210: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0863 - MinusLogProbMetric: 4.0863 - val_loss: 4.1209 - val_MinusLogProbMetric: 4.1209 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 211/1000
2023-09-12 04:49:21.467 
Epoch 211/1000 
	 loss: 4.0812, MinusLogProbMetric: 4.0812, val_loss: 4.1177, val_MinusLogProbMetric: 4.1177

Epoch 211: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0812 - MinusLogProbMetric: 4.0812 - val_loss: 4.1177 - val_MinusLogProbMetric: 4.1177 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 212/1000
2023-09-12 04:49:33.252 
Epoch 212/1000 
	 loss: 4.0822, MinusLogProbMetric: 4.0822, val_loss: 4.1215, val_MinusLogProbMetric: 4.1215

Epoch 212: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0822 - MinusLogProbMetric: 4.0822 - val_loss: 4.1215 - val_MinusLogProbMetric: 4.1215 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 213/1000
2023-09-12 04:49:45.056 
Epoch 213/1000 
	 loss: 4.0805, MinusLogProbMetric: 4.0805, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 213: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0805 - MinusLogProbMetric: 4.0805 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 214/1000
2023-09-12 04:49:56.840 
Epoch 214/1000 
	 loss: 4.0828, MinusLogProbMetric: 4.0828, val_loss: 4.1254, val_MinusLogProbMetric: 4.1254

Epoch 214: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0828 - MinusLogProbMetric: 4.0828 - val_loss: 4.1254 - val_MinusLogProbMetric: 4.1254 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-12 04:50:08.654 
Epoch 215/1000 
	 loss: 4.0802, MinusLogProbMetric: 4.0802, val_loss: 4.1217, val_MinusLogProbMetric: 4.1217

Epoch 215: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0802 - MinusLogProbMetric: 4.0802 - val_loss: 4.1217 - val_MinusLogProbMetric: 4.1217 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 216/1000
2023-09-12 04:50:20.434 
Epoch 216/1000 
	 loss: 4.0798, MinusLogProbMetric: 4.0798, val_loss: 4.1290, val_MinusLogProbMetric: 4.1290

Epoch 216: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0798 - MinusLogProbMetric: 4.0798 - val_loss: 4.1290 - val_MinusLogProbMetric: 4.1290 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 217/1000
2023-09-12 04:50:32.326 
Epoch 217/1000 
	 loss: 4.0816, MinusLogProbMetric: 4.0816, val_loss: 4.1204, val_MinusLogProbMetric: 4.1204

Epoch 217: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0816 - MinusLogProbMetric: 4.0816 - val_loss: 4.1204 - val_MinusLogProbMetric: 4.1204 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 218/1000
2023-09-12 04:50:44.105 
Epoch 218/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1264, val_MinusLogProbMetric: 4.1264

Epoch 218: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1264 - val_MinusLogProbMetric: 4.1264 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-12 04:50:55.964 
Epoch 219/1000 
	 loss: 4.0805, MinusLogProbMetric: 4.0805, val_loss: 4.1264, val_MinusLogProbMetric: 4.1264

Epoch 219: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0805 - MinusLogProbMetric: 4.0805 - val_loss: 4.1264 - val_MinusLogProbMetric: 4.1264 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 220/1000
2023-09-12 04:51:07.674 
Epoch 220/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1229, val_MinusLogProbMetric: 4.1229

Epoch 220: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1229 - val_MinusLogProbMetric: 4.1229 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 221/1000
2023-09-12 04:51:19.436 
Epoch 221/1000 
	 loss: 4.0806, MinusLogProbMetric: 4.0806, val_loss: 4.1205, val_MinusLogProbMetric: 4.1205

Epoch 221: val_loss did not improve from 4.11649
196/196 - 12s - loss: 4.0806 - MinusLogProbMetric: 4.0806 - val_loss: 4.1205 - val_MinusLogProbMetric: 4.1205 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-12 04:51:31.284 
Epoch 222/1000 
	 loss: 4.0792, MinusLogProbMetric: 4.0792, val_loss: 4.1153, val_MinusLogProbMetric: 4.1153

Epoch 222: val_loss improved from 4.11649 to 4.11530, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0792 - MinusLogProbMetric: 4.0792 - val_loss: 4.1153 - val_MinusLogProbMetric: 4.1153 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 223/1000
2023-09-12 04:51:43.190 
Epoch 223/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1232, val_MinusLogProbMetric: 4.1232

Epoch 223: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1232 - val_MinusLogProbMetric: 4.1232 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 224/1000
2023-09-12 04:51:55.003 
Epoch 224/1000 
	 loss: 4.0785, MinusLogProbMetric: 4.0785, val_loss: 4.1237, val_MinusLogProbMetric: 4.1237

Epoch 224: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0785 - MinusLogProbMetric: 4.0785 - val_loss: 4.1237 - val_MinusLogProbMetric: 4.1237 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-12 04:52:06.752 
Epoch 225/1000 
	 loss: 4.0829, MinusLogProbMetric: 4.0829, val_loss: 4.1394, val_MinusLogProbMetric: 4.1394

Epoch 225: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0829 - MinusLogProbMetric: 4.0829 - val_loss: 4.1394 - val_MinusLogProbMetric: 4.1394 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-12 04:52:18.540 
Epoch 226/1000 
	 loss: 4.0867, MinusLogProbMetric: 4.0867, val_loss: 4.1237, val_MinusLogProbMetric: 4.1237

Epoch 226: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0867 - MinusLogProbMetric: 4.0867 - val_loss: 4.1237 - val_MinusLogProbMetric: 4.1237 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 227/1000
2023-09-12 04:52:30.288 
Epoch 227/1000 
	 loss: 4.0811, MinusLogProbMetric: 4.0811, val_loss: 4.1265, val_MinusLogProbMetric: 4.1265

Epoch 227: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0811 - MinusLogProbMetric: 4.0811 - val_loss: 4.1265 - val_MinusLogProbMetric: 4.1265 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 228/1000
2023-09-12 04:52:41.898 
Epoch 228/1000 
	 loss: 4.0798, MinusLogProbMetric: 4.0798, val_loss: 4.1264, val_MinusLogProbMetric: 4.1264

Epoch 228: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0798 - MinusLogProbMetric: 4.0798 - val_loss: 4.1264 - val_MinusLogProbMetric: 4.1264 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 229/1000
2023-09-12 04:52:53.680 
Epoch 229/1000 
	 loss: 4.0806, MinusLogProbMetric: 4.0806, val_loss: 4.1195, val_MinusLogProbMetric: 4.1195

Epoch 229: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0806 - MinusLogProbMetric: 4.0806 - val_loss: 4.1195 - val_MinusLogProbMetric: 4.1195 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-12 04:53:05.494 
Epoch 230/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1248, val_MinusLogProbMetric: 4.1248

Epoch 230: val_loss did not improve from 4.11530
196/196 - 12s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1248 - val_MinusLogProbMetric: 4.1248 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 231/1000
2023-09-12 04:53:17.197 
Epoch 231/1000 
	 loss: 4.0801, MinusLogProbMetric: 4.0801, val_loss: 4.1151, val_MinusLogProbMetric: 4.1151

Epoch 231: val_loss improved from 4.11530 to 4.11509, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0801 - MinusLogProbMetric: 4.0801 - val_loss: 4.1151 - val_MinusLogProbMetric: 4.1151 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 232/1000
2023-09-12 04:53:28.964 
Epoch 232/1000 
	 loss: 4.0790, MinusLogProbMetric: 4.0790, val_loss: 4.1221, val_MinusLogProbMetric: 4.1221

Epoch 232: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0790 - MinusLogProbMetric: 4.0790 - val_loss: 4.1221 - val_MinusLogProbMetric: 4.1221 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 233/1000
2023-09-12 04:53:40.679 
Epoch 233/1000 
	 loss: 4.0830, MinusLogProbMetric: 4.0830, val_loss: 4.1186, val_MinusLogProbMetric: 4.1186

Epoch 233: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0830 - MinusLogProbMetric: 4.0830 - val_loss: 4.1186 - val_MinusLogProbMetric: 4.1186 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 234/1000
2023-09-12 04:53:52.430 
Epoch 234/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1488, val_MinusLogProbMetric: 4.1488

Epoch 234: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1488 - val_MinusLogProbMetric: 4.1488 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-12 04:54:04.234 
Epoch 235/1000 
	 loss: 4.0831, MinusLogProbMetric: 4.0831, val_loss: 4.1298, val_MinusLogProbMetric: 4.1298

Epoch 235: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0831 - MinusLogProbMetric: 4.0831 - val_loss: 4.1298 - val_MinusLogProbMetric: 4.1298 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 236/1000
2023-09-12 04:54:16.013 
Epoch 236/1000 
	 loss: 4.0811, MinusLogProbMetric: 4.0811, val_loss: 4.1243, val_MinusLogProbMetric: 4.1243

Epoch 236: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0811 - MinusLogProbMetric: 4.0811 - val_loss: 4.1243 - val_MinusLogProbMetric: 4.1243 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 237/1000
2023-09-12 04:54:27.772 
Epoch 237/1000 
	 loss: 4.0782, MinusLogProbMetric: 4.0782, val_loss: 4.1264, val_MinusLogProbMetric: 4.1264

Epoch 237: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0782 - MinusLogProbMetric: 4.0782 - val_loss: 4.1264 - val_MinusLogProbMetric: 4.1264 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 238/1000
2023-09-12 04:54:39.666 
Epoch 238/1000 
	 loss: 4.0813, MinusLogProbMetric: 4.0813, val_loss: 4.1290, val_MinusLogProbMetric: 4.1290

Epoch 238: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0813 - MinusLogProbMetric: 4.0813 - val_loss: 4.1290 - val_MinusLogProbMetric: 4.1290 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 239/1000
2023-09-12 04:54:51.398 
Epoch 239/1000 
	 loss: 4.0791, MinusLogProbMetric: 4.0791, val_loss: 4.1281, val_MinusLogProbMetric: 4.1281

Epoch 239: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0791 - MinusLogProbMetric: 4.0791 - val_loss: 4.1281 - val_MinusLogProbMetric: 4.1281 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 240/1000
2023-09-12 04:55:03.147 
Epoch 240/1000 
	 loss: 4.0806, MinusLogProbMetric: 4.0806, val_loss: 4.1191, val_MinusLogProbMetric: 4.1191

Epoch 240: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0806 - MinusLogProbMetric: 4.0806 - val_loss: 4.1191 - val_MinusLogProbMetric: 4.1191 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-12 04:55:14.905 
Epoch 241/1000 
	 loss: 4.0800, MinusLogProbMetric: 4.0800, val_loss: 4.1220, val_MinusLogProbMetric: 4.1220

Epoch 241: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0800 - MinusLogProbMetric: 4.0800 - val_loss: 4.1220 - val_MinusLogProbMetric: 4.1220 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 242/1000
2023-09-12 04:55:26.587 
Epoch 242/1000 
	 loss: 4.0792, MinusLogProbMetric: 4.0792, val_loss: 4.1197, val_MinusLogProbMetric: 4.1197

Epoch 242: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0792 - MinusLogProbMetric: 4.0792 - val_loss: 4.1197 - val_MinusLogProbMetric: 4.1197 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 243/1000
2023-09-12 04:55:38.311 
Epoch 243/1000 
	 loss: 4.0798, MinusLogProbMetric: 4.0798, val_loss: 4.1294, val_MinusLogProbMetric: 4.1294

Epoch 243: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0798 - MinusLogProbMetric: 4.0798 - val_loss: 4.1294 - val_MinusLogProbMetric: 4.1294 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 244/1000
2023-09-12 04:55:50.150 
Epoch 244/1000 
	 loss: 4.0776, MinusLogProbMetric: 4.0776, val_loss: 4.1153, val_MinusLogProbMetric: 4.1153

Epoch 244: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0776 - MinusLogProbMetric: 4.0776 - val_loss: 4.1153 - val_MinusLogProbMetric: 4.1153 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 245/1000
2023-09-12 04:56:01.948 
Epoch 245/1000 
	 loss: 4.0775, MinusLogProbMetric: 4.0775, val_loss: 4.1231, val_MinusLogProbMetric: 4.1231

Epoch 245: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0775 - MinusLogProbMetric: 4.0775 - val_loss: 4.1231 - val_MinusLogProbMetric: 4.1231 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 246/1000
2023-09-12 04:56:13.605 
Epoch 246/1000 
	 loss: 4.0783, MinusLogProbMetric: 4.0783, val_loss: 4.1245, val_MinusLogProbMetric: 4.1245

Epoch 246: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0783 - MinusLogProbMetric: 4.0783 - val_loss: 4.1245 - val_MinusLogProbMetric: 4.1245 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 247/1000
2023-09-12 04:56:25.417 
Epoch 247/1000 
	 loss: 4.0817, MinusLogProbMetric: 4.0817, val_loss: 4.1213, val_MinusLogProbMetric: 4.1213

Epoch 247: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0817 - MinusLogProbMetric: 4.0817 - val_loss: 4.1213 - val_MinusLogProbMetric: 4.1213 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-12 04:56:37.214 
Epoch 248/1000 
	 loss: 4.0781, MinusLogProbMetric: 4.0781, val_loss: 4.1228, val_MinusLogProbMetric: 4.1228

Epoch 248: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0781 - MinusLogProbMetric: 4.0781 - val_loss: 4.1228 - val_MinusLogProbMetric: 4.1228 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-12 04:56:48.922 
Epoch 249/1000 
	 loss: 4.0811, MinusLogProbMetric: 4.0811, val_loss: 4.1281, val_MinusLogProbMetric: 4.1281

Epoch 249: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0811 - MinusLogProbMetric: 4.0811 - val_loss: 4.1281 - val_MinusLogProbMetric: 4.1281 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 250/1000
2023-09-12 04:57:00.681 
Epoch 250/1000 
	 loss: 4.0818, MinusLogProbMetric: 4.0818, val_loss: 4.1269, val_MinusLogProbMetric: 4.1269

Epoch 250: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0818 - MinusLogProbMetric: 4.0818 - val_loss: 4.1269 - val_MinusLogProbMetric: 4.1269 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-12 04:57:12.436 
Epoch 251/1000 
	 loss: 4.0799, MinusLogProbMetric: 4.0799, val_loss: 4.1241, val_MinusLogProbMetric: 4.1241

Epoch 251: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0799 - MinusLogProbMetric: 4.0799 - val_loss: 4.1241 - val_MinusLogProbMetric: 4.1241 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 252/1000
2023-09-12 04:57:24.104 
Epoch 252/1000 
	 loss: 4.0781, MinusLogProbMetric: 4.0781, val_loss: 4.1233, val_MinusLogProbMetric: 4.1233

Epoch 252: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0781 - MinusLogProbMetric: 4.0781 - val_loss: 4.1233 - val_MinusLogProbMetric: 4.1233 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-12 04:57:35.859 
Epoch 253/1000 
	 loss: 4.0779, MinusLogProbMetric: 4.0779, val_loss: 4.1241, val_MinusLogProbMetric: 4.1241

Epoch 253: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0779 - MinusLogProbMetric: 4.0779 - val_loss: 4.1241 - val_MinusLogProbMetric: 4.1241 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 254/1000
2023-09-12 04:57:47.696 
Epoch 254/1000 
	 loss: 4.0790, MinusLogProbMetric: 4.0790, val_loss: 4.1166, val_MinusLogProbMetric: 4.1166

Epoch 254: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0790 - MinusLogProbMetric: 4.0790 - val_loss: 4.1166 - val_MinusLogProbMetric: 4.1166 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-12 04:57:59.430 
Epoch 255/1000 
	 loss: 4.0803, MinusLogProbMetric: 4.0803, val_loss: 4.1265, val_MinusLogProbMetric: 4.1265

Epoch 255: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0803 - MinusLogProbMetric: 4.0803 - val_loss: 4.1265 - val_MinusLogProbMetric: 4.1265 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 256/1000
2023-09-12 04:58:11.427 
Epoch 256/1000 
	 loss: 4.0795, MinusLogProbMetric: 4.0795, val_loss: 4.1250, val_MinusLogProbMetric: 4.1250

Epoch 256: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0795 - MinusLogProbMetric: 4.0795 - val_loss: 4.1250 - val_MinusLogProbMetric: 4.1250 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 257/1000
2023-09-12 04:58:23.264 
Epoch 257/1000 
	 loss: 4.0831, MinusLogProbMetric: 4.0831, val_loss: 4.1230, val_MinusLogProbMetric: 4.1230

Epoch 257: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0831 - MinusLogProbMetric: 4.0831 - val_loss: 4.1230 - val_MinusLogProbMetric: 4.1230 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-12 04:58:34.981 
Epoch 258/1000 
	 loss: 4.0791, MinusLogProbMetric: 4.0791, val_loss: 4.1207, val_MinusLogProbMetric: 4.1207

Epoch 258: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0791 - MinusLogProbMetric: 4.0791 - val_loss: 4.1207 - val_MinusLogProbMetric: 4.1207 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 259/1000
2023-09-12 04:58:46.720 
Epoch 259/1000 
	 loss: 4.0829, MinusLogProbMetric: 4.0829, val_loss: 4.1247, val_MinusLogProbMetric: 4.1247

Epoch 259: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0829 - MinusLogProbMetric: 4.0829 - val_loss: 4.1247 - val_MinusLogProbMetric: 4.1247 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 260/1000
2023-09-12 04:58:58.496 
Epoch 260/1000 
	 loss: 4.0783, MinusLogProbMetric: 4.0783, val_loss: 4.1259, val_MinusLogProbMetric: 4.1259

Epoch 260: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0783 - MinusLogProbMetric: 4.0783 - val_loss: 4.1259 - val_MinusLogProbMetric: 4.1259 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 261/1000
2023-09-12 04:59:10.300 
Epoch 261/1000 
	 loss: 4.0807, MinusLogProbMetric: 4.0807, val_loss: 4.1354, val_MinusLogProbMetric: 4.1354

Epoch 261: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0807 - MinusLogProbMetric: 4.0807 - val_loss: 4.1354 - val_MinusLogProbMetric: 4.1354 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 262/1000
2023-09-12 04:59:22.084 
Epoch 262/1000 
	 loss: 4.0831, MinusLogProbMetric: 4.0831, val_loss: 4.1389, val_MinusLogProbMetric: 4.1389

Epoch 262: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0831 - MinusLogProbMetric: 4.0831 - val_loss: 4.1389 - val_MinusLogProbMetric: 4.1389 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-12 04:59:33.888 
Epoch 263/1000 
	 loss: 4.0847, MinusLogProbMetric: 4.0847, val_loss: 4.1245, val_MinusLogProbMetric: 4.1245

Epoch 263: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0847 - MinusLogProbMetric: 4.0847 - val_loss: 4.1245 - val_MinusLogProbMetric: 4.1245 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 264/1000
2023-09-12 04:59:45.812 
Epoch 264/1000 
	 loss: 4.0811, MinusLogProbMetric: 4.0811, val_loss: 4.1286, val_MinusLogProbMetric: 4.1286

Epoch 264: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0811 - MinusLogProbMetric: 4.0811 - val_loss: 4.1286 - val_MinusLogProbMetric: 4.1286 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 265/1000
2023-09-12 04:59:57.575 
Epoch 265/1000 
	 loss: 4.0790, MinusLogProbMetric: 4.0790, val_loss: 4.1356, val_MinusLogProbMetric: 4.1356

Epoch 265: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0790 - MinusLogProbMetric: 4.0790 - val_loss: 4.1356 - val_MinusLogProbMetric: 4.1356 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 266/1000
2023-09-12 05:00:09.172 
Epoch 266/1000 
	 loss: 4.0788, MinusLogProbMetric: 4.0788, val_loss: 4.1206, val_MinusLogProbMetric: 4.1206

Epoch 266: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0788 - MinusLogProbMetric: 4.0788 - val_loss: 4.1206 - val_MinusLogProbMetric: 4.1206 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 267/1000
2023-09-12 05:00:20.841 
Epoch 267/1000 
	 loss: 4.0800, MinusLogProbMetric: 4.0800, val_loss: 4.1193, val_MinusLogProbMetric: 4.1193

Epoch 267: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0800 - MinusLogProbMetric: 4.0800 - val_loss: 4.1193 - val_MinusLogProbMetric: 4.1193 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 268/1000
2023-09-12 05:00:32.519 
Epoch 268/1000 
	 loss: 4.0791, MinusLogProbMetric: 4.0791, val_loss: 4.1267, val_MinusLogProbMetric: 4.1267

Epoch 268: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0791 - MinusLogProbMetric: 4.0791 - val_loss: 4.1267 - val_MinusLogProbMetric: 4.1267 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-12 05:00:44.306 
Epoch 269/1000 
	 loss: 4.0779, MinusLogProbMetric: 4.0779, val_loss: 4.1349, val_MinusLogProbMetric: 4.1349

Epoch 269: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0779 - MinusLogProbMetric: 4.0779 - val_loss: 4.1349 - val_MinusLogProbMetric: 4.1349 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 270/1000
2023-09-12 05:00:56.018 
Epoch 270/1000 
	 loss: 4.0836, MinusLogProbMetric: 4.0836, val_loss: 4.1194, val_MinusLogProbMetric: 4.1194

Epoch 270: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0836 - MinusLogProbMetric: 4.0836 - val_loss: 4.1194 - val_MinusLogProbMetric: 4.1194 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 271/1000
2023-09-12 05:01:07.775 
Epoch 271/1000 
	 loss: 4.0787, MinusLogProbMetric: 4.0787, val_loss: 4.1227, val_MinusLogProbMetric: 4.1227

Epoch 271: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0787 - MinusLogProbMetric: 4.0787 - val_loss: 4.1227 - val_MinusLogProbMetric: 4.1227 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-12 05:01:19.520 
Epoch 272/1000 
	 loss: 4.0780, MinusLogProbMetric: 4.0780, val_loss: 4.1351, val_MinusLogProbMetric: 4.1351

Epoch 272: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0780 - MinusLogProbMetric: 4.0780 - val_loss: 4.1351 - val_MinusLogProbMetric: 4.1351 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 273/1000
2023-09-12 05:01:31.216 
Epoch 273/1000 
	 loss: 4.0767, MinusLogProbMetric: 4.0767, val_loss: 4.1183, val_MinusLogProbMetric: 4.1183

Epoch 273: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0767 - MinusLogProbMetric: 4.0767 - val_loss: 4.1183 - val_MinusLogProbMetric: 4.1183 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 274/1000
2023-09-12 05:01:42.852 
Epoch 274/1000 
	 loss: 4.0788, MinusLogProbMetric: 4.0788, val_loss: 4.1196, val_MinusLogProbMetric: 4.1196

Epoch 274: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0788 - MinusLogProbMetric: 4.0788 - val_loss: 4.1196 - val_MinusLogProbMetric: 4.1196 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 275/1000
2023-09-12 05:01:54.665 
Epoch 275/1000 
	 loss: 4.0789, MinusLogProbMetric: 4.0789, val_loss: 4.1160, val_MinusLogProbMetric: 4.1160

Epoch 275: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0789 - MinusLogProbMetric: 4.0789 - val_loss: 4.1160 - val_MinusLogProbMetric: 4.1160 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 276/1000
2023-09-12 05:02:06.267 
Epoch 276/1000 
	 loss: 4.0777, MinusLogProbMetric: 4.0777, val_loss: 4.1206, val_MinusLogProbMetric: 4.1206

Epoch 276: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0777 - MinusLogProbMetric: 4.0777 - val_loss: 4.1206 - val_MinusLogProbMetric: 4.1206 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 277/1000
2023-09-12 05:02:18.009 
Epoch 277/1000 
	 loss: 4.0778, MinusLogProbMetric: 4.0778, val_loss: 4.1314, val_MinusLogProbMetric: 4.1314

Epoch 277: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0778 - MinusLogProbMetric: 4.0778 - val_loss: 4.1314 - val_MinusLogProbMetric: 4.1314 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 278/1000
2023-09-12 05:02:29.793 
Epoch 278/1000 
	 loss: 4.0761, MinusLogProbMetric: 4.0761, val_loss: 4.1550, val_MinusLogProbMetric: 4.1550

Epoch 278: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0761 - MinusLogProbMetric: 4.0761 - val_loss: 4.1550 - val_MinusLogProbMetric: 4.1550 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 279/1000
2023-09-12 05:02:41.607 
Epoch 279/1000 
	 loss: 4.0830, MinusLogProbMetric: 4.0830, val_loss: 4.1224, val_MinusLogProbMetric: 4.1224

Epoch 279: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0830 - MinusLogProbMetric: 4.0830 - val_loss: 4.1224 - val_MinusLogProbMetric: 4.1224 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 280/1000
2023-09-12 05:02:53.338 
Epoch 280/1000 
	 loss: 4.0790, MinusLogProbMetric: 4.0790, val_loss: 4.1196, val_MinusLogProbMetric: 4.1196

Epoch 280: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0790 - MinusLogProbMetric: 4.0790 - val_loss: 4.1196 - val_MinusLogProbMetric: 4.1196 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-12 05:03:05.011 
Epoch 281/1000 
	 loss: 4.0791, MinusLogProbMetric: 4.0791, val_loss: 4.1345, val_MinusLogProbMetric: 4.1345

Epoch 281: val_loss did not improve from 4.11509
196/196 - 12s - loss: 4.0791 - MinusLogProbMetric: 4.0791 - val_loss: 4.1345 - val_MinusLogProbMetric: 4.1345 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 282/1000
2023-09-12 05:03:16.835 
Epoch 282/1000 
	 loss: 4.0740, MinusLogProbMetric: 4.0740, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 282: val_loss improved from 4.11509 to 4.11313, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0740 - MinusLogProbMetric: 4.0740 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 283/1000
2023-09-12 05:03:28.694 
Epoch 283/1000 
	 loss: 4.0704, MinusLogProbMetric: 4.0704, val_loss: 4.1140, val_MinusLogProbMetric: 4.1140

Epoch 283: val_loss did not improve from 4.11313
196/196 - 12s - loss: 4.0704 - MinusLogProbMetric: 4.0704 - val_loss: 4.1140 - val_MinusLogProbMetric: 4.1140 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-12 05:03:40.315 
Epoch 284/1000 
	 loss: 4.0721, MinusLogProbMetric: 4.0721, val_loss: 4.1143, val_MinusLogProbMetric: 4.1143

Epoch 284: val_loss did not improve from 4.11313
196/196 - 12s - loss: 4.0721 - MinusLogProbMetric: 4.0721 - val_loss: 4.1143 - val_MinusLogProbMetric: 4.1143 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 285/1000
2023-09-12 05:03:51.901 
Epoch 285/1000 
	 loss: 4.0712, MinusLogProbMetric: 4.0712, val_loss: 4.1162, val_MinusLogProbMetric: 4.1162

Epoch 285: val_loss did not improve from 4.11313
196/196 - 12s - loss: 4.0712 - MinusLogProbMetric: 4.0712 - val_loss: 4.1162 - val_MinusLogProbMetric: 4.1162 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 286/1000
2023-09-12 05:04:02.631 
Epoch 286/1000 
	 loss: 4.0704, MinusLogProbMetric: 4.0704, val_loss: 4.1135, val_MinusLogProbMetric: 4.1135

Epoch 286: val_loss did not improve from 4.11313
196/196 - 11s - loss: 4.0704 - MinusLogProbMetric: 4.0704 - val_loss: 4.1135 - val_MinusLogProbMetric: 4.1135 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 287/1000
2023-09-12 05:04:14.107 
Epoch 287/1000 
	 loss: 4.0707, MinusLogProbMetric: 4.0707, val_loss: 4.1158, val_MinusLogProbMetric: 4.1158

Epoch 287: val_loss did not improve from 4.11313
196/196 - 11s - loss: 4.0707 - MinusLogProbMetric: 4.0707 - val_loss: 4.1158 - val_MinusLogProbMetric: 4.1158 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 288/1000
2023-09-12 05:04:25.112 
Epoch 288/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1164, val_MinusLogProbMetric: 4.1164

Epoch 288: val_loss did not improve from 4.11313
196/196 - 11s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1164 - val_MinusLogProbMetric: 4.1164 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 289/1000
2023-09-12 05:04:35.213 
Epoch 289/1000 
	 loss: 4.0721, MinusLogProbMetric: 4.0721, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 289: val_loss did not improve from 4.11313
196/196 - 10s - loss: 4.0721 - MinusLogProbMetric: 4.0721 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 290/1000
2023-09-12 05:04:46.534 
Epoch 290/1000 
	 loss: 4.0691, MinusLogProbMetric: 4.0691, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 290: val_loss did not improve from 4.11313
196/196 - 11s - loss: 4.0691 - MinusLogProbMetric: 4.0691 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 291/1000
2023-09-12 05:04:58.328 
Epoch 291/1000 
	 loss: 4.0703, MinusLogProbMetric: 4.0703, val_loss: 4.1181, val_MinusLogProbMetric: 4.1181

Epoch 291: val_loss did not improve from 4.11313
196/196 - 12s - loss: 4.0703 - MinusLogProbMetric: 4.0703 - val_loss: 4.1181 - val_MinusLogProbMetric: 4.1181 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 292/1000
2023-09-12 05:05:10.179 
Epoch 292/1000 
	 loss: 4.0695, MinusLogProbMetric: 4.0695, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 292: val_loss improved from 4.11313 to 4.11262, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0695 - MinusLogProbMetric: 4.0695 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 293/1000
2023-09-12 05:05:22.098 
Epoch 293/1000 
	 loss: 4.0703, MinusLogProbMetric: 4.0703, val_loss: 4.1160, val_MinusLogProbMetric: 4.1160

Epoch 293: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0703 - MinusLogProbMetric: 4.0703 - val_loss: 4.1160 - val_MinusLogProbMetric: 4.1160 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 294/1000
2023-09-12 05:05:33.848 
Epoch 294/1000 
	 loss: 4.0698, MinusLogProbMetric: 4.0698, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 294: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0698 - MinusLogProbMetric: 4.0698 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 295/1000
2023-09-12 05:05:45.613 
Epoch 295/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1287, val_MinusLogProbMetric: 4.1287

Epoch 295: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1287 - val_MinusLogProbMetric: 4.1287 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 296/1000
2023-09-12 05:05:57.473 
Epoch 296/1000 
	 loss: 4.0707, MinusLogProbMetric: 4.0707, val_loss: 4.1181, val_MinusLogProbMetric: 4.1181

Epoch 296: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0707 - MinusLogProbMetric: 4.0707 - val_loss: 4.1181 - val_MinusLogProbMetric: 4.1181 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 297/1000
2023-09-12 05:06:09.291 
Epoch 297/1000 
	 loss: 4.0705, MinusLogProbMetric: 4.0705, val_loss: 4.1174, val_MinusLogProbMetric: 4.1174

Epoch 297: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0705 - MinusLogProbMetric: 4.0705 - val_loss: 4.1174 - val_MinusLogProbMetric: 4.1174 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 298/1000
2023-09-12 05:06:20.986 
Epoch 298/1000 
	 loss: 4.0714, MinusLogProbMetric: 4.0714, val_loss: 4.1190, val_MinusLogProbMetric: 4.1190

Epoch 298: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0714 - MinusLogProbMetric: 4.0714 - val_loss: 4.1190 - val_MinusLogProbMetric: 4.1190 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 299/1000
2023-09-12 05:06:32.821 
Epoch 299/1000 
	 loss: 4.0700, MinusLogProbMetric: 4.0700, val_loss: 4.1143, val_MinusLogProbMetric: 4.1143

Epoch 299: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0700 - MinusLogProbMetric: 4.0700 - val_loss: 4.1143 - val_MinusLogProbMetric: 4.1143 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 300/1000
2023-09-12 05:06:44.627 
Epoch 300/1000 
	 loss: 4.0698, MinusLogProbMetric: 4.0698, val_loss: 4.1181, val_MinusLogProbMetric: 4.1181

Epoch 300: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0698 - MinusLogProbMetric: 4.0698 - val_loss: 4.1181 - val_MinusLogProbMetric: 4.1181 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 301/1000
2023-09-12 05:06:56.288 
Epoch 301/1000 
	 loss: 4.0703, MinusLogProbMetric: 4.0703, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 301: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0703 - MinusLogProbMetric: 4.0703 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 302/1000
2023-09-12 05:07:07.950 
Epoch 302/1000 
	 loss: 4.0705, MinusLogProbMetric: 4.0705, val_loss: 4.1148, val_MinusLogProbMetric: 4.1148

Epoch 302: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0705 - MinusLogProbMetric: 4.0705 - val_loss: 4.1148 - val_MinusLogProbMetric: 4.1148 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 303/1000
2023-09-12 05:07:19.787 
Epoch 303/1000 
	 loss: 4.0696, MinusLogProbMetric: 4.0696, val_loss: 4.1142, val_MinusLogProbMetric: 4.1142

Epoch 303: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0696 - MinusLogProbMetric: 4.0696 - val_loss: 4.1142 - val_MinusLogProbMetric: 4.1142 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 304/1000
2023-09-12 05:07:31.488 
Epoch 304/1000 
	 loss: 4.0705, MinusLogProbMetric: 4.0705, val_loss: 4.1141, val_MinusLogProbMetric: 4.1141

Epoch 304: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0705 - MinusLogProbMetric: 4.0705 - val_loss: 4.1141 - val_MinusLogProbMetric: 4.1141 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 305/1000
2023-09-12 05:07:43.300 
Epoch 305/1000 
	 loss: 4.0699, MinusLogProbMetric: 4.0699, val_loss: 4.1203, val_MinusLogProbMetric: 4.1203

Epoch 305: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0699 - MinusLogProbMetric: 4.0699 - val_loss: 4.1203 - val_MinusLogProbMetric: 4.1203 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 306/1000
2023-09-12 05:07:55.138 
Epoch 306/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1195, val_MinusLogProbMetric: 4.1195

Epoch 306: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1195 - val_MinusLogProbMetric: 4.1195 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 307/1000
2023-09-12 05:08:06.877 
Epoch 307/1000 
	 loss: 4.0692, MinusLogProbMetric: 4.0692, val_loss: 4.1172, val_MinusLogProbMetric: 4.1172

Epoch 307: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0692 - MinusLogProbMetric: 4.0692 - val_loss: 4.1172 - val_MinusLogProbMetric: 4.1172 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 308/1000
2023-09-12 05:08:18.589 
Epoch 308/1000 
	 loss: 4.0699, MinusLogProbMetric: 4.0699, val_loss: 4.1183, val_MinusLogProbMetric: 4.1183

Epoch 308: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0699 - MinusLogProbMetric: 4.0699 - val_loss: 4.1183 - val_MinusLogProbMetric: 4.1183 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 309/1000
2023-09-12 05:08:30.330 
Epoch 309/1000 
	 loss: 4.0711, MinusLogProbMetric: 4.0711, val_loss: 4.1148, val_MinusLogProbMetric: 4.1148

Epoch 309: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0711 - MinusLogProbMetric: 4.0711 - val_loss: 4.1148 - val_MinusLogProbMetric: 4.1148 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 310/1000
2023-09-12 05:08:42.112 
Epoch 310/1000 
	 loss: 4.0706, MinusLogProbMetric: 4.0706, val_loss: 4.1188, val_MinusLogProbMetric: 4.1188

Epoch 310: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0706 - MinusLogProbMetric: 4.0706 - val_loss: 4.1188 - val_MinusLogProbMetric: 4.1188 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 311/1000
2023-09-12 05:08:54.051 
Epoch 311/1000 
	 loss: 4.0697, MinusLogProbMetric: 4.0697, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 311: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0697 - MinusLogProbMetric: 4.0697 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 312/1000
2023-09-12 05:09:05.950 
Epoch 312/1000 
	 loss: 4.0694, MinusLogProbMetric: 4.0694, val_loss: 4.1191, val_MinusLogProbMetric: 4.1191

Epoch 312: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0694 - MinusLogProbMetric: 4.0694 - val_loss: 4.1191 - val_MinusLogProbMetric: 4.1191 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 313/1000
2023-09-12 05:09:17.737 
Epoch 313/1000 
	 loss: 4.0698, MinusLogProbMetric: 4.0698, val_loss: 4.1135, val_MinusLogProbMetric: 4.1135

Epoch 313: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0698 - MinusLogProbMetric: 4.0698 - val_loss: 4.1135 - val_MinusLogProbMetric: 4.1135 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 314/1000
2023-09-12 05:09:29.425 
Epoch 314/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1184, val_MinusLogProbMetric: 4.1184

Epoch 314: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1184 - val_MinusLogProbMetric: 4.1184 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 315/1000
2023-09-12 05:09:41.114 
Epoch 315/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.1144, val_MinusLogProbMetric: 4.1144

Epoch 315: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.1144 - val_MinusLogProbMetric: 4.1144 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-12 05:09:52.926 
Epoch 316/1000 
	 loss: 4.0703, MinusLogProbMetric: 4.0703, val_loss: 4.1150, val_MinusLogProbMetric: 4.1150

Epoch 316: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0703 - MinusLogProbMetric: 4.0703 - val_loss: 4.1150 - val_MinusLogProbMetric: 4.1150 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 317/1000
2023-09-12 05:10:04.708 
Epoch 317/1000 
	 loss: 4.0692, MinusLogProbMetric: 4.0692, val_loss: 4.1210, val_MinusLogProbMetric: 4.1210

Epoch 317: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0692 - MinusLogProbMetric: 4.0692 - val_loss: 4.1210 - val_MinusLogProbMetric: 4.1210 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 318/1000
2023-09-12 05:10:16.432 
Epoch 318/1000 
	 loss: 4.0694, MinusLogProbMetric: 4.0694, val_loss: 4.1148, val_MinusLogProbMetric: 4.1148

Epoch 318: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0694 - MinusLogProbMetric: 4.0694 - val_loss: 4.1148 - val_MinusLogProbMetric: 4.1148 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 319/1000
2023-09-12 05:10:28.269 
Epoch 319/1000 
	 loss: 4.0704, MinusLogProbMetric: 4.0704, val_loss: 4.1171, val_MinusLogProbMetric: 4.1171

Epoch 319: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0704 - MinusLogProbMetric: 4.0704 - val_loss: 4.1171 - val_MinusLogProbMetric: 4.1171 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 320/1000
2023-09-12 05:10:39.984 
Epoch 320/1000 
	 loss: 4.0700, MinusLogProbMetric: 4.0700, val_loss: 4.1156, val_MinusLogProbMetric: 4.1156

Epoch 320: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0700 - MinusLogProbMetric: 4.0700 - val_loss: 4.1156 - val_MinusLogProbMetric: 4.1156 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 321/1000
2023-09-12 05:10:51.057 
Epoch 321/1000 
	 loss: 4.0711, MinusLogProbMetric: 4.0711, val_loss: 4.1260, val_MinusLogProbMetric: 4.1260

Epoch 321: val_loss did not improve from 4.11262
196/196 - 11s - loss: 4.0711 - MinusLogProbMetric: 4.0711 - val_loss: 4.1260 - val_MinusLogProbMetric: 4.1260 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 322/1000
2023-09-12 05:11:01.122 
Epoch 322/1000 
	 loss: 4.0691, MinusLogProbMetric: 4.0691, val_loss: 4.1143, val_MinusLogProbMetric: 4.1143

Epoch 322: val_loss did not improve from 4.11262
196/196 - 10s - loss: 4.0691 - MinusLogProbMetric: 4.0691 - val_loss: 4.1143 - val_MinusLogProbMetric: 4.1143 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 323/1000
2023-09-12 05:11:11.990 
Epoch 323/1000 
	 loss: 4.0713, MinusLogProbMetric: 4.0713, val_loss: 4.1176, val_MinusLogProbMetric: 4.1176

Epoch 323: val_loss did not improve from 4.11262
196/196 - 11s - loss: 4.0713 - MinusLogProbMetric: 4.0713 - val_loss: 4.1176 - val_MinusLogProbMetric: 4.1176 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 324/1000
2023-09-12 05:11:23.790 
Epoch 324/1000 
	 loss: 4.0709, MinusLogProbMetric: 4.0709, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 324: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0709 - MinusLogProbMetric: 4.0709 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 325/1000
2023-09-12 05:11:35.590 
Epoch 325/1000 
	 loss: 4.0698, MinusLogProbMetric: 4.0698, val_loss: 4.1150, val_MinusLogProbMetric: 4.1150

Epoch 325: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0698 - MinusLogProbMetric: 4.0698 - val_loss: 4.1150 - val_MinusLogProbMetric: 4.1150 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 326/1000
2023-09-12 05:11:47.337 
Epoch 326/1000 
	 loss: 4.0704, MinusLogProbMetric: 4.0704, val_loss: 4.1189, val_MinusLogProbMetric: 4.1189

Epoch 326: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0704 - MinusLogProbMetric: 4.0704 - val_loss: 4.1189 - val_MinusLogProbMetric: 4.1189 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-12 05:11:58.966 
Epoch 327/1000 
	 loss: 4.0715, MinusLogProbMetric: 4.0715, val_loss: 4.1193, val_MinusLogProbMetric: 4.1193

Epoch 327: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0715 - MinusLogProbMetric: 4.0715 - val_loss: 4.1193 - val_MinusLogProbMetric: 4.1193 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 328/1000
2023-09-12 05:12:10.742 
Epoch 328/1000 
	 loss: 4.0706, MinusLogProbMetric: 4.0706, val_loss: 4.1216, val_MinusLogProbMetric: 4.1216

Epoch 328: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0706 - MinusLogProbMetric: 4.0706 - val_loss: 4.1216 - val_MinusLogProbMetric: 4.1216 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 329/1000
2023-09-12 05:12:22.668 
Epoch 329/1000 
	 loss: 4.0694, MinusLogProbMetric: 4.0694, val_loss: 4.1165, val_MinusLogProbMetric: 4.1165

Epoch 329: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0694 - MinusLogProbMetric: 4.0694 - val_loss: 4.1165 - val_MinusLogProbMetric: 4.1165 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 330/1000
2023-09-12 05:12:34.348 
Epoch 330/1000 
	 loss: 4.0696, MinusLogProbMetric: 4.0696, val_loss: 4.1164, val_MinusLogProbMetric: 4.1164

Epoch 330: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0696 - MinusLogProbMetric: 4.0696 - val_loss: 4.1164 - val_MinusLogProbMetric: 4.1164 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 331/1000
2023-09-12 05:12:46.051 
Epoch 331/1000 
	 loss: 4.0692, MinusLogProbMetric: 4.0692, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 331: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0692 - MinusLogProbMetric: 4.0692 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 332/1000
2023-09-12 05:12:57.775 
Epoch 332/1000 
	 loss: 4.0700, MinusLogProbMetric: 4.0700, val_loss: 4.1132, val_MinusLogProbMetric: 4.1132

Epoch 332: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0700 - MinusLogProbMetric: 4.0700 - val_loss: 4.1132 - val_MinusLogProbMetric: 4.1132 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 333/1000
2023-09-12 05:13:09.969 
Epoch 333/1000 
	 loss: 4.0697, MinusLogProbMetric: 4.0697, val_loss: 4.1225, val_MinusLogProbMetric: 4.1225

Epoch 333: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0697 - MinusLogProbMetric: 4.0697 - val_loss: 4.1225 - val_MinusLogProbMetric: 4.1225 - lr: 2.5000e-04 - 12s/epoch - 62ms/step
Epoch 334/1000
2023-09-12 05:13:21.592 
Epoch 334/1000 
	 loss: 4.0701, MinusLogProbMetric: 4.0701, val_loss: 4.1171, val_MinusLogProbMetric: 4.1171

Epoch 334: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0701 - MinusLogProbMetric: 4.0701 - val_loss: 4.1171 - val_MinusLogProbMetric: 4.1171 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 335/1000
2023-09-12 05:13:33.340 
Epoch 335/1000 
	 loss: 4.0686, MinusLogProbMetric: 4.0686, val_loss: 4.1162, val_MinusLogProbMetric: 4.1162

Epoch 335: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0686 - MinusLogProbMetric: 4.0686 - val_loss: 4.1162 - val_MinusLogProbMetric: 4.1162 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 336/1000
2023-09-12 05:13:45.038 
Epoch 336/1000 
	 loss: 4.0704, MinusLogProbMetric: 4.0704, val_loss: 4.1138, val_MinusLogProbMetric: 4.1138

Epoch 336: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0704 - MinusLogProbMetric: 4.0704 - val_loss: 4.1138 - val_MinusLogProbMetric: 4.1138 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 337/1000
2023-09-12 05:13:56.776 
Epoch 337/1000 
	 loss: 4.0689, MinusLogProbMetric: 4.0689, val_loss: 4.1144, val_MinusLogProbMetric: 4.1144

Epoch 337: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0689 - MinusLogProbMetric: 4.0689 - val_loss: 4.1144 - val_MinusLogProbMetric: 4.1144 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 338/1000
2023-09-12 05:14:08.605 
Epoch 338/1000 
	 loss: 4.0686, MinusLogProbMetric: 4.0686, val_loss: 4.1149, val_MinusLogProbMetric: 4.1149

Epoch 338: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0686 - MinusLogProbMetric: 4.0686 - val_loss: 4.1149 - val_MinusLogProbMetric: 4.1149 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 339/1000
2023-09-12 05:14:20.336 
Epoch 339/1000 
	 loss: 4.0687, MinusLogProbMetric: 4.0687, val_loss: 4.1198, val_MinusLogProbMetric: 4.1198

Epoch 339: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0687 - MinusLogProbMetric: 4.0687 - val_loss: 4.1198 - val_MinusLogProbMetric: 4.1198 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 340/1000
2023-09-12 05:14:32.140 
Epoch 340/1000 
	 loss: 4.0707, MinusLogProbMetric: 4.0707, val_loss: 4.1165, val_MinusLogProbMetric: 4.1165

Epoch 340: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0707 - MinusLogProbMetric: 4.0707 - val_loss: 4.1165 - val_MinusLogProbMetric: 4.1165 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 341/1000
2023-09-12 05:14:43.949 
Epoch 341/1000 
	 loss: 4.0690, MinusLogProbMetric: 4.0690, val_loss: 4.1178, val_MinusLogProbMetric: 4.1178

Epoch 341: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0690 - MinusLogProbMetric: 4.0690 - val_loss: 4.1178 - val_MinusLogProbMetric: 4.1178 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 342/1000
2023-09-12 05:14:55.784 
Epoch 342/1000 
	 loss: 4.0687, MinusLogProbMetric: 4.0687, val_loss: 4.1235, val_MinusLogProbMetric: 4.1235

Epoch 342: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0687 - MinusLogProbMetric: 4.0687 - val_loss: 4.1235 - val_MinusLogProbMetric: 4.1235 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-12 05:15:07.453 
Epoch 343/1000 
	 loss: 4.0670, MinusLogProbMetric: 4.0670, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 343: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0670 - MinusLogProbMetric: 4.0670 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 344/1000
2023-09-12 05:15:19.186 
Epoch 344/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1132, val_MinusLogProbMetric: 4.1132

Epoch 344: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1132 - val_MinusLogProbMetric: 4.1132 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 345/1000
2023-09-12 05:15:30.963 
Epoch 345/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1142, val_MinusLogProbMetric: 4.1142

Epoch 345: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1142 - val_MinusLogProbMetric: 4.1142 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 346/1000
2023-09-12 05:15:43.498 
Epoch 346/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 346: val_loss did not improve from 4.11262
196/196 - 13s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 1.2500e-04 - 13s/epoch - 64ms/step
Epoch 347/1000
2023-09-12 05:15:55.396 
Epoch 347/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 347: val_loss did not improve from 4.11262
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 348/1000
2023-09-12 05:16:05.130 
Epoch 348/1000 
	 loss: 4.0656, MinusLogProbMetric: 4.0656, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 348: val_loss improved from 4.11262 to 4.11196, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 10s - loss: 4.0656 - MinusLogProbMetric: 4.0656 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 1.2500e-04 - 10s/epoch - 51ms/step
Epoch 349/1000
2023-09-12 05:16:15.761 
Epoch 349/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1158, val_MinusLogProbMetric: 4.1158

Epoch 349: val_loss did not improve from 4.11196
196/196 - 10s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1158 - val_MinusLogProbMetric: 4.1158 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 350/1000
2023-09-12 05:16:26.001 
Epoch 350/1000 
	 loss: 4.0655, MinusLogProbMetric: 4.0655, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 350: val_loss did not improve from 4.11196
196/196 - 10s - loss: 4.0655 - MinusLogProbMetric: 4.0655 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 351/1000
2023-09-12 05:16:37.702 
Epoch 351/1000 
	 loss: 4.0658, MinusLogProbMetric: 4.0658, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 351: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0658 - MinusLogProbMetric: 4.0658 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 352/1000
2023-09-12 05:16:49.426 
Epoch 352/1000 
	 loss: 4.0649, MinusLogProbMetric: 4.0649, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 352: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0649 - MinusLogProbMetric: 4.0649 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 353/1000
2023-09-12 05:17:01.226 
Epoch 353/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1157, val_MinusLogProbMetric: 4.1157

Epoch 353: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1157 - val_MinusLogProbMetric: 4.1157 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 354/1000
2023-09-12 05:17:12.993 
Epoch 354/1000 
	 loss: 4.0649, MinusLogProbMetric: 4.0649, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 354: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0649 - MinusLogProbMetric: 4.0649 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 355/1000
2023-09-12 05:17:24.586 
Epoch 355/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 355: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 356/1000
2023-09-12 05:17:36.389 
Epoch 356/1000 
	 loss: 4.0655, MinusLogProbMetric: 4.0655, val_loss: 4.1135, val_MinusLogProbMetric: 4.1135

Epoch 356: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0655 - MinusLogProbMetric: 4.0655 - val_loss: 4.1135 - val_MinusLogProbMetric: 4.1135 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 357/1000
2023-09-12 05:17:48.192 
Epoch 357/1000 
	 loss: 4.0645, MinusLogProbMetric: 4.0645, val_loss: 4.1151, val_MinusLogProbMetric: 4.1151

Epoch 357: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0645 - MinusLogProbMetric: 4.0645 - val_loss: 4.1151 - val_MinusLogProbMetric: 4.1151 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 358/1000
2023-09-12 05:17:59.836 
Epoch 358/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1155, val_MinusLogProbMetric: 4.1155

Epoch 358: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1155 - val_MinusLogProbMetric: 4.1155 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 359/1000
2023-09-12 05:18:11.483 
Epoch 359/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 359: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 360/1000
2023-09-12 05:18:22.875 
Epoch 360/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 360: val_loss did not improve from 4.11196
196/196 - 11s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 361/1000
2023-09-12 05:18:34.210 
Epoch 361/1000 
	 loss: 4.0655, MinusLogProbMetric: 4.0655, val_loss: 4.1154, val_MinusLogProbMetric: 4.1154

Epoch 361: val_loss did not improve from 4.11196
196/196 - 11s - loss: 4.0655 - MinusLogProbMetric: 4.0655 - val_loss: 4.1154 - val_MinusLogProbMetric: 4.1154 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 362/1000
2023-09-12 05:18:44.344 
Epoch 362/1000 
	 loss: 4.0650, MinusLogProbMetric: 4.0650, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 362: val_loss did not improve from 4.11196
196/196 - 10s - loss: 4.0650 - MinusLogProbMetric: 4.0650 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 363/1000
2023-09-12 05:18:55.821 
Epoch 363/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1145, val_MinusLogProbMetric: 4.1145

Epoch 363: val_loss did not improve from 4.11196
196/196 - 11s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1145 - val_MinusLogProbMetric: 4.1145 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 364/1000
2023-09-12 05:19:07.636 
Epoch 364/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.1147, val_MinusLogProbMetric: 4.1147

Epoch 364: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.1147 - val_MinusLogProbMetric: 4.1147 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 365/1000
2023-09-12 05:19:19.282 
Epoch 365/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1188, val_MinusLogProbMetric: 4.1188

Epoch 365: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1188 - val_MinusLogProbMetric: 4.1188 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 366/1000
2023-09-12 05:19:30.998 
Epoch 366/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1146, val_MinusLogProbMetric: 4.1146

Epoch 366: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1146 - val_MinusLogProbMetric: 4.1146 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 367/1000
2023-09-12 05:19:42.760 
Epoch 367/1000 
	 loss: 4.0648, MinusLogProbMetric: 4.0648, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 367: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0648 - MinusLogProbMetric: 4.0648 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 368/1000
2023-09-12 05:19:54.418 
Epoch 368/1000 
	 loss: 4.0647, MinusLogProbMetric: 4.0647, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 368: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0647 - MinusLogProbMetric: 4.0647 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 369/1000
2023-09-12 05:20:06.083 
Epoch 369/1000 
	 loss: 4.0658, MinusLogProbMetric: 4.0658, val_loss: 4.1125, val_MinusLogProbMetric: 4.1125

Epoch 369: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0658 - MinusLogProbMetric: 4.0658 - val_loss: 4.1125 - val_MinusLogProbMetric: 4.1125 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 370/1000
2023-09-12 05:20:17.807 
Epoch 370/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.1148, val_MinusLogProbMetric: 4.1148

Epoch 370: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.1148 - val_MinusLogProbMetric: 4.1148 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 371/1000
2023-09-12 05:20:29.532 
Epoch 371/1000 
	 loss: 4.0661, MinusLogProbMetric: 4.0661, val_loss: 4.1144, val_MinusLogProbMetric: 4.1144

Epoch 371: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0661 - MinusLogProbMetric: 4.0661 - val_loss: 4.1144 - val_MinusLogProbMetric: 4.1144 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 372/1000
2023-09-12 05:20:41.299 
Epoch 372/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 372: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 373/1000
2023-09-12 05:20:52.996 
Epoch 373/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1133, val_MinusLogProbMetric: 4.1133

Epoch 373: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1133 - val_MinusLogProbMetric: 4.1133 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 374/1000
2023-09-12 05:21:04.680 
Epoch 374/1000 
	 loss: 4.0649, MinusLogProbMetric: 4.0649, val_loss: 4.1177, val_MinusLogProbMetric: 4.1177

Epoch 374: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0649 - MinusLogProbMetric: 4.0649 - val_loss: 4.1177 - val_MinusLogProbMetric: 4.1177 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 375/1000
2023-09-12 05:21:16.417 
Epoch 375/1000 
	 loss: 4.0648, MinusLogProbMetric: 4.0648, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 375: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0648 - MinusLogProbMetric: 4.0648 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 376/1000
2023-09-12 05:21:28.086 
Epoch 376/1000 
	 loss: 4.0648, MinusLogProbMetric: 4.0648, val_loss: 4.1143, val_MinusLogProbMetric: 4.1143

Epoch 376: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0648 - MinusLogProbMetric: 4.0648 - val_loss: 4.1143 - val_MinusLogProbMetric: 4.1143 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-12 05:21:39.740 
Epoch 377/1000 
	 loss: 4.0655, MinusLogProbMetric: 4.0655, val_loss: 4.1144, val_MinusLogProbMetric: 4.1144

Epoch 377: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0655 - MinusLogProbMetric: 4.0655 - val_loss: 4.1144 - val_MinusLogProbMetric: 4.1144 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 378/1000
2023-09-12 05:21:51.452 
Epoch 378/1000 
	 loss: 4.0658, MinusLogProbMetric: 4.0658, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 378: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0658 - MinusLogProbMetric: 4.0658 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 379/1000
2023-09-12 05:22:03.181 
Epoch 379/1000 
	 loss: 4.0646, MinusLogProbMetric: 4.0646, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 379: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0646 - MinusLogProbMetric: 4.0646 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-12 05:22:14.866 
Epoch 380/1000 
	 loss: 4.0647, MinusLogProbMetric: 4.0647, val_loss: 4.1156, val_MinusLogProbMetric: 4.1156

Epoch 380: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0647 - MinusLogProbMetric: 4.0647 - val_loss: 4.1156 - val_MinusLogProbMetric: 4.1156 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 381/1000
2023-09-12 05:22:26.530 
Epoch 381/1000 
	 loss: 4.0648, MinusLogProbMetric: 4.0648, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 381: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0648 - MinusLogProbMetric: 4.0648 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 382/1000
2023-09-12 05:22:38.403 
Epoch 382/1000 
	 loss: 4.0654, MinusLogProbMetric: 4.0654, val_loss: 4.1163, val_MinusLogProbMetric: 4.1163

Epoch 382: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0654 - MinusLogProbMetric: 4.0654 - val_loss: 4.1163 - val_MinusLogProbMetric: 4.1163 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 383/1000
2023-09-12 05:22:50.116 
Epoch 383/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.1253, val_MinusLogProbMetric: 4.1253

Epoch 383: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.1253 - val_MinusLogProbMetric: 4.1253 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 384/1000
2023-09-12 05:23:01.900 
Epoch 384/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 384: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 385/1000
2023-09-12 05:23:13.675 
Epoch 385/1000 
	 loss: 4.0657, MinusLogProbMetric: 4.0657, val_loss: 4.1135, val_MinusLogProbMetric: 4.1135

Epoch 385: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0657 - MinusLogProbMetric: 4.0657 - val_loss: 4.1135 - val_MinusLogProbMetric: 4.1135 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 386/1000
2023-09-12 05:23:25.412 
Epoch 386/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1132, val_MinusLogProbMetric: 4.1132

Epoch 386: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1132 - val_MinusLogProbMetric: 4.1132 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 387/1000
2023-09-12 05:23:37.182 
Epoch 387/1000 
	 loss: 4.0660, MinusLogProbMetric: 4.0660, val_loss: 4.1165, val_MinusLogProbMetric: 4.1165

Epoch 387: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0660 - MinusLogProbMetric: 4.0660 - val_loss: 4.1165 - val_MinusLogProbMetric: 4.1165 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 388/1000
2023-09-12 05:23:48.974 
Epoch 388/1000 
	 loss: 4.0647, MinusLogProbMetric: 4.0647, val_loss: 4.1133, val_MinusLogProbMetric: 4.1133

Epoch 388: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0647 - MinusLogProbMetric: 4.0647 - val_loss: 4.1133 - val_MinusLogProbMetric: 4.1133 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 389/1000
2023-09-12 05:24:00.823 
Epoch 389/1000 
	 loss: 4.0651, MinusLogProbMetric: 4.0651, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 389: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0651 - MinusLogProbMetric: 4.0651 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 390/1000
2023-09-12 05:24:12.472 
Epoch 390/1000 
	 loss: 4.0646, MinusLogProbMetric: 4.0646, val_loss: 4.1156, val_MinusLogProbMetric: 4.1156

Epoch 390: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0646 - MinusLogProbMetric: 4.0646 - val_loss: 4.1156 - val_MinusLogProbMetric: 4.1156 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 391/1000
2023-09-12 05:24:24.124 
Epoch 391/1000 
	 loss: 4.0652, MinusLogProbMetric: 4.0652, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 391: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0652 - MinusLogProbMetric: 4.0652 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 392/1000
2023-09-12 05:24:35.809 
Epoch 392/1000 
	 loss: 4.0649, MinusLogProbMetric: 4.0649, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 392: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0649 - MinusLogProbMetric: 4.0649 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 393/1000
2023-09-12 05:24:47.570 
Epoch 393/1000 
	 loss: 4.0645, MinusLogProbMetric: 4.0645, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 393: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0645 - MinusLogProbMetric: 4.0645 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 394/1000
2023-09-12 05:24:59.377 
Epoch 394/1000 
	 loss: 4.0659, MinusLogProbMetric: 4.0659, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 394: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0659 - MinusLogProbMetric: 4.0659 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 395/1000
2023-09-12 05:25:11.176 
Epoch 395/1000 
	 loss: 4.0653, MinusLogProbMetric: 4.0653, val_loss: 4.1147, val_MinusLogProbMetric: 4.1147

Epoch 395: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0653 - MinusLogProbMetric: 4.0653 - val_loss: 4.1147 - val_MinusLogProbMetric: 4.1147 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 396/1000
2023-09-12 05:25:22.884 
Epoch 396/1000 
	 loss: 4.0644, MinusLogProbMetric: 4.0644, val_loss: 4.1143, val_MinusLogProbMetric: 4.1143

Epoch 396: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0644 - MinusLogProbMetric: 4.0644 - val_loss: 4.1143 - val_MinusLogProbMetric: 4.1143 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 397/1000
2023-09-12 05:25:34.452 
Epoch 397/1000 
	 loss: 4.0648, MinusLogProbMetric: 4.0648, val_loss: 4.1139, val_MinusLogProbMetric: 4.1139

Epoch 397: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0648 - MinusLogProbMetric: 4.0648 - val_loss: 4.1139 - val_MinusLogProbMetric: 4.1139 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 398/1000
2023-09-12 05:25:46.236 
Epoch 398/1000 
	 loss: 4.0644, MinusLogProbMetric: 4.0644, val_loss: 4.1135, val_MinusLogProbMetric: 4.1135

Epoch 398: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0644 - MinusLogProbMetric: 4.0644 - val_loss: 4.1135 - val_MinusLogProbMetric: 4.1135 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 399/1000
2023-09-12 05:25:57.928 
Epoch 399/1000 
	 loss: 4.0634, MinusLogProbMetric: 4.0634, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 399: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0634 - MinusLogProbMetric: 4.0634 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 400/1000
2023-09-12 05:26:09.602 
Epoch 400/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 400: val_loss did not improve from 4.11196
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 401/1000
2023-09-12 05:26:21.441 
Epoch 401/1000 
	 loss: 4.0630, MinusLogProbMetric: 4.0630, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 401: val_loss improved from 4.11196 to 4.11180, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0630 - MinusLogProbMetric: 4.0630 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 402/1000
2023-09-12 05:26:33.274 
Epoch 402/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 402: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 403/1000
2023-09-12 05:26:45.025 
Epoch 403/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 403: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 404/1000
2023-09-12 05:26:56.808 
Epoch 404/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 404: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 405/1000
2023-09-12 05:27:08.542 
Epoch 405/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 405: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 406/1000
2023-09-12 05:27:20.203 
Epoch 406/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 406: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 407/1000
2023-09-12 05:27:31.918 
Epoch 407/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 407: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 408/1000
2023-09-12 05:27:43.573 
Epoch 408/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1133, val_MinusLogProbMetric: 4.1133

Epoch 408: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1133 - val_MinusLogProbMetric: 4.1133 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 409/1000
2023-09-12 05:27:55.298 
Epoch 409/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 409: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 410/1000
2023-09-12 05:28:07.068 
Epoch 410/1000 
	 loss: 4.0632, MinusLogProbMetric: 4.0632, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 410: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0632 - MinusLogProbMetric: 4.0632 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 411/1000
2023-09-12 05:28:18.926 
Epoch 411/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1135, val_MinusLogProbMetric: 4.1135

Epoch 411: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1135 - val_MinusLogProbMetric: 4.1135 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 412/1000
2023-09-12 05:28:30.649 
Epoch 412/1000 
	 loss: 4.0629, MinusLogProbMetric: 4.0629, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 412: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0629 - MinusLogProbMetric: 4.0629 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 413/1000
2023-09-12 05:28:42.223 
Epoch 413/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 413: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 414/1000
2023-09-12 05:28:53.965 
Epoch 414/1000 
	 loss: 4.0632, MinusLogProbMetric: 4.0632, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 414: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0632 - MinusLogProbMetric: 4.0632 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 415/1000
2023-09-12 05:29:05.759 
Epoch 415/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1172, val_MinusLogProbMetric: 4.1172

Epoch 415: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1172 - val_MinusLogProbMetric: 4.1172 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 416/1000
2023-09-12 05:29:17.534 
Epoch 416/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 416: val_loss did not improve from 4.11180
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 417/1000
2023-09-12 05:29:29.143 
Epoch 417/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 417: val_loss improved from 4.11180 to 4.11165, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_67/weights/best_weights.h5
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-12 05:29:40.982 
Epoch 418/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 418: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 419/1000
2023-09-12 05:29:52.525 
Epoch 419/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1119, val_MinusLogProbMetric: 4.1119

Epoch 419: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1119 - val_MinusLogProbMetric: 4.1119 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 420/1000
2023-09-12 05:30:04.273 
Epoch 420/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 420: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 421/1000
2023-09-12 05:30:15.979 
Epoch 421/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1142, val_MinusLogProbMetric: 4.1142

Epoch 421: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1142 - val_MinusLogProbMetric: 4.1142 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 422/1000
2023-09-12 05:30:27.738 
Epoch 422/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1141, val_MinusLogProbMetric: 4.1141

Epoch 422: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1141 - val_MinusLogProbMetric: 4.1141 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 423/1000
2023-09-12 05:30:39.416 
Epoch 423/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 423: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 424/1000
2023-09-12 05:30:51.290 
Epoch 424/1000 
	 loss: 4.0632, MinusLogProbMetric: 4.0632, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 424: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0632 - MinusLogProbMetric: 4.0632 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 425/1000
2023-09-12 05:31:03.125 
Epoch 425/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1143, val_MinusLogProbMetric: 4.1143

Epoch 425: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1143 - val_MinusLogProbMetric: 4.1143 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 426/1000
2023-09-12 05:31:14.857 
Epoch 426/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 426: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 427/1000
2023-09-12 05:31:26.487 
Epoch 427/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 427: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 428/1000
2023-09-12 05:31:38.229 
Epoch 428/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 428: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 429/1000
2023-09-12 05:31:49.948 
Epoch 429/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 429: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 430/1000
2023-09-12 05:32:01.748 
Epoch 430/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 430: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 431/1000
2023-09-12 05:32:13.470 
Epoch 431/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 431: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 432/1000
2023-09-12 05:32:25.255 
Epoch 432/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 432: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 433/1000
2023-09-12 05:32:37.069 
Epoch 433/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1125, val_MinusLogProbMetric: 4.1125

Epoch 433: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1125 - val_MinusLogProbMetric: 4.1125 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 434/1000
2023-09-12 05:32:48.810 
Epoch 434/1000 
	 loss: 4.0632, MinusLogProbMetric: 4.0632, val_loss: 4.1245, val_MinusLogProbMetric: 4.1245

Epoch 434: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0632 - MinusLogProbMetric: 4.0632 - val_loss: 4.1245 - val_MinusLogProbMetric: 4.1245 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 435/1000
2023-09-12 05:33:00.584 
Epoch 435/1000 
	 loss: 4.0631, MinusLogProbMetric: 4.0631, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 435: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0631 - MinusLogProbMetric: 4.0631 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 436/1000
2023-09-12 05:33:12.389 
Epoch 436/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 436: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 437/1000
2023-09-12 05:33:24.039 
Epoch 437/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 437: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 438/1000
2023-09-12 05:33:35.855 
Epoch 438/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 438: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 439/1000
2023-09-12 05:33:47.683 
Epoch 439/1000 
	 loss: 4.0622, MinusLogProbMetric: 4.0622, val_loss: 4.1137, val_MinusLogProbMetric: 4.1137

Epoch 439: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0622 - MinusLogProbMetric: 4.0622 - val_loss: 4.1137 - val_MinusLogProbMetric: 4.1137 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-12 05:33:59.522 
Epoch 440/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.1141, val_MinusLogProbMetric: 4.1141

Epoch 440: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.1141 - val_MinusLogProbMetric: 4.1141 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 441/1000
2023-09-12 05:34:11.295 
Epoch 441/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1119, val_MinusLogProbMetric: 4.1119

Epoch 441: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1119 - val_MinusLogProbMetric: 4.1119 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 442/1000
2023-09-12 05:34:22.999 
Epoch 442/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 442: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 443/1000
2023-09-12 05:34:34.711 
Epoch 443/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 443: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 444/1000
2023-09-12 05:34:46.603 
Epoch 444/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 444: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 445/1000
2023-09-12 05:34:58.386 
Epoch 445/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1135, val_MinusLogProbMetric: 4.1135

Epoch 445: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1135 - val_MinusLogProbMetric: 4.1135 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 446/1000
2023-09-12 05:35:10.103 
Epoch 446/1000 
	 loss: 4.0624, MinusLogProbMetric: 4.0624, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 446: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0624 - MinusLogProbMetric: 4.0624 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 447/1000
2023-09-12 05:35:21.878 
Epoch 447/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1133, val_MinusLogProbMetric: 4.1133

Epoch 447: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1133 - val_MinusLogProbMetric: 4.1133 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 448/1000
2023-09-12 05:35:33.560 
Epoch 448/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 448: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 449/1000
2023-09-12 05:35:45.369 
Epoch 449/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 449: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 450/1000
2023-09-12 05:35:57.057 
Epoch 450/1000 
	 loss: 4.0622, MinusLogProbMetric: 4.0622, val_loss: 4.1138, val_MinusLogProbMetric: 4.1138

Epoch 450: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0622 - MinusLogProbMetric: 4.0622 - val_loss: 4.1138 - val_MinusLogProbMetric: 4.1138 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 451/1000
2023-09-12 05:36:08.740 
Epoch 451/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 451: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 452/1000
2023-09-12 05:36:20.451 
Epoch 452/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 452: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 453/1000
2023-09-12 05:36:32.188 
Epoch 453/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 453: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 454/1000
2023-09-12 05:36:43.983 
Epoch 454/1000 
	 loss: 4.0625, MinusLogProbMetric: 4.0625, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 454: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0625 - MinusLogProbMetric: 4.0625 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 455/1000
2023-09-12 05:36:55.740 
Epoch 455/1000 
	 loss: 4.0622, MinusLogProbMetric: 4.0622, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 455: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0622 - MinusLogProbMetric: 4.0622 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 456/1000
2023-09-12 05:37:07.571 
Epoch 456/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1138, val_MinusLogProbMetric: 4.1138

Epoch 456: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1138 - val_MinusLogProbMetric: 4.1138 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 457/1000
2023-09-12 05:37:19.182 
Epoch 457/1000 
	 loss: 4.0632, MinusLogProbMetric: 4.0632, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 457: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0632 - MinusLogProbMetric: 4.0632 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 458/1000
2023-09-12 05:37:30.897 
Epoch 458/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 458: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 459/1000
2023-09-12 05:37:42.656 
Epoch 459/1000 
	 loss: 4.0623, MinusLogProbMetric: 4.0623, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 459: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0623 - MinusLogProbMetric: 4.0623 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 460/1000
2023-09-12 05:37:54.547 
Epoch 460/1000 
	 loss: 4.0622, MinusLogProbMetric: 4.0622, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 460: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0622 - MinusLogProbMetric: 4.0622 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 6.2500e-05 - 12s/epoch - 61ms/step
Epoch 461/1000
2023-09-12 05:38:06.225 
Epoch 461/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 461: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 462/1000
2023-09-12 05:38:17.912 
Epoch 462/1000 
	 loss: 4.0621, MinusLogProbMetric: 4.0621, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 462: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0621 - MinusLogProbMetric: 4.0621 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 463/1000
2023-09-12 05:38:29.654 
Epoch 463/1000 
	 loss: 4.0626, MinusLogProbMetric: 4.0626, val_loss: 4.1143, val_MinusLogProbMetric: 4.1143

Epoch 463: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0626 - MinusLogProbMetric: 4.0626 - val_loss: 4.1143 - val_MinusLogProbMetric: 4.1143 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 464/1000
2023-09-12 05:38:41.332 
Epoch 464/1000 
	 loss: 4.0628, MinusLogProbMetric: 4.0628, val_loss: 4.1130, val_MinusLogProbMetric: 4.1130

Epoch 464: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0628 - MinusLogProbMetric: 4.0628 - val_loss: 4.1130 - val_MinusLogProbMetric: 4.1130 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 465/1000
2023-09-12 05:38:53.108 
Epoch 465/1000 
	 loss: 4.0621, MinusLogProbMetric: 4.0621, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 465: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0621 - MinusLogProbMetric: 4.0621 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 466/1000
2023-09-12 05:39:04.758 
Epoch 466/1000 
	 loss: 4.0622, MinusLogProbMetric: 4.0622, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 466: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0622 - MinusLogProbMetric: 4.0622 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 6.2500e-05 - 12s/epoch - 59ms/step
Epoch 467/1000
2023-09-12 05:39:16.475 
Epoch 467/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 467: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 468/1000
2023-09-12 05:39:28.178 
Epoch 468/1000 
	 loss: 4.0614, MinusLogProbMetric: 4.0614, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 468: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0614 - MinusLogProbMetric: 4.0614 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 469/1000
2023-09-12 05:39:39.798 
Epoch 469/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 469: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 470/1000
2023-09-12 05:39:51.389 
Epoch 470/1000 
	 loss: 4.0613, MinusLogProbMetric: 4.0613, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 470: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0613 - MinusLogProbMetric: 4.0613 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 471/1000
2023-09-12 05:40:03.038 
Epoch 471/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 471: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 472/1000
2023-09-12 05:40:14.768 
Epoch 472/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 472: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 473/1000
2023-09-12 05:40:26.378 
Epoch 473/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1119, val_MinusLogProbMetric: 4.1119

Epoch 473: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1119 - val_MinusLogProbMetric: 4.1119 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 474/1000
2023-09-12 05:40:37.963 
Epoch 474/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 474: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 475/1000
2023-09-12 05:40:49.769 
Epoch 475/1000 
	 loss: 4.0616, MinusLogProbMetric: 4.0616, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 475: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0616 - MinusLogProbMetric: 4.0616 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 476/1000
2023-09-12 05:41:01.408 
Epoch 476/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 476: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 477/1000
2023-09-12 05:41:13.144 
Epoch 477/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 477: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 478/1000
2023-09-12 05:41:25.035 
Epoch 478/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 478: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 479/1000
2023-09-12 05:41:36.696 
Epoch 479/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 479: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 480/1000
2023-09-12 05:41:48.340 
Epoch 480/1000 
	 loss: 4.0613, MinusLogProbMetric: 4.0613, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 480: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0613 - MinusLogProbMetric: 4.0613 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 481/1000
2023-09-12 05:42:00.112 
Epoch 481/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1118, val_MinusLogProbMetric: 4.1118

Epoch 481: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1118 - val_MinusLogProbMetric: 4.1118 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 482/1000
2023-09-12 05:42:11.788 
Epoch 482/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 482: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 483/1000
2023-09-12 05:42:23.623 
Epoch 483/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1136, val_MinusLogProbMetric: 4.1136

Epoch 483: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1136 - val_MinusLogProbMetric: 4.1136 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 484/1000
2023-09-12 05:42:35.388 
Epoch 484/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1119, val_MinusLogProbMetric: 4.1119

Epoch 484: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1119 - val_MinusLogProbMetric: 4.1119 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 485/1000
2023-09-12 05:42:47.049 
Epoch 485/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1125, val_MinusLogProbMetric: 4.1125

Epoch 485: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1125 - val_MinusLogProbMetric: 4.1125 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 486/1000
2023-09-12 05:42:58.665 
Epoch 486/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 486: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 487/1000
2023-09-12 05:43:10.325 
Epoch 487/1000 
	 loss: 4.0618, MinusLogProbMetric: 4.0618, val_loss: 4.1117, val_MinusLogProbMetric: 4.1117

Epoch 487: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0618 - MinusLogProbMetric: 4.0618 - val_loss: 4.1117 - val_MinusLogProbMetric: 4.1117 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 488/1000
2023-09-12 05:43:22.095 
Epoch 488/1000 
	 loss: 4.0613, MinusLogProbMetric: 4.0613, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 488: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0613 - MinusLogProbMetric: 4.0613 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 489/1000
2023-09-12 05:43:33.902 
Epoch 489/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 489: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 490/1000
2023-09-12 05:43:45.706 
Epoch 490/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1134, val_MinusLogProbMetric: 4.1134

Epoch 490: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1134 - val_MinusLogProbMetric: 4.1134 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 491/1000
2023-09-12 05:43:57.367 
Epoch 491/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 491: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 492/1000
2023-09-12 05:44:09.126 
Epoch 492/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 492: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 493/1000
2023-09-12 05:44:20.780 
Epoch 493/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 493: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 494/1000
2023-09-12 05:44:32.464 
Epoch 494/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 494: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 495/1000
2023-09-12 05:44:44.375 
Epoch 495/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 495: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 496/1000
2023-09-12 05:44:56.182 
Epoch 496/1000 
	 loss: 4.0615, MinusLogProbMetric: 4.0615, val_loss: 4.1129, val_MinusLogProbMetric: 4.1129

Epoch 496: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0615 - MinusLogProbMetric: 4.0615 - val_loss: 4.1129 - val_MinusLogProbMetric: 4.1129 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 497/1000
2023-09-12 05:45:08.011 
Epoch 497/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 497: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 498/1000
2023-09-12 05:45:19.692 
Epoch 498/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 498: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 499/1000
2023-09-12 05:45:31.505 
Epoch 499/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 499: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 500/1000
2023-09-12 05:45:43.352 
Epoch 500/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 500: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 501/1000
2023-09-12 05:45:55.215 
Epoch 501/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 501: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 61ms/step
Epoch 502/1000
2023-09-12 05:46:06.989 
Epoch 502/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1126, val_MinusLogProbMetric: 4.1126

Epoch 502: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1126 - val_MinusLogProbMetric: 4.1126 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 503/1000
2023-09-12 05:46:18.750 
Epoch 503/1000 
	 loss: 4.0615, MinusLogProbMetric: 4.0615, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 503: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0615 - MinusLogProbMetric: 4.0615 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 504/1000
2023-09-12 05:46:30.465 
Epoch 504/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 504: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 505/1000
2023-09-12 05:46:42.258 
Epoch 505/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1123, val_MinusLogProbMetric: 4.1123

Epoch 505: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1123 - val_MinusLogProbMetric: 4.1123 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 506/1000
2023-09-12 05:46:54.017 
Epoch 506/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 506: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 507/1000
2023-09-12 05:47:05.740 
Epoch 507/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 507: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 508/1000
2023-09-12 05:47:17.553 
Epoch 508/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 508: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 509/1000
2023-09-12 05:47:29.387 
Epoch 509/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 509: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 510/1000
2023-09-12 05:47:41.183 
Epoch 510/1000 
	 loss: 4.0612, MinusLogProbMetric: 4.0612, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 510: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0612 - MinusLogProbMetric: 4.0612 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 511/1000
2023-09-12 05:47:52.858 
Epoch 511/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1128, val_MinusLogProbMetric: 4.1128

Epoch 511: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1128 - val_MinusLogProbMetric: 4.1128 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 512/1000
2023-09-12 05:48:05.316 
Epoch 512/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1122, val_MinusLogProbMetric: 4.1122

Epoch 512: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1122 - val_MinusLogProbMetric: 4.1122 - lr: 3.1250e-05 - 12s/epoch - 64ms/step
Epoch 513/1000
2023-09-12 05:48:17.082 
Epoch 513/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1124, val_MinusLogProbMetric: 4.1124

Epoch 513: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1124 - val_MinusLogProbMetric: 4.1124 - lr: 3.1250e-05 - 12s/epoch - 60ms/step
Epoch 514/1000
2023-09-12 05:48:28.708 
Epoch 514/1000 
	 loss: 4.0609, MinusLogProbMetric: 4.0609, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 514: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0609 - MinusLogProbMetric: 4.0609 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 515/1000
2023-09-12 05:48:40.276 
Epoch 515/1000 
	 loss: 4.0610, MinusLogProbMetric: 4.0610, val_loss: 4.1127, val_MinusLogProbMetric: 4.1127

Epoch 515: val_loss did not improve from 4.11165
196/196 - 12s - loss: 4.0610 - MinusLogProbMetric: 4.0610 - val_loss: 4.1127 - val_MinusLogProbMetric: 4.1127 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 516/1000
2023-09-12 05:48:50.184 
Epoch 516/1000 
	 loss: 4.0608, MinusLogProbMetric: 4.0608, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 516: val_loss did not improve from 4.11165
196/196 - 10s - loss: 4.0608 - MinusLogProbMetric: 4.0608 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 10s/epoch - 51ms/step
Epoch 517/1000
2023-09-12 05:49:01.709 
Epoch 517/1000 
	 loss: 4.0611, MinusLogProbMetric: 4.0611, val_loss: 4.1121, val_MinusLogProbMetric: 4.1121

Epoch 517: val_loss did not improve from 4.11165
Restoring model weights from the end of the best epoch: 417.
196/196 - 12s - loss: 4.0611 - MinusLogProbMetric: 4.0611 - val_loss: 4.1121 - val_MinusLogProbMetric: 4.1121 - lr: 3.1250e-05 - 12s/epoch - 59ms/step
Epoch 517: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.510924550937489 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.396878462983295 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.098354359040968 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.1652286879252642 seconds.
Training succeeded with seed 721.
Model trained in 6064.61 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 21.69 s.
Plots done in 10.29 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 31.98 s.
===========
Run 67/360 done in 6097.99 s.
===========

Directory ../../results/MsplineN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

===========
Generating train data for run 76.
===========
Train data generated in 0.29 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 8)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_76/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_76/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[-1.8162504e-02,  8.8381166e+00,  8.6877737e+00, ...,
         6.9322171e+00,  4.0983129e+00,  7.9362688e+00],
       [ 8.7457299e-03,  8.1090946e+00,  7.2493863e+00, ...,
         6.9349885e+00,  4.6630187e+00,  7.8035836e+00],
       [ 9.8774462e+00,  3.2168188e+00,  7.9118123e+00, ...,
         9.3064079e+00,  6.8860310e-01,  1.4308348e+00],
       ...,
       [ 4.7885728e-01,  7.5187321e+00,  7.6983232e+00, ...,
         7.2090416e+00,  4.8741002e+00,  7.5171561e+00],
       [ 2.5328305e-01,  8.1886292e+00,  8.8014259e+00, ...,
         9.1725578e+00,  4.1776223e+00,  7.7115631e+00],
       [ 2.6981741e-02,  8.2328224e+00,  7.0491204e+00, ...,
         8.6794777e+00,  4.7622304e+00,  7.8125534e+00]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[8], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_76/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_76
self.data_kwargs: {'seed': 926}
self.x_data: [[-0.05356155  7.823141    8.656547   ...  7.203113    4.5568213
   7.9341974 ]
 [ 0.33506995  8.891628    6.827406   ...  7.456951    4.5099497
   7.6623387 ]
 [ 9.696308    4.906292    7.9414268  ...  8.918397    0.67725384
  -0.04672056]
 ...
 [10.426017    4.189514    7.913414   ...  7.849298    1.1715728
   1.3694253 ]
 [ 9.3889      2.8583937   7.9482403  ...  9.59728     0.5144149
   0.49252704]
 [ 5.455715    6.4598684   6.023231   ...  6.084529    4.572967
   7.994362  ]]
self.y_data: []
self.ndims: 8
Model defined.
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_28 (InputLayer)       [(None, 8)]               0         
                                                                 
 log_prob_layer_9 (LogProbLa  (None,)                  411696    
 yer)                                                            
                                                                 
=================================================================
Total params: 411,696
Trainable params: 411,696
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_9/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_9'")
self.model: <keras.engine.functional.Functional object at 0x7fc6ec2abd60>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc6cc788460>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc6cc788460>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc6ec28ddb0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc6cc55ab60>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc6cc55b0d0>, <keras.callbacks.ModelCheckpoint object at 0x7fc6cc55b190>, <keras.callbacks.EarlyStopping object at 0x7fc6cc55b400>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc6cc55b430>, <keras.callbacks.TerminateOnNaN object at 0x7fc6cc55b070>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[-1.8162504e-02,  8.8381166e+00,  8.6877737e+00, ...,
         6.9322171e+00,  4.0983129e+00,  7.9362688e+00],
       [ 8.7457299e-03,  8.1090946e+00,  7.2493863e+00, ...,
         6.9349885e+00,  4.6630187e+00,  7.8035836e+00],
       [ 9.8774462e+00,  3.2168188e+00,  7.9118123e+00, ...,
         9.3064079e+00,  6.8860310e-01,  1.4308348e+00],
       ...,
       [ 4.7885728e-01,  7.5187321e+00,  7.6983232e+00, ...,
         7.2090416e+00,  4.8741002e+00,  7.5171561e+00],
       [ 2.5328305e-01,  8.1886292e+00,  8.8014259e+00, ...,
         9.1725578e+00,  4.1776223e+00,  7.7115631e+00],
       [ 2.6981741e-02,  8.2328224e+00,  7.0491204e+00, ...,
         8.6794777e+00,  4.7622304e+00,  7.8125534e+00]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_76/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 76/360 with hyperparameters:
timestamp = 2023-09-12 05:49:35.285458
ndims = 8
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 411696
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [-0.05356155  7.823141    8.656547    8.717833   10.823843    7.203113
  4.5568213   7.9341974 ]
Epoch 1/1000
2023-09-12 05:50:06.890 
Epoch 1/1000 
	 loss: 14.1717, MinusLogProbMetric: 14.1717, val_loss: 5.4177, val_MinusLogProbMetric: 5.4177

Epoch 1: val_loss improved from inf to 5.41774, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 32s - loss: 14.1717 - MinusLogProbMetric: 14.1717 - val_loss: 5.4177 - val_MinusLogProbMetric: 5.4177 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 2/1000
2023-09-12 05:50:18.852 
Epoch 2/1000 
	 loss: 4.9359, MinusLogProbMetric: 4.9359, val_loss: 4.8642, val_MinusLogProbMetric: 4.8642

Epoch 2: val_loss improved from 5.41774 to 4.86415, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.9359 - MinusLogProbMetric: 4.9359 - val_loss: 4.8642 - val_MinusLogProbMetric: 4.8642 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 3/1000
2023-09-12 05:50:30.633 
Epoch 3/1000 
	 loss: 4.5985, MinusLogProbMetric: 4.5985, val_loss: 4.5102, val_MinusLogProbMetric: 4.5102

Epoch 3: val_loss improved from 4.86415 to 4.51018, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.5985 - MinusLogProbMetric: 4.5985 - val_loss: 4.5102 - val_MinusLogProbMetric: 4.5102 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-12 05:50:42.549 
Epoch 4/1000 
	 loss: 4.4658, MinusLogProbMetric: 4.4658, val_loss: 4.4053, val_MinusLogProbMetric: 4.4053

Epoch 4: val_loss improved from 4.51018 to 4.40534, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.4658 - MinusLogProbMetric: 4.4658 - val_loss: 4.4053 - val_MinusLogProbMetric: 4.4053 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 5/1000
2023-09-12 05:50:54.438 
Epoch 5/1000 
	 loss: 4.3780, MinusLogProbMetric: 4.3780, val_loss: 4.6220, val_MinusLogProbMetric: 4.6220

Epoch 5: val_loss did not improve from 4.40534
196/196 - 12s - loss: 4.3780 - MinusLogProbMetric: 4.3780 - val_loss: 4.6220 - val_MinusLogProbMetric: 4.6220 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 6/1000
2023-09-12 05:51:06.132 
Epoch 6/1000 
	 loss: 4.3616, MinusLogProbMetric: 4.3616, val_loss: 4.5394, val_MinusLogProbMetric: 4.5394

Epoch 6: val_loss did not improve from 4.40534
196/196 - 12s - loss: 4.3616 - MinusLogProbMetric: 4.3616 - val_loss: 4.5394 - val_MinusLogProbMetric: 4.5394 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-12 05:51:17.882 
Epoch 7/1000 
	 loss: 4.3007, MinusLogProbMetric: 4.3007, val_loss: 4.2546, val_MinusLogProbMetric: 4.2546

Epoch 7: val_loss improved from 4.40534 to 4.25464, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.3007 - MinusLogProbMetric: 4.3007 - val_loss: 4.2546 - val_MinusLogProbMetric: 4.2546 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 8/1000
2023-09-12 05:51:29.640 
Epoch 8/1000 
	 loss: 4.2732, MinusLogProbMetric: 4.2732, val_loss: 4.2477, val_MinusLogProbMetric: 4.2477

Epoch 8: val_loss improved from 4.25464 to 4.24770, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.2732 - MinusLogProbMetric: 4.2732 - val_loss: 4.2477 - val_MinusLogProbMetric: 4.2477 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-12 05:51:41.535 
Epoch 9/1000 
	 loss: 4.2743, MinusLogProbMetric: 4.2743, val_loss: 4.3124, val_MinusLogProbMetric: 4.3124

Epoch 9: val_loss did not improve from 4.24770
196/196 - 12s - loss: 4.2743 - MinusLogProbMetric: 4.2743 - val_loss: 4.3124 - val_MinusLogProbMetric: 4.3124 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 10/1000
2023-09-12 05:51:53.176 
Epoch 10/1000 
	 loss: 4.2613, MinusLogProbMetric: 4.2613, val_loss: 4.1900, val_MinusLogProbMetric: 4.1900

Epoch 10: val_loss improved from 4.24770 to 4.19000, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.2613 - MinusLogProbMetric: 4.2613 - val_loss: 4.1900 - val_MinusLogProbMetric: 4.1900 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-12 05:52:04.861 
Epoch 11/1000 
	 loss: 4.2348, MinusLogProbMetric: 4.2348, val_loss: 4.2015, val_MinusLogProbMetric: 4.2015

Epoch 11: val_loss did not improve from 4.19000
196/196 - 12s - loss: 4.2348 - MinusLogProbMetric: 4.2348 - val_loss: 4.2015 - val_MinusLogProbMetric: 4.2015 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 12/1000
2023-09-12 05:52:16.505 
Epoch 12/1000 
	 loss: 4.2195, MinusLogProbMetric: 4.2195, val_loss: 4.3764, val_MinusLogProbMetric: 4.3764

Epoch 12: val_loss did not improve from 4.19000
196/196 - 12s - loss: 4.2195 - MinusLogProbMetric: 4.2195 - val_loss: 4.3764 - val_MinusLogProbMetric: 4.3764 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 13/1000
2023-09-12 05:52:28.331 
Epoch 13/1000 
	 loss: 4.2354, MinusLogProbMetric: 4.2354, val_loss: 4.1998, val_MinusLogProbMetric: 4.1998

Epoch 13: val_loss did not improve from 4.19000
196/196 - 12s - loss: 4.2354 - MinusLogProbMetric: 4.2354 - val_loss: 4.1998 - val_MinusLogProbMetric: 4.1998 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 05:52:39.965 
Epoch 14/1000 
	 loss: 4.2173, MinusLogProbMetric: 4.2173, val_loss: 4.1860, val_MinusLogProbMetric: 4.1860

Epoch 14: val_loss improved from 4.19000 to 4.18599, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.2173 - MinusLogProbMetric: 4.2173 - val_loss: 4.1860 - val_MinusLogProbMetric: 4.1860 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-12 05:52:51.724 
Epoch 15/1000 
	 loss: 4.2082, MinusLogProbMetric: 4.2082, val_loss: 4.2779, val_MinusLogProbMetric: 4.2779

Epoch 15: val_loss did not improve from 4.18599
196/196 - 12s - loss: 4.2082 - MinusLogProbMetric: 4.2082 - val_loss: 4.2779 - val_MinusLogProbMetric: 4.2779 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 16/1000
2023-09-12 05:53:03.403 
Epoch 16/1000 
	 loss: 4.1985, MinusLogProbMetric: 4.1985, val_loss: 4.1642, val_MinusLogProbMetric: 4.1642

Epoch 16: val_loss improved from 4.18599 to 4.16418, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1985 - MinusLogProbMetric: 4.1985 - val_loss: 4.1642 - val_MinusLogProbMetric: 4.1642 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 05:53:15.176 
Epoch 17/1000 
	 loss: 4.2005, MinusLogProbMetric: 4.2005, val_loss: 4.1497, val_MinusLogProbMetric: 4.1497

Epoch 17: val_loss improved from 4.16418 to 4.14973, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.2005 - MinusLogProbMetric: 4.2005 - val_loss: 4.1497 - val_MinusLogProbMetric: 4.1497 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-12 05:53:27.043 
Epoch 18/1000 
	 loss: 4.1919, MinusLogProbMetric: 4.1919, val_loss: 4.1521, val_MinusLogProbMetric: 4.1521

Epoch 18: val_loss did not improve from 4.14973
196/196 - 12s - loss: 4.1919 - MinusLogProbMetric: 4.1919 - val_loss: 4.1521 - val_MinusLogProbMetric: 4.1521 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 05:53:38.712 
Epoch 19/1000 
	 loss: 4.2001, MinusLogProbMetric: 4.2001, val_loss: 4.2099, val_MinusLogProbMetric: 4.2099

Epoch 19: val_loss did not improve from 4.14973
196/196 - 12s - loss: 4.2001 - MinusLogProbMetric: 4.2001 - val_loss: 4.2099 - val_MinusLogProbMetric: 4.2099 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-12 05:53:50.452 
Epoch 20/1000 
	 loss: 4.1997, MinusLogProbMetric: 4.1997, val_loss: 4.1293, val_MinusLogProbMetric: 4.1293

Epoch 20: val_loss improved from 4.14973 to 4.12927, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1997 - MinusLogProbMetric: 4.1997 - val_loss: 4.1293 - val_MinusLogProbMetric: 4.1293 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 21/1000
2023-09-12 05:54:02.257 
Epoch 21/1000 
	 loss: 4.1816, MinusLogProbMetric: 4.1816, val_loss: 4.1495, val_MinusLogProbMetric: 4.1495

Epoch 21: val_loss did not improve from 4.12927
196/196 - 12s - loss: 4.1816 - MinusLogProbMetric: 4.1816 - val_loss: 4.1495 - val_MinusLogProbMetric: 4.1495 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 05:54:14.003 
Epoch 22/1000 
	 loss: 4.1754, MinusLogProbMetric: 4.1754, val_loss: 4.1344, val_MinusLogProbMetric: 4.1344

Epoch 22: val_loss did not improve from 4.12927
196/196 - 12s - loss: 4.1754 - MinusLogProbMetric: 4.1754 - val_loss: 4.1344 - val_MinusLogProbMetric: 4.1344 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 05:54:25.686 
Epoch 23/1000 
	 loss: 4.1694, MinusLogProbMetric: 4.1694, val_loss: 4.3558, val_MinusLogProbMetric: 4.3558

Epoch 23: val_loss did not improve from 4.12927
196/196 - 12s - loss: 4.1694 - MinusLogProbMetric: 4.1694 - val_loss: 4.3558 - val_MinusLogProbMetric: 4.3558 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-12 05:54:37.495 
Epoch 24/1000 
	 loss: 4.1786, MinusLogProbMetric: 4.1786, val_loss: 4.1304, val_MinusLogProbMetric: 4.1304

Epoch 24: val_loss did not improve from 4.12927
196/196 - 12s - loss: 4.1786 - MinusLogProbMetric: 4.1786 - val_loss: 4.1304 - val_MinusLogProbMetric: 4.1304 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-12 05:54:49.303 
Epoch 25/1000 
	 loss: 4.1750, MinusLogProbMetric: 4.1750, val_loss: 4.1520, val_MinusLogProbMetric: 4.1520

Epoch 25: val_loss did not improve from 4.12927
196/196 - 12s - loss: 4.1750 - MinusLogProbMetric: 4.1750 - val_loss: 4.1520 - val_MinusLogProbMetric: 4.1520 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 05:55:01.003 
Epoch 26/1000 
	 loss: 4.1683, MinusLogProbMetric: 4.1683, val_loss: 4.1205, val_MinusLogProbMetric: 4.1205

Epoch 26: val_loss improved from 4.12927 to 4.12049, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1683 - MinusLogProbMetric: 4.1683 - val_loss: 4.1205 - val_MinusLogProbMetric: 4.1205 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 05:55:12.736 
Epoch 27/1000 
	 loss: 4.1719, MinusLogProbMetric: 4.1719, val_loss: 4.2362, val_MinusLogProbMetric: 4.2362

Epoch 27: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1719 - MinusLogProbMetric: 4.1719 - val_loss: 4.2362 - val_MinusLogProbMetric: 4.2362 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 28/1000
2023-09-12 05:55:24.340 
Epoch 28/1000 
	 loss: 4.1622, MinusLogProbMetric: 4.1622, val_loss: 4.1661, val_MinusLogProbMetric: 4.1661

Epoch 28: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1622 - MinusLogProbMetric: 4.1622 - val_loss: 4.1661 - val_MinusLogProbMetric: 4.1661 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 05:55:35.978 
Epoch 29/1000 
	 loss: 4.1691, MinusLogProbMetric: 4.1691, val_loss: 4.1521, val_MinusLogProbMetric: 4.1521

Epoch 29: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1691 - MinusLogProbMetric: 4.1691 - val_loss: 4.1521 - val_MinusLogProbMetric: 4.1521 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 30/1000
2023-09-12 05:55:47.638 
Epoch 30/1000 
	 loss: 4.1499, MinusLogProbMetric: 4.1499, val_loss: 4.1685, val_MinusLogProbMetric: 4.1685

Epoch 30: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1499 - MinusLogProbMetric: 4.1499 - val_loss: 4.1685 - val_MinusLogProbMetric: 4.1685 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 31/1000
2023-09-12 05:55:59.280 
Epoch 31/1000 
	 loss: 4.1607, MinusLogProbMetric: 4.1607, val_loss: 4.1325, val_MinusLogProbMetric: 4.1325

Epoch 31: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1607 - MinusLogProbMetric: 4.1607 - val_loss: 4.1325 - val_MinusLogProbMetric: 4.1325 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 32/1000
2023-09-12 05:56:11.034 
Epoch 32/1000 
	 loss: 4.2124, MinusLogProbMetric: 4.2124, val_loss: 4.2284, val_MinusLogProbMetric: 4.2284

Epoch 32: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.2124 - MinusLogProbMetric: 4.2124 - val_loss: 4.2284 - val_MinusLogProbMetric: 4.2284 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-12 05:56:22.799 
Epoch 33/1000 
	 loss: 4.1497, MinusLogProbMetric: 4.1497, val_loss: 4.1620, val_MinusLogProbMetric: 4.1620

Epoch 33: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1497 - MinusLogProbMetric: 4.1497 - val_loss: 4.1620 - val_MinusLogProbMetric: 4.1620 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-12 05:56:34.583 
Epoch 34/1000 
	 loss: 4.1442, MinusLogProbMetric: 4.1442, val_loss: 4.1309, val_MinusLogProbMetric: 4.1309

Epoch 34: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1442 - MinusLogProbMetric: 4.1442 - val_loss: 4.1309 - val_MinusLogProbMetric: 4.1309 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-12 05:56:46.290 
Epoch 35/1000 
	 loss: 4.2677, MinusLogProbMetric: 4.2677, val_loss: 4.1417, val_MinusLogProbMetric: 4.1417

Epoch 35: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.2677 - MinusLogProbMetric: 4.2677 - val_loss: 4.1417 - val_MinusLogProbMetric: 4.1417 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-12 05:56:57.984 
Epoch 36/1000 
	 loss: 4.1494, MinusLogProbMetric: 4.1494, val_loss: 4.1558, val_MinusLogProbMetric: 4.1558

Epoch 36: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1494 - MinusLogProbMetric: 4.1494 - val_loss: 4.1558 - val_MinusLogProbMetric: 4.1558 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 05:57:09.589 
Epoch 37/1000 
	 loss: 4.1389, MinusLogProbMetric: 4.1389, val_loss: 4.1625, val_MinusLogProbMetric: 4.1625

Epoch 37: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1389 - MinusLogProbMetric: 4.1389 - val_loss: 4.1625 - val_MinusLogProbMetric: 4.1625 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 38/1000
2023-09-12 05:57:21.403 
Epoch 38/1000 
	 loss: 4.1452, MinusLogProbMetric: 4.1452, val_loss: 4.1581, val_MinusLogProbMetric: 4.1581

Epoch 38: val_loss did not improve from 4.12049
196/196 - 12s - loss: 4.1452 - MinusLogProbMetric: 4.1452 - val_loss: 4.1581 - val_MinusLogProbMetric: 4.1581 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 05:57:33.104 
Epoch 39/1000 
	 loss: 4.1478, MinusLogProbMetric: 4.1478, val_loss: 4.1066, val_MinusLogProbMetric: 4.1066

Epoch 39: val_loss improved from 4.12049 to 4.10656, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1478 - MinusLogProbMetric: 4.1478 - val_loss: 4.1066 - val_MinusLogProbMetric: 4.1066 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-12 05:57:44.942 
Epoch 40/1000 
	 loss: 4.1354, MinusLogProbMetric: 4.1354, val_loss: 4.1106, val_MinusLogProbMetric: 4.1106

Epoch 40: val_loss did not improve from 4.10656
196/196 - 12s - loss: 4.1354 - MinusLogProbMetric: 4.1354 - val_loss: 4.1106 - val_MinusLogProbMetric: 4.1106 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-12 05:57:56.696 
Epoch 41/1000 
	 loss: 4.1428, MinusLogProbMetric: 4.1428, val_loss: 4.1107, val_MinusLogProbMetric: 4.1107

Epoch 41: val_loss did not improve from 4.10656
196/196 - 12s - loss: 4.1428 - MinusLogProbMetric: 4.1428 - val_loss: 4.1107 - val_MinusLogProbMetric: 4.1107 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-12 05:58:08.419 
Epoch 42/1000 
	 loss: 4.1376, MinusLogProbMetric: 4.1376, val_loss: 4.1049, val_MinusLogProbMetric: 4.1049

Epoch 42: val_loss improved from 4.10656 to 4.10490, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1376 - MinusLogProbMetric: 4.1376 - val_loss: 4.1049 - val_MinusLogProbMetric: 4.1049 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 43/1000
2023-09-12 05:58:20.099 
Epoch 43/1000 
	 loss: 4.1295, MinusLogProbMetric: 4.1295, val_loss: 4.1226, val_MinusLogProbMetric: 4.1226

Epoch 43: val_loss did not improve from 4.10490
196/196 - 12s - loss: 4.1295 - MinusLogProbMetric: 4.1295 - val_loss: 4.1226 - val_MinusLogProbMetric: 4.1226 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-12 05:58:31.939 
Epoch 44/1000 
	 loss: 4.1348, MinusLogProbMetric: 4.1348, val_loss: 4.1368, val_MinusLogProbMetric: 4.1368

Epoch 44: val_loss did not improve from 4.10490
196/196 - 12s - loss: 4.1348 - MinusLogProbMetric: 4.1348 - val_loss: 4.1368 - val_MinusLogProbMetric: 4.1368 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-12 05:58:43.589 
Epoch 45/1000 
	 loss: 4.1325, MinusLogProbMetric: 4.1325, val_loss: 4.1188, val_MinusLogProbMetric: 4.1188

Epoch 45: val_loss did not improve from 4.10490
196/196 - 12s - loss: 4.1325 - MinusLogProbMetric: 4.1325 - val_loss: 4.1188 - val_MinusLogProbMetric: 4.1188 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 46/1000
2023-09-12 05:58:55.176 
Epoch 46/1000 
	 loss: 4.1283, MinusLogProbMetric: 4.1283, val_loss: 4.0989, val_MinusLogProbMetric: 4.0989

Epoch 46: val_loss improved from 4.10490 to 4.09888, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1283 - MinusLogProbMetric: 4.1283 - val_loss: 4.0989 - val_MinusLogProbMetric: 4.0989 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 47/1000
2023-09-12 05:59:07.016 
Epoch 47/1000 
	 loss: 4.1311, MinusLogProbMetric: 4.1311, val_loss: 4.1429, val_MinusLogProbMetric: 4.1429

Epoch 47: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1311 - MinusLogProbMetric: 4.1311 - val_loss: 4.1429 - val_MinusLogProbMetric: 4.1429 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-12 05:59:18.755 
Epoch 48/1000 
	 loss: 4.1328, MinusLogProbMetric: 4.1328, val_loss: 4.1878, val_MinusLogProbMetric: 4.1878

Epoch 48: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1328 - MinusLogProbMetric: 4.1328 - val_loss: 4.1878 - val_MinusLogProbMetric: 4.1878 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-12 05:59:30.482 
Epoch 49/1000 
	 loss: 4.1270, MinusLogProbMetric: 4.1270, val_loss: 4.1075, val_MinusLogProbMetric: 4.1075

Epoch 49: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1270 - MinusLogProbMetric: 4.1270 - val_loss: 4.1075 - val_MinusLogProbMetric: 4.1075 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-12 05:59:42.217 
Epoch 50/1000 
	 loss: 4.1264, MinusLogProbMetric: 4.1264, val_loss: 4.1114, val_MinusLogProbMetric: 4.1114

Epoch 50: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1264 - MinusLogProbMetric: 4.1264 - val_loss: 4.1114 - val_MinusLogProbMetric: 4.1114 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 51/1000
2023-09-12 05:59:53.945 
Epoch 51/1000 
	 loss: 4.1197, MinusLogProbMetric: 4.1197, val_loss: 4.1560, val_MinusLogProbMetric: 4.1560

Epoch 51: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1197 - MinusLogProbMetric: 4.1197 - val_loss: 4.1560 - val_MinusLogProbMetric: 4.1560 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-12 06:00:05.856 
Epoch 52/1000 
	 loss: 4.1171, MinusLogProbMetric: 4.1171, val_loss: 4.1524, val_MinusLogProbMetric: 4.1524

Epoch 52: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1171 - MinusLogProbMetric: 4.1171 - val_loss: 4.1524 - val_MinusLogProbMetric: 4.1524 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 53/1000
2023-09-12 06:00:17.517 
Epoch 53/1000 
	 loss: 4.1285, MinusLogProbMetric: 4.1285, val_loss: 4.1494, val_MinusLogProbMetric: 4.1494

Epoch 53: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1285 - MinusLogProbMetric: 4.1285 - val_loss: 4.1494 - val_MinusLogProbMetric: 4.1494 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 54/1000
2023-09-12 06:00:29.257 
Epoch 54/1000 
	 loss: 4.1421, MinusLogProbMetric: 4.1421, val_loss: 4.1032, val_MinusLogProbMetric: 4.1032

Epoch 54: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1421 - MinusLogProbMetric: 4.1421 - val_loss: 4.1032 - val_MinusLogProbMetric: 4.1032 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 55/1000
2023-09-12 06:00:40.901 
Epoch 55/1000 
	 loss: 4.1231, MinusLogProbMetric: 4.1231, val_loss: 4.1344, val_MinusLogProbMetric: 4.1344

Epoch 55: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1231 - MinusLogProbMetric: 4.1231 - val_loss: 4.1344 - val_MinusLogProbMetric: 4.1344 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 56/1000
2023-09-12 06:00:52.568 
Epoch 56/1000 
	 loss: 4.1224, MinusLogProbMetric: 4.1224, val_loss: 4.1383, val_MinusLogProbMetric: 4.1383

Epoch 56: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1224 - MinusLogProbMetric: 4.1224 - val_loss: 4.1383 - val_MinusLogProbMetric: 4.1383 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-12 06:01:04.294 
Epoch 57/1000 
	 loss: 4.1176, MinusLogProbMetric: 4.1176, val_loss: 4.1197, val_MinusLogProbMetric: 4.1197

Epoch 57: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1176 - MinusLogProbMetric: 4.1176 - val_loss: 4.1197 - val_MinusLogProbMetric: 4.1197 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-12 06:01:15.943 
Epoch 58/1000 
	 loss: 4.1132, MinusLogProbMetric: 4.1132, val_loss: 4.1052, val_MinusLogProbMetric: 4.1052

Epoch 58: val_loss did not improve from 4.09888
196/196 - 12s - loss: 4.1132 - MinusLogProbMetric: 4.1132 - val_loss: 4.1052 - val_MinusLogProbMetric: 4.1052 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 59/1000
2023-09-12 06:01:27.623 
Epoch 59/1000 
	 loss: 4.1147, MinusLogProbMetric: 4.1147, val_loss: 4.0870, val_MinusLogProbMetric: 4.0870

Epoch 59: val_loss improved from 4.09888 to 4.08705, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1147 - MinusLogProbMetric: 4.1147 - val_loss: 4.0870 - val_MinusLogProbMetric: 4.0870 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 60/1000
2023-09-12 06:01:39.500 
Epoch 60/1000 
	 loss: 4.1125, MinusLogProbMetric: 4.1125, val_loss: 4.1239, val_MinusLogProbMetric: 4.1239

Epoch 60: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1125 - MinusLogProbMetric: 4.1125 - val_loss: 4.1239 - val_MinusLogProbMetric: 4.1239 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-12 06:01:51.184 
Epoch 61/1000 
	 loss: 4.1187, MinusLogProbMetric: 4.1187, val_loss: 4.3660, val_MinusLogProbMetric: 4.3660

Epoch 61: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1187 - MinusLogProbMetric: 4.1187 - val_loss: 4.3660 - val_MinusLogProbMetric: 4.3660 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-12 06:02:02.991 
Epoch 62/1000 
	 loss: 4.1564, MinusLogProbMetric: 4.1564, val_loss: 4.1216, val_MinusLogProbMetric: 4.1216

Epoch 62: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1564 - MinusLogProbMetric: 4.1564 - val_loss: 4.1216 - val_MinusLogProbMetric: 4.1216 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-12 06:02:14.686 
Epoch 63/1000 
	 loss: 4.1159, MinusLogProbMetric: 4.1159, val_loss: 4.0989, val_MinusLogProbMetric: 4.0989

Epoch 63: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1159 - MinusLogProbMetric: 4.1159 - val_loss: 4.0989 - val_MinusLogProbMetric: 4.0989 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-12 06:02:26.499 
Epoch 64/1000 
	 loss: 4.1159, MinusLogProbMetric: 4.1159, val_loss: 4.1183, val_MinusLogProbMetric: 4.1183

Epoch 64: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1159 - MinusLogProbMetric: 4.1159 - val_loss: 4.1183 - val_MinusLogProbMetric: 4.1183 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-12 06:02:38.190 
Epoch 65/1000 
	 loss: 4.1138, MinusLogProbMetric: 4.1138, val_loss: 4.1146, val_MinusLogProbMetric: 4.1146

Epoch 65: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1138 - MinusLogProbMetric: 4.1138 - val_loss: 4.1146 - val_MinusLogProbMetric: 4.1146 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-12 06:02:49.906 
Epoch 66/1000 
	 loss: 4.1200, MinusLogProbMetric: 4.1200, val_loss: 4.1843, val_MinusLogProbMetric: 4.1843

Epoch 66: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1200 - MinusLogProbMetric: 4.1200 - val_loss: 4.1843 - val_MinusLogProbMetric: 4.1843 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-12 06:03:01.607 
Epoch 67/1000 
	 loss: 4.1116, MinusLogProbMetric: 4.1116, val_loss: 4.1218, val_MinusLogProbMetric: 4.1218

Epoch 67: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1116 - MinusLogProbMetric: 4.1116 - val_loss: 4.1218 - val_MinusLogProbMetric: 4.1218 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-12 06:03:13.268 
Epoch 68/1000 
	 loss: 4.1136, MinusLogProbMetric: 4.1136, val_loss: 4.1350, val_MinusLogProbMetric: 4.1350

Epoch 68: val_loss did not improve from 4.08705
196/196 - 12s - loss: 4.1136 - MinusLogProbMetric: 4.1136 - val_loss: 4.1350 - val_MinusLogProbMetric: 4.1350 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-12 06:03:24.985 
Epoch 69/1000 
	 loss: 4.1071, MinusLogProbMetric: 4.1071, val_loss: 4.0845, val_MinusLogProbMetric: 4.0845

Epoch 69: val_loss improved from 4.08705 to 4.08451, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.1071 - MinusLogProbMetric: 4.1071 - val_loss: 4.0845 - val_MinusLogProbMetric: 4.0845 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 70/1000
2023-09-12 06:03:36.870 
Epoch 70/1000 
	 loss: 4.1037, MinusLogProbMetric: 4.1037, val_loss: 4.0948, val_MinusLogProbMetric: 4.0948

Epoch 70: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1037 - MinusLogProbMetric: 4.1037 - val_loss: 4.0948 - val_MinusLogProbMetric: 4.0948 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-12 06:03:48.610 
Epoch 71/1000 
	 loss: 4.1153, MinusLogProbMetric: 4.1153, val_loss: 4.0982, val_MinusLogProbMetric: 4.0982

Epoch 71: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1153 - MinusLogProbMetric: 4.1153 - val_loss: 4.0982 - val_MinusLogProbMetric: 4.0982 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-12 06:04:00.272 
Epoch 72/1000 
	 loss: 4.1172, MinusLogProbMetric: 4.1172, val_loss: 4.1368, val_MinusLogProbMetric: 4.1368

Epoch 72: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1172 - MinusLogProbMetric: 4.1172 - val_loss: 4.1368 - val_MinusLogProbMetric: 4.1368 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 73/1000
2023-09-12 06:04:11.895 
Epoch 73/1000 
	 loss: 4.1130, MinusLogProbMetric: 4.1130, val_loss: 4.1433, val_MinusLogProbMetric: 4.1433

Epoch 73: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1130 - MinusLogProbMetric: 4.1130 - val_loss: 4.1433 - val_MinusLogProbMetric: 4.1433 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 06:04:23.434 
Epoch 74/1000 
	 loss: 4.1070, MinusLogProbMetric: 4.1070, val_loss: 4.1048, val_MinusLogProbMetric: 4.1048

Epoch 74: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1070 - MinusLogProbMetric: 4.1070 - val_loss: 4.1048 - val_MinusLogProbMetric: 4.1048 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 75/1000
2023-09-12 06:04:35.112 
Epoch 75/1000 
	 loss: 4.1089, MinusLogProbMetric: 4.1089, val_loss: 4.0937, val_MinusLogProbMetric: 4.0937

Epoch 75: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1089 - MinusLogProbMetric: 4.1089 - val_loss: 4.0937 - val_MinusLogProbMetric: 4.0937 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-12 06:04:46.814 
Epoch 76/1000 
	 loss: 4.1068, MinusLogProbMetric: 4.1068, val_loss: 4.1052, val_MinusLogProbMetric: 4.1052

Epoch 76: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1068 - MinusLogProbMetric: 4.1068 - val_loss: 4.1052 - val_MinusLogProbMetric: 4.1052 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-12 06:04:58.494 
Epoch 77/1000 
	 loss: 4.1080, MinusLogProbMetric: 4.1080, val_loss: 4.1075, val_MinusLogProbMetric: 4.1075

Epoch 77: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1080 - MinusLogProbMetric: 4.1080 - val_loss: 4.1075 - val_MinusLogProbMetric: 4.1075 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-12 06:05:09.913 
Epoch 78/1000 
	 loss: 4.1067, MinusLogProbMetric: 4.1067, val_loss: 4.1111, val_MinusLogProbMetric: 4.1111

Epoch 78: val_loss did not improve from 4.08451
196/196 - 11s - loss: 4.1067 - MinusLogProbMetric: 4.1067 - val_loss: 4.1111 - val_MinusLogProbMetric: 4.1111 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 79/1000
2023-09-12 06:05:20.574 
Epoch 79/1000 
	 loss: 4.1114, MinusLogProbMetric: 4.1114, val_loss: 4.1224, val_MinusLogProbMetric: 4.1224

Epoch 79: val_loss did not improve from 4.08451
196/196 - 11s - loss: 4.1114 - MinusLogProbMetric: 4.1114 - val_loss: 4.1224 - val_MinusLogProbMetric: 4.1224 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 80/1000
2023-09-12 06:05:31.614 
Epoch 80/1000 
	 loss: 4.1093, MinusLogProbMetric: 4.1093, val_loss: 4.0968, val_MinusLogProbMetric: 4.0968

Epoch 80: val_loss did not improve from 4.08451
196/196 - 11s - loss: 4.1093 - MinusLogProbMetric: 4.1093 - val_loss: 4.0968 - val_MinusLogProbMetric: 4.0968 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 81/1000
2023-09-12 06:05:42.261 
Epoch 81/1000 
	 loss: 4.1024, MinusLogProbMetric: 4.1024, val_loss: 4.0897, val_MinusLogProbMetric: 4.0897

Epoch 81: val_loss did not improve from 4.08451
196/196 - 11s - loss: 4.1024 - MinusLogProbMetric: 4.1024 - val_loss: 4.0897 - val_MinusLogProbMetric: 4.0897 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 82/1000
2023-09-12 06:05:53.955 
Epoch 82/1000 
	 loss: 4.1062, MinusLogProbMetric: 4.1062, val_loss: 4.0958, val_MinusLogProbMetric: 4.0958

Epoch 82: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1062 - MinusLogProbMetric: 4.1062 - val_loss: 4.0958 - val_MinusLogProbMetric: 4.0958 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-12 06:06:05.771 
Epoch 83/1000 
	 loss: 4.1132, MinusLogProbMetric: 4.1132, val_loss: 4.0938, val_MinusLogProbMetric: 4.0938

Epoch 83: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1132 - MinusLogProbMetric: 4.1132 - val_loss: 4.0938 - val_MinusLogProbMetric: 4.0938 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 84/1000
2023-09-12 06:06:17.573 
Epoch 84/1000 
	 loss: 4.1113, MinusLogProbMetric: 4.1113, val_loss: 4.1081, val_MinusLogProbMetric: 4.1081

Epoch 84: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1113 - MinusLogProbMetric: 4.1113 - val_loss: 4.1081 - val_MinusLogProbMetric: 4.1081 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 85/1000
2023-09-12 06:06:29.209 
Epoch 85/1000 
	 loss: 4.1007, MinusLogProbMetric: 4.1007, val_loss: 4.1183, val_MinusLogProbMetric: 4.1183

Epoch 85: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1007 - MinusLogProbMetric: 4.1007 - val_loss: 4.1183 - val_MinusLogProbMetric: 4.1183 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-12 06:06:40.812 
Epoch 86/1000 
	 loss: 4.1029, MinusLogProbMetric: 4.1029, val_loss: 4.0976, val_MinusLogProbMetric: 4.0976

Epoch 86: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1029 - MinusLogProbMetric: 4.1029 - val_loss: 4.0976 - val_MinusLogProbMetric: 4.0976 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-12 06:06:52.545 
Epoch 87/1000 
	 loss: 4.1037, MinusLogProbMetric: 4.1037, val_loss: 4.0875, val_MinusLogProbMetric: 4.0875

Epoch 87: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1037 - MinusLogProbMetric: 4.1037 - val_loss: 4.0875 - val_MinusLogProbMetric: 4.0875 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 88/1000
2023-09-12 06:07:04.297 
Epoch 88/1000 
	 loss: 4.0964, MinusLogProbMetric: 4.0964, val_loss: 4.1187, val_MinusLogProbMetric: 4.1187

Epoch 88: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.0964 - MinusLogProbMetric: 4.0964 - val_loss: 4.1187 - val_MinusLogProbMetric: 4.1187 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-12 06:07:16.056 
Epoch 89/1000 
	 loss: 4.1009, MinusLogProbMetric: 4.1009, val_loss: 4.0993, val_MinusLogProbMetric: 4.0993

Epoch 89: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1009 - MinusLogProbMetric: 4.1009 - val_loss: 4.0993 - val_MinusLogProbMetric: 4.0993 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-12 06:07:27.720 
Epoch 90/1000 
	 loss: 4.1031, MinusLogProbMetric: 4.1031, val_loss: 4.1051, val_MinusLogProbMetric: 4.1051

Epoch 90: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.1031 - MinusLogProbMetric: 4.1031 - val_loss: 4.1051 - val_MinusLogProbMetric: 4.1051 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 91/1000
2023-09-12 06:07:39.443 
Epoch 91/1000 
	 loss: 4.0995, MinusLogProbMetric: 4.0995, val_loss: 4.0971, val_MinusLogProbMetric: 4.0971

Epoch 91: val_loss did not improve from 4.08451
196/196 - 12s - loss: 4.0995 - MinusLogProbMetric: 4.0995 - val_loss: 4.0971 - val_MinusLogProbMetric: 4.0971 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 06:07:51.120 
Epoch 92/1000 
	 loss: 4.0999, MinusLogProbMetric: 4.0999, val_loss: 4.0836, val_MinusLogProbMetric: 4.0836

Epoch 92: val_loss improved from 4.08451 to 4.08364, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.0999 - MinusLogProbMetric: 4.0999 - val_loss: 4.0836 - val_MinusLogProbMetric: 4.0836 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-12 06:08:02.894 
Epoch 93/1000 
	 loss: 4.1037, MinusLogProbMetric: 4.1037, val_loss: 4.1226, val_MinusLogProbMetric: 4.1226

Epoch 93: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1037 - MinusLogProbMetric: 4.1037 - val_loss: 4.1226 - val_MinusLogProbMetric: 4.1226 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 94/1000
2023-09-12 06:08:14.533 
Epoch 94/1000 
	 loss: 4.1089, MinusLogProbMetric: 4.1089, val_loss: 4.1139, val_MinusLogProbMetric: 4.1139

Epoch 94: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1089 - MinusLogProbMetric: 4.1089 - val_loss: 4.1139 - val_MinusLogProbMetric: 4.1139 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-12 06:08:26.246 
Epoch 95/1000 
	 loss: 4.0944, MinusLogProbMetric: 4.0944, val_loss: 4.0864, val_MinusLogProbMetric: 4.0864

Epoch 95: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0944 - MinusLogProbMetric: 4.0944 - val_loss: 4.0864 - val_MinusLogProbMetric: 4.0864 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-12 06:08:37.982 
Epoch 96/1000 
	 loss: 4.1065, MinusLogProbMetric: 4.1065, val_loss: 4.1556, val_MinusLogProbMetric: 4.1556

Epoch 96: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1065 - MinusLogProbMetric: 4.1065 - val_loss: 4.1556 - val_MinusLogProbMetric: 4.1556 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 97/1000
2023-09-12 06:08:49.568 
Epoch 97/1000 
	 loss: 4.1015, MinusLogProbMetric: 4.1015, val_loss: 4.0921, val_MinusLogProbMetric: 4.0921

Epoch 97: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1015 - MinusLogProbMetric: 4.1015 - val_loss: 4.0921 - val_MinusLogProbMetric: 4.0921 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 98/1000
2023-09-12 06:09:01.207 
Epoch 98/1000 
	 loss: 4.1023, MinusLogProbMetric: 4.1023, val_loss: 4.1006, val_MinusLogProbMetric: 4.1006

Epoch 98: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1023 - MinusLogProbMetric: 4.1023 - val_loss: 4.1006 - val_MinusLogProbMetric: 4.1006 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 99/1000
2023-09-12 06:09:12.858 
Epoch 99/1000 
	 loss: 4.0982, MinusLogProbMetric: 4.0982, val_loss: 4.1069, val_MinusLogProbMetric: 4.1069

Epoch 99: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0982 - MinusLogProbMetric: 4.0982 - val_loss: 4.1069 - val_MinusLogProbMetric: 4.1069 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 06:09:24.542 
Epoch 100/1000 
	 loss: 4.1341, MinusLogProbMetric: 4.1341, val_loss: 4.6821, val_MinusLogProbMetric: 4.6821

Epoch 100: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1341 - MinusLogProbMetric: 4.1341 - val_loss: 4.6821 - val_MinusLogProbMetric: 4.6821 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-12 06:09:36.185 
Epoch 101/1000 
	 loss: 4.1696, MinusLogProbMetric: 4.1696, val_loss: 4.1240, val_MinusLogProbMetric: 4.1240

Epoch 101: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1696 - MinusLogProbMetric: 4.1696 - val_loss: 4.1240 - val_MinusLogProbMetric: 4.1240 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 102/1000
2023-09-12 06:09:47.802 
Epoch 102/1000 
	 loss: 4.1062, MinusLogProbMetric: 4.1062, val_loss: 4.1389, val_MinusLogProbMetric: 4.1389

Epoch 102: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1062 - MinusLogProbMetric: 4.1062 - val_loss: 4.1389 - val_MinusLogProbMetric: 4.1389 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 103/1000
2023-09-12 06:09:59.531 
Epoch 103/1000 
	 loss: 4.1018, MinusLogProbMetric: 4.1018, val_loss: 4.1045, val_MinusLogProbMetric: 4.1045

Epoch 103: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1018 - MinusLogProbMetric: 4.1018 - val_loss: 4.1045 - val_MinusLogProbMetric: 4.1045 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-12 06:10:11.146 
Epoch 104/1000 
	 loss: 4.0988, MinusLogProbMetric: 4.0988, val_loss: 4.0987, val_MinusLogProbMetric: 4.0987

Epoch 104: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0988 - MinusLogProbMetric: 4.0988 - val_loss: 4.0987 - val_MinusLogProbMetric: 4.0987 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 105/1000
2023-09-12 06:10:22.924 
Epoch 105/1000 
	 loss: 4.0961, MinusLogProbMetric: 4.0961, val_loss: 4.1043, val_MinusLogProbMetric: 4.1043

Epoch 105: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0961 - MinusLogProbMetric: 4.0961 - val_loss: 4.1043 - val_MinusLogProbMetric: 4.1043 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-12 06:10:34.205 
Epoch 106/1000 
	 loss: 4.0990, MinusLogProbMetric: 4.0990, val_loss: 4.1194, val_MinusLogProbMetric: 4.1194

Epoch 106: val_loss did not improve from 4.08364
196/196 - 11s - loss: 4.0990 - MinusLogProbMetric: 4.0990 - val_loss: 4.1194 - val_MinusLogProbMetric: 4.1194 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 107/1000
2023-09-12 06:10:45.591 
Epoch 107/1000 
	 loss: 4.0991, MinusLogProbMetric: 4.0991, val_loss: 4.0857, val_MinusLogProbMetric: 4.0857

Epoch 107: val_loss did not improve from 4.08364
196/196 - 11s - loss: 4.0991 - MinusLogProbMetric: 4.0991 - val_loss: 4.0857 - val_MinusLogProbMetric: 4.0857 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 108/1000
2023-09-12 06:10:56.720 
Epoch 108/1000 
	 loss: 4.0956, MinusLogProbMetric: 4.0956, val_loss: 4.1077, val_MinusLogProbMetric: 4.1077

Epoch 108: val_loss did not improve from 4.08364
196/196 - 11s - loss: 4.0956 - MinusLogProbMetric: 4.0956 - val_loss: 4.1077 - val_MinusLogProbMetric: 4.1077 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 109/1000
2023-09-12 06:11:07.675 
Epoch 109/1000 
	 loss: 4.0960, MinusLogProbMetric: 4.0960, val_loss: 4.1052, val_MinusLogProbMetric: 4.1052

Epoch 109: val_loss did not improve from 4.08364
196/196 - 11s - loss: 4.0960 - MinusLogProbMetric: 4.0960 - val_loss: 4.1052 - val_MinusLogProbMetric: 4.1052 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 110/1000
2023-09-12 06:11:18.895 
Epoch 110/1000 
	 loss: 4.1004, MinusLogProbMetric: 4.1004, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 110: val_loss did not improve from 4.08364
196/196 - 11s - loss: 4.1004 - MinusLogProbMetric: 4.1004 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 111/1000
2023-09-12 06:11:30.545 
Epoch 111/1000 
	 loss: 4.0940, MinusLogProbMetric: 4.0940, val_loss: 4.1044, val_MinusLogProbMetric: 4.1044

Epoch 111: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0940 - MinusLogProbMetric: 4.0940 - val_loss: 4.1044 - val_MinusLogProbMetric: 4.1044 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 112/1000
2023-09-12 06:11:42.160 
Epoch 112/1000 
	 loss: 4.0914, MinusLogProbMetric: 4.0914, val_loss: 4.0938, val_MinusLogProbMetric: 4.0938

Epoch 112: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0914 - MinusLogProbMetric: 4.0914 - val_loss: 4.0938 - val_MinusLogProbMetric: 4.0938 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 113/1000
2023-09-12 06:11:53.886 
Epoch 113/1000 
	 loss: 4.1784, MinusLogProbMetric: 4.1784, val_loss: 4.1589, val_MinusLogProbMetric: 4.1589

Epoch 113: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1784 - MinusLogProbMetric: 4.1784 - val_loss: 4.1589 - val_MinusLogProbMetric: 4.1589 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-12 06:12:05.617 
Epoch 114/1000 
	 loss: 4.1117, MinusLogProbMetric: 4.1117, val_loss: 4.0991, val_MinusLogProbMetric: 4.0991

Epoch 114: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1117 - MinusLogProbMetric: 4.1117 - val_loss: 4.0991 - val_MinusLogProbMetric: 4.0991 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 115/1000
2023-09-12 06:12:17.238 
Epoch 115/1000 
	 loss: 4.1025, MinusLogProbMetric: 4.1025, val_loss: 4.1274, val_MinusLogProbMetric: 4.1274

Epoch 115: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1025 - MinusLogProbMetric: 4.1025 - val_loss: 4.1274 - val_MinusLogProbMetric: 4.1274 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 116/1000
2023-09-12 06:12:29.013 
Epoch 116/1000 
	 loss: 4.1000, MinusLogProbMetric: 4.1000, val_loss: 4.1065, val_MinusLogProbMetric: 4.1065

Epoch 116: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1000 - MinusLogProbMetric: 4.1000 - val_loss: 4.1065 - val_MinusLogProbMetric: 4.1065 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 117/1000
2023-09-12 06:12:40.742 
Epoch 117/1000 
	 loss: 4.0977, MinusLogProbMetric: 4.0977, val_loss: 4.1145, val_MinusLogProbMetric: 4.1145

Epoch 117: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0977 - MinusLogProbMetric: 4.0977 - val_loss: 4.1145 - val_MinusLogProbMetric: 4.1145 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-12 06:12:52.508 
Epoch 118/1000 
	 loss: 4.0951, MinusLogProbMetric: 4.0951, val_loss: 4.0919, val_MinusLogProbMetric: 4.0919

Epoch 118: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0951 - MinusLogProbMetric: 4.0951 - val_loss: 4.0919 - val_MinusLogProbMetric: 4.0919 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-12 06:13:04.256 
Epoch 119/1000 
	 loss: 4.1008, MinusLogProbMetric: 4.1008, val_loss: 4.0936, val_MinusLogProbMetric: 4.0936

Epoch 119: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1008 - MinusLogProbMetric: 4.1008 - val_loss: 4.0936 - val_MinusLogProbMetric: 4.0936 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 120/1000
2023-09-12 06:13:15.881 
Epoch 120/1000 
	 loss: 4.1001, MinusLogProbMetric: 4.1001, val_loss: 4.1319, val_MinusLogProbMetric: 4.1319

Epoch 120: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.1001 - MinusLogProbMetric: 4.1001 - val_loss: 4.1319 - val_MinusLogProbMetric: 4.1319 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 121/1000
2023-09-12 06:13:27.600 
Epoch 121/1000 
	 loss: 4.0906, MinusLogProbMetric: 4.0906, val_loss: 4.0915, val_MinusLogProbMetric: 4.0915

Epoch 121: val_loss did not improve from 4.08364
196/196 - 12s - loss: 4.0906 - MinusLogProbMetric: 4.0906 - val_loss: 4.0915 - val_MinusLogProbMetric: 4.0915 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-12 06:13:39.288 
Epoch 122/1000 
	 loss: 4.0910, MinusLogProbMetric: 4.0910, val_loss: 4.0833, val_MinusLogProbMetric: 4.0833

Epoch 122: val_loss improved from 4.08364 to 4.08328, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.0910 - MinusLogProbMetric: 4.0910 - val_loss: 4.0833 - val_MinusLogProbMetric: 4.0833 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-12 06:13:51.272 
Epoch 123/1000 
	 loss: 4.0889, MinusLogProbMetric: 4.0889, val_loss: 4.0960, val_MinusLogProbMetric: 4.0960

Epoch 123: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0889 - MinusLogProbMetric: 4.0889 - val_loss: 4.0960 - val_MinusLogProbMetric: 4.0960 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-12 06:14:03.004 
Epoch 124/1000 
	 loss: 4.0955, MinusLogProbMetric: 4.0955, val_loss: 4.1109, val_MinusLogProbMetric: 4.1109

Epoch 124: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0955 - MinusLogProbMetric: 4.0955 - val_loss: 4.1109 - val_MinusLogProbMetric: 4.1109 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-12 06:14:14.634 
Epoch 125/1000 
	 loss: 4.0927, MinusLogProbMetric: 4.0927, val_loss: 4.0833, val_MinusLogProbMetric: 4.0833

Epoch 125: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0927 - MinusLogProbMetric: 4.0927 - val_loss: 4.0833 - val_MinusLogProbMetric: 4.0833 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 126/1000
2023-09-12 06:14:26.030 
Epoch 126/1000 
	 loss: 4.0886, MinusLogProbMetric: 4.0886, val_loss: 4.1179, val_MinusLogProbMetric: 4.1179

Epoch 126: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0886 - MinusLogProbMetric: 4.0886 - val_loss: 4.1179 - val_MinusLogProbMetric: 4.1179 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 127/1000
2023-09-12 06:14:37.383 
Epoch 127/1000 
	 loss: 4.0956, MinusLogProbMetric: 4.0956, val_loss: 4.1876, val_MinusLogProbMetric: 4.1876

Epoch 127: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0956 - MinusLogProbMetric: 4.0956 - val_loss: 4.1876 - val_MinusLogProbMetric: 4.1876 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 128/1000
2023-09-12 06:14:48.799 
Epoch 128/1000 
	 loss: 4.0985, MinusLogProbMetric: 4.0985, val_loss: 4.0918, val_MinusLogProbMetric: 4.0918

Epoch 128: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0985 - MinusLogProbMetric: 4.0985 - val_loss: 4.0918 - val_MinusLogProbMetric: 4.0918 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 129/1000
2023-09-12 06:15:00.286 
Epoch 129/1000 
	 loss: 4.0903, MinusLogProbMetric: 4.0903, val_loss: 4.0931, val_MinusLogProbMetric: 4.0931

Epoch 129: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0903 - MinusLogProbMetric: 4.0903 - val_loss: 4.0931 - val_MinusLogProbMetric: 4.0931 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 130/1000
2023-09-12 06:15:11.862 
Epoch 130/1000 
	 loss: 4.1000, MinusLogProbMetric: 4.1000, val_loss: 4.0950, val_MinusLogProbMetric: 4.0950

Epoch 130: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.1000 - MinusLogProbMetric: 4.1000 - val_loss: 4.0950 - val_MinusLogProbMetric: 4.0950 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 131/1000
2023-09-12 06:15:23.337 
Epoch 131/1000 
	 loss: 4.0892, MinusLogProbMetric: 4.0892, val_loss: 4.1009, val_MinusLogProbMetric: 4.1009

Epoch 131: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0892 - MinusLogProbMetric: 4.0892 - val_loss: 4.1009 - val_MinusLogProbMetric: 4.1009 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 132/1000
2023-09-12 06:15:34.353 
Epoch 132/1000 
	 loss: 4.0895, MinusLogProbMetric: 4.0895, val_loss: 4.1264, val_MinusLogProbMetric: 4.1264

Epoch 132: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0895 - MinusLogProbMetric: 4.0895 - val_loss: 4.1264 - val_MinusLogProbMetric: 4.1264 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 133/1000
2023-09-12 06:15:45.517 
Epoch 133/1000 
	 loss: 4.1053, MinusLogProbMetric: 4.1053, val_loss: 4.0873, val_MinusLogProbMetric: 4.0873

Epoch 133: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.1053 - MinusLogProbMetric: 4.1053 - val_loss: 4.0873 - val_MinusLogProbMetric: 4.0873 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 134/1000
2023-09-12 06:15:57.006 
Epoch 134/1000 
	 loss: 4.0871, MinusLogProbMetric: 4.0871, val_loss: 4.0933, val_MinusLogProbMetric: 4.0933

Epoch 134: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0871 - MinusLogProbMetric: 4.0871 - val_loss: 4.0933 - val_MinusLogProbMetric: 4.0933 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 135/1000
2023-09-12 06:16:08.759 
Epoch 135/1000 
	 loss: 4.1070, MinusLogProbMetric: 4.1070, val_loss: 4.1093, val_MinusLogProbMetric: 4.1093

Epoch 135: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.1070 - MinusLogProbMetric: 4.1070 - val_loss: 4.1093 - val_MinusLogProbMetric: 4.1093 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-12 06:16:20.407 
Epoch 136/1000 
	 loss: 4.0838, MinusLogProbMetric: 4.0838, val_loss: 4.1003, val_MinusLogProbMetric: 4.1003

Epoch 136: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0838 - MinusLogProbMetric: 4.0838 - val_loss: 4.1003 - val_MinusLogProbMetric: 4.1003 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 137/1000
2023-09-12 06:16:31.991 
Epoch 137/1000 
	 loss: 4.0877, MinusLogProbMetric: 4.0877, val_loss: 4.0938, val_MinusLogProbMetric: 4.0938

Epoch 137: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0877 - MinusLogProbMetric: 4.0877 - val_loss: 4.0938 - val_MinusLogProbMetric: 4.0938 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 138/1000
2023-09-12 06:16:43.771 
Epoch 138/1000 
	 loss: 4.0979, MinusLogProbMetric: 4.0979, val_loss: 4.0930, val_MinusLogProbMetric: 4.0930

Epoch 138: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0979 - MinusLogProbMetric: 4.0979 - val_loss: 4.0930 - val_MinusLogProbMetric: 4.0930 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-12 06:16:55.504 
Epoch 139/1000 
	 loss: 4.0825, MinusLogProbMetric: 4.0825, val_loss: 4.0913, val_MinusLogProbMetric: 4.0913

Epoch 139: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0825 - MinusLogProbMetric: 4.0825 - val_loss: 4.0913 - val_MinusLogProbMetric: 4.0913 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-12 06:17:07.282 
Epoch 140/1000 
	 loss: 4.0878, MinusLogProbMetric: 4.0878, val_loss: 4.1034, val_MinusLogProbMetric: 4.1034

Epoch 140: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0878 - MinusLogProbMetric: 4.0878 - val_loss: 4.1034 - val_MinusLogProbMetric: 4.1034 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 141/1000
2023-09-12 06:17:18.955 
Epoch 141/1000 
	 loss: 4.0891, MinusLogProbMetric: 4.0891, val_loss: 4.1063, val_MinusLogProbMetric: 4.1063

Epoch 141: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0891 - MinusLogProbMetric: 4.0891 - val_loss: 4.1063 - val_MinusLogProbMetric: 4.1063 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 142/1000
2023-09-12 06:17:30.921 
Epoch 142/1000 
	 loss: 4.0820, MinusLogProbMetric: 4.0820, val_loss: 4.1024, val_MinusLogProbMetric: 4.1024

Epoch 142: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0820 - MinusLogProbMetric: 4.0820 - val_loss: 4.1024 - val_MinusLogProbMetric: 4.1024 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 143/1000
2023-09-12 06:17:42.747 
Epoch 143/1000 
	 loss: 4.0909, MinusLogProbMetric: 4.0909, val_loss: 4.0912, val_MinusLogProbMetric: 4.0912

Epoch 143: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0909 - MinusLogProbMetric: 4.0909 - val_loss: 4.0912 - val_MinusLogProbMetric: 4.0912 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 144/1000
2023-09-12 06:17:54.561 
Epoch 144/1000 
	 loss: 4.0857, MinusLogProbMetric: 4.0857, val_loss: 4.0855, val_MinusLogProbMetric: 4.0855

Epoch 144: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0857 - MinusLogProbMetric: 4.0857 - val_loss: 4.0855 - val_MinusLogProbMetric: 4.0855 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 145/1000
2023-09-12 06:18:06.272 
Epoch 145/1000 
	 loss: 4.0896, MinusLogProbMetric: 4.0896, val_loss: 4.1120, val_MinusLogProbMetric: 4.1120

Epoch 145: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0896 - MinusLogProbMetric: 4.0896 - val_loss: 4.1120 - val_MinusLogProbMetric: 4.1120 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 146/1000
2023-09-12 06:18:17.899 
Epoch 146/1000 
	 loss: 4.0864, MinusLogProbMetric: 4.0864, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 146: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0864 - MinusLogProbMetric: 4.0864 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 147/1000
2023-09-12 06:18:29.625 
Epoch 147/1000 
	 loss: 4.0860, MinusLogProbMetric: 4.0860, val_loss: 4.1081, val_MinusLogProbMetric: 4.1081

Epoch 147: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0860 - MinusLogProbMetric: 4.0860 - val_loss: 4.1081 - val_MinusLogProbMetric: 4.1081 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-12 06:18:41.100 
Epoch 148/1000 
	 loss: 4.0843, MinusLogProbMetric: 4.0843, val_loss: 4.0921, val_MinusLogProbMetric: 4.0921

Epoch 148: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0843 - MinusLogProbMetric: 4.0843 - val_loss: 4.0921 - val_MinusLogProbMetric: 4.0921 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 149/1000
2023-09-12 06:18:52.769 
Epoch 149/1000 
	 loss: 4.0815, MinusLogProbMetric: 4.0815, val_loss: 4.0929, val_MinusLogProbMetric: 4.0929

Epoch 149: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0815 - MinusLogProbMetric: 4.0815 - val_loss: 4.0929 - val_MinusLogProbMetric: 4.0929 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-12 06:19:04.397 
Epoch 150/1000 
	 loss: 4.0835, MinusLogProbMetric: 4.0835, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 150: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0835 - MinusLogProbMetric: 4.0835 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 151/1000
2023-09-12 06:19:16.076 
Epoch 151/1000 
	 loss: 4.0924, MinusLogProbMetric: 4.0924, val_loss: 4.1109, val_MinusLogProbMetric: 4.1109

Epoch 151: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0924 - MinusLogProbMetric: 4.0924 - val_loss: 4.1109 - val_MinusLogProbMetric: 4.1109 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-12 06:19:27.724 
Epoch 152/1000 
	 loss: 4.0916, MinusLogProbMetric: 4.0916, val_loss: 4.1015, val_MinusLogProbMetric: 4.1015

Epoch 152: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0916 - MinusLogProbMetric: 4.0916 - val_loss: 4.1015 - val_MinusLogProbMetric: 4.1015 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 153/1000
2023-09-12 06:19:39.443 
Epoch 153/1000 
	 loss: 4.0835, MinusLogProbMetric: 4.0835, val_loss: 4.0962, val_MinusLogProbMetric: 4.0962

Epoch 153: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0835 - MinusLogProbMetric: 4.0835 - val_loss: 4.0962 - val_MinusLogProbMetric: 4.0962 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 154/1000
2023-09-12 06:19:50.632 
Epoch 154/1000 
	 loss: 4.0845, MinusLogProbMetric: 4.0845, val_loss: 4.0865, val_MinusLogProbMetric: 4.0865

Epoch 154: val_loss did not improve from 4.08328
196/196 - 11s - loss: 4.0845 - MinusLogProbMetric: 4.0845 - val_loss: 4.0865 - val_MinusLogProbMetric: 4.0865 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 155/1000
2023-09-12 06:20:00.868 
Epoch 155/1000 
	 loss: 4.0863, MinusLogProbMetric: 4.0863, val_loss: 4.0888, val_MinusLogProbMetric: 4.0888

Epoch 155: val_loss did not improve from 4.08328
196/196 - 10s - loss: 4.0863 - MinusLogProbMetric: 4.0863 - val_loss: 4.0888 - val_MinusLogProbMetric: 4.0888 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 156/1000
2023-09-12 06:20:12.385 
Epoch 156/1000 
	 loss: 4.0796, MinusLogProbMetric: 4.0796, val_loss: 4.1084, val_MinusLogProbMetric: 4.1084

Epoch 156: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0796 - MinusLogProbMetric: 4.0796 - val_loss: 4.1084 - val_MinusLogProbMetric: 4.1084 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 157/1000
2023-09-12 06:20:24.055 
Epoch 157/1000 
	 loss: 4.0840, MinusLogProbMetric: 4.0840, val_loss: 4.0921, val_MinusLogProbMetric: 4.0921

Epoch 157: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0840 - MinusLogProbMetric: 4.0840 - val_loss: 4.0921 - val_MinusLogProbMetric: 4.0921 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-12 06:20:35.821 
Epoch 158/1000 
	 loss: 4.0895, MinusLogProbMetric: 4.0895, val_loss: 4.0882, val_MinusLogProbMetric: 4.0882

Epoch 158: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0895 - MinusLogProbMetric: 4.0895 - val_loss: 4.0882 - val_MinusLogProbMetric: 4.0882 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 159/1000
2023-09-12 06:20:47.463 
Epoch 159/1000 
	 loss: 4.0805, MinusLogProbMetric: 4.0805, val_loss: 4.0920, val_MinusLogProbMetric: 4.0920

Epoch 159: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0805 - MinusLogProbMetric: 4.0805 - val_loss: 4.0920 - val_MinusLogProbMetric: 4.0920 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 160/1000
2023-09-12 06:20:59.207 
Epoch 160/1000 
	 loss: 4.0843, MinusLogProbMetric: 4.0843, val_loss: 4.1024, val_MinusLogProbMetric: 4.1024

Epoch 160: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0843 - MinusLogProbMetric: 4.0843 - val_loss: 4.1024 - val_MinusLogProbMetric: 4.1024 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 161/1000
2023-09-12 06:21:10.822 
Epoch 161/1000 
	 loss: 4.0815, MinusLogProbMetric: 4.0815, val_loss: 4.0874, val_MinusLogProbMetric: 4.0874

Epoch 161: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0815 - MinusLogProbMetric: 4.0815 - val_loss: 4.0874 - val_MinusLogProbMetric: 4.0874 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 162/1000
2023-09-12 06:21:22.550 
Epoch 162/1000 
	 loss: 4.0785, MinusLogProbMetric: 4.0785, val_loss: 4.0968, val_MinusLogProbMetric: 4.0968

Epoch 162: val_loss did not improve from 4.08328
196/196 - 12s - loss: 4.0785 - MinusLogProbMetric: 4.0785 - val_loss: 4.0968 - val_MinusLogProbMetric: 4.0968 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 163/1000
2023-09-12 06:21:34.162 
Epoch 163/1000 
	 loss: 4.0810, MinusLogProbMetric: 4.0810, val_loss: 4.0780, val_MinusLogProbMetric: 4.0780

Epoch 163: val_loss improved from 4.08328 to 4.07798, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_76/weights/best_weights.h5
196/196 - 12s - loss: 4.0810 - MinusLogProbMetric: 4.0810 - val_loss: 4.0780 - val_MinusLogProbMetric: 4.0780 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 164/1000
2023-09-12 06:21:46.061 
Epoch 164/1000 
	 loss: 4.0852, MinusLogProbMetric: 4.0852, val_loss: 4.0854, val_MinusLogProbMetric: 4.0854

Epoch 164: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0852 - MinusLogProbMetric: 4.0852 - val_loss: 4.0854 - val_MinusLogProbMetric: 4.0854 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 165/1000
2023-09-12 06:21:57.826 
Epoch 165/1000 
	 loss: 4.0840, MinusLogProbMetric: 4.0840, val_loss: 4.0981, val_MinusLogProbMetric: 4.0981

Epoch 165: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0840 - MinusLogProbMetric: 4.0840 - val_loss: 4.0981 - val_MinusLogProbMetric: 4.0981 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 166/1000
2023-09-12 06:22:09.514 
Epoch 166/1000 
	 loss: 4.0797, MinusLogProbMetric: 4.0797, val_loss: 4.1020, val_MinusLogProbMetric: 4.1020

Epoch 166: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0797 - MinusLogProbMetric: 4.0797 - val_loss: 4.1020 - val_MinusLogProbMetric: 4.1020 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 167/1000
2023-09-12 06:22:21.186 
Epoch 167/1000 
	 loss: 4.0876, MinusLogProbMetric: 4.0876, val_loss: 4.1296, val_MinusLogProbMetric: 4.1296

Epoch 167: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0876 - MinusLogProbMetric: 4.0876 - val_loss: 4.1296 - val_MinusLogProbMetric: 4.1296 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 168/1000
2023-09-12 06:22:32.714 
Epoch 168/1000 
	 loss: 4.0857, MinusLogProbMetric: 4.0857, val_loss: 4.1145, val_MinusLogProbMetric: 4.1145

Epoch 168: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0857 - MinusLogProbMetric: 4.0857 - val_loss: 4.1145 - val_MinusLogProbMetric: 4.1145 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 169/1000
2023-09-12 06:22:44.400 
Epoch 169/1000 
	 loss: 4.0852, MinusLogProbMetric: 4.0852, val_loss: 4.0933, val_MinusLogProbMetric: 4.0933

Epoch 169: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0852 - MinusLogProbMetric: 4.0852 - val_loss: 4.0933 - val_MinusLogProbMetric: 4.0933 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 170/1000
2023-09-12 06:22:56.167 
Epoch 170/1000 
	 loss: 4.0767, MinusLogProbMetric: 4.0767, val_loss: 4.1014, val_MinusLogProbMetric: 4.1014

Epoch 170: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0767 - MinusLogProbMetric: 4.0767 - val_loss: 4.1014 - val_MinusLogProbMetric: 4.1014 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 171/1000
2023-09-12 06:23:07.826 
Epoch 171/1000 
	 loss: 4.0832, MinusLogProbMetric: 4.0832, val_loss: 4.0999, val_MinusLogProbMetric: 4.0999

Epoch 171: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0832 - MinusLogProbMetric: 4.0832 - val_loss: 4.0999 - val_MinusLogProbMetric: 4.0999 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 172/1000
2023-09-12 06:23:19.438 
Epoch 172/1000 
	 loss: 4.0788, MinusLogProbMetric: 4.0788, val_loss: 4.1050, val_MinusLogProbMetric: 4.1050

Epoch 172: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0788 - MinusLogProbMetric: 4.0788 - val_loss: 4.1050 - val_MinusLogProbMetric: 4.1050 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 06:23:31.138 
Epoch 173/1000 
	 loss: 4.0788, MinusLogProbMetric: 4.0788, val_loss: 4.1042, val_MinusLogProbMetric: 4.1042

Epoch 173: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0788 - MinusLogProbMetric: 4.0788 - val_loss: 4.1042 - val_MinusLogProbMetric: 4.1042 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 174/1000
2023-09-12 06:23:42.902 
Epoch 174/1000 
	 loss: 4.0791, MinusLogProbMetric: 4.0791, val_loss: 4.0884, val_MinusLogProbMetric: 4.0884

Epoch 174: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0791 - MinusLogProbMetric: 4.0791 - val_loss: 4.0884 - val_MinusLogProbMetric: 4.0884 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 175/1000
2023-09-12 06:23:54.559 
Epoch 175/1000 
	 loss: 4.0786, MinusLogProbMetric: 4.0786, val_loss: 4.0954, val_MinusLogProbMetric: 4.0954

Epoch 175: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0786 - MinusLogProbMetric: 4.0786 - val_loss: 4.0954 - val_MinusLogProbMetric: 4.0954 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-12 06:24:06.343 
Epoch 176/1000 
	 loss: 4.0808, MinusLogProbMetric: 4.0808, val_loss: 4.0927, val_MinusLogProbMetric: 4.0927

Epoch 176: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0808 - MinusLogProbMetric: 4.0808 - val_loss: 4.0927 - val_MinusLogProbMetric: 4.0927 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-12 06:24:18.069 
Epoch 177/1000 
	 loss: 4.0777, MinusLogProbMetric: 4.0777, val_loss: 4.1045, val_MinusLogProbMetric: 4.1045

Epoch 177: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0777 - MinusLogProbMetric: 4.0777 - val_loss: 4.1045 - val_MinusLogProbMetric: 4.1045 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 178/1000
2023-09-12 06:24:29.755 
Epoch 178/1000 
	 loss: 4.0787, MinusLogProbMetric: 4.0787, val_loss: 4.0881, val_MinusLogProbMetric: 4.0881

Epoch 178: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0787 - MinusLogProbMetric: 4.0787 - val_loss: 4.0881 - val_MinusLogProbMetric: 4.0881 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-12 06:24:41.494 
Epoch 179/1000 
	 loss: 4.0799, MinusLogProbMetric: 4.0799, val_loss: 4.0905, val_MinusLogProbMetric: 4.0905

Epoch 179: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0799 - MinusLogProbMetric: 4.0799 - val_loss: 4.0905 - val_MinusLogProbMetric: 4.0905 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 180/1000
2023-09-12 06:24:53.130 
Epoch 180/1000 
	 loss: 4.0806, MinusLogProbMetric: 4.0806, val_loss: 4.1183, val_MinusLogProbMetric: 4.1183

Epoch 180: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0806 - MinusLogProbMetric: 4.0806 - val_loss: 4.1183 - val_MinusLogProbMetric: 4.1183 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 181/1000
2023-09-12 06:25:04.801 
Epoch 181/1000 
	 loss: 4.0867, MinusLogProbMetric: 4.0867, val_loss: 4.1263, val_MinusLogProbMetric: 4.1263

Epoch 181: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0867 - MinusLogProbMetric: 4.0867 - val_loss: 4.1263 - val_MinusLogProbMetric: 4.1263 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 182/1000
2023-09-12 06:25:16.474 
Epoch 182/1000 
	 loss: 4.0758, MinusLogProbMetric: 4.0758, val_loss: 4.1048, val_MinusLogProbMetric: 4.1048

Epoch 182: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0758 - MinusLogProbMetric: 4.0758 - val_loss: 4.1048 - val_MinusLogProbMetric: 4.1048 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 183/1000
2023-09-12 06:25:28.219 
Epoch 183/1000 
	 loss: 4.0781, MinusLogProbMetric: 4.0781, val_loss: 4.1031, val_MinusLogProbMetric: 4.1031

Epoch 183: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0781 - MinusLogProbMetric: 4.0781 - val_loss: 4.1031 - val_MinusLogProbMetric: 4.1031 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 184/1000
2023-09-12 06:25:39.913 
Epoch 184/1000 
	 loss: 4.0897, MinusLogProbMetric: 4.0897, val_loss: 4.1056, val_MinusLogProbMetric: 4.1056

Epoch 184: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0897 - MinusLogProbMetric: 4.0897 - val_loss: 4.1056 - val_MinusLogProbMetric: 4.1056 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 185/1000
2023-09-12 06:25:51.650 
Epoch 185/1000 
	 loss: 4.0782, MinusLogProbMetric: 4.0782, val_loss: 4.1057, val_MinusLogProbMetric: 4.1057

Epoch 185: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0782 - MinusLogProbMetric: 4.0782 - val_loss: 4.1057 - val_MinusLogProbMetric: 4.1057 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 186/1000
2023-09-12 06:26:03.338 
Epoch 186/1000 
	 loss: 4.0816, MinusLogProbMetric: 4.0816, val_loss: 4.0955, val_MinusLogProbMetric: 4.0955

Epoch 186: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0816 - MinusLogProbMetric: 4.0816 - val_loss: 4.0955 - val_MinusLogProbMetric: 4.0955 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 187/1000
2023-09-12 06:26:15.071 
Epoch 187/1000 
	 loss: 4.0769, MinusLogProbMetric: 4.0769, val_loss: 4.1173, val_MinusLogProbMetric: 4.1173

Epoch 187: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0769 - MinusLogProbMetric: 4.0769 - val_loss: 4.1173 - val_MinusLogProbMetric: 4.1173 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 188/1000
2023-09-12 06:26:26.755 
Epoch 188/1000 
	 loss: 4.0729, MinusLogProbMetric: 4.0729, val_loss: 4.0914, val_MinusLogProbMetric: 4.0914

Epoch 188: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0729 - MinusLogProbMetric: 4.0729 - val_loss: 4.0914 - val_MinusLogProbMetric: 4.0914 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 189/1000
2023-09-12 06:26:38.335 
Epoch 189/1000 
	 loss: 4.0785, MinusLogProbMetric: 4.0785, val_loss: 4.0916, val_MinusLogProbMetric: 4.0916

Epoch 189: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0785 - MinusLogProbMetric: 4.0785 - val_loss: 4.0916 - val_MinusLogProbMetric: 4.0916 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 190/1000
2023-09-12 06:26:50.038 
Epoch 190/1000 
	 loss: 4.0834, MinusLogProbMetric: 4.0834, val_loss: 4.0841, val_MinusLogProbMetric: 4.0841

Epoch 190: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0834 - MinusLogProbMetric: 4.0834 - val_loss: 4.0841 - val_MinusLogProbMetric: 4.0841 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-12 06:27:01.789 
Epoch 191/1000 
	 loss: 4.0780, MinusLogProbMetric: 4.0780, val_loss: 4.1322, val_MinusLogProbMetric: 4.1322

Epoch 191: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0780 - MinusLogProbMetric: 4.0780 - val_loss: 4.1322 - val_MinusLogProbMetric: 4.1322 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 192/1000
2023-09-12 06:27:13.492 
Epoch 192/1000 
	 loss: 4.0783, MinusLogProbMetric: 4.0783, val_loss: 4.1040, val_MinusLogProbMetric: 4.1040

Epoch 192: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0783 - MinusLogProbMetric: 4.0783 - val_loss: 4.1040 - val_MinusLogProbMetric: 4.1040 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-12 06:27:25.202 
Epoch 193/1000 
	 loss: 4.0746, MinusLogProbMetric: 4.0746, val_loss: 4.0912, val_MinusLogProbMetric: 4.0912

Epoch 193: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0746 - MinusLogProbMetric: 4.0746 - val_loss: 4.0912 - val_MinusLogProbMetric: 4.0912 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-12 06:27:36.868 
Epoch 194/1000 
	 loss: 4.0729, MinusLogProbMetric: 4.0729, val_loss: 4.1068, val_MinusLogProbMetric: 4.1068

Epoch 194: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0729 - MinusLogProbMetric: 4.0729 - val_loss: 4.1068 - val_MinusLogProbMetric: 4.1068 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 195/1000
2023-09-12 06:27:48.504 
Epoch 195/1000 
	 loss: 4.0724, MinusLogProbMetric: 4.0724, val_loss: 4.1025, val_MinusLogProbMetric: 4.1025

Epoch 195: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0724 - MinusLogProbMetric: 4.0724 - val_loss: 4.1025 - val_MinusLogProbMetric: 4.1025 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 196/1000
2023-09-12 06:28:00.173 
Epoch 196/1000 
	 loss: 4.0709, MinusLogProbMetric: 4.0709, val_loss: 4.1005, val_MinusLogProbMetric: 4.1005

Epoch 196: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0709 - MinusLogProbMetric: 4.0709 - val_loss: 4.1005 - val_MinusLogProbMetric: 4.1005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-12 06:28:11.862 
Epoch 197/1000 
	 loss: 4.0712, MinusLogProbMetric: 4.0712, val_loss: 4.0918, val_MinusLogProbMetric: 4.0918

Epoch 197: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0712 - MinusLogProbMetric: 4.0712 - val_loss: 4.0918 - val_MinusLogProbMetric: 4.0918 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-12 06:28:23.465 
Epoch 198/1000 
	 loss: 4.0748, MinusLogProbMetric: 4.0748, val_loss: 4.1156, val_MinusLogProbMetric: 4.1156

Epoch 198: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0748 - MinusLogProbMetric: 4.0748 - val_loss: 4.1156 - val_MinusLogProbMetric: 4.1156 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 199/1000
2023-09-12 06:28:35.151 
Epoch 199/1000 
	 loss: 4.0721, MinusLogProbMetric: 4.0721, val_loss: 4.1026, val_MinusLogProbMetric: 4.1026

Epoch 199: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0721 - MinusLogProbMetric: 4.0721 - val_loss: 4.1026 - val_MinusLogProbMetric: 4.1026 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-12 06:28:46.933 
Epoch 200/1000 
	 loss: 4.0726, MinusLogProbMetric: 4.0726, val_loss: 4.1023, val_MinusLogProbMetric: 4.1023

Epoch 200: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0726 - MinusLogProbMetric: 4.0726 - val_loss: 4.1023 - val_MinusLogProbMetric: 4.1023 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-12 06:28:58.797 
Epoch 201/1000 
	 loss: 4.0727, MinusLogProbMetric: 4.0727, val_loss: 4.0980, val_MinusLogProbMetric: 4.0980

Epoch 201: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0727 - MinusLogProbMetric: 4.0727 - val_loss: 4.0980 - val_MinusLogProbMetric: 4.0980 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 202/1000
2023-09-12 06:29:10.538 
Epoch 202/1000 
	 loss: 4.0833, MinusLogProbMetric: 4.0833, val_loss: 4.0981, val_MinusLogProbMetric: 4.0981

Epoch 202: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0833 - MinusLogProbMetric: 4.0833 - val_loss: 4.0981 - val_MinusLogProbMetric: 4.0981 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-12 06:29:22.157 
Epoch 203/1000 
	 loss: 4.0679, MinusLogProbMetric: 4.0679, val_loss: 4.1092, val_MinusLogProbMetric: 4.1092

Epoch 203: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0679 - MinusLogProbMetric: 4.0679 - val_loss: 4.1092 - val_MinusLogProbMetric: 4.1092 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 204/1000
2023-09-12 06:29:33.887 
Epoch 204/1000 
	 loss: 4.0796, MinusLogProbMetric: 4.0796, val_loss: 4.1017, val_MinusLogProbMetric: 4.1017

Epoch 204: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0796 - MinusLogProbMetric: 4.0796 - val_loss: 4.1017 - val_MinusLogProbMetric: 4.1017 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-12 06:29:45.544 
Epoch 205/1000 
	 loss: 4.0721, MinusLogProbMetric: 4.0721, val_loss: 4.1131, val_MinusLogProbMetric: 4.1131

Epoch 205: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0721 - MinusLogProbMetric: 4.0721 - val_loss: 4.1131 - val_MinusLogProbMetric: 4.1131 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 206/1000
2023-09-12 06:29:57.206 
Epoch 206/1000 
	 loss: 4.0712, MinusLogProbMetric: 4.0712, val_loss: 4.1169, val_MinusLogProbMetric: 4.1169

Epoch 206: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0712 - MinusLogProbMetric: 4.0712 - val_loss: 4.1169 - val_MinusLogProbMetric: 4.1169 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-12 06:30:08.938 
Epoch 207/1000 
	 loss: 4.0756, MinusLogProbMetric: 4.0756, val_loss: 4.0995, val_MinusLogProbMetric: 4.0995

Epoch 207: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0756 - MinusLogProbMetric: 4.0756 - val_loss: 4.0995 - val_MinusLogProbMetric: 4.0995 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-12 06:30:20.594 
Epoch 208/1000 
	 loss: 4.0756, MinusLogProbMetric: 4.0756, val_loss: 4.0897, val_MinusLogProbMetric: 4.0897

Epoch 208: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0756 - MinusLogProbMetric: 4.0756 - val_loss: 4.0897 - val_MinusLogProbMetric: 4.0897 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 209/1000
2023-09-12 06:30:32.233 
Epoch 209/1000 
	 loss: 4.0845, MinusLogProbMetric: 4.0845, val_loss: 4.0933, val_MinusLogProbMetric: 4.0933

Epoch 209: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0845 - MinusLogProbMetric: 4.0845 - val_loss: 4.0933 - val_MinusLogProbMetric: 4.0933 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-12 06:30:43.864 
Epoch 210/1000 
	 loss: 4.0730, MinusLogProbMetric: 4.0730, val_loss: 4.0927, val_MinusLogProbMetric: 4.0927

Epoch 210: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0730 - MinusLogProbMetric: 4.0730 - val_loss: 4.0927 - val_MinusLogProbMetric: 4.0927 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 211/1000
2023-09-12 06:30:55.596 
Epoch 211/1000 
	 loss: 4.0737, MinusLogProbMetric: 4.0737, val_loss: 4.0953, val_MinusLogProbMetric: 4.0953

Epoch 211: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0737 - MinusLogProbMetric: 4.0737 - val_loss: 4.0953 - val_MinusLogProbMetric: 4.0953 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 212/1000
2023-09-12 06:31:07.252 
Epoch 212/1000 
	 loss: 4.0684, MinusLogProbMetric: 4.0684, val_loss: 4.0889, val_MinusLogProbMetric: 4.0889

Epoch 212: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0684 - MinusLogProbMetric: 4.0684 - val_loss: 4.0889 - val_MinusLogProbMetric: 4.0889 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 213/1000
2023-09-12 06:31:19.094 
Epoch 213/1000 
	 loss: 4.0708, MinusLogProbMetric: 4.0708, val_loss: 4.0914, val_MinusLogProbMetric: 4.0914

Epoch 213: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0708 - MinusLogProbMetric: 4.0708 - val_loss: 4.0914 - val_MinusLogProbMetric: 4.0914 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 214/1000
2023-09-12 06:31:30.709 
Epoch 214/1000 
	 loss: 4.0554, MinusLogProbMetric: 4.0554, val_loss: 4.0892, val_MinusLogProbMetric: 4.0892

Epoch 214: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0554 - MinusLogProbMetric: 4.0554 - val_loss: 4.0892 - val_MinusLogProbMetric: 4.0892 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 215/1000
2023-09-12 06:31:42.497 
Epoch 215/1000 
	 loss: 4.0555, MinusLogProbMetric: 4.0555, val_loss: 4.0878, val_MinusLogProbMetric: 4.0878

Epoch 215: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0555 - MinusLogProbMetric: 4.0555 - val_loss: 4.0878 - val_MinusLogProbMetric: 4.0878 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 216/1000
2023-09-12 06:31:54.381 
Epoch 216/1000 
	 loss: 4.0535, MinusLogProbMetric: 4.0535, val_loss: 4.0858, val_MinusLogProbMetric: 4.0858

Epoch 216: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0535 - MinusLogProbMetric: 4.0535 - val_loss: 4.0858 - val_MinusLogProbMetric: 4.0858 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 217/1000
2023-09-12 06:32:06.237 
Epoch 217/1000 
	 loss: 4.0544, MinusLogProbMetric: 4.0544, val_loss: 4.0904, val_MinusLogProbMetric: 4.0904

Epoch 217: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0544 - MinusLogProbMetric: 4.0544 - val_loss: 4.0904 - val_MinusLogProbMetric: 4.0904 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 218/1000
2023-09-12 06:32:18.056 
Epoch 218/1000 
	 loss: 4.0560, MinusLogProbMetric: 4.0560, val_loss: 4.0941, val_MinusLogProbMetric: 4.0941

Epoch 218: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0560 - MinusLogProbMetric: 4.0560 - val_loss: 4.0941 - val_MinusLogProbMetric: 4.0941 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-12 06:32:29.631 
Epoch 219/1000 
	 loss: 4.0558, MinusLogProbMetric: 4.0558, val_loss: 4.0866, val_MinusLogProbMetric: 4.0866

Epoch 219: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0558 - MinusLogProbMetric: 4.0558 - val_loss: 4.0866 - val_MinusLogProbMetric: 4.0866 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 220/1000
2023-09-12 06:32:41.284 
Epoch 220/1000 
	 loss: 4.0543, MinusLogProbMetric: 4.0543, val_loss: 4.0845, val_MinusLogProbMetric: 4.0845

Epoch 220: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0543 - MinusLogProbMetric: 4.0543 - val_loss: 4.0845 - val_MinusLogProbMetric: 4.0845 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 221/1000
2023-09-12 06:32:53.061 
Epoch 221/1000 
	 loss: 4.0523, MinusLogProbMetric: 4.0523, val_loss: 4.0939, val_MinusLogProbMetric: 4.0939

Epoch 221: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0523 - MinusLogProbMetric: 4.0523 - val_loss: 4.0939 - val_MinusLogProbMetric: 4.0939 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-12 06:33:04.797 
Epoch 222/1000 
	 loss: 4.0557, MinusLogProbMetric: 4.0557, val_loss: 4.1049, val_MinusLogProbMetric: 4.1049

Epoch 222: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0557 - MinusLogProbMetric: 4.0557 - val_loss: 4.1049 - val_MinusLogProbMetric: 4.1049 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-12 06:33:16.524 
Epoch 223/1000 
	 loss: 4.0525, MinusLogProbMetric: 4.0525, val_loss: 4.0906, val_MinusLogProbMetric: 4.0906

Epoch 223: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0525 - MinusLogProbMetric: 4.0525 - val_loss: 4.0906 - val_MinusLogProbMetric: 4.0906 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 224/1000
2023-09-12 06:33:28.340 
Epoch 224/1000 
	 loss: 4.0529, MinusLogProbMetric: 4.0529, val_loss: 4.0841, val_MinusLogProbMetric: 4.0841

Epoch 224: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0529 - MinusLogProbMetric: 4.0529 - val_loss: 4.0841 - val_MinusLogProbMetric: 4.0841 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-12 06:33:40.100 
Epoch 225/1000 
	 loss: 4.0542, MinusLogProbMetric: 4.0542, val_loss: 4.0900, val_MinusLogProbMetric: 4.0900

Epoch 225: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0542 - MinusLogProbMetric: 4.0542 - val_loss: 4.0900 - val_MinusLogProbMetric: 4.0900 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-12 06:33:51.930 
Epoch 226/1000 
	 loss: 4.0516, MinusLogProbMetric: 4.0516, val_loss: 4.0978, val_MinusLogProbMetric: 4.0978

Epoch 226: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0516 - MinusLogProbMetric: 4.0516 - val_loss: 4.0978 - val_MinusLogProbMetric: 4.0978 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 227/1000
2023-09-12 06:34:03.521 
Epoch 227/1000 
	 loss: 4.0530, MinusLogProbMetric: 4.0530, val_loss: 4.0868, val_MinusLogProbMetric: 4.0868

Epoch 227: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0530 - MinusLogProbMetric: 4.0530 - val_loss: 4.0868 - val_MinusLogProbMetric: 4.0868 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-12 06:34:15.329 
Epoch 228/1000 
	 loss: 4.0521, MinusLogProbMetric: 4.0521, val_loss: 4.0839, val_MinusLogProbMetric: 4.0839

Epoch 228: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0521 - MinusLogProbMetric: 4.0521 - val_loss: 4.0839 - val_MinusLogProbMetric: 4.0839 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 229/1000
2023-09-12 06:34:27.007 
Epoch 229/1000 
	 loss: 4.0524, MinusLogProbMetric: 4.0524, val_loss: 4.0964, val_MinusLogProbMetric: 4.0964

Epoch 229: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0524 - MinusLogProbMetric: 4.0524 - val_loss: 4.0964 - val_MinusLogProbMetric: 4.0964 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-12 06:34:38.898 
Epoch 230/1000 
	 loss: 4.0506, MinusLogProbMetric: 4.0506, val_loss: 4.0950, val_MinusLogProbMetric: 4.0950

Epoch 230: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0506 - MinusLogProbMetric: 4.0506 - val_loss: 4.0950 - val_MinusLogProbMetric: 4.0950 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 231/1000
2023-09-12 06:34:50.662 
Epoch 231/1000 
	 loss: 4.0560, MinusLogProbMetric: 4.0560, val_loss: 4.0896, val_MinusLogProbMetric: 4.0896

Epoch 231: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0560 - MinusLogProbMetric: 4.0560 - val_loss: 4.0896 - val_MinusLogProbMetric: 4.0896 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 232/1000
2023-09-12 06:35:02.475 
Epoch 232/1000 
	 loss: 4.0530, MinusLogProbMetric: 4.0530, val_loss: 4.0896, val_MinusLogProbMetric: 4.0896

Epoch 232: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0530 - MinusLogProbMetric: 4.0530 - val_loss: 4.0896 - val_MinusLogProbMetric: 4.0896 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 233/1000
2023-09-12 06:35:14.169 
Epoch 233/1000 
	 loss: 4.0532, MinusLogProbMetric: 4.0532, val_loss: 4.0941, val_MinusLogProbMetric: 4.0941

Epoch 233: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0532 - MinusLogProbMetric: 4.0532 - val_loss: 4.0941 - val_MinusLogProbMetric: 4.0941 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 234/1000
2023-09-12 06:35:25.864 
Epoch 234/1000 
	 loss: 4.0512, MinusLogProbMetric: 4.0512, val_loss: 4.0938, val_MinusLogProbMetric: 4.0938

Epoch 234: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0512 - MinusLogProbMetric: 4.0512 - val_loss: 4.0938 - val_MinusLogProbMetric: 4.0938 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-12 06:35:36.546 
Epoch 235/1000 
	 loss: 4.0524, MinusLogProbMetric: 4.0524, val_loss: 4.0848, val_MinusLogProbMetric: 4.0848

Epoch 235: val_loss did not improve from 4.07798
196/196 - 11s - loss: 4.0524 - MinusLogProbMetric: 4.0524 - val_loss: 4.0848 - val_MinusLogProbMetric: 4.0848 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 236/1000
2023-09-12 06:35:47.787 
Epoch 236/1000 
	 loss: 4.0538, MinusLogProbMetric: 4.0538, val_loss: 4.0978, val_MinusLogProbMetric: 4.0978

Epoch 236: val_loss did not improve from 4.07798
196/196 - 11s - loss: 4.0538 - MinusLogProbMetric: 4.0538 - val_loss: 4.0978 - val_MinusLogProbMetric: 4.0978 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 237/1000
2023-09-12 06:35:57.800 
Epoch 237/1000 
	 loss: 4.0545, MinusLogProbMetric: 4.0545, val_loss: 4.0877, val_MinusLogProbMetric: 4.0877

Epoch 237: val_loss did not improve from 4.07798
196/196 - 10s - loss: 4.0545 - MinusLogProbMetric: 4.0545 - val_loss: 4.0877 - val_MinusLogProbMetric: 4.0877 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 238/1000
2023-09-12 06:36:09.394 
Epoch 238/1000 
	 loss: 4.0529, MinusLogProbMetric: 4.0529, val_loss: 4.0908, val_MinusLogProbMetric: 4.0908

Epoch 238: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0529 - MinusLogProbMetric: 4.0529 - val_loss: 4.0908 - val_MinusLogProbMetric: 4.0908 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 239/1000
2023-09-12 06:36:20.861 
Epoch 239/1000 
	 loss: 4.0532, MinusLogProbMetric: 4.0532, val_loss: 4.0877, val_MinusLogProbMetric: 4.0877

Epoch 239: val_loss did not improve from 4.07798
196/196 - 11s - loss: 4.0532 - MinusLogProbMetric: 4.0532 - val_loss: 4.0877 - val_MinusLogProbMetric: 4.0877 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 240/1000
2023-09-12 06:36:32.706 
Epoch 240/1000 
	 loss: 4.0499, MinusLogProbMetric: 4.0499, val_loss: 4.1101, val_MinusLogProbMetric: 4.1101

Epoch 240: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0499 - MinusLogProbMetric: 4.0499 - val_loss: 4.1101 - val_MinusLogProbMetric: 4.1101 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-12 06:36:44.277 
Epoch 241/1000 
	 loss: 4.0510, MinusLogProbMetric: 4.0510, val_loss: 4.0894, val_MinusLogProbMetric: 4.0894

Epoch 241: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0510 - MinusLogProbMetric: 4.0510 - val_loss: 4.0894 - val_MinusLogProbMetric: 4.0894 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 242/1000
2023-09-12 06:36:55.951 
Epoch 242/1000 
	 loss: 4.0550, MinusLogProbMetric: 4.0550, val_loss: 4.0906, val_MinusLogProbMetric: 4.0906

Epoch 242: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0550 - MinusLogProbMetric: 4.0550 - val_loss: 4.0906 - val_MinusLogProbMetric: 4.0906 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 243/1000
2023-09-12 06:37:07.623 
Epoch 243/1000 
	 loss: 4.0496, MinusLogProbMetric: 4.0496, val_loss: 4.0956, val_MinusLogProbMetric: 4.0956

Epoch 243: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0496 - MinusLogProbMetric: 4.0496 - val_loss: 4.0956 - val_MinusLogProbMetric: 4.0956 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 244/1000
2023-09-12 06:37:19.347 
Epoch 244/1000 
	 loss: 4.0509, MinusLogProbMetric: 4.0509, val_loss: 4.0861, val_MinusLogProbMetric: 4.0861

Epoch 244: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0509 - MinusLogProbMetric: 4.0509 - val_loss: 4.0861 - val_MinusLogProbMetric: 4.0861 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 245/1000
2023-09-12 06:37:31.119 
Epoch 245/1000 
	 loss: 4.0508, MinusLogProbMetric: 4.0508, val_loss: 4.0991, val_MinusLogProbMetric: 4.0991

Epoch 245: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0508 - MinusLogProbMetric: 4.0508 - val_loss: 4.0991 - val_MinusLogProbMetric: 4.0991 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 246/1000
2023-09-12 06:37:42.845 
Epoch 246/1000 
	 loss: 4.0554, MinusLogProbMetric: 4.0554, val_loss: 4.0924, val_MinusLogProbMetric: 4.0924

Epoch 246: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0554 - MinusLogProbMetric: 4.0554 - val_loss: 4.0924 - val_MinusLogProbMetric: 4.0924 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 247/1000
2023-09-12 06:37:54.470 
Epoch 247/1000 
	 loss: 4.0504, MinusLogProbMetric: 4.0504, val_loss: 4.0919, val_MinusLogProbMetric: 4.0919

Epoch 247: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0504 - MinusLogProbMetric: 4.0504 - val_loss: 4.0919 - val_MinusLogProbMetric: 4.0919 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 248/1000
2023-09-12 06:38:06.173 
Epoch 248/1000 
	 loss: 4.0538, MinusLogProbMetric: 4.0538, val_loss: 4.0893, val_MinusLogProbMetric: 4.0893

Epoch 248: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0538 - MinusLogProbMetric: 4.0538 - val_loss: 4.0893 - val_MinusLogProbMetric: 4.0893 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-12 06:38:17.889 
Epoch 249/1000 
	 loss: 4.0555, MinusLogProbMetric: 4.0555, val_loss: 4.0937, val_MinusLogProbMetric: 4.0937

Epoch 249: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0555 - MinusLogProbMetric: 4.0555 - val_loss: 4.0937 - val_MinusLogProbMetric: 4.0937 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 250/1000
2023-09-12 06:38:29.630 
Epoch 250/1000 
	 loss: 4.0507, MinusLogProbMetric: 4.0507, val_loss: 4.0898, val_MinusLogProbMetric: 4.0898

Epoch 250: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0507 - MinusLogProbMetric: 4.0507 - val_loss: 4.0898 - val_MinusLogProbMetric: 4.0898 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 251/1000
2023-09-12 06:38:41.266 
Epoch 251/1000 
	 loss: 4.0838, MinusLogProbMetric: 4.0838, val_loss: 4.0946, val_MinusLogProbMetric: 4.0946

Epoch 251: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0838 - MinusLogProbMetric: 4.0838 - val_loss: 4.0946 - val_MinusLogProbMetric: 4.0946 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 252/1000
2023-09-12 06:38:52.923 
Epoch 252/1000 
	 loss: 4.0514, MinusLogProbMetric: 4.0514, val_loss: 4.0935, val_MinusLogProbMetric: 4.0935

Epoch 252: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0514 - MinusLogProbMetric: 4.0514 - val_loss: 4.0935 - val_MinusLogProbMetric: 4.0935 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 253/1000
2023-09-12 06:39:04.633 
Epoch 253/1000 
	 loss: 4.0627, MinusLogProbMetric: 4.0627, val_loss: 4.0988, val_MinusLogProbMetric: 4.0988

Epoch 253: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0627 - MinusLogProbMetric: 4.0627 - val_loss: 4.0988 - val_MinusLogProbMetric: 4.0988 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 254/1000
2023-09-12 06:39:16.428 
Epoch 254/1000 
	 loss: 4.0525, MinusLogProbMetric: 4.0525, val_loss: 4.1017, val_MinusLogProbMetric: 4.1017

Epoch 254: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0525 - MinusLogProbMetric: 4.0525 - val_loss: 4.1017 - val_MinusLogProbMetric: 4.1017 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-12 06:39:28.164 
Epoch 255/1000 
	 loss: 4.0495, MinusLogProbMetric: 4.0495, val_loss: 4.1025, val_MinusLogProbMetric: 4.1025

Epoch 255: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0495 - MinusLogProbMetric: 4.0495 - val_loss: 4.1025 - val_MinusLogProbMetric: 4.1025 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 256/1000
2023-09-12 06:39:39.825 
Epoch 256/1000 
	 loss: 4.0522, MinusLogProbMetric: 4.0522, val_loss: 4.0946, val_MinusLogProbMetric: 4.0946

Epoch 256: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0522 - MinusLogProbMetric: 4.0522 - val_loss: 4.0946 - val_MinusLogProbMetric: 4.0946 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 257/1000
2023-09-12 06:39:51.520 
Epoch 257/1000 
	 loss: 4.0515, MinusLogProbMetric: 4.0515, val_loss: 4.0897, val_MinusLogProbMetric: 4.0897

Epoch 257: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0515 - MinusLogProbMetric: 4.0515 - val_loss: 4.0897 - val_MinusLogProbMetric: 4.0897 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-12 06:40:03.277 
Epoch 258/1000 
	 loss: 4.0499, MinusLogProbMetric: 4.0499, val_loss: 4.0943, val_MinusLogProbMetric: 4.0943

Epoch 258: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0499 - MinusLogProbMetric: 4.0499 - val_loss: 4.0943 - val_MinusLogProbMetric: 4.0943 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 259/1000
2023-09-12 06:40:14.929 
Epoch 259/1000 
	 loss: 4.0513, MinusLogProbMetric: 4.0513, val_loss: 4.0905, val_MinusLogProbMetric: 4.0905

Epoch 259: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0513 - MinusLogProbMetric: 4.0513 - val_loss: 4.0905 - val_MinusLogProbMetric: 4.0905 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 260/1000
2023-09-12 06:40:26.678 
Epoch 260/1000 
	 loss: 4.0577, MinusLogProbMetric: 4.0577, val_loss: 4.0913, val_MinusLogProbMetric: 4.0913

Epoch 260: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0577 - MinusLogProbMetric: 4.0577 - val_loss: 4.0913 - val_MinusLogProbMetric: 4.0913 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 261/1000
2023-09-12 06:40:38.473 
Epoch 261/1000 
	 loss: 4.0477, MinusLogProbMetric: 4.0477, val_loss: 4.0936, val_MinusLogProbMetric: 4.0936

Epoch 261: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0477 - MinusLogProbMetric: 4.0477 - val_loss: 4.0936 - val_MinusLogProbMetric: 4.0936 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 262/1000
2023-09-12 06:40:50.190 
Epoch 262/1000 
	 loss: 4.0566, MinusLogProbMetric: 4.0566, val_loss: 4.0881, val_MinusLogProbMetric: 4.0881

Epoch 262: val_loss did not improve from 4.07798
196/196 - 12s - loss: 4.0566 - MinusLogProbMetric: 4.0566 - val_loss: 4.0881 - val_MinusLogProbMetric: 4.0881 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 263/1000
2023-09-12 06:41:01.845 
Epoch 263/1000 
	 loss: 4.0512, MinusLogProbMetric: 4.0512, val_loss: 4.1058, val_MinusLogProbMetric: 4.1058

Epoch 263: val_loss did not improve from 4.07798
Restoring model weights from the end of the best epoch: 163.
196/196 - 12s - loss: 4.0512 - MinusLogProbMetric: 4.0512 - val_loss: 4.1058 - val_MinusLogProbMetric: 4.1058 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 263: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 6.830042475950904 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.330178307020105 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.053612552001141 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.010312261991203 seconds.
Training succeeded with seed 926.
Model trained in 3086.63 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 26.93 s.
Plots done in 9.72 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 36.65 s.
===========
Run 76/360 done in 3124.80 s.
===========

Directory ../../results/MsplineN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

===========
Generating train data for run 82.
===========
Train data generated in 0.26 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_82/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_82/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.089422  ,  7.0493126 ,  5.591244  , ...,  9.216724  ,
        -0.53186065,  0.84240437],
       [ 4.6393895 ,  5.7437677 ,  0.22019444, ...,  8.070238  ,
         1.9049016 ,  1.2655213 ],
       [ 4.6048517 ,  6.1983166 ,  0.18879257, ...,  8.233682  ,
         1.7095788 ,  1.161441  ],
       ...,
       [ 4.869068  ,  6.9721594 ,  6.235107  , ...,  9.328383  ,
         0.04100066,  0.88470554],
       [ 5.1966558 ,  6.7663946 ,  6.223111  , ...,  9.209971  ,
         0.91517496,  0.6504801 ],
       [ 5.832558  ,  7.0632644 ,  5.988635  , ...,  9.222229  ,
         0.7068257 ,  0.93882483]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_82/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_82
self.data_kwargs: {'seed': 0}
self.x_data: [[ 4.6443877   5.1248813   0.15364125 ...  6.8407702   2.0160663
   1.393048  ]
 [ 5.2627883   7.0261273   5.9651794  ...  9.430413    0.89294076
   0.6485443 ]
 [ 5.1055775   6.32089     5.5556955  ...  9.359603    1.0867832
   0.6525862 ]
 ...
 [ 4.644594    5.5640745  -0.02721447 ...  7.503493    1.893476
   1.3357137 ]
 [ 4.6134467   6.4517426   0.20086306 ...  6.9660497   1.6896975
   1.1264002 ]
 [ 4.9823613   5.4172196   0.15810055 ...  7.23583     2.5058396
   1.4047252 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_31 (InputLayer)       [(None, 16)]              0         
                                                                 
 log_prob_layer_10 (LogProbL  (None,)                  461024    
 ayer)                                                           
                                                                 
=================================================================
Total params: 461,024
Trainable params: 461,024
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_10/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_10'")
self.model: <keras.engine.functional.Functional object at 0x7fc9c41c1c90>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc7b41b5e10>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc7b41b5e10>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc890142470>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fcd4da78be0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fcd4da78460>, <keras.callbacks.ModelCheckpoint object at 0x7fc7bc438520>, <keras.callbacks.EarlyStopping object at 0x7fc7bc438130>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc7bc439840>, <keras.callbacks.TerminateOnNaN object at 0x7fc7bc43ab00>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.089422  ,  7.0493126 ,  5.591244  , ...,  9.216724  ,
        -0.53186065,  0.84240437],
       [ 4.6393895 ,  5.7437677 ,  0.22019444, ...,  8.070238  ,
         1.9049016 ,  1.2655213 ],
       [ 4.6048517 ,  6.1983166 ,  0.18879257, ...,  8.233682  ,
         1.7095788 ,  1.161441  ],
       ...,
       [ 4.869068  ,  6.9721594 ,  6.235107  , ...,  9.328383  ,
         0.04100066,  0.88470554],
       [ 5.1966558 ,  6.7663946 ,  6.223111  , ...,  9.209971  ,
         0.91517496,  0.6504801 ],
       [ 5.832558  ,  7.0632644 ,  5.988635  , ...,  9.222229  ,
         0.7068257 ,  0.93882483]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_82/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 82/360 with hyperparameters:
timestamp = 2023-09-12 06:41:39.891055
ndims = 16
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 461024
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.6443877   5.1248813   0.15364125  6.8496265   6.576092    5.979507
 10.570373    6.68657     3.5296488   4.903077    6.739542    0.3100805
  6.5303206   6.8407702   2.0160663   1.393048  ]
Epoch 1/1000
2023-09-12 06:42:10.841 
Epoch 1/1000 
	 loss: 17.7953, MinusLogProbMetric: 17.7953, val_loss: 6.2924, val_MinusLogProbMetric: 6.2924

Epoch 1: val_loss improved from inf to 6.29237, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 31s - loss: 17.7953 - MinusLogProbMetric: 17.7953 - val_loss: 6.2924 - val_MinusLogProbMetric: 6.2924 - lr: 0.0010 - 31s/epoch - 158ms/step
Epoch 2/1000
2023-09-12 06:42:22.558 
Epoch 2/1000 
	 loss: 5.9439, MinusLogProbMetric: 5.9439, val_loss: 5.8026, val_MinusLogProbMetric: 5.8026

Epoch 2: val_loss improved from 6.29237 to 5.80261, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.9439 - MinusLogProbMetric: 5.9439 - val_loss: 5.8026 - val_MinusLogProbMetric: 5.8026 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 3/1000
2023-09-12 06:42:34.227 
Epoch 3/1000 
	 loss: 5.5902, MinusLogProbMetric: 5.5902, val_loss: 5.4697, val_MinusLogProbMetric: 5.4697

Epoch 3: val_loss improved from 5.80261 to 5.46974, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.5902 - MinusLogProbMetric: 5.5902 - val_loss: 5.4697 - val_MinusLogProbMetric: 5.4697 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-12 06:42:45.795 
Epoch 4/1000 
	 loss: 5.4559, MinusLogProbMetric: 5.4559, val_loss: 5.4418, val_MinusLogProbMetric: 5.4418

Epoch 4: val_loss improved from 5.46974 to 5.44183, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.4559 - MinusLogProbMetric: 5.4559 - val_loss: 5.4418 - val_MinusLogProbMetric: 5.4418 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 5/1000
2023-09-12 06:42:57.497 
Epoch 5/1000 
	 loss: 5.4018, MinusLogProbMetric: 5.4018, val_loss: 5.4043, val_MinusLogProbMetric: 5.4043

Epoch 5: val_loss improved from 5.44183 to 5.40434, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.4018 - MinusLogProbMetric: 5.4018 - val_loss: 5.4043 - val_MinusLogProbMetric: 5.4043 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 6/1000
2023-09-12 06:43:09.125 
Epoch 6/1000 
	 loss: 5.3574, MinusLogProbMetric: 5.3574, val_loss: 5.4441, val_MinusLogProbMetric: 5.4441

Epoch 6: val_loss did not improve from 5.40434
196/196 - 11s - loss: 5.3574 - MinusLogProbMetric: 5.3574 - val_loss: 5.4441 - val_MinusLogProbMetric: 5.4441 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 7/1000
2023-09-12 06:43:20.637 
Epoch 7/1000 
	 loss: 5.3475, MinusLogProbMetric: 5.3475, val_loss: 5.3387, val_MinusLogProbMetric: 5.3387

Epoch 7: val_loss improved from 5.40434 to 5.33869, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.3475 - MinusLogProbMetric: 5.3475 - val_loss: 5.3387 - val_MinusLogProbMetric: 5.3387 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 8/1000
2023-09-12 06:43:32.357 
Epoch 8/1000 
	 loss: 5.2938, MinusLogProbMetric: 5.2938, val_loss: 5.2990, val_MinusLogProbMetric: 5.2990

Epoch 8: val_loss improved from 5.33869 to 5.29895, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.2938 - MinusLogProbMetric: 5.2938 - val_loss: 5.2990 - val_MinusLogProbMetric: 5.2990 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-12 06:43:43.986 
Epoch 9/1000 
	 loss: 5.2966, MinusLogProbMetric: 5.2966, val_loss: 5.2793, val_MinusLogProbMetric: 5.2793

Epoch 9: val_loss improved from 5.29895 to 5.27931, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.2966 - MinusLogProbMetric: 5.2966 - val_loss: 5.2793 - val_MinusLogProbMetric: 5.2793 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 10/1000
2023-09-12 06:43:55.600 
Epoch 10/1000 
	 loss: 5.2525, MinusLogProbMetric: 5.2525, val_loss: 5.3212, val_MinusLogProbMetric: 5.3212

Epoch 10: val_loss did not improve from 5.27931
196/196 - 11s - loss: 5.2525 - MinusLogProbMetric: 5.2525 - val_loss: 5.3212 - val_MinusLogProbMetric: 5.3212 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 11/1000
2023-09-12 06:44:07.082 
Epoch 11/1000 
	 loss: 5.2316, MinusLogProbMetric: 5.2316, val_loss: 5.2473, val_MinusLogProbMetric: 5.2473

Epoch 11: val_loss improved from 5.27931 to 5.24732, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.2316 - MinusLogProbMetric: 5.2316 - val_loss: 5.2473 - val_MinusLogProbMetric: 5.2473 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 12/1000
2023-09-12 06:44:18.721 
Epoch 12/1000 
	 loss: 5.2433, MinusLogProbMetric: 5.2433, val_loss: 5.3959, val_MinusLogProbMetric: 5.3959

Epoch 12: val_loss did not improve from 5.24732
196/196 - 11s - loss: 5.2433 - MinusLogProbMetric: 5.2433 - val_loss: 5.3959 - val_MinusLogProbMetric: 5.3959 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 13/1000
2023-09-12 06:44:30.275 
Epoch 13/1000 
	 loss: 5.2278, MinusLogProbMetric: 5.2278, val_loss: 5.2106, val_MinusLogProbMetric: 5.2106

Epoch 13: val_loss improved from 5.24732 to 5.21061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.2278 - MinusLogProbMetric: 5.2278 - val_loss: 5.2106 - val_MinusLogProbMetric: 5.2106 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 06:44:41.941 
Epoch 14/1000 
	 loss: 5.2081, MinusLogProbMetric: 5.2081, val_loss: 5.2002, val_MinusLogProbMetric: 5.2002

Epoch 14: val_loss improved from 5.21061 to 5.20016, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.2081 - MinusLogProbMetric: 5.2081 - val_loss: 5.2002 - val_MinusLogProbMetric: 5.2002 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-12 06:44:53.617 
Epoch 15/1000 
	 loss: 5.1895, MinusLogProbMetric: 5.1895, val_loss: 5.2080, val_MinusLogProbMetric: 5.2080

Epoch 15: val_loss did not improve from 5.20016
196/196 - 12s - loss: 5.1895 - MinusLogProbMetric: 5.1895 - val_loss: 5.2080 - val_MinusLogProbMetric: 5.2080 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 16/1000
2023-09-12 06:45:05.145 
Epoch 16/1000 
	 loss: 5.1864, MinusLogProbMetric: 5.1864, val_loss: 5.2665, val_MinusLogProbMetric: 5.2665

Epoch 16: val_loss did not improve from 5.20016
196/196 - 12s - loss: 5.1864 - MinusLogProbMetric: 5.1864 - val_loss: 5.2665 - val_MinusLogProbMetric: 5.2665 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 17/1000
2023-09-12 06:45:16.688 
Epoch 17/1000 
	 loss: 5.1680, MinusLogProbMetric: 5.1680, val_loss: 5.2717, val_MinusLogProbMetric: 5.2717

Epoch 17: val_loss did not improve from 5.20016
196/196 - 12s - loss: 5.1680 - MinusLogProbMetric: 5.1680 - val_loss: 5.2717 - val_MinusLogProbMetric: 5.2717 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 18/1000
2023-09-12 06:45:28.235 
Epoch 18/1000 
	 loss: 5.1816, MinusLogProbMetric: 5.1816, val_loss: 5.1864, val_MinusLogProbMetric: 5.1864

Epoch 18: val_loss improved from 5.20016 to 5.18636, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1816 - MinusLogProbMetric: 5.1816 - val_loss: 5.1864 - val_MinusLogProbMetric: 5.1864 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 06:45:39.895 
Epoch 19/1000 
	 loss: 5.1667, MinusLogProbMetric: 5.1667, val_loss: 5.1519, val_MinusLogProbMetric: 5.1519

Epoch 19: val_loss improved from 5.18636 to 5.15189, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1667 - MinusLogProbMetric: 5.1667 - val_loss: 5.1519 - val_MinusLogProbMetric: 5.1519 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-12 06:45:51.443 
Epoch 20/1000 
	 loss: 5.1564, MinusLogProbMetric: 5.1564, val_loss: 5.2259, val_MinusLogProbMetric: 5.2259

Epoch 20: val_loss did not improve from 5.15189
196/196 - 11s - loss: 5.1564 - MinusLogProbMetric: 5.1564 - val_loss: 5.2259 - val_MinusLogProbMetric: 5.2259 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 21/1000
2023-09-12 06:46:03.040 
Epoch 21/1000 
	 loss: 5.1641, MinusLogProbMetric: 5.1641, val_loss: 5.1973, val_MinusLogProbMetric: 5.1973

Epoch 21: val_loss did not improve from 5.15189
196/196 - 12s - loss: 5.1641 - MinusLogProbMetric: 5.1641 - val_loss: 5.1973 - val_MinusLogProbMetric: 5.1973 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 06:46:14.610 
Epoch 22/1000 
	 loss: 5.1637, MinusLogProbMetric: 5.1637, val_loss: 5.1685, val_MinusLogProbMetric: 5.1685

Epoch 22: val_loss did not improve from 5.15189
196/196 - 12s - loss: 5.1637 - MinusLogProbMetric: 5.1637 - val_loss: 5.1685 - val_MinusLogProbMetric: 5.1685 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 23/1000
2023-09-12 06:46:26.048 
Epoch 23/1000 
	 loss: 5.1460, MinusLogProbMetric: 5.1460, val_loss: 5.1577, val_MinusLogProbMetric: 5.1577

Epoch 23: val_loss did not improve from 5.15189
196/196 - 11s - loss: 5.1460 - MinusLogProbMetric: 5.1460 - val_loss: 5.1577 - val_MinusLogProbMetric: 5.1577 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 24/1000
2023-09-12 06:46:37.426 
Epoch 24/1000 
	 loss: 5.1478, MinusLogProbMetric: 5.1478, val_loss: 5.1732, val_MinusLogProbMetric: 5.1732

Epoch 24: val_loss did not improve from 5.15189
196/196 - 11s - loss: 5.1478 - MinusLogProbMetric: 5.1478 - val_loss: 5.1732 - val_MinusLogProbMetric: 5.1732 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 25/1000
2023-09-12 06:46:49.015 
Epoch 25/1000 
	 loss: 5.1435, MinusLogProbMetric: 5.1435, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 25: val_loss did not improve from 5.15189
196/196 - 12s - loss: 5.1435 - MinusLogProbMetric: 5.1435 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 26/1000
2023-09-12 06:47:00.500 
Epoch 26/1000 
	 loss: 5.1412, MinusLogProbMetric: 5.1412, val_loss: 5.1570, val_MinusLogProbMetric: 5.1570

Epoch 26: val_loss did not improve from 5.15189
196/196 - 11s - loss: 5.1412 - MinusLogProbMetric: 5.1412 - val_loss: 5.1570 - val_MinusLogProbMetric: 5.1570 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 27/1000
2023-09-12 06:47:11.945 
Epoch 27/1000 
	 loss: 5.1455, MinusLogProbMetric: 5.1455, val_loss: 5.1677, val_MinusLogProbMetric: 5.1677

Epoch 27: val_loss did not improve from 5.15189
196/196 - 11s - loss: 5.1455 - MinusLogProbMetric: 5.1455 - val_loss: 5.1677 - val_MinusLogProbMetric: 5.1677 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 28/1000
2023-09-12 06:47:23.611 
Epoch 28/1000 
	 loss: 5.1306, MinusLogProbMetric: 5.1306, val_loss: 5.1467, val_MinusLogProbMetric: 5.1467

Epoch 28: val_loss improved from 5.15189 to 5.14673, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1306 - MinusLogProbMetric: 5.1306 - val_loss: 5.1467 - val_MinusLogProbMetric: 5.1467 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 29/1000
2023-09-12 06:47:35.270 
Epoch 29/1000 
	 loss: 5.1376, MinusLogProbMetric: 5.1376, val_loss: 5.1514, val_MinusLogProbMetric: 5.1514

Epoch 29: val_loss did not improve from 5.14673
196/196 - 11s - loss: 5.1376 - MinusLogProbMetric: 5.1376 - val_loss: 5.1514 - val_MinusLogProbMetric: 5.1514 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 30/1000
2023-09-12 06:47:46.907 
Epoch 30/1000 
	 loss: 5.1345, MinusLogProbMetric: 5.1345, val_loss: 5.1475, val_MinusLogProbMetric: 5.1475

Epoch 30: val_loss did not improve from 5.14673
196/196 - 12s - loss: 5.1345 - MinusLogProbMetric: 5.1345 - val_loss: 5.1475 - val_MinusLogProbMetric: 5.1475 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 31/1000
2023-09-12 06:47:58.344 
Epoch 31/1000 
	 loss: 5.1311, MinusLogProbMetric: 5.1311, val_loss: 5.1526, val_MinusLogProbMetric: 5.1526

Epoch 31: val_loss did not improve from 5.14673
196/196 - 11s - loss: 5.1311 - MinusLogProbMetric: 5.1311 - val_loss: 5.1526 - val_MinusLogProbMetric: 5.1526 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 32/1000
2023-09-12 06:48:09.888 
Epoch 32/1000 
	 loss: 5.1231, MinusLogProbMetric: 5.1231, val_loss: 5.1554, val_MinusLogProbMetric: 5.1554

Epoch 32: val_loss did not improve from 5.14673
196/196 - 12s - loss: 5.1231 - MinusLogProbMetric: 5.1231 - val_loss: 5.1554 - val_MinusLogProbMetric: 5.1554 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 33/1000
2023-09-12 06:48:21.260 
Epoch 33/1000 
	 loss: 5.1238, MinusLogProbMetric: 5.1238, val_loss: 5.1507, val_MinusLogProbMetric: 5.1507

Epoch 33: val_loss did not improve from 5.14673
196/196 - 11s - loss: 5.1238 - MinusLogProbMetric: 5.1238 - val_loss: 5.1507 - val_MinusLogProbMetric: 5.1507 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 34/1000
2023-09-12 06:48:32.775 
Epoch 34/1000 
	 loss: 5.1168, MinusLogProbMetric: 5.1168, val_loss: 5.1402, val_MinusLogProbMetric: 5.1402

Epoch 34: val_loss improved from 5.14673 to 5.14018, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1168 - MinusLogProbMetric: 5.1168 - val_loss: 5.1402 - val_MinusLogProbMetric: 5.1402 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 35/1000
2023-09-12 06:48:44.371 
Epoch 35/1000 
	 loss: 5.1260, MinusLogProbMetric: 5.1260, val_loss: 5.1369, val_MinusLogProbMetric: 5.1369

Epoch 35: val_loss improved from 5.14018 to 5.13687, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1260 - MinusLogProbMetric: 5.1260 - val_loss: 5.1369 - val_MinusLogProbMetric: 5.1369 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 36/1000
2023-09-12 06:48:56.014 
Epoch 36/1000 
	 loss: 5.1161, MinusLogProbMetric: 5.1161, val_loss: 5.1574, val_MinusLogProbMetric: 5.1574

Epoch 36: val_loss did not improve from 5.13687
196/196 - 11s - loss: 5.1161 - MinusLogProbMetric: 5.1161 - val_loss: 5.1574 - val_MinusLogProbMetric: 5.1574 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 37/1000
2023-09-12 06:49:07.551 
Epoch 37/1000 
	 loss: 5.1248, MinusLogProbMetric: 5.1248, val_loss: 5.1411, val_MinusLogProbMetric: 5.1411

Epoch 37: val_loss did not improve from 5.13687
196/196 - 12s - loss: 5.1248 - MinusLogProbMetric: 5.1248 - val_loss: 5.1411 - val_MinusLogProbMetric: 5.1411 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 38/1000
2023-09-12 06:49:19.104 
Epoch 38/1000 
	 loss: 5.1129, MinusLogProbMetric: 5.1129, val_loss: 5.1313, val_MinusLogProbMetric: 5.1313

Epoch 38: val_loss improved from 5.13687 to 5.13135, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1129 - MinusLogProbMetric: 5.1129 - val_loss: 5.1313 - val_MinusLogProbMetric: 5.1313 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 06:49:30.757 
Epoch 39/1000 
	 loss: 5.1120, MinusLogProbMetric: 5.1120, val_loss: 5.1278, val_MinusLogProbMetric: 5.1278

Epoch 39: val_loss improved from 5.13135 to 5.12783, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1120 - MinusLogProbMetric: 5.1120 - val_loss: 5.1278 - val_MinusLogProbMetric: 5.1278 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-12 06:49:42.358 
Epoch 40/1000 
	 loss: 5.1092, MinusLogProbMetric: 5.1092, val_loss: 5.1317, val_MinusLogProbMetric: 5.1317

Epoch 40: val_loss did not improve from 5.12783
196/196 - 11s - loss: 5.1092 - MinusLogProbMetric: 5.1092 - val_loss: 5.1317 - val_MinusLogProbMetric: 5.1317 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 41/1000
2023-09-12 06:49:53.951 
Epoch 41/1000 
	 loss: 5.1165, MinusLogProbMetric: 5.1165, val_loss: 5.1430, val_MinusLogProbMetric: 5.1430

Epoch 41: val_loss did not improve from 5.12783
196/196 - 12s - loss: 5.1165 - MinusLogProbMetric: 5.1165 - val_loss: 5.1430 - val_MinusLogProbMetric: 5.1430 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 42/1000
2023-09-12 06:50:05.336 
Epoch 42/1000 
	 loss: 5.1086, MinusLogProbMetric: 5.1086, val_loss: 5.1307, val_MinusLogProbMetric: 5.1307

Epoch 42: val_loss did not improve from 5.12783
196/196 - 11s - loss: 5.1086 - MinusLogProbMetric: 5.1086 - val_loss: 5.1307 - val_MinusLogProbMetric: 5.1307 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 43/1000
2023-09-12 06:50:16.916 
Epoch 43/1000 
	 loss: 5.1161, MinusLogProbMetric: 5.1161, val_loss: 5.1605, val_MinusLogProbMetric: 5.1605

Epoch 43: val_loss did not improve from 5.12783
196/196 - 12s - loss: 5.1161 - MinusLogProbMetric: 5.1161 - val_loss: 5.1605 - val_MinusLogProbMetric: 5.1605 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-12 06:50:28.408 
Epoch 44/1000 
	 loss: 5.1092, MinusLogProbMetric: 5.1092, val_loss: 5.1413, val_MinusLogProbMetric: 5.1413

Epoch 44: val_loss did not improve from 5.12783
196/196 - 11s - loss: 5.1092 - MinusLogProbMetric: 5.1092 - val_loss: 5.1413 - val_MinusLogProbMetric: 5.1413 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 45/1000
2023-09-12 06:50:39.848 
Epoch 45/1000 
	 loss: 5.1045, MinusLogProbMetric: 5.1045, val_loss: 5.1606, val_MinusLogProbMetric: 5.1606

Epoch 45: val_loss did not improve from 5.12783
196/196 - 11s - loss: 5.1045 - MinusLogProbMetric: 5.1045 - val_loss: 5.1606 - val_MinusLogProbMetric: 5.1606 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 46/1000
2023-09-12 06:50:51.393 
Epoch 46/1000 
	 loss: 5.1034, MinusLogProbMetric: 5.1034, val_loss: 5.1519, val_MinusLogProbMetric: 5.1519

Epoch 46: val_loss did not improve from 5.12783
196/196 - 12s - loss: 5.1034 - MinusLogProbMetric: 5.1034 - val_loss: 5.1519 - val_MinusLogProbMetric: 5.1519 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 06:51:02.893 
Epoch 47/1000 
	 loss: 5.1066, MinusLogProbMetric: 5.1066, val_loss: 5.1179, val_MinusLogProbMetric: 5.1179

Epoch 47: val_loss improved from 5.12783 to 5.11790, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.1066 - MinusLogProbMetric: 5.1066 - val_loss: 5.1179 - val_MinusLogProbMetric: 5.1179 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 48/1000
2023-09-12 06:51:14.491 
Epoch 48/1000 
	 loss: 5.0967, MinusLogProbMetric: 5.0967, val_loss: 5.1187, val_MinusLogProbMetric: 5.1187

Epoch 48: val_loss did not improve from 5.11790
196/196 - 11s - loss: 5.0967 - MinusLogProbMetric: 5.0967 - val_loss: 5.1187 - val_MinusLogProbMetric: 5.1187 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 49/1000
2023-09-12 06:51:26.051 
Epoch 49/1000 
	 loss: 5.0981, MinusLogProbMetric: 5.0981, val_loss: 5.1077, val_MinusLogProbMetric: 5.1077

Epoch 49: val_loss improved from 5.11790 to 5.10774, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.0981 - MinusLogProbMetric: 5.0981 - val_loss: 5.1077 - val_MinusLogProbMetric: 5.1077 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-12 06:51:37.610 
Epoch 50/1000 
	 loss: 5.0982, MinusLogProbMetric: 5.0982, val_loss: 5.1521, val_MinusLogProbMetric: 5.1521

Epoch 50: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0982 - MinusLogProbMetric: 5.0982 - val_loss: 5.1521 - val_MinusLogProbMetric: 5.1521 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 51/1000
2023-09-12 06:51:49.025 
Epoch 51/1000 
	 loss: 5.1006, MinusLogProbMetric: 5.1006, val_loss: 5.1150, val_MinusLogProbMetric: 5.1150

Epoch 51: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.1006 - MinusLogProbMetric: 5.1006 - val_loss: 5.1150 - val_MinusLogProbMetric: 5.1150 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 52/1000
2023-09-12 06:52:00.482 
Epoch 52/1000 
	 loss: 5.0990, MinusLogProbMetric: 5.0990, val_loss: 5.1480, val_MinusLogProbMetric: 5.1480

Epoch 52: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0990 - MinusLogProbMetric: 5.0990 - val_loss: 5.1480 - val_MinusLogProbMetric: 5.1480 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 53/1000
2023-09-12 06:52:11.887 
Epoch 53/1000 
	 loss: 5.0926, MinusLogProbMetric: 5.0926, val_loss: 5.1485, val_MinusLogProbMetric: 5.1485

Epoch 53: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0926 - MinusLogProbMetric: 5.0926 - val_loss: 5.1485 - val_MinusLogProbMetric: 5.1485 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 54/1000
2023-09-12 06:52:23.320 
Epoch 54/1000 
	 loss: 5.0960, MinusLogProbMetric: 5.0960, val_loss: 5.1215, val_MinusLogProbMetric: 5.1215

Epoch 54: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0960 - MinusLogProbMetric: 5.0960 - val_loss: 5.1215 - val_MinusLogProbMetric: 5.1215 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 55/1000
2023-09-12 06:52:34.880 
Epoch 55/1000 
	 loss: 5.0891, MinusLogProbMetric: 5.0891, val_loss: 5.1537, val_MinusLogProbMetric: 5.1537

Epoch 55: val_loss did not improve from 5.10774
196/196 - 12s - loss: 5.0891 - MinusLogProbMetric: 5.0891 - val_loss: 5.1537 - val_MinusLogProbMetric: 5.1537 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 56/1000
2023-09-12 06:52:46.369 
Epoch 56/1000 
	 loss: 5.0947, MinusLogProbMetric: 5.0947, val_loss: 5.1333, val_MinusLogProbMetric: 5.1333

Epoch 56: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0947 - MinusLogProbMetric: 5.0947 - val_loss: 5.1333 - val_MinusLogProbMetric: 5.1333 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 57/1000
2023-09-12 06:52:57.863 
Epoch 57/1000 
	 loss: 5.0966, MinusLogProbMetric: 5.0966, val_loss: 5.1260, val_MinusLogProbMetric: 5.1260

Epoch 57: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0966 - MinusLogProbMetric: 5.0966 - val_loss: 5.1260 - val_MinusLogProbMetric: 5.1260 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 58/1000
2023-09-12 06:53:09.243 
Epoch 58/1000 
	 loss: 5.0960, MinusLogProbMetric: 5.0960, val_loss: 5.1351, val_MinusLogProbMetric: 5.1351

Epoch 58: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0960 - MinusLogProbMetric: 5.0960 - val_loss: 5.1351 - val_MinusLogProbMetric: 5.1351 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 59/1000
2023-09-12 06:53:20.677 
Epoch 59/1000 
	 loss: 5.0892, MinusLogProbMetric: 5.0892, val_loss: 5.1542, val_MinusLogProbMetric: 5.1542

Epoch 59: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0892 - MinusLogProbMetric: 5.0892 - val_loss: 5.1542 - val_MinusLogProbMetric: 5.1542 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 60/1000
2023-09-12 06:53:32.171 
Epoch 60/1000 
	 loss: 5.0897, MinusLogProbMetric: 5.0897, val_loss: 5.1096, val_MinusLogProbMetric: 5.1096

Epoch 60: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0897 - MinusLogProbMetric: 5.0897 - val_loss: 5.1096 - val_MinusLogProbMetric: 5.1096 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 61/1000
2023-09-12 06:53:43.661 
Epoch 61/1000 
	 loss: 5.0862, MinusLogProbMetric: 5.0862, val_loss: 5.1421, val_MinusLogProbMetric: 5.1421

Epoch 61: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0862 - MinusLogProbMetric: 5.0862 - val_loss: 5.1421 - val_MinusLogProbMetric: 5.1421 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 62/1000
2023-09-12 06:53:55.050 
Epoch 62/1000 
	 loss: 5.0879, MinusLogProbMetric: 5.0879, val_loss: 5.1452, val_MinusLogProbMetric: 5.1452

Epoch 62: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0879 - MinusLogProbMetric: 5.0879 - val_loss: 5.1452 - val_MinusLogProbMetric: 5.1452 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 63/1000
2023-09-12 06:54:06.481 
Epoch 63/1000 
	 loss: 5.0941, MinusLogProbMetric: 5.0941, val_loss: 5.1532, val_MinusLogProbMetric: 5.1532

Epoch 63: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0941 - MinusLogProbMetric: 5.0941 - val_loss: 5.1532 - val_MinusLogProbMetric: 5.1532 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 64/1000
2023-09-12 06:54:18.125 
Epoch 64/1000 
	 loss: 5.0897, MinusLogProbMetric: 5.0897, val_loss: 5.1244, val_MinusLogProbMetric: 5.1244

Epoch 64: val_loss did not improve from 5.10774
196/196 - 12s - loss: 5.0897 - MinusLogProbMetric: 5.0897 - val_loss: 5.1244 - val_MinusLogProbMetric: 5.1244 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 65/1000
2023-09-12 06:54:29.654 
Epoch 65/1000 
	 loss: 5.0811, MinusLogProbMetric: 5.0811, val_loss: 5.1585, val_MinusLogProbMetric: 5.1585

Epoch 65: val_loss did not improve from 5.10774
196/196 - 12s - loss: 5.0811 - MinusLogProbMetric: 5.0811 - val_loss: 5.1585 - val_MinusLogProbMetric: 5.1585 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 66/1000
2023-09-12 06:54:41.038 
Epoch 66/1000 
	 loss: 5.0855, MinusLogProbMetric: 5.0855, val_loss: 5.1206, val_MinusLogProbMetric: 5.1206

Epoch 66: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0855 - MinusLogProbMetric: 5.0855 - val_loss: 5.1206 - val_MinusLogProbMetric: 5.1206 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 67/1000
2023-09-12 06:54:52.664 
Epoch 67/1000 
	 loss: 5.0871, MinusLogProbMetric: 5.0871, val_loss: 5.1116, val_MinusLogProbMetric: 5.1116

Epoch 67: val_loss did not improve from 5.10774
196/196 - 12s - loss: 5.0871 - MinusLogProbMetric: 5.0871 - val_loss: 5.1116 - val_MinusLogProbMetric: 5.1116 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 68/1000
2023-09-12 06:55:04.122 
Epoch 68/1000 
	 loss: 5.0831, MinusLogProbMetric: 5.0831, val_loss: 5.1183, val_MinusLogProbMetric: 5.1183

Epoch 68: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0831 - MinusLogProbMetric: 5.0831 - val_loss: 5.1183 - val_MinusLogProbMetric: 5.1183 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 69/1000
2023-09-12 06:55:15.576 
Epoch 69/1000 
	 loss: 5.0794, MinusLogProbMetric: 5.0794, val_loss: 5.1467, val_MinusLogProbMetric: 5.1467

Epoch 69: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0794 - MinusLogProbMetric: 5.0794 - val_loss: 5.1467 - val_MinusLogProbMetric: 5.1467 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 70/1000
2023-09-12 06:55:27.076 
Epoch 70/1000 
	 loss: 5.0846, MinusLogProbMetric: 5.0846, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 70: val_loss did not improve from 5.10774
196/196 - 11s - loss: 5.0846 - MinusLogProbMetric: 5.0846 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 71/1000
2023-09-12 06:55:38.629 
Epoch 71/1000 
	 loss: 5.0803, MinusLogProbMetric: 5.0803, val_loss: 5.1505, val_MinusLogProbMetric: 5.1505

Epoch 71: val_loss did not improve from 5.10774
196/196 - 12s - loss: 5.0803 - MinusLogProbMetric: 5.0803 - val_loss: 5.1505 - val_MinusLogProbMetric: 5.1505 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 72/1000
2023-09-12 06:55:50.215 
Epoch 72/1000 
	 loss: 5.0874, MinusLogProbMetric: 5.0874, val_loss: 5.1499, val_MinusLogProbMetric: 5.1499

Epoch 72: val_loss did not improve from 5.10774
196/196 - 12s - loss: 5.0874 - MinusLogProbMetric: 5.0874 - val_loss: 5.1499 - val_MinusLogProbMetric: 5.1499 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 73/1000
2023-09-12 06:56:01.650 
Epoch 73/1000 
	 loss: 5.0758, MinusLogProbMetric: 5.0758, val_loss: 5.1014, val_MinusLogProbMetric: 5.1014

Epoch 73: val_loss improved from 5.10774 to 5.10140, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.0758 - MinusLogProbMetric: 5.0758 - val_loss: 5.1014 - val_MinusLogProbMetric: 5.1014 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 06:56:13.364 
Epoch 74/1000 
	 loss: 5.0780, MinusLogProbMetric: 5.0780, val_loss: 5.1200, val_MinusLogProbMetric: 5.1200

Epoch 74: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0780 - MinusLogProbMetric: 5.0780 - val_loss: 5.1200 - val_MinusLogProbMetric: 5.1200 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 75/1000
2023-09-12 06:56:24.846 
Epoch 75/1000 
	 loss: 5.0830, MinusLogProbMetric: 5.0830, val_loss: 5.1431, val_MinusLogProbMetric: 5.1431

Epoch 75: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0830 - MinusLogProbMetric: 5.0830 - val_loss: 5.1431 - val_MinusLogProbMetric: 5.1431 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 76/1000
2023-09-12 06:56:36.290 
Epoch 76/1000 
	 loss: 5.0736, MinusLogProbMetric: 5.0736, val_loss: 5.1105, val_MinusLogProbMetric: 5.1105

Epoch 76: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0736 - MinusLogProbMetric: 5.0736 - val_loss: 5.1105 - val_MinusLogProbMetric: 5.1105 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 77/1000
2023-09-12 06:56:47.747 
Epoch 77/1000 
	 loss: 5.0781, MinusLogProbMetric: 5.0781, val_loss: 5.1676, val_MinusLogProbMetric: 5.1676

Epoch 77: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0781 - MinusLogProbMetric: 5.0781 - val_loss: 5.1676 - val_MinusLogProbMetric: 5.1676 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 78/1000
2023-09-12 06:56:59.176 
Epoch 78/1000 
	 loss: 5.0729, MinusLogProbMetric: 5.0729, val_loss: 5.1221, val_MinusLogProbMetric: 5.1221

Epoch 78: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0729 - MinusLogProbMetric: 5.0729 - val_loss: 5.1221 - val_MinusLogProbMetric: 5.1221 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 79/1000
2023-09-12 06:57:10.888 
Epoch 79/1000 
	 loss: 5.0762, MinusLogProbMetric: 5.0762, val_loss: 5.1181, val_MinusLogProbMetric: 5.1181

Epoch 79: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0762 - MinusLogProbMetric: 5.0762 - val_loss: 5.1181 - val_MinusLogProbMetric: 5.1181 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 06:57:22.522 
Epoch 80/1000 
	 loss: 5.0768, MinusLogProbMetric: 5.0768, val_loss: 5.1036, val_MinusLogProbMetric: 5.1036

Epoch 80: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0768 - MinusLogProbMetric: 5.0768 - val_loss: 5.1036 - val_MinusLogProbMetric: 5.1036 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-12 06:57:34.121 
Epoch 81/1000 
	 loss: 5.0754, MinusLogProbMetric: 5.0754, val_loss: 5.1137, val_MinusLogProbMetric: 5.1137

Epoch 81: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0754 - MinusLogProbMetric: 5.0754 - val_loss: 5.1137 - val_MinusLogProbMetric: 5.1137 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 82/1000
2023-09-12 06:57:45.600 
Epoch 82/1000 
	 loss: 5.0715, MinusLogProbMetric: 5.0715, val_loss: 5.1454, val_MinusLogProbMetric: 5.1454

Epoch 82: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0715 - MinusLogProbMetric: 5.0715 - val_loss: 5.1454 - val_MinusLogProbMetric: 5.1454 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 83/1000
2023-09-12 06:57:57.125 
Epoch 83/1000 
	 loss: 5.0694, MinusLogProbMetric: 5.0694, val_loss: 5.1524, val_MinusLogProbMetric: 5.1524

Epoch 83: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0694 - MinusLogProbMetric: 5.0694 - val_loss: 5.1524 - val_MinusLogProbMetric: 5.1524 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-12 06:58:08.587 
Epoch 84/1000 
	 loss: 5.0694, MinusLogProbMetric: 5.0694, val_loss: 5.1197, val_MinusLogProbMetric: 5.1197

Epoch 84: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0694 - MinusLogProbMetric: 5.0694 - val_loss: 5.1197 - val_MinusLogProbMetric: 5.1197 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 85/1000
2023-09-12 06:58:20.257 
Epoch 85/1000 
	 loss: 5.0700, MinusLogProbMetric: 5.0700, val_loss: 5.1368, val_MinusLogProbMetric: 5.1368

Epoch 85: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0700 - MinusLogProbMetric: 5.0700 - val_loss: 5.1368 - val_MinusLogProbMetric: 5.1368 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-12 06:58:31.751 
Epoch 86/1000 
	 loss: 5.0715, MinusLogProbMetric: 5.0715, val_loss: 5.1299, val_MinusLogProbMetric: 5.1299

Epoch 86: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0715 - MinusLogProbMetric: 5.0715 - val_loss: 5.1299 - val_MinusLogProbMetric: 5.1299 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 87/1000
2023-09-12 06:58:43.313 
Epoch 87/1000 
	 loss: 5.0690, MinusLogProbMetric: 5.0690, val_loss: 5.1208, val_MinusLogProbMetric: 5.1208

Epoch 87: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0690 - MinusLogProbMetric: 5.0690 - val_loss: 5.1208 - val_MinusLogProbMetric: 5.1208 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-12 06:58:54.872 
Epoch 88/1000 
	 loss: 5.0695, MinusLogProbMetric: 5.0695, val_loss: 5.1098, val_MinusLogProbMetric: 5.1098

Epoch 88: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0695 - MinusLogProbMetric: 5.0695 - val_loss: 5.1098 - val_MinusLogProbMetric: 5.1098 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-12 06:59:06.463 
Epoch 89/1000 
	 loss: 5.0652, MinusLogProbMetric: 5.0652, val_loss: 5.1139, val_MinusLogProbMetric: 5.1139

Epoch 89: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0652 - MinusLogProbMetric: 5.0652 - val_loss: 5.1139 - val_MinusLogProbMetric: 5.1139 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 90/1000
2023-09-12 06:59:17.886 
Epoch 90/1000 
	 loss: 5.0646, MinusLogProbMetric: 5.0646, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 90: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0646 - MinusLogProbMetric: 5.0646 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 91/1000
2023-09-12 06:59:29.385 
Epoch 91/1000 
	 loss: 5.0645, MinusLogProbMetric: 5.0645, val_loss: 5.1247, val_MinusLogProbMetric: 5.1247

Epoch 91: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0645 - MinusLogProbMetric: 5.0645 - val_loss: 5.1247 - val_MinusLogProbMetric: 5.1247 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 92/1000
2023-09-12 06:59:40.822 
Epoch 92/1000 
	 loss: 5.0593, MinusLogProbMetric: 5.0593, val_loss: 5.1226, val_MinusLogProbMetric: 5.1226

Epoch 92: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0593 - MinusLogProbMetric: 5.0593 - val_loss: 5.1226 - val_MinusLogProbMetric: 5.1226 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 93/1000
2023-09-12 06:59:52.379 
Epoch 93/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1146, val_MinusLogProbMetric: 5.1146

Epoch 93: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1146 - val_MinusLogProbMetric: 5.1146 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 94/1000
2023-09-12 07:00:03.910 
Epoch 94/1000 
	 loss: 5.0706, MinusLogProbMetric: 5.0706, val_loss: 5.1165, val_MinusLogProbMetric: 5.1165

Epoch 94: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0706 - MinusLogProbMetric: 5.0706 - val_loss: 5.1165 - val_MinusLogProbMetric: 5.1165 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-12 07:00:15.374 
Epoch 95/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1086, val_MinusLogProbMetric: 5.1086

Epoch 95: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1086 - val_MinusLogProbMetric: 5.1086 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 96/1000
2023-09-12 07:00:26.918 
Epoch 96/1000 
	 loss: 5.0581, MinusLogProbMetric: 5.0581, val_loss: 5.1033, val_MinusLogProbMetric: 5.1033

Epoch 96: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0581 - MinusLogProbMetric: 5.0581 - val_loss: 5.1033 - val_MinusLogProbMetric: 5.1033 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 97/1000
2023-09-12 07:00:38.533 
Epoch 97/1000 
	 loss: 5.0614, MinusLogProbMetric: 5.0614, val_loss: 5.1161, val_MinusLogProbMetric: 5.1161

Epoch 97: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0614 - MinusLogProbMetric: 5.0614 - val_loss: 5.1161 - val_MinusLogProbMetric: 5.1161 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 98/1000
2023-09-12 07:00:50.094 
Epoch 98/1000 
	 loss: 5.0637, MinusLogProbMetric: 5.0637, val_loss: 5.1116, val_MinusLogProbMetric: 5.1116

Epoch 98: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0637 - MinusLogProbMetric: 5.0637 - val_loss: 5.1116 - val_MinusLogProbMetric: 5.1116 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 99/1000
2023-09-12 07:01:01.610 
Epoch 99/1000 
	 loss: 5.0625, MinusLogProbMetric: 5.0625, val_loss: 5.1097, val_MinusLogProbMetric: 5.1097

Epoch 99: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0625 - MinusLogProbMetric: 5.0625 - val_loss: 5.1097 - val_MinusLogProbMetric: 5.1097 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 07:01:13.170 
Epoch 100/1000 
	 loss: 5.0601, MinusLogProbMetric: 5.0601, val_loss: 5.1180, val_MinusLogProbMetric: 5.1180

Epoch 100: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0601 - MinusLogProbMetric: 5.0601 - val_loss: 5.1180 - val_MinusLogProbMetric: 5.1180 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 101/1000
2023-09-12 07:01:24.724 
Epoch 101/1000 
	 loss: 5.0579, MinusLogProbMetric: 5.0579, val_loss: 5.1154, val_MinusLogProbMetric: 5.1154

Epoch 101: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0579 - MinusLogProbMetric: 5.0579 - val_loss: 5.1154 - val_MinusLogProbMetric: 5.1154 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 102/1000
2023-09-12 07:01:36.316 
Epoch 102/1000 
	 loss: 5.0608, MinusLogProbMetric: 5.0608, val_loss: 5.1514, val_MinusLogProbMetric: 5.1514

Epoch 102: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0608 - MinusLogProbMetric: 5.0608 - val_loss: 5.1514 - val_MinusLogProbMetric: 5.1514 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 103/1000
2023-09-12 07:01:47.813 
Epoch 103/1000 
	 loss: 5.0572, MinusLogProbMetric: 5.0572, val_loss: 5.1120, val_MinusLogProbMetric: 5.1120

Epoch 103: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0572 - MinusLogProbMetric: 5.0572 - val_loss: 5.1120 - val_MinusLogProbMetric: 5.1120 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 104/1000
2023-09-12 07:01:59.126 
Epoch 104/1000 
	 loss: 5.0538, MinusLogProbMetric: 5.0538, val_loss: 5.1434, val_MinusLogProbMetric: 5.1434

Epoch 104: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0538 - MinusLogProbMetric: 5.0538 - val_loss: 5.1434 - val_MinusLogProbMetric: 5.1434 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 105/1000
2023-09-12 07:02:10.677 
Epoch 105/1000 
	 loss: 5.0561, MinusLogProbMetric: 5.0561, val_loss: 5.1154, val_MinusLogProbMetric: 5.1154

Epoch 105: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0561 - MinusLogProbMetric: 5.0561 - val_loss: 5.1154 - val_MinusLogProbMetric: 5.1154 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 106/1000
2023-09-12 07:02:22.132 
Epoch 106/1000 
	 loss: 5.0525, MinusLogProbMetric: 5.0525, val_loss: 5.1176, val_MinusLogProbMetric: 5.1176

Epoch 106: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0525 - MinusLogProbMetric: 5.0525 - val_loss: 5.1176 - val_MinusLogProbMetric: 5.1176 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 107/1000
2023-09-12 07:02:33.683 
Epoch 107/1000 
	 loss: 5.0509, MinusLogProbMetric: 5.0509, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 107: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0509 - MinusLogProbMetric: 5.0509 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 108/1000
2023-09-12 07:02:45.358 
Epoch 108/1000 
	 loss: 5.0529, MinusLogProbMetric: 5.0529, val_loss: 5.1346, val_MinusLogProbMetric: 5.1346

Epoch 108: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0529 - MinusLogProbMetric: 5.0529 - val_loss: 5.1346 - val_MinusLogProbMetric: 5.1346 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-12 07:02:56.793 
Epoch 109/1000 
	 loss: 5.0526, MinusLogProbMetric: 5.0526, val_loss: 5.1074, val_MinusLogProbMetric: 5.1074

Epoch 109: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0526 - MinusLogProbMetric: 5.0526 - val_loss: 5.1074 - val_MinusLogProbMetric: 5.1074 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 07:03:08.118 
Epoch 110/1000 
	 loss: 5.0534, MinusLogProbMetric: 5.0534, val_loss: 5.1030, val_MinusLogProbMetric: 5.1030

Epoch 110: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0534 - MinusLogProbMetric: 5.0534 - val_loss: 5.1030 - val_MinusLogProbMetric: 5.1030 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 111/1000
2023-09-12 07:03:19.638 
Epoch 111/1000 
	 loss: 5.0595, MinusLogProbMetric: 5.0595, val_loss: 5.1424, val_MinusLogProbMetric: 5.1424

Epoch 111: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0595 - MinusLogProbMetric: 5.0595 - val_loss: 5.1424 - val_MinusLogProbMetric: 5.1424 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 112/1000
2023-09-12 07:03:31.091 
Epoch 112/1000 
	 loss: 5.0518, MinusLogProbMetric: 5.0518, val_loss: 5.1261, val_MinusLogProbMetric: 5.1261

Epoch 112: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0518 - MinusLogProbMetric: 5.0518 - val_loss: 5.1261 - val_MinusLogProbMetric: 5.1261 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-12 07:03:42.514 
Epoch 113/1000 
	 loss: 5.0544, MinusLogProbMetric: 5.0544, val_loss: 5.1316, val_MinusLogProbMetric: 5.1316

Epoch 113: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0544 - MinusLogProbMetric: 5.0544 - val_loss: 5.1316 - val_MinusLogProbMetric: 5.1316 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 114/1000
2023-09-12 07:03:53.950 
Epoch 114/1000 
	 loss: 5.0527, MinusLogProbMetric: 5.0527, val_loss: 5.1363, val_MinusLogProbMetric: 5.1363

Epoch 114: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0527 - MinusLogProbMetric: 5.0527 - val_loss: 5.1363 - val_MinusLogProbMetric: 5.1363 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 115/1000
2023-09-12 07:04:05.586 
Epoch 115/1000 
	 loss: 5.0503, MinusLogProbMetric: 5.0503, val_loss: 5.1030, val_MinusLogProbMetric: 5.1030

Epoch 115: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0503 - MinusLogProbMetric: 5.0503 - val_loss: 5.1030 - val_MinusLogProbMetric: 5.1030 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 116/1000
2023-09-12 07:04:17.037 
Epoch 116/1000 
	 loss: 5.0448, MinusLogProbMetric: 5.0448, val_loss: 5.1162, val_MinusLogProbMetric: 5.1162

Epoch 116: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0448 - MinusLogProbMetric: 5.0448 - val_loss: 5.1162 - val_MinusLogProbMetric: 5.1162 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 117/1000
2023-09-12 07:04:28.681 
Epoch 117/1000 
	 loss: 5.0482, MinusLogProbMetric: 5.0482, val_loss: 5.1161, val_MinusLogProbMetric: 5.1161

Epoch 117: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0482 - MinusLogProbMetric: 5.0482 - val_loss: 5.1161 - val_MinusLogProbMetric: 5.1161 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 118/1000
2023-09-12 07:04:40.234 
Epoch 118/1000 
	 loss: 5.0428, MinusLogProbMetric: 5.0428, val_loss: 5.1222, val_MinusLogProbMetric: 5.1222

Epoch 118: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0428 - MinusLogProbMetric: 5.0428 - val_loss: 5.1222 - val_MinusLogProbMetric: 5.1222 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-12 07:04:51.722 
Epoch 119/1000 
	 loss: 5.0485, MinusLogProbMetric: 5.0485, val_loss: 5.1240, val_MinusLogProbMetric: 5.1240

Epoch 119: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0485 - MinusLogProbMetric: 5.0485 - val_loss: 5.1240 - val_MinusLogProbMetric: 5.1240 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 120/1000
2023-09-12 07:05:03.323 
Epoch 120/1000 
	 loss: 5.0461, MinusLogProbMetric: 5.0461, val_loss: 5.1393, val_MinusLogProbMetric: 5.1393

Epoch 120: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0461 - MinusLogProbMetric: 5.0461 - val_loss: 5.1393 - val_MinusLogProbMetric: 5.1393 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 121/1000
2023-09-12 07:05:14.800 
Epoch 121/1000 
	 loss: 5.0440, MinusLogProbMetric: 5.0440, val_loss: 5.1165, val_MinusLogProbMetric: 5.1165

Epoch 121: val_loss did not improve from 5.10140
196/196 - 11s - loss: 5.0440 - MinusLogProbMetric: 5.0440 - val_loss: 5.1165 - val_MinusLogProbMetric: 5.1165 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 122/1000
2023-09-12 07:05:26.354 
Epoch 122/1000 
	 loss: 5.0422, MinusLogProbMetric: 5.0422, val_loss: 5.1449, val_MinusLogProbMetric: 5.1449

Epoch 122: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0422 - MinusLogProbMetric: 5.0422 - val_loss: 5.1449 - val_MinusLogProbMetric: 5.1449 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 123/1000
2023-09-12 07:05:37.998 
Epoch 123/1000 
	 loss: 5.0477, MinusLogProbMetric: 5.0477, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 123: val_loss did not improve from 5.10140
196/196 - 12s - loss: 5.0477 - MinusLogProbMetric: 5.0477 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 124/1000
2023-09-12 07:05:49.430 
Epoch 124/1000 
	 loss: 5.0175, MinusLogProbMetric: 5.0175, val_loss: 5.0928, val_MinusLogProbMetric: 5.0928

Epoch 124: val_loss improved from 5.10140 to 5.09280, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 12s - loss: 5.0175 - MinusLogProbMetric: 5.0175 - val_loss: 5.0928 - val_MinusLogProbMetric: 5.0928 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 125/1000
2023-09-12 07:06:00.921 
Epoch 125/1000 
	 loss: 5.0148, MinusLogProbMetric: 5.0148, val_loss: 5.0983, val_MinusLogProbMetric: 5.0983

Epoch 125: val_loss did not improve from 5.09280
196/196 - 11s - loss: 5.0148 - MinusLogProbMetric: 5.0148 - val_loss: 5.0983 - val_MinusLogProbMetric: 5.0983 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 126/1000
2023-09-12 07:06:12.230 
Epoch 126/1000 
	 loss: 5.0174, MinusLogProbMetric: 5.0174, val_loss: 5.0951, val_MinusLogProbMetric: 5.0951

Epoch 126: val_loss did not improve from 5.09280
196/196 - 11s - loss: 5.0174 - MinusLogProbMetric: 5.0174 - val_loss: 5.0951 - val_MinusLogProbMetric: 5.0951 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 127/1000
2023-09-12 07:06:22.884 
Epoch 127/1000 
	 loss: 5.0120, MinusLogProbMetric: 5.0120, val_loss: 5.0928, val_MinusLogProbMetric: 5.0928

Epoch 127: val_loss improved from 5.09280 to 5.09279, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 11s - loss: 5.0120 - MinusLogProbMetric: 5.0120 - val_loss: 5.0928 - val_MinusLogProbMetric: 5.0928 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 128/1000
2023-09-12 07:06:33.880 
Epoch 128/1000 
	 loss: 5.0137, MinusLogProbMetric: 5.0137, val_loss: 5.0892, val_MinusLogProbMetric: 5.0892

Epoch 128: val_loss improved from 5.09279 to 5.08919, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_82/weights/best_weights.h5
196/196 - 11s - loss: 5.0137 - MinusLogProbMetric: 5.0137 - val_loss: 5.0892 - val_MinusLogProbMetric: 5.0892 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 129/1000
2023-09-12 07:06:44.206 
Epoch 129/1000 
	 loss: 5.0129, MinusLogProbMetric: 5.0129, val_loss: 5.1074, val_MinusLogProbMetric: 5.1074

Epoch 129: val_loss did not improve from 5.08919
196/196 - 10s - loss: 5.0129 - MinusLogProbMetric: 5.0129 - val_loss: 5.1074 - val_MinusLogProbMetric: 5.1074 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 130/1000
2023-09-12 07:06:55.468 
Epoch 130/1000 
	 loss: 5.0137, MinusLogProbMetric: 5.0137, val_loss: 5.1007, val_MinusLogProbMetric: 5.1007

Epoch 130: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0137 - MinusLogProbMetric: 5.0137 - val_loss: 5.1007 - val_MinusLogProbMetric: 5.1007 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 131/1000
2023-09-12 07:07:06.922 
Epoch 131/1000 
	 loss: 5.0134, MinusLogProbMetric: 5.0134, val_loss: 5.0982, val_MinusLogProbMetric: 5.0982

Epoch 131: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0134 - MinusLogProbMetric: 5.0134 - val_loss: 5.0982 - val_MinusLogProbMetric: 5.0982 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 132/1000
2023-09-12 07:07:18.462 
Epoch 132/1000 
	 loss: 5.0121, MinusLogProbMetric: 5.0121, val_loss: 5.0997, val_MinusLogProbMetric: 5.0997

Epoch 132: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0121 - MinusLogProbMetric: 5.0121 - val_loss: 5.0997 - val_MinusLogProbMetric: 5.0997 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 133/1000
2023-09-12 07:07:29.965 
Epoch 133/1000 
	 loss: 5.0146, MinusLogProbMetric: 5.0146, val_loss: 5.0942, val_MinusLogProbMetric: 5.0942

Epoch 133: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0146 - MinusLogProbMetric: 5.0146 - val_loss: 5.0942 - val_MinusLogProbMetric: 5.0942 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 134/1000
2023-09-12 07:07:41.572 
Epoch 134/1000 
	 loss: 5.0109, MinusLogProbMetric: 5.0109, val_loss: 5.1102, val_MinusLogProbMetric: 5.1102

Epoch 134: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0109 - MinusLogProbMetric: 5.0109 - val_loss: 5.1102 - val_MinusLogProbMetric: 5.1102 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 135/1000
2023-09-12 07:07:53.174 
Epoch 135/1000 
	 loss: 5.0103, MinusLogProbMetric: 5.0103, val_loss: 5.1061, val_MinusLogProbMetric: 5.1061

Epoch 135: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0103 - MinusLogProbMetric: 5.0103 - val_loss: 5.1061 - val_MinusLogProbMetric: 5.1061 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 136/1000
2023-09-12 07:08:04.621 
Epoch 136/1000 
	 loss: 5.0133, MinusLogProbMetric: 5.0133, val_loss: 5.0976, val_MinusLogProbMetric: 5.0976

Epoch 136: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0133 - MinusLogProbMetric: 5.0133 - val_loss: 5.0976 - val_MinusLogProbMetric: 5.0976 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 137/1000
2023-09-12 07:08:16.193 
Epoch 137/1000 
	 loss: 5.0095, MinusLogProbMetric: 5.0095, val_loss: 5.1093, val_MinusLogProbMetric: 5.1093

Epoch 137: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0095 - MinusLogProbMetric: 5.0095 - val_loss: 5.1093 - val_MinusLogProbMetric: 5.1093 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 138/1000
2023-09-12 07:08:27.697 
Epoch 138/1000 
	 loss: 5.0135, MinusLogProbMetric: 5.0135, val_loss: 5.1100, val_MinusLogProbMetric: 5.1100

Epoch 138: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0135 - MinusLogProbMetric: 5.0135 - val_loss: 5.1100 - val_MinusLogProbMetric: 5.1100 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 139/1000
2023-09-12 07:08:39.318 
Epoch 139/1000 
	 loss: 5.0102, MinusLogProbMetric: 5.0102, val_loss: 5.1165, val_MinusLogProbMetric: 5.1165

Epoch 139: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0102 - MinusLogProbMetric: 5.0102 - val_loss: 5.1165 - val_MinusLogProbMetric: 5.1165 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 140/1000
2023-09-12 07:08:50.823 
Epoch 140/1000 
	 loss: 5.0093, MinusLogProbMetric: 5.0093, val_loss: 5.1001, val_MinusLogProbMetric: 5.1001

Epoch 140: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0093 - MinusLogProbMetric: 5.0093 - val_loss: 5.1001 - val_MinusLogProbMetric: 5.1001 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 141/1000
2023-09-12 07:09:02.319 
Epoch 141/1000 
	 loss: 5.0089, MinusLogProbMetric: 5.0089, val_loss: 5.1098, val_MinusLogProbMetric: 5.1098

Epoch 141: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0089 - MinusLogProbMetric: 5.0089 - val_loss: 5.1098 - val_MinusLogProbMetric: 5.1098 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 142/1000
2023-09-12 07:09:13.912 
Epoch 142/1000 
	 loss: 5.0075, MinusLogProbMetric: 5.0075, val_loss: 5.1021, val_MinusLogProbMetric: 5.1021

Epoch 142: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0075 - MinusLogProbMetric: 5.0075 - val_loss: 5.1021 - val_MinusLogProbMetric: 5.1021 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 143/1000
2023-09-12 07:09:25.508 
Epoch 143/1000 
	 loss: 5.0096, MinusLogProbMetric: 5.0096, val_loss: 5.1054, val_MinusLogProbMetric: 5.1054

Epoch 143: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0096 - MinusLogProbMetric: 5.0096 - val_loss: 5.1054 - val_MinusLogProbMetric: 5.1054 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 144/1000
2023-09-12 07:09:37.035 
Epoch 144/1000 
	 loss: 5.0086, MinusLogProbMetric: 5.0086, val_loss: 5.1095, val_MinusLogProbMetric: 5.1095

Epoch 144: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0086 - MinusLogProbMetric: 5.0086 - val_loss: 5.1095 - val_MinusLogProbMetric: 5.1095 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 145/1000
2023-09-12 07:09:48.506 
Epoch 145/1000 
	 loss: 5.0089, MinusLogProbMetric: 5.0089, val_loss: 5.1112, val_MinusLogProbMetric: 5.1112

Epoch 145: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0089 - MinusLogProbMetric: 5.0089 - val_loss: 5.1112 - val_MinusLogProbMetric: 5.1112 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 146/1000
2023-09-12 07:10:00.053 
Epoch 146/1000 
	 loss: 5.0072, MinusLogProbMetric: 5.0072, val_loss: 5.1072, val_MinusLogProbMetric: 5.1072

Epoch 146: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0072 - MinusLogProbMetric: 5.0072 - val_loss: 5.1072 - val_MinusLogProbMetric: 5.1072 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 147/1000
2023-09-12 07:10:11.477 
Epoch 147/1000 
	 loss: 5.0076, MinusLogProbMetric: 5.0076, val_loss: 5.1090, val_MinusLogProbMetric: 5.1090

Epoch 147: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0076 - MinusLogProbMetric: 5.0076 - val_loss: 5.1090 - val_MinusLogProbMetric: 5.1090 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 148/1000
2023-09-12 07:10:23.022 
Epoch 148/1000 
	 loss: 5.0064, MinusLogProbMetric: 5.0064, val_loss: 5.1174, val_MinusLogProbMetric: 5.1174

Epoch 148: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0064 - MinusLogProbMetric: 5.0064 - val_loss: 5.1174 - val_MinusLogProbMetric: 5.1174 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 149/1000
2023-09-12 07:10:34.715 
Epoch 149/1000 
	 loss: 5.0063, MinusLogProbMetric: 5.0063, val_loss: 5.1144, val_MinusLogProbMetric: 5.1144

Epoch 149: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0063 - MinusLogProbMetric: 5.0063 - val_loss: 5.1144 - val_MinusLogProbMetric: 5.1144 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-12 07:10:46.248 
Epoch 150/1000 
	 loss: 5.0041, MinusLogProbMetric: 5.0041, val_loss: 5.1039, val_MinusLogProbMetric: 5.1039

Epoch 150: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0041 - MinusLogProbMetric: 5.0041 - val_loss: 5.1039 - val_MinusLogProbMetric: 5.1039 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 151/1000
2023-09-12 07:10:57.730 
Epoch 151/1000 
	 loss: 5.0050, MinusLogProbMetric: 5.0050, val_loss: 5.0953, val_MinusLogProbMetric: 5.0953

Epoch 151: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0050 - MinusLogProbMetric: 5.0050 - val_loss: 5.0953 - val_MinusLogProbMetric: 5.0953 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 152/1000
2023-09-12 07:11:09.096 
Epoch 152/1000 
	 loss: 5.0043, MinusLogProbMetric: 5.0043, val_loss: 5.1133, val_MinusLogProbMetric: 5.1133

Epoch 152: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0043 - MinusLogProbMetric: 5.0043 - val_loss: 5.1133 - val_MinusLogProbMetric: 5.1133 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 153/1000
2023-09-12 07:11:19.644 
Epoch 153/1000 
	 loss: 5.0059, MinusLogProbMetric: 5.0059, val_loss: 5.1064, val_MinusLogProbMetric: 5.1064

Epoch 153: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0059 - MinusLogProbMetric: 5.0059 - val_loss: 5.1064 - val_MinusLogProbMetric: 5.1064 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 154/1000
2023-09-12 07:11:30.463 
Epoch 154/1000 
	 loss: 5.0044, MinusLogProbMetric: 5.0044, val_loss: 5.1152, val_MinusLogProbMetric: 5.1152

Epoch 154: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0044 - MinusLogProbMetric: 5.0044 - val_loss: 5.1152 - val_MinusLogProbMetric: 5.1152 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 155/1000
2023-09-12 07:11:41.707 
Epoch 155/1000 
	 loss: 5.0048, MinusLogProbMetric: 5.0048, val_loss: 5.1055, val_MinusLogProbMetric: 5.1055

Epoch 155: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0048 - MinusLogProbMetric: 5.0048 - val_loss: 5.1055 - val_MinusLogProbMetric: 5.1055 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 156/1000
2023-09-12 07:11:53.223 
Epoch 156/1000 
	 loss: 5.0050, MinusLogProbMetric: 5.0050, val_loss: 5.1036, val_MinusLogProbMetric: 5.1036

Epoch 156: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0050 - MinusLogProbMetric: 5.0050 - val_loss: 5.1036 - val_MinusLogProbMetric: 5.1036 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 157/1000
2023-09-12 07:12:04.688 
Epoch 157/1000 
	 loss: 5.0051, MinusLogProbMetric: 5.0051, val_loss: 5.1063, val_MinusLogProbMetric: 5.1063

Epoch 157: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0051 - MinusLogProbMetric: 5.0051 - val_loss: 5.1063 - val_MinusLogProbMetric: 5.1063 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 158/1000
2023-09-12 07:12:16.216 
Epoch 158/1000 
	 loss: 5.0031, MinusLogProbMetric: 5.0031, val_loss: 5.1217, val_MinusLogProbMetric: 5.1217

Epoch 158: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0031 - MinusLogProbMetric: 5.0031 - val_loss: 5.1217 - val_MinusLogProbMetric: 5.1217 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 159/1000
2023-09-12 07:12:27.807 
Epoch 159/1000 
	 loss: 5.0017, MinusLogProbMetric: 5.0017, val_loss: 5.1059, val_MinusLogProbMetric: 5.1059

Epoch 159: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0017 - MinusLogProbMetric: 5.0017 - val_loss: 5.1059 - val_MinusLogProbMetric: 5.1059 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 160/1000
2023-09-12 07:12:39.296 
Epoch 160/1000 
	 loss: 5.0023, MinusLogProbMetric: 5.0023, val_loss: 5.1256, val_MinusLogProbMetric: 5.1256

Epoch 160: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0023 - MinusLogProbMetric: 5.0023 - val_loss: 5.1256 - val_MinusLogProbMetric: 5.1256 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 161/1000
2023-09-12 07:12:50.735 
Epoch 161/1000 
	 loss: 5.0033, MinusLogProbMetric: 5.0033, val_loss: 5.1129, val_MinusLogProbMetric: 5.1129

Epoch 161: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0033 - MinusLogProbMetric: 5.0033 - val_loss: 5.1129 - val_MinusLogProbMetric: 5.1129 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 162/1000
2023-09-12 07:13:02.218 
Epoch 162/1000 
	 loss: 5.0004, MinusLogProbMetric: 5.0004, val_loss: 5.1119, val_MinusLogProbMetric: 5.1119

Epoch 162: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0004 - MinusLogProbMetric: 5.0004 - val_loss: 5.1119 - val_MinusLogProbMetric: 5.1119 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 163/1000
2023-09-12 07:13:13.623 
Epoch 163/1000 
	 loss: 5.0037, MinusLogProbMetric: 5.0037, val_loss: 5.1087, val_MinusLogProbMetric: 5.1087

Epoch 163: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0037 - MinusLogProbMetric: 5.0037 - val_loss: 5.1087 - val_MinusLogProbMetric: 5.1087 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 164/1000
2023-09-12 07:13:25.133 
Epoch 164/1000 
	 loss: 4.9985, MinusLogProbMetric: 4.9985, val_loss: 5.1142, val_MinusLogProbMetric: 5.1142

Epoch 164: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9985 - MinusLogProbMetric: 4.9985 - val_loss: 5.1142 - val_MinusLogProbMetric: 5.1142 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-12 07:13:36.601 
Epoch 165/1000 
	 loss: 5.0010, MinusLogProbMetric: 5.0010, val_loss: 5.1303, val_MinusLogProbMetric: 5.1303

Epoch 165: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0010 - MinusLogProbMetric: 5.0010 - val_loss: 5.1303 - val_MinusLogProbMetric: 5.1303 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 166/1000
2023-09-12 07:13:48.129 
Epoch 166/1000 
	 loss: 5.0033, MinusLogProbMetric: 5.0033, val_loss: 5.1054, val_MinusLogProbMetric: 5.1054

Epoch 166: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0033 - MinusLogProbMetric: 5.0033 - val_loss: 5.1054 - val_MinusLogProbMetric: 5.1054 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-12 07:13:59.662 
Epoch 167/1000 
	 loss: 4.9990, MinusLogProbMetric: 4.9990, val_loss: 5.1089, val_MinusLogProbMetric: 5.1089

Epoch 167: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9990 - MinusLogProbMetric: 4.9990 - val_loss: 5.1089 - val_MinusLogProbMetric: 5.1089 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 168/1000
2023-09-12 07:14:11.194 
Epoch 168/1000 
	 loss: 5.0009, MinusLogProbMetric: 5.0009, val_loss: 5.1180, val_MinusLogProbMetric: 5.1180

Epoch 168: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0009 - MinusLogProbMetric: 5.0009 - val_loss: 5.1180 - val_MinusLogProbMetric: 5.1180 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 169/1000
2023-09-12 07:14:22.839 
Epoch 169/1000 
	 loss: 5.0003, MinusLogProbMetric: 5.0003, val_loss: 5.1149, val_MinusLogProbMetric: 5.1149

Epoch 169: val_loss did not improve from 5.08919
196/196 - 12s - loss: 5.0003 - MinusLogProbMetric: 5.0003 - val_loss: 5.1149 - val_MinusLogProbMetric: 5.1149 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 170/1000
2023-09-12 07:14:34.287 
Epoch 170/1000 
	 loss: 4.9989, MinusLogProbMetric: 4.9989, val_loss: 5.1112, val_MinusLogProbMetric: 5.1112

Epoch 170: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9989 - MinusLogProbMetric: 4.9989 - val_loss: 5.1112 - val_MinusLogProbMetric: 5.1112 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 171/1000
2023-09-12 07:14:45.644 
Epoch 171/1000 
	 loss: 5.0001, MinusLogProbMetric: 5.0001, val_loss: 5.1162, val_MinusLogProbMetric: 5.1162

Epoch 171: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0001 - MinusLogProbMetric: 5.0001 - val_loss: 5.1162 - val_MinusLogProbMetric: 5.1162 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 172/1000
2023-09-12 07:14:57.065 
Epoch 172/1000 
	 loss: 4.9988, MinusLogProbMetric: 4.9988, val_loss: 5.1126, val_MinusLogProbMetric: 5.1126

Epoch 172: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9988 - MinusLogProbMetric: 4.9988 - val_loss: 5.1126 - val_MinusLogProbMetric: 5.1126 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 173/1000
2023-09-12 07:15:08.531 
Epoch 173/1000 
	 loss: 5.0011, MinusLogProbMetric: 5.0011, val_loss: 5.1107, val_MinusLogProbMetric: 5.1107

Epoch 173: val_loss did not improve from 5.08919
196/196 - 11s - loss: 5.0011 - MinusLogProbMetric: 5.0011 - val_loss: 5.1107 - val_MinusLogProbMetric: 5.1107 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 174/1000
2023-09-12 07:15:20.171 
Epoch 174/1000 
	 loss: 4.9996, MinusLogProbMetric: 4.9996, val_loss: 5.1102, val_MinusLogProbMetric: 5.1102

Epoch 174: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9996 - MinusLogProbMetric: 4.9996 - val_loss: 5.1102 - val_MinusLogProbMetric: 5.1102 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 175/1000
2023-09-12 07:15:31.698 
Epoch 175/1000 
	 loss: 4.9966, MinusLogProbMetric: 4.9966, val_loss: 5.1095, val_MinusLogProbMetric: 5.1095

Epoch 175: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9966 - MinusLogProbMetric: 4.9966 - val_loss: 5.1095 - val_MinusLogProbMetric: 5.1095 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-12 07:15:43.247 
Epoch 176/1000 
	 loss: 4.9966, MinusLogProbMetric: 4.9966, val_loss: 5.1144, val_MinusLogProbMetric: 5.1144

Epoch 176: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9966 - MinusLogProbMetric: 4.9966 - val_loss: 5.1144 - val_MinusLogProbMetric: 5.1144 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 177/1000
2023-09-12 07:15:54.709 
Epoch 177/1000 
	 loss: 4.9973, MinusLogProbMetric: 4.9973, val_loss: 5.1109, val_MinusLogProbMetric: 5.1109

Epoch 177: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9973 - MinusLogProbMetric: 4.9973 - val_loss: 5.1109 - val_MinusLogProbMetric: 5.1109 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 178/1000
2023-09-12 07:16:06.046 
Epoch 178/1000 
	 loss: 4.9991, MinusLogProbMetric: 4.9991, val_loss: 5.1131, val_MinusLogProbMetric: 5.1131

Epoch 178: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9991 - MinusLogProbMetric: 4.9991 - val_loss: 5.1131 - val_MinusLogProbMetric: 5.1131 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 179/1000
2023-09-12 07:16:17.469 
Epoch 179/1000 
	 loss: 4.9819, MinusLogProbMetric: 4.9819, val_loss: 5.1014, val_MinusLogProbMetric: 5.1014

Epoch 179: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9819 - MinusLogProbMetric: 4.9819 - val_loss: 5.1014 - val_MinusLogProbMetric: 5.1014 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 180/1000
2023-09-12 07:16:28.939 
Epoch 180/1000 
	 loss: 4.9802, MinusLogProbMetric: 4.9802, val_loss: 5.1041, val_MinusLogProbMetric: 5.1041

Epoch 180: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9802 - MinusLogProbMetric: 4.9802 - val_loss: 5.1041 - val_MinusLogProbMetric: 5.1041 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 181/1000
2023-09-12 07:16:40.483 
Epoch 181/1000 
	 loss: 4.9806, MinusLogProbMetric: 4.9806, val_loss: 5.1095, val_MinusLogProbMetric: 5.1095

Epoch 181: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9806 - MinusLogProbMetric: 4.9806 - val_loss: 5.1095 - val_MinusLogProbMetric: 5.1095 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 182/1000
2023-09-12 07:16:50.787 
Epoch 182/1000 
	 loss: 4.9798, MinusLogProbMetric: 4.9798, val_loss: 5.1112, val_MinusLogProbMetric: 5.1112

Epoch 182: val_loss did not improve from 5.08919
196/196 - 10s - loss: 4.9798 - MinusLogProbMetric: 4.9798 - val_loss: 5.1112 - val_MinusLogProbMetric: 5.1112 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 183/1000
2023-09-12 07:17:00.578 
Epoch 183/1000 
	 loss: 4.9800, MinusLogProbMetric: 4.9800, val_loss: 5.1025, val_MinusLogProbMetric: 5.1025

Epoch 183: val_loss did not improve from 5.08919
196/196 - 10s - loss: 4.9800 - MinusLogProbMetric: 4.9800 - val_loss: 5.1025 - val_MinusLogProbMetric: 5.1025 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 184/1000
2023-09-12 07:17:10.400 
Epoch 184/1000 
	 loss: 4.9799, MinusLogProbMetric: 4.9799, val_loss: 5.1049, val_MinusLogProbMetric: 5.1049

Epoch 184: val_loss did not improve from 5.08919
196/196 - 10s - loss: 4.9799 - MinusLogProbMetric: 4.9799 - val_loss: 5.1049 - val_MinusLogProbMetric: 5.1049 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 185/1000
2023-09-12 07:17:21.438 
Epoch 185/1000 
	 loss: 4.9807, MinusLogProbMetric: 4.9807, val_loss: 5.1062, val_MinusLogProbMetric: 5.1062

Epoch 185: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9807 - MinusLogProbMetric: 4.9807 - val_loss: 5.1062 - val_MinusLogProbMetric: 5.1062 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 186/1000
2023-09-12 07:17:32.894 
Epoch 186/1000 
	 loss: 4.9800, MinusLogProbMetric: 4.9800, val_loss: 5.1073, val_MinusLogProbMetric: 5.1073

Epoch 186: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9800 - MinusLogProbMetric: 4.9800 - val_loss: 5.1073 - val_MinusLogProbMetric: 5.1073 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 187/1000
2023-09-12 07:17:44.268 
Epoch 187/1000 
	 loss: 4.9798, MinusLogProbMetric: 4.9798, val_loss: 5.1114, val_MinusLogProbMetric: 5.1114

Epoch 187: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9798 - MinusLogProbMetric: 4.9798 - val_loss: 5.1114 - val_MinusLogProbMetric: 5.1114 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 188/1000
2023-09-12 07:17:55.712 
Epoch 188/1000 
	 loss: 4.9803, MinusLogProbMetric: 4.9803, val_loss: 5.1031, val_MinusLogProbMetric: 5.1031

Epoch 188: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9803 - MinusLogProbMetric: 4.9803 - val_loss: 5.1031 - val_MinusLogProbMetric: 5.1031 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 189/1000
2023-09-12 07:18:07.304 
Epoch 189/1000 
	 loss: 4.9789, MinusLogProbMetric: 4.9789, val_loss: 5.1089, val_MinusLogProbMetric: 5.1089

Epoch 189: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9789 - MinusLogProbMetric: 4.9789 - val_loss: 5.1089 - val_MinusLogProbMetric: 5.1089 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 190/1000
2023-09-12 07:18:18.843 
Epoch 190/1000 
	 loss: 4.9795, MinusLogProbMetric: 4.9795, val_loss: 5.1145, val_MinusLogProbMetric: 5.1145

Epoch 190: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9795 - MinusLogProbMetric: 4.9795 - val_loss: 5.1145 - val_MinusLogProbMetric: 5.1145 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 191/1000
2023-09-12 07:18:30.370 
Epoch 191/1000 
	 loss: 4.9793, MinusLogProbMetric: 4.9793, val_loss: 5.1088, val_MinusLogProbMetric: 5.1088

Epoch 191: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9793 - MinusLogProbMetric: 4.9793 - val_loss: 5.1088 - val_MinusLogProbMetric: 5.1088 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 192/1000
2023-09-12 07:18:41.963 
Epoch 192/1000 
	 loss: 4.9778, MinusLogProbMetric: 4.9778, val_loss: 5.1121, val_MinusLogProbMetric: 5.1121

Epoch 192: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9778 - MinusLogProbMetric: 4.9778 - val_loss: 5.1121 - val_MinusLogProbMetric: 5.1121 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 193/1000
2023-09-12 07:18:53.484 
Epoch 193/1000 
	 loss: 4.9792, MinusLogProbMetric: 4.9792, val_loss: 5.1120, val_MinusLogProbMetric: 5.1120

Epoch 193: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9792 - MinusLogProbMetric: 4.9792 - val_loss: 5.1120 - val_MinusLogProbMetric: 5.1120 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 194/1000
2023-09-12 07:19:04.884 
Epoch 194/1000 
	 loss: 4.9774, MinusLogProbMetric: 4.9774, val_loss: 5.1074, val_MinusLogProbMetric: 5.1074

Epoch 194: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9774 - MinusLogProbMetric: 4.9774 - val_loss: 5.1074 - val_MinusLogProbMetric: 5.1074 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 195/1000
2023-09-12 07:19:16.399 
Epoch 195/1000 
	 loss: 4.9780, MinusLogProbMetric: 4.9780, val_loss: 5.1072, val_MinusLogProbMetric: 5.1072

Epoch 195: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9780 - MinusLogProbMetric: 4.9780 - val_loss: 5.1072 - val_MinusLogProbMetric: 5.1072 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 196/1000
2023-09-12 07:19:27.965 
Epoch 196/1000 
	 loss: 4.9788, MinusLogProbMetric: 4.9788, val_loss: 5.1097, val_MinusLogProbMetric: 5.1097

Epoch 196: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9788 - MinusLogProbMetric: 4.9788 - val_loss: 5.1097 - val_MinusLogProbMetric: 5.1097 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 197/1000
2023-09-12 07:19:39.476 
Epoch 197/1000 
	 loss: 4.9768, MinusLogProbMetric: 4.9768, val_loss: 5.1138, val_MinusLogProbMetric: 5.1138

Epoch 197: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9768 - MinusLogProbMetric: 4.9768 - val_loss: 5.1138 - val_MinusLogProbMetric: 5.1138 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 198/1000
2023-09-12 07:19:51.025 
Epoch 198/1000 
	 loss: 4.9778, MinusLogProbMetric: 4.9778, val_loss: 5.1134, val_MinusLogProbMetric: 5.1134

Epoch 198: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9778 - MinusLogProbMetric: 4.9778 - val_loss: 5.1134 - val_MinusLogProbMetric: 5.1134 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 199/1000
2023-09-12 07:20:02.513 
Epoch 199/1000 
	 loss: 4.9772, MinusLogProbMetric: 4.9772, val_loss: 5.1153, val_MinusLogProbMetric: 5.1153

Epoch 199: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9772 - MinusLogProbMetric: 4.9772 - val_loss: 5.1153 - val_MinusLogProbMetric: 5.1153 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 200/1000
2023-09-12 07:20:14.132 
Epoch 200/1000 
	 loss: 4.9768, MinusLogProbMetric: 4.9768, val_loss: 5.1113, val_MinusLogProbMetric: 5.1113

Epoch 200: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9768 - MinusLogProbMetric: 4.9768 - val_loss: 5.1113 - val_MinusLogProbMetric: 5.1113 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 201/1000
2023-09-12 07:20:25.613 
Epoch 201/1000 
	 loss: 4.9764, MinusLogProbMetric: 4.9764, val_loss: 5.1093, val_MinusLogProbMetric: 5.1093

Epoch 201: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9764 - MinusLogProbMetric: 4.9764 - val_loss: 5.1093 - val_MinusLogProbMetric: 5.1093 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 202/1000
2023-09-12 07:20:37.372 
Epoch 202/1000 
	 loss: 4.9769, MinusLogProbMetric: 4.9769, val_loss: 5.1133, val_MinusLogProbMetric: 5.1133

Epoch 202: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9769 - MinusLogProbMetric: 4.9769 - val_loss: 5.1133 - val_MinusLogProbMetric: 5.1133 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-12 07:20:48.739 
Epoch 203/1000 
	 loss: 4.9756, MinusLogProbMetric: 4.9756, val_loss: 5.1192, val_MinusLogProbMetric: 5.1192

Epoch 203: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9756 - MinusLogProbMetric: 4.9756 - val_loss: 5.1192 - val_MinusLogProbMetric: 5.1192 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 204/1000
2023-09-12 07:21:00.504 
Epoch 204/1000 
	 loss: 4.9768, MinusLogProbMetric: 4.9768, val_loss: 5.1113, val_MinusLogProbMetric: 5.1113

Epoch 204: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9768 - MinusLogProbMetric: 4.9768 - val_loss: 5.1113 - val_MinusLogProbMetric: 5.1113 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-12 07:21:11.904 
Epoch 205/1000 
	 loss: 4.9756, MinusLogProbMetric: 4.9756, val_loss: 5.1117, val_MinusLogProbMetric: 5.1117

Epoch 205: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9756 - MinusLogProbMetric: 4.9756 - val_loss: 5.1117 - val_MinusLogProbMetric: 5.1117 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-12 07:21:23.518 
Epoch 206/1000 
	 loss: 4.9754, MinusLogProbMetric: 4.9754, val_loss: 5.1154, val_MinusLogProbMetric: 5.1154

Epoch 206: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9754 - MinusLogProbMetric: 4.9754 - val_loss: 5.1154 - val_MinusLogProbMetric: 5.1154 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-12 07:21:35.236 
Epoch 207/1000 
	 loss: 4.9759, MinusLogProbMetric: 4.9759, val_loss: 5.1173, val_MinusLogProbMetric: 5.1173

Epoch 207: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9759 - MinusLogProbMetric: 4.9759 - val_loss: 5.1173 - val_MinusLogProbMetric: 5.1173 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-12 07:21:46.527 
Epoch 208/1000 
	 loss: 4.9756, MinusLogProbMetric: 4.9756, val_loss: 5.1142, val_MinusLogProbMetric: 5.1142

Epoch 208: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9756 - MinusLogProbMetric: 4.9756 - val_loss: 5.1142 - val_MinusLogProbMetric: 5.1142 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 209/1000
2023-09-12 07:21:57.155 
Epoch 209/1000 
	 loss: 4.9748, MinusLogProbMetric: 4.9748, val_loss: 5.1152, val_MinusLogProbMetric: 5.1152

Epoch 209: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9748 - MinusLogProbMetric: 4.9748 - val_loss: 5.1152 - val_MinusLogProbMetric: 5.1152 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 210/1000
2023-09-12 07:22:06.925 
Epoch 210/1000 
	 loss: 4.9749, MinusLogProbMetric: 4.9749, val_loss: 5.1132, val_MinusLogProbMetric: 5.1132

Epoch 210: val_loss did not improve from 5.08919
196/196 - 10s - loss: 4.9749 - MinusLogProbMetric: 4.9749 - val_loss: 5.1132 - val_MinusLogProbMetric: 5.1132 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 211/1000
2023-09-12 07:22:18.083 
Epoch 211/1000 
	 loss: 4.9753, MinusLogProbMetric: 4.9753, val_loss: 5.1136, val_MinusLogProbMetric: 5.1136

Epoch 211: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9753 - MinusLogProbMetric: 4.9753 - val_loss: 5.1136 - val_MinusLogProbMetric: 5.1136 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 212/1000
2023-09-12 07:22:29.543 
Epoch 212/1000 
	 loss: 4.9731, MinusLogProbMetric: 4.9731, val_loss: 5.1155, val_MinusLogProbMetric: 5.1155

Epoch 212: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9731 - MinusLogProbMetric: 4.9731 - val_loss: 5.1155 - val_MinusLogProbMetric: 5.1155 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 213/1000
2023-09-12 07:22:40.956 
Epoch 213/1000 
	 loss: 4.9732, MinusLogProbMetric: 4.9732, val_loss: 5.1142, val_MinusLogProbMetric: 5.1142

Epoch 213: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9732 - MinusLogProbMetric: 4.9732 - val_loss: 5.1142 - val_MinusLogProbMetric: 5.1142 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 214/1000
2023-09-12 07:22:52.331 
Epoch 214/1000 
	 loss: 4.9733, MinusLogProbMetric: 4.9733, val_loss: 5.1144, val_MinusLogProbMetric: 5.1144

Epoch 214: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9733 - MinusLogProbMetric: 4.9733 - val_loss: 5.1144 - val_MinusLogProbMetric: 5.1144 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 215/1000
2023-09-12 07:23:03.766 
Epoch 215/1000 
	 loss: 4.9741, MinusLogProbMetric: 4.9741, val_loss: 5.1172, val_MinusLogProbMetric: 5.1172

Epoch 215: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9741 - MinusLogProbMetric: 4.9741 - val_loss: 5.1172 - val_MinusLogProbMetric: 5.1172 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 216/1000
2023-09-12 07:23:15.137 
Epoch 216/1000 
	 loss: 4.9733, MinusLogProbMetric: 4.9733, val_loss: 5.1188, val_MinusLogProbMetric: 5.1188

Epoch 216: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9733 - MinusLogProbMetric: 4.9733 - val_loss: 5.1188 - val_MinusLogProbMetric: 5.1188 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 217/1000
2023-09-12 07:23:26.576 
Epoch 217/1000 
	 loss: 4.9726, MinusLogProbMetric: 4.9726, val_loss: 5.1160, val_MinusLogProbMetric: 5.1160

Epoch 217: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9726 - MinusLogProbMetric: 4.9726 - val_loss: 5.1160 - val_MinusLogProbMetric: 5.1160 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 218/1000
2023-09-12 07:23:38.003 
Epoch 218/1000 
	 loss: 4.9752, MinusLogProbMetric: 4.9752, val_loss: 5.1178, val_MinusLogProbMetric: 5.1178

Epoch 218: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9752 - MinusLogProbMetric: 4.9752 - val_loss: 5.1178 - val_MinusLogProbMetric: 5.1178 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 219/1000
2023-09-12 07:23:49.569 
Epoch 219/1000 
	 loss: 4.9718, MinusLogProbMetric: 4.9718, val_loss: 5.1131, val_MinusLogProbMetric: 5.1131

Epoch 219: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9718 - MinusLogProbMetric: 4.9718 - val_loss: 5.1131 - val_MinusLogProbMetric: 5.1131 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 220/1000
2023-09-12 07:24:01.116 
Epoch 220/1000 
	 loss: 4.9721, MinusLogProbMetric: 4.9721, val_loss: 5.1289, val_MinusLogProbMetric: 5.1289

Epoch 220: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9721 - MinusLogProbMetric: 4.9721 - val_loss: 5.1289 - val_MinusLogProbMetric: 5.1289 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 221/1000
2023-09-12 07:24:12.552 
Epoch 221/1000 
	 loss: 4.9733, MinusLogProbMetric: 4.9733, val_loss: 5.1163, val_MinusLogProbMetric: 5.1163

Epoch 221: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9733 - MinusLogProbMetric: 4.9733 - val_loss: 5.1163 - val_MinusLogProbMetric: 5.1163 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 222/1000
2023-09-12 07:24:24.003 
Epoch 222/1000 
	 loss: 4.9725, MinusLogProbMetric: 4.9725, val_loss: 5.1194, val_MinusLogProbMetric: 5.1194

Epoch 222: val_loss did not improve from 5.08919
196/196 - 11s - loss: 4.9725 - MinusLogProbMetric: 4.9725 - val_loss: 5.1194 - val_MinusLogProbMetric: 5.1194 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 223/1000
2023-09-12 07:24:35.546 
Epoch 223/1000 
	 loss: 4.9714, MinusLogProbMetric: 4.9714, val_loss: 5.1224, val_MinusLogProbMetric: 5.1224

Epoch 223: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9714 - MinusLogProbMetric: 4.9714 - val_loss: 5.1224 - val_MinusLogProbMetric: 5.1224 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 224/1000
2023-09-12 07:24:47.051 
Epoch 224/1000 
	 loss: 4.9728, MinusLogProbMetric: 4.9728, val_loss: 5.1173, val_MinusLogProbMetric: 5.1173

Epoch 224: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9728 - MinusLogProbMetric: 4.9728 - val_loss: 5.1173 - val_MinusLogProbMetric: 5.1173 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 225/1000
2023-09-12 07:24:58.698 
Epoch 225/1000 
	 loss: 4.9714, MinusLogProbMetric: 4.9714, val_loss: 5.1206, val_MinusLogProbMetric: 5.1206

Epoch 225: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9714 - MinusLogProbMetric: 4.9714 - val_loss: 5.1206 - val_MinusLogProbMetric: 5.1206 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 226/1000
2023-09-12 07:25:10.267 
Epoch 226/1000 
	 loss: 4.9722, MinusLogProbMetric: 4.9722, val_loss: 5.1148, val_MinusLogProbMetric: 5.1148

Epoch 226: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9722 - MinusLogProbMetric: 4.9722 - val_loss: 5.1148 - val_MinusLogProbMetric: 5.1148 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 227/1000
2023-09-12 07:25:21.826 
Epoch 227/1000 
	 loss: 4.9703, MinusLogProbMetric: 4.9703, val_loss: 5.1168, val_MinusLogProbMetric: 5.1168

Epoch 227: val_loss did not improve from 5.08919
196/196 - 12s - loss: 4.9703 - MinusLogProbMetric: 4.9703 - val_loss: 5.1168 - val_MinusLogProbMetric: 5.1168 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-12 07:25:33.390 
Epoch 228/1000 
	 loss: 4.9710, MinusLogProbMetric: 4.9710, val_loss: 5.1179, val_MinusLogProbMetric: 5.1179

Epoch 228: val_loss did not improve from 5.08919
Restoring model weights from the end of the best epoch: 128.
196/196 - 12s - loss: 4.9710 - MinusLogProbMetric: 4.9710 - val_loss: 5.1179 - val_MinusLogProbMetric: 5.1179 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 228: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 5.315009121084586 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.629379460006021 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.3248750229831785 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.9764070089440793 seconds.
Training succeeded with seed 0.
Model trained in 2633.58 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Metrics computed in 127.18 s.
Plots done in 32.91 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 160.09 s.
===========
Run 82/360 done in 2794.90 s.
===========

Directory ../../results/MsplineN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

===========
Generating train data for run 87.
===========
Train data generated in 0.28 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_87/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_87/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.831399  , 5.863554  , 0.1652866 , ..., 6.776286  , 2.0655468 ,
        1.4845017 ],
       [4.0864964 , 5.24693   , 0.13653305, ..., 5.762559  , 2.5860255 ,
        1.364856  ],
       [5.275347  , 8.040183  , 5.6235228 , ..., 9.369459  , 0.6142187 ,
        1.0642337 ],
       ...,
       [5.461225  , 8.116312  , 5.529141  , ..., 9.237533  , 1.256566  ,
        1.0620883 ],
       [4.5966773 , 5.3314133 , 0.2894929 , ..., 7.691963  , 2.0622973 ,
        1.1898649 ],
       [4.9526467 , 6.7362523 , 6.305528  , ..., 9.387884  , 1.0884995 ,
        0.8526704 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_87/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_87
self.data_kwargs: {'seed': 187}
self.x_data: [[ 4.812802    5.5024137   0.1852501  ...  6.472553    2.278431
   1.0939016 ]
 [ 5.542564    7.0347266   6.375047   ...  9.405323   -0.10398155
   0.7335531 ]
 [ 4.965488    6.398319    0.14414716 ...  5.6583366   2.1096616
   1.5241935 ]
 ...
 [ 4.4325466   6.3903317   0.21309651 ...  7.1345162   2.1785538
   1.3028526 ]
 [ 4.137084    6.680504    0.19241284 ...  7.049218    2.1201315
   1.4646225 ]
 [ 4.9299364   5.1759768   0.18408507 ...  7.8870034   1.6553737
   1.2631798 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_34 (InputLayer)       [(None, 16)]              0         
                                                                 
 log_prob_layer_11 (LogProbL  (None,)                  214880    
 ayer)                                                           
                                                                 
=================================================================
Total params: 214,880
Trainable params: 214,880
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_11/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_11'")
self.model: <keras.engine.functional.Functional object at 0x7fc5c12be500>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc5c10f1030>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc5c10f1030>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc5c10f1900>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc5c10f25c0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc5c10f2b30>, <keras.callbacks.ModelCheckpoint object at 0x7fc5c10f2bf0>, <keras.callbacks.EarlyStopping object at 0x7fc5c10f2e60>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc5c10f2e90>, <keras.callbacks.TerminateOnNaN object at 0x7fc5c10f2ad0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.831399  , 5.863554  , 0.1652866 , ..., 6.776286  , 2.0655468 ,
        1.4845017 ],
       [4.0864964 , 5.24693   , 0.13653305, ..., 5.762559  , 2.5860255 ,
        1.364856  ],
       [5.275347  , 8.040183  , 5.6235228 , ..., 9.369459  , 0.6142187 ,
        1.0642337 ],
       ...,
       [5.461225  , 8.116312  , 5.529141  , ..., 9.237533  , 1.256566  ,
        1.0620883 ],
       [4.5966773 , 5.3314133 , 0.2894929 , ..., 7.691963  , 2.0622973 ,
        1.1898649 ],
       [4.9526467 , 6.7362523 , 6.305528  , ..., 9.387884  , 1.0884995 ,
        0.8526704 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_87/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 87/360 with hyperparameters:
timestamp = 2023-09-12 07:28:14.950178
ndims = 16
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 214880
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.812802   5.5024137  0.1852501  6.0790067  6.7126174  6.365971
 10.504365   6.889143   4.1779566  4.127769   7.026523   1.1252476
  6.6392775  6.472553   2.278431   1.0939016]
Epoch 1/1000
2023-09-12 07:28:45.825 
Epoch 1/1000 
	 loss: 24.0093, MinusLogProbMetric: 24.0093, val_loss: 6.7689, val_MinusLogProbMetric: 6.7689

Epoch 1: val_loss improved from inf to 6.76892, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 31s - loss: 24.0093 - MinusLogProbMetric: 24.0093 - val_loss: 6.7689 - val_MinusLogProbMetric: 6.7689 - lr: 0.0010 - 31s/epoch - 158ms/step
Epoch 2/1000
2023-09-12 07:28:57.610 
Epoch 2/1000 
	 loss: 6.1036, MinusLogProbMetric: 6.1036, val_loss: 5.9319, val_MinusLogProbMetric: 5.9319

Epoch 2: val_loss improved from 6.76892 to 5.93193, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 6.1036 - MinusLogProbMetric: 6.1036 - val_loss: 5.9319 - val_MinusLogProbMetric: 5.9319 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 3/1000
2023-09-12 07:29:09.473 
Epoch 3/1000 
	 loss: 5.6473, MinusLogProbMetric: 5.6473, val_loss: 5.6508, val_MinusLogProbMetric: 5.6508

Epoch 3: val_loss improved from 5.93193 to 5.65081, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.6473 - MinusLogProbMetric: 5.6473 - val_loss: 5.6508 - val_MinusLogProbMetric: 5.6508 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 4/1000
2023-09-12 07:29:21.306 
Epoch 4/1000 
	 loss: 5.4914, MinusLogProbMetric: 5.4914, val_loss: 5.4569, val_MinusLogProbMetric: 5.4569

Epoch 4: val_loss improved from 5.65081 to 5.45690, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.4914 - MinusLogProbMetric: 5.4914 - val_loss: 5.4569 - val_MinusLogProbMetric: 5.4569 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-12 07:29:33.022 
Epoch 5/1000 
	 loss: 5.3881, MinusLogProbMetric: 5.3881, val_loss: 5.3614, val_MinusLogProbMetric: 5.3614

Epoch 5: val_loss improved from 5.45690 to 5.36143, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.3881 - MinusLogProbMetric: 5.3881 - val_loss: 5.3614 - val_MinusLogProbMetric: 5.3614 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 6/1000
2023-09-12 07:29:44.856 
Epoch 6/1000 
	 loss: 5.3438, MinusLogProbMetric: 5.3438, val_loss: 5.6483, val_MinusLogProbMetric: 5.6483

Epoch 6: val_loss did not improve from 5.36143
196/196 - 12s - loss: 5.3438 - MinusLogProbMetric: 5.3438 - val_loss: 5.6483 - val_MinusLogProbMetric: 5.6483 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-12 07:29:56.552 
Epoch 7/1000 
	 loss: 5.3179, MinusLogProbMetric: 5.3179, val_loss: 5.3040, val_MinusLogProbMetric: 5.3040

Epoch 7: val_loss improved from 5.36143 to 5.30396, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.3179 - MinusLogProbMetric: 5.3179 - val_loss: 5.3040 - val_MinusLogProbMetric: 5.3040 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 8/1000
2023-09-12 07:30:08.374 
Epoch 8/1000 
	 loss: 5.2983, MinusLogProbMetric: 5.2983, val_loss: 5.2254, val_MinusLogProbMetric: 5.2254

Epoch 8: val_loss improved from 5.30396 to 5.22538, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.2983 - MinusLogProbMetric: 5.2983 - val_loss: 5.2254 - val_MinusLogProbMetric: 5.2254 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-12 07:30:20.123 
Epoch 9/1000 
	 loss: 5.2641, MinusLogProbMetric: 5.2641, val_loss: 5.3403, val_MinusLogProbMetric: 5.3403

Epoch 9: val_loss did not improve from 5.22538
196/196 - 12s - loss: 5.2641 - MinusLogProbMetric: 5.2641 - val_loss: 5.3403 - val_MinusLogProbMetric: 5.3403 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 10/1000
2023-09-12 07:30:31.823 
Epoch 10/1000 
	 loss: 5.2473, MinusLogProbMetric: 5.2473, val_loss: 5.2494, val_MinusLogProbMetric: 5.2494

Epoch 10: val_loss did not improve from 5.22538
196/196 - 12s - loss: 5.2473 - MinusLogProbMetric: 5.2473 - val_loss: 5.2494 - val_MinusLogProbMetric: 5.2494 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-12 07:30:43.506 
Epoch 11/1000 
	 loss: 5.2468, MinusLogProbMetric: 5.2468, val_loss: 5.2873, val_MinusLogProbMetric: 5.2873

Epoch 11: val_loss did not improve from 5.22538
196/196 - 12s - loss: 5.2468 - MinusLogProbMetric: 5.2468 - val_loss: 5.2873 - val_MinusLogProbMetric: 5.2873 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-12 07:30:55.269 
Epoch 12/1000 
	 loss: 5.2411, MinusLogProbMetric: 5.2411, val_loss: 5.2267, val_MinusLogProbMetric: 5.2267

Epoch 12: val_loss did not improve from 5.22538
196/196 - 12s - loss: 5.2411 - MinusLogProbMetric: 5.2411 - val_loss: 5.2267 - val_MinusLogProbMetric: 5.2267 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-12 07:31:06.902 
Epoch 13/1000 
	 loss: 5.2314, MinusLogProbMetric: 5.2314, val_loss: 5.2418, val_MinusLogProbMetric: 5.2418

Epoch 13: val_loss did not improve from 5.22538
196/196 - 12s - loss: 5.2314 - MinusLogProbMetric: 5.2314 - val_loss: 5.2418 - val_MinusLogProbMetric: 5.2418 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 14/1000
2023-09-12 07:31:18.513 
Epoch 14/1000 
	 loss: 5.2199, MinusLogProbMetric: 5.2199, val_loss: 5.2957, val_MinusLogProbMetric: 5.2957

Epoch 14: val_loss did not improve from 5.22538
196/196 - 12s - loss: 5.2199 - MinusLogProbMetric: 5.2199 - val_loss: 5.2957 - val_MinusLogProbMetric: 5.2957 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-12 07:31:30.222 
Epoch 15/1000 
	 loss: 5.2205, MinusLogProbMetric: 5.2205, val_loss: 5.2223, val_MinusLogProbMetric: 5.2223

Epoch 15: val_loss improved from 5.22538 to 5.22232, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.2205 - MinusLogProbMetric: 5.2205 - val_loss: 5.2223 - val_MinusLogProbMetric: 5.2223 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-12 07:31:41.969 
Epoch 16/1000 
	 loss: 5.1919, MinusLogProbMetric: 5.1919, val_loss: 5.2016, val_MinusLogProbMetric: 5.2016

Epoch 16: val_loss improved from 5.22232 to 5.20160, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.1919 - MinusLogProbMetric: 5.1919 - val_loss: 5.2016 - val_MinusLogProbMetric: 5.2016 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 07:31:53.734 
Epoch 17/1000 
	 loss: 5.2007, MinusLogProbMetric: 5.2007, val_loss: 5.2174, val_MinusLogProbMetric: 5.2174

Epoch 17: val_loss did not improve from 5.20160
196/196 - 12s - loss: 5.2007 - MinusLogProbMetric: 5.2007 - val_loss: 5.2174 - val_MinusLogProbMetric: 5.2174 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 18/1000
2023-09-12 07:32:05.464 
Epoch 18/1000 
	 loss: 5.1881, MinusLogProbMetric: 5.1881, val_loss: 5.2348, val_MinusLogProbMetric: 5.2348

Epoch 18: val_loss did not improve from 5.20160
196/196 - 12s - loss: 5.1881 - MinusLogProbMetric: 5.1881 - val_loss: 5.2348 - val_MinusLogProbMetric: 5.2348 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 07:32:17.090 
Epoch 19/1000 
	 loss: 5.1877, MinusLogProbMetric: 5.1877, val_loss: 5.1477, val_MinusLogProbMetric: 5.1477

Epoch 19: val_loss improved from 5.20160 to 5.14771, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.1877 - MinusLogProbMetric: 5.1877 - val_loss: 5.1477 - val_MinusLogProbMetric: 5.1477 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-12 07:32:28.807 
Epoch 20/1000 
	 loss: 5.1927, MinusLogProbMetric: 5.1927, val_loss: 5.2327, val_MinusLogProbMetric: 5.2327

Epoch 20: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1927 - MinusLogProbMetric: 5.1927 - val_loss: 5.2327 - val_MinusLogProbMetric: 5.2327 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 07:32:40.444 
Epoch 21/1000 
	 loss: 5.1883, MinusLogProbMetric: 5.1883, val_loss: 5.2493, val_MinusLogProbMetric: 5.2493

Epoch 21: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1883 - MinusLogProbMetric: 5.1883 - val_loss: 5.2493 - val_MinusLogProbMetric: 5.2493 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 07:32:52.110 
Epoch 22/1000 
	 loss: 5.1709, MinusLogProbMetric: 5.1709, val_loss: 5.1742, val_MinusLogProbMetric: 5.1742

Epoch 22: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1709 - MinusLogProbMetric: 5.1709 - val_loss: 5.1742 - val_MinusLogProbMetric: 5.1742 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 07:33:03.850 
Epoch 23/1000 
	 loss: 5.1681, MinusLogProbMetric: 5.1681, val_loss: 5.1852, val_MinusLogProbMetric: 5.1852

Epoch 23: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1681 - MinusLogProbMetric: 5.1681 - val_loss: 5.1852 - val_MinusLogProbMetric: 5.1852 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-12 07:33:15.512 
Epoch 24/1000 
	 loss: 5.1683, MinusLogProbMetric: 5.1683, val_loss: 5.2077, val_MinusLogProbMetric: 5.2077

Epoch 24: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1683 - MinusLogProbMetric: 5.1683 - val_loss: 5.2077 - val_MinusLogProbMetric: 5.2077 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 25/1000
2023-09-12 07:33:27.201 
Epoch 25/1000 
	 loss: 5.1668, MinusLogProbMetric: 5.1668, val_loss: 5.1631, val_MinusLogProbMetric: 5.1631

Epoch 25: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1668 - MinusLogProbMetric: 5.1668 - val_loss: 5.1631 - val_MinusLogProbMetric: 5.1631 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 07:33:38.918 
Epoch 26/1000 
	 loss: 5.1602, MinusLogProbMetric: 5.1602, val_loss: 5.2112, val_MinusLogProbMetric: 5.2112

Epoch 26: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1602 - MinusLogProbMetric: 5.1602 - val_loss: 5.2112 - val_MinusLogProbMetric: 5.2112 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 07:33:50.518 
Epoch 27/1000 
	 loss: 5.1624, MinusLogProbMetric: 5.1624, val_loss: 5.1726, val_MinusLogProbMetric: 5.1726

Epoch 27: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1624 - MinusLogProbMetric: 5.1624 - val_loss: 5.1726 - val_MinusLogProbMetric: 5.1726 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 28/1000
2023-09-12 07:34:02.149 
Epoch 28/1000 
	 loss: 5.1610, MinusLogProbMetric: 5.1610, val_loss: 5.2081, val_MinusLogProbMetric: 5.2081

Epoch 28: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1610 - MinusLogProbMetric: 5.1610 - val_loss: 5.2081 - val_MinusLogProbMetric: 5.2081 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 07:34:13.869 
Epoch 29/1000 
	 loss: 5.1539, MinusLogProbMetric: 5.1539, val_loss: 5.2037, val_MinusLogProbMetric: 5.2037

Epoch 29: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1539 - MinusLogProbMetric: 5.1539 - val_loss: 5.2037 - val_MinusLogProbMetric: 5.2037 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 30/1000
2023-09-12 07:34:25.478 
Epoch 30/1000 
	 loss: 5.1546, MinusLogProbMetric: 5.1546, val_loss: 5.2317, val_MinusLogProbMetric: 5.2317

Epoch 30: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1546 - MinusLogProbMetric: 5.1546 - val_loss: 5.2317 - val_MinusLogProbMetric: 5.2317 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 31/1000
2023-09-12 07:34:37.156 
Epoch 31/1000 
	 loss: 5.1480, MinusLogProbMetric: 5.1480, val_loss: 5.1985, val_MinusLogProbMetric: 5.1985

Epoch 31: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1480 - MinusLogProbMetric: 5.1480 - val_loss: 5.1985 - val_MinusLogProbMetric: 5.1985 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-12 07:34:48.877 
Epoch 32/1000 
	 loss: 5.1544, MinusLogProbMetric: 5.1544, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 32: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1544 - MinusLogProbMetric: 5.1544 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-12 07:35:00.532 
Epoch 33/1000 
	 loss: 5.1480, MinusLogProbMetric: 5.1480, val_loss: 5.1517, val_MinusLogProbMetric: 5.1517

Epoch 33: val_loss did not improve from 5.14771
196/196 - 12s - loss: 5.1480 - MinusLogProbMetric: 5.1480 - val_loss: 5.1517 - val_MinusLogProbMetric: 5.1517 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 34/1000
2023-09-12 07:35:12.235 
Epoch 34/1000 
	 loss: 5.1441, MinusLogProbMetric: 5.1441, val_loss: 5.1330, val_MinusLogProbMetric: 5.1330

Epoch 34: val_loss improved from 5.14771 to 5.13304, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.1441 - MinusLogProbMetric: 5.1441 - val_loss: 5.1330 - val_MinusLogProbMetric: 5.1330 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-12 07:35:24.038 
Epoch 35/1000 
	 loss: 5.1375, MinusLogProbMetric: 5.1375, val_loss: 5.1413, val_MinusLogProbMetric: 5.1413

Epoch 35: val_loss did not improve from 5.13304
196/196 - 12s - loss: 5.1375 - MinusLogProbMetric: 5.1375 - val_loss: 5.1413 - val_MinusLogProbMetric: 5.1413 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-12 07:35:35.717 
Epoch 36/1000 
	 loss: 5.1371, MinusLogProbMetric: 5.1371, val_loss: 5.1705, val_MinusLogProbMetric: 5.1705

Epoch 36: val_loss did not improve from 5.13304
196/196 - 12s - loss: 5.1371 - MinusLogProbMetric: 5.1371 - val_loss: 5.1705 - val_MinusLogProbMetric: 5.1705 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 07:35:47.116 
Epoch 37/1000 
	 loss: 5.1385, MinusLogProbMetric: 5.1385, val_loss: 5.2054, val_MinusLogProbMetric: 5.2054

Epoch 37: val_loss did not improve from 5.13304
196/196 - 11s - loss: 5.1385 - MinusLogProbMetric: 5.1385 - val_loss: 5.2054 - val_MinusLogProbMetric: 5.2054 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 38/1000
2023-09-12 07:35:58.557 
Epoch 38/1000 
	 loss: 5.1465, MinusLogProbMetric: 5.1465, val_loss: 5.1357, val_MinusLogProbMetric: 5.1357

Epoch 38: val_loss did not improve from 5.13304
196/196 - 11s - loss: 5.1465 - MinusLogProbMetric: 5.1465 - val_loss: 5.1357 - val_MinusLogProbMetric: 5.1357 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 39/1000
2023-09-12 07:36:10.010 
Epoch 39/1000 
	 loss: 5.1329, MinusLogProbMetric: 5.1329, val_loss: 5.1734, val_MinusLogProbMetric: 5.1734

Epoch 39: val_loss did not improve from 5.13304
196/196 - 11s - loss: 5.1329 - MinusLogProbMetric: 5.1329 - val_loss: 5.1734 - val_MinusLogProbMetric: 5.1734 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 40/1000
2023-09-12 07:36:21.356 
Epoch 40/1000 
	 loss: 5.1411, MinusLogProbMetric: 5.1411, val_loss: 5.1319, val_MinusLogProbMetric: 5.1319

Epoch 40: val_loss improved from 5.13304 to 5.13193, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 11s - loss: 5.1411 - MinusLogProbMetric: 5.1411 - val_loss: 5.1319 - val_MinusLogProbMetric: 5.1319 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 41/1000
2023-09-12 07:36:32.910 
Epoch 41/1000 
	 loss: 5.1356, MinusLogProbMetric: 5.1356, val_loss: 5.1815, val_MinusLogProbMetric: 5.1815

Epoch 41: val_loss did not improve from 5.13193
196/196 - 11s - loss: 5.1356 - MinusLogProbMetric: 5.1356 - val_loss: 5.1815 - val_MinusLogProbMetric: 5.1815 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 42/1000
2023-09-12 07:36:44.325 
Epoch 42/1000 
	 loss: 5.1310, MinusLogProbMetric: 5.1310, val_loss: 5.1432, val_MinusLogProbMetric: 5.1432

Epoch 42: val_loss did not improve from 5.13193
196/196 - 11s - loss: 5.1310 - MinusLogProbMetric: 5.1310 - val_loss: 5.1432 - val_MinusLogProbMetric: 5.1432 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 43/1000
2023-09-12 07:36:55.802 
Epoch 43/1000 
	 loss: 5.1315, MinusLogProbMetric: 5.1315, val_loss: 5.1345, val_MinusLogProbMetric: 5.1345

Epoch 43: val_loss did not improve from 5.13193
196/196 - 11s - loss: 5.1315 - MinusLogProbMetric: 5.1315 - val_loss: 5.1345 - val_MinusLogProbMetric: 5.1345 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 44/1000
2023-09-12 07:37:06.169 
Epoch 44/1000 
	 loss: 5.1309, MinusLogProbMetric: 5.1309, val_loss: 5.1193, val_MinusLogProbMetric: 5.1193

Epoch 44: val_loss improved from 5.13193 to 5.11928, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 10s - loss: 5.1309 - MinusLogProbMetric: 5.1309 - val_loss: 5.1193 - val_MinusLogProbMetric: 5.1193 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 45/1000
2023-09-12 07:37:17.699 
Epoch 45/1000 
	 loss: 5.1363, MinusLogProbMetric: 5.1363, val_loss: 5.1341, val_MinusLogProbMetric: 5.1341

Epoch 45: val_loss did not improve from 5.11928
196/196 - 11s - loss: 5.1363 - MinusLogProbMetric: 5.1363 - val_loss: 5.1341 - val_MinusLogProbMetric: 5.1341 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 46/1000
2023-09-12 07:37:29.196 
Epoch 46/1000 
	 loss: 5.1287, MinusLogProbMetric: 5.1287, val_loss: 5.2112, val_MinusLogProbMetric: 5.2112

Epoch 46: val_loss did not improve from 5.11928
196/196 - 11s - loss: 5.1287 - MinusLogProbMetric: 5.1287 - val_loss: 5.2112 - val_MinusLogProbMetric: 5.2112 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 07:37:40.524 
Epoch 47/1000 
	 loss: 5.1316, MinusLogProbMetric: 5.1316, val_loss: 5.2038, val_MinusLogProbMetric: 5.2038

Epoch 47: val_loss did not improve from 5.11928
196/196 - 11s - loss: 5.1316 - MinusLogProbMetric: 5.1316 - val_loss: 5.2038 - val_MinusLogProbMetric: 5.2038 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 48/1000
2023-09-12 07:37:52.044 
Epoch 48/1000 
	 loss: 5.1237, MinusLogProbMetric: 5.1237, val_loss: 5.1308, val_MinusLogProbMetric: 5.1308

Epoch 48: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1237 - MinusLogProbMetric: 5.1237 - val_loss: 5.1308 - val_MinusLogProbMetric: 5.1308 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 49/1000
2023-09-12 07:38:03.637 
Epoch 49/1000 
	 loss: 5.1243, MinusLogProbMetric: 5.1243, val_loss: 5.1629, val_MinusLogProbMetric: 5.1629

Epoch 49: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1243 - MinusLogProbMetric: 5.1243 - val_loss: 5.1629 - val_MinusLogProbMetric: 5.1629 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-12 07:38:15.260 
Epoch 50/1000 
	 loss: 5.1254, MinusLogProbMetric: 5.1254, val_loss: 5.1602, val_MinusLogProbMetric: 5.1602

Epoch 50: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1254 - MinusLogProbMetric: 5.1254 - val_loss: 5.1602 - val_MinusLogProbMetric: 5.1602 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 51/1000
2023-09-12 07:38:26.989 
Epoch 51/1000 
	 loss: 5.1199, MinusLogProbMetric: 5.1199, val_loss: 5.1514, val_MinusLogProbMetric: 5.1514

Epoch 51: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1199 - MinusLogProbMetric: 5.1199 - val_loss: 5.1514 - val_MinusLogProbMetric: 5.1514 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-12 07:38:38.625 
Epoch 52/1000 
	 loss: 5.1224, MinusLogProbMetric: 5.1224, val_loss: 5.1795, val_MinusLogProbMetric: 5.1795

Epoch 52: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1224 - MinusLogProbMetric: 5.1224 - val_loss: 5.1795 - val_MinusLogProbMetric: 5.1795 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 53/1000
2023-09-12 07:38:50.292 
Epoch 53/1000 
	 loss: 5.1206, MinusLogProbMetric: 5.1206, val_loss: 5.1276, val_MinusLogProbMetric: 5.1276

Epoch 53: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1206 - MinusLogProbMetric: 5.1206 - val_loss: 5.1276 - val_MinusLogProbMetric: 5.1276 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-12 07:39:01.959 
Epoch 54/1000 
	 loss: 5.1222, MinusLogProbMetric: 5.1222, val_loss: 5.1440, val_MinusLogProbMetric: 5.1440

Epoch 54: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1222 - MinusLogProbMetric: 5.1222 - val_loss: 5.1440 - val_MinusLogProbMetric: 5.1440 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 55/1000
2023-09-12 07:39:13.624 
Epoch 55/1000 
	 loss: 5.1141, MinusLogProbMetric: 5.1141, val_loss: 5.1335, val_MinusLogProbMetric: 5.1335

Epoch 55: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1141 - MinusLogProbMetric: 5.1141 - val_loss: 5.1335 - val_MinusLogProbMetric: 5.1335 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-12 07:39:25.292 
Epoch 56/1000 
	 loss: 5.1147, MinusLogProbMetric: 5.1147, val_loss: 5.1717, val_MinusLogProbMetric: 5.1717

Epoch 56: val_loss did not improve from 5.11928
196/196 - 12s - loss: 5.1147 - MinusLogProbMetric: 5.1147 - val_loss: 5.1717 - val_MinusLogProbMetric: 5.1717 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-12 07:39:37.008 
Epoch 57/1000 
	 loss: 5.1215, MinusLogProbMetric: 5.1215, val_loss: 5.1160, val_MinusLogProbMetric: 5.1160

Epoch 57: val_loss improved from 5.11928 to 5.11603, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.1215 - MinusLogProbMetric: 5.1215 - val_loss: 5.1160 - val_MinusLogProbMetric: 5.1160 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-12 07:39:48.815 
Epoch 58/1000 
	 loss: 5.1124, MinusLogProbMetric: 5.1124, val_loss: 5.1317, val_MinusLogProbMetric: 5.1317

Epoch 58: val_loss did not improve from 5.11603
196/196 - 12s - loss: 5.1124 - MinusLogProbMetric: 5.1124 - val_loss: 5.1317 - val_MinusLogProbMetric: 5.1317 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-12 07:40:00.376 
Epoch 59/1000 
	 loss: 5.1107, MinusLogProbMetric: 5.1107, val_loss: 5.1470, val_MinusLogProbMetric: 5.1470

Epoch 59: val_loss did not improve from 5.11603
196/196 - 12s - loss: 5.1107 - MinusLogProbMetric: 5.1107 - val_loss: 5.1470 - val_MinusLogProbMetric: 5.1470 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 60/1000
2023-09-12 07:40:12.001 
Epoch 60/1000 
	 loss: 5.1198, MinusLogProbMetric: 5.1198, val_loss: 5.1366, val_MinusLogProbMetric: 5.1366

Epoch 60: val_loss did not improve from 5.11603
196/196 - 12s - loss: 5.1198 - MinusLogProbMetric: 5.1198 - val_loss: 5.1366 - val_MinusLogProbMetric: 5.1366 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 61/1000
2023-09-12 07:40:23.704 
Epoch 61/1000 
	 loss: 5.1106, MinusLogProbMetric: 5.1106, val_loss: 5.1331, val_MinusLogProbMetric: 5.1331

Epoch 61: val_loss did not improve from 5.11603
196/196 - 12s - loss: 5.1106 - MinusLogProbMetric: 5.1106 - val_loss: 5.1331 - val_MinusLogProbMetric: 5.1331 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-12 07:40:35.427 
Epoch 62/1000 
	 loss: 5.1145, MinusLogProbMetric: 5.1145, val_loss: 5.1361, val_MinusLogProbMetric: 5.1361

Epoch 62: val_loss did not improve from 5.11603
196/196 - 12s - loss: 5.1145 - MinusLogProbMetric: 5.1145 - val_loss: 5.1361 - val_MinusLogProbMetric: 5.1361 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-12 07:40:46.944 
Epoch 63/1000 
	 loss: 5.1096, MinusLogProbMetric: 5.1096, val_loss: 5.1697, val_MinusLogProbMetric: 5.1697

Epoch 63: val_loss did not improve from 5.11603
196/196 - 12s - loss: 5.1096 - MinusLogProbMetric: 5.1096 - val_loss: 5.1697 - val_MinusLogProbMetric: 5.1697 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 64/1000
2023-09-12 07:40:58.635 
Epoch 64/1000 
	 loss: 5.1120, MinusLogProbMetric: 5.1120, val_loss: 5.1300, val_MinusLogProbMetric: 5.1300

Epoch 64: val_loss did not improve from 5.11603
196/196 - 12s - loss: 5.1120 - MinusLogProbMetric: 5.1120 - val_loss: 5.1300 - val_MinusLogProbMetric: 5.1300 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-12 07:41:10.218 
Epoch 65/1000 
	 loss: 5.1083, MinusLogProbMetric: 5.1083, val_loss: 5.1129, val_MinusLogProbMetric: 5.1129

Epoch 65: val_loss improved from 5.11603 to 5.11294, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.1083 - MinusLogProbMetric: 5.1083 - val_loss: 5.1129 - val_MinusLogProbMetric: 5.1129 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-12 07:41:22.010 
Epoch 66/1000 
	 loss: 5.1008, MinusLogProbMetric: 5.1008, val_loss: 5.1081, val_MinusLogProbMetric: 5.1081

Epoch 66: val_loss improved from 5.11294 to 5.10810, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.1008 - MinusLogProbMetric: 5.1008 - val_loss: 5.1081 - val_MinusLogProbMetric: 5.1081 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-12 07:41:33.868 
Epoch 67/1000 
	 loss: 5.1156, MinusLogProbMetric: 5.1156, val_loss: 5.1625, val_MinusLogProbMetric: 5.1625

Epoch 67: val_loss did not improve from 5.10810
196/196 - 12s - loss: 5.1156 - MinusLogProbMetric: 5.1156 - val_loss: 5.1625 - val_MinusLogProbMetric: 5.1625 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-12 07:41:45.510 
Epoch 68/1000 
	 loss: 5.1042, MinusLogProbMetric: 5.1042, val_loss: 5.1655, val_MinusLogProbMetric: 5.1655

Epoch 68: val_loss did not improve from 5.10810
196/196 - 12s - loss: 5.1042 - MinusLogProbMetric: 5.1042 - val_loss: 5.1655 - val_MinusLogProbMetric: 5.1655 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-12 07:41:57.226 
Epoch 69/1000 
	 loss: 5.1094, MinusLogProbMetric: 5.1094, val_loss: 5.1003, val_MinusLogProbMetric: 5.1003

Epoch 69: val_loss improved from 5.10810 to 5.10028, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.1094 - MinusLogProbMetric: 5.1094 - val_loss: 5.1003 - val_MinusLogProbMetric: 5.1003 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 07:42:08.979 
Epoch 70/1000 
	 loss: 5.1041, MinusLogProbMetric: 5.1041, val_loss: 5.1097, val_MinusLogProbMetric: 5.1097

Epoch 70: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1041 - MinusLogProbMetric: 5.1041 - val_loss: 5.1097 - val_MinusLogProbMetric: 5.1097 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 71/1000
2023-09-12 07:42:20.682 
Epoch 71/1000 
	 loss: 5.1112, MinusLogProbMetric: 5.1112, val_loss: 5.1785, val_MinusLogProbMetric: 5.1785

Epoch 71: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1112 - MinusLogProbMetric: 5.1112 - val_loss: 5.1785 - val_MinusLogProbMetric: 5.1785 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-12 07:42:32.385 
Epoch 72/1000 
	 loss: 5.1095, MinusLogProbMetric: 5.1095, val_loss: 5.1055, val_MinusLogProbMetric: 5.1055

Epoch 72: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1095 - MinusLogProbMetric: 5.1095 - val_loss: 5.1055 - val_MinusLogProbMetric: 5.1055 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-12 07:42:44.040 
Epoch 73/1000 
	 loss: 5.1017, MinusLogProbMetric: 5.1017, val_loss: 5.1607, val_MinusLogProbMetric: 5.1607

Epoch 73: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1017 - MinusLogProbMetric: 5.1017 - val_loss: 5.1607 - val_MinusLogProbMetric: 5.1607 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 07:42:55.779 
Epoch 74/1000 
	 loss: 5.1044, MinusLogProbMetric: 5.1044, val_loss: 5.1158, val_MinusLogProbMetric: 5.1158

Epoch 74: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1044 - MinusLogProbMetric: 5.1044 - val_loss: 5.1158 - val_MinusLogProbMetric: 5.1158 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-12 07:43:07.390 
Epoch 75/1000 
	 loss: 5.1039, MinusLogProbMetric: 5.1039, val_loss: 5.1611, val_MinusLogProbMetric: 5.1611

Epoch 75: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1039 - MinusLogProbMetric: 5.1039 - val_loss: 5.1611 - val_MinusLogProbMetric: 5.1611 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 76/1000
2023-09-12 07:43:19.045 
Epoch 76/1000 
	 loss: 5.1089, MinusLogProbMetric: 5.1089, val_loss: 5.1335, val_MinusLogProbMetric: 5.1335

Epoch 76: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1089 - MinusLogProbMetric: 5.1089 - val_loss: 5.1335 - val_MinusLogProbMetric: 5.1335 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 77/1000
2023-09-12 07:43:30.592 
Epoch 77/1000 
	 loss: 5.1097, MinusLogProbMetric: 5.1097, val_loss: 5.1153, val_MinusLogProbMetric: 5.1153

Epoch 77: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1097 - MinusLogProbMetric: 5.1097 - val_loss: 5.1153 - val_MinusLogProbMetric: 5.1153 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 78/1000
2023-09-12 07:43:42.179 
Epoch 78/1000 
	 loss: 5.1043, MinusLogProbMetric: 5.1043, val_loss: 5.1202, val_MinusLogProbMetric: 5.1202

Epoch 78: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1043 - MinusLogProbMetric: 5.1043 - val_loss: 5.1202 - val_MinusLogProbMetric: 5.1202 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 79/1000
2023-09-12 07:43:53.886 
Epoch 79/1000 
	 loss: 5.1014, MinusLogProbMetric: 5.1014, val_loss: 5.1348, val_MinusLogProbMetric: 5.1348

Epoch 79: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1014 - MinusLogProbMetric: 5.1014 - val_loss: 5.1348 - val_MinusLogProbMetric: 5.1348 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 07:44:05.559 
Epoch 80/1000 
	 loss: 5.1064, MinusLogProbMetric: 5.1064, val_loss: 5.1121, val_MinusLogProbMetric: 5.1121

Epoch 80: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1064 - MinusLogProbMetric: 5.1064 - val_loss: 5.1121 - val_MinusLogProbMetric: 5.1121 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 81/1000
2023-09-12 07:44:17.302 
Epoch 81/1000 
	 loss: 5.1024, MinusLogProbMetric: 5.1024, val_loss: 5.1355, val_MinusLogProbMetric: 5.1355

Epoch 81: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1024 - MinusLogProbMetric: 5.1024 - val_loss: 5.1355 - val_MinusLogProbMetric: 5.1355 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 82/1000
2023-09-12 07:44:29.005 
Epoch 82/1000 
	 loss: 5.1003, MinusLogProbMetric: 5.1003, val_loss: 5.1446, val_MinusLogProbMetric: 5.1446

Epoch 82: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1003 - MinusLogProbMetric: 5.1003 - val_loss: 5.1446 - val_MinusLogProbMetric: 5.1446 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-12 07:44:40.753 
Epoch 83/1000 
	 loss: 5.0945, MinusLogProbMetric: 5.0945, val_loss: 5.1320, val_MinusLogProbMetric: 5.1320

Epoch 83: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0945 - MinusLogProbMetric: 5.0945 - val_loss: 5.1320 - val_MinusLogProbMetric: 5.1320 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 84/1000
2023-09-12 07:44:52.285 
Epoch 84/1000 
	 loss: 5.0981, MinusLogProbMetric: 5.0981, val_loss: 5.1208, val_MinusLogProbMetric: 5.1208

Epoch 84: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0981 - MinusLogProbMetric: 5.0981 - val_loss: 5.1208 - val_MinusLogProbMetric: 5.1208 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 85/1000
2023-09-12 07:45:03.860 
Epoch 85/1000 
	 loss: 5.0973, MinusLogProbMetric: 5.0973, val_loss: 5.1168, val_MinusLogProbMetric: 5.1168

Epoch 85: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0973 - MinusLogProbMetric: 5.0973 - val_loss: 5.1168 - val_MinusLogProbMetric: 5.1168 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-12 07:45:15.461 
Epoch 86/1000 
	 loss: 5.1032, MinusLogProbMetric: 5.1032, val_loss: 5.1179, val_MinusLogProbMetric: 5.1179

Epoch 86: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.1032 - MinusLogProbMetric: 5.1032 - val_loss: 5.1179 - val_MinusLogProbMetric: 5.1179 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-12 07:45:27.206 
Epoch 87/1000 
	 loss: 5.0928, MinusLogProbMetric: 5.0928, val_loss: 5.1183, val_MinusLogProbMetric: 5.1183

Epoch 87: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0928 - MinusLogProbMetric: 5.0928 - val_loss: 5.1183 - val_MinusLogProbMetric: 5.1183 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 88/1000
2023-09-12 07:45:38.833 
Epoch 88/1000 
	 loss: 5.0958, MinusLogProbMetric: 5.0958, val_loss: 5.1138, val_MinusLogProbMetric: 5.1138

Epoch 88: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0958 - MinusLogProbMetric: 5.0958 - val_loss: 5.1138 - val_MinusLogProbMetric: 5.1138 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-12 07:45:50.534 
Epoch 89/1000 
	 loss: 5.0912, MinusLogProbMetric: 5.0912, val_loss: 5.1131, val_MinusLogProbMetric: 5.1131

Epoch 89: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0912 - MinusLogProbMetric: 5.0912 - val_loss: 5.1131 - val_MinusLogProbMetric: 5.1131 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-12 07:46:02.193 
Epoch 90/1000 
	 loss: 5.0958, MinusLogProbMetric: 5.0958, val_loss: 5.1280, val_MinusLogProbMetric: 5.1280

Epoch 90: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0958 - MinusLogProbMetric: 5.0958 - val_loss: 5.1280 - val_MinusLogProbMetric: 5.1280 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 91/1000
2023-09-12 07:46:13.915 
Epoch 91/1000 
	 loss: 5.0915, MinusLogProbMetric: 5.0915, val_loss: 5.1167, val_MinusLogProbMetric: 5.1167

Epoch 91: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0915 - MinusLogProbMetric: 5.0915 - val_loss: 5.1167 - val_MinusLogProbMetric: 5.1167 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 07:46:25.639 
Epoch 92/1000 
	 loss: 5.0904, MinusLogProbMetric: 5.0904, val_loss: 5.1110, val_MinusLogProbMetric: 5.1110

Epoch 92: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0904 - MinusLogProbMetric: 5.0904 - val_loss: 5.1110 - val_MinusLogProbMetric: 5.1110 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-12 07:46:37.329 
Epoch 93/1000 
	 loss: 5.0950, MinusLogProbMetric: 5.0950, val_loss: 5.1448, val_MinusLogProbMetric: 5.1448

Epoch 93: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0950 - MinusLogProbMetric: 5.0950 - val_loss: 5.1448 - val_MinusLogProbMetric: 5.1448 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-12 07:46:48.972 
Epoch 94/1000 
	 loss: 5.0927, MinusLogProbMetric: 5.0927, val_loss: 5.1131, val_MinusLogProbMetric: 5.1131

Epoch 94: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0927 - MinusLogProbMetric: 5.0927 - val_loss: 5.1131 - val_MinusLogProbMetric: 5.1131 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-12 07:47:00.693 
Epoch 95/1000 
	 loss: 5.0946, MinusLogProbMetric: 5.0946, val_loss: 5.1381, val_MinusLogProbMetric: 5.1381

Epoch 95: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0946 - MinusLogProbMetric: 5.0946 - val_loss: 5.1381 - val_MinusLogProbMetric: 5.1381 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-12 07:47:12.405 
Epoch 96/1000 
	 loss: 5.0938, MinusLogProbMetric: 5.0938, val_loss: 5.1357, val_MinusLogProbMetric: 5.1357

Epoch 96: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0938 - MinusLogProbMetric: 5.0938 - val_loss: 5.1357 - val_MinusLogProbMetric: 5.1357 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 97/1000
2023-09-12 07:47:24.169 
Epoch 97/1000 
	 loss: 5.0948, MinusLogProbMetric: 5.0948, val_loss: 5.1089, val_MinusLogProbMetric: 5.1089

Epoch 97: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0948 - MinusLogProbMetric: 5.0948 - val_loss: 5.1089 - val_MinusLogProbMetric: 5.1089 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 98/1000
2023-09-12 07:47:35.923 
Epoch 98/1000 
	 loss: 5.0930, MinusLogProbMetric: 5.0930, val_loss: 5.1422, val_MinusLogProbMetric: 5.1422

Epoch 98: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0930 - MinusLogProbMetric: 5.0930 - val_loss: 5.1422 - val_MinusLogProbMetric: 5.1422 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 99/1000
2023-09-12 07:47:47.607 
Epoch 99/1000 
	 loss: 5.0918, MinusLogProbMetric: 5.0918, val_loss: 5.1119, val_MinusLogProbMetric: 5.1119

Epoch 99: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0918 - MinusLogProbMetric: 5.0918 - val_loss: 5.1119 - val_MinusLogProbMetric: 5.1119 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 100/1000
2023-09-12 07:47:59.279 
Epoch 100/1000 
	 loss: 5.0882, MinusLogProbMetric: 5.0882, val_loss: 5.1035, val_MinusLogProbMetric: 5.1035

Epoch 100: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0882 - MinusLogProbMetric: 5.0882 - val_loss: 5.1035 - val_MinusLogProbMetric: 5.1035 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-12 07:48:10.970 
Epoch 101/1000 
	 loss: 5.0902, MinusLogProbMetric: 5.0902, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 101: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0902 - MinusLogProbMetric: 5.0902 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 102/1000
2023-09-12 07:48:22.554 
Epoch 102/1000 
	 loss: 5.0917, MinusLogProbMetric: 5.0917, val_loss: 5.1364, val_MinusLogProbMetric: 5.1364

Epoch 102: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0917 - MinusLogProbMetric: 5.0917 - val_loss: 5.1364 - val_MinusLogProbMetric: 5.1364 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 103/1000
2023-09-12 07:48:34.208 
Epoch 103/1000 
	 loss: 5.0905, MinusLogProbMetric: 5.0905, val_loss: 5.1099, val_MinusLogProbMetric: 5.1099

Epoch 103: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0905 - MinusLogProbMetric: 5.0905 - val_loss: 5.1099 - val_MinusLogProbMetric: 5.1099 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 104/1000
2023-09-12 07:48:45.816 
Epoch 104/1000 
	 loss: 5.0871, MinusLogProbMetric: 5.0871, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 104: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0871 - MinusLogProbMetric: 5.0871 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 105/1000
2023-09-12 07:48:57.512 
Epoch 105/1000 
	 loss: 5.0878, MinusLogProbMetric: 5.0878, val_loss: 5.1352, val_MinusLogProbMetric: 5.1352

Epoch 105: val_loss did not improve from 5.10028
196/196 - 12s - loss: 5.0878 - MinusLogProbMetric: 5.0878 - val_loss: 5.1352 - val_MinusLogProbMetric: 5.1352 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-12 07:49:09.269 
Epoch 106/1000 
	 loss: 5.0820, MinusLogProbMetric: 5.0820, val_loss: 5.0981, val_MinusLogProbMetric: 5.0981

Epoch 106: val_loss improved from 5.10028 to 5.09808, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.0820 - MinusLogProbMetric: 5.0820 - val_loss: 5.0981 - val_MinusLogProbMetric: 5.0981 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 107/1000
2023-09-12 07:49:21.117 
Epoch 107/1000 
	 loss: 5.0856, MinusLogProbMetric: 5.0856, val_loss: 5.1047, val_MinusLogProbMetric: 5.1047

Epoch 107: val_loss did not improve from 5.09808
196/196 - 12s - loss: 5.0856 - MinusLogProbMetric: 5.0856 - val_loss: 5.1047 - val_MinusLogProbMetric: 5.1047 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-12 07:49:32.841 
Epoch 108/1000 
	 loss: 5.0894, MinusLogProbMetric: 5.0894, val_loss: 5.0970, val_MinusLogProbMetric: 5.0970

Epoch 108: val_loss improved from 5.09808 to 5.09699, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.0894 - MinusLogProbMetric: 5.0894 - val_loss: 5.0970 - val_MinusLogProbMetric: 5.0970 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-12 07:49:44.624 
Epoch 109/1000 
	 loss: 5.0851, MinusLogProbMetric: 5.0851, val_loss: 5.1172, val_MinusLogProbMetric: 5.1172

Epoch 109: val_loss did not improve from 5.09699
196/196 - 12s - loss: 5.0851 - MinusLogProbMetric: 5.0851 - val_loss: 5.1172 - val_MinusLogProbMetric: 5.1172 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-12 07:49:56.286 
Epoch 110/1000 
	 loss: 5.0885, MinusLogProbMetric: 5.0885, val_loss: 5.1368, val_MinusLogProbMetric: 5.1368

Epoch 110: val_loss did not improve from 5.09699
196/196 - 12s - loss: 5.0885 - MinusLogProbMetric: 5.0885 - val_loss: 5.1368 - val_MinusLogProbMetric: 5.1368 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 111/1000
2023-09-12 07:50:07.780 
Epoch 111/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.0975, val_MinusLogProbMetric: 5.0975

Epoch 111: val_loss did not improve from 5.09699
196/196 - 11s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.0975 - val_MinusLogProbMetric: 5.0975 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 112/1000
2023-09-12 07:50:18.865 
Epoch 112/1000 
	 loss: 5.0828, MinusLogProbMetric: 5.0828, val_loss: 5.1376, val_MinusLogProbMetric: 5.1376

Epoch 112: val_loss did not improve from 5.09699
196/196 - 11s - loss: 5.0828 - MinusLogProbMetric: 5.0828 - val_loss: 5.1376 - val_MinusLogProbMetric: 5.1376 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 113/1000
2023-09-12 07:50:29.342 
Epoch 113/1000 
	 loss: 5.0868, MinusLogProbMetric: 5.0868, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 113: val_loss did not improve from 5.09699
196/196 - 10s - loss: 5.0868 - MinusLogProbMetric: 5.0868 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 114/1000
2023-09-12 07:50:39.930 
Epoch 114/1000 
	 loss: 5.0852, MinusLogProbMetric: 5.0852, val_loss: 5.1058, val_MinusLogProbMetric: 5.1058

Epoch 114: val_loss did not improve from 5.09699
196/196 - 11s - loss: 5.0852 - MinusLogProbMetric: 5.0852 - val_loss: 5.1058 - val_MinusLogProbMetric: 5.1058 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 115/1000
2023-09-12 07:50:50.838 
Epoch 115/1000 
	 loss: 5.0861, MinusLogProbMetric: 5.0861, val_loss: 5.1075, val_MinusLogProbMetric: 5.1075

Epoch 115: val_loss did not improve from 5.09699
196/196 - 11s - loss: 5.0861 - MinusLogProbMetric: 5.0861 - val_loss: 5.1075 - val_MinusLogProbMetric: 5.1075 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 116/1000
2023-09-12 07:51:01.479 
Epoch 116/1000 
	 loss: 5.0851, MinusLogProbMetric: 5.0851, val_loss: 5.1150, val_MinusLogProbMetric: 5.1150

Epoch 116: val_loss did not improve from 5.09699
196/196 - 11s - loss: 5.0851 - MinusLogProbMetric: 5.0851 - val_loss: 5.1150 - val_MinusLogProbMetric: 5.1150 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 117/1000
2023-09-12 07:51:13.028 
Epoch 117/1000 
	 loss: 5.0865, MinusLogProbMetric: 5.0865, val_loss: 5.1190, val_MinusLogProbMetric: 5.1190

Epoch 117: val_loss did not improve from 5.09699
196/196 - 12s - loss: 5.0865 - MinusLogProbMetric: 5.0865 - val_loss: 5.1190 - val_MinusLogProbMetric: 5.1190 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 118/1000
2023-09-12 07:51:24.757 
Epoch 118/1000 
	 loss: 5.0821, MinusLogProbMetric: 5.0821, val_loss: 5.0997, val_MinusLogProbMetric: 5.0997

Epoch 118: val_loss did not improve from 5.09699
196/196 - 12s - loss: 5.0821 - MinusLogProbMetric: 5.0821 - val_loss: 5.0997 - val_MinusLogProbMetric: 5.0997 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-12 07:51:36.279 
Epoch 119/1000 
	 loss: 5.0794, MinusLogProbMetric: 5.0794, val_loss: 5.1262, val_MinusLogProbMetric: 5.1262

Epoch 119: val_loss did not improve from 5.09699
196/196 - 12s - loss: 5.0794 - MinusLogProbMetric: 5.0794 - val_loss: 5.1262 - val_MinusLogProbMetric: 5.1262 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 120/1000
2023-09-12 07:51:47.829 
Epoch 120/1000 
	 loss: 5.0841, MinusLogProbMetric: 5.0841, val_loss: 5.1159, val_MinusLogProbMetric: 5.1159

Epoch 120: val_loss did not improve from 5.09699
196/196 - 12s - loss: 5.0841 - MinusLogProbMetric: 5.0841 - val_loss: 5.1159 - val_MinusLogProbMetric: 5.1159 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 121/1000
2023-09-12 07:51:59.436 
Epoch 121/1000 
	 loss: 5.0834, MinusLogProbMetric: 5.0834, val_loss: 5.1032, val_MinusLogProbMetric: 5.1032

Epoch 121: val_loss did not improve from 5.09699
196/196 - 12s - loss: 5.0834 - MinusLogProbMetric: 5.0834 - val_loss: 5.1032 - val_MinusLogProbMetric: 5.1032 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 122/1000
2023-09-12 07:52:10.712 
Epoch 122/1000 
	 loss: 5.0820, MinusLogProbMetric: 5.0820, val_loss: 5.0963, val_MinusLogProbMetric: 5.0963

Epoch 122: val_loss improved from 5.09699 to 5.09633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 11s - loss: 5.0820 - MinusLogProbMetric: 5.0820 - val_loss: 5.0963 - val_MinusLogProbMetric: 5.0963 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 123/1000
2023-09-12 07:52:20.789 
Epoch 123/1000 
	 loss: 5.0850, MinusLogProbMetric: 5.0850, val_loss: 5.0965, val_MinusLogProbMetric: 5.0965

Epoch 123: val_loss did not improve from 5.09633
196/196 - 10s - loss: 5.0850 - MinusLogProbMetric: 5.0850 - val_loss: 5.0965 - val_MinusLogProbMetric: 5.0965 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 124/1000
2023-09-12 07:52:31.164 
Epoch 124/1000 
	 loss: 5.0802, MinusLogProbMetric: 5.0802, val_loss: 5.0977, val_MinusLogProbMetric: 5.0977

Epoch 124: val_loss did not improve from 5.09633
196/196 - 10s - loss: 5.0802 - MinusLogProbMetric: 5.0802 - val_loss: 5.0977 - val_MinusLogProbMetric: 5.0977 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 125/1000
2023-09-12 07:52:42.253 
Epoch 125/1000 
	 loss: 5.0773, MinusLogProbMetric: 5.0773, val_loss: 5.1159, val_MinusLogProbMetric: 5.1159

Epoch 125: val_loss did not improve from 5.09633
196/196 - 11s - loss: 5.0773 - MinusLogProbMetric: 5.0773 - val_loss: 5.1159 - val_MinusLogProbMetric: 5.1159 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 126/1000
2023-09-12 07:52:52.298 
Epoch 126/1000 
	 loss: 5.0818, MinusLogProbMetric: 5.0818, val_loss: 5.1178, val_MinusLogProbMetric: 5.1178

Epoch 126: val_loss did not improve from 5.09633
196/196 - 10s - loss: 5.0818 - MinusLogProbMetric: 5.0818 - val_loss: 5.1178 - val_MinusLogProbMetric: 5.1178 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 127/1000
2023-09-12 07:53:03.533 
Epoch 127/1000 
	 loss: 5.0779, MinusLogProbMetric: 5.0779, val_loss: 5.1002, val_MinusLogProbMetric: 5.1002

Epoch 127: val_loss did not improve from 5.09633
196/196 - 11s - loss: 5.0779 - MinusLogProbMetric: 5.0779 - val_loss: 5.1002 - val_MinusLogProbMetric: 5.1002 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 128/1000
2023-09-12 07:53:15.216 
Epoch 128/1000 
	 loss: 5.0807, MinusLogProbMetric: 5.0807, val_loss: 5.1040, val_MinusLogProbMetric: 5.1040

Epoch 128: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0807 - MinusLogProbMetric: 5.0807 - val_loss: 5.1040 - val_MinusLogProbMetric: 5.1040 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-12 07:53:26.848 
Epoch 129/1000 
	 loss: 5.0808, MinusLogProbMetric: 5.0808, val_loss: 5.1120, val_MinusLogProbMetric: 5.1120

Epoch 129: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0808 - MinusLogProbMetric: 5.0808 - val_loss: 5.1120 - val_MinusLogProbMetric: 5.1120 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 130/1000
2023-09-12 07:53:38.453 
Epoch 130/1000 
	 loss: 5.0751, MinusLogProbMetric: 5.0751, val_loss: 5.1063, val_MinusLogProbMetric: 5.1063

Epoch 130: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0751 - MinusLogProbMetric: 5.0751 - val_loss: 5.1063 - val_MinusLogProbMetric: 5.1063 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 131/1000
2023-09-12 07:53:50.019 
Epoch 131/1000 
	 loss: 5.0777, MinusLogProbMetric: 5.0777, val_loss: 5.1218, val_MinusLogProbMetric: 5.1218

Epoch 131: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0777 - MinusLogProbMetric: 5.0777 - val_loss: 5.1218 - val_MinusLogProbMetric: 5.1218 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 132/1000
2023-09-12 07:54:01.643 
Epoch 132/1000 
	 loss: 5.0827, MinusLogProbMetric: 5.0827, val_loss: 5.1129, val_MinusLogProbMetric: 5.1129

Epoch 132: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0827 - MinusLogProbMetric: 5.0827 - val_loss: 5.1129 - val_MinusLogProbMetric: 5.1129 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 133/1000
2023-09-12 07:54:13.341 
Epoch 133/1000 
	 loss: 5.0826, MinusLogProbMetric: 5.0826, val_loss: 5.1208, val_MinusLogProbMetric: 5.1208

Epoch 133: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0826 - MinusLogProbMetric: 5.0826 - val_loss: 5.1208 - val_MinusLogProbMetric: 5.1208 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-12 07:54:25.083 
Epoch 134/1000 
	 loss: 5.0814, MinusLogProbMetric: 5.0814, val_loss: 5.1047, val_MinusLogProbMetric: 5.1047

Epoch 134: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0814 - MinusLogProbMetric: 5.0814 - val_loss: 5.1047 - val_MinusLogProbMetric: 5.1047 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-12 07:54:36.731 
Epoch 135/1000 
	 loss: 5.0789, MinusLogProbMetric: 5.0789, val_loss: 5.1023, val_MinusLogProbMetric: 5.1023

Epoch 135: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0789 - MinusLogProbMetric: 5.0789 - val_loss: 5.1023 - val_MinusLogProbMetric: 5.1023 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 136/1000
2023-09-12 07:54:48.357 
Epoch 136/1000 
	 loss: 5.0770, MinusLogProbMetric: 5.0770, val_loss: 5.1126, val_MinusLogProbMetric: 5.1126

Epoch 136: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0770 - MinusLogProbMetric: 5.0770 - val_loss: 5.1126 - val_MinusLogProbMetric: 5.1126 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 137/1000
2023-09-12 07:54:59.993 
Epoch 137/1000 
	 loss: 5.0736, MinusLogProbMetric: 5.0736, val_loss: 5.1027, val_MinusLogProbMetric: 5.1027

Epoch 137: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0736 - MinusLogProbMetric: 5.0736 - val_loss: 5.1027 - val_MinusLogProbMetric: 5.1027 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 138/1000
2023-09-12 07:55:11.707 
Epoch 138/1000 
	 loss: 5.0792, MinusLogProbMetric: 5.0792, val_loss: 5.1015, val_MinusLogProbMetric: 5.1015

Epoch 138: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0792 - MinusLogProbMetric: 5.0792 - val_loss: 5.1015 - val_MinusLogProbMetric: 5.1015 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-12 07:55:23.476 
Epoch 139/1000 
	 loss: 5.0770, MinusLogProbMetric: 5.0770, val_loss: 5.1001, val_MinusLogProbMetric: 5.1001

Epoch 139: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0770 - MinusLogProbMetric: 5.0770 - val_loss: 5.1001 - val_MinusLogProbMetric: 5.1001 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-12 07:55:35.159 
Epoch 140/1000 
	 loss: 5.0730, MinusLogProbMetric: 5.0730, val_loss: 5.1094, val_MinusLogProbMetric: 5.1094

Epoch 140: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0730 - MinusLogProbMetric: 5.0730 - val_loss: 5.1094 - val_MinusLogProbMetric: 5.1094 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 141/1000
2023-09-12 07:55:46.709 
Epoch 141/1000 
	 loss: 5.0764, MinusLogProbMetric: 5.0764, val_loss: 5.1137, val_MinusLogProbMetric: 5.1137

Epoch 141: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0764 - MinusLogProbMetric: 5.0764 - val_loss: 5.1137 - val_MinusLogProbMetric: 5.1137 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 142/1000
2023-09-12 07:55:58.249 
Epoch 142/1000 
	 loss: 5.0750, MinusLogProbMetric: 5.0750, val_loss: 5.0975, val_MinusLogProbMetric: 5.0975

Epoch 142: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0750 - MinusLogProbMetric: 5.0750 - val_loss: 5.0975 - val_MinusLogProbMetric: 5.0975 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 143/1000
2023-09-12 07:56:09.946 
Epoch 143/1000 
	 loss: 5.0785, MinusLogProbMetric: 5.0785, val_loss: 5.1022, val_MinusLogProbMetric: 5.1022

Epoch 143: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0785 - MinusLogProbMetric: 5.0785 - val_loss: 5.1022 - val_MinusLogProbMetric: 5.1022 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 144/1000
2023-09-12 07:56:21.560 
Epoch 144/1000 
	 loss: 5.0794, MinusLogProbMetric: 5.0794, val_loss: 5.1146, val_MinusLogProbMetric: 5.1146

Epoch 144: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0794 - MinusLogProbMetric: 5.0794 - val_loss: 5.1146 - val_MinusLogProbMetric: 5.1146 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 145/1000
2023-09-12 07:56:33.220 
Epoch 145/1000 
	 loss: 5.0743, MinusLogProbMetric: 5.0743, val_loss: 5.1013, val_MinusLogProbMetric: 5.1013

Epoch 145: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0743 - MinusLogProbMetric: 5.0743 - val_loss: 5.1013 - val_MinusLogProbMetric: 5.1013 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 146/1000
2023-09-12 07:56:45.129 
Epoch 146/1000 
	 loss: 5.0742, MinusLogProbMetric: 5.0742, val_loss: 5.0964, val_MinusLogProbMetric: 5.0964

Epoch 146: val_loss did not improve from 5.09633
196/196 - 12s - loss: 5.0742 - MinusLogProbMetric: 5.0742 - val_loss: 5.0964 - val_MinusLogProbMetric: 5.0964 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 147/1000
2023-09-12 07:56:56.790 
Epoch 147/1000 
	 loss: 5.0702, MinusLogProbMetric: 5.0702, val_loss: 5.0940, val_MinusLogProbMetric: 5.0940

Epoch 147: val_loss improved from 5.09633 to 5.09402, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.0702 - MinusLogProbMetric: 5.0702 - val_loss: 5.0940 - val_MinusLogProbMetric: 5.0940 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-12 07:57:08.567 
Epoch 148/1000 
	 loss: 5.0720, MinusLogProbMetric: 5.0720, val_loss: 5.1026, val_MinusLogProbMetric: 5.1026

Epoch 148: val_loss did not improve from 5.09402
196/196 - 12s - loss: 5.0720 - MinusLogProbMetric: 5.0720 - val_loss: 5.1026 - val_MinusLogProbMetric: 5.1026 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-12 07:57:20.174 
Epoch 149/1000 
	 loss: 5.0744, MinusLogProbMetric: 5.0744, val_loss: 5.1184, val_MinusLogProbMetric: 5.1184

Epoch 149: val_loss did not improve from 5.09402
196/196 - 12s - loss: 5.0744 - MinusLogProbMetric: 5.0744 - val_loss: 5.1184 - val_MinusLogProbMetric: 5.1184 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 150/1000
2023-09-12 07:57:31.854 
Epoch 150/1000 
	 loss: 5.0739, MinusLogProbMetric: 5.0739, val_loss: 5.1041, val_MinusLogProbMetric: 5.1041

Epoch 150: val_loss did not improve from 5.09402
196/196 - 12s - loss: 5.0739 - MinusLogProbMetric: 5.0739 - val_loss: 5.1041 - val_MinusLogProbMetric: 5.1041 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-12 07:57:43.582 
Epoch 151/1000 
	 loss: 5.0762, MinusLogProbMetric: 5.0762, val_loss: 5.0938, val_MinusLogProbMetric: 5.0938

Epoch 151: val_loss improved from 5.09402 to 5.09377, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.0762 - MinusLogProbMetric: 5.0762 - val_loss: 5.0938 - val_MinusLogProbMetric: 5.0938 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-12 07:57:55.314 
Epoch 152/1000 
	 loss: 5.0746, MinusLogProbMetric: 5.0746, val_loss: 5.0976, val_MinusLogProbMetric: 5.0976

Epoch 152: val_loss did not improve from 5.09377
196/196 - 12s - loss: 5.0746 - MinusLogProbMetric: 5.0746 - val_loss: 5.0976 - val_MinusLogProbMetric: 5.0976 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 153/1000
2023-09-12 07:58:07.114 
Epoch 153/1000 
	 loss: 5.0720, MinusLogProbMetric: 5.0720, val_loss: 5.1087, val_MinusLogProbMetric: 5.1087

Epoch 153: val_loss did not improve from 5.09377
196/196 - 12s - loss: 5.0720 - MinusLogProbMetric: 5.0720 - val_loss: 5.1087 - val_MinusLogProbMetric: 5.1087 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 154/1000
2023-09-12 07:58:18.890 
Epoch 154/1000 
	 loss: 5.0727, MinusLogProbMetric: 5.0727, val_loss: 5.0846, val_MinusLogProbMetric: 5.0846

Epoch 154: val_loss improved from 5.09377 to 5.08462, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 12s - loss: 5.0727 - MinusLogProbMetric: 5.0727 - val_loss: 5.0846 - val_MinusLogProbMetric: 5.0846 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 155/1000
2023-09-12 07:58:30.638 
Epoch 155/1000 
	 loss: 5.0701, MinusLogProbMetric: 5.0701, val_loss: 5.1255, val_MinusLogProbMetric: 5.1255

Epoch 155: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0701 - MinusLogProbMetric: 5.0701 - val_loss: 5.1255 - val_MinusLogProbMetric: 5.1255 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 156/1000
2023-09-12 07:58:42.233 
Epoch 156/1000 
	 loss: 5.0725, MinusLogProbMetric: 5.0725, val_loss: 5.1094, val_MinusLogProbMetric: 5.1094

Epoch 156: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0725 - MinusLogProbMetric: 5.0725 - val_loss: 5.1094 - val_MinusLogProbMetric: 5.1094 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 157/1000
2023-09-12 07:58:53.859 
Epoch 157/1000 
	 loss: 5.0730, MinusLogProbMetric: 5.0730, val_loss: 5.1138, val_MinusLogProbMetric: 5.1138

Epoch 157: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0730 - MinusLogProbMetric: 5.0730 - val_loss: 5.1138 - val_MinusLogProbMetric: 5.1138 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 158/1000
2023-09-12 07:59:05.459 
Epoch 158/1000 
	 loss: 5.0692, MinusLogProbMetric: 5.0692, val_loss: 5.1022, val_MinusLogProbMetric: 5.1022

Epoch 158: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0692 - MinusLogProbMetric: 5.0692 - val_loss: 5.1022 - val_MinusLogProbMetric: 5.1022 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 159/1000
2023-09-12 07:59:17.232 
Epoch 159/1000 
	 loss: 5.0702, MinusLogProbMetric: 5.0702, val_loss: 5.1367, val_MinusLogProbMetric: 5.1367

Epoch 159: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0702 - MinusLogProbMetric: 5.0702 - val_loss: 5.1367 - val_MinusLogProbMetric: 5.1367 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-12 07:59:28.958 
Epoch 160/1000 
	 loss: 5.0745, MinusLogProbMetric: 5.0745, val_loss: 5.1172, val_MinusLogProbMetric: 5.1172

Epoch 160: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0745 - MinusLogProbMetric: 5.0745 - val_loss: 5.1172 - val_MinusLogProbMetric: 5.1172 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 161/1000
2023-09-12 07:59:40.531 
Epoch 161/1000 
	 loss: 5.0735, MinusLogProbMetric: 5.0735, val_loss: 5.0969, val_MinusLogProbMetric: 5.0969

Epoch 161: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0735 - MinusLogProbMetric: 5.0735 - val_loss: 5.0969 - val_MinusLogProbMetric: 5.0969 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 162/1000
2023-09-12 07:59:52.129 
Epoch 162/1000 
	 loss: 5.0749, MinusLogProbMetric: 5.0749, val_loss: 5.1036, val_MinusLogProbMetric: 5.1036

Epoch 162: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0749 - MinusLogProbMetric: 5.0749 - val_loss: 5.1036 - val_MinusLogProbMetric: 5.1036 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 163/1000
2023-09-12 08:00:03.830 
Epoch 163/1000 
	 loss: 5.0687, MinusLogProbMetric: 5.0687, val_loss: 5.0901, val_MinusLogProbMetric: 5.0901

Epoch 163: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0687 - MinusLogProbMetric: 5.0687 - val_loss: 5.0901 - val_MinusLogProbMetric: 5.0901 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 164/1000
2023-09-12 08:00:15.433 
Epoch 164/1000 
	 loss: 5.0744, MinusLogProbMetric: 5.0744, val_loss: 5.1130, val_MinusLogProbMetric: 5.1130

Epoch 164: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0744 - MinusLogProbMetric: 5.0744 - val_loss: 5.1130 - val_MinusLogProbMetric: 5.1130 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-12 08:00:27.285 
Epoch 165/1000 
	 loss: 5.0749, MinusLogProbMetric: 5.0749, val_loss: 5.1324, val_MinusLogProbMetric: 5.1324

Epoch 165: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0749 - MinusLogProbMetric: 5.0749 - val_loss: 5.1324 - val_MinusLogProbMetric: 5.1324 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 166/1000
2023-09-12 08:00:38.939 
Epoch 166/1000 
	 loss: 5.0731, MinusLogProbMetric: 5.0731, val_loss: 5.1083, val_MinusLogProbMetric: 5.1083

Epoch 166: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0731 - MinusLogProbMetric: 5.0731 - val_loss: 5.1083 - val_MinusLogProbMetric: 5.1083 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-12 08:00:50.453 
Epoch 167/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.1001, val_MinusLogProbMetric: 5.1001

Epoch 167: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.1001 - val_MinusLogProbMetric: 5.1001 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 168/1000
2023-09-12 08:01:02.141 
Epoch 168/1000 
	 loss: 5.0684, MinusLogProbMetric: 5.0684, val_loss: 5.1475, val_MinusLogProbMetric: 5.1475

Epoch 168: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0684 - MinusLogProbMetric: 5.0684 - val_loss: 5.1475 - val_MinusLogProbMetric: 5.1475 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 169/1000
2023-09-12 08:01:13.691 
Epoch 169/1000 
	 loss: 5.0770, MinusLogProbMetric: 5.0770, val_loss: 5.1011, val_MinusLogProbMetric: 5.1011

Epoch 169: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0770 - MinusLogProbMetric: 5.0770 - val_loss: 5.1011 - val_MinusLogProbMetric: 5.1011 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 170/1000
2023-09-12 08:01:25.338 
Epoch 170/1000 
	 loss: 5.0672, MinusLogProbMetric: 5.0672, val_loss: 5.1039, val_MinusLogProbMetric: 5.1039

Epoch 170: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0672 - MinusLogProbMetric: 5.0672 - val_loss: 5.1039 - val_MinusLogProbMetric: 5.1039 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 171/1000
2023-09-12 08:01:36.725 
Epoch 171/1000 
	 loss: 5.0665, MinusLogProbMetric: 5.0665, val_loss: 5.1016, val_MinusLogProbMetric: 5.1016

Epoch 171: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0665 - MinusLogProbMetric: 5.0665 - val_loss: 5.1016 - val_MinusLogProbMetric: 5.1016 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 172/1000
2023-09-12 08:01:48.205 
Epoch 172/1000 
	 loss: 5.0685, MinusLogProbMetric: 5.0685, val_loss: 5.1331, val_MinusLogProbMetric: 5.1331

Epoch 172: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0685 - MinusLogProbMetric: 5.0685 - val_loss: 5.1331 - val_MinusLogProbMetric: 5.1331 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 08:01:59.575 
Epoch 173/1000 
	 loss: 5.0657, MinusLogProbMetric: 5.0657, val_loss: 5.1087, val_MinusLogProbMetric: 5.1087

Epoch 173: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0657 - MinusLogProbMetric: 5.0657 - val_loss: 5.1087 - val_MinusLogProbMetric: 5.1087 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 174/1000
2023-09-12 08:02:10.990 
Epoch 174/1000 
	 loss: 5.0656, MinusLogProbMetric: 5.0656, val_loss: 5.1133, val_MinusLogProbMetric: 5.1133

Epoch 174: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0656 - MinusLogProbMetric: 5.0656 - val_loss: 5.1133 - val_MinusLogProbMetric: 5.1133 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 175/1000
2023-09-12 08:02:22.781 
Epoch 175/1000 
	 loss: 5.0706, MinusLogProbMetric: 5.0706, val_loss: 5.1171, val_MinusLogProbMetric: 5.1171

Epoch 175: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0706 - MinusLogProbMetric: 5.0706 - val_loss: 5.1171 - val_MinusLogProbMetric: 5.1171 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 176/1000
2023-09-12 08:02:34.532 
Epoch 176/1000 
	 loss: 5.0703, MinusLogProbMetric: 5.0703, val_loss: 5.1018, val_MinusLogProbMetric: 5.1018

Epoch 176: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0703 - MinusLogProbMetric: 5.0703 - val_loss: 5.1018 - val_MinusLogProbMetric: 5.1018 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-12 08:02:46.271 
Epoch 177/1000 
	 loss: 5.0662, MinusLogProbMetric: 5.0662, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 177: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0662 - MinusLogProbMetric: 5.0662 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 178/1000
2023-09-12 08:02:57.681 
Epoch 178/1000 
	 loss: 5.0685, MinusLogProbMetric: 5.0685, val_loss: 5.1097, val_MinusLogProbMetric: 5.1097

Epoch 178: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0685 - MinusLogProbMetric: 5.0685 - val_loss: 5.1097 - val_MinusLogProbMetric: 5.1097 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 179/1000
2023-09-12 08:03:09.180 
Epoch 179/1000 
	 loss: 5.0715, MinusLogProbMetric: 5.0715, val_loss: 5.0994, val_MinusLogProbMetric: 5.0994

Epoch 179: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0715 - MinusLogProbMetric: 5.0715 - val_loss: 5.0994 - val_MinusLogProbMetric: 5.0994 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 180/1000
2023-09-12 08:03:20.785 
Epoch 180/1000 
	 loss: 5.0674, MinusLogProbMetric: 5.0674, val_loss: 5.1187, val_MinusLogProbMetric: 5.1187

Epoch 180: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0674 - MinusLogProbMetric: 5.0674 - val_loss: 5.1187 - val_MinusLogProbMetric: 5.1187 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 181/1000
2023-09-12 08:03:32.138 
Epoch 181/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.0964, val_MinusLogProbMetric: 5.0964

Epoch 181: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.0964 - val_MinusLogProbMetric: 5.0964 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 182/1000
2023-09-12 08:03:43.601 
Epoch 182/1000 
	 loss: 5.0667, MinusLogProbMetric: 5.0667, val_loss: 5.1020, val_MinusLogProbMetric: 5.1020

Epoch 182: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0667 - MinusLogProbMetric: 5.0667 - val_loss: 5.1020 - val_MinusLogProbMetric: 5.1020 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 183/1000
2023-09-12 08:03:55.428 
Epoch 183/1000 
	 loss: 5.0727, MinusLogProbMetric: 5.0727, val_loss: 5.1073, val_MinusLogProbMetric: 5.1073

Epoch 183: val_loss did not improve from 5.08462
196/196 - 12s - loss: 5.0727 - MinusLogProbMetric: 5.0727 - val_loss: 5.1073 - val_MinusLogProbMetric: 5.1073 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 184/1000
2023-09-12 08:04:06.557 
Epoch 184/1000 
	 loss: 5.0675, MinusLogProbMetric: 5.0675, val_loss: 5.1048, val_MinusLogProbMetric: 5.1048

Epoch 184: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0675 - MinusLogProbMetric: 5.0675 - val_loss: 5.1048 - val_MinusLogProbMetric: 5.1048 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 185/1000
2023-09-12 08:04:16.713 
Epoch 185/1000 
	 loss: 5.0671, MinusLogProbMetric: 5.0671, val_loss: 5.1037, val_MinusLogProbMetric: 5.1037

Epoch 185: val_loss did not improve from 5.08462
196/196 - 10s - loss: 5.0671 - MinusLogProbMetric: 5.0671 - val_loss: 5.1037 - val_MinusLogProbMetric: 5.1037 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 186/1000
2023-09-12 08:04:26.369 
Epoch 186/1000 
	 loss: 5.0653, MinusLogProbMetric: 5.0653, val_loss: 5.1072, val_MinusLogProbMetric: 5.1072

Epoch 186: val_loss did not improve from 5.08462
196/196 - 10s - loss: 5.0653 - MinusLogProbMetric: 5.0653 - val_loss: 5.1072 - val_MinusLogProbMetric: 5.1072 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 187/1000
2023-09-12 08:04:36.991 
Epoch 187/1000 
	 loss: 5.0705, MinusLogProbMetric: 5.0705, val_loss: 5.1012, val_MinusLogProbMetric: 5.1012

Epoch 187: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0705 - MinusLogProbMetric: 5.0705 - val_loss: 5.1012 - val_MinusLogProbMetric: 5.1012 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 188/1000
2023-09-12 08:04:47.809 
Epoch 188/1000 
	 loss: 5.0663, MinusLogProbMetric: 5.0663, val_loss: 5.0836, val_MinusLogProbMetric: 5.0836

Epoch 188: val_loss improved from 5.08462 to 5.08359, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_87/weights/best_weights.h5
196/196 - 11s - loss: 5.0663 - MinusLogProbMetric: 5.0663 - val_loss: 5.0836 - val_MinusLogProbMetric: 5.0836 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 189/1000
2023-09-12 08:04:58.445 
Epoch 189/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1022, val_MinusLogProbMetric: 5.1022

Epoch 189: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1022 - val_MinusLogProbMetric: 5.1022 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 190/1000
2023-09-12 08:05:10.159 
Epoch 190/1000 
	 loss: 5.0635, MinusLogProbMetric: 5.0635, val_loss: 5.0999, val_MinusLogProbMetric: 5.0999

Epoch 190: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0635 - MinusLogProbMetric: 5.0635 - val_loss: 5.0999 - val_MinusLogProbMetric: 5.0999 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-12 08:05:21.842 
Epoch 191/1000 
	 loss: 5.0613, MinusLogProbMetric: 5.0613, val_loss: 5.0935, val_MinusLogProbMetric: 5.0935

Epoch 191: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0613 - MinusLogProbMetric: 5.0613 - val_loss: 5.0935 - val_MinusLogProbMetric: 5.0935 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 192/1000
2023-09-12 08:05:33.576 
Epoch 192/1000 
	 loss: 5.0622, MinusLogProbMetric: 5.0622, val_loss: 5.1014, val_MinusLogProbMetric: 5.1014

Epoch 192: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0622 - MinusLogProbMetric: 5.0622 - val_loss: 5.1014 - val_MinusLogProbMetric: 5.1014 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 193/1000
2023-09-12 08:05:45.284 
Epoch 193/1000 
	 loss: 5.0619, MinusLogProbMetric: 5.0619, val_loss: 5.1209, val_MinusLogProbMetric: 5.1209

Epoch 193: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0619 - MinusLogProbMetric: 5.0619 - val_loss: 5.1209 - val_MinusLogProbMetric: 5.1209 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-12 08:05:57.090 
Epoch 194/1000 
	 loss: 5.0680, MinusLogProbMetric: 5.0680, val_loss: 5.1121, val_MinusLogProbMetric: 5.1121

Epoch 194: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0680 - MinusLogProbMetric: 5.0680 - val_loss: 5.1121 - val_MinusLogProbMetric: 5.1121 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 195/1000
2023-09-12 08:06:08.764 
Epoch 195/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.1005, val_MinusLogProbMetric: 5.1005

Epoch 195: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.1005 - val_MinusLogProbMetric: 5.1005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-12 08:06:20.540 
Epoch 196/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1130, val_MinusLogProbMetric: 5.1130

Epoch 196: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1130 - val_MinusLogProbMetric: 5.1130 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-12 08:06:32.219 
Epoch 197/1000 
	 loss: 5.0635, MinusLogProbMetric: 5.0635, val_loss: 5.0968, val_MinusLogProbMetric: 5.0968

Epoch 197: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0635 - MinusLogProbMetric: 5.0635 - val_loss: 5.0968 - val_MinusLogProbMetric: 5.0968 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-12 08:06:43.994 
Epoch 198/1000 
	 loss: 5.0594, MinusLogProbMetric: 5.0594, val_loss: 5.1005, val_MinusLogProbMetric: 5.1005

Epoch 198: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0594 - MinusLogProbMetric: 5.0594 - val_loss: 5.1005 - val_MinusLogProbMetric: 5.1005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 199/1000
2023-09-12 08:06:55.729 
Epoch 199/1000 
	 loss: 5.0623, MinusLogProbMetric: 5.0623, val_loss: 5.1147, val_MinusLogProbMetric: 5.1147

Epoch 199: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0623 - MinusLogProbMetric: 5.0623 - val_loss: 5.1147 - val_MinusLogProbMetric: 5.1147 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 200/1000
2023-09-12 08:07:07.449 
Epoch 200/1000 
	 loss: 5.0640, MinusLogProbMetric: 5.0640, val_loss: 5.0909, val_MinusLogProbMetric: 5.0909

Epoch 200: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0640 - MinusLogProbMetric: 5.0640 - val_loss: 5.0909 - val_MinusLogProbMetric: 5.0909 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-12 08:07:19.268 
Epoch 201/1000 
	 loss: 5.0644, MinusLogProbMetric: 5.0644, val_loss: 5.1276, val_MinusLogProbMetric: 5.1276

Epoch 201: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0644 - MinusLogProbMetric: 5.0644 - val_loss: 5.1276 - val_MinusLogProbMetric: 5.1276 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-12 08:07:31.046 
Epoch 202/1000 
	 loss: 5.0676, MinusLogProbMetric: 5.0676, val_loss: 5.1147, val_MinusLogProbMetric: 5.1147

Epoch 202: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0676 - MinusLogProbMetric: 5.0676 - val_loss: 5.1147 - val_MinusLogProbMetric: 5.1147 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-12 08:07:42.703 
Epoch 203/1000 
	 loss: 5.0601, MinusLogProbMetric: 5.0601, val_loss: 5.0944, val_MinusLogProbMetric: 5.0944

Epoch 203: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0601 - MinusLogProbMetric: 5.0601 - val_loss: 5.0944 - val_MinusLogProbMetric: 5.0944 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 204/1000
2023-09-12 08:07:54.486 
Epoch 204/1000 
	 loss: 5.0662, MinusLogProbMetric: 5.0662, val_loss: 5.1005, val_MinusLogProbMetric: 5.1005

Epoch 204: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0662 - MinusLogProbMetric: 5.0662 - val_loss: 5.1005 - val_MinusLogProbMetric: 5.1005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-12 08:08:06.120 
Epoch 205/1000 
	 loss: 5.0612, MinusLogProbMetric: 5.0612, val_loss: 5.1122, val_MinusLogProbMetric: 5.1122

Epoch 205: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0612 - MinusLogProbMetric: 5.0612 - val_loss: 5.1122 - val_MinusLogProbMetric: 5.1122 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 206/1000
2023-09-12 08:08:17.856 
Epoch 206/1000 
	 loss: 5.0595, MinusLogProbMetric: 5.0595, val_loss: 5.0891, val_MinusLogProbMetric: 5.0891

Epoch 206: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0595 - MinusLogProbMetric: 5.0595 - val_loss: 5.0891 - val_MinusLogProbMetric: 5.0891 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 207/1000
2023-09-12 08:08:29.475 
Epoch 207/1000 
	 loss: 5.0598, MinusLogProbMetric: 5.0598, val_loss: 5.1068, val_MinusLogProbMetric: 5.1068

Epoch 207: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0598 - MinusLogProbMetric: 5.0598 - val_loss: 5.1068 - val_MinusLogProbMetric: 5.1068 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 208/1000
2023-09-12 08:08:41.119 
Epoch 208/1000 
	 loss: 5.0624, MinusLogProbMetric: 5.0624, val_loss: 5.1004, val_MinusLogProbMetric: 5.1004

Epoch 208: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0624 - MinusLogProbMetric: 5.0624 - val_loss: 5.1004 - val_MinusLogProbMetric: 5.1004 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 209/1000
2023-09-12 08:08:52.742 
Epoch 209/1000 
	 loss: 5.0579, MinusLogProbMetric: 5.0579, val_loss: 5.0970, val_MinusLogProbMetric: 5.0970

Epoch 209: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0579 - MinusLogProbMetric: 5.0579 - val_loss: 5.0970 - val_MinusLogProbMetric: 5.0970 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-12 08:09:04.333 
Epoch 210/1000 
	 loss: 5.0631, MinusLogProbMetric: 5.0631, val_loss: 5.0862, val_MinusLogProbMetric: 5.0862

Epoch 210: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0631 - MinusLogProbMetric: 5.0631 - val_loss: 5.0862 - val_MinusLogProbMetric: 5.0862 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 211/1000
2023-09-12 08:09:15.952 
Epoch 211/1000 
	 loss: 5.0637, MinusLogProbMetric: 5.0637, val_loss: 5.0883, val_MinusLogProbMetric: 5.0883

Epoch 211: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0637 - MinusLogProbMetric: 5.0637 - val_loss: 5.0883 - val_MinusLogProbMetric: 5.0883 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 212/1000
2023-09-12 08:09:27.587 
Epoch 212/1000 
	 loss: 5.0616, MinusLogProbMetric: 5.0616, val_loss: 5.0975, val_MinusLogProbMetric: 5.0975

Epoch 212: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0616 - MinusLogProbMetric: 5.0616 - val_loss: 5.0975 - val_MinusLogProbMetric: 5.0975 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 213/1000
2023-09-12 08:09:39.222 
Epoch 213/1000 
	 loss: 5.0589, MinusLogProbMetric: 5.0589, val_loss: 5.1062, val_MinusLogProbMetric: 5.1062

Epoch 213: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0589 - MinusLogProbMetric: 5.0589 - val_loss: 5.1062 - val_MinusLogProbMetric: 5.1062 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 214/1000
2023-09-12 08:09:50.982 
Epoch 214/1000 
	 loss: 5.0599, MinusLogProbMetric: 5.0599, val_loss: 5.0889, val_MinusLogProbMetric: 5.0889

Epoch 214: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0599 - MinusLogProbMetric: 5.0599 - val_loss: 5.0889 - val_MinusLogProbMetric: 5.0889 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 215/1000
2023-09-12 08:10:02.745 
Epoch 215/1000 
	 loss: 5.0601, MinusLogProbMetric: 5.0601, val_loss: 5.1042, val_MinusLogProbMetric: 5.1042

Epoch 215: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0601 - MinusLogProbMetric: 5.0601 - val_loss: 5.1042 - val_MinusLogProbMetric: 5.1042 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 216/1000
2023-09-12 08:10:14.445 
Epoch 216/1000 
	 loss: 5.0653, MinusLogProbMetric: 5.0653, val_loss: 5.0951, val_MinusLogProbMetric: 5.0951

Epoch 216: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0653 - MinusLogProbMetric: 5.0653 - val_loss: 5.0951 - val_MinusLogProbMetric: 5.0951 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 217/1000
2023-09-12 08:10:26.250 
Epoch 217/1000 
	 loss: 5.0627, MinusLogProbMetric: 5.0627, val_loss: 5.1128, val_MinusLogProbMetric: 5.1128

Epoch 217: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0627 - MinusLogProbMetric: 5.0627 - val_loss: 5.1128 - val_MinusLogProbMetric: 5.1128 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 218/1000
2023-09-12 08:10:36.100 
Epoch 218/1000 
	 loss: 5.0627, MinusLogProbMetric: 5.0627, val_loss: 5.1079, val_MinusLogProbMetric: 5.1079

Epoch 218: val_loss did not improve from 5.08359
196/196 - 10s - loss: 5.0627 - MinusLogProbMetric: 5.0627 - val_loss: 5.1079 - val_MinusLogProbMetric: 5.1079 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 219/1000
2023-09-12 08:10:44.441 
Epoch 219/1000 
	 loss: 5.0590, MinusLogProbMetric: 5.0590, val_loss: 5.1133, val_MinusLogProbMetric: 5.1133

Epoch 219: val_loss did not improve from 5.08359
196/196 - 8s - loss: 5.0590 - MinusLogProbMetric: 5.0590 - val_loss: 5.1133 - val_MinusLogProbMetric: 5.1133 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 220/1000
2023-09-12 08:10:55.108 
Epoch 220/1000 
	 loss: 5.0572, MinusLogProbMetric: 5.0572, val_loss: 5.1060, val_MinusLogProbMetric: 5.1060

Epoch 220: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0572 - MinusLogProbMetric: 5.0572 - val_loss: 5.1060 - val_MinusLogProbMetric: 5.1060 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 221/1000
2023-09-12 08:11:06.048 
Epoch 221/1000 
	 loss: 5.0605, MinusLogProbMetric: 5.0605, val_loss: 5.1220, val_MinusLogProbMetric: 5.1220

Epoch 221: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0605 - MinusLogProbMetric: 5.0605 - val_loss: 5.1220 - val_MinusLogProbMetric: 5.1220 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 222/1000
2023-09-12 08:11:17.741 
Epoch 222/1000 
	 loss: 5.0594, MinusLogProbMetric: 5.0594, val_loss: 5.1067, val_MinusLogProbMetric: 5.1067

Epoch 222: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0594 - MinusLogProbMetric: 5.0594 - val_loss: 5.1067 - val_MinusLogProbMetric: 5.1067 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 223/1000
2023-09-12 08:11:29.386 
Epoch 223/1000 
	 loss: 5.0578, MinusLogProbMetric: 5.0578, val_loss: 5.0897, val_MinusLogProbMetric: 5.0897

Epoch 223: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0578 - MinusLogProbMetric: 5.0578 - val_loss: 5.0897 - val_MinusLogProbMetric: 5.0897 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 224/1000
2023-09-12 08:11:41.102 
Epoch 224/1000 
	 loss: 5.0547, MinusLogProbMetric: 5.0547, val_loss: 5.1001, val_MinusLogProbMetric: 5.1001

Epoch 224: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0547 - MinusLogProbMetric: 5.0547 - val_loss: 5.1001 - val_MinusLogProbMetric: 5.1001 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 225/1000
2023-09-12 08:11:52.835 
Epoch 225/1000 
	 loss: 5.0563, MinusLogProbMetric: 5.0563, val_loss: 5.0865, val_MinusLogProbMetric: 5.0865

Epoch 225: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0563 - MinusLogProbMetric: 5.0563 - val_loss: 5.0865 - val_MinusLogProbMetric: 5.0865 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-12 08:12:04.607 
Epoch 226/1000 
	 loss: 5.0562, MinusLogProbMetric: 5.0562, val_loss: 5.0913, val_MinusLogProbMetric: 5.0913

Epoch 226: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0562 - MinusLogProbMetric: 5.0562 - val_loss: 5.0913 - val_MinusLogProbMetric: 5.0913 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 227/1000
2023-09-12 08:12:16.222 
Epoch 227/1000 
	 loss: 5.0593, MinusLogProbMetric: 5.0593, val_loss: 5.1127, val_MinusLogProbMetric: 5.1127

Epoch 227: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0593 - MinusLogProbMetric: 5.0593 - val_loss: 5.1127 - val_MinusLogProbMetric: 5.1127 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-12 08:12:27.817 
Epoch 228/1000 
	 loss: 5.0601, MinusLogProbMetric: 5.0601, val_loss: 5.1133, val_MinusLogProbMetric: 5.1133

Epoch 228: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0601 - MinusLogProbMetric: 5.0601 - val_loss: 5.1133 - val_MinusLogProbMetric: 5.1133 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 229/1000
2023-09-12 08:12:39.563 
Epoch 229/1000 
	 loss: 5.0553, MinusLogProbMetric: 5.0553, val_loss: 5.0949, val_MinusLogProbMetric: 5.0949

Epoch 229: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0553 - MinusLogProbMetric: 5.0553 - val_loss: 5.0949 - val_MinusLogProbMetric: 5.0949 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 230/1000
2023-09-12 08:12:48.982 
Epoch 230/1000 
	 loss: 5.0591, MinusLogProbMetric: 5.0591, val_loss: 5.0945, val_MinusLogProbMetric: 5.0945

Epoch 230: val_loss did not improve from 5.08359
196/196 - 9s - loss: 5.0591 - MinusLogProbMetric: 5.0591 - val_loss: 5.0945 - val_MinusLogProbMetric: 5.0945 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 231/1000
2023-09-12 08:12:59.549 
Epoch 231/1000 
	 loss: 5.0527, MinusLogProbMetric: 5.0527, val_loss: 5.0956, val_MinusLogProbMetric: 5.0956

Epoch 231: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0527 - MinusLogProbMetric: 5.0527 - val_loss: 5.0956 - val_MinusLogProbMetric: 5.0956 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 232/1000
2023-09-12 08:13:10.243 
Epoch 232/1000 
	 loss: 5.0574, MinusLogProbMetric: 5.0574, val_loss: 5.0898, val_MinusLogProbMetric: 5.0898

Epoch 232: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0574 - MinusLogProbMetric: 5.0574 - val_loss: 5.0898 - val_MinusLogProbMetric: 5.0898 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 233/1000
2023-09-12 08:13:21.314 
Epoch 233/1000 
	 loss: 5.0575, MinusLogProbMetric: 5.0575, val_loss: 5.1004, val_MinusLogProbMetric: 5.1004

Epoch 233: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0575 - MinusLogProbMetric: 5.0575 - val_loss: 5.1004 - val_MinusLogProbMetric: 5.1004 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 234/1000
2023-09-12 08:13:32.783 
Epoch 234/1000 
	 loss: 5.0569, MinusLogProbMetric: 5.0569, val_loss: 5.1117, val_MinusLogProbMetric: 5.1117

Epoch 234: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0569 - MinusLogProbMetric: 5.0569 - val_loss: 5.1117 - val_MinusLogProbMetric: 5.1117 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 235/1000
2023-09-12 08:13:44.414 
Epoch 235/1000 
	 loss: 5.0533, MinusLogProbMetric: 5.0533, val_loss: 5.1021, val_MinusLogProbMetric: 5.1021

Epoch 235: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0533 - MinusLogProbMetric: 5.0533 - val_loss: 5.1021 - val_MinusLogProbMetric: 5.1021 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 236/1000
2023-09-12 08:13:56.187 
Epoch 236/1000 
	 loss: 5.0531, MinusLogProbMetric: 5.0531, val_loss: 5.0958, val_MinusLogProbMetric: 5.0958

Epoch 236: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0531 - MinusLogProbMetric: 5.0531 - val_loss: 5.0958 - val_MinusLogProbMetric: 5.0958 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 237/1000
2023-09-12 08:14:07.736 
Epoch 237/1000 
	 loss: 5.0582, MinusLogProbMetric: 5.0582, val_loss: 5.0983, val_MinusLogProbMetric: 5.0983

Epoch 237: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0582 - MinusLogProbMetric: 5.0582 - val_loss: 5.0983 - val_MinusLogProbMetric: 5.0983 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 238/1000
2023-09-12 08:14:19.406 
Epoch 238/1000 
	 loss: 5.0579, MinusLogProbMetric: 5.0579, val_loss: 5.1046, val_MinusLogProbMetric: 5.1046

Epoch 238: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0579 - MinusLogProbMetric: 5.0579 - val_loss: 5.1046 - val_MinusLogProbMetric: 5.1046 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-12 08:14:31.226 
Epoch 239/1000 
	 loss: 5.0374, MinusLogProbMetric: 5.0374, val_loss: 5.0881, val_MinusLogProbMetric: 5.0881

Epoch 239: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0374 - MinusLogProbMetric: 5.0374 - val_loss: 5.0881 - val_MinusLogProbMetric: 5.0881 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 240/1000
2023-09-12 08:14:42.548 
Epoch 240/1000 
	 loss: 5.0353, MinusLogProbMetric: 5.0353, val_loss: 5.0884, val_MinusLogProbMetric: 5.0884

Epoch 240: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0353 - MinusLogProbMetric: 5.0353 - val_loss: 5.0884 - val_MinusLogProbMetric: 5.0884 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 241/1000
2023-09-12 08:14:53.968 
Epoch 241/1000 
	 loss: 5.0347, MinusLogProbMetric: 5.0347, val_loss: 5.0871, val_MinusLogProbMetric: 5.0871

Epoch 241: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0347 - MinusLogProbMetric: 5.0347 - val_loss: 5.0871 - val_MinusLogProbMetric: 5.0871 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 242/1000
2023-09-12 08:15:05.417 
Epoch 242/1000 
	 loss: 5.0353, MinusLogProbMetric: 5.0353, val_loss: 5.0879, val_MinusLogProbMetric: 5.0879

Epoch 242: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0353 - MinusLogProbMetric: 5.0353 - val_loss: 5.0879 - val_MinusLogProbMetric: 5.0879 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 243/1000
2023-09-12 08:15:16.791 
Epoch 243/1000 
	 loss: 5.0349, MinusLogProbMetric: 5.0349, val_loss: 5.0904, val_MinusLogProbMetric: 5.0904

Epoch 243: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0349 - MinusLogProbMetric: 5.0349 - val_loss: 5.0904 - val_MinusLogProbMetric: 5.0904 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 244/1000
2023-09-12 08:15:28.154 
Epoch 244/1000 
	 loss: 5.0345, MinusLogProbMetric: 5.0345, val_loss: 5.0856, val_MinusLogProbMetric: 5.0856

Epoch 244: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0345 - MinusLogProbMetric: 5.0345 - val_loss: 5.0856 - val_MinusLogProbMetric: 5.0856 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 245/1000
2023-09-12 08:15:39.542 
Epoch 245/1000 
	 loss: 5.0347, MinusLogProbMetric: 5.0347, val_loss: 5.0952, val_MinusLogProbMetric: 5.0952

Epoch 245: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0347 - MinusLogProbMetric: 5.0347 - val_loss: 5.0952 - val_MinusLogProbMetric: 5.0952 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 246/1000
2023-09-12 08:15:50.755 
Epoch 246/1000 
	 loss: 5.0366, MinusLogProbMetric: 5.0366, val_loss: 5.0923, val_MinusLogProbMetric: 5.0923

Epoch 246: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0366 - MinusLogProbMetric: 5.0366 - val_loss: 5.0923 - val_MinusLogProbMetric: 5.0923 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 247/1000
2023-09-12 08:16:02.069 
Epoch 247/1000 
	 loss: 5.0345, MinusLogProbMetric: 5.0345, val_loss: 5.0910, val_MinusLogProbMetric: 5.0910

Epoch 247: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0345 - MinusLogProbMetric: 5.0345 - val_loss: 5.0910 - val_MinusLogProbMetric: 5.0910 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 248/1000
2023-09-12 08:16:13.320 
Epoch 248/1000 
	 loss: 5.0338, MinusLogProbMetric: 5.0338, val_loss: 5.0981, val_MinusLogProbMetric: 5.0981

Epoch 248: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0338 - MinusLogProbMetric: 5.0338 - val_loss: 5.0981 - val_MinusLogProbMetric: 5.0981 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 249/1000
2023-09-12 08:16:23.825 
Epoch 249/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.1086, val_MinusLogProbMetric: 5.1086

Epoch 249: val_loss did not improve from 5.08359
196/196 - 10s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.1086 - val_MinusLogProbMetric: 5.1086 - lr: 5.0000e-04 - 10s/epoch - 54ms/step
Epoch 250/1000
2023-09-12 08:16:34.657 
Epoch 250/1000 
	 loss: 5.0355, MinusLogProbMetric: 5.0355, val_loss: 5.0987, val_MinusLogProbMetric: 5.0987

Epoch 250: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0355 - MinusLogProbMetric: 5.0355 - val_loss: 5.0987 - val_MinusLogProbMetric: 5.0987 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 251/1000
2023-09-12 08:16:45.807 
Epoch 251/1000 
	 loss: 5.0353, MinusLogProbMetric: 5.0353, val_loss: 5.0906, val_MinusLogProbMetric: 5.0906

Epoch 251: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0353 - MinusLogProbMetric: 5.0353 - val_loss: 5.0906 - val_MinusLogProbMetric: 5.0906 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 252/1000
2023-09-12 08:16:57.212 
Epoch 252/1000 
	 loss: 5.0338, MinusLogProbMetric: 5.0338, val_loss: 5.0938, val_MinusLogProbMetric: 5.0938

Epoch 252: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0338 - MinusLogProbMetric: 5.0338 - val_loss: 5.0938 - val_MinusLogProbMetric: 5.0938 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 253/1000
2023-09-12 08:17:08.489 
Epoch 253/1000 
	 loss: 5.0336, MinusLogProbMetric: 5.0336, val_loss: 5.0949, val_MinusLogProbMetric: 5.0949

Epoch 253: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0336 - MinusLogProbMetric: 5.0336 - val_loss: 5.0949 - val_MinusLogProbMetric: 5.0949 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 254/1000
2023-09-12 08:17:19.677 
Epoch 254/1000 
	 loss: 5.0351, MinusLogProbMetric: 5.0351, val_loss: 5.0868, val_MinusLogProbMetric: 5.0868

Epoch 254: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0351 - MinusLogProbMetric: 5.0351 - val_loss: 5.0868 - val_MinusLogProbMetric: 5.0868 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 255/1000
2023-09-12 08:17:31.001 
Epoch 255/1000 
	 loss: 5.0341, MinusLogProbMetric: 5.0341, val_loss: 5.0876, val_MinusLogProbMetric: 5.0876

Epoch 255: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0341 - MinusLogProbMetric: 5.0341 - val_loss: 5.0876 - val_MinusLogProbMetric: 5.0876 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 256/1000
2023-09-12 08:17:42.415 
Epoch 256/1000 
	 loss: 5.0326, MinusLogProbMetric: 5.0326, val_loss: 5.0862, val_MinusLogProbMetric: 5.0862

Epoch 256: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0326 - MinusLogProbMetric: 5.0326 - val_loss: 5.0862 - val_MinusLogProbMetric: 5.0862 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 257/1000
2023-09-12 08:17:53.776 
Epoch 257/1000 
	 loss: 5.0348, MinusLogProbMetric: 5.0348, val_loss: 5.0955, val_MinusLogProbMetric: 5.0955

Epoch 257: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0348 - MinusLogProbMetric: 5.0348 - val_loss: 5.0955 - val_MinusLogProbMetric: 5.0955 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 258/1000
2023-09-12 08:18:05.046 
Epoch 258/1000 
	 loss: 5.0349, MinusLogProbMetric: 5.0349, val_loss: 5.0905, val_MinusLogProbMetric: 5.0905

Epoch 258: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0349 - MinusLogProbMetric: 5.0349 - val_loss: 5.0905 - val_MinusLogProbMetric: 5.0905 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 259/1000
2023-09-12 08:18:16.446 
Epoch 259/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.0894, val_MinusLogProbMetric: 5.0894

Epoch 259: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.0894 - val_MinusLogProbMetric: 5.0894 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 260/1000
2023-09-12 08:18:27.766 
Epoch 260/1000 
	 loss: 5.0345, MinusLogProbMetric: 5.0345, val_loss: 5.0991, val_MinusLogProbMetric: 5.0991

Epoch 260: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0345 - MinusLogProbMetric: 5.0345 - val_loss: 5.0991 - val_MinusLogProbMetric: 5.0991 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 261/1000
2023-09-12 08:18:38.761 
Epoch 261/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.0994, val_MinusLogProbMetric: 5.0994

Epoch 261: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.0994 - val_MinusLogProbMetric: 5.0994 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 262/1000
2023-09-12 08:18:48.777 
Epoch 262/1000 
	 loss: 5.0335, MinusLogProbMetric: 5.0335, val_loss: 5.0891, val_MinusLogProbMetric: 5.0891

Epoch 262: val_loss did not improve from 5.08359
196/196 - 10s - loss: 5.0335 - MinusLogProbMetric: 5.0335 - val_loss: 5.0891 - val_MinusLogProbMetric: 5.0891 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 263/1000
2023-09-12 08:18:58.164 
Epoch 263/1000 
	 loss: 5.0329, MinusLogProbMetric: 5.0329, val_loss: 5.0915, val_MinusLogProbMetric: 5.0915

Epoch 263: val_loss did not improve from 5.08359
196/196 - 9s - loss: 5.0329 - MinusLogProbMetric: 5.0329 - val_loss: 5.0915 - val_MinusLogProbMetric: 5.0915 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 264/1000
2023-09-12 08:19:07.512 
Epoch 264/1000 
	 loss: 5.0311, MinusLogProbMetric: 5.0311, val_loss: 5.0879, val_MinusLogProbMetric: 5.0879

Epoch 264: val_loss did not improve from 5.08359
196/196 - 9s - loss: 5.0311 - MinusLogProbMetric: 5.0311 - val_loss: 5.0879 - val_MinusLogProbMetric: 5.0879 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 265/1000
2023-09-12 08:19:16.877 
Epoch 265/1000 
	 loss: 5.0323, MinusLogProbMetric: 5.0323, val_loss: 5.0890, val_MinusLogProbMetric: 5.0890

Epoch 265: val_loss did not improve from 5.08359
196/196 - 9s - loss: 5.0323 - MinusLogProbMetric: 5.0323 - val_loss: 5.0890 - val_MinusLogProbMetric: 5.0890 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 266/1000
2023-09-12 08:19:26.477 
Epoch 266/1000 
	 loss: 5.0331, MinusLogProbMetric: 5.0331, val_loss: 5.0863, val_MinusLogProbMetric: 5.0863

Epoch 266: val_loss did not improve from 5.08359
196/196 - 10s - loss: 5.0331 - MinusLogProbMetric: 5.0331 - val_loss: 5.0863 - val_MinusLogProbMetric: 5.0863 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 267/1000
2023-09-12 08:19:37.904 
Epoch 267/1000 
	 loss: 5.0323, MinusLogProbMetric: 5.0323, val_loss: 5.0902, val_MinusLogProbMetric: 5.0902

Epoch 267: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0323 - MinusLogProbMetric: 5.0323 - val_loss: 5.0902 - val_MinusLogProbMetric: 5.0902 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 268/1000
2023-09-12 08:19:49.239 
Epoch 268/1000 
	 loss: 5.0318, MinusLogProbMetric: 5.0318, val_loss: 5.0995, val_MinusLogProbMetric: 5.0995

Epoch 268: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0318 - MinusLogProbMetric: 5.0318 - val_loss: 5.0995 - val_MinusLogProbMetric: 5.0995 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 269/1000
2023-09-12 08:20:00.787 
Epoch 269/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.0918, val_MinusLogProbMetric: 5.0918

Epoch 269: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.0918 - val_MinusLogProbMetric: 5.0918 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 270/1000
2023-09-12 08:20:12.334 
Epoch 270/1000 
	 loss: 5.0317, MinusLogProbMetric: 5.0317, val_loss: 5.0954, val_MinusLogProbMetric: 5.0954

Epoch 270: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0317 - MinusLogProbMetric: 5.0317 - val_loss: 5.0954 - val_MinusLogProbMetric: 5.0954 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 271/1000
2023-09-12 08:20:23.628 
Epoch 271/1000 
	 loss: 5.0339, MinusLogProbMetric: 5.0339, val_loss: 5.0922, val_MinusLogProbMetric: 5.0922

Epoch 271: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0339 - MinusLogProbMetric: 5.0339 - val_loss: 5.0922 - val_MinusLogProbMetric: 5.0922 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 272/1000
2023-09-12 08:20:35.200 
Epoch 272/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.0852, val_MinusLogProbMetric: 5.0852

Epoch 272: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.0852 - val_MinusLogProbMetric: 5.0852 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 273/1000
2023-09-12 08:20:46.762 
Epoch 273/1000 
	 loss: 5.0299, MinusLogProbMetric: 5.0299, val_loss: 5.0954, val_MinusLogProbMetric: 5.0954

Epoch 273: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0299 - MinusLogProbMetric: 5.0299 - val_loss: 5.0954 - val_MinusLogProbMetric: 5.0954 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 274/1000
2023-09-12 08:20:57.704 
Epoch 274/1000 
	 loss: 5.0313, MinusLogProbMetric: 5.0313, val_loss: 5.0893, val_MinusLogProbMetric: 5.0893

Epoch 274: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0313 - MinusLogProbMetric: 5.0313 - val_loss: 5.0893 - val_MinusLogProbMetric: 5.0893 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 275/1000
2023-09-12 08:21:07.471 
Epoch 275/1000 
	 loss: 5.0314, MinusLogProbMetric: 5.0314, val_loss: 5.0859, val_MinusLogProbMetric: 5.0859

Epoch 275: val_loss did not improve from 5.08359
196/196 - 10s - loss: 5.0314 - MinusLogProbMetric: 5.0314 - val_loss: 5.0859 - val_MinusLogProbMetric: 5.0859 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 276/1000
2023-09-12 08:21:17.282 
Epoch 276/1000 
	 loss: 5.0311, MinusLogProbMetric: 5.0311, val_loss: 5.1002, val_MinusLogProbMetric: 5.1002

Epoch 276: val_loss did not improve from 5.08359
196/196 - 10s - loss: 5.0311 - MinusLogProbMetric: 5.0311 - val_loss: 5.1002 - val_MinusLogProbMetric: 5.1002 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 277/1000
2023-09-12 08:21:27.955 
Epoch 277/1000 
	 loss: 5.0304, MinusLogProbMetric: 5.0304, val_loss: 5.0848, val_MinusLogProbMetric: 5.0848

Epoch 277: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0304 - MinusLogProbMetric: 5.0304 - val_loss: 5.0848 - val_MinusLogProbMetric: 5.0848 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 278/1000
2023-09-12 08:21:38.334 
Epoch 278/1000 
	 loss: 5.0306, MinusLogProbMetric: 5.0306, val_loss: 5.0896, val_MinusLogProbMetric: 5.0896

Epoch 278: val_loss did not improve from 5.08359
196/196 - 10s - loss: 5.0306 - MinusLogProbMetric: 5.0306 - val_loss: 5.0896 - val_MinusLogProbMetric: 5.0896 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 279/1000
2023-09-12 08:21:49.464 
Epoch 279/1000 
	 loss: 5.0306, MinusLogProbMetric: 5.0306, val_loss: 5.0907, val_MinusLogProbMetric: 5.0907

Epoch 279: val_loss did not improve from 5.08359
196/196 - 11s - loss: 5.0306 - MinusLogProbMetric: 5.0306 - val_loss: 5.0907 - val_MinusLogProbMetric: 5.0907 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 280/1000
2023-09-12 08:22:01.180 
Epoch 280/1000 
	 loss: 5.0310, MinusLogProbMetric: 5.0310, val_loss: 5.0955, val_MinusLogProbMetric: 5.0955

Epoch 280: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0310 - MinusLogProbMetric: 5.0310 - val_loss: 5.0955 - val_MinusLogProbMetric: 5.0955 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-12 08:22:12.861 
Epoch 281/1000 
	 loss: 5.0307, MinusLogProbMetric: 5.0307, val_loss: 5.0967, val_MinusLogProbMetric: 5.0967

Epoch 281: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0307 - MinusLogProbMetric: 5.0307 - val_loss: 5.0967 - val_MinusLogProbMetric: 5.0967 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 282/1000
2023-09-12 08:22:24.497 
Epoch 282/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.0912, val_MinusLogProbMetric: 5.0912

Epoch 282: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.0912 - val_MinusLogProbMetric: 5.0912 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 283/1000
2023-09-12 08:22:36.264 
Epoch 283/1000 
	 loss: 5.0303, MinusLogProbMetric: 5.0303, val_loss: 5.0902, val_MinusLogProbMetric: 5.0902

Epoch 283: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0303 - MinusLogProbMetric: 5.0303 - val_loss: 5.0902 - val_MinusLogProbMetric: 5.0902 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 284/1000
2023-09-12 08:22:47.945 
Epoch 284/1000 
	 loss: 5.0303, MinusLogProbMetric: 5.0303, val_loss: 5.0912, val_MinusLogProbMetric: 5.0912

Epoch 284: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0303 - MinusLogProbMetric: 5.0303 - val_loss: 5.0912 - val_MinusLogProbMetric: 5.0912 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 285/1000
2023-09-12 08:22:59.560 
Epoch 285/1000 
	 loss: 5.0314, MinusLogProbMetric: 5.0314, val_loss: 5.0950, val_MinusLogProbMetric: 5.0950

Epoch 285: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0314 - MinusLogProbMetric: 5.0314 - val_loss: 5.0950 - val_MinusLogProbMetric: 5.0950 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 286/1000
2023-09-12 08:23:11.225 
Epoch 286/1000 
	 loss: 5.0304, MinusLogProbMetric: 5.0304, val_loss: 5.0910, val_MinusLogProbMetric: 5.0910

Epoch 286: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0304 - MinusLogProbMetric: 5.0304 - val_loss: 5.0910 - val_MinusLogProbMetric: 5.0910 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 287/1000
2023-09-12 08:23:22.916 
Epoch 287/1000 
	 loss: 5.0304, MinusLogProbMetric: 5.0304, val_loss: 5.1002, val_MinusLogProbMetric: 5.1002

Epoch 287: val_loss did not improve from 5.08359
196/196 - 12s - loss: 5.0304 - MinusLogProbMetric: 5.0304 - val_loss: 5.1002 - val_MinusLogProbMetric: 5.1002 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 288/1000
2023-09-12 08:23:34.694 
Epoch 288/1000 
	 loss: 5.0309, MinusLogProbMetric: 5.0309, val_loss: 5.0951, val_MinusLogProbMetric: 5.0951

Epoch 288: val_loss did not improve from 5.08359
Restoring model weights from the end of the best epoch: 188.
196/196 - 12s - loss: 5.0309 - MinusLogProbMetric: 5.0309 - val_loss: 5.0951 - val_MinusLogProbMetric: 5.0951 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 288: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 4.637305773096159 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 3.2472783649573103 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.419793923967518 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.5890736470464617 seconds.
Training succeeded with seed 187.
Model trained in 3319.83 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Metrics computed in 203.85 s.
Plots done in 33.14 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 236.99 s.
===========
Run 87/360 done in 3558.21 s.
===========

Directory ../../results/MsplineN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

===========
Generating train data for run 96.
===========
Train data generated in 0.11 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_96/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_96/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_96/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_96
self.data_kwargs: {'seed': 440}
self.x_data: [[5.9069815  7.5444255  6.3762054  ... 9.075856   0.9364161  0.80815375]
 [4.741565   5.111489   0.30516613 ... 6.3444896  2.1198235  1.1959152 ]
 [5.3968034  7.4016695  5.7313123  ... 9.37714    0.68808633 0.8965562 ]
 ...
 [5.630116   6.508466   4.560816   ... 9.354164   0.5113934  0.8420493 ]
 [3.8550687  6.072236   0.15075347 ... 6.0798836  1.9062192  1.6859822 ]
 [5.6194196  7.5907955  5.8847475  ... 9.269651   0.46180454 0.8692333 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_37 (InputLayer)       [(None, 16)]              0         
                                                                 
 log_prob_layer_12 (LogProbL  (None,)                  559712    
 ayer)                                                           
                                                                 
=================================================================
Total params: 559,712
Trainable params: 559,712
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_12/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_12'")
self.model: <keras.engine.functional.Functional object at 0x7fc61b430d30>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc61b165270>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc61b165270>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc61b165b40>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc61b166800>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc61b166d70>, <keras.callbacks.ModelCheckpoint object at 0x7fc61b166e30>, <keras.callbacks.EarlyStopping object at 0x7fc61b1670a0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc61b1670d0>, <keras.callbacks.TerminateOnNaN object at 0x7fc61b166d10>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.9388056 ,  6.6011305 ,  7.1936936 , ...,  9.376897  ,
        -0.20441407,  0.997946  ],
       [ 5.7592807 ,  7.4562755 ,  6.073807  , ...,  8.982617  ,
         1.3178213 ,  0.7693994 ],
       [ 4.825065  ,  5.849577  ,  0.14626749, ...,  6.3837705 ,
         2.132065  ,  1.518469  ],
       ...,
       [ 5.615609  ,  7.2656503 ,  4.8600593 , ...,  9.083482  ,
         0.68300927,  1.0057955 ],
       [ 4.1834145 ,  6.0909553 ,  0.23574165, ...,  7.763974  ,
         1.9834036 ,  1.2137753 ],
       [ 3.9210687 ,  6.0211887 ,  0.28002483, ...,  6.9610376 ,
         1.7232312 ,  1.247894  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_96/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 96/360 with hyperparameters:
timestamp = 2023-09-12 08:27:32.627340
ndims = 16
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 559712
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.9069815  7.5444255  6.3762054  5.732217   4.629946   6.4001193
 4.3642464  8.792809   9.021455   4.047819   7.801147   5.4133105
 5.6628323  9.075856   0.9364161  0.80815375]
Epoch 1/1000
2023-09-12 08:28:01.243 
Epoch 1/1000 
	 loss: 18.2687, MinusLogProbMetric: 18.2687, val_loss: 6.3120, val_MinusLogProbMetric: 6.3120

Epoch 1: val_loss improved from inf to 6.31195, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 29s - loss: 18.2687 - MinusLogProbMetric: 18.2687 - val_loss: 6.3120 - val_MinusLogProbMetric: 6.3120 - lr: 0.0010 - 29s/epoch - 146ms/step
Epoch 2/1000
2023-09-12 08:28:13.168 
Epoch 2/1000 
	 loss: 5.8432, MinusLogProbMetric: 5.8432, val_loss: 5.6085, val_MinusLogProbMetric: 5.6085

Epoch 2: val_loss improved from 6.31195 to 5.60849, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.8432 - MinusLogProbMetric: 5.8432 - val_loss: 5.6085 - val_MinusLogProbMetric: 5.6085 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 3/1000
2023-09-12 08:28:25.323 
Epoch 3/1000 
	 loss: 5.5046, MinusLogProbMetric: 5.5046, val_loss: 5.7599, val_MinusLogProbMetric: 5.7599

Epoch 3: val_loss did not improve from 5.60849
196/196 - 12s - loss: 5.5046 - MinusLogProbMetric: 5.5046 - val_loss: 5.7599 - val_MinusLogProbMetric: 5.7599 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-12 08:28:37.163 
Epoch 4/1000 
	 loss: 5.4017, MinusLogProbMetric: 5.4017, val_loss: 5.3409, val_MinusLogProbMetric: 5.3409

Epoch 4: val_loss improved from 5.60849 to 5.34091, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 13s - loss: 5.4017 - MinusLogProbMetric: 5.4017 - val_loss: 5.3409 - val_MinusLogProbMetric: 5.3409 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 5/1000
2023-09-12 08:28:49.970 
Epoch 5/1000 
	 loss: 5.3495, MinusLogProbMetric: 5.3495, val_loss: 5.5954, val_MinusLogProbMetric: 5.5954

Epoch 5: val_loss did not improve from 5.34091
196/196 - 12s - loss: 5.3495 - MinusLogProbMetric: 5.3495 - val_loss: 5.5954 - val_MinusLogProbMetric: 5.5954 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 6/1000
2023-09-12 08:29:01.709 
Epoch 6/1000 
	 loss: 5.3027, MinusLogProbMetric: 5.3027, val_loss: 5.3073, val_MinusLogProbMetric: 5.3073

Epoch 6: val_loss improved from 5.34091 to 5.30732, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.3027 - MinusLogProbMetric: 5.3027 - val_loss: 5.3073 - val_MinusLogProbMetric: 5.3073 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-12 08:29:13.753 
Epoch 7/1000 
	 loss: 5.2803, MinusLogProbMetric: 5.2803, val_loss: 5.2089, val_MinusLogProbMetric: 5.2089

Epoch 7: val_loss improved from 5.30732 to 5.20894, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.2803 - MinusLogProbMetric: 5.2803 - val_loss: 5.2089 - val_MinusLogProbMetric: 5.2089 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 8/1000
2023-09-12 08:29:25.709 
Epoch 8/1000 
	 loss: 5.2676, MinusLogProbMetric: 5.2676, val_loss: 5.5069, val_MinusLogProbMetric: 5.5069

Epoch 8: val_loss did not improve from 5.20894
196/196 - 12s - loss: 5.2676 - MinusLogProbMetric: 5.2676 - val_loss: 5.5069 - val_MinusLogProbMetric: 5.5069 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-12 08:29:37.426 
Epoch 9/1000 
	 loss: 5.2497, MinusLogProbMetric: 5.2497, val_loss: 5.3733, val_MinusLogProbMetric: 5.3733

Epoch 9: val_loss did not improve from 5.20894
196/196 - 12s - loss: 5.2497 - MinusLogProbMetric: 5.2497 - val_loss: 5.3733 - val_MinusLogProbMetric: 5.3733 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 10/1000
2023-09-12 08:29:49.173 
Epoch 10/1000 
	 loss: 5.2255, MinusLogProbMetric: 5.2255, val_loss: 5.2702, val_MinusLogProbMetric: 5.2702

Epoch 10: val_loss did not improve from 5.20894
196/196 - 12s - loss: 5.2255 - MinusLogProbMetric: 5.2255 - val_loss: 5.2702 - val_MinusLogProbMetric: 5.2702 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-12 08:30:00.990 
Epoch 11/1000 
	 loss: 5.2266, MinusLogProbMetric: 5.2266, val_loss: 5.1626, val_MinusLogProbMetric: 5.1626

Epoch 11: val_loss improved from 5.20894 to 5.16265, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 13s - loss: 5.2266 - MinusLogProbMetric: 5.2266 - val_loss: 5.1626 - val_MinusLogProbMetric: 5.1626 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 12/1000
2023-09-12 08:30:13.792 
Epoch 12/1000 
	 loss: 5.2104, MinusLogProbMetric: 5.2104, val_loss: 5.2177, val_MinusLogProbMetric: 5.2177

Epoch 12: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.2104 - MinusLogProbMetric: 5.2104 - val_loss: 5.2177 - val_MinusLogProbMetric: 5.2177 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-12 08:30:25.563 
Epoch 13/1000 
	 loss: 5.2135, MinusLogProbMetric: 5.2135, val_loss: 5.1917, val_MinusLogProbMetric: 5.1917

Epoch 13: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.2135 - MinusLogProbMetric: 5.2135 - val_loss: 5.1917 - val_MinusLogProbMetric: 5.1917 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 08:30:37.220 
Epoch 14/1000 
	 loss: 5.2102, MinusLogProbMetric: 5.2102, val_loss: 5.3625, val_MinusLogProbMetric: 5.3625

Epoch 14: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.2102 - MinusLogProbMetric: 5.2102 - val_loss: 5.3625 - val_MinusLogProbMetric: 5.3625 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-12 08:30:49.046 
Epoch 15/1000 
	 loss: 5.2011, MinusLogProbMetric: 5.2011, val_loss: 5.2291, val_MinusLogProbMetric: 5.2291

Epoch 15: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.2011 - MinusLogProbMetric: 5.2011 - val_loss: 5.2291 - val_MinusLogProbMetric: 5.2291 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-12 08:31:00.770 
Epoch 16/1000 
	 loss: 5.1790, MinusLogProbMetric: 5.1790, val_loss: 5.2476, val_MinusLogProbMetric: 5.2476

Epoch 16: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1790 - MinusLogProbMetric: 5.1790 - val_loss: 5.2476 - val_MinusLogProbMetric: 5.2476 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 08:31:12.535 
Epoch 17/1000 
	 loss: 5.1846, MinusLogProbMetric: 5.1846, val_loss: 5.3058, val_MinusLogProbMetric: 5.3058

Epoch 17: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1846 - MinusLogProbMetric: 5.1846 - val_loss: 5.3058 - val_MinusLogProbMetric: 5.3058 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-12 08:31:24.311 
Epoch 18/1000 
	 loss: 5.1800, MinusLogProbMetric: 5.1800, val_loss: 5.2102, val_MinusLogProbMetric: 5.2102

Epoch 18: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1800 - MinusLogProbMetric: 5.1800 - val_loss: 5.2102 - val_MinusLogProbMetric: 5.2102 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 08:31:35.934 
Epoch 19/1000 
	 loss: 5.1875, MinusLogProbMetric: 5.1875, val_loss: 5.3676, val_MinusLogProbMetric: 5.3676

Epoch 19: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1875 - MinusLogProbMetric: 5.1875 - val_loss: 5.3676 - val_MinusLogProbMetric: 5.3676 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 20/1000
2023-09-12 08:31:47.566 
Epoch 20/1000 
	 loss: 5.1764, MinusLogProbMetric: 5.1764, val_loss: 5.1751, val_MinusLogProbMetric: 5.1751

Epoch 20: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1764 - MinusLogProbMetric: 5.1764 - val_loss: 5.1751 - val_MinusLogProbMetric: 5.1751 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 08:31:59.199 
Epoch 21/1000 
	 loss: 5.1580, MinusLogProbMetric: 5.1580, val_loss: 5.1657, val_MinusLogProbMetric: 5.1657

Epoch 21: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1580 - MinusLogProbMetric: 5.1580 - val_loss: 5.1657 - val_MinusLogProbMetric: 5.1657 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 08:32:10.885 
Epoch 22/1000 
	 loss: 5.1469, MinusLogProbMetric: 5.1469, val_loss: 5.2247, val_MinusLogProbMetric: 5.2247

Epoch 22: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1469 - MinusLogProbMetric: 5.1469 - val_loss: 5.2247 - val_MinusLogProbMetric: 5.2247 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 08:32:22.612 
Epoch 23/1000 
	 loss: 5.1548, MinusLogProbMetric: 5.1548, val_loss: 5.2002, val_MinusLogProbMetric: 5.2002

Epoch 23: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1548 - MinusLogProbMetric: 5.1548 - val_loss: 5.2002 - val_MinusLogProbMetric: 5.2002 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-12 08:32:34.359 
Epoch 24/1000 
	 loss: 5.1434, MinusLogProbMetric: 5.1434, val_loss: 5.1929, val_MinusLogProbMetric: 5.1929

Epoch 24: val_loss did not improve from 5.16265
196/196 - 12s - loss: 5.1434 - MinusLogProbMetric: 5.1434 - val_loss: 5.1929 - val_MinusLogProbMetric: 5.1929 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-12 08:32:46.008 
Epoch 25/1000 
	 loss: 5.1374, MinusLogProbMetric: 5.1374, val_loss: 5.1613, val_MinusLogProbMetric: 5.1613

Epoch 25: val_loss improved from 5.16265 to 5.16135, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.1374 - MinusLogProbMetric: 5.1374 - val_loss: 5.1613 - val_MinusLogProbMetric: 5.1613 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 08:32:57.749 
Epoch 26/1000 
	 loss: 5.1387, MinusLogProbMetric: 5.1387, val_loss: 5.1807, val_MinusLogProbMetric: 5.1807

Epoch 26: val_loss did not improve from 5.16135
196/196 - 12s - loss: 5.1387 - MinusLogProbMetric: 5.1387 - val_loss: 5.1807 - val_MinusLogProbMetric: 5.1807 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 27/1000
2023-09-12 08:33:09.443 
Epoch 27/1000 
	 loss: 5.1380, MinusLogProbMetric: 5.1380, val_loss: 5.1952, val_MinusLogProbMetric: 5.1952

Epoch 27: val_loss did not improve from 5.16135
196/196 - 12s - loss: 5.1380 - MinusLogProbMetric: 5.1380 - val_loss: 5.1952 - val_MinusLogProbMetric: 5.1952 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-12 08:33:21.145 
Epoch 28/1000 
	 loss: 5.1292, MinusLogProbMetric: 5.1292, val_loss: 5.1425, val_MinusLogProbMetric: 5.1425

Epoch 28: val_loss improved from 5.16135 to 5.14248, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.1292 - MinusLogProbMetric: 5.1292 - val_loss: 5.1425 - val_MinusLogProbMetric: 5.1425 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 29/1000
2023-09-12 08:33:32.938 
Epoch 29/1000 
	 loss: 5.1351, MinusLogProbMetric: 5.1351, val_loss: 5.1760, val_MinusLogProbMetric: 5.1760

Epoch 29: val_loss did not improve from 5.14248
196/196 - 12s - loss: 5.1351 - MinusLogProbMetric: 5.1351 - val_loss: 5.1760 - val_MinusLogProbMetric: 5.1760 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 30/1000
2023-09-12 08:33:44.502 
Epoch 30/1000 
	 loss: 5.1168, MinusLogProbMetric: 5.1168, val_loss: 5.2263, val_MinusLogProbMetric: 5.2263

Epoch 30: val_loss did not improve from 5.14248
196/196 - 12s - loss: 5.1168 - MinusLogProbMetric: 5.1168 - val_loss: 5.2263 - val_MinusLogProbMetric: 5.2263 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 31/1000
2023-09-12 08:33:56.254 
Epoch 31/1000 
	 loss: 5.1369, MinusLogProbMetric: 5.1369, val_loss: 5.1829, val_MinusLogProbMetric: 5.1829

Epoch 31: val_loss did not improve from 5.14248
196/196 - 12s - loss: 5.1369 - MinusLogProbMetric: 5.1369 - val_loss: 5.1829 - val_MinusLogProbMetric: 5.1829 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-12 08:34:07.904 
Epoch 32/1000 
	 loss: 5.1292, MinusLogProbMetric: 5.1292, val_loss: 5.1573, val_MinusLogProbMetric: 5.1573

Epoch 32: val_loss did not improve from 5.14248
196/196 - 12s - loss: 5.1292 - MinusLogProbMetric: 5.1292 - val_loss: 5.1573 - val_MinusLogProbMetric: 5.1573 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 33/1000
2023-09-12 08:34:19.461 
Epoch 33/1000 
	 loss: 5.1211, MinusLogProbMetric: 5.1211, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 33: val_loss improved from 5.14248 to 5.12583, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.1211 - MinusLogProbMetric: 5.1211 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 34/1000
2023-09-12 08:34:31.116 
Epoch 34/1000 
	 loss: 5.1081, MinusLogProbMetric: 5.1081, val_loss: 5.1188, val_MinusLogProbMetric: 5.1188

Epoch 34: val_loss improved from 5.12583 to 5.11876, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.1081 - MinusLogProbMetric: 5.1081 - val_loss: 5.1188 - val_MinusLogProbMetric: 5.1188 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 35/1000
2023-09-12 08:34:42.738 
Epoch 35/1000 
	 loss: 5.1159, MinusLogProbMetric: 5.1159, val_loss: 5.1373, val_MinusLogProbMetric: 5.1373

Epoch 35: val_loss did not improve from 5.11876
196/196 - 12s - loss: 5.1159 - MinusLogProbMetric: 5.1159 - val_loss: 5.1373 - val_MinusLogProbMetric: 5.1373 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 36/1000
2023-09-12 08:34:54.424 
Epoch 36/1000 
	 loss: 5.1219, MinusLogProbMetric: 5.1219, val_loss: 5.1266, val_MinusLogProbMetric: 5.1266

Epoch 36: val_loss did not improve from 5.11876
196/196 - 12s - loss: 5.1219 - MinusLogProbMetric: 5.1219 - val_loss: 5.1266 - val_MinusLogProbMetric: 5.1266 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 08:35:06.149 
Epoch 37/1000 
	 loss: 5.1100, MinusLogProbMetric: 5.1100, val_loss: 5.1983, val_MinusLogProbMetric: 5.1983

Epoch 37: val_loss did not improve from 5.11876
196/196 - 12s - loss: 5.1100 - MinusLogProbMetric: 5.1100 - val_loss: 5.1983 - val_MinusLogProbMetric: 5.1983 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 38/1000
2023-09-12 08:35:17.821 
Epoch 38/1000 
	 loss: 5.1106, MinusLogProbMetric: 5.1106, val_loss: 5.1650, val_MinusLogProbMetric: 5.1650

Epoch 38: val_loss did not improve from 5.11876
196/196 - 12s - loss: 5.1106 - MinusLogProbMetric: 5.1106 - val_loss: 5.1650 - val_MinusLogProbMetric: 5.1650 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 08:35:29.314 
Epoch 39/1000 
	 loss: 5.1119, MinusLogProbMetric: 5.1119, val_loss: 5.1169, val_MinusLogProbMetric: 5.1169

Epoch 39: val_loss improved from 5.11876 to 5.11686, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.1119 - MinusLogProbMetric: 5.1119 - val_loss: 5.1169 - val_MinusLogProbMetric: 5.1169 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-12 08:35:41.057 
Epoch 40/1000 
	 loss: 5.1021, MinusLogProbMetric: 5.1021, val_loss: 5.2601, val_MinusLogProbMetric: 5.2601

Epoch 40: val_loss did not improve from 5.11686
196/196 - 12s - loss: 5.1021 - MinusLogProbMetric: 5.1021 - val_loss: 5.2601 - val_MinusLogProbMetric: 5.2601 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 41/1000
2023-09-12 08:35:52.614 
Epoch 41/1000 
	 loss: 5.1118, MinusLogProbMetric: 5.1118, val_loss: 5.1122, val_MinusLogProbMetric: 5.1122

Epoch 41: val_loss improved from 5.11686 to 5.11223, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.1118 - MinusLogProbMetric: 5.1118 - val_loss: 5.1122 - val_MinusLogProbMetric: 5.1122 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-12 08:36:04.297 
Epoch 42/1000 
	 loss: 5.1052, MinusLogProbMetric: 5.1052, val_loss: 5.2238, val_MinusLogProbMetric: 5.2238

Epoch 42: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.1052 - MinusLogProbMetric: 5.1052 - val_loss: 5.2238 - val_MinusLogProbMetric: 5.2238 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 43/1000
2023-09-12 08:36:15.849 
Epoch 43/1000 
	 loss: 5.1034, MinusLogProbMetric: 5.1034, val_loss: 5.1365, val_MinusLogProbMetric: 5.1365

Epoch 43: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.1034 - MinusLogProbMetric: 5.1034 - val_loss: 5.1365 - val_MinusLogProbMetric: 5.1365 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-12 08:36:27.505 
Epoch 44/1000 
	 loss: 5.1100, MinusLogProbMetric: 5.1100, val_loss: 5.1268, val_MinusLogProbMetric: 5.1268

Epoch 44: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.1100 - MinusLogProbMetric: 5.1100 - val_loss: 5.1268 - val_MinusLogProbMetric: 5.1268 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 45/1000
2023-09-12 08:36:39.127 
Epoch 45/1000 
	 loss: 5.0923, MinusLogProbMetric: 5.0923, val_loss: 5.1925, val_MinusLogProbMetric: 5.1925

Epoch 45: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.0923 - MinusLogProbMetric: 5.0923 - val_loss: 5.1925 - val_MinusLogProbMetric: 5.1925 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 46/1000
2023-09-12 08:36:50.801 
Epoch 46/1000 
	 loss: 5.1090, MinusLogProbMetric: 5.1090, val_loss: 5.1863, val_MinusLogProbMetric: 5.1863

Epoch 46: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.1090 - MinusLogProbMetric: 5.1090 - val_loss: 5.1863 - val_MinusLogProbMetric: 5.1863 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 47/1000
2023-09-12 08:37:02.477 
Epoch 47/1000 
	 loss: 5.0967, MinusLogProbMetric: 5.0967, val_loss: 5.1154, val_MinusLogProbMetric: 5.1154

Epoch 47: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.0967 - MinusLogProbMetric: 5.0967 - val_loss: 5.1154 - val_MinusLogProbMetric: 5.1154 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-12 08:37:14.144 
Epoch 48/1000 
	 loss: 5.0894, MinusLogProbMetric: 5.0894, val_loss: 5.1125, val_MinusLogProbMetric: 5.1125

Epoch 48: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.0894 - MinusLogProbMetric: 5.0894 - val_loss: 5.1125 - val_MinusLogProbMetric: 5.1125 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-12 08:37:25.828 
Epoch 49/1000 
	 loss: 5.0972, MinusLogProbMetric: 5.0972, val_loss: 5.1334, val_MinusLogProbMetric: 5.1334

Epoch 49: val_loss did not improve from 5.11223
196/196 - 12s - loss: 5.0972 - MinusLogProbMetric: 5.0972 - val_loss: 5.1334 - val_MinusLogProbMetric: 5.1334 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-12 08:37:37.262 
Epoch 50/1000 
	 loss: 5.0957, MinusLogProbMetric: 5.0957, val_loss: 5.1101, val_MinusLogProbMetric: 5.1101

Epoch 50: val_loss improved from 5.11223 to 5.11007, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.0957 - MinusLogProbMetric: 5.0957 - val_loss: 5.1101 - val_MinusLogProbMetric: 5.1101 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 51/1000
2023-09-12 08:37:48.301 
Epoch 51/1000 
	 loss: 5.0932, MinusLogProbMetric: 5.0932, val_loss: 5.1099, val_MinusLogProbMetric: 5.1099

Epoch 51: val_loss improved from 5.11007 to 5.10989, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 11s - loss: 5.0932 - MinusLogProbMetric: 5.0932 - val_loss: 5.1099 - val_MinusLogProbMetric: 5.1099 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 52/1000
2023-09-12 08:37:58.245 
Epoch 52/1000 
	 loss: 5.0835, MinusLogProbMetric: 5.0835, val_loss: 5.0999, val_MinusLogProbMetric: 5.0999

Epoch 52: val_loss improved from 5.10989 to 5.09988, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 10s - loss: 5.0835 - MinusLogProbMetric: 5.0835 - val_loss: 5.0999 - val_MinusLogProbMetric: 5.0999 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 53/1000
2023-09-12 08:38:08.525 
Epoch 53/1000 
	 loss: 5.0850, MinusLogProbMetric: 5.0850, val_loss: 5.1148, val_MinusLogProbMetric: 5.1148

Epoch 53: val_loss did not improve from 5.09988
196/196 - 10s - loss: 5.0850 - MinusLogProbMetric: 5.0850 - val_loss: 5.1148 - val_MinusLogProbMetric: 5.1148 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 54/1000
2023-09-12 08:38:18.681 
Epoch 54/1000 
	 loss: 5.0974, MinusLogProbMetric: 5.0974, val_loss: 5.1276, val_MinusLogProbMetric: 5.1276

Epoch 54: val_loss did not improve from 5.09988
196/196 - 10s - loss: 5.0974 - MinusLogProbMetric: 5.0974 - val_loss: 5.1276 - val_MinusLogProbMetric: 5.1276 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 55/1000
2023-09-12 08:38:28.807 
Epoch 55/1000 
	 loss: 5.0893, MinusLogProbMetric: 5.0893, val_loss: 5.1148, val_MinusLogProbMetric: 5.1148

Epoch 55: val_loss did not improve from 5.09988
196/196 - 10s - loss: 5.0893 - MinusLogProbMetric: 5.0893 - val_loss: 5.1148 - val_MinusLogProbMetric: 5.1148 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 56/1000
2023-09-12 08:38:39.351 
Epoch 56/1000 
	 loss: 5.0842, MinusLogProbMetric: 5.0842, val_loss: 5.1072, val_MinusLogProbMetric: 5.1072

Epoch 56: val_loss did not improve from 5.09988
196/196 - 11s - loss: 5.0842 - MinusLogProbMetric: 5.0842 - val_loss: 5.1072 - val_MinusLogProbMetric: 5.1072 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 57/1000
2023-09-12 08:38:50.948 
Epoch 57/1000 
	 loss: 5.0863, MinusLogProbMetric: 5.0863, val_loss: 5.1504, val_MinusLogProbMetric: 5.1504

Epoch 57: val_loss did not improve from 5.09988
196/196 - 12s - loss: 5.0863 - MinusLogProbMetric: 5.0863 - val_loss: 5.1504 - val_MinusLogProbMetric: 5.1504 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 58/1000
2023-09-12 08:39:02.673 
Epoch 58/1000 
	 loss: 5.0824, MinusLogProbMetric: 5.0824, val_loss: 5.1123, val_MinusLogProbMetric: 5.1123

Epoch 58: val_loss did not improve from 5.09988
196/196 - 12s - loss: 5.0824 - MinusLogProbMetric: 5.0824 - val_loss: 5.1123 - val_MinusLogProbMetric: 5.1123 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-12 08:39:14.312 
Epoch 59/1000 
	 loss: 5.0833, MinusLogProbMetric: 5.0833, val_loss: 5.0864, val_MinusLogProbMetric: 5.0864

Epoch 59: val_loss improved from 5.09988 to 5.08645, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_96/weights/best_weights.h5
196/196 - 12s - loss: 5.0833 - MinusLogProbMetric: 5.0833 - val_loss: 5.0864 - val_MinusLogProbMetric: 5.0864 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-12 08:39:26.133 
Epoch 60/1000 
	 loss: 5.0757, MinusLogProbMetric: 5.0757, val_loss: 5.1473, val_MinusLogProbMetric: 5.1473

Epoch 60: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0757 - MinusLogProbMetric: 5.0757 - val_loss: 5.1473 - val_MinusLogProbMetric: 5.1473 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-12 08:39:37.716 
Epoch 61/1000 
	 loss: 5.0859, MinusLogProbMetric: 5.0859, val_loss: 5.0997, val_MinusLogProbMetric: 5.0997

Epoch 61: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0859 - MinusLogProbMetric: 5.0859 - val_loss: 5.0997 - val_MinusLogProbMetric: 5.0997 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 62/1000
2023-09-12 08:39:49.440 
Epoch 62/1000 
	 loss: 5.0779, MinusLogProbMetric: 5.0779, val_loss: 5.1241, val_MinusLogProbMetric: 5.1241

Epoch 62: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0779 - MinusLogProbMetric: 5.0779 - val_loss: 5.1241 - val_MinusLogProbMetric: 5.1241 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-12 08:40:01.220 
Epoch 63/1000 
	 loss: 5.0823, MinusLogProbMetric: 5.0823, val_loss: 5.2023, val_MinusLogProbMetric: 5.2023

Epoch 63: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0823 - MinusLogProbMetric: 5.0823 - val_loss: 5.2023 - val_MinusLogProbMetric: 5.2023 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-12 08:40:12.915 
Epoch 64/1000 
	 loss: 5.0816, MinusLogProbMetric: 5.0816, val_loss: 5.1405, val_MinusLogProbMetric: 5.1405

Epoch 64: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0816 - MinusLogProbMetric: 5.0816 - val_loss: 5.1405 - val_MinusLogProbMetric: 5.1405 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-12 08:40:24.483 
Epoch 65/1000 
	 loss: 5.0809, MinusLogProbMetric: 5.0809, val_loss: 5.1032, val_MinusLogProbMetric: 5.1032

Epoch 65: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0809 - MinusLogProbMetric: 5.0809 - val_loss: 5.1032 - val_MinusLogProbMetric: 5.1032 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 66/1000
2023-09-12 08:40:36.124 
Epoch 66/1000 
	 loss: 5.0826, MinusLogProbMetric: 5.0826, val_loss: 5.1442, val_MinusLogProbMetric: 5.1442

Epoch 66: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0826 - MinusLogProbMetric: 5.0826 - val_loss: 5.1442 - val_MinusLogProbMetric: 5.1442 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-12 08:40:47.799 
Epoch 67/1000 
	 loss: 5.0750, MinusLogProbMetric: 5.0750, val_loss: 5.1017, val_MinusLogProbMetric: 5.1017

Epoch 67: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0750 - MinusLogProbMetric: 5.0750 - val_loss: 5.1017 - val_MinusLogProbMetric: 5.1017 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 68/1000
2023-09-12 08:40:59.422 
Epoch 68/1000 
	 loss: 5.0795, MinusLogProbMetric: 5.0795, val_loss: 5.1235, val_MinusLogProbMetric: 5.1235

Epoch 68: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0795 - MinusLogProbMetric: 5.0795 - val_loss: 5.1235 - val_MinusLogProbMetric: 5.1235 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-12 08:41:11.110 
Epoch 69/1000 
	 loss: 5.0679, MinusLogProbMetric: 5.0679, val_loss: 5.1103, val_MinusLogProbMetric: 5.1103

Epoch 69: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0679 - MinusLogProbMetric: 5.0679 - val_loss: 5.1103 - val_MinusLogProbMetric: 5.1103 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 08:41:22.820 
Epoch 70/1000 
	 loss: 5.0700, MinusLogProbMetric: 5.0700, val_loss: 5.1921, val_MinusLogProbMetric: 5.1921

Epoch 70: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0700 - MinusLogProbMetric: 5.0700 - val_loss: 5.1921 - val_MinusLogProbMetric: 5.1921 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-12 08:41:34.433 
Epoch 71/1000 
	 loss: 5.0686, MinusLogProbMetric: 5.0686, val_loss: 5.1145, val_MinusLogProbMetric: 5.1145

Epoch 71: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0686 - MinusLogProbMetric: 5.0686 - val_loss: 5.1145 - val_MinusLogProbMetric: 5.1145 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 72/1000
2023-09-12 08:41:46.083 
Epoch 72/1000 
	 loss: 5.0726, MinusLogProbMetric: 5.0726, val_loss: 5.1369, val_MinusLogProbMetric: 5.1369

Epoch 72: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0726 - MinusLogProbMetric: 5.0726 - val_loss: 5.1369 - val_MinusLogProbMetric: 5.1369 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 73/1000
2023-09-12 08:41:57.669 
Epoch 73/1000 
	 loss: 5.0779, MinusLogProbMetric: 5.0779, val_loss: 5.1109, val_MinusLogProbMetric: 5.1109

Epoch 73: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0779 - MinusLogProbMetric: 5.0779 - val_loss: 5.1109 - val_MinusLogProbMetric: 5.1109 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 08:42:09.497 
Epoch 74/1000 
	 loss: 5.0668, MinusLogProbMetric: 5.0668, val_loss: 5.1491, val_MinusLogProbMetric: 5.1491

Epoch 74: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0668 - MinusLogProbMetric: 5.0668 - val_loss: 5.1491 - val_MinusLogProbMetric: 5.1491 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-12 08:42:21.205 
Epoch 75/1000 
	 loss: 5.0698, MinusLogProbMetric: 5.0698, val_loss: 5.1620, val_MinusLogProbMetric: 5.1620

Epoch 75: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0698 - MinusLogProbMetric: 5.0698 - val_loss: 5.1620 - val_MinusLogProbMetric: 5.1620 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-12 08:42:32.852 
Epoch 76/1000 
	 loss: 5.0601, MinusLogProbMetric: 5.0601, val_loss: 5.1197, val_MinusLogProbMetric: 5.1197

Epoch 76: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0601 - MinusLogProbMetric: 5.0601 - val_loss: 5.1197 - val_MinusLogProbMetric: 5.1197 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 77/1000
2023-09-12 08:42:44.602 
Epoch 77/1000 
	 loss: 5.0577, MinusLogProbMetric: 5.0577, val_loss: 5.1027, val_MinusLogProbMetric: 5.1027

Epoch 77: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0577 - MinusLogProbMetric: 5.0577 - val_loss: 5.1027 - val_MinusLogProbMetric: 5.1027 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-12 08:42:56.189 
Epoch 78/1000 
	 loss: 5.0575, MinusLogProbMetric: 5.0575, val_loss: 5.1176, val_MinusLogProbMetric: 5.1176

Epoch 78: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0575 - MinusLogProbMetric: 5.0575 - val_loss: 5.1176 - val_MinusLogProbMetric: 5.1176 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 79/1000
2023-09-12 08:43:07.887 
Epoch 79/1000 
	 loss: 5.0630, MinusLogProbMetric: 5.0630, val_loss: 5.1313, val_MinusLogProbMetric: 5.1313

Epoch 79: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0630 - MinusLogProbMetric: 5.0630 - val_loss: 5.1313 - val_MinusLogProbMetric: 5.1313 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 08:43:19.772 
Epoch 80/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1121, val_MinusLogProbMetric: 5.1121

Epoch 80: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1121 - val_MinusLogProbMetric: 5.1121 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 81/1000
2023-09-12 08:43:31.505 
Epoch 81/1000 
	 loss: 5.0697, MinusLogProbMetric: 5.0697, val_loss: 5.1541, val_MinusLogProbMetric: 5.1541

Epoch 81: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0697 - MinusLogProbMetric: 5.0697 - val_loss: 5.1541 - val_MinusLogProbMetric: 5.1541 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 82/1000
2023-09-12 08:43:43.229 
Epoch 82/1000 
	 loss: 5.0590, MinusLogProbMetric: 5.0590, val_loss: 5.1099, val_MinusLogProbMetric: 5.1099

Epoch 82: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0590 - MinusLogProbMetric: 5.0590 - val_loss: 5.1099 - val_MinusLogProbMetric: 5.1099 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-12 08:43:54.861 
Epoch 83/1000 
	 loss: 5.0569, MinusLogProbMetric: 5.0569, val_loss: 5.1281, val_MinusLogProbMetric: 5.1281

Epoch 83: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0569 - MinusLogProbMetric: 5.0569 - val_loss: 5.1281 - val_MinusLogProbMetric: 5.1281 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-12 08:44:06.694 
Epoch 84/1000 
	 loss: 5.0664, MinusLogProbMetric: 5.0664, val_loss: 5.1340, val_MinusLogProbMetric: 5.1340

Epoch 84: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0664 - MinusLogProbMetric: 5.0664 - val_loss: 5.1340 - val_MinusLogProbMetric: 5.1340 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 85/1000
2023-09-12 08:44:18.395 
Epoch 85/1000 
	 loss: 5.0632, MinusLogProbMetric: 5.0632, val_loss: 5.1039, val_MinusLogProbMetric: 5.1039

Epoch 85: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0632 - MinusLogProbMetric: 5.0632 - val_loss: 5.1039 - val_MinusLogProbMetric: 5.1039 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-12 08:44:30.008 
Epoch 86/1000 
	 loss: 5.0507, MinusLogProbMetric: 5.0507, val_loss: 5.1473, val_MinusLogProbMetric: 5.1473

Epoch 86: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0507 - MinusLogProbMetric: 5.0507 - val_loss: 5.1473 - val_MinusLogProbMetric: 5.1473 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-12 08:44:41.560 
Epoch 87/1000 
	 loss: 5.0554, MinusLogProbMetric: 5.0554, val_loss: 5.1263, val_MinusLogProbMetric: 5.1263

Epoch 87: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0554 - MinusLogProbMetric: 5.0554 - val_loss: 5.1263 - val_MinusLogProbMetric: 5.1263 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-12 08:44:53.220 
Epoch 88/1000 
	 loss: 5.0507, MinusLogProbMetric: 5.0507, val_loss: 5.1214, val_MinusLogProbMetric: 5.1214

Epoch 88: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0507 - MinusLogProbMetric: 5.0507 - val_loss: 5.1214 - val_MinusLogProbMetric: 5.1214 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-12 08:45:04.885 
Epoch 89/1000 
	 loss: 5.0525, MinusLogProbMetric: 5.0525, val_loss: 5.1190, val_MinusLogProbMetric: 5.1190

Epoch 89: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0525 - MinusLogProbMetric: 5.0525 - val_loss: 5.1190 - val_MinusLogProbMetric: 5.1190 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 90/1000
2023-09-12 08:45:16.575 
Epoch 90/1000 
	 loss: 5.0478, MinusLogProbMetric: 5.0478, val_loss: 5.1435, val_MinusLogProbMetric: 5.1435

Epoch 90: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0478 - MinusLogProbMetric: 5.0478 - val_loss: 5.1435 - val_MinusLogProbMetric: 5.1435 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-12 08:45:28.336 
Epoch 91/1000 
	 loss: 5.0492, MinusLogProbMetric: 5.0492, val_loss: 5.1197, val_MinusLogProbMetric: 5.1197

Epoch 91: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0492 - MinusLogProbMetric: 5.0492 - val_loss: 5.1197 - val_MinusLogProbMetric: 5.1197 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 08:45:40.151 
Epoch 92/1000 
	 loss: 5.0473, MinusLogProbMetric: 5.0473, val_loss: 5.0886, val_MinusLogProbMetric: 5.0886

Epoch 92: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0473 - MinusLogProbMetric: 5.0473 - val_loss: 5.0886 - val_MinusLogProbMetric: 5.0886 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-12 08:45:51.839 
Epoch 93/1000 
	 loss: 5.0521, MinusLogProbMetric: 5.0521, val_loss: 5.1478, val_MinusLogProbMetric: 5.1478

Epoch 93: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0521 - MinusLogProbMetric: 5.0521 - val_loss: 5.1478 - val_MinusLogProbMetric: 5.1478 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-12 08:46:03.530 
Epoch 94/1000 
	 loss: 5.0453, MinusLogProbMetric: 5.0453, val_loss: 5.1213, val_MinusLogProbMetric: 5.1213

Epoch 94: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0453 - MinusLogProbMetric: 5.0453 - val_loss: 5.1213 - val_MinusLogProbMetric: 5.1213 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-12 08:46:15.325 
Epoch 95/1000 
	 loss: 5.0438, MinusLogProbMetric: 5.0438, val_loss: 5.1376, val_MinusLogProbMetric: 5.1376

Epoch 95: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0438 - MinusLogProbMetric: 5.0438 - val_loss: 5.1376 - val_MinusLogProbMetric: 5.1376 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-12 08:46:26.937 
Epoch 96/1000 
	 loss: 5.0460, MinusLogProbMetric: 5.0460, val_loss: 5.1273, val_MinusLogProbMetric: 5.1273

Epoch 96: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0460 - MinusLogProbMetric: 5.0460 - val_loss: 5.1273 - val_MinusLogProbMetric: 5.1273 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 97/1000
2023-09-12 08:46:38.210 
Epoch 97/1000 
	 loss: 5.0427, MinusLogProbMetric: 5.0427, val_loss: 5.1155, val_MinusLogProbMetric: 5.1155

Epoch 97: val_loss did not improve from 5.08645
196/196 - 11s - loss: 5.0427 - MinusLogProbMetric: 5.0427 - val_loss: 5.1155 - val_MinusLogProbMetric: 5.1155 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 98/1000
2023-09-12 08:46:49.235 
Epoch 98/1000 
	 loss: 5.0428, MinusLogProbMetric: 5.0428, val_loss: 5.1328, val_MinusLogProbMetric: 5.1328

Epoch 98: val_loss did not improve from 5.08645
196/196 - 11s - loss: 5.0428 - MinusLogProbMetric: 5.0428 - val_loss: 5.1328 - val_MinusLogProbMetric: 5.1328 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 99/1000
2023-09-12 08:46:59.545 
Epoch 99/1000 
	 loss: 5.0454, MinusLogProbMetric: 5.0454, val_loss: 5.1449, val_MinusLogProbMetric: 5.1449

Epoch 99: val_loss did not improve from 5.08645
196/196 - 10s - loss: 5.0454 - MinusLogProbMetric: 5.0454 - val_loss: 5.1449 - val_MinusLogProbMetric: 5.1449 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 100/1000
2023-09-12 08:47:10.585 
Epoch 100/1000 
	 loss: 5.0421, MinusLogProbMetric: 5.0421, val_loss: 5.1149, val_MinusLogProbMetric: 5.1149

Epoch 100: val_loss did not improve from 5.08645
196/196 - 11s - loss: 5.0421 - MinusLogProbMetric: 5.0421 - val_loss: 5.1149 - val_MinusLogProbMetric: 5.1149 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 101/1000
2023-09-12 08:47:20.784 
Epoch 101/1000 
	 loss: 5.0431, MinusLogProbMetric: 5.0431, val_loss: 5.1270, val_MinusLogProbMetric: 5.1270

Epoch 101: val_loss did not improve from 5.08645
196/196 - 10s - loss: 5.0431 - MinusLogProbMetric: 5.0431 - val_loss: 5.1270 - val_MinusLogProbMetric: 5.1270 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 102/1000
2023-09-12 08:47:32.073 
Epoch 102/1000 
	 loss: 5.0422, MinusLogProbMetric: 5.0422, val_loss: 5.1703, val_MinusLogProbMetric: 5.1703

Epoch 102: val_loss did not improve from 5.08645
196/196 - 11s - loss: 5.0422 - MinusLogProbMetric: 5.0422 - val_loss: 5.1703 - val_MinusLogProbMetric: 5.1703 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 103/1000
2023-09-12 08:47:43.750 
Epoch 103/1000 
	 loss: 5.0458, MinusLogProbMetric: 5.0458, val_loss: 5.1301, val_MinusLogProbMetric: 5.1301

Epoch 103: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0458 - MinusLogProbMetric: 5.0458 - val_loss: 5.1301 - val_MinusLogProbMetric: 5.1301 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-12 08:47:55.548 
Epoch 104/1000 
	 loss: 5.0439, MinusLogProbMetric: 5.0439, val_loss: 5.1146, val_MinusLogProbMetric: 5.1146

Epoch 104: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0439 - MinusLogProbMetric: 5.0439 - val_loss: 5.1146 - val_MinusLogProbMetric: 5.1146 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 105/1000
2023-09-12 08:48:07.352 
Epoch 105/1000 
	 loss: 5.0392, MinusLogProbMetric: 5.0392, val_loss: 5.1381, val_MinusLogProbMetric: 5.1381

Epoch 105: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0392 - MinusLogProbMetric: 5.0392 - val_loss: 5.1381 - val_MinusLogProbMetric: 5.1381 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 106/1000
2023-09-12 08:48:19.155 
Epoch 106/1000 
	 loss: 5.0415, MinusLogProbMetric: 5.0415, val_loss: 5.1192, val_MinusLogProbMetric: 5.1192

Epoch 106: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0415 - MinusLogProbMetric: 5.0415 - val_loss: 5.1192 - val_MinusLogProbMetric: 5.1192 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 107/1000
2023-09-12 08:48:30.724 
Epoch 107/1000 
	 loss: 5.0376, MinusLogProbMetric: 5.0376, val_loss: 5.1223, val_MinusLogProbMetric: 5.1223

Epoch 107: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0376 - MinusLogProbMetric: 5.0376 - val_loss: 5.1223 - val_MinusLogProbMetric: 5.1223 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 108/1000
2023-09-12 08:48:42.377 
Epoch 108/1000 
	 loss: 5.0297, MinusLogProbMetric: 5.0297, val_loss: 5.1248, val_MinusLogProbMetric: 5.1248

Epoch 108: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0297 - MinusLogProbMetric: 5.0297 - val_loss: 5.1248 - val_MinusLogProbMetric: 5.1248 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 109/1000
2023-09-12 08:48:53.996 
Epoch 109/1000 
	 loss: 5.0327, MinusLogProbMetric: 5.0327, val_loss: 5.1176, val_MinusLogProbMetric: 5.1176

Epoch 109: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0327 - MinusLogProbMetric: 5.0327 - val_loss: 5.1176 - val_MinusLogProbMetric: 5.1176 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-12 08:49:05.768 
Epoch 110/1000 
	 loss: 5.0005, MinusLogProbMetric: 5.0005, val_loss: 5.1102, val_MinusLogProbMetric: 5.1102

Epoch 110: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0005 - MinusLogProbMetric: 5.0005 - val_loss: 5.1102 - val_MinusLogProbMetric: 5.1102 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 111/1000
2023-09-12 08:49:17.456 
Epoch 111/1000 
	 loss: 5.0022, MinusLogProbMetric: 5.0022, val_loss: 5.0994, val_MinusLogProbMetric: 5.0994

Epoch 111: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0022 - MinusLogProbMetric: 5.0022 - val_loss: 5.0994 - val_MinusLogProbMetric: 5.0994 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-12 08:49:29.299 
Epoch 112/1000 
	 loss: 5.0014, MinusLogProbMetric: 5.0014, val_loss: 5.1063, val_MinusLogProbMetric: 5.1063

Epoch 112: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0014 - MinusLogProbMetric: 5.0014 - val_loss: 5.1063 - val_MinusLogProbMetric: 5.1063 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 113/1000
2023-09-12 08:49:41.053 
Epoch 113/1000 
	 loss: 5.0000, MinusLogProbMetric: 5.0000, val_loss: 5.1136, val_MinusLogProbMetric: 5.1136

Epoch 113: val_loss did not improve from 5.08645
196/196 - 12s - loss: 5.0000 - MinusLogProbMetric: 5.0000 - val_loss: 5.1136 - val_MinusLogProbMetric: 5.1136 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 114/1000
2023-09-12 08:49:52.718 
Epoch 114/1000 
	 loss: 4.9999, MinusLogProbMetric: 4.9999, val_loss: 5.1157, val_MinusLogProbMetric: 5.1157

Epoch 114: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9999 - MinusLogProbMetric: 4.9999 - val_loss: 5.1157 - val_MinusLogProbMetric: 5.1157 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 115/1000
2023-09-12 08:50:04.406 
Epoch 115/1000 
	 loss: 4.9973, MinusLogProbMetric: 4.9973, val_loss: 5.0968, val_MinusLogProbMetric: 5.0968

Epoch 115: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9973 - MinusLogProbMetric: 4.9973 - val_loss: 5.0968 - val_MinusLogProbMetric: 5.0968 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 116/1000
2023-09-12 08:50:16.286 
Epoch 116/1000 
	 loss: 4.9957, MinusLogProbMetric: 4.9957, val_loss: 5.1195, val_MinusLogProbMetric: 5.1195

Epoch 116: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9957 - MinusLogProbMetric: 4.9957 - val_loss: 5.1195 - val_MinusLogProbMetric: 5.1195 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 117/1000
2023-09-12 08:50:27.957 
Epoch 117/1000 
	 loss: 4.9985, MinusLogProbMetric: 4.9985, val_loss: 5.1132, val_MinusLogProbMetric: 5.1132

Epoch 117: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9985 - MinusLogProbMetric: 4.9985 - val_loss: 5.1132 - val_MinusLogProbMetric: 5.1132 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-12 08:50:39.534 
Epoch 118/1000 
	 loss: 4.9944, MinusLogProbMetric: 4.9944, val_loss: 5.1073, val_MinusLogProbMetric: 5.1073

Epoch 118: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9944 - MinusLogProbMetric: 4.9944 - val_loss: 5.1073 - val_MinusLogProbMetric: 5.1073 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-12 08:50:51.291 
Epoch 119/1000 
	 loss: 4.9944, MinusLogProbMetric: 4.9944, val_loss: 5.1109, val_MinusLogProbMetric: 5.1109

Epoch 119: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9944 - MinusLogProbMetric: 4.9944 - val_loss: 5.1109 - val_MinusLogProbMetric: 5.1109 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 120/1000
2023-09-12 08:51:02.981 
Epoch 120/1000 
	 loss: 4.9943, MinusLogProbMetric: 4.9943, val_loss: 5.1099, val_MinusLogProbMetric: 5.1099

Epoch 120: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9943 - MinusLogProbMetric: 4.9943 - val_loss: 5.1099 - val_MinusLogProbMetric: 5.1099 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-12 08:51:14.825 
Epoch 121/1000 
	 loss: 4.9964, MinusLogProbMetric: 4.9964, val_loss: 5.1186, val_MinusLogProbMetric: 5.1186

Epoch 121: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9964 - MinusLogProbMetric: 4.9964 - val_loss: 5.1186 - val_MinusLogProbMetric: 5.1186 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-12 08:51:26.578 
Epoch 122/1000 
	 loss: 4.9942, MinusLogProbMetric: 4.9942, val_loss: 5.1107, val_MinusLogProbMetric: 5.1107

Epoch 122: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9942 - MinusLogProbMetric: 4.9942 - val_loss: 5.1107 - val_MinusLogProbMetric: 5.1107 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-12 08:51:38.407 
Epoch 123/1000 
	 loss: 4.9926, MinusLogProbMetric: 4.9926, val_loss: 5.1197, val_MinusLogProbMetric: 5.1197

Epoch 123: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9926 - MinusLogProbMetric: 4.9926 - val_loss: 5.1197 - val_MinusLogProbMetric: 5.1197 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-12 08:51:50.098 
Epoch 124/1000 
	 loss: 4.9947, MinusLogProbMetric: 4.9947, val_loss: 5.1128, val_MinusLogProbMetric: 5.1128

Epoch 124: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9947 - MinusLogProbMetric: 4.9947 - val_loss: 5.1128 - val_MinusLogProbMetric: 5.1128 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-12 08:52:01.824 
Epoch 125/1000 
	 loss: 4.9913, MinusLogProbMetric: 4.9913, val_loss: 5.1167, val_MinusLogProbMetric: 5.1167

Epoch 125: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9913 - MinusLogProbMetric: 4.9913 - val_loss: 5.1167 - val_MinusLogProbMetric: 5.1167 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 126/1000
2023-09-12 08:52:13.523 
Epoch 126/1000 
	 loss: 4.9919, MinusLogProbMetric: 4.9919, val_loss: 5.1168, val_MinusLogProbMetric: 5.1168

Epoch 126: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9919 - MinusLogProbMetric: 4.9919 - val_loss: 5.1168 - val_MinusLogProbMetric: 5.1168 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-12 08:52:25.173 
Epoch 127/1000 
	 loss: 4.9900, MinusLogProbMetric: 4.9900, val_loss: 5.1216, val_MinusLogProbMetric: 5.1216

Epoch 127: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9900 - MinusLogProbMetric: 4.9900 - val_loss: 5.1216 - val_MinusLogProbMetric: 5.1216 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 128/1000
2023-09-12 08:52:36.839 
Epoch 128/1000 
	 loss: 4.9936, MinusLogProbMetric: 4.9936, val_loss: 5.1177, val_MinusLogProbMetric: 5.1177

Epoch 128: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9936 - MinusLogProbMetric: 4.9936 - val_loss: 5.1177 - val_MinusLogProbMetric: 5.1177 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 129/1000
2023-09-12 08:52:48.581 
Epoch 129/1000 
	 loss: 4.9881, MinusLogProbMetric: 4.9881, val_loss: 5.1314, val_MinusLogProbMetric: 5.1314

Epoch 129: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9881 - MinusLogProbMetric: 4.9881 - val_loss: 5.1314 - val_MinusLogProbMetric: 5.1314 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-12 08:53:00.374 
Epoch 130/1000 
	 loss: 4.9905, MinusLogProbMetric: 4.9905, val_loss: 5.1333, val_MinusLogProbMetric: 5.1333

Epoch 130: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9905 - MinusLogProbMetric: 4.9905 - val_loss: 5.1333 - val_MinusLogProbMetric: 5.1333 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-12 08:53:12.100 
Epoch 131/1000 
	 loss: 4.9908, MinusLogProbMetric: 4.9908, val_loss: 5.1192, val_MinusLogProbMetric: 5.1192

Epoch 131: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9908 - MinusLogProbMetric: 4.9908 - val_loss: 5.1192 - val_MinusLogProbMetric: 5.1192 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 132/1000
2023-09-12 08:53:23.737 
Epoch 132/1000 
	 loss: 4.9893, MinusLogProbMetric: 4.9893, val_loss: 5.1158, val_MinusLogProbMetric: 5.1158

Epoch 132: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9893 - MinusLogProbMetric: 4.9893 - val_loss: 5.1158 - val_MinusLogProbMetric: 5.1158 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 133/1000
2023-09-12 08:53:35.589 
Epoch 133/1000 
	 loss: 4.9863, MinusLogProbMetric: 4.9863, val_loss: 5.1271, val_MinusLogProbMetric: 5.1271

Epoch 133: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9863 - MinusLogProbMetric: 4.9863 - val_loss: 5.1271 - val_MinusLogProbMetric: 5.1271 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-12 08:53:47.345 
Epoch 134/1000 
	 loss: 4.9879, MinusLogProbMetric: 4.9879, val_loss: 5.1265, val_MinusLogProbMetric: 5.1265

Epoch 134: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9879 - MinusLogProbMetric: 4.9879 - val_loss: 5.1265 - val_MinusLogProbMetric: 5.1265 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-12 08:53:58.930 
Epoch 135/1000 
	 loss: 4.9887, MinusLogProbMetric: 4.9887, val_loss: 5.1261, val_MinusLogProbMetric: 5.1261

Epoch 135: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9887 - MinusLogProbMetric: 4.9887 - val_loss: 5.1261 - val_MinusLogProbMetric: 5.1261 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 136/1000
2023-09-12 08:54:10.643 
Epoch 136/1000 
	 loss: 4.9901, MinusLogProbMetric: 4.9901, val_loss: 5.1249, val_MinusLogProbMetric: 5.1249

Epoch 136: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9901 - MinusLogProbMetric: 4.9901 - val_loss: 5.1249 - val_MinusLogProbMetric: 5.1249 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 137/1000
2023-09-12 08:54:22.242 
Epoch 137/1000 
	 loss: 4.9840, MinusLogProbMetric: 4.9840, val_loss: 5.1378, val_MinusLogProbMetric: 5.1378

Epoch 137: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9840 - MinusLogProbMetric: 4.9840 - val_loss: 5.1378 - val_MinusLogProbMetric: 5.1378 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 138/1000
2023-09-12 08:54:33.935 
Epoch 138/1000 
	 loss: 4.9874, MinusLogProbMetric: 4.9874, val_loss: 5.1228, val_MinusLogProbMetric: 5.1228

Epoch 138: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9874 - MinusLogProbMetric: 4.9874 - val_loss: 5.1228 - val_MinusLogProbMetric: 5.1228 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-12 08:54:45.619 
Epoch 139/1000 
	 loss: 4.9879, MinusLogProbMetric: 4.9879, val_loss: 5.1358, val_MinusLogProbMetric: 5.1358

Epoch 139: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9879 - MinusLogProbMetric: 4.9879 - val_loss: 5.1358 - val_MinusLogProbMetric: 5.1358 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-12 08:54:57.369 
Epoch 140/1000 
	 loss: 4.9858, MinusLogProbMetric: 4.9858, val_loss: 5.1332, val_MinusLogProbMetric: 5.1332

Epoch 140: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9858 - MinusLogProbMetric: 4.9858 - val_loss: 5.1332 - val_MinusLogProbMetric: 5.1332 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 141/1000
2023-09-12 08:55:09.106 
Epoch 141/1000 
	 loss: 4.9828, MinusLogProbMetric: 4.9828, val_loss: 5.1268, val_MinusLogProbMetric: 5.1268

Epoch 141: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9828 - MinusLogProbMetric: 4.9828 - val_loss: 5.1268 - val_MinusLogProbMetric: 5.1268 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 142/1000
2023-09-12 08:55:20.846 
Epoch 142/1000 
	 loss: 4.9822, MinusLogProbMetric: 4.9822, val_loss: 5.1282, val_MinusLogProbMetric: 5.1282

Epoch 142: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9822 - MinusLogProbMetric: 4.9822 - val_loss: 5.1282 - val_MinusLogProbMetric: 5.1282 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 143/1000
2023-09-12 08:55:32.438 
Epoch 143/1000 
	 loss: 4.9828, MinusLogProbMetric: 4.9828, val_loss: 5.1219, val_MinusLogProbMetric: 5.1219

Epoch 143: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9828 - MinusLogProbMetric: 4.9828 - val_loss: 5.1219 - val_MinusLogProbMetric: 5.1219 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 144/1000
2023-09-12 08:55:44.259 
Epoch 144/1000 
	 loss: 4.9813, MinusLogProbMetric: 4.9813, val_loss: 5.1176, val_MinusLogProbMetric: 5.1176

Epoch 144: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9813 - MinusLogProbMetric: 4.9813 - val_loss: 5.1176 - val_MinusLogProbMetric: 5.1176 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 145/1000
2023-09-12 08:55:55.999 
Epoch 145/1000 
	 loss: 4.9828, MinusLogProbMetric: 4.9828, val_loss: 5.1321, val_MinusLogProbMetric: 5.1321

Epoch 145: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9828 - MinusLogProbMetric: 4.9828 - val_loss: 5.1321 - val_MinusLogProbMetric: 5.1321 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 146/1000
2023-09-12 08:56:07.674 
Epoch 146/1000 
	 loss: 4.9808, MinusLogProbMetric: 4.9808, val_loss: 5.1313, val_MinusLogProbMetric: 5.1313

Epoch 146: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9808 - MinusLogProbMetric: 4.9808 - val_loss: 5.1313 - val_MinusLogProbMetric: 5.1313 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-12 08:56:19.428 
Epoch 147/1000 
	 loss: 4.9819, MinusLogProbMetric: 4.9819, val_loss: 5.1322, val_MinusLogProbMetric: 5.1322

Epoch 147: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9819 - MinusLogProbMetric: 4.9819 - val_loss: 5.1322 - val_MinusLogProbMetric: 5.1322 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-12 08:56:31.243 
Epoch 148/1000 
	 loss: 4.9809, MinusLogProbMetric: 4.9809, val_loss: 5.1381, val_MinusLogProbMetric: 5.1381

Epoch 148: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9809 - MinusLogProbMetric: 4.9809 - val_loss: 5.1381 - val_MinusLogProbMetric: 5.1381 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-12 08:56:42.984 
Epoch 149/1000 
	 loss: 4.9796, MinusLogProbMetric: 4.9796, val_loss: 5.1318, val_MinusLogProbMetric: 5.1318

Epoch 149: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9796 - MinusLogProbMetric: 4.9796 - val_loss: 5.1318 - val_MinusLogProbMetric: 5.1318 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-12 08:56:54.636 
Epoch 150/1000 
	 loss: 4.9783, MinusLogProbMetric: 4.9783, val_loss: 5.1322, val_MinusLogProbMetric: 5.1322

Epoch 150: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9783 - MinusLogProbMetric: 4.9783 - val_loss: 5.1322 - val_MinusLogProbMetric: 5.1322 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 151/1000
2023-09-12 08:57:06.471 
Epoch 151/1000 
	 loss: 4.9860, MinusLogProbMetric: 4.9860, val_loss: 5.1221, val_MinusLogProbMetric: 5.1221

Epoch 151: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9860 - MinusLogProbMetric: 4.9860 - val_loss: 5.1221 - val_MinusLogProbMetric: 5.1221 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-12 08:57:18.114 
Epoch 152/1000 
	 loss: 4.9801, MinusLogProbMetric: 4.9801, val_loss: 5.1406, val_MinusLogProbMetric: 5.1406

Epoch 152: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9801 - MinusLogProbMetric: 4.9801 - val_loss: 5.1406 - val_MinusLogProbMetric: 5.1406 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 153/1000
2023-09-12 08:57:29.921 
Epoch 153/1000 
	 loss: 4.9765, MinusLogProbMetric: 4.9765, val_loss: 5.1243, val_MinusLogProbMetric: 5.1243

Epoch 153: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9765 - MinusLogProbMetric: 4.9765 - val_loss: 5.1243 - val_MinusLogProbMetric: 5.1243 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 154/1000
2023-09-12 08:57:41.731 
Epoch 154/1000 
	 loss: 4.9799, MinusLogProbMetric: 4.9799, val_loss: 5.1373, val_MinusLogProbMetric: 5.1373

Epoch 154: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9799 - MinusLogProbMetric: 4.9799 - val_loss: 5.1373 - val_MinusLogProbMetric: 5.1373 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 155/1000
2023-09-12 08:57:53.408 
Epoch 155/1000 
	 loss: 4.9782, MinusLogProbMetric: 4.9782, val_loss: 5.1559, val_MinusLogProbMetric: 5.1559

Epoch 155: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9782 - MinusLogProbMetric: 4.9782 - val_loss: 5.1559 - val_MinusLogProbMetric: 5.1559 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 156/1000
2023-09-12 08:58:05.038 
Epoch 156/1000 
	 loss: 4.9747, MinusLogProbMetric: 4.9747, val_loss: 5.1320, val_MinusLogProbMetric: 5.1320

Epoch 156: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9747 - MinusLogProbMetric: 4.9747 - val_loss: 5.1320 - val_MinusLogProbMetric: 5.1320 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 157/1000
2023-09-12 08:58:16.897 
Epoch 157/1000 
	 loss: 4.9766, MinusLogProbMetric: 4.9766, val_loss: 5.1452, val_MinusLogProbMetric: 5.1452

Epoch 157: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9766 - MinusLogProbMetric: 4.9766 - val_loss: 5.1452 - val_MinusLogProbMetric: 5.1452 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 158/1000
2023-09-12 08:58:28.613 
Epoch 158/1000 
	 loss: 4.9761, MinusLogProbMetric: 4.9761, val_loss: 5.1514, val_MinusLogProbMetric: 5.1514

Epoch 158: val_loss did not improve from 5.08645
196/196 - 12s - loss: 4.9761 - MinusLogProbMetric: 4.9761 - val_loss: 5.1514 - val_MinusLogProbMetric: 5.1514 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 159/1000
2023-09-12 08:58:40.240 
Epoch 159/1000 
	 loss: 4.9793, MinusLogProbMetric: 4.9793, val_loss: 5.1424, val_MinusLogProbMetric: 5.1424

Epoch 159: val_loss did not improve from 5.08645
Restoring model weights from the end of the best epoch: 59.
196/196 - 12s - loss: 4.9793 - MinusLogProbMetric: 4.9793 - val_loss: 5.1424 - val_MinusLogProbMetric: 5.1424 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 159: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 5.802479631034657 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 3.83182055701036 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.6994362360564992 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.829189119976945 seconds.
Training succeeded with seed 440.
Model trained in 1867.70 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Metrics computed in 121.18 s.
Plots done in 35.40 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 156.59 s.
===========
Run 96/360 done in 2025.15 s.
===========

Directory ../../results/MsplineN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

===========
Generating train data for run 100.
===========
Train data generated in 0.27 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_100/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_100/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[0.38022646, 8.607701  , 8.188467  , ..., 4.120624  , 2.7077272 ,
        7.774094  ],
       [4.8196216 , 5.322764  , 0.23177525, ..., 6.6490507 , 2.2244883 ,
        1.4368625 ],
       [4.372809  , 5.4970036 , 0.2661619 , ..., 6.7417064 , 1.9180639 ,
        1.2820187 ],
       ...,
       [4.698602  , 5.590594  , 0.15122014, ..., 5.903814  , 2.560357  ,
        1.4384264 ],
       [4.78274   , 5.0663724 , 0.21942878, ..., 6.718675  , 1.7440856 ,
        1.1519673 ],
       [5.0597296 , 5.956661  , 0.10863999, ..., 7.41993   , 2.408465  ,
        1.5008225 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_100/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_100
self.data_kwargs: {'seed': 520}
self.x_data: [[ 4.404796    5.4921975   0.23664948 ...  7.564216    2.321595
   1.1917233 ]
 [ 4.5716944   5.8112526   0.21128002 ...  7.4468536   1.9158355
   1.3247035 ]
 [ 4.525824    4.9398046   0.242967   ...  6.9621987   2.4206023
   0.9921393 ]
 ...
 [ 3.9811025   5.683119    0.25731167 ...  6.6038966   2.4554362
   1.1169562 ]
 [ 5.2221084   7.363898    5.392251   ...  9.259994   -0.16446447
   0.8693828 ]
 [ 4.465022    5.5781837   0.23531836 ...  8.510526    1.9942145
   1.1519785 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_40 (InputLayer)       [(None, 16)]              0         
                                                                 
 log_prob_layer_13 (LogProbL  (None,)                  559712    
 ayer)                                                           
                                                                 
=================================================================
Total params: 559,712
Trainable params: 559,712
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_13/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_13'")
self.model: <keras.engine.functional.Functional object at 0x7fc61affd570>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc621a07370>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc621a07370>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc621a381f0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc621a38940>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc621a38eb0>, <keras.callbacks.ModelCheckpoint object at 0x7fc621a38f70>, <keras.callbacks.EarlyStopping object at 0x7fc621a391e0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc621a39210>, <keras.callbacks.TerminateOnNaN object at 0x7fc621a38e50>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[0.38022646, 8.607701  , 8.188467  , ..., 4.120624  , 2.7077272 ,
        7.774094  ],
       [4.8196216 , 5.322764  , 0.23177525, ..., 6.6490507 , 2.2244883 ,
        1.4368625 ],
       [4.372809  , 5.4970036 , 0.2661619 , ..., 6.7417064 , 1.9180639 ,
        1.2820187 ],
       ...,
       [4.698602  , 5.590594  , 0.15122014, ..., 5.903814  , 2.560357  ,
        1.4384264 ],
       [4.78274   , 5.0663724 , 0.21942878, ..., 6.718675  , 1.7440856 ,
        1.1519673 ],
       [5.0597296 , 5.956661  , 0.10863999, ..., 7.41993   , 2.408465  ,
        1.5008225 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_100/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 100/360 with hyperparameters:
timestamp = 2023-09-12 09:01:18.397329
ndims = 16
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 559712
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.404796   5.4921975  0.23664948 5.9787536  6.444371   5.747771
 9.516937   6.795833   3.7946396  5.109782   7.171333   0.7853222
 6.670326   7.564216   2.321595   1.1917233 ]
Epoch 1/1000
2023-09-12 09:01:48.087 
Epoch 1/1000 
	 loss: 19.0897, MinusLogProbMetric: 19.0897, val_loss: 6.6019, val_MinusLogProbMetric: 6.6019

Epoch 1: val_loss improved from inf to 6.60187, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 30s - loss: 19.0897 - MinusLogProbMetric: 19.0897 - val_loss: 6.6019 - val_MinusLogProbMetric: 6.6019 - lr: 0.0010 - 30s/epoch - 152ms/step
Epoch 2/1000
2023-09-12 09:01:59.296 
Epoch 2/1000 
	 loss: 5.8838, MinusLogProbMetric: 5.8838, val_loss: 5.8177, val_MinusLogProbMetric: 5.8177

Epoch 2: val_loss improved from 6.60187 to 5.81772, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.8838 - MinusLogProbMetric: 5.8838 - val_loss: 5.8177 - val_MinusLogProbMetric: 5.8177 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 3/1000
2023-09-12 09:02:10.398 
Epoch 3/1000 
	 loss: 5.5390, MinusLogProbMetric: 5.5390, val_loss: 5.4938, val_MinusLogProbMetric: 5.4938

Epoch 3: val_loss improved from 5.81772 to 5.49380, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.5390 - MinusLogProbMetric: 5.5390 - val_loss: 5.4938 - val_MinusLogProbMetric: 5.4938 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 4/1000
2023-09-12 09:02:21.625 
Epoch 4/1000 
	 loss: 5.4178, MinusLogProbMetric: 5.4178, val_loss: 5.6094, val_MinusLogProbMetric: 5.6094

Epoch 4: val_loss did not improve from 5.49380
196/196 - 11s - loss: 5.4178 - MinusLogProbMetric: 5.4178 - val_loss: 5.6094 - val_MinusLogProbMetric: 5.6094 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 5/1000
2023-09-12 09:02:32.818 
Epoch 5/1000 
	 loss: 5.3695, MinusLogProbMetric: 5.3695, val_loss: 5.2815, val_MinusLogProbMetric: 5.2815

Epoch 5: val_loss improved from 5.49380 to 5.28151, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.3695 - MinusLogProbMetric: 5.3695 - val_loss: 5.2815 - val_MinusLogProbMetric: 5.2815 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 6/1000
2023-09-12 09:02:43.755 
Epoch 6/1000 
	 loss: 5.3050, MinusLogProbMetric: 5.3050, val_loss: 5.4736, val_MinusLogProbMetric: 5.4736

Epoch 6: val_loss did not improve from 5.28151
196/196 - 11s - loss: 5.3050 - MinusLogProbMetric: 5.3050 - val_loss: 5.4736 - val_MinusLogProbMetric: 5.4736 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 7/1000
2023-09-12 09:02:55.056 
Epoch 7/1000 
	 loss: 5.2891, MinusLogProbMetric: 5.2891, val_loss: 5.2596, val_MinusLogProbMetric: 5.2596

Epoch 7: val_loss improved from 5.28151 to 5.25960, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.2891 - MinusLogProbMetric: 5.2891 - val_loss: 5.2596 - val_MinusLogProbMetric: 5.2596 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 8/1000
2023-09-12 09:03:06.577 
Epoch 8/1000 
	 loss: 5.2588, MinusLogProbMetric: 5.2588, val_loss: 5.2396, val_MinusLogProbMetric: 5.2396

Epoch 8: val_loss improved from 5.25960 to 5.23964, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.2588 - MinusLogProbMetric: 5.2588 - val_loss: 5.2396 - val_MinusLogProbMetric: 5.2396 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 9/1000
2023-09-12 09:03:17.858 
Epoch 9/1000 
	 loss: 5.2289, MinusLogProbMetric: 5.2289, val_loss: 5.2527, val_MinusLogProbMetric: 5.2527

Epoch 9: val_loss did not improve from 5.23964
196/196 - 11s - loss: 5.2289 - MinusLogProbMetric: 5.2289 - val_loss: 5.2527 - val_MinusLogProbMetric: 5.2527 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 10/1000
2023-09-12 09:03:29.030 
Epoch 10/1000 
	 loss: 5.2260, MinusLogProbMetric: 5.2260, val_loss: 5.2124, val_MinusLogProbMetric: 5.2124

Epoch 10: val_loss improved from 5.23964 to 5.21236, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.2260 - MinusLogProbMetric: 5.2260 - val_loss: 5.2124 - val_MinusLogProbMetric: 5.2124 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 11/1000
2023-09-12 09:03:40.268 
Epoch 11/1000 
	 loss: 5.2128, MinusLogProbMetric: 5.2128, val_loss: 5.2000, val_MinusLogProbMetric: 5.2000

Epoch 11: val_loss improved from 5.21236 to 5.19996, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.2128 - MinusLogProbMetric: 5.2128 - val_loss: 5.2000 - val_MinusLogProbMetric: 5.2000 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 12/1000
2023-09-12 09:03:51.461 
Epoch 12/1000 
	 loss: 5.1927, MinusLogProbMetric: 5.1927, val_loss: 5.2682, val_MinusLogProbMetric: 5.2682

Epoch 12: val_loss did not improve from 5.19996
196/196 - 11s - loss: 5.1927 - MinusLogProbMetric: 5.1927 - val_loss: 5.2682 - val_MinusLogProbMetric: 5.2682 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 13/1000
2023-09-12 09:04:02.856 
Epoch 13/1000 
	 loss: 5.1790, MinusLogProbMetric: 5.1790, val_loss: 5.2677, val_MinusLogProbMetric: 5.2677

Epoch 13: val_loss did not improve from 5.19996
196/196 - 11s - loss: 5.1790 - MinusLogProbMetric: 5.1790 - val_loss: 5.2677 - val_MinusLogProbMetric: 5.2677 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 14/1000
2023-09-12 09:04:14.234 
Epoch 14/1000 
	 loss: 5.1810, MinusLogProbMetric: 5.1810, val_loss: 5.1747, val_MinusLogProbMetric: 5.1747

Epoch 14: val_loss improved from 5.19996 to 5.17475, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 12s - loss: 5.1810 - MinusLogProbMetric: 5.1810 - val_loss: 5.1747 - val_MinusLogProbMetric: 5.1747 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-12 09:04:25.637 
Epoch 15/1000 
	 loss: 5.1802, MinusLogProbMetric: 5.1802, val_loss: 5.2370, val_MinusLogProbMetric: 5.2370

Epoch 15: val_loss did not improve from 5.17475
196/196 - 11s - loss: 5.1802 - MinusLogProbMetric: 5.1802 - val_loss: 5.2370 - val_MinusLogProbMetric: 5.2370 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 16/1000
2023-09-12 09:04:37.085 
Epoch 16/1000 
	 loss: 5.1592, MinusLogProbMetric: 5.1592, val_loss: 5.1782, val_MinusLogProbMetric: 5.1782

Epoch 16: val_loss did not improve from 5.17475
196/196 - 11s - loss: 5.1592 - MinusLogProbMetric: 5.1592 - val_loss: 5.1782 - val_MinusLogProbMetric: 5.1782 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 17/1000
2023-09-12 09:04:48.503 
Epoch 17/1000 
	 loss: 5.1603, MinusLogProbMetric: 5.1603, val_loss: 5.2727, val_MinusLogProbMetric: 5.2727

Epoch 17: val_loss did not improve from 5.17475
196/196 - 11s - loss: 5.1603 - MinusLogProbMetric: 5.1603 - val_loss: 5.2727 - val_MinusLogProbMetric: 5.2727 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 18/1000
2023-09-12 09:05:00.060 
Epoch 18/1000 
	 loss: 5.1587, MinusLogProbMetric: 5.1587, val_loss: 5.1992, val_MinusLogProbMetric: 5.1992

Epoch 18: val_loss did not improve from 5.17475
196/196 - 12s - loss: 5.1587 - MinusLogProbMetric: 5.1587 - val_loss: 5.1992 - val_MinusLogProbMetric: 5.1992 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 19/1000
2023-09-12 09:05:11.435 
Epoch 19/1000 
	 loss: 5.1589, MinusLogProbMetric: 5.1589, val_loss: 5.1605, val_MinusLogProbMetric: 5.1605

Epoch 19: val_loss improved from 5.17475 to 5.16050, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 12s - loss: 5.1589 - MinusLogProbMetric: 5.1589 - val_loss: 5.1605 - val_MinusLogProbMetric: 5.1605 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 20/1000
2023-09-12 09:05:22.937 
Epoch 20/1000 
	 loss: 5.1536, MinusLogProbMetric: 5.1536, val_loss: 5.2127, val_MinusLogProbMetric: 5.2127

Epoch 20: val_loss did not improve from 5.16050
196/196 - 11s - loss: 5.1536 - MinusLogProbMetric: 5.1536 - val_loss: 5.2127 - val_MinusLogProbMetric: 5.2127 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 21/1000
2023-09-12 09:05:34.244 
Epoch 21/1000 
	 loss: 5.1437, MinusLogProbMetric: 5.1437, val_loss: 5.1891, val_MinusLogProbMetric: 5.1891

Epoch 21: val_loss did not improve from 5.16050
196/196 - 11s - loss: 5.1437 - MinusLogProbMetric: 5.1437 - val_loss: 5.1891 - val_MinusLogProbMetric: 5.1891 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 22/1000
2023-09-12 09:05:45.617 
Epoch 22/1000 
	 loss: 5.1435, MinusLogProbMetric: 5.1435, val_loss: 5.1443, val_MinusLogProbMetric: 5.1443

Epoch 22: val_loss improved from 5.16050 to 5.14430, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 12s - loss: 5.1435 - MinusLogProbMetric: 5.1435 - val_loss: 5.1443 - val_MinusLogProbMetric: 5.1443 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 23/1000
2023-09-12 09:05:57.160 
Epoch 23/1000 
	 loss: 5.1330, MinusLogProbMetric: 5.1330, val_loss: 5.1711, val_MinusLogProbMetric: 5.1711

Epoch 23: val_loss did not improve from 5.14430
196/196 - 11s - loss: 5.1330 - MinusLogProbMetric: 5.1330 - val_loss: 5.1711 - val_MinusLogProbMetric: 5.1711 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 24/1000
2023-09-12 09:06:08.637 
Epoch 24/1000 
	 loss: 5.1338, MinusLogProbMetric: 5.1338, val_loss: 5.1674, val_MinusLogProbMetric: 5.1674

Epoch 24: val_loss did not improve from 5.14430
196/196 - 11s - loss: 5.1338 - MinusLogProbMetric: 5.1338 - val_loss: 5.1674 - val_MinusLogProbMetric: 5.1674 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 25/1000
2023-09-12 09:06:20.017 
Epoch 25/1000 
	 loss: 5.1265, MinusLogProbMetric: 5.1265, val_loss: 5.1765, val_MinusLogProbMetric: 5.1765

Epoch 25: val_loss did not improve from 5.14430
196/196 - 11s - loss: 5.1265 - MinusLogProbMetric: 5.1265 - val_loss: 5.1765 - val_MinusLogProbMetric: 5.1765 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 26/1000
2023-09-12 09:06:31.449 
Epoch 26/1000 
	 loss: 5.1309, MinusLogProbMetric: 5.1309, val_loss: 5.1736, val_MinusLogProbMetric: 5.1736

Epoch 26: val_loss did not improve from 5.14430
196/196 - 11s - loss: 5.1309 - MinusLogProbMetric: 5.1309 - val_loss: 5.1736 - val_MinusLogProbMetric: 5.1736 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 27/1000
2023-09-12 09:06:42.752 
Epoch 27/1000 
	 loss: 5.1291, MinusLogProbMetric: 5.1291, val_loss: 5.1757, val_MinusLogProbMetric: 5.1757

Epoch 27: val_loss did not improve from 5.14430
196/196 - 11s - loss: 5.1291 - MinusLogProbMetric: 5.1291 - val_loss: 5.1757 - val_MinusLogProbMetric: 5.1757 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 28/1000
2023-09-12 09:06:53.915 
Epoch 28/1000 
	 loss: 5.1197, MinusLogProbMetric: 5.1197, val_loss: 5.1068, val_MinusLogProbMetric: 5.1068

Epoch 28: val_loss improved from 5.14430 to 5.10677, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.1197 - MinusLogProbMetric: 5.1197 - val_loss: 5.1068 - val_MinusLogProbMetric: 5.1068 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 29/1000
2023-09-12 09:07:05.312 
Epoch 29/1000 
	 loss: 5.1230, MinusLogProbMetric: 5.1230, val_loss: 5.2178, val_MinusLogProbMetric: 5.2178

Epoch 29: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1230 - MinusLogProbMetric: 5.1230 - val_loss: 5.2178 - val_MinusLogProbMetric: 5.2178 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 30/1000
2023-09-12 09:07:16.584 
Epoch 30/1000 
	 loss: 5.1158, MinusLogProbMetric: 5.1158, val_loss: 5.1716, val_MinusLogProbMetric: 5.1716

Epoch 30: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1158 - MinusLogProbMetric: 5.1158 - val_loss: 5.1716 - val_MinusLogProbMetric: 5.1716 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 31/1000
2023-09-12 09:07:27.806 
Epoch 31/1000 
	 loss: 5.1048, MinusLogProbMetric: 5.1048, val_loss: 5.1126, val_MinusLogProbMetric: 5.1126

Epoch 31: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1048 - MinusLogProbMetric: 5.1048 - val_loss: 5.1126 - val_MinusLogProbMetric: 5.1126 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 32/1000
2023-09-12 09:07:39.167 
Epoch 32/1000 
	 loss: 5.1287, MinusLogProbMetric: 5.1287, val_loss: 5.1185, val_MinusLogProbMetric: 5.1185

Epoch 32: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1287 - MinusLogProbMetric: 5.1287 - val_loss: 5.1185 - val_MinusLogProbMetric: 5.1185 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 33/1000
2023-09-12 09:07:50.517 
Epoch 33/1000 
	 loss: 5.1094, MinusLogProbMetric: 5.1094, val_loss: 5.1360, val_MinusLogProbMetric: 5.1360

Epoch 33: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1094 - MinusLogProbMetric: 5.1094 - val_loss: 5.1360 - val_MinusLogProbMetric: 5.1360 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 34/1000
2023-09-12 09:08:01.807 
Epoch 34/1000 
	 loss: 5.1027, MinusLogProbMetric: 5.1027, val_loss: 5.1347, val_MinusLogProbMetric: 5.1347

Epoch 34: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1027 - MinusLogProbMetric: 5.1027 - val_loss: 5.1347 - val_MinusLogProbMetric: 5.1347 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 35/1000
2023-09-12 09:08:13.031 
Epoch 35/1000 
	 loss: 5.0972, MinusLogProbMetric: 5.0972, val_loss: 5.1165, val_MinusLogProbMetric: 5.1165

Epoch 35: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0972 - MinusLogProbMetric: 5.0972 - val_loss: 5.1165 - val_MinusLogProbMetric: 5.1165 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 36/1000
2023-09-12 09:08:24.202 
Epoch 36/1000 
	 loss: 5.1052, MinusLogProbMetric: 5.1052, val_loss: 5.1605, val_MinusLogProbMetric: 5.1605

Epoch 36: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1052 - MinusLogProbMetric: 5.1052 - val_loss: 5.1605 - val_MinusLogProbMetric: 5.1605 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 37/1000
2023-09-12 09:08:35.469 
Epoch 37/1000 
	 loss: 5.0981, MinusLogProbMetric: 5.0981, val_loss: 5.1691, val_MinusLogProbMetric: 5.1691

Epoch 37: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0981 - MinusLogProbMetric: 5.0981 - val_loss: 5.1691 - val_MinusLogProbMetric: 5.1691 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 38/1000
2023-09-12 09:08:46.757 
Epoch 38/1000 
	 loss: 5.1001, MinusLogProbMetric: 5.1001, val_loss: 5.1308, val_MinusLogProbMetric: 5.1308

Epoch 38: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1001 - MinusLogProbMetric: 5.1001 - val_loss: 5.1308 - val_MinusLogProbMetric: 5.1308 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 39/1000
2023-09-12 09:08:57.844 
Epoch 39/1000 
	 loss: 5.0920, MinusLogProbMetric: 5.0920, val_loss: 5.1455, val_MinusLogProbMetric: 5.1455

Epoch 39: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0920 - MinusLogProbMetric: 5.0920 - val_loss: 5.1455 - val_MinusLogProbMetric: 5.1455 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 40/1000
2023-09-12 09:09:09.046 
Epoch 40/1000 
	 loss: 5.1000, MinusLogProbMetric: 5.1000, val_loss: 5.1107, val_MinusLogProbMetric: 5.1107

Epoch 40: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.1000 - MinusLogProbMetric: 5.1000 - val_loss: 5.1107 - val_MinusLogProbMetric: 5.1107 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 41/1000
2023-09-12 09:09:20.272 
Epoch 41/1000 
	 loss: 5.0879, MinusLogProbMetric: 5.0879, val_loss: 5.1207, val_MinusLogProbMetric: 5.1207

Epoch 41: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0879 - MinusLogProbMetric: 5.0879 - val_loss: 5.1207 - val_MinusLogProbMetric: 5.1207 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 42/1000
2023-09-12 09:09:31.597 
Epoch 42/1000 
	 loss: 5.0907, MinusLogProbMetric: 5.0907, val_loss: 5.1224, val_MinusLogProbMetric: 5.1224

Epoch 42: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0907 - MinusLogProbMetric: 5.0907 - val_loss: 5.1224 - val_MinusLogProbMetric: 5.1224 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 43/1000
2023-09-12 09:09:42.785 
Epoch 43/1000 
	 loss: 5.0875, MinusLogProbMetric: 5.0875, val_loss: 5.1273, val_MinusLogProbMetric: 5.1273

Epoch 43: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0875 - MinusLogProbMetric: 5.0875 - val_loss: 5.1273 - val_MinusLogProbMetric: 5.1273 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 44/1000
2023-09-12 09:09:54.016 
Epoch 44/1000 
	 loss: 5.0874, MinusLogProbMetric: 5.0874, val_loss: 5.1473, val_MinusLogProbMetric: 5.1473

Epoch 44: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0874 - MinusLogProbMetric: 5.0874 - val_loss: 5.1473 - val_MinusLogProbMetric: 5.1473 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 45/1000
2023-09-12 09:10:05.218 
Epoch 45/1000 
	 loss: 5.0862, MinusLogProbMetric: 5.0862, val_loss: 5.1424, val_MinusLogProbMetric: 5.1424

Epoch 45: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0862 - MinusLogProbMetric: 5.0862 - val_loss: 5.1424 - val_MinusLogProbMetric: 5.1424 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 46/1000
2023-09-12 09:10:16.586 
Epoch 46/1000 
	 loss: 5.0930, MinusLogProbMetric: 5.0930, val_loss: 5.1544, val_MinusLogProbMetric: 5.1544

Epoch 46: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0930 - MinusLogProbMetric: 5.0930 - val_loss: 5.1544 - val_MinusLogProbMetric: 5.1544 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 47/1000
2023-09-12 09:10:27.873 
Epoch 47/1000 
	 loss: 5.0849, MinusLogProbMetric: 5.0849, val_loss: 5.1241, val_MinusLogProbMetric: 5.1241

Epoch 47: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0849 - MinusLogProbMetric: 5.0849 - val_loss: 5.1241 - val_MinusLogProbMetric: 5.1241 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 48/1000
2023-09-12 09:10:39.007 
Epoch 48/1000 
	 loss: 5.0780, MinusLogProbMetric: 5.0780, val_loss: 5.1391, val_MinusLogProbMetric: 5.1391

Epoch 48: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0780 - MinusLogProbMetric: 5.0780 - val_loss: 5.1391 - val_MinusLogProbMetric: 5.1391 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 49/1000
2023-09-12 09:10:50.358 
Epoch 49/1000 
	 loss: 5.0824, MinusLogProbMetric: 5.0824, val_loss: 5.1332, val_MinusLogProbMetric: 5.1332

Epoch 49: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0824 - MinusLogProbMetric: 5.0824 - val_loss: 5.1332 - val_MinusLogProbMetric: 5.1332 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 50/1000
2023-09-12 09:11:01.350 
Epoch 50/1000 
	 loss: 5.0744, MinusLogProbMetric: 5.0744, val_loss: 5.1324, val_MinusLogProbMetric: 5.1324

Epoch 50: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0744 - MinusLogProbMetric: 5.0744 - val_loss: 5.1324 - val_MinusLogProbMetric: 5.1324 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 51/1000
2023-09-12 09:11:12.645 
Epoch 51/1000 
	 loss: 5.0786, MinusLogProbMetric: 5.0786, val_loss: 5.1100, val_MinusLogProbMetric: 5.1100

Epoch 51: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0786 - MinusLogProbMetric: 5.0786 - val_loss: 5.1100 - val_MinusLogProbMetric: 5.1100 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 52/1000
2023-09-12 09:11:23.796 
Epoch 52/1000 
	 loss: 5.0780, MinusLogProbMetric: 5.0780, val_loss: 5.1168, val_MinusLogProbMetric: 5.1168

Epoch 52: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0780 - MinusLogProbMetric: 5.0780 - val_loss: 5.1168 - val_MinusLogProbMetric: 5.1168 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 53/1000
2023-09-12 09:11:35.146 
Epoch 53/1000 
	 loss: 5.0788, MinusLogProbMetric: 5.0788, val_loss: 5.2348, val_MinusLogProbMetric: 5.2348

Epoch 53: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0788 - MinusLogProbMetric: 5.0788 - val_loss: 5.2348 - val_MinusLogProbMetric: 5.2348 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 54/1000
2023-09-12 09:11:46.484 
Epoch 54/1000 
	 loss: 5.0836, MinusLogProbMetric: 5.0836, val_loss: 5.1730, val_MinusLogProbMetric: 5.1730

Epoch 54: val_loss did not improve from 5.10677
196/196 - 11s - loss: 5.0836 - MinusLogProbMetric: 5.0836 - val_loss: 5.1730 - val_MinusLogProbMetric: 5.1730 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 55/1000
2023-09-12 09:11:57.807 
Epoch 55/1000 
	 loss: 5.0715, MinusLogProbMetric: 5.0715, val_loss: 5.0846, val_MinusLogProbMetric: 5.0846

Epoch 55: val_loss improved from 5.10677 to 5.08462, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 11s - loss: 5.0715 - MinusLogProbMetric: 5.0715 - val_loss: 5.0846 - val_MinusLogProbMetric: 5.0846 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 56/1000
2023-09-12 09:12:09.371 
Epoch 56/1000 
	 loss: 5.0751, MinusLogProbMetric: 5.0751, val_loss: 5.1402, val_MinusLogProbMetric: 5.1402

Epoch 56: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0751 - MinusLogProbMetric: 5.0751 - val_loss: 5.1402 - val_MinusLogProbMetric: 5.1402 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 57/1000
2023-09-12 09:12:20.016 
Epoch 57/1000 
	 loss: 5.0706, MinusLogProbMetric: 5.0706, val_loss: 5.0903, val_MinusLogProbMetric: 5.0903

Epoch 57: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0706 - MinusLogProbMetric: 5.0706 - val_loss: 5.0903 - val_MinusLogProbMetric: 5.0903 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 58/1000
2023-09-12 09:12:29.641 
Epoch 58/1000 
	 loss: 5.0676, MinusLogProbMetric: 5.0676, val_loss: 5.0934, val_MinusLogProbMetric: 5.0934

Epoch 58: val_loss did not improve from 5.08462
196/196 - 10s - loss: 5.0676 - MinusLogProbMetric: 5.0676 - val_loss: 5.0934 - val_MinusLogProbMetric: 5.0934 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 59/1000
2023-09-12 09:12:39.371 
Epoch 59/1000 
	 loss: 5.0648, MinusLogProbMetric: 5.0648, val_loss: 5.0976, val_MinusLogProbMetric: 5.0976

Epoch 59: val_loss did not improve from 5.08462
196/196 - 10s - loss: 5.0648 - MinusLogProbMetric: 5.0648 - val_loss: 5.0976 - val_MinusLogProbMetric: 5.0976 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 60/1000
2023-09-12 09:12:49.976 
Epoch 60/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1180, val_MinusLogProbMetric: 5.1180

Epoch 60: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1180 - val_MinusLogProbMetric: 5.1180 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 61/1000
2023-09-12 09:13:01.030 
Epoch 61/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1441, val_MinusLogProbMetric: 5.1441

Epoch 61: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1441 - val_MinusLogProbMetric: 5.1441 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 62/1000
2023-09-12 09:13:12.382 
Epoch 62/1000 
	 loss: 5.0682, MinusLogProbMetric: 5.0682, val_loss: 5.0884, val_MinusLogProbMetric: 5.0884

Epoch 62: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0682 - MinusLogProbMetric: 5.0682 - val_loss: 5.0884 - val_MinusLogProbMetric: 5.0884 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 63/1000
2023-09-12 09:13:23.882 
Epoch 63/1000 
	 loss: 5.0663, MinusLogProbMetric: 5.0663, val_loss: 5.1217, val_MinusLogProbMetric: 5.1217

Epoch 63: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0663 - MinusLogProbMetric: 5.0663 - val_loss: 5.1217 - val_MinusLogProbMetric: 5.1217 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 64/1000
2023-09-12 09:13:35.163 
Epoch 64/1000 
	 loss: 5.0612, MinusLogProbMetric: 5.0612, val_loss: 5.0967, val_MinusLogProbMetric: 5.0967

Epoch 64: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0612 - MinusLogProbMetric: 5.0612 - val_loss: 5.0967 - val_MinusLogProbMetric: 5.0967 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 65/1000
2023-09-12 09:13:46.433 
Epoch 65/1000 
	 loss: 5.0606, MinusLogProbMetric: 5.0606, val_loss: 5.1217, val_MinusLogProbMetric: 5.1217

Epoch 65: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0606 - MinusLogProbMetric: 5.0606 - val_loss: 5.1217 - val_MinusLogProbMetric: 5.1217 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 66/1000
2023-09-12 09:13:57.576 
Epoch 66/1000 
	 loss: 5.0671, MinusLogProbMetric: 5.0671, val_loss: 5.1189, val_MinusLogProbMetric: 5.1189

Epoch 66: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0671 - MinusLogProbMetric: 5.0671 - val_loss: 5.1189 - val_MinusLogProbMetric: 5.1189 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 67/1000
2023-09-12 09:14:08.708 
Epoch 67/1000 
	 loss: 5.0697, MinusLogProbMetric: 5.0697, val_loss: 5.1281, val_MinusLogProbMetric: 5.1281

Epoch 67: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0697 - MinusLogProbMetric: 5.0697 - val_loss: 5.1281 - val_MinusLogProbMetric: 5.1281 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 68/1000
2023-09-12 09:14:20.061 
Epoch 68/1000 
	 loss: 5.0586, MinusLogProbMetric: 5.0586, val_loss: 5.1047, val_MinusLogProbMetric: 5.1047

Epoch 68: val_loss did not improve from 5.08462
196/196 - 11s - loss: 5.0586 - MinusLogProbMetric: 5.0586 - val_loss: 5.1047 - val_MinusLogProbMetric: 5.1047 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 69/1000
2023-09-12 09:14:31.675 
Epoch 69/1000 
	 loss: 5.0554, MinusLogProbMetric: 5.0554, val_loss: 5.0834, val_MinusLogProbMetric: 5.0834

Epoch 69: val_loss improved from 5.08462 to 5.08345, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 12s - loss: 5.0554 - MinusLogProbMetric: 5.0554 - val_loss: 5.0834 - val_MinusLogProbMetric: 5.0834 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 09:14:43.465 
Epoch 70/1000 
	 loss: 5.0601, MinusLogProbMetric: 5.0601, val_loss: 5.1097, val_MinusLogProbMetric: 5.1097

Epoch 70: val_loss did not improve from 5.08345
196/196 - 12s - loss: 5.0601 - MinusLogProbMetric: 5.0601 - val_loss: 5.1097 - val_MinusLogProbMetric: 5.1097 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-12 09:14:55.167 
Epoch 71/1000 
	 loss: 5.0598, MinusLogProbMetric: 5.0598, val_loss: 5.1173, val_MinusLogProbMetric: 5.1173

Epoch 71: val_loss did not improve from 5.08345
196/196 - 12s - loss: 5.0598 - MinusLogProbMetric: 5.0598 - val_loss: 5.1173 - val_MinusLogProbMetric: 5.1173 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-12 09:15:06.741 
Epoch 72/1000 
	 loss: 5.0530, MinusLogProbMetric: 5.0530, val_loss: 5.0850, val_MinusLogProbMetric: 5.0850

Epoch 72: val_loss did not improve from 5.08345
196/196 - 12s - loss: 5.0530 - MinusLogProbMetric: 5.0530 - val_loss: 5.0850 - val_MinusLogProbMetric: 5.0850 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 73/1000
2023-09-12 09:15:18.320 
Epoch 73/1000 
	 loss: 5.0499, MinusLogProbMetric: 5.0499, val_loss: 5.1214, val_MinusLogProbMetric: 5.1214

Epoch 73: val_loss did not improve from 5.08345
196/196 - 12s - loss: 5.0499 - MinusLogProbMetric: 5.0499 - val_loss: 5.1214 - val_MinusLogProbMetric: 5.1214 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 09:15:29.200 
Epoch 74/1000 
	 loss: 5.0532, MinusLogProbMetric: 5.0532, val_loss: 5.1075, val_MinusLogProbMetric: 5.1075

Epoch 74: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0532 - MinusLogProbMetric: 5.0532 - val_loss: 5.1075 - val_MinusLogProbMetric: 5.1075 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 75/1000
2023-09-12 09:15:38.597 
Epoch 75/1000 
	 loss: 5.0571, MinusLogProbMetric: 5.0571, val_loss: 5.1159, val_MinusLogProbMetric: 5.1159

Epoch 75: val_loss did not improve from 5.08345
196/196 - 9s - loss: 5.0571 - MinusLogProbMetric: 5.0571 - val_loss: 5.1159 - val_MinusLogProbMetric: 5.1159 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 76/1000
2023-09-12 09:15:49.360 
Epoch 76/1000 
	 loss: 5.0590, MinusLogProbMetric: 5.0590, val_loss: 5.1367, val_MinusLogProbMetric: 5.1367

Epoch 76: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0590 - MinusLogProbMetric: 5.0590 - val_loss: 5.1367 - val_MinusLogProbMetric: 5.1367 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 77/1000
2023-09-12 09:15:58.908 
Epoch 77/1000 
	 loss: 5.0616, MinusLogProbMetric: 5.0616, val_loss: 5.1048, val_MinusLogProbMetric: 5.1048

Epoch 77: val_loss did not improve from 5.08345
196/196 - 10s - loss: 5.0616 - MinusLogProbMetric: 5.0616 - val_loss: 5.1048 - val_MinusLogProbMetric: 5.1048 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 78/1000
2023-09-12 09:16:09.019 
Epoch 78/1000 
	 loss: 5.0540, MinusLogProbMetric: 5.0540, val_loss: 5.1437, val_MinusLogProbMetric: 5.1437

Epoch 78: val_loss did not improve from 5.08345
196/196 - 10s - loss: 5.0540 - MinusLogProbMetric: 5.0540 - val_loss: 5.1437 - val_MinusLogProbMetric: 5.1437 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 79/1000
2023-09-12 09:16:18.594 
Epoch 79/1000 
	 loss: 5.0525, MinusLogProbMetric: 5.0525, val_loss: 5.1012, val_MinusLogProbMetric: 5.1012

Epoch 79: val_loss did not improve from 5.08345
196/196 - 10s - loss: 5.0525 - MinusLogProbMetric: 5.0525 - val_loss: 5.1012 - val_MinusLogProbMetric: 5.1012 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 80/1000
2023-09-12 09:16:29.441 
Epoch 80/1000 
	 loss: 5.0471, MinusLogProbMetric: 5.0471, val_loss: 5.1255, val_MinusLogProbMetric: 5.1255

Epoch 80: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0471 - MinusLogProbMetric: 5.0471 - val_loss: 5.1255 - val_MinusLogProbMetric: 5.1255 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 81/1000
2023-09-12 09:16:39.214 
Epoch 81/1000 
	 loss: 5.0633, MinusLogProbMetric: 5.0633, val_loss: 5.1371, val_MinusLogProbMetric: 5.1371

Epoch 81: val_loss did not improve from 5.08345
196/196 - 10s - loss: 5.0633 - MinusLogProbMetric: 5.0633 - val_loss: 5.1371 - val_MinusLogProbMetric: 5.1371 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 82/1000
2023-09-12 09:16:49.591 
Epoch 82/1000 
	 loss: 5.0545, MinusLogProbMetric: 5.0545, val_loss: 5.1027, val_MinusLogProbMetric: 5.1027

Epoch 82: val_loss did not improve from 5.08345
196/196 - 10s - loss: 5.0545 - MinusLogProbMetric: 5.0545 - val_loss: 5.1027 - val_MinusLogProbMetric: 5.1027 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 83/1000
2023-09-12 09:17:00.990 
Epoch 83/1000 
	 loss: 5.0416, MinusLogProbMetric: 5.0416, val_loss: 5.1220, val_MinusLogProbMetric: 5.1220

Epoch 83: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0416 - MinusLogProbMetric: 5.0416 - val_loss: 5.1220 - val_MinusLogProbMetric: 5.1220 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 84/1000
2023-09-12 09:17:12.403 
Epoch 84/1000 
	 loss: 5.0509, MinusLogProbMetric: 5.0509, val_loss: 5.0887, val_MinusLogProbMetric: 5.0887

Epoch 84: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0509 - MinusLogProbMetric: 5.0509 - val_loss: 5.0887 - val_MinusLogProbMetric: 5.0887 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 85/1000
2023-09-12 09:17:23.819 
Epoch 85/1000 
	 loss: 5.0435, MinusLogProbMetric: 5.0435, val_loss: 5.1255, val_MinusLogProbMetric: 5.1255

Epoch 85: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0435 - MinusLogProbMetric: 5.0435 - val_loss: 5.1255 - val_MinusLogProbMetric: 5.1255 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 86/1000
2023-09-12 09:17:35.303 
Epoch 86/1000 
	 loss: 5.0399, MinusLogProbMetric: 5.0399, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 86: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0399 - MinusLogProbMetric: 5.0399 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 87/1000
2023-09-12 09:17:46.728 
Epoch 87/1000 
	 loss: 5.0493, MinusLogProbMetric: 5.0493, val_loss: 5.0840, val_MinusLogProbMetric: 5.0840

Epoch 87: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0493 - MinusLogProbMetric: 5.0493 - val_loss: 5.0840 - val_MinusLogProbMetric: 5.0840 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 88/1000
2023-09-12 09:17:58.183 
Epoch 88/1000 
	 loss: 5.0431, MinusLogProbMetric: 5.0431, val_loss: 5.1290, val_MinusLogProbMetric: 5.1290

Epoch 88: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0431 - MinusLogProbMetric: 5.0431 - val_loss: 5.1290 - val_MinusLogProbMetric: 5.1290 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 89/1000
2023-09-12 09:18:09.521 
Epoch 89/1000 
	 loss: 5.0450, MinusLogProbMetric: 5.0450, val_loss: 5.1092, val_MinusLogProbMetric: 5.1092

Epoch 89: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0450 - MinusLogProbMetric: 5.0450 - val_loss: 5.1092 - val_MinusLogProbMetric: 5.1092 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 90/1000
2023-09-12 09:18:20.763 
Epoch 90/1000 
	 loss: 5.0372, MinusLogProbMetric: 5.0372, val_loss: 5.0948, val_MinusLogProbMetric: 5.0948

Epoch 90: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0372 - MinusLogProbMetric: 5.0372 - val_loss: 5.0948 - val_MinusLogProbMetric: 5.0948 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 91/1000
2023-09-12 09:18:32.011 
Epoch 91/1000 
	 loss: 5.0362, MinusLogProbMetric: 5.0362, val_loss: 5.0993, val_MinusLogProbMetric: 5.0993

Epoch 91: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0362 - MinusLogProbMetric: 5.0362 - val_loss: 5.0993 - val_MinusLogProbMetric: 5.0993 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 92/1000
2023-09-12 09:18:43.397 
Epoch 92/1000 
	 loss: 5.0392, MinusLogProbMetric: 5.0392, val_loss: 5.1258, val_MinusLogProbMetric: 5.1258

Epoch 92: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0392 - MinusLogProbMetric: 5.0392 - val_loss: 5.1258 - val_MinusLogProbMetric: 5.1258 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 93/1000
2023-09-12 09:18:54.913 
Epoch 93/1000 
	 loss: 5.0419, MinusLogProbMetric: 5.0419, val_loss: 5.1199, val_MinusLogProbMetric: 5.1199

Epoch 93: val_loss did not improve from 5.08345
196/196 - 12s - loss: 5.0419 - MinusLogProbMetric: 5.0419 - val_loss: 5.1199 - val_MinusLogProbMetric: 5.1199 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 94/1000
2023-09-12 09:19:06.255 
Epoch 94/1000 
	 loss: 5.0449, MinusLogProbMetric: 5.0449, val_loss: 5.1088, val_MinusLogProbMetric: 5.1088

Epoch 94: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0449 - MinusLogProbMetric: 5.0449 - val_loss: 5.1088 - val_MinusLogProbMetric: 5.1088 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 95/1000
2023-09-12 09:19:17.648 
Epoch 95/1000 
	 loss: 5.0390, MinusLogProbMetric: 5.0390, val_loss: 5.1250, val_MinusLogProbMetric: 5.1250

Epoch 95: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0390 - MinusLogProbMetric: 5.0390 - val_loss: 5.1250 - val_MinusLogProbMetric: 5.1250 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 96/1000
2023-09-12 09:19:28.886 
Epoch 96/1000 
	 loss: 5.0380, MinusLogProbMetric: 5.0380, val_loss: 5.1006, val_MinusLogProbMetric: 5.1006

Epoch 96: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0380 - MinusLogProbMetric: 5.0380 - val_loss: 5.1006 - val_MinusLogProbMetric: 5.1006 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 97/1000
2023-09-12 09:19:40.070 
Epoch 97/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.1079, val_MinusLogProbMetric: 5.1079

Epoch 97: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.1079 - val_MinusLogProbMetric: 5.1079 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 98/1000
2023-09-12 09:19:51.436 
Epoch 98/1000 
	 loss: 5.0335, MinusLogProbMetric: 5.0335, val_loss: 5.1339, val_MinusLogProbMetric: 5.1339

Epoch 98: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0335 - MinusLogProbMetric: 5.0335 - val_loss: 5.1339 - val_MinusLogProbMetric: 5.1339 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 99/1000
2023-09-12 09:20:02.707 
Epoch 99/1000 
	 loss: 5.0330, MinusLogProbMetric: 5.0330, val_loss: 5.1136, val_MinusLogProbMetric: 5.1136

Epoch 99: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0330 - MinusLogProbMetric: 5.0330 - val_loss: 5.1136 - val_MinusLogProbMetric: 5.1136 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 100/1000
2023-09-12 09:20:14.032 
Epoch 100/1000 
	 loss: 5.0364, MinusLogProbMetric: 5.0364, val_loss: 5.1020, val_MinusLogProbMetric: 5.1020

Epoch 100: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0364 - MinusLogProbMetric: 5.0364 - val_loss: 5.1020 - val_MinusLogProbMetric: 5.1020 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 101/1000
2023-09-12 09:20:25.409 
Epoch 101/1000 
	 loss: 5.0356, MinusLogProbMetric: 5.0356, val_loss: 5.1019, val_MinusLogProbMetric: 5.1019

Epoch 101: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0356 - MinusLogProbMetric: 5.0356 - val_loss: 5.1019 - val_MinusLogProbMetric: 5.1019 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 102/1000
2023-09-12 09:20:36.735 
Epoch 102/1000 
	 loss: 5.0298, MinusLogProbMetric: 5.0298, val_loss: 5.1170, val_MinusLogProbMetric: 5.1170

Epoch 102: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0298 - MinusLogProbMetric: 5.0298 - val_loss: 5.1170 - val_MinusLogProbMetric: 5.1170 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 103/1000
2023-09-12 09:20:47.973 
Epoch 103/1000 
	 loss: 5.0354, MinusLogProbMetric: 5.0354, val_loss: 5.0923, val_MinusLogProbMetric: 5.0923

Epoch 103: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0354 - MinusLogProbMetric: 5.0354 - val_loss: 5.0923 - val_MinusLogProbMetric: 5.0923 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 104/1000
2023-09-12 09:20:59.270 
Epoch 104/1000 
	 loss: 5.0314, MinusLogProbMetric: 5.0314, val_loss: 5.1317, val_MinusLogProbMetric: 5.1317

Epoch 104: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0314 - MinusLogProbMetric: 5.0314 - val_loss: 5.1317 - val_MinusLogProbMetric: 5.1317 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 105/1000
2023-09-12 09:21:10.602 
Epoch 105/1000 
	 loss: 5.0338, MinusLogProbMetric: 5.0338, val_loss: 5.1002, val_MinusLogProbMetric: 5.1002

Epoch 105: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0338 - MinusLogProbMetric: 5.0338 - val_loss: 5.1002 - val_MinusLogProbMetric: 5.1002 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 106/1000
2023-09-12 09:21:21.835 
Epoch 106/1000 
	 loss: 5.0367, MinusLogProbMetric: 5.0367, val_loss: 5.1013, val_MinusLogProbMetric: 5.1013

Epoch 106: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0367 - MinusLogProbMetric: 5.0367 - val_loss: 5.1013 - val_MinusLogProbMetric: 5.1013 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 107/1000
2023-09-12 09:21:33.240 
Epoch 107/1000 
	 loss: 5.0288, MinusLogProbMetric: 5.0288, val_loss: 5.1005, val_MinusLogProbMetric: 5.1005

Epoch 107: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0288 - MinusLogProbMetric: 5.0288 - val_loss: 5.1005 - val_MinusLogProbMetric: 5.1005 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 108/1000
2023-09-12 09:21:44.546 
Epoch 108/1000 
	 loss: 5.0282, MinusLogProbMetric: 5.0282, val_loss: 5.1082, val_MinusLogProbMetric: 5.1082

Epoch 108: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0282 - MinusLogProbMetric: 5.0282 - val_loss: 5.1082 - val_MinusLogProbMetric: 5.1082 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 109/1000
2023-09-12 09:21:55.951 
Epoch 109/1000 
	 loss: 5.0300, MinusLogProbMetric: 5.0300, val_loss: 5.1068, val_MinusLogProbMetric: 5.1068

Epoch 109: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0300 - MinusLogProbMetric: 5.0300 - val_loss: 5.1068 - val_MinusLogProbMetric: 5.1068 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 09:22:07.224 
Epoch 110/1000 
	 loss: 5.0304, MinusLogProbMetric: 5.0304, val_loss: 5.0938, val_MinusLogProbMetric: 5.0938

Epoch 110: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0304 - MinusLogProbMetric: 5.0304 - val_loss: 5.0938 - val_MinusLogProbMetric: 5.0938 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 111/1000
2023-09-12 09:22:18.535 
Epoch 111/1000 
	 loss: 5.0222, MinusLogProbMetric: 5.0222, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 111: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0222 - MinusLogProbMetric: 5.0222 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 112/1000
2023-09-12 09:22:29.845 
Epoch 112/1000 
	 loss: 5.0230, MinusLogProbMetric: 5.0230, val_loss: 5.1075, val_MinusLogProbMetric: 5.1075

Epoch 112: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0230 - MinusLogProbMetric: 5.0230 - val_loss: 5.1075 - val_MinusLogProbMetric: 5.1075 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-12 09:22:41.101 
Epoch 113/1000 
	 loss: 5.0254, MinusLogProbMetric: 5.0254, val_loss: 5.1402, val_MinusLogProbMetric: 5.1402

Epoch 113: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0254 - MinusLogProbMetric: 5.0254 - val_loss: 5.1402 - val_MinusLogProbMetric: 5.1402 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 114/1000
2023-09-12 09:22:52.398 
Epoch 114/1000 
	 loss: 5.0246, MinusLogProbMetric: 5.0246, val_loss: 5.0997, val_MinusLogProbMetric: 5.0997

Epoch 114: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0246 - MinusLogProbMetric: 5.0246 - val_loss: 5.0997 - val_MinusLogProbMetric: 5.0997 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 115/1000
2023-09-12 09:23:03.806 
Epoch 115/1000 
	 loss: 5.0250, MinusLogProbMetric: 5.0250, val_loss: 5.1174, val_MinusLogProbMetric: 5.1174

Epoch 115: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0250 - MinusLogProbMetric: 5.0250 - val_loss: 5.1174 - val_MinusLogProbMetric: 5.1174 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 116/1000
2023-09-12 09:23:15.182 
Epoch 116/1000 
	 loss: 5.0296, MinusLogProbMetric: 5.0296, val_loss: 5.1066, val_MinusLogProbMetric: 5.1066

Epoch 116: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0296 - MinusLogProbMetric: 5.0296 - val_loss: 5.1066 - val_MinusLogProbMetric: 5.1066 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 117/1000
2023-09-12 09:23:26.595 
Epoch 117/1000 
	 loss: 5.0262, MinusLogProbMetric: 5.0262, val_loss: 5.1626, val_MinusLogProbMetric: 5.1626

Epoch 117: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0262 - MinusLogProbMetric: 5.0262 - val_loss: 5.1626 - val_MinusLogProbMetric: 5.1626 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 118/1000
2023-09-12 09:23:37.781 
Epoch 118/1000 
	 loss: 5.0227, MinusLogProbMetric: 5.0227, val_loss: 5.1087, val_MinusLogProbMetric: 5.1087

Epoch 118: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0227 - MinusLogProbMetric: 5.0227 - val_loss: 5.1087 - val_MinusLogProbMetric: 5.1087 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 119/1000
2023-09-12 09:23:49.116 
Epoch 119/1000 
	 loss: 5.0209, MinusLogProbMetric: 5.0209, val_loss: 5.1030, val_MinusLogProbMetric: 5.1030

Epoch 119: val_loss did not improve from 5.08345
196/196 - 11s - loss: 5.0209 - MinusLogProbMetric: 5.0209 - val_loss: 5.1030 - val_MinusLogProbMetric: 5.1030 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 120/1000
2023-09-12 09:24:00.424 
Epoch 120/1000 
	 loss: 4.9911, MinusLogProbMetric: 4.9911, val_loss: 5.0920, val_MinusLogProbMetric: 5.0920

Epoch 120: val_loss did not improve from 5.08345
196/196 - 11s - loss: 4.9911 - MinusLogProbMetric: 4.9911 - val_loss: 5.0920 - val_MinusLogProbMetric: 5.0920 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 121/1000
2023-09-12 09:24:11.824 
Epoch 121/1000 
	 loss: 4.9873, MinusLogProbMetric: 4.9873, val_loss: 5.0811, val_MinusLogProbMetric: 5.0811

Epoch 121: val_loss improved from 5.08345 to 5.08111, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_100/weights/best_weights.h5
196/196 - 12s - loss: 4.9873 - MinusLogProbMetric: 4.9873 - val_loss: 5.0811 - val_MinusLogProbMetric: 5.0811 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 122/1000
2023-09-12 09:24:23.333 
Epoch 122/1000 
	 loss: 4.9855, MinusLogProbMetric: 4.9855, val_loss: 5.0884, val_MinusLogProbMetric: 5.0884

Epoch 122: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9855 - MinusLogProbMetric: 4.9855 - val_loss: 5.0884 - val_MinusLogProbMetric: 5.0884 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 123/1000
2023-09-12 09:24:34.829 
Epoch 123/1000 
	 loss: 4.9871, MinusLogProbMetric: 4.9871, val_loss: 5.0916, val_MinusLogProbMetric: 5.0916

Epoch 123: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9871 - MinusLogProbMetric: 4.9871 - val_loss: 5.0916 - val_MinusLogProbMetric: 5.0916 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 124/1000
2023-09-12 09:24:46.315 
Epoch 124/1000 
	 loss: 4.9843, MinusLogProbMetric: 4.9843, val_loss: 5.0947, val_MinusLogProbMetric: 5.0947

Epoch 124: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9843 - MinusLogProbMetric: 4.9843 - val_loss: 5.0947 - val_MinusLogProbMetric: 5.0947 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 125/1000
2023-09-12 09:24:57.489 
Epoch 125/1000 
	 loss: 4.9890, MinusLogProbMetric: 4.9890, val_loss: 5.0959, val_MinusLogProbMetric: 5.0959

Epoch 125: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9890 - MinusLogProbMetric: 4.9890 - val_loss: 5.0959 - val_MinusLogProbMetric: 5.0959 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 126/1000
2023-09-12 09:25:08.770 
Epoch 126/1000 
	 loss: 4.9972, MinusLogProbMetric: 4.9972, val_loss: 5.0836, val_MinusLogProbMetric: 5.0836

Epoch 126: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9972 - MinusLogProbMetric: 4.9972 - val_loss: 5.0836 - val_MinusLogProbMetric: 5.0836 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 127/1000
2023-09-12 09:25:20.079 
Epoch 127/1000 
	 loss: 4.9845, MinusLogProbMetric: 4.9845, val_loss: 5.0942, val_MinusLogProbMetric: 5.0942

Epoch 127: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9845 - MinusLogProbMetric: 4.9845 - val_loss: 5.0942 - val_MinusLogProbMetric: 5.0942 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 128/1000
2023-09-12 09:25:31.386 
Epoch 128/1000 
	 loss: 4.9843, MinusLogProbMetric: 4.9843, val_loss: 5.0931, val_MinusLogProbMetric: 5.0931

Epoch 128: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9843 - MinusLogProbMetric: 4.9843 - val_loss: 5.0931 - val_MinusLogProbMetric: 5.0931 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 129/1000
2023-09-12 09:25:42.702 
Epoch 129/1000 
	 loss: 4.9852, MinusLogProbMetric: 4.9852, val_loss: 5.0917, val_MinusLogProbMetric: 5.0917

Epoch 129: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9852 - MinusLogProbMetric: 4.9852 - val_loss: 5.0917 - val_MinusLogProbMetric: 5.0917 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 130/1000
2023-09-12 09:25:54.062 
Epoch 130/1000 
	 loss: 4.9820, MinusLogProbMetric: 4.9820, val_loss: 5.0884, val_MinusLogProbMetric: 5.0884

Epoch 130: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9820 - MinusLogProbMetric: 4.9820 - val_loss: 5.0884 - val_MinusLogProbMetric: 5.0884 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 131/1000
2023-09-12 09:26:04.940 
Epoch 131/1000 
	 loss: 4.9843, MinusLogProbMetric: 4.9843, val_loss: 5.0923, val_MinusLogProbMetric: 5.0923

Epoch 131: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9843 - MinusLogProbMetric: 4.9843 - val_loss: 5.0923 - val_MinusLogProbMetric: 5.0923 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 132/1000
2023-09-12 09:26:14.920 
Epoch 132/1000 
	 loss: 4.9822, MinusLogProbMetric: 4.9822, val_loss: 5.1021, val_MinusLogProbMetric: 5.1021

Epoch 132: val_loss did not improve from 5.08111
196/196 - 10s - loss: 4.9822 - MinusLogProbMetric: 4.9822 - val_loss: 5.1021 - val_MinusLogProbMetric: 5.1021 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 133/1000
2023-09-12 09:26:24.504 
Epoch 133/1000 
	 loss: 4.9829, MinusLogProbMetric: 4.9829, val_loss: 5.0926, val_MinusLogProbMetric: 5.0926

Epoch 133: val_loss did not improve from 5.08111
196/196 - 10s - loss: 4.9829 - MinusLogProbMetric: 4.9829 - val_loss: 5.0926 - val_MinusLogProbMetric: 5.0926 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 134/1000
2023-09-12 09:26:34.166 
Epoch 134/1000 
	 loss: 4.9848, MinusLogProbMetric: 4.9848, val_loss: 5.0932, val_MinusLogProbMetric: 5.0932

Epoch 134: val_loss did not improve from 5.08111
196/196 - 10s - loss: 4.9848 - MinusLogProbMetric: 4.9848 - val_loss: 5.0932 - val_MinusLogProbMetric: 5.0932 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 135/1000
2023-09-12 09:26:43.841 
Epoch 135/1000 
	 loss: 4.9808, MinusLogProbMetric: 4.9808, val_loss: 5.1173, val_MinusLogProbMetric: 5.1173

Epoch 135: val_loss did not improve from 5.08111
196/196 - 10s - loss: 4.9808 - MinusLogProbMetric: 4.9808 - val_loss: 5.1173 - val_MinusLogProbMetric: 5.1173 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 136/1000
2023-09-12 09:26:54.064 
Epoch 136/1000 
	 loss: 4.9871, MinusLogProbMetric: 4.9871, val_loss: 5.0930, val_MinusLogProbMetric: 5.0930

Epoch 136: val_loss did not improve from 5.08111
196/196 - 10s - loss: 4.9871 - MinusLogProbMetric: 4.9871 - val_loss: 5.0930 - val_MinusLogProbMetric: 5.0930 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 137/1000
2023-09-12 09:27:05.437 
Epoch 137/1000 
	 loss: 4.9827, MinusLogProbMetric: 4.9827, val_loss: 5.1032, val_MinusLogProbMetric: 5.1032

Epoch 137: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9827 - MinusLogProbMetric: 4.9827 - val_loss: 5.1032 - val_MinusLogProbMetric: 5.1032 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 138/1000
2023-09-12 09:27:16.780 
Epoch 138/1000 
	 loss: 4.9833, MinusLogProbMetric: 4.9833, val_loss: 5.0912, val_MinusLogProbMetric: 5.0912

Epoch 138: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9833 - MinusLogProbMetric: 4.9833 - val_loss: 5.0912 - val_MinusLogProbMetric: 5.0912 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 139/1000
2023-09-12 09:27:28.067 
Epoch 139/1000 
	 loss: 4.9798, MinusLogProbMetric: 4.9798, val_loss: 5.0956, val_MinusLogProbMetric: 5.0956

Epoch 139: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9798 - MinusLogProbMetric: 4.9798 - val_loss: 5.0956 - val_MinusLogProbMetric: 5.0956 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 140/1000
2023-09-12 09:27:39.281 
Epoch 140/1000 
	 loss: 4.9797, MinusLogProbMetric: 4.9797, val_loss: 5.0936, val_MinusLogProbMetric: 5.0936

Epoch 140: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9797 - MinusLogProbMetric: 4.9797 - val_loss: 5.0936 - val_MinusLogProbMetric: 5.0936 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 141/1000
2023-09-12 09:27:50.594 
Epoch 141/1000 
	 loss: 4.9820, MinusLogProbMetric: 4.9820, val_loss: 5.1082, val_MinusLogProbMetric: 5.1082

Epoch 141: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9820 - MinusLogProbMetric: 4.9820 - val_loss: 5.1082 - val_MinusLogProbMetric: 5.1082 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 142/1000
2023-09-12 09:28:01.912 
Epoch 142/1000 
	 loss: 4.9812, MinusLogProbMetric: 4.9812, val_loss: 5.0995, val_MinusLogProbMetric: 5.0995

Epoch 142: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9812 - MinusLogProbMetric: 4.9812 - val_loss: 5.0995 - val_MinusLogProbMetric: 5.0995 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 143/1000
2023-09-12 09:28:13.260 
Epoch 143/1000 
	 loss: 4.9806, MinusLogProbMetric: 4.9806, val_loss: 5.1013, val_MinusLogProbMetric: 5.1013

Epoch 143: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9806 - MinusLogProbMetric: 4.9806 - val_loss: 5.1013 - val_MinusLogProbMetric: 5.1013 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-12 09:28:24.693 
Epoch 144/1000 
	 loss: 4.9782, MinusLogProbMetric: 4.9782, val_loss: 5.1031, val_MinusLogProbMetric: 5.1031

Epoch 144: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9782 - MinusLogProbMetric: 4.9782 - val_loss: 5.1031 - val_MinusLogProbMetric: 5.1031 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 145/1000
2023-09-12 09:28:35.944 
Epoch 145/1000 
	 loss: 4.9745, MinusLogProbMetric: 4.9745, val_loss: 5.1084, val_MinusLogProbMetric: 5.1084

Epoch 145: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9745 - MinusLogProbMetric: 4.9745 - val_loss: 5.1084 - val_MinusLogProbMetric: 5.1084 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 146/1000
2023-09-12 09:28:47.323 
Epoch 146/1000 
	 loss: 4.9868, MinusLogProbMetric: 4.9868, val_loss: 5.1130, val_MinusLogProbMetric: 5.1130

Epoch 146: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9868 - MinusLogProbMetric: 4.9868 - val_loss: 5.1130 - val_MinusLogProbMetric: 5.1130 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-12 09:28:58.633 
Epoch 147/1000 
	 loss: 4.9800, MinusLogProbMetric: 4.9800, val_loss: 5.1090, val_MinusLogProbMetric: 5.1090

Epoch 147: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9800 - MinusLogProbMetric: 4.9800 - val_loss: 5.1090 - val_MinusLogProbMetric: 5.1090 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 148/1000
2023-09-12 09:29:09.825 
Epoch 148/1000 
	 loss: 4.9764, MinusLogProbMetric: 4.9764, val_loss: 5.0986, val_MinusLogProbMetric: 5.0986

Epoch 148: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9764 - MinusLogProbMetric: 4.9764 - val_loss: 5.0986 - val_MinusLogProbMetric: 5.0986 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 149/1000
2023-09-12 09:29:21.103 
Epoch 149/1000 
	 loss: 4.9760, MinusLogProbMetric: 4.9760, val_loss: 5.0973, val_MinusLogProbMetric: 5.0973

Epoch 149: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9760 - MinusLogProbMetric: 4.9760 - val_loss: 5.0973 - val_MinusLogProbMetric: 5.0973 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-12 09:29:32.422 
Epoch 150/1000 
	 loss: 4.9758, MinusLogProbMetric: 4.9758, val_loss: 5.1108, val_MinusLogProbMetric: 5.1108

Epoch 150: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9758 - MinusLogProbMetric: 4.9758 - val_loss: 5.1108 - val_MinusLogProbMetric: 5.1108 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 151/1000
2023-09-12 09:29:43.942 
Epoch 151/1000 
	 loss: 4.9746, MinusLogProbMetric: 4.9746, val_loss: 5.1149, val_MinusLogProbMetric: 5.1149

Epoch 151: val_loss did not improve from 5.08111
196/196 - 12s - loss: 4.9746 - MinusLogProbMetric: 4.9746 - val_loss: 5.1149 - val_MinusLogProbMetric: 5.1149 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 152/1000
2023-09-12 09:29:55.189 
Epoch 152/1000 
	 loss: 4.9754, MinusLogProbMetric: 4.9754, val_loss: 5.1069, val_MinusLogProbMetric: 5.1069

Epoch 152: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9754 - MinusLogProbMetric: 4.9754 - val_loss: 5.1069 - val_MinusLogProbMetric: 5.1069 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 153/1000
2023-09-12 09:30:06.604 
Epoch 153/1000 
	 loss: 4.9735, MinusLogProbMetric: 4.9735, val_loss: 5.1136, val_MinusLogProbMetric: 5.1136

Epoch 153: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9735 - MinusLogProbMetric: 4.9735 - val_loss: 5.1136 - val_MinusLogProbMetric: 5.1136 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 154/1000
2023-09-12 09:30:17.824 
Epoch 154/1000 
	 loss: 4.9908, MinusLogProbMetric: 4.9908, val_loss: 5.1025, val_MinusLogProbMetric: 5.1025

Epoch 154: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9908 - MinusLogProbMetric: 4.9908 - val_loss: 5.1025 - val_MinusLogProbMetric: 5.1025 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 155/1000
2023-09-12 09:30:29.118 
Epoch 155/1000 
	 loss: 4.9738, MinusLogProbMetric: 4.9738, val_loss: 5.1067, val_MinusLogProbMetric: 5.1067

Epoch 155: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9738 - MinusLogProbMetric: 4.9738 - val_loss: 5.1067 - val_MinusLogProbMetric: 5.1067 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 156/1000
2023-09-12 09:30:40.492 
Epoch 156/1000 
	 loss: 4.9743, MinusLogProbMetric: 4.9743, val_loss: 5.1064, val_MinusLogProbMetric: 5.1064

Epoch 156: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9743 - MinusLogProbMetric: 4.9743 - val_loss: 5.1064 - val_MinusLogProbMetric: 5.1064 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 157/1000
2023-09-12 09:30:51.698 
Epoch 157/1000 
	 loss: 4.9746, MinusLogProbMetric: 4.9746, val_loss: 5.1112, val_MinusLogProbMetric: 5.1112

Epoch 157: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9746 - MinusLogProbMetric: 4.9746 - val_loss: 5.1112 - val_MinusLogProbMetric: 5.1112 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 158/1000
2023-09-12 09:31:02.894 
Epoch 158/1000 
	 loss: 4.9726, MinusLogProbMetric: 4.9726, val_loss: 5.1120, val_MinusLogProbMetric: 5.1120

Epoch 158: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9726 - MinusLogProbMetric: 4.9726 - val_loss: 5.1120 - val_MinusLogProbMetric: 5.1120 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 159/1000
2023-09-12 09:31:14.156 
Epoch 159/1000 
	 loss: 4.9712, MinusLogProbMetric: 4.9712, val_loss: 5.1133, val_MinusLogProbMetric: 5.1133

Epoch 159: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9712 - MinusLogProbMetric: 4.9712 - val_loss: 5.1133 - val_MinusLogProbMetric: 5.1133 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 160/1000
2023-09-12 09:31:25.469 
Epoch 160/1000 
	 loss: 4.9717, MinusLogProbMetric: 4.9717, val_loss: 5.1077, val_MinusLogProbMetric: 5.1077

Epoch 160: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9717 - MinusLogProbMetric: 4.9717 - val_loss: 5.1077 - val_MinusLogProbMetric: 5.1077 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 161/1000
2023-09-12 09:31:36.899 
Epoch 161/1000 
	 loss: 4.9717, MinusLogProbMetric: 4.9717, val_loss: 5.1073, val_MinusLogProbMetric: 5.1073

Epoch 161: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9717 - MinusLogProbMetric: 4.9717 - val_loss: 5.1073 - val_MinusLogProbMetric: 5.1073 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 162/1000
2023-09-12 09:31:48.157 
Epoch 162/1000 
	 loss: 4.9679, MinusLogProbMetric: 4.9679, val_loss: 5.1130, val_MinusLogProbMetric: 5.1130

Epoch 162: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9679 - MinusLogProbMetric: 4.9679 - val_loss: 5.1130 - val_MinusLogProbMetric: 5.1130 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 163/1000
2023-09-12 09:31:59.302 
Epoch 163/1000 
	 loss: 4.9694, MinusLogProbMetric: 4.9694, val_loss: 5.1074, val_MinusLogProbMetric: 5.1074

Epoch 163: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9694 - MinusLogProbMetric: 4.9694 - val_loss: 5.1074 - val_MinusLogProbMetric: 5.1074 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 164/1000
2023-09-12 09:32:10.655 
Epoch 164/1000 
	 loss: 4.9686, MinusLogProbMetric: 4.9686, val_loss: 5.1173, val_MinusLogProbMetric: 5.1173

Epoch 164: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9686 - MinusLogProbMetric: 4.9686 - val_loss: 5.1173 - val_MinusLogProbMetric: 5.1173 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 165/1000
2023-09-12 09:32:21.990 
Epoch 165/1000 
	 loss: 4.9669, MinusLogProbMetric: 4.9669, val_loss: 5.1120, val_MinusLogProbMetric: 5.1120

Epoch 165: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9669 - MinusLogProbMetric: 4.9669 - val_loss: 5.1120 - val_MinusLogProbMetric: 5.1120 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 166/1000
2023-09-12 09:32:33.206 
Epoch 166/1000 
	 loss: 4.9663, MinusLogProbMetric: 4.9663, val_loss: 5.1221, val_MinusLogProbMetric: 5.1221

Epoch 166: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9663 - MinusLogProbMetric: 4.9663 - val_loss: 5.1221 - val_MinusLogProbMetric: 5.1221 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 167/1000
2023-09-12 09:32:44.542 
Epoch 167/1000 
	 loss: 4.9689, MinusLogProbMetric: 4.9689, val_loss: 5.1081, val_MinusLogProbMetric: 5.1081

Epoch 167: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9689 - MinusLogProbMetric: 4.9689 - val_loss: 5.1081 - val_MinusLogProbMetric: 5.1081 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 168/1000
2023-09-12 09:32:55.756 
Epoch 168/1000 
	 loss: 4.9672, MinusLogProbMetric: 4.9672, val_loss: 5.1174, val_MinusLogProbMetric: 5.1174

Epoch 168: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9672 - MinusLogProbMetric: 4.9672 - val_loss: 5.1174 - val_MinusLogProbMetric: 5.1174 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 169/1000
2023-09-12 09:33:06.996 
Epoch 169/1000 
	 loss: 4.9667, MinusLogProbMetric: 4.9667, val_loss: 5.1127, val_MinusLogProbMetric: 5.1127

Epoch 169: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9667 - MinusLogProbMetric: 4.9667 - val_loss: 5.1127 - val_MinusLogProbMetric: 5.1127 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 170/1000
2023-09-12 09:33:18.275 
Epoch 170/1000 
	 loss: 4.9661, MinusLogProbMetric: 4.9661, val_loss: 5.1179, val_MinusLogProbMetric: 5.1179

Epoch 170: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9661 - MinusLogProbMetric: 4.9661 - val_loss: 5.1179 - val_MinusLogProbMetric: 5.1179 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 171/1000
2023-09-12 09:33:29.535 
Epoch 171/1000 
	 loss: 4.9654, MinusLogProbMetric: 4.9654, val_loss: 5.1168, val_MinusLogProbMetric: 5.1168

Epoch 171: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9654 - MinusLogProbMetric: 4.9654 - val_loss: 5.1168 - val_MinusLogProbMetric: 5.1168 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 172/1000
2023-09-12 09:33:40.844 
Epoch 172/1000 
	 loss: 4.9491, MinusLogProbMetric: 4.9491, val_loss: 5.1114, val_MinusLogProbMetric: 5.1114

Epoch 172: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9491 - MinusLogProbMetric: 4.9491 - val_loss: 5.1114 - val_MinusLogProbMetric: 5.1114 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 173/1000
2023-09-12 09:33:52.161 
Epoch 173/1000 
	 loss: 4.9485, MinusLogProbMetric: 4.9485, val_loss: 5.1057, val_MinusLogProbMetric: 5.1057

Epoch 173: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9485 - MinusLogProbMetric: 4.9485 - val_loss: 5.1057 - val_MinusLogProbMetric: 5.1057 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 174/1000
2023-09-12 09:34:03.587 
Epoch 174/1000 
	 loss: 4.9471, MinusLogProbMetric: 4.9471, val_loss: 5.1111, val_MinusLogProbMetric: 5.1111

Epoch 174: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9471 - MinusLogProbMetric: 4.9471 - val_loss: 5.1111 - val_MinusLogProbMetric: 5.1111 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 175/1000
2023-09-12 09:34:14.831 
Epoch 175/1000 
	 loss: 4.9472, MinusLogProbMetric: 4.9472, val_loss: 5.1027, val_MinusLogProbMetric: 5.1027

Epoch 175: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9472 - MinusLogProbMetric: 4.9472 - val_loss: 5.1027 - val_MinusLogProbMetric: 5.1027 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 176/1000
2023-09-12 09:34:25.976 
Epoch 176/1000 
	 loss: 4.9461, MinusLogProbMetric: 4.9461, val_loss: 5.1101, val_MinusLogProbMetric: 5.1101

Epoch 176: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9461 - MinusLogProbMetric: 4.9461 - val_loss: 5.1101 - val_MinusLogProbMetric: 5.1101 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 177/1000
2023-09-12 09:34:37.319 
Epoch 177/1000 
	 loss: 4.9468, MinusLogProbMetric: 4.9468, val_loss: 5.1042, val_MinusLogProbMetric: 5.1042

Epoch 177: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9468 - MinusLogProbMetric: 4.9468 - val_loss: 5.1042 - val_MinusLogProbMetric: 5.1042 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 178/1000
2023-09-12 09:34:48.573 
Epoch 178/1000 
	 loss: 4.9465, MinusLogProbMetric: 4.9465, val_loss: 5.1059, val_MinusLogProbMetric: 5.1059

Epoch 178: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9465 - MinusLogProbMetric: 4.9465 - val_loss: 5.1059 - val_MinusLogProbMetric: 5.1059 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 179/1000
2023-09-12 09:34:59.919 
Epoch 179/1000 
	 loss: 4.9463, MinusLogProbMetric: 4.9463, val_loss: 5.1077, val_MinusLogProbMetric: 5.1077

Epoch 179: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9463 - MinusLogProbMetric: 4.9463 - val_loss: 5.1077 - val_MinusLogProbMetric: 5.1077 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 180/1000
2023-09-12 09:35:11.155 
Epoch 180/1000 
	 loss: 4.9455, MinusLogProbMetric: 4.9455, val_loss: 5.1146, val_MinusLogProbMetric: 5.1146

Epoch 180: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9455 - MinusLogProbMetric: 4.9455 - val_loss: 5.1146 - val_MinusLogProbMetric: 5.1146 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 181/1000
2023-09-12 09:35:22.509 
Epoch 181/1000 
	 loss: 4.9465, MinusLogProbMetric: 4.9465, val_loss: 5.1062, val_MinusLogProbMetric: 5.1062

Epoch 181: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9465 - MinusLogProbMetric: 4.9465 - val_loss: 5.1062 - val_MinusLogProbMetric: 5.1062 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 182/1000
2023-09-12 09:35:33.780 
Epoch 182/1000 
	 loss: 4.9451, MinusLogProbMetric: 4.9451, val_loss: 5.1075, val_MinusLogProbMetric: 5.1075

Epoch 182: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9451 - MinusLogProbMetric: 4.9451 - val_loss: 5.1075 - val_MinusLogProbMetric: 5.1075 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 183/1000
2023-09-12 09:35:45.179 
Epoch 183/1000 
	 loss: 4.9446, MinusLogProbMetric: 4.9446, val_loss: 5.1069, val_MinusLogProbMetric: 5.1069

Epoch 183: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9446 - MinusLogProbMetric: 4.9446 - val_loss: 5.1069 - val_MinusLogProbMetric: 5.1069 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 184/1000
2023-09-12 09:35:56.432 
Epoch 184/1000 
	 loss: 4.9442, MinusLogProbMetric: 4.9442, val_loss: 5.1103, val_MinusLogProbMetric: 5.1103

Epoch 184: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9442 - MinusLogProbMetric: 4.9442 - val_loss: 5.1103 - val_MinusLogProbMetric: 5.1103 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 185/1000
2023-09-12 09:36:07.750 
Epoch 185/1000 
	 loss: 4.9438, MinusLogProbMetric: 4.9438, val_loss: 5.1106, val_MinusLogProbMetric: 5.1106

Epoch 185: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9438 - MinusLogProbMetric: 4.9438 - val_loss: 5.1106 - val_MinusLogProbMetric: 5.1106 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 186/1000
2023-09-12 09:36:19.069 
Epoch 186/1000 
	 loss: 4.9436, MinusLogProbMetric: 4.9436, val_loss: 5.1126, val_MinusLogProbMetric: 5.1126

Epoch 186: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9436 - MinusLogProbMetric: 4.9436 - val_loss: 5.1126 - val_MinusLogProbMetric: 5.1126 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 187/1000
2023-09-12 09:36:30.400 
Epoch 187/1000 
	 loss: 4.9435, MinusLogProbMetric: 4.9435, val_loss: 5.1088, val_MinusLogProbMetric: 5.1088

Epoch 187: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9435 - MinusLogProbMetric: 4.9435 - val_loss: 5.1088 - val_MinusLogProbMetric: 5.1088 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 188/1000
2023-09-12 09:36:41.693 
Epoch 188/1000 
	 loss: 4.9425, MinusLogProbMetric: 4.9425, val_loss: 5.1117, val_MinusLogProbMetric: 5.1117

Epoch 188: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9425 - MinusLogProbMetric: 4.9425 - val_loss: 5.1117 - val_MinusLogProbMetric: 5.1117 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 189/1000
2023-09-12 09:36:52.979 
Epoch 189/1000 
	 loss: 4.9427, MinusLogProbMetric: 4.9427, val_loss: 5.1081, val_MinusLogProbMetric: 5.1081

Epoch 189: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9427 - MinusLogProbMetric: 4.9427 - val_loss: 5.1081 - val_MinusLogProbMetric: 5.1081 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 190/1000
2023-09-12 09:37:04.237 
Epoch 190/1000 
	 loss: 4.9419, MinusLogProbMetric: 4.9419, val_loss: 5.1122, val_MinusLogProbMetric: 5.1122

Epoch 190: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9419 - MinusLogProbMetric: 4.9419 - val_loss: 5.1122 - val_MinusLogProbMetric: 5.1122 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 191/1000
2023-09-12 09:37:15.506 
Epoch 191/1000 
	 loss: 4.9414, MinusLogProbMetric: 4.9414, val_loss: 5.1176, val_MinusLogProbMetric: 5.1176

Epoch 191: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9414 - MinusLogProbMetric: 4.9414 - val_loss: 5.1176 - val_MinusLogProbMetric: 5.1176 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 192/1000
2023-09-12 09:37:26.788 
Epoch 192/1000 
	 loss: 4.9414, MinusLogProbMetric: 4.9414, val_loss: 5.1136, val_MinusLogProbMetric: 5.1136

Epoch 192: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9414 - MinusLogProbMetric: 4.9414 - val_loss: 5.1136 - val_MinusLogProbMetric: 5.1136 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 193/1000
2023-09-12 09:37:38.062 
Epoch 193/1000 
	 loss: 4.9453, MinusLogProbMetric: 4.9453, val_loss: 5.1155, val_MinusLogProbMetric: 5.1155

Epoch 193: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9453 - MinusLogProbMetric: 4.9453 - val_loss: 5.1155 - val_MinusLogProbMetric: 5.1155 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 194/1000
2023-09-12 09:37:49.271 
Epoch 194/1000 
	 loss: 4.9418, MinusLogProbMetric: 4.9418, val_loss: 5.1139, val_MinusLogProbMetric: 5.1139

Epoch 194: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9418 - MinusLogProbMetric: 4.9418 - val_loss: 5.1139 - val_MinusLogProbMetric: 5.1139 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 195/1000
2023-09-12 09:38:00.575 
Epoch 195/1000 
	 loss: 4.9411, MinusLogProbMetric: 4.9411, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 195: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9411 - MinusLogProbMetric: 4.9411 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 196/1000
2023-09-12 09:38:11.773 
Epoch 196/1000 
	 loss: 4.9412, MinusLogProbMetric: 4.9412, val_loss: 5.1161, val_MinusLogProbMetric: 5.1161

Epoch 196: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9412 - MinusLogProbMetric: 4.9412 - val_loss: 5.1161 - val_MinusLogProbMetric: 5.1161 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 197/1000
2023-09-12 09:38:23.116 
Epoch 197/1000 
	 loss: 4.9405, MinusLogProbMetric: 4.9405, val_loss: 5.1145, val_MinusLogProbMetric: 5.1145

Epoch 197: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9405 - MinusLogProbMetric: 4.9405 - val_loss: 5.1145 - val_MinusLogProbMetric: 5.1145 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 198/1000
2023-09-12 09:38:34.422 
Epoch 198/1000 
	 loss: 4.9411, MinusLogProbMetric: 4.9411, val_loss: 5.1221, val_MinusLogProbMetric: 5.1221

Epoch 198: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9411 - MinusLogProbMetric: 4.9411 - val_loss: 5.1221 - val_MinusLogProbMetric: 5.1221 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 199/1000
2023-09-12 09:38:45.716 
Epoch 199/1000 
	 loss: 4.9396, MinusLogProbMetric: 4.9396, val_loss: 5.1173, val_MinusLogProbMetric: 5.1173

Epoch 199: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9396 - MinusLogProbMetric: 4.9396 - val_loss: 5.1173 - val_MinusLogProbMetric: 5.1173 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 200/1000
2023-09-12 09:38:57.059 
Epoch 200/1000 
	 loss: 4.9391, MinusLogProbMetric: 4.9391, val_loss: 5.1203, val_MinusLogProbMetric: 5.1203

Epoch 200: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9391 - MinusLogProbMetric: 4.9391 - val_loss: 5.1203 - val_MinusLogProbMetric: 5.1203 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 201/1000
2023-09-12 09:39:08.490 
Epoch 201/1000 
	 loss: 4.9393, MinusLogProbMetric: 4.9393, val_loss: 5.1134, val_MinusLogProbMetric: 5.1134

Epoch 201: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9393 - MinusLogProbMetric: 4.9393 - val_loss: 5.1134 - val_MinusLogProbMetric: 5.1134 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 202/1000
2023-09-12 09:39:19.829 
Epoch 202/1000 
	 loss: 4.9396, MinusLogProbMetric: 4.9396, val_loss: 5.1304, val_MinusLogProbMetric: 5.1304

Epoch 202: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9396 - MinusLogProbMetric: 4.9396 - val_loss: 5.1304 - val_MinusLogProbMetric: 5.1304 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 203/1000
2023-09-12 09:39:31.040 
Epoch 203/1000 
	 loss: 4.9405, MinusLogProbMetric: 4.9405, val_loss: 5.1210, val_MinusLogProbMetric: 5.1210

Epoch 203: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9405 - MinusLogProbMetric: 4.9405 - val_loss: 5.1210 - val_MinusLogProbMetric: 5.1210 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 204/1000
2023-09-12 09:39:42.405 
Epoch 204/1000 
	 loss: 4.9380, MinusLogProbMetric: 4.9380, val_loss: 5.1282, val_MinusLogProbMetric: 5.1282

Epoch 204: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9380 - MinusLogProbMetric: 4.9380 - val_loss: 5.1282 - val_MinusLogProbMetric: 5.1282 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 205/1000
2023-09-12 09:39:53.697 
Epoch 205/1000 
	 loss: 4.9379, MinusLogProbMetric: 4.9379, val_loss: 5.1182, val_MinusLogProbMetric: 5.1182

Epoch 205: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9379 - MinusLogProbMetric: 4.9379 - val_loss: 5.1182 - val_MinusLogProbMetric: 5.1182 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-12 09:40:04.953 
Epoch 206/1000 
	 loss: 4.9387, MinusLogProbMetric: 4.9387, val_loss: 5.1215, val_MinusLogProbMetric: 5.1215

Epoch 206: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9387 - MinusLogProbMetric: 4.9387 - val_loss: 5.1215 - val_MinusLogProbMetric: 5.1215 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 207/1000
2023-09-12 09:40:16.241 
Epoch 207/1000 
	 loss: 4.9380, MinusLogProbMetric: 4.9380, val_loss: 5.1251, val_MinusLogProbMetric: 5.1251

Epoch 207: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9380 - MinusLogProbMetric: 4.9380 - val_loss: 5.1251 - val_MinusLogProbMetric: 5.1251 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 208/1000
2023-09-12 09:40:27.444 
Epoch 208/1000 
	 loss: 4.9375, MinusLogProbMetric: 4.9375, val_loss: 5.1188, val_MinusLogProbMetric: 5.1188

Epoch 208: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9375 - MinusLogProbMetric: 4.9375 - val_loss: 5.1188 - val_MinusLogProbMetric: 5.1188 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 209/1000
2023-09-12 09:40:38.838 
Epoch 209/1000 
	 loss: 4.9367, MinusLogProbMetric: 4.9367, val_loss: 5.1197, val_MinusLogProbMetric: 5.1197

Epoch 209: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9367 - MinusLogProbMetric: 4.9367 - val_loss: 5.1197 - val_MinusLogProbMetric: 5.1197 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 210/1000
2023-09-12 09:40:50.073 
Epoch 210/1000 
	 loss: 4.9360, MinusLogProbMetric: 4.9360, val_loss: 5.1260, val_MinusLogProbMetric: 5.1260

Epoch 210: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9360 - MinusLogProbMetric: 4.9360 - val_loss: 5.1260 - val_MinusLogProbMetric: 5.1260 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 211/1000
2023-09-12 09:41:01.539 
Epoch 211/1000 
	 loss: 4.9372, MinusLogProbMetric: 4.9372, val_loss: 5.1217, val_MinusLogProbMetric: 5.1217

Epoch 211: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9372 - MinusLogProbMetric: 4.9372 - val_loss: 5.1217 - val_MinusLogProbMetric: 5.1217 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 212/1000
2023-09-12 09:41:12.915 
Epoch 212/1000 
	 loss: 4.9355, MinusLogProbMetric: 4.9355, val_loss: 5.1199, val_MinusLogProbMetric: 5.1199

Epoch 212: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9355 - MinusLogProbMetric: 4.9355 - val_loss: 5.1199 - val_MinusLogProbMetric: 5.1199 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 213/1000
2023-09-12 09:41:24.169 
Epoch 213/1000 
	 loss: 4.9360, MinusLogProbMetric: 4.9360, val_loss: 5.1210, val_MinusLogProbMetric: 5.1210

Epoch 213: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9360 - MinusLogProbMetric: 4.9360 - val_loss: 5.1210 - val_MinusLogProbMetric: 5.1210 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 214/1000
2023-09-12 09:41:35.474 
Epoch 214/1000 
	 loss: 4.9375, MinusLogProbMetric: 4.9375, val_loss: 5.1218, val_MinusLogProbMetric: 5.1218

Epoch 214: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9375 - MinusLogProbMetric: 4.9375 - val_loss: 5.1218 - val_MinusLogProbMetric: 5.1218 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 215/1000
2023-09-12 09:41:46.760 
Epoch 215/1000 
	 loss: 4.9356, MinusLogProbMetric: 4.9356, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 215: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9356 - MinusLogProbMetric: 4.9356 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 216/1000
2023-09-12 09:41:57.937 
Epoch 216/1000 
	 loss: 4.9359, MinusLogProbMetric: 4.9359, val_loss: 5.1208, val_MinusLogProbMetric: 5.1208

Epoch 216: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9359 - MinusLogProbMetric: 4.9359 - val_loss: 5.1208 - val_MinusLogProbMetric: 5.1208 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 217/1000
2023-09-12 09:42:09.172 
Epoch 217/1000 
	 loss: 4.9364, MinusLogProbMetric: 4.9364, val_loss: 5.1188, val_MinusLogProbMetric: 5.1188

Epoch 217: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9364 - MinusLogProbMetric: 4.9364 - val_loss: 5.1188 - val_MinusLogProbMetric: 5.1188 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 218/1000
2023-09-12 09:42:20.449 
Epoch 218/1000 
	 loss: 4.9329, MinusLogProbMetric: 4.9329, val_loss: 5.1261, val_MinusLogProbMetric: 5.1261

Epoch 218: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9329 - MinusLogProbMetric: 4.9329 - val_loss: 5.1261 - val_MinusLogProbMetric: 5.1261 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 219/1000
2023-09-12 09:42:31.757 
Epoch 219/1000 
	 loss: 4.9344, MinusLogProbMetric: 4.9344, val_loss: 5.1379, val_MinusLogProbMetric: 5.1379

Epoch 219: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9344 - MinusLogProbMetric: 4.9344 - val_loss: 5.1379 - val_MinusLogProbMetric: 5.1379 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 220/1000
2023-09-12 09:42:42.995 
Epoch 220/1000 
	 loss: 4.9348, MinusLogProbMetric: 4.9348, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 220: val_loss did not improve from 5.08111
196/196 - 11s - loss: 4.9348 - MinusLogProbMetric: 4.9348 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 221/1000
2023-09-12 09:42:54.364 
Epoch 221/1000 
	 loss: 4.9335, MinusLogProbMetric: 4.9335, val_loss: 5.1223, val_MinusLogProbMetric: 5.1223

Epoch 221: val_loss did not improve from 5.08111
Restoring model weights from the end of the best epoch: 121.
196/196 - 11s - loss: 4.9335 - MinusLogProbMetric: 4.9335 - val_loss: 5.1223 - val_MinusLogProbMetric: 5.1223 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 221: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 5.649852464906871 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.0090877279872075 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.0582820129347965 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.081283492036164 seconds.
Training succeeded with seed 520.
Model trained in 2496.05 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Metrics computed in 121.57 s.
Plots done in 33.00 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 154.57 s.
===========
Run 100/360 done in 2652.10 s.
===========

Directory ../../results/MsplineN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

===========
Generating train data for run 107.
===========
Train data generated in 0.11 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_107/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 721}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_107/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.1888657 , 7.2769737 , 5.909152  , ..., 9.082649  , 0.9403403 ,
        0.7059462 ],
       [4.176088  , 5.244718  , 0.08754387, ..., 5.8996167 , 2.311068  ,
        1.2166278 ],
       [4.6650877 , 6.4019322 , 0.22886449, ..., 7.5690355 , 1.5742183 ,
        1.4550321 ],
       ...,
       [5.419054  , 7.254176  , 6.182308  , ..., 9.139094  , 0.7199806 ,
        0.66618156],
       [5.6352715 , 7.265105  , 6.0395503 , ..., 9.201334  , 0.8430511 ,
        0.6850713 ],
       [5.4601226 , 7.206975  , 6.318588  , ..., 9.265648  , 0.21410441,
        0.9461267 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_107/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_107
self.data_kwargs: {'seed': 721}
self.x_data: [[5.4665003  7.3385735  6.463596   ... 9.343143   0.328562   0.9563145 ]
 [4.275613   5.4815526  0.15300363 ... 6.9591465  1.6560063  1.2140182 ]
 [4.3759246  5.754746   0.14841495 ... 6.8496375  1.9663514  1.572164  ]
 ...
 [5.7330003  6.8392987  5.978887   ... 9.097835   0.6935307  1.0205181 ]
 [5.699182   7.534408   6.171382   ... 9.451991   0.43158138 0.787925  ]
 [5.5040865  6.9830837  5.4547796  ... 9.276321   1.3292037  1.0396906 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_43 (InputLayer)       [(None, 16)]              0         
                                                                 
 log_prob_layer_14 (LogProbL  (None,)                  214880    
 ayer)                                                           
                                                                 
=================================================================
Total params: 214,880
Trainable params: 214,880
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_14/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_14'")
self.model: <keras.engine.functional.Functional object at 0x7fc6417f8f10>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc61b785630>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc61b785630>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc61b785f00>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc61b786bc0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc61b787130>, <keras.callbacks.ModelCheckpoint object at 0x7fc61b7871f0>, <keras.callbacks.EarlyStopping object at 0x7fc61b787460>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc61b787490>, <keras.callbacks.TerminateOnNaN object at 0x7fc61b7870d0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.1888657 , 7.2769737 , 5.909152  , ..., 9.082649  , 0.9403403 ,
        0.7059462 ],
       [4.176088  , 5.244718  , 0.08754387, ..., 5.8996167 , 2.311068  ,
        1.2166278 ],
       [4.6650877 , 6.4019322 , 0.22886449, ..., 7.5690355 , 1.5742183 ,
        1.4550321 ],
       ...,
       [5.419054  , 7.254176  , 6.182308  , ..., 9.139094  , 0.7199806 ,
        0.66618156],
       [5.6352715 , 7.265105  , 6.0395503 , ..., 9.201334  , 0.8430511 ,
        0.6850713 ],
       [5.4601226 , 7.206975  , 6.318588  , ..., 9.265648  , 0.21410441,
        0.9461267 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_107/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 107/360 with hyperparameters:
timestamp = 2023-09-12 09:45:29.871886
ndims = 16
seed_train = 721
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 214880
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [5.4665003 7.3385735 6.463596  5.2454143 4.88222   6.494657  4.435836
 8.813813  9.097803  3.551577  8.8986635 4.7866344 5.8176413 9.343143
 0.328562  0.9563145]
Epoch 1/1000
2023-09-12 09:45:56.960 
Epoch 1/1000 
	 loss: 24.0449, MinusLogProbMetric: 24.0449, val_loss: 6.9713, val_MinusLogProbMetric: 6.9713

Epoch 1: val_loss improved from inf to 6.97130, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 27s - loss: 24.0449 - MinusLogProbMetric: 24.0449 - val_loss: 6.9713 - val_MinusLogProbMetric: 6.9713 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 2/1000
2023-09-12 09:46:08.456 
Epoch 2/1000 
	 loss: 6.0555, MinusLogProbMetric: 6.0555, val_loss: 5.8260, val_MinusLogProbMetric: 5.8260

Epoch 2: val_loss improved from 6.97130 to 5.82605, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 11s - loss: 6.0555 - MinusLogProbMetric: 6.0555 - val_loss: 5.8260 - val_MinusLogProbMetric: 5.8260 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 3/1000
2023-09-12 09:46:19.974 
Epoch 3/1000 
	 loss: 5.5741, MinusLogProbMetric: 5.5741, val_loss: 5.6640, val_MinusLogProbMetric: 5.6640

Epoch 3: val_loss improved from 5.82605 to 5.66397, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.5741 - MinusLogProbMetric: 5.5741 - val_loss: 5.6640 - val_MinusLogProbMetric: 5.6640 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 4/1000
2023-09-12 09:46:31.467 
Epoch 4/1000 
	 loss: 5.4550, MinusLogProbMetric: 5.4550, val_loss: 5.5216, val_MinusLogProbMetric: 5.5216

Epoch 4: val_loss improved from 5.66397 to 5.52158, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.4550 - MinusLogProbMetric: 5.4550 - val_loss: 5.5216 - val_MinusLogProbMetric: 5.5216 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 5/1000
2023-09-12 09:46:43.049 
Epoch 5/1000 
	 loss: 5.3691, MinusLogProbMetric: 5.3691, val_loss: 5.3825, val_MinusLogProbMetric: 5.3825

Epoch 5: val_loss improved from 5.52158 to 5.38255, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.3691 - MinusLogProbMetric: 5.3691 - val_loss: 5.3825 - val_MinusLogProbMetric: 5.3825 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 6/1000
2023-09-12 09:46:54.608 
Epoch 6/1000 
	 loss: 5.3465, MinusLogProbMetric: 5.3465, val_loss: 5.3344, val_MinusLogProbMetric: 5.3344

Epoch 6: val_loss improved from 5.38255 to 5.33437, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.3465 - MinusLogProbMetric: 5.3465 - val_loss: 5.3344 - val_MinusLogProbMetric: 5.3344 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 7/1000
2023-09-12 09:47:06.111 
Epoch 7/1000 
	 loss: 5.3016, MinusLogProbMetric: 5.3016, val_loss: 5.3781, val_MinusLogProbMetric: 5.3781

Epoch 7: val_loss did not improve from 5.33437
196/196 - 11s - loss: 5.3016 - MinusLogProbMetric: 5.3016 - val_loss: 5.3781 - val_MinusLogProbMetric: 5.3781 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 8/1000
2023-09-12 09:47:17.613 
Epoch 8/1000 
	 loss: 5.2815, MinusLogProbMetric: 5.2815, val_loss: 5.3569, val_MinusLogProbMetric: 5.3569

Epoch 8: val_loss did not improve from 5.33437
196/196 - 11s - loss: 5.2815 - MinusLogProbMetric: 5.2815 - val_loss: 5.3569 - val_MinusLogProbMetric: 5.3569 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 9/1000
2023-09-12 09:47:29.159 
Epoch 9/1000 
	 loss: 5.2620, MinusLogProbMetric: 5.2620, val_loss: 5.2487, val_MinusLogProbMetric: 5.2487

Epoch 9: val_loss improved from 5.33437 to 5.24873, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.2620 - MinusLogProbMetric: 5.2620 - val_loss: 5.2487 - val_MinusLogProbMetric: 5.2487 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 10/1000
2023-09-12 09:47:40.797 
Epoch 10/1000 
	 loss: 5.2567, MinusLogProbMetric: 5.2567, val_loss: 5.3771, val_MinusLogProbMetric: 5.3771

Epoch 10: val_loss did not improve from 5.24873
196/196 - 12s - loss: 5.2567 - MinusLogProbMetric: 5.2567 - val_loss: 5.3771 - val_MinusLogProbMetric: 5.3771 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 11/1000
2023-09-12 09:47:52.179 
Epoch 11/1000 
	 loss: 5.2424, MinusLogProbMetric: 5.2424, val_loss: 5.2459, val_MinusLogProbMetric: 5.2459

Epoch 11: val_loss improved from 5.24873 to 5.24586, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 11s - loss: 5.2424 - MinusLogProbMetric: 5.2424 - val_loss: 5.2459 - val_MinusLogProbMetric: 5.2459 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 12/1000
2023-09-12 09:48:03.744 
Epoch 12/1000 
	 loss: 5.2288, MinusLogProbMetric: 5.2288, val_loss: 5.3316, val_MinusLogProbMetric: 5.3316

Epoch 12: val_loss did not improve from 5.24586
196/196 - 11s - loss: 5.2288 - MinusLogProbMetric: 5.2288 - val_loss: 5.3316 - val_MinusLogProbMetric: 5.3316 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 13/1000
2023-09-12 09:48:15.231 
Epoch 13/1000 
	 loss: 5.2153, MinusLogProbMetric: 5.2153, val_loss: 5.2622, val_MinusLogProbMetric: 5.2622

Epoch 13: val_loss did not improve from 5.24586
196/196 - 11s - loss: 5.2153 - MinusLogProbMetric: 5.2153 - val_loss: 5.2622 - val_MinusLogProbMetric: 5.2622 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 14/1000
2023-09-12 09:48:26.672 
Epoch 14/1000 
	 loss: 5.2039, MinusLogProbMetric: 5.2039, val_loss: 5.2308, val_MinusLogProbMetric: 5.2308

Epoch 14: val_loss improved from 5.24586 to 5.23081, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.2039 - MinusLogProbMetric: 5.2039 - val_loss: 5.2308 - val_MinusLogProbMetric: 5.2308 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-12 09:48:38.292 
Epoch 15/1000 
	 loss: 5.1939, MinusLogProbMetric: 5.1939, val_loss: 5.2183, val_MinusLogProbMetric: 5.2183

Epoch 15: val_loss improved from 5.23081 to 5.21834, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.1939 - MinusLogProbMetric: 5.1939 - val_loss: 5.2183 - val_MinusLogProbMetric: 5.2183 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 16/1000
2023-09-12 09:48:49.954 
Epoch 16/1000 
	 loss: 5.1977, MinusLogProbMetric: 5.1977, val_loss: 5.2007, val_MinusLogProbMetric: 5.2007

Epoch 16: val_loss improved from 5.21834 to 5.20067, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.1977 - MinusLogProbMetric: 5.1977 - val_loss: 5.2007 - val_MinusLogProbMetric: 5.2007 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 09:49:01.785 
Epoch 17/1000 
	 loss: 5.1778, MinusLogProbMetric: 5.1778, val_loss: 5.2345, val_MinusLogProbMetric: 5.2345

Epoch 17: val_loss did not improve from 5.20067
196/196 - 12s - loss: 5.1778 - MinusLogProbMetric: 5.1778 - val_loss: 5.2345 - val_MinusLogProbMetric: 5.2345 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-12 09:49:13.458 
Epoch 18/1000 
	 loss: 5.1730, MinusLogProbMetric: 5.1730, val_loss: 5.3165, val_MinusLogProbMetric: 5.3165

Epoch 18: val_loss did not improve from 5.20067
196/196 - 12s - loss: 5.1730 - MinusLogProbMetric: 5.1730 - val_loss: 5.3165 - val_MinusLogProbMetric: 5.3165 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 09:49:24.897 
Epoch 19/1000 
	 loss: 5.1668, MinusLogProbMetric: 5.1668, val_loss: 5.2117, val_MinusLogProbMetric: 5.2117

Epoch 19: val_loss did not improve from 5.20067
196/196 - 11s - loss: 5.1668 - MinusLogProbMetric: 5.1668 - val_loss: 5.2117 - val_MinusLogProbMetric: 5.2117 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 20/1000
2023-09-12 09:49:36.363 
Epoch 20/1000 
	 loss: 5.1555, MinusLogProbMetric: 5.1555, val_loss: 5.1703, val_MinusLogProbMetric: 5.1703

Epoch 20: val_loss improved from 5.20067 to 5.17027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.1555 - MinusLogProbMetric: 5.1555 - val_loss: 5.1703 - val_MinusLogProbMetric: 5.1703 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 09:49:47.957 
Epoch 21/1000 
	 loss: 5.1690, MinusLogProbMetric: 5.1690, val_loss: 5.2081, val_MinusLogProbMetric: 5.2081

Epoch 21: val_loss did not improve from 5.17027
196/196 - 11s - loss: 5.1690 - MinusLogProbMetric: 5.1690 - val_loss: 5.2081 - val_MinusLogProbMetric: 5.2081 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 09:49:59.674 
Epoch 22/1000 
	 loss: 5.1626, MinusLogProbMetric: 5.1626, val_loss: 5.1719, val_MinusLogProbMetric: 5.1719

Epoch 22: val_loss did not improve from 5.17027
196/196 - 12s - loss: 5.1626 - MinusLogProbMetric: 5.1626 - val_loss: 5.1719 - val_MinusLogProbMetric: 5.1719 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 09:50:11.351 
Epoch 23/1000 
	 loss: 5.1614, MinusLogProbMetric: 5.1614, val_loss: 5.2315, val_MinusLogProbMetric: 5.2315

Epoch 23: val_loss did not improve from 5.17027
196/196 - 12s - loss: 5.1614 - MinusLogProbMetric: 5.1614 - val_loss: 5.2315 - val_MinusLogProbMetric: 5.2315 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-12 09:50:22.794 
Epoch 24/1000 
	 loss: 5.1463, MinusLogProbMetric: 5.1463, val_loss: 5.1665, val_MinusLogProbMetric: 5.1665

Epoch 24: val_loss improved from 5.17027 to 5.16649, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.1463 - MinusLogProbMetric: 5.1463 - val_loss: 5.1665 - val_MinusLogProbMetric: 5.1665 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 25/1000
2023-09-12 09:50:34.432 
Epoch 25/1000 
	 loss: 5.1446, MinusLogProbMetric: 5.1446, val_loss: 5.1773, val_MinusLogProbMetric: 5.1773

Epoch 25: val_loss did not improve from 5.16649
196/196 - 12s - loss: 5.1446 - MinusLogProbMetric: 5.1446 - val_loss: 5.1773 - val_MinusLogProbMetric: 5.1773 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 26/1000
2023-09-12 09:50:45.951 
Epoch 26/1000 
	 loss: 5.1363, MinusLogProbMetric: 5.1363, val_loss: 5.1603, val_MinusLogProbMetric: 5.1603

Epoch 26: val_loss improved from 5.16649 to 5.16026, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.1363 - MinusLogProbMetric: 5.1363 - val_loss: 5.1603 - val_MinusLogProbMetric: 5.1603 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 27/1000
2023-09-12 09:50:57.538 
Epoch 27/1000 
	 loss: 5.1529, MinusLogProbMetric: 5.1529, val_loss: 5.1480, val_MinusLogProbMetric: 5.1480

Epoch 27: val_loss improved from 5.16026 to 5.14802, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.1529 - MinusLogProbMetric: 5.1529 - val_loss: 5.1480 - val_MinusLogProbMetric: 5.1480 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 28/1000
2023-09-12 09:51:08.995 
Epoch 28/1000 
	 loss: 5.1376, MinusLogProbMetric: 5.1376, val_loss: 5.1504, val_MinusLogProbMetric: 5.1504

Epoch 28: val_loss did not improve from 5.14802
196/196 - 11s - loss: 5.1376 - MinusLogProbMetric: 5.1376 - val_loss: 5.1504 - val_MinusLogProbMetric: 5.1504 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 29/1000
2023-09-12 09:51:20.260 
Epoch 29/1000 
	 loss: 5.1350, MinusLogProbMetric: 5.1350, val_loss: 5.1730, val_MinusLogProbMetric: 5.1730

Epoch 29: val_loss did not improve from 5.14802
196/196 - 11s - loss: 5.1350 - MinusLogProbMetric: 5.1350 - val_loss: 5.1730 - val_MinusLogProbMetric: 5.1730 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 30/1000
2023-09-12 09:51:31.935 
Epoch 30/1000 
	 loss: 5.1354, MinusLogProbMetric: 5.1354, val_loss: 5.1499, val_MinusLogProbMetric: 5.1499

Epoch 30: val_loss did not improve from 5.14802
196/196 - 12s - loss: 5.1354 - MinusLogProbMetric: 5.1354 - val_loss: 5.1499 - val_MinusLogProbMetric: 5.1499 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-12 09:51:42.287 
Epoch 31/1000 
	 loss: 5.1376, MinusLogProbMetric: 5.1376, val_loss: 5.1480, val_MinusLogProbMetric: 5.1480

Epoch 31: val_loss improved from 5.14802 to 5.14797, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 10s - loss: 5.1376 - MinusLogProbMetric: 5.1376 - val_loss: 5.1480 - val_MinusLogProbMetric: 5.1480 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 32/1000
2023-09-12 09:51:52.112 
Epoch 32/1000 
	 loss: 5.1322, MinusLogProbMetric: 5.1322, val_loss: 5.1335, val_MinusLogProbMetric: 5.1335

Epoch 32: val_loss improved from 5.14797 to 5.13353, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 10s - loss: 5.1322 - MinusLogProbMetric: 5.1322 - val_loss: 5.1335 - val_MinusLogProbMetric: 5.1335 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 33/1000
2023-09-12 09:52:01.966 
Epoch 33/1000 
	 loss: 5.1262, MinusLogProbMetric: 5.1262, val_loss: 5.1130, val_MinusLogProbMetric: 5.1130

Epoch 33: val_loss improved from 5.13353 to 5.11296, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 10s - loss: 5.1262 - MinusLogProbMetric: 5.1262 - val_loss: 5.1130 - val_MinusLogProbMetric: 5.1130 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 34/1000
2023-09-12 09:52:11.656 
Epoch 34/1000 
	 loss: 5.1271, MinusLogProbMetric: 5.1271, val_loss: 5.1536, val_MinusLogProbMetric: 5.1536

Epoch 34: val_loss did not improve from 5.11296
196/196 - 10s - loss: 5.1271 - MinusLogProbMetric: 5.1271 - val_loss: 5.1536 - val_MinusLogProbMetric: 5.1536 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 35/1000
2023-09-12 09:52:21.949 
Epoch 35/1000 
	 loss: 5.1231, MinusLogProbMetric: 5.1231, val_loss: 5.1417, val_MinusLogProbMetric: 5.1417

Epoch 35: val_loss did not improve from 5.11296
196/196 - 10s - loss: 5.1231 - MinusLogProbMetric: 5.1231 - val_loss: 5.1417 - val_MinusLogProbMetric: 5.1417 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 36/1000
2023-09-12 09:52:31.818 
Epoch 36/1000 
	 loss: 5.1188, MinusLogProbMetric: 5.1188, val_loss: 5.1166, val_MinusLogProbMetric: 5.1166

Epoch 36: val_loss did not improve from 5.11296
196/196 - 10s - loss: 5.1188 - MinusLogProbMetric: 5.1188 - val_loss: 5.1166 - val_MinusLogProbMetric: 5.1166 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 37/1000
2023-09-12 09:52:42.143 
Epoch 37/1000 
	 loss: 5.1176, MinusLogProbMetric: 5.1176, val_loss: 5.1568, val_MinusLogProbMetric: 5.1568

Epoch 37: val_loss did not improve from 5.11296
196/196 - 10s - loss: 5.1176 - MinusLogProbMetric: 5.1176 - val_loss: 5.1568 - val_MinusLogProbMetric: 5.1568 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 38/1000
2023-09-12 09:52:53.452 
Epoch 38/1000 
	 loss: 5.1217, MinusLogProbMetric: 5.1217, val_loss: 5.1431, val_MinusLogProbMetric: 5.1431

Epoch 38: val_loss did not improve from 5.11296
196/196 - 11s - loss: 5.1217 - MinusLogProbMetric: 5.1217 - val_loss: 5.1431 - val_MinusLogProbMetric: 5.1431 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 39/1000
2023-09-12 09:53:04.525 
Epoch 39/1000 
	 loss: 5.1175, MinusLogProbMetric: 5.1175, val_loss: 5.1452, val_MinusLogProbMetric: 5.1452

Epoch 39: val_loss did not improve from 5.11296
196/196 - 11s - loss: 5.1175 - MinusLogProbMetric: 5.1175 - val_loss: 5.1452 - val_MinusLogProbMetric: 5.1452 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 40/1000
2023-09-12 09:53:15.979 
Epoch 40/1000 
	 loss: 5.1127, MinusLogProbMetric: 5.1127, val_loss: 5.1304, val_MinusLogProbMetric: 5.1304

Epoch 40: val_loss did not improve from 5.11296
196/196 - 11s - loss: 5.1127 - MinusLogProbMetric: 5.1127 - val_loss: 5.1304 - val_MinusLogProbMetric: 5.1304 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 41/1000
2023-09-12 09:53:27.556 
Epoch 41/1000 
	 loss: 5.1143, MinusLogProbMetric: 5.1143, val_loss: 5.1245, val_MinusLogProbMetric: 5.1245

Epoch 41: val_loss did not improve from 5.11296
196/196 - 12s - loss: 5.1143 - MinusLogProbMetric: 5.1143 - val_loss: 5.1245 - val_MinusLogProbMetric: 5.1245 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 42/1000
2023-09-12 09:53:39.206 
Epoch 42/1000 
	 loss: 5.1029, MinusLogProbMetric: 5.1029, val_loss: 5.0923, val_MinusLogProbMetric: 5.0923

Epoch 42: val_loss improved from 5.11296 to 5.09230, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.1029 - MinusLogProbMetric: 5.1029 - val_loss: 5.0923 - val_MinusLogProbMetric: 5.0923 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-12 09:53:50.763 
Epoch 43/1000 
	 loss: 5.1043, MinusLogProbMetric: 5.1043, val_loss: 5.1239, val_MinusLogProbMetric: 5.1239

Epoch 43: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.1043 - MinusLogProbMetric: 5.1043 - val_loss: 5.1239 - val_MinusLogProbMetric: 5.1239 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 44/1000
2023-09-12 09:54:02.535 
Epoch 44/1000 
	 loss: 5.1074, MinusLogProbMetric: 5.1074, val_loss: 5.1272, val_MinusLogProbMetric: 5.1272

Epoch 44: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.1074 - MinusLogProbMetric: 5.1074 - val_loss: 5.1272 - val_MinusLogProbMetric: 5.1272 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-12 09:54:14.079 
Epoch 45/1000 
	 loss: 5.1034, MinusLogProbMetric: 5.1034, val_loss: 5.1573, val_MinusLogProbMetric: 5.1573

Epoch 45: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.1034 - MinusLogProbMetric: 5.1034 - val_loss: 5.1573 - val_MinusLogProbMetric: 5.1573 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 46/1000
2023-09-12 09:54:25.664 
Epoch 46/1000 
	 loss: 5.1066, MinusLogProbMetric: 5.1066, val_loss: 5.1522, val_MinusLogProbMetric: 5.1522

Epoch 46: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.1066 - MinusLogProbMetric: 5.1066 - val_loss: 5.1522 - val_MinusLogProbMetric: 5.1522 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 09:54:37.392 
Epoch 47/1000 
	 loss: 5.1133, MinusLogProbMetric: 5.1133, val_loss: 5.1730, val_MinusLogProbMetric: 5.1730

Epoch 47: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.1133 - MinusLogProbMetric: 5.1133 - val_loss: 5.1730 - val_MinusLogProbMetric: 5.1730 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-12 09:54:48.870 
Epoch 48/1000 
	 loss: 5.1045, MinusLogProbMetric: 5.1045, val_loss: 5.1438, val_MinusLogProbMetric: 5.1438

Epoch 48: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.1045 - MinusLogProbMetric: 5.1045 - val_loss: 5.1438 - val_MinusLogProbMetric: 5.1438 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 49/1000
2023-09-12 09:55:00.311 
Epoch 49/1000 
	 loss: 5.1043, MinusLogProbMetric: 5.1043, val_loss: 5.1284, val_MinusLogProbMetric: 5.1284

Epoch 49: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.1043 - MinusLogProbMetric: 5.1043 - val_loss: 5.1284 - val_MinusLogProbMetric: 5.1284 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 50/1000
2023-09-12 09:55:11.669 
Epoch 50/1000 
	 loss: 5.1045, MinusLogProbMetric: 5.1045, val_loss: 5.1312, val_MinusLogProbMetric: 5.1312

Epoch 50: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.1045 - MinusLogProbMetric: 5.1045 - val_loss: 5.1312 - val_MinusLogProbMetric: 5.1312 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 51/1000
2023-09-12 09:55:23.089 
Epoch 51/1000 
	 loss: 5.1052, MinusLogProbMetric: 5.1052, val_loss: 5.1403, val_MinusLogProbMetric: 5.1403

Epoch 51: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.1052 - MinusLogProbMetric: 5.1052 - val_loss: 5.1403 - val_MinusLogProbMetric: 5.1403 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 52/1000
2023-09-12 09:55:34.517 
Epoch 52/1000 
	 loss: 5.1053, MinusLogProbMetric: 5.1053, val_loss: 5.1625, val_MinusLogProbMetric: 5.1625

Epoch 52: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.1053 - MinusLogProbMetric: 5.1053 - val_loss: 5.1625 - val_MinusLogProbMetric: 5.1625 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 53/1000
2023-09-12 09:55:45.750 
Epoch 53/1000 
	 loss: 5.1113, MinusLogProbMetric: 5.1113, val_loss: 5.1540, val_MinusLogProbMetric: 5.1540

Epoch 53: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.1113 - MinusLogProbMetric: 5.1113 - val_loss: 5.1540 - val_MinusLogProbMetric: 5.1540 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 54/1000
2023-09-12 09:55:56.813 
Epoch 54/1000 
	 loss: 5.0993, MinusLogProbMetric: 5.0993, val_loss: 5.1336, val_MinusLogProbMetric: 5.1336

Epoch 54: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.0993 - MinusLogProbMetric: 5.0993 - val_loss: 5.1336 - val_MinusLogProbMetric: 5.1336 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 55/1000
2023-09-12 09:56:08.324 
Epoch 55/1000 
	 loss: 5.1055, MinusLogProbMetric: 5.1055, val_loss: 5.1236, val_MinusLogProbMetric: 5.1236

Epoch 55: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.1055 - MinusLogProbMetric: 5.1055 - val_loss: 5.1236 - val_MinusLogProbMetric: 5.1236 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 56/1000
2023-09-12 09:56:19.863 
Epoch 56/1000 
	 loss: 5.1089, MinusLogProbMetric: 5.1089, val_loss: 5.1211, val_MinusLogProbMetric: 5.1211

Epoch 56: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.1089 - MinusLogProbMetric: 5.1089 - val_loss: 5.1211 - val_MinusLogProbMetric: 5.1211 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 57/1000
2023-09-12 09:56:31.411 
Epoch 57/1000 
	 loss: 5.0976, MinusLogProbMetric: 5.0976, val_loss: 5.1207, val_MinusLogProbMetric: 5.1207

Epoch 57: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.0976 - MinusLogProbMetric: 5.0976 - val_loss: 5.1207 - val_MinusLogProbMetric: 5.1207 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 58/1000
2023-09-12 09:56:42.932 
Epoch 58/1000 
	 loss: 5.0940, MinusLogProbMetric: 5.0940, val_loss: 5.1238, val_MinusLogProbMetric: 5.1238

Epoch 58: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.0940 - MinusLogProbMetric: 5.0940 - val_loss: 5.1238 - val_MinusLogProbMetric: 5.1238 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 59/1000
2023-09-12 09:56:54.293 
Epoch 59/1000 
	 loss: 5.0942, MinusLogProbMetric: 5.0942, val_loss: 5.1338, val_MinusLogProbMetric: 5.1338

Epoch 59: val_loss did not improve from 5.09230
196/196 - 11s - loss: 5.0942 - MinusLogProbMetric: 5.0942 - val_loss: 5.1338 - val_MinusLogProbMetric: 5.1338 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 60/1000
2023-09-12 09:57:04.123 
Epoch 60/1000 
	 loss: 5.0943, MinusLogProbMetric: 5.0943, val_loss: 5.1214, val_MinusLogProbMetric: 5.1214

Epoch 60: val_loss did not improve from 5.09230
196/196 - 10s - loss: 5.0943 - MinusLogProbMetric: 5.0943 - val_loss: 5.1214 - val_MinusLogProbMetric: 5.1214 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 61/1000
2023-09-12 09:57:13.859 
Epoch 61/1000 
	 loss: 5.0984, MinusLogProbMetric: 5.0984, val_loss: 5.1604, val_MinusLogProbMetric: 5.1604

Epoch 61: val_loss did not improve from 5.09230
196/196 - 10s - loss: 5.0984 - MinusLogProbMetric: 5.0984 - val_loss: 5.1604 - val_MinusLogProbMetric: 5.1604 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 62/1000
2023-09-12 09:57:24.138 
Epoch 62/1000 
	 loss: 5.0962, MinusLogProbMetric: 5.0962, val_loss: 5.1358, val_MinusLogProbMetric: 5.1358

Epoch 62: val_loss did not improve from 5.09230
196/196 - 10s - loss: 5.0962 - MinusLogProbMetric: 5.0962 - val_loss: 5.1358 - val_MinusLogProbMetric: 5.1358 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 63/1000
2023-09-12 09:57:34.405 
Epoch 63/1000 
	 loss: 5.0948, MinusLogProbMetric: 5.0948, val_loss: 5.1175, val_MinusLogProbMetric: 5.1175

Epoch 63: val_loss did not improve from 5.09230
196/196 - 10s - loss: 5.0948 - MinusLogProbMetric: 5.0948 - val_loss: 5.1175 - val_MinusLogProbMetric: 5.1175 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 64/1000
2023-09-12 09:57:45.916 
Epoch 64/1000 
	 loss: 5.0900, MinusLogProbMetric: 5.0900, val_loss: 5.1270, val_MinusLogProbMetric: 5.1270

Epoch 64: val_loss did not improve from 5.09230
196/196 - 12s - loss: 5.0900 - MinusLogProbMetric: 5.0900 - val_loss: 5.1270 - val_MinusLogProbMetric: 5.1270 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 65/1000
2023-09-12 09:57:57.263 
Epoch 65/1000 
	 loss: 5.0932, MinusLogProbMetric: 5.0932, val_loss: 5.0839, val_MinusLogProbMetric: 5.0839

Epoch 65: val_loss improved from 5.09230 to 5.08387, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 11s - loss: 5.0932 - MinusLogProbMetric: 5.0932 - val_loss: 5.0839 - val_MinusLogProbMetric: 5.0839 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 66/1000
2023-09-12 09:58:08.916 
Epoch 66/1000 
	 loss: 5.0930, MinusLogProbMetric: 5.0930, val_loss: 5.1183, val_MinusLogProbMetric: 5.1183

Epoch 66: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0930 - MinusLogProbMetric: 5.0930 - val_loss: 5.1183 - val_MinusLogProbMetric: 5.1183 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-12 09:58:20.423 
Epoch 67/1000 
	 loss: 5.0881, MinusLogProbMetric: 5.0881, val_loss: 5.1456, val_MinusLogProbMetric: 5.1456

Epoch 67: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0881 - MinusLogProbMetric: 5.0881 - val_loss: 5.1456 - val_MinusLogProbMetric: 5.1456 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 68/1000
2023-09-12 09:58:32.018 
Epoch 68/1000 
	 loss: 5.0956, MinusLogProbMetric: 5.0956, val_loss: 5.1127, val_MinusLogProbMetric: 5.1127

Epoch 68: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0956 - MinusLogProbMetric: 5.0956 - val_loss: 5.1127 - val_MinusLogProbMetric: 5.1127 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-12 09:58:43.630 
Epoch 69/1000 
	 loss: 5.0922, MinusLogProbMetric: 5.0922, val_loss: 5.1137, val_MinusLogProbMetric: 5.1137

Epoch 69: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0922 - MinusLogProbMetric: 5.0922 - val_loss: 5.1137 - val_MinusLogProbMetric: 5.1137 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 70/1000
2023-09-12 09:58:55.123 
Epoch 70/1000 
	 loss: 5.0836, MinusLogProbMetric: 5.0836, val_loss: 5.1294, val_MinusLogProbMetric: 5.1294

Epoch 70: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0836 - MinusLogProbMetric: 5.0836 - val_loss: 5.1294 - val_MinusLogProbMetric: 5.1294 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 71/1000
2023-09-12 09:59:06.544 
Epoch 71/1000 
	 loss: 5.0874, MinusLogProbMetric: 5.0874, val_loss: 5.1089, val_MinusLogProbMetric: 5.1089

Epoch 71: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0874 - MinusLogProbMetric: 5.0874 - val_loss: 5.1089 - val_MinusLogProbMetric: 5.1089 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 72/1000
2023-09-12 09:59:18.085 
Epoch 72/1000 
	 loss: 5.0857, MinusLogProbMetric: 5.0857, val_loss: 5.1127, val_MinusLogProbMetric: 5.1127

Epoch 72: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0857 - MinusLogProbMetric: 5.0857 - val_loss: 5.1127 - val_MinusLogProbMetric: 5.1127 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 73/1000
2023-09-12 09:59:29.645 
Epoch 73/1000 
	 loss: 5.0865, MinusLogProbMetric: 5.0865, val_loss: 5.1176, val_MinusLogProbMetric: 5.1176

Epoch 73: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0865 - MinusLogProbMetric: 5.0865 - val_loss: 5.1176 - val_MinusLogProbMetric: 5.1176 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 09:59:41.288 
Epoch 74/1000 
	 loss: 5.0865, MinusLogProbMetric: 5.0865, val_loss: 5.1116, val_MinusLogProbMetric: 5.1116

Epoch 74: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0865 - MinusLogProbMetric: 5.0865 - val_loss: 5.1116 - val_MinusLogProbMetric: 5.1116 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 75/1000
2023-09-12 09:59:52.880 
Epoch 75/1000 
	 loss: 5.0889, MinusLogProbMetric: 5.0889, val_loss: 5.1150, val_MinusLogProbMetric: 5.1150

Epoch 75: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0889 - MinusLogProbMetric: 5.0889 - val_loss: 5.1150 - val_MinusLogProbMetric: 5.1150 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 76/1000
2023-09-12 10:00:04.317 
Epoch 76/1000 
	 loss: 5.0837, MinusLogProbMetric: 5.0837, val_loss: 5.1159, val_MinusLogProbMetric: 5.1159

Epoch 76: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0837 - MinusLogProbMetric: 5.0837 - val_loss: 5.1159 - val_MinusLogProbMetric: 5.1159 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 77/1000
2023-09-12 10:00:15.780 
Epoch 77/1000 
	 loss: 5.0880, MinusLogProbMetric: 5.0880, val_loss: 5.0991, val_MinusLogProbMetric: 5.0991

Epoch 77: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0880 - MinusLogProbMetric: 5.0880 - val_loss: 5.0991 - val_MinusLogProbMetric: 5.0991 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 78/1000
2023-09-12 10:00:27.216 
Epoch 78/1000 
	 loss: 5.0856, MinusLogProbMetric: 5.0856, val_loss: 5.1014, val_MinusLogProbMetric: 5.1014

Epoch 78: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0856 - MinusLogProbMetric: 5.0856 - val_loss: 5.1014 - val_MinusLogProbMetric: 5.1014 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 79/1000
2023-09-12 10:00:38.805 
Epoch 79/1000 
	 loss: 5.0818, MinusLogProbMetric: 5.0818, val_loss: 5.1086, val_MinusLogProbMetric: 5.1086

Epoch 79: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0818 - MinusLogProbMetric: 5.0818 - val_loss: 5.1086 - val_MinusLogProbMetric: 5.1086 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 80/1000
2023-09-12 10:00:50.331 
Epoch 80/1000 
	 loss: 5.0819, MinusLogProbMetric: 5.0819, val_loss: 5.0998, val_MinusLogProbMetric: 5.0998

Epoch 80: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0819 - MinusLogProbMetric: 5.0819 - val_loss: 5.0998 - val_MinusLogProbMetric: 5.0998 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-12 10:01:01.834 
Epoch 81/1000 
	 loss: 5.0797, MinusLogProbMetric: 5.0797, val_loss: 5.1201, val_MinusLogProbMetric: 5.1201

Epoch 81: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0797 - MinusLogProbMetric: 5.0797 - val_loss: 5.1201 - val_MinusLogProbMetric: 5.1201 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 82/1000
2023-09-12 10:01:13.351 
Epoch 82/1000 
	 loss: 5.0854, MinusLogProbMetric: 5.0854, val_loss: 5.1061, val_MinusLogProbMetric: 5.1061

Epoch 82: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0854 - MinusLogProbMetric: 5.0854 - val_loss: 5.1061 - val_MinusLogProbMetric: 5.1061 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 83/1000
2023-09-12 10:01:24.778 
Epoch 83/1000 
	 loss: 5.0848, MinusLogProbMetric: 5.0848, val_loss: 5.1041, val_MinusLogProbMetric: 5.1041

Epoch 83: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0848 - MinusLogProbMetric: 5.0848 - val_loss: 5.1041 - val_MinusLogProbMetric: 5.1041 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 84/1000
2023-09-12 10:01:36.129 
Epoch 84/1000 
	 loss: 5.0749, MinusLogProbMetric: 5.0749, val_loss: 5.1167, val_MinusLogProbMetric: 5.1167

Epoch 84: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0749 - MinusLogProbMetric: 5.0749 - val_loss: 5.1167 - val_MinusLogProbMetric: 5.1167 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 85/1000
2023-09-12 10:01:47.633 
Epoch 85/1000 
	 loss: 5.0830, MinusLogProbMetric: 5.0830, val_loss: 5.1141, val_MinusLogProbMetric: 5.1141

Epoch 85: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0830 - MinusLogProbMetric: 5.0830 - val_loss: 5.1141 - val_MinusLogProbMetric: 5.1141 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-12 10:01:59.247 
Epoch 86/1000 
	 loss: 5.0888, MinusLogProbMetric: 5.0888, val_loss: 5.1085, val_MinusLogProbMetric: 5.1085

Epoch 86: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0888 - MinusLogProbMetric: 5.0888 - val_loss: 5.1085 - val_MinusLogProbMetric: 5.1085 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 87/1000
2023-09-12 10:02:10.715 
Epoch 87/1000 
	 loss: 5.0826, MinusLogProbMetric: 5.0826, val_loss: 5.0976, val_MinusLogProbMetric: 5.0976

Epoch 87: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0826 - MinusLogProbMetric: 5.0826 - val_loss: 5.0976 - val_MinusLogProbMetric: 5.0976 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 88/1000
2023-09-12 10:02:22.259 
Epoch 88/1000 
	 loss: 5.0745, MinusLogProbMetric: 5.0745, val_loss: 5.1165, val_MinusLogProbMetric: 5.1165

Epoch 88: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0745 - MinusLogProbMetric: 5.0745 - val_loss: 5.1165 - val_MinusLogProbMetric: 5.1165 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-12 10:02:33.747 
Epoch 89/1000 
	 loss: 5.0803, MinusLogProbMetric: 5.0803, val_loss: 5.1183, val_MinusLogProbMetric: 5.1183

Epoch 89: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0803 - MinusLogProbMetric: 5.0803 - val_loss: 5.1183 - val_MinusLogProbMetric: 5.1183 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 90/1000
2023-09-12 10:02:45.315 
Epoch 90/1000 
	 loss: 5.0732, MinusLogProbMetric: 5.0732, val_loss: 5.1206, val_MinusLogProbMetric: 5.1206

Epoch 90: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0732 - MinusLogProbMetric: 5.0732 - val_loss: 5.1206 - val_MinusLogProbMetric: 5.1206 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 91/1000
2023-09-12 10:02:56.752 
Epoch 91/1000 
	 loss: 5.0751, MinusLogProbMetric: 5.0751, val_loss: 5.0910, val_MinusLogProbMetric: 5.0910

Epoch 91: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0751 - MinusLogProbMetric: 5.0751 - val_loss: 5.0910 - val_MinusLogProbMetric: 5.0910 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 92/1000
2023-09-12 10:03:08.189 
Epoch 92/1000 
	 loss: 5.0756, MinusLogProbMetric: 5.0756, val_loss: 5.1286, val_MinusLogProbMetric: 5.1286

Epoch 92: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0756 - MinusLogProbMetric: 5.0756 - val_loss: 5.1286 - val_MinusLogProbMetric: 5.1286 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 93/1000
2023-09-12 10:03:19.675 
Epoch 93/1000 
	 loss: 5.0779, MinusLogProbMetric: 5.0779, val_loss: 5.1147, val_MinusLogProbMetric: 5.1147

Epoch 93: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0779 - MinusLogProbMetric: 5.0779 - val_loss: 5.1147 - val_MinusLogProbMetric: 5.1147 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 94/1000
2023-09-12 10:03:31.125 
Epoch 94/1000 
	 loss: 5.0818, MinusLogProbMetric: 5.0818, val_loss: 5.1195, val_MinusLogProbMetric: 5.1195

Epoch 94: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0818 - MinusLogProbMetric: 5.0818 - val_loss: 5.1195 - val_MinusLogProbMetric: 5.1195 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 95/1000
2023-09-12 10:03:42.593 
Epoch 95/1000 
	 loss: 5.0725, MinusLogProbMetric: 5.0725, val_loss: 5.0940, val_MinusLogProbMetric: 5.0940

Epoch 95: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0725 - MinusLogProbMetric: 5.0725 - val_loss: 5.0940 - val_MinusLogProbMetric: 5.0940 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 96/1000
2023-09-12 10:03:53.990 
Epoch 96/1000 
	 loss: 5.0698, MinusLogProbMetric: 5.0698, val_loss: 5.1024, val_MinusLogProbMetric: 5.1024

Epoch 96: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0698 - MinusLogProbMetric: 5.0698 - val_loss: 5.1024 - val_MinusLogProbMetric: 5.1024 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 97/1000
2023-09-12 10:04:05.394 
Epoch 97/1000 
	 loss: 5.0747, MinusLogProbMetric: 5.0747, val_loss: 5.1041, val_MinusLogProbMetric: 5.1041

Epoch 97: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0747 - MinusLogProbMetric: 5.0747 - val_loss: 5.1041 - val_MinusLogProbMetric: 5.1041 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 98/1000
2023-09-12 10:04:16.943 
Epoch 98/1000 
	 loss: 5.0747, MinusLogProbMetric: 5.0747, val_loss: 5.1253, val_MinusLogProbMetric: 5.1253

Epoch 98: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0747 - MinusLogProbMetric: 5.0747 - val_loss: 5.1253 - val_MinusLogProbMetric: 5.1253 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 99/1000
2023-09-12 10:04:28.503 
Epoch 99/1000 
	 loss: 5.0796, MinusLogProbMetric: 5.0796, val_loss: 5.1188, val_MinusLogProbMetric: 5.1188

Epoch 99: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0796 - MinusLogProbMetric: 5.0796 - val_loss: 5.1188 - val_MinusLogProbMetric: 5.1188 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 10:04:39.905 
Epoch 100/1000 
	 loss: 5.0778, MinusLogProbMetric: 5.0778, val_loss: 5.0973, val_MinusLogProbMetric: 5.0973

Epoch 100: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0778 - MinusLogProbMetric: 5.0778 - val_loss: 5.0973 - val_MinusLogProbMetric: 5.0973 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 101/1000
2023-09-12 10:04:51.345 
Epoch 101/1000 
	 loss: 5.0709, MinusLogProbMetric: 5.0709, val_loss: 5.0865, val_MinusLogProbMetric: 5.0865

Epoch 101: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0709 - MinusLogProbMetric: 5.0709 - val_loss: 5.0865 - val_MinusLogProbMetric: 5.0865 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 102/1000
2023-09-12 10:05:02.808 
Epoch 102/1000 
	 loss: 5.0749, MinusLogProbMetric: 5.0749, val_loss: 5.1121, val_MinusLogProbMetric: 5.1121

Epoch 102: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0749 - MinusLogProbMetric: 5.0749 - val_loss: 5.1121 - val_MinusLogProbMetric: 5.1121 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 103/1000
2023-09-12 10:05:14.316 
Epoch 103/1000 
	 loss: 5.0744, MinusLogProbMetric: 5.0744, val_loss: 5.1458, val_MinusLogProbMetric: 5.1458

Epoch 103: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0744 - MinusLogProbMetric: 5.0744 - val_loss: 5.1458 - val_MinusLogProbMetric: 5.1458 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 104/1000
2023-09-12 10:05:25.904 
Epoch 104/1000 
	 loss: 5.0736, MinusLogProbMetric: 5.0736, val_loss: 5.1012, val_MinusLogProbMetric: 5.1012

Epoch 104: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0736 - MinusLogProbMetric: 5.0736 - val_loss: 5.1012 - val_MinusLogProbMetric: 5.1012 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 105/1000
2023-09-12 10:05:37.418 
Epoch 105/1000 
	 loss: 5.0698, MinusLogProbMetric: 5.0698, val_loss: 5.1395, val_MinusLogProbMetric: 5.1395

Epoch 105: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0698 - MinusLogProbMetric: 5.0698 - val_loss: 5.1395 - val_MinusLogProbMetric: 5.1395 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 106/1000
2023-09-12 10:05:48.891 
Epoch 106/1000 
	 loss: 5.0740, MinusLogProbMetric: 5.0740, val_loss: 5.0999, val_MinusLogProbMetric: 5.0999

Epoch 106: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0740 - MinusLogProbMetric: 5.0740 - val_loss: 5.0999 - val_MinusLogProbMetric: 5.0999 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 107/1000
2023-09-12 10:06:00.144 
Epoch 107/1000 
	 loss: 5.0717, MinusLogProbMetric: 5.0717, val_loss: 5.1067, val_MinusLogProbMetric: 5.1067

Epoch 107: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0717 - MinusLogProbMetric: 5.0717 - val_loss: 5.1067 - val_MinusLogProbMetric: 5.1067 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 108/1000
2023-09-12 10:06:11.596 
Epoch 108/1000 
	 loss: 5.0745, MinusLogProbMetric: 5.0745, val_loss: 5.0959, val_MinusLogProbMetric: 5.0959

Epoch 108: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0745 - MinusLogProbMetric: 5.0745 - val_loss: 5.0959 - val_MinusLogProbMetric: 5.0959 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 109/1000
2023-09-12 10:06:23.001 
Epoch 109/1000 
	 loss: 5.0678, MinusLogProbMetric: 5.0678, val_loss: 5.1117, val_MinusLogProbMetric: 5.1117

Epoch 109: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0678 - MinusLogProbMetric: 5.0678 - val_loss: 5.1117 - val_MinusLogProbMetric: 5.1117 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 10:06:34.494 
Epoch 110/1000 
	 loss: 5.0753, MinusLogProbMetric: 5.0753, val_loss: 5.0923, val_MinusLogProbMetric: 5.0923

Epoch 110: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0753 - MinusLogProbMetric: 5.0753 - val_loss: 5.0923 - val_MinusLogProbMetric: 5.0923 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 111/1000
2023-09-12 10:06:45.894 
Epoch 111/1000 
	 loss: 5.0725, MinusLogProbMetric: 5.0725, val_loss: 5.0973, val_MinusLogProbMetric: 5.0973

Epoch 111: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0725 - MinusLogProbMetric: 5.0725 - val_loss: 5.0973 - val_MinusLogProbMetric: 5.0973 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 112/1000
2023-09-12 10:06:57.308 
Epoch 112/1000 
	 loss: 5.0719, MinusLogProbMetric: 5.0719, val_loss: 5.1098, val_MinusLogProbMetric: 5.1098

Epoch 112: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0719 - MinusLogProbMetric: 5.0719 - val_loss: 5.1098 - val_MinusLogProbMetric: 5.1098 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-12 10:07:08.685 
Epoch 113/1000 
	 loss: 5.0701, MinusLogProbMetric: 5.0701, val_loss: 5.0933, val_MinusLogProbMetric: 5.0933

Epoch 113: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0701 - MinusLogProbMetric: 5.0701 - val_loss: 5.0933 - val_MinusLogProbMetric: 5.0933 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 114/1000
2023-09-12 10:07:20.180 
Epoch 114/1000 
	 loss: 5.0665, MinusLogProbMetric: 5.0665, val_loss: 5.0932, val_MinusLogProbMetric: 5.0932

Epoch 114: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0665 - MinusLogProbMetric: 5.0665 - val_loss: 5.0932 - val_MinusLogProbMetric: 5.0932 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 115/1000
2023-09-12 10:07:31.656 
Epoch 115/1000 
	 loss: 5.0724, MinusLogProbMetric: 5.0724, val_loss: 5.1164, val_MinusLogProbMetric: 5.1164

Epoch 115: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0724 - MinusLogProbMetric: 5.0724 - val_loss: 5.1164 - val_MinusLogProbMetric: 5.1164 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 116/1000
2023-09-12 10:07:43.059 
Epoch 116/1000 
	 loss: 5.0450, MinusLogProbMetric: 5.0450, val_loss: 5.0878, val_MinusLogProbMetric: 5.0878

Epoch 116: val_loss did not improve from 5.08387
196/196 - 11s - loss: 5.0450 - MinusLogProbMetric: 5.0450 - val_loss: 5.0878 - val_MinusLogProbMetric: 5.0878 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 117/1000
2023-09-12 10:07:54.675 
Epoch 117/1000 
	 loss: 5.0439, MinusLogProbMetric: 5.0439, val_loss: 5.0916, val_MinusLogProbMetric: 5.0916

Epoch 117: val_loss did not improve from 5.08387
196/196 - 12s - loss: 5.0439 - MinusLogProbMetric: 5.0439 - val_loss: 5.0916 - val_MinusLogProbMetric: 5.0916 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 118/1000
2023-09-12 10:08:06.185 
Epoch 118/1000 
	 loss: 5.0453, MinusLogProbMetric: 5.0453, val_loss: 5.0760, val_MinusLogProbMetric: 5.0760

Epoch 118: val_loss improved from 5.08387 to 5.07601, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.0453 - MinusLogProbMetric: 5.0453 - val_loss: 5.0760 - val_MinusLogProbMetric: 5.0760 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-12 10:08:17.848 
Epoch 119/1000 
	 loss: 5.0421, MinusLogProbMetric: 5.0421, val_loss: 5.0737, val_MinusLogProbMetric: 5.0737

Epoch 119: val_loss improved from 5.07601 to 5.07370, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.0421 - MinusLogProbMetric: 5.0421 - val_loss: 5.0737 - val_MinusLogProbMetric: 5.0737 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 120/1000
2023-09-12 10:08:29.218 
Epoch 120/1000 
	 loss: 5.0423, MinusLogProbMetric: 5.0423, val_loss: 5.0796, val_MinusLogProbMetric: 5.0796

Epoch 120: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0423 - MinusLogProbMetric: 5.0423 - val_loss: 5.0796 - val_MinusLogProbMetric: 5.0796 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 121/1000
2023-09-12 10:08:40.376 
Epoch 121/1000 
	 loss: 5.0431, MinusLogProbMetric: 5.0431, val_loss: 5.0801, val_MinusLogProbMetric: 5.0801

Epoch 121: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0431 - MinusLogProbMetric: 5.0431 - val_loss: 5.0801 - val_MinusLogProbMetric: 5.0801 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 122/1000
2023-09-12 10:08:51.622 
Epoch 122/1000 
	 loss: 5.0425, MinusLogProbMetric: 5.0425, val_loss: 5.0788, val_MinusLogProbMetric: 5.0788

Epoch 122: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0425 - MinusLogProbMetric: 5.0425 - val_loss: 5.0788 - val_MinusLogProbMetric: 5.0788 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 123/1000
2023-09-12 10:09:02.815 
Epoch 123/1000 
	 loss: 5.0414, MinusLogProbMetric: 5.0414, val_loss: 5.0864, val_MinusLogProbMetric: 5.0864

Epoch 123: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0414 - MinusLogProbMetric: 5.0414 - val_loss: 5.0864 - val_MinusLogProbMetric: 5.0864 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 124/1000
2023-09-12 10:09:14.098 
Epoch 124/1000 
	 loss: 5.0439, MinusLogProbMetric: 5.0439, val_loss: 5.0757, val_MinusLogProbMetric: 5.0757

Epoch 124: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0439 - MinusLogProbMetric: 5.0439 - val_loss: 5.0757 - val_MinusLogProbMetric: 5.0757 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 125/1000
2023-09-12 10:09:25.219 
Epoch 125/1000 
	 loss: 5.0423, MinusLogProbMetric: 5.0423, val_loss: 5.0792, val_MinusLogProbMetric: 5.0792

Epoch 125: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0423 - MinusLogProbMetric: 5.0423 - val_loss: 5.0792 - val_MinusLogProbMetric: 5.0792 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 126/1000
2023-09-12 10:09:36.351 
Epoch 126/1000 
	 loss: 5.0412, MinusLogProbMetric: 5.0412, val_loss: 5.0871, val_MinusLogProbMetric: 5.0871

Epoch 126: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0412 - MinusLogProbMetric: 5.0412 - val_loss: 5.0871 - val_MinusLogProbMetric: 5.0871 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 127/1000
2023-09-12 10:09:47.294 
Epoch 127/1000 
	 loss: 5.0426, MinusLogProbMetric: 5.0426, val_loss: 5.0827, val_MinusLogProbMetric: 5.0827

Epoch 127: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0426 - MinusLogProbMetric: 5.0426 - val_loss: 5.0827 - val_MinusLogProbMetric: 5.0827 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 128/1000
2023-09-12 10:09:58.214 
Epoch 128/1000 
	 loss: 5.0431, MinusLogProbMetric: 5.0431, val_loss: 5.0787, val_MinusLogProbMetric: 5.0787

Epoch 128: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0431 - MinusLogProbMetric: 5.0431 - val_loss: 5.0787 - val_MinusLogProbMetric: 5.0787 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 129/1000
2023-09-12 10:10:09.272 
Epoch 129/1000 
	 loss: 5.0421, MinusLogProbMetric: 5.0421, val_loss: 5.0768, val_MinusLogProbMetric: 5.0768

Epoch 129: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0421 - MinusLogProbMetric: 5.0421 - val_loss: 5.0768 - val_MinusLogProbMetric: 5.0768 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 130/1000
2023-09-12 10:10:20.394 
Epoch 130/1000 
	 loss: 5.0417, MinusLogProbMetric: 5.0417, val_loss: 5.0816, val_MinusLogProbMetric: 5.0816

Epoch 130: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0417 - MinusLogProbMetric: 5.0417 - val_loss: 5.0816 - val_MinusLogProbMetric: 5.0816 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 131/1000
2023-09-12 10:10:31.415 
Epoch 131/1000 
	 loss: 5.0437, MinusLogProbMetric: 5.0437, val_loss: 5.0836, val_MinusLogProbMetric: 5.0836

Epoch 131: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0437 - MinusLogProbMetric: 5.0437 - val_loss: 5.0836 - val_MinusLogProbMetric: 5.0836 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 132/1000
2023-09-12 10:10:42.453 
Epoch 132/1000 
	 loss: 5.0457, MinusLogProbMetric: 5.0457, val_loss: 5.0917, val_MinusLogProbMetric: 5.0917

Epoch 132: val_loss did not improve from 5.07370
196/196 - 11s - loss: 5.0457 - MinusLogProbMetric: 5.0457 - val_loss: 5.0917 - val_MinusLogProbMetric: 5.0917 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 133/1000
2023-09-12 10:10:53.636 
Epoch 133/1000 
	 loss: 5.0409, MinusLogProbMetric: 5.0409, val_loss: 5.0733, val_MinusLogProbMetric: 5.0733

Epoch 133: val_loss improved from 5.07370 to 5.07326, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 11s - loss: 5.0409 - MinusLogProbMetric: 5.0409 - val_loss: 5.0733 - val_MinusLogProbMetric: 5.0733 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 134/1000
2023-09-12 10:11:04.829 
Epoch 134/1000 
	 loss: 5.0402, MinusLogProbMetric: 5.0402, val_loss: 5.0835, val_MinusLogProbMetric: 5.0835

Epoch 134: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0402 - MinusLogProbMetric: 5.0402 - val_loss: 5.0835 - val_MinusLogProbMetric: 5.0835 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 135/1000
2023-09-12 10:11:16.106 
Epoch 135/1000 
	 loss: 5.0415, MinusLogProbMetric: 5.0415, val_loss: 5.0942, val_MinusLogProbMetric: 5.0942

Epoch 135: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0415 - MinusLogProbMetric: 5.0415 - val_loss: 5.0942 - val_MinusLogProbMetric: 5.0942 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 136/1000
2023-09-12 10:11:27.234 
Epoch 136/1000 
	 loss: 5.0416, MinusLogProbMetric: 5.0416, val_loss: 5.0775, val_MinusLogProbMetric: 5.0775

Epoch 136: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0416 - MinusLogProbMetric: 5.0416 - val_loss: 5.0775 - val_MinusLogProbMetric: 5.0775 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 137/1000
2023-09-12 10:11:38.349 
Epoch 137/1000 
	 loss: 5.0406, MinusLogProbMetric: 5.0406, val_loss: 5.0786, val_MinusLogProbMetric: 5.0786

Epoch 137: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0406 - MinusLogProbMetric: 5.0406 - val_loss: 5.0786 - val_MinusLogProbMetric: 5.0786 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 138/1000
2023-09-12 10:11:49.421 
Epoch 138/1000 
	 loss: 5.0398, MinusLogProbMetric: 5.0398, val_loss: 5.0781, val_MinusLogProbMetric: 5.0781

Epoch 138: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0398 - MinusLogProbMetric: 5.0398 - val_loss: 5.0781 - val_MinusLogProbMetric: 5.0781 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 139/1000
2023-09-12 10:12:00.522 
Epoch 139/1000 
	 loss: 5.0402, MinusLogProbMetric: 5.0402, val_loss: 5.0793, val_MinusLogProbMetric: 5.0793

Epoch 139: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0402 - MinusLogProbMetric: 5.0402 - val_loss: 5.0793 - val_MinusLogProbMetric: 5.0793 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 140/1000
2023-09-12 10:12:11.663 
Epoch 140/1000 
	 loss: 5.0405, MinusLogProbMetric: 5.0405, val_loss: 5.0884, val_MinusLogProbMetric: 5.0884

Epoch 140: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0405 - MinusLogProbMetric: 5.0405 - val_loss: 5.0884 - val_MinusLogProbMetric: 5.0884 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 141/1000
2023-09-12 10:12:22.848 
Epoch 141/1000 
	 loss: 5.0390, MinusLogProbMetric: 5.0390, val_loss: 5.0923, val_MinusLogProbMetric: 5.0923

Epoch 141: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0390 - MinusLogProbMetric: 5.0390 - val_loss: 5.0923 - val_MinusLogProbMetric: 5.0923 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 142/1000
2023-09-12 10:12:34.076 
Epoch 142/1000 
	 loss: 5.0382, MinusLogProbMetric: 5.0382, val_loss: 5.0950, val_MinusLogProbMetric: 5.0950

Epoch 142: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0382 - MinusLogProbMetric: 5.0382 - val_loss: 5.0950 - val_MinusLogProbMetric: 5.0950 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 143/1000
2023-09-12 10:12:45.326 
Epoch 143/1000 
	 loss: 5.0383, MinusLogProbMetric: 5.0383, val_loss: 5.0773, val_MinusLogProbMetric: 5.0773

Epoch 143: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0383 - MinusLogProbMetric: 5.0383 - val_loss: 5.0773 - val_MinusLogProbMetric: 5.0773 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 144/1000
2023-09-12 10:12:56.553 
Epoch 144/1000 
	 loss: 5.0393, MinusLogProbMetric: 5.0393, val_loss: 5.0900, val_MinusLogProbMetric: 5.0900

Epoch 144: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0393 - MinusLogProbMetric: 5.0393 - val_loss: 5.0900 - val_MinusLogProbMetric: 5.0900 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 145/1000
2023-09-12 10:13:07.631 
Epoch 145/1000 
	 loss: 5.0406, MinusLogProbMetric: 5.0406, val_loss: 5.0786, val_MinusLogProbMetric: 5.0786

Epoch 145: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0406 - MinusLogProbMetric: 5.0406 - val_loss: 5.0786 - val_MinusLogProbMetric: 5.0786 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 146/1000
2023-09-12 10:13:18.770 
Epoch 146/1000 
	 loss: 5.0410, MinusLogProbMetric: 5.0410, val_loss: 5.0802, val_MinusLogProbMetric: 5.0802

Epoch 146: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0410 - MinusLogProbMetric: 5.0410 - val_loss: 5.0802 - val_MinusLogProbMetric: 5.0802 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 147/1000
2023-09-12 10:13:29.744 
Epoch 147/1000 
	 loss: 5.0399, MinusLogProbMetric: 5.0399, val_loss: 5.0891, val_MinusLogProbMetric: 5.0891

Epoch 147: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0399 - MinusLogProbMetric: 5.0399 - val_loss: 5.0891 - val_MinusLogProbMetric: 5.0891 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 148/1000
2023-09-12 10:13:41.074 
Epoch 148/1000 
	 loss: 5.0376, MinusLogProbMetric: 5.0376, val_loss: 5.0803, val_MinusLogProbMetric: 5.0803

Epoch 148: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0376 - MinusLogProbMetric: 5.0376 - val_loss: 5.0803 - val_MinusLogProbMetric: 5.0803 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 149/1000
2023-09-12 10:13:52.405 
Epoch 149/1000 
	 loss: 5.0372, MinusLogProbMetric: 5.0372, val_loss: 5.0828, val_MinusLogProbMetric: 5.0828

Epoch 149: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0372 - MinusLogProbMetric: 5.0372 - val_loss: 5.0828 - val_MinusLogProbMetric: 5.0828 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-12 10:14:03.898 
Epoch 150/1000 
	 loss: 5.0382, MinusLogProbMetric: 5.0382, val_loss: 5.0788, val_MinusLogProbMetric: 5.0788

Epoch 150: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0382 - MinusLogProbMetric: 5.0382 - val_loss: 5.0788 - val_MinusLogProbMetric: 5.0788 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 151/1000
2023-09-12 10:14:15.379 
Epoch 151/1000 
	 loss: 5.0390, MinusLogProbMetric: 5.0390, val_loss: 5.0799, val_MinusLogProbMetric: 5.0799

Epoch 151: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0390 - MinusLogProbMetric: 5.0390 - val_loss: 5.0799 - val_MinusLogProbMetric: 5.0799 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 152/1000
2023-09-12 10:14:26.865 
Epoch 152/1000 
	 loss: 5.0447, MinusLogProbMetric: 5.0447, val_loss: 5.0857, val_MinusLogProbMetric: 5.0857

Epoch 152: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0447 - MinusLogProbMetric: 5.0447 - val_loss: 5.0857 - val_MinusLogProbMetric: 5.0857 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 153/1000
2023-09-12 10:14:38.369 
Epoch 153/1000 
	 loss: 5.0396, MinusLogProbMetric: 5.0396, val_loss: 5.0820, val_MinusLogProbMetric: 5.0820

Epoch 153: val_loss did not improve from 5.07326
196/196 - 12s - loss: 5.0396 - MinusLogProbMetric: 5.0396 - val_loss: 5.0820 - val_MinusLogProbMetric: 5.0820 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-12 10:14:49.835 
Epoch 154/1000 
	 loss: 5.0379, MinusLogProbMetric: 5.0379, val_loss: 5.0817, val_MinusLogProbMetric: 5.0817

Epoch 154: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0379 - MinusLogProbMetric: 5.0379 - val_loss: 5.0817 - val_MinusLogProbMetric: 5.0817 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 155/1000
2023-09-12 10:15:01.227 
Epoch 155/1000 
	 loss: 5.0384, MinusLogProbMetric: 5.0384, val_loss: 5.0743, val_MinusLogProbMetric: 5.0743

Epoch 155: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0384 - MinusLogProbMetric: 5.0384 - val_loss: 5.0743 - val_MinusLogProbMetric: 5.0743 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 156/1000
2023-09-12 10:15:12.615 
Epoch 156/1000 
	 loss: 5.0388, MinusLogProbMetric: 5.0388, val_loss: 5.0877, val_MinusLogProbMetric: 5.0877

Epoch 156: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0388 - MinusLogProbMetric: 5.0388 - val_loss: 5.0877 - val_MinusLogProbMetric: 5.0877 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 157/1000
2023-09-12 10:15:24.167 
Epoch 157/1000 
	 loss: 5.0367, MinusLogProbMetric: 5.0367, val_loss: 5.0778, val_MinusLogProbMetric: 5.0778

Epoch 157: val_loss did not improve from 5.07326
196/196 - 12s - loss: 5.0367 - MinusLogProbMetric: 5.0367 - val_loss: 5.0778 - val_MinusLogProbMetric: 5.0778 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 158/1000
2023-09-12 10:15:35.558 
Epoch 158/1000 
	 loss: 5.0375, MinusLogProbMetric: 5.0375, val_loss: 5.0800, val_MinusLogProbMetric: 5.0800

Epoch 158: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0375 - MinusLogProbMetric: 5.0375 - val_loss: 5.0800 - val_MinusLogProbMetric: 5.0800 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 159/1000
2023-09-12 10:15:47.039 
Epoch 159/1000 
	 loss: 5.0384, MinusLogProbMetric: 5.0384, val_loss: 5.0910, val_MinusLogProbMetric: 5.0910

Epoch 159: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0384 - MinusLogProbMetric: 5.0384 - val_loss: 5.0910 - val_MinusLogProbMetric: 5.0910 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 160/1000
2023-09-12 10:15:58.460 
Epoch 160/1000 
	 loss: 5.0420, MinusLogProbMetric: 5.0420, val_loss: 5.1031, val_MinusLogProbMetric: 5.1031

Epoch 160: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0420 - MinusLogProbMetric: 5.0420 - val_loss: 5.1031 - val_MinusLogProbMetric: 5.1031 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 161/1000
2023-09-12 10:16:09.598 
Epoch 161/1000 
	 loss: 5.0396, MinusLogProbMetric: 5.0396, val_loss: 5.0839, val_MinusLogProbMetric: 5.0839

Epoch 161: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0396 - MinusLogProbMetric: 5.0396 - val_loss: 5.0839 - val_MinusLogProbMetric: 5.0839 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 162/1000
2023-09-12 10:16:21.105 
Epoch 162/1000 
	 loss: 5.0371, MinusLogProbMetric: 5.0371, val_loss: 5.0823, val_MinusLogProbMetric: 5.0823

Epoch 162: val_loss did not improve from 5.07326
196/196 - 12s - loss: 5.0371 - MinusLogProbMetric: 5.0371 - val_loss: 5.0823 - val_MinusLogProbMetric: 5.0823 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 163/1000
2023-09-12 10:16:32.569 
Epoch 163/1000 
	 loss: 5.0362, MinusLogProbMetric: 5.0362, val_loss: 5.0820, val_MinusLogProbMetric: 5.0820

Epoch 163: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0362 - MinusLogProbMetric: 5.0362 - val_loss: 5.0820 - val_MinusLogProbMetric: 5.0820 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 164/1000
2023-09-12 10:16:43.128 
Epoch 164/1000 
	 loss: 5.0377, MinusLogProbMetric: 5.0377, val_loss: 5.0806, val_MinusLogProbMetric: 5.0806

Epoch 164: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0377 - MinusLogProbMetric: 5.0377 - val_loss: 5.0806 - val_MinusLogProbMetric: 5.0806 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 165/1000
2023-09-12 10:16:54.176 
Epoch 165/1000 
	 loss: 5.0369, MinusLogProbMetric: 5.0369, val_loss: 5.0779, val_MinusLogProbMetric: 5.0779

Epoch 165: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0369 - MinusLogProbMetric: 5.0369 - val_loss: 5.0779 - val_MinusLogProbMetric: 5.0779 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 166/1000
2023-09-12 10:17:04.906 
Epoch 166/1000 
	 loss: 5.0353, MinusLogProbMetric: 5.0353, val_loss: 5.0793, val_MinusLogProbMetric: 5.0793

Epoch 166: val_loss did not improve from 5.07326
196/196 - 11s - loss: 5.0353 - MinusLogProbMetric: 5.0353 - val_loss: 5.0793 - val_MinusLogProbMetric: 5.0793 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 167/1000
2023-09-12 10:17:15.247 
Epoch 167/1000 
	 loss: 5.0369, MinusLogProbMetric: 5.0369, val_loss: 5.0872, val_MinusLogProbMetric: 5.0872

Epoch 167: val_loss did not improve from 5.07326
196/196 - 10s - loss: 5.0369 - MinusLogProbMetric: 5.0369 - val_loss: 5.0872 - val_MinusLogProbMetric: 5.0872 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 168/1000
2023-09-12 10:17:26.750 
Epoch 168/1000 
	 loss: 5.0370, MinusLogProbMetric: 5.0370, val_loss: 5.0731, val_MinusLogProbMetric: 5.0731

Epoch 168: val_loss improved from 5.07326 to 5.07308, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.0370 - MinusLogProbMetric: 5.0370 - val_loss: 5.0731 - val_MinusLogProbMetric: 5.0731 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 169/1000
2023-09-12 10:17:38.320 
Epoch 169/1000 
	 loss: 5.0352, MinusLogProbMetric: 5.0352, val_loss: 5.0913, val_MinusLogProbMetric: 5.0913

Epoch 169: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0352 - MinusLogProbMetric: 5.0352 - val_loss: 5.0913 - val_MinusLogProbMetric: 5.0913 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 170/1000
2023-09-12 10:17:49.801 
Epoch 170/1000 
	 loss: 5.0381, MinusLogProbMetric: 5.0381, val_loss: 5.0787, val_MinusLogProbMetric: 5.0787

Epoch 170: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0381 - MinusLogProbMetric: 5.0381 - val_loss: 5.0787 - val_MinusLogProbMetric: 5.0787 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 171/1000
2023-09-12 10:18:01.441 
Epoch 171/1000 
	 loss: 5.0354, MinusLogProbMetric: 5.0354, val_loss: 5.0925, val_MinusLogProbMetric: 5.0925

Epoch 171: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0354 - MinusLogProbMetric: 5.0354 - val_loss: 5.0925 - val_MinusLogProbMetric: 5.0925 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 172/1000
2023-09-12 10:18:13.061 
Epoch 172/1000 
	 loss: 5.0370, MinusLogProbMetric: 5.0370, val_loss: 5.0773, val_MinusLogProbMetric: 5.0773

Epoch 172: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0370 - MinusLogProbMetric: 5.0370 - val_loss: 5.0773 - val_MinusLogProbMetric: 5.0773 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 10:18:24.664 
Epoch 173/1000 
	 loss: 5.0348, MinusLogProbMetric: 5.0348, val_loss: 5.0761, val_MinusLogProbMetric: 5.0761

Epoch 173: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0348 - MinusLogProbMetric: 5.0348 - val_loss: 5.0761 - val_MinusLogProbMetric: 5.0761 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 174/1000
2023-09-12 10:18:36.217 
Epoch 174/1000 
	 loss: 5.0380, MinusLogProbMetric: 5.0380, val_loss: 5.0840, val_MinusLogProbMetric: 5.0840

Epoch 174: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0380 - MinusLogProbMetric: 5.0380 - val_loss: 5.0840 - val_MinusLogProbMetric: 5.0840 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 175/1000
2023-09-12 10:18:47.731 
Epoch 175/1000 
	 loss: 5.0366, MinusLogProbMetric: 5.0366, val_loss: 5.0889, val_MinusLogProbMetric: 5.0889

Epoch 175: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0366 - MinusLogProbMetric: 5.0366 - val_loss: 5.0889 - val_MinusLogProbMetric: 5.0889 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-12 10:18:59.292 
Epoch 176/1000 
	 loss: 5.0332, MinusLogProbMetric: 5.0332, val_loss: 5.0812, val_MinusLogProbMetric: 5.0812

Epoch 176: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0332 - MinusLogProbMetric: 5.0332 - val_loss: 5.0812 - val_MinusLogProbMetric: 5.0812 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 177/1000
2023-09-12 10:19:10.840 
Epoch 177/1000 
	 loss: 5.0375, MinusLogProbMetric: 5.0375, val_loss: 5.0814, val_MinusLogProbMetric: 5.0814

Epoch 177: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0375 - MinusLogProbMetric: 5.0375 - val_loss: 5.0814 - val_MinusLogProbMetric: 5.0814 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 178/1000
2023-09-12 10:19:22.498 
Epoch 178/1000 
	 loss: 5.0352, MinusLogProbMetric: 5.0352, val_loss: 5.0789, val_MinusLogProbMetric: 5.0789

Epoch 178: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0352 - MinusLogProbMetric: 5.0352 - val_loss: 5.0789 - val_MinusLogProbMetric: 5.0789 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 179/1000
2023-09-12 10:19:33.971 
Epoch 179/1000 
	 loss: 5.0380, MinusLogProbMetric: 5.0380, val_loss: 5.0964, val_MinusLogProbMetric: 5.0964

Epoch 179: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0380 - MinusLogProbMetric: 5.0380 - val_loss: 5.0964 - val_MinusLogProbMetric: 5.0964 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 180/1000
2023-09-12 10:19:43.678 
Epoch 180/1000 
	 loss: 5.0384, MinusLogProbMetric: 5.0384, val_loss: 5.0895, val_MinusLogProbMetric: 5.0895

Epoch 180: val_loss did not improve from 5.07308
196/196 - 10s - loss: 5.0384 - MinusLogProbMetric: 5.0384 - val_loss: 5.0895 - val_MinusLogProbMetric: 5.0895 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 181/1000
2023-09-12 10:19:53.488 
Epoch 181/1000 
	 loss: 5.0366, MinusLogProbMetric: 5.0366, val_loss: 5.0836, val_MinusLogProbMetric: 5.0836

Epoch 181: val_loss did not improve from 5.07308
196/196 - 10s - loss: 5.0366 - MinusLogProbMetric: 5.0366 - val_loss: 5.0836 - val_MinusLogProbMetric: 5.0836 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 182/1000
2023-09-12 10:20:03.689 
Epoch 182/1000 
	 loss: 5.0360, MinusLogProbMetric: 5.0360, val_loss: 5.0779, val_MinusLogProbMetric: 5.0779

Epoch 182: val_loss did not improve from 5.07308
196/196 - 10s - loss: 5.0360 - MinusLogProbMetric: 5.0360 - val_loss: 5.0779 - val_MinusLogProbMetric: 5.0779 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 183/1000
2023-09-12 10:20:14.041 
Epoch 183/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.0842, val_MinusLogProbMetric: 5.0842

Epoch 183: val_loss did not improve from 5.07308
196/196 - 10s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.0842 - val_MinusLogProbMetric: 5.0842 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 184/1000
2023-09-12 10:20:24.921 
Epoch 184/1000 
	 loss: 5.0348, MinusLogProbMetric: 5.0348, val_loss: 5.0781, val_MinusLogProbMetric: 5.0781

Epoch 184: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0348 - MinusLogProbMetric: 5.0348 - val_loss: 5.0781 - val_MinusLogProbMetric: 5.0781 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 185/1000
2023-09-12 10:20:36.487 
Epoch 185/1000 
	 loss: 5.0352, MinusLogProbMetric: 5.0352, val_loss: 5.0901, val_MinusLogProbMetric: 5.0901

Epoch 185: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0352 - MinusLogProbMetric: 5.0352 - val_loss: 5.0901 - val_MinusLogProbMetric: 5.0901 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 186/1000
2023-09-12 10:20:47.996 
Epoch 186/1000 
	 loss: 5.0360, MinusLogProbMetric: 5.0360, val_loss: 5.0926, val_MinusLogProbMetric: 5.0926

Epoch 186: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0360 - MinusLogProbMetric: 5.0360 - val_loss: 5.0926 - val_MinusLogProbMetric: 5.0926 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 187/1000
2023-09-12 10:20:59.555 
Epoch 187/1000 
	 loss: 5.0365, MinusLogProbMetric: 5.0365, val_loss: 5.0860, val_MinusLogProbMetric: 5.0860

Epoch 187: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0365 - MinusLogProbMetric: 5.0365 - val_loss: 5.0860 - val_MinusLogProbMetric: 5.0860 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 188/1000
2023-09-12 10:21:10.989 
Epoch 188/1000 
	 loss: 5.0336, MinusLogProbMetric: 5.0336, val_loss: 5.0864, val_MinusLogProbMetric: 5.0864

Epoch 188: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0336 - MinusLogProbMetric: 5.0336 - val_loss: 5.0864 - val_MinusLogProbMetric: 5.0864 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 189/1000
2023-09-12 10:21:22.440 
Epoch 189/1000 
	 loss: 5.0374, MinusLogProbMetric: 5.0374, val_loss: 5.0906, val_MinusLogProbMetric: 5.0906

Epoch 189: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0374 - MinusLogProbMetric: 5.0374 - val_loss: 5.0906 - val_MinusLogProbMetric: 5.0906 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 190/1000
2023-09-12 10:21:34.015 
Epoch 190/1000 
	 loss: 5.0354, MinusLogProbMetric: 5.0354, val_loss: 5.0907, val_MinusLogProbMetric: 5.0907

Epoch 190: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0354 - MinusLogProbMetric: 5.0354 - val_loss: 5.0907 - val_MinusLogProbMetric: 5.0907 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 191/1000
2023-09-12 10:21:45.629 
Epoch 191/1000 
	 loss: 5.0344, MinusLogProbMetric: 5.0344, val_loss: 5.0857, val_MinusLogProbMetric: 5.0857

Epoch 191: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0344 - MinusLogProbMetric: 5.0344 - val_loss: 5.0857 - val_MinusLogProbMetric: 5.0857 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 192/1000
2023-09-12 10:21:57.181 
Epoch 192/1000 
	 loss: 5.0340, MinusLogProbMetric: 5.0340, val_loss: 5.0824, val_MinusLogProbMetric: 5.0824

Epoch 192: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0340 - MinusLogProbMetric: 5.0340 - val_loss: 5.0824 - val_MinusLogProbMetric: 5.0824 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 193/1000
2023-09-12 10:22:08.670 
Epoch 193/1000 
	 loss: 5.0343, MinusLogProbMetric: 5.0343, val_loss: 5.0808, val_MinusLogProbMetric: 5.0808

Epoch 193: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0343 - MinusLogProbMetric: 5.0343 - val_loss: 5.0808 - val_MinusLogProbMetric: 5.0808 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 194/1000
2023-09-12 10:22:20.217 
Epoch 194/1000 
	 loss: 5.0357, MinusLogProbMetric: 5.0357, val_loss: 5.0871, val_MinusLogProbMetric: 5.0871

Epoch 194: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0357 - MinusLogProbMetric: 5.0357 - val_loss: 5.0871 - val_MinusLogProbMetric: 5.0871 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 195/1000
2023-09-12 10:22:31.621 
Epoch 195/1000 
	 loss: 5.0361, MinusLogProbMetric: 5.0361, val_loss: 5.0762, val_MinusLogProbMetric: 5.0762

Epoch 195: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0361 - MinusLogProbMetric: 5.0361 - val_loss: 5.0762 - val_MinusLogProbMetric: 5.0762 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 196/1000
2023-09-12 10:22:43.076 
Epoch 196/1000 
	 loss: 5.0323, MinusLogProbMetric: 5.0323, val_loss: 5.0923, val_MinusLogProbMetric: 5.0923

Epoch 196: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0323 - MinusLogProbMetric: 5.0323 - val_loss: 5.0923 - val_MinusLogProbMetric: 5.0923 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 197/1000
2023-09-12 10:22:54.644 
Epoch 197/1000 
	 loss: 5.0325, MinusLogProbMetric: 5.0325, val_loss: 5.0868, val_MinusLogProbMetric: 5.0868

Epoch 197: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0325 - MinusLogProbMetric: 5.0325 - val_loss: 5.0868 - val_MinusLogProbMetric: 5.0868 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 198/1000
2023-09-12 10:23:06.342 
Epoch 198/1000 
	 loss: 5.0334, MinusLogProbMetric: 5.0334, val_loss: 5.0762, val_MinusLogProbMetric: 5.0762

Epoch 198: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0334 - MinusLogProbMetric: 5.0334 - val_loss: 5.0762 - val_MinusLogProbMetric: 5.0762 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 199/1000
2023-09-12 10:23:17.951 
Epoch 199/1000 
	 loss: 5.0316, MinusLogProbMetric: 5.0316, val_loss: 5.0827, val_MinusLogProbMetric: 5.0827

Epoch 199: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0316 - MinusLogProbMetric: 5.0316 - val_loss: 5.0827 - val_MinusLogProbMetric: 5.0827 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 200/1000
2023-09-12 10:23:29.653 
Epoch 200/1000 
	 loss: 5.0314, MinusLogProbMetric: 5.0314, val_loss: 5.0908, val_MinusLogProbMetric: 5.0908

Epoch 200: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0314 - MinusLogProbMetric: 5.0314 - val_loss: 5.0908 - val_MinusLogProbMetric: 5.0908 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 201/1000
2023-09-12 10:23:41.092 
Epoch 201/1000 
	 loss: 5.0360, MinusLogProbMetric: 5.0360, val_loss: 5.0781, val_MinusLogProbMetric: 5.0781

Epoch 201: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0360 - MinusLogProbMetric: 5.0360 - val_loss: 5.0781 - val_MinusLogProbMetric: 5.0781 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 202/1000
2023-09-12 10:23:52.687 
Epoch 202/1000 
	 loss: 5.0345, MinusLogProbMetric: 5.0345, val_loss: 5.0922, val_MinusLogProbMetric: 5.0922

Epoch 202: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0345 - MinusLogProbMetric: 5.0345 - val_loss: 5.0922 - val_MinusLogProbMetric: 5.0922 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 203/1000
2023-09-12 10:24:04.336 
Epoch 203/1000 
	 loss: 5.0313, MinusLogProbMetric: 5.0313, val_loss: 5.0833, val_MinusLogProbMetric: 5.0833

Epoch 203: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0313 - MinusLogProbMetric: 5.0313 - val_loss: 5.0833 - val_MinusLogProbMetric: 5.0833 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 204/1000
2023-09-12 10:24:16.079 
Epoch 204/1000 
	 loss: 5.0327, MinusLogProbMetric: 5.0327, val_loss: 5.0865, val_MinusLogProbMetric: 5.0865

Epoch 204: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0327 - MinusLogProbMetric: 5.0327 - val_loss: 5.0865 - val_MinusLogProbMetric: 5.0865 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 205/1000
2023-09-12 10:24:27.820 
Epoch 205/1000 
	 loss: 5.0339, MinusLogProbMetric: 5.0339, val_loss: 5.0865, val_MinusLogProbMetric: 5.0865

Epoch 205: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0339 - MinusLogProbMetric: 5.0339 - val_loss: 5.0865 - val_MinusLogProbMetric: 5.0865 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 206/1000
2023-09-12 10:24:39.252 
Epoch 206/1000 
	 loss: 5.0356, MinusLogProbMetric: 5.0356, val_loss: 5.0958, val_MinusLogProbMetric: 5.0958

Epoch 206: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0356 - MinusLogProbMetric: 5.0356 - val_loss: 5.0958 - val_MinusLogProbMetric: 5.0958 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 207/1000
2023-09-12 10:24:50.851 
Epoch 207/1000 
	 loss: 5.0350, MinusLogProbMetric: 5.0350, val_loss: 5.0841, val_MinusLogProbMetric: 5.0841

Epoch 207: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0350 - MinusLogProbMetric: 5.0350 - val_loss: 5.0841 - val_MinusLogProbMetric: 5.0841 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 208/1000
2023-09-12 10:25:02.366 
Epoch 208/1000 
	 loss: 5.0357, MinusLogProbMetric: 5.0357, val_loss: 5.0967, val_MinusLogProbMetric: 5.0967

Epoch 208: val_loss did not improve from 5.07308
196/196 - 12s - loss: 5.0357 - MinusLogProbMetric: 5.0357 - val_loss: 5.0967 - val_MinusLogProbMetric: 5.0967 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 209/1000
2023-09-12 10:25:13.764 
Epoch 209/1000 
	 loss: 5.0336, MinusLogProbMetric: 5.0336, val_loss: 5.0828, val_MinusLogProbMetric: 5.0828

Epoch 209: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0336 - MinusLogProbMetric: 5.0336 - val_loss: 5.0828 - val_MinusLogProbMetric: 5.0828 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 210/1000
2023-09-12 10:25:24.926 
Epoch 210/1000 
	 loss: 5.0353, MinusLogProbMetric: 5.0353, val_loss: 5.1027, val_MinusLogProbMetric: 5.1027

Epoch 210: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0353 - MinusLogProbMetric: 5.0353 - val_loss: 5.1027 - val_MinusLogProbMetric: 5.1027 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 211/1000
2023-09-12 10:25:36.261 
Epoch 211/1000 
	 loss: 5.0340, MinusLogProbMetric: 5.0340, val_loss: 5.0807, val_MinusLogProbMetric: 5.0807

Epoch 211: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0340 - MinusLogProbMetric: 5.0340 - val_loss: 5.0807 - val_MinusLogProbMetric: 5.0807 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 212/1000
2023-09-12 10:25:47.567 
Epoch 212/1000 
	 loss: 5.0313, MinusLogProbMetric: 5.0313, val_loss: 5.0799, val_MinusLogProbMetric: 5.0799

Epoch 212: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0313 - MinusLogProbMetric: 5.0313 - val_loss: 5.0799 - val_MinusLogProbMetric: 5.0799 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 213/1000
2023-09-12 10:25:58.669 
Epoch 213/1000 
	 loss: 5.0322, MinusLogProbMetric: 5.0322, val_loss: 5.0791, val_MinusLogProbMetric: 5.0791

Epoch 213: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0322 - MinusLogProbMetric: 5.0322 - val_loss: 5.0791 - val_MinusLogProbMetric: 5.0791 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 214/1000
2023-09-12 10:26:09.940 
Epoch 214/1000 
	 loss: 5.0315, MinusLogProbMetric: 5.0315, val_loss: 5.0879, val_MinusLogProbMetric: 5.0879

Epoch 214: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0315 - MinusLogProbMetric: 5.0315 - val_loss: 5.0879 - val_MinusLogProbMetric: 5.0879 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 215/1000
2023-09-12 10:26:21.183 
Epoch 215/1000 
	 loss: 5.0305, MinusLogProbMetric: 5.0305, val_loss: 5.0819, val_MinusLogProbMetric: 5.0819

Epoch 215: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0305 - MinusLogProbMetric: 5.0305 - val_loss: 5.0819 - val_MinusLogProbMetric: 5.0819 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 216/1000
2023-09-12 10:26:32.326 
Epoch 216/1000 
	 loss: 5.0307, MinusLogProbMetric: 5.0307, val_loss: 5.0759, val_MinusLogProbMetric: 5.0759

Epoch 216: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0307 - MinusLogProbMetric: 5.0307 - val_loss: 5.0759 - val_MinusLogProbMetric: 5.0759 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 217/1000
2023-09-12 10:26:42.838 
Epoch 217/1000 
	 loss: 5.0313, MinusLogProbMetric: 5.0313, val_loss: 5.0872, val_MinusLogProbMetric: 5.0872

Epoch 217: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0313 - MinusLogProbMetric: 5.0313 - val_loss: 5.0872 - val_MinusLogProbMetric: 5.0872 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 218/1000
2023-09-12 10:26:52.560 
Epoch 218/1000 
	 loss: 5.0288, MinusLogProbMetric: 5.0288, val_loss: 5.0821, val_MinusLogProbMetric: 5.0821

Epoch 218: val_loss did not improve from 5.07308
196/196 - 10s - loss: 5.0288 - MinusLogProbMetric: 5.0288 - val_loss: 5.0821 - val_MinusLogProbMetric: 5.0821 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 219/1000
2023-09-12 10:27:02.204 
Epoch 219/1000 
	 loss: 5.0198, MinusLogProbMetric: 5.0198, val_loss: 5.0805, val_MinusLogProbMetric: 5.0805

Epoch 219: val_loss did not improve from 5.07308
196/196 - 10s - loss: 5.0198 - MinusLogProbMetric: 5.0198 - val_loss: 5.0805 - val_MinusLogProbMetric: 5.0805 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 220/1000
2023-09-12 10:27:13.228 
Epoch 220/1000 
	 loss: 5.0195, MinusLogProbMetric: 5.0195, val_loss: 5.0865, val_MinusLogProbMetric: 5.0865

Epoch 220: val_loss did not improve from 5.07308
196/196 - 11s - loss: 5.0195 - MinusLogProbMetric: 5.0195 - val_loss: 5.0865 - val_MinusLogProbMetric: 5.0865 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 221/1000
2023-09-12 10:27:23.535 
Epoch 221/1000 
	 loss: 5.0190, MinusLogProbMetric: 5.0190, val_loss: 5.0727, val_MinusLogProbMetric: 5.0727

Epoch 221: val_loss improved from 5.07308 to 5.07271, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 10s - loss: 5.0190 - MinusLogProbMetric: 5.0190 - val_loss: 5.0727 - val_MinusLogProbMetric: 5.0727 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 222/1000
2023-09-12 10:27:34.999 
Epoch 222/1000 
	 loss: 5.0197, MinusLogProbMetric: 5.0197, val_loss: 5.0765, val_MinusLogProbMetric: 5.0765

Epoch 222: val_loss did not improve from 5.07271
196/196 - 11s - loss: 5.0197 - MinusLogProbMetric: 5.0197 - val_loss: 5.0765 - val_MinusLogProbMetric: 5.0765 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 223/1000
2023-09-12 10:27:46.509 
Epoch 223/1000 
	 loss: 5.0196, MinusLogProbMetric: 5.0196, val_loss: 5.0747, val_MinusLogProbMetric: 5.0747

Epoch 223: val_loss did not improve from 5.07271
196/196 - 12s - loss: 5.0196 - MinusLogProbMetric: 5.0196 - val_loss: 5.0747 - val_MinusLogProbMetric: 5.0747 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 224/1000
2023-09-12 10:27:58.045 
Epoch 224/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.0813, val_MinusLogProbMetric: 5.0813

Epoch 224: val_loss did not improve from 5.07271
196/196 - 12s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.0813 - val_MinusLogProbMetric: 5.0813 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 225/1000
2023-09-12 10:28:09.529 
Epoch 225/1000 
	 loss: 5.0186, MinusLogProbMetric: 5.0186, val_loss: 5.0824, val_MinusLogProbMetric: 5.0824

Epoch 225: val_loss did not improve from 5.07271
196/196 - 11s - loss: 5.0186 - MinusLogProbMetric: 5.0186 - val_loss: 5.0824 - val_MinusLogProbMetric: 5.0824 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 226/1000
2023-09-12 10:28:20.878 
Epoch 226/1000 
	 loss: 5.0184, MinusLogProbMetric: 5.0184, val_loss: 5.0718, val_MinusLogProbMetric: 5.0718

Epoch 226: val_loss improved from 5.07271 to 5.07185, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 11s - loss: 5.0184 - MinusLogProbMetric: 5.0184 - val_loss: 5.0718 - val_MinusLogProbMetric: 5.0718 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 227/1000
2023-09-12 10:28:32.469 
Epoch 227/1000 
	 loss: 5.0187, MinusLogProbMetric: 5.0187, val_loss: 5.0756, val_MinusLogProbMetric: 5.0756

Epoch 227: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0187 - MinusLogProbMetric: 5.0187 - val_loss: 5.0756 - val_MinusLogProbMetric: 5.0756 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 228/1000
2023-09-12 10:28:43.974 
Epoch 228/1000 
	 loss: 5.0193, MinusLogProbMetric: 5.0193, val_loss: 5.0739, val_MinusLogProbMetric: 5.0739

Epoch 228: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0193 - MinusLogProbMetric: 5.0193 - val_loss: 5.0739 - val_MinusLogProbMetric: 5.0739 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 229/1000
2023-09-12 10:28:55.440 
Epoch 229/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.0800, val_MinusLogProbMetric: 5.0800

Epoch 229: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.0800 - val_MinusLogProbMetric: 5.0800 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 230/1000
2023-09-12 10:29:06.764 
Epoch 230/1000 
	 loss: 5.0194, MinusLogProbMetric: 5.0194, val_loss: 5.0769, val_MinusLogProbMetric: 5.0769

Epoch 230: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0194 - MinusLogProbMetric: 5.0194 - val_loss: 5.0769 - val_MinusLogProbMetric: 5.0769 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 231/1000
2023-09-12 10:29:17.986 
Epoch 231/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.0769, val_MinusLogProbMetric: 5.0769

Epoch 231: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.0769 - val_MinusLogProbMetric: 5.0769 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 232/1000
2023-09-12 10:29:29.078 
Epoch 232/1000 
	 loss: 5.0186, MinusLogProbMetric: 5.0186, val_loss: 5.0811, val_MinusLogProbMetric: 5.0811

Epoch 232: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0186 - MinusLogProbMetric: 5.0186 - val_loss: 5.0811 - val_MinusLogProbMetric: 5.0811 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 233/1000
2023-09-12 10:29:40.226 
Epoch 233/1000 
	 loss: 5.0189, MinusLogProbMetric: 5.0189, val_loss: 5.0798, val_MinusLogProbMetric: 5.0798

Epoch 233: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0189 - MinusLogProbMetric: 5.0189 - val_loss: 5.0798 - val_MinusLogProbMetric: 5.0798 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 234/1000
2023-09-12 10:29:51.471 
Epoch 234/1000 
	 loss: 5.0193, MinusLogProbMetric: 5.0193, val_loss: 5.0803, val_MinusLogProbMetric: 5.0803

Epoch 234: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0193 - MinusLogProbMetric: 5.0193 - val_loss: 5.0803 - val_MinusLogProbMetric: 5.0803 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 235/1000
2023-09-12 10:30:02.558 
Epoch 235/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.0824, val_MinusLogProbMetric: 5.0824

Epoch 235: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.0824 - val_MinusLogProbMetric: 5.0824 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 236/1000
2023-09-12 10:30:13.595 
Epoch 236/1000 
	 loss: 5.0192, MinusLogProbMetric: 5.0192, val_loss: 5.0780, val_MinusLogProbMetric: 5.0780

Epoch 236: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0192 - MinusLogProbMetric: 5.0192 - val_loss: 5.0780 - val_MinusLogProbMetric: 5.0780 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 237/1000
2023-09-12 10:30:24.663 
Epoch 237/1000 
	 loss: 5.0188, MinusLogProbMetric: 5.0188, val_loss: 5.0734, val_MinusLogProbMetric: 5.0734

Epoch 237: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0188 - MinusLogProbMetric: 5.0188 - val_loss: 5.0734 - val_MinusLogProbMetric: 5.0734 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 238/1000
2023-09-12 10:30:35.883 
Epoch 238/1000 
	 loss: 5.0187, MinusLogProbMetric: 5.0187, val_loss: 5.0752, val_MinusLogProbMetric: 5.0752

Epoch 238: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0187 - MinusLogProbMetric: 5.0187 - val_loss: 5.0752 - val_MinusLogProbMetric: 5.0752 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 239/1000
2023-09-12 10:30:46.984 
Epoch 239/1000 
	 loss: 5.0185, MinusLogProbMetric: 5.0185, val_loss: 5.0740, val_MinusLogProbMetric: 5.0740

Epoch 239: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0185 - MinusLogProbMetric: 5.0185 - val_loss: 5.0740 - val_MinusLogProbMetric: 5.0740 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 240/1000
2023-09-12 10:30:58.189 
Epoch 240/1000 
	 loss: 5.0189, MinusLogProbMetric: 5.0189, val_loss: 5.0770, val_MinusLogProbMetric: 5.0770

Epoch 240: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0189 - MinusLogProbMetric: 5.0189 - val_loss: 5.0770 - val_MinusLogProbMetric: 5.0770 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 241/1000
2023-09-12 10:31:09.531 
Epoch 241/1000 
	 loss: 5.0187, MinusLogProbMetric: 5.0187, val_loss: 5.0768, val_MinusLogProbMetric: 5.0768

Epoch 241: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0187 - MinusLogProbMetric: 5.0187 - val_loss: 5.0768 - val_MinusLogProbMetric: 5.0768 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 242/1000
2023-09-12 10:31:20.767 
Epoch 242/1000 
	 loss: 5.0183, MinusLogProbMetric: 5.0183, val_loss: 5.0736, val_MinusLogProbMetric: 5.0736

Epoch 242: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0183 - MinusLogProbMetric: 5.0183 - val_loss: 5.0736 - val_MinusLogProbMetric: 5.0736 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 243/1000
2023-09-12 10:31:31.970 
Epoch 243/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.0782, val_MinusLogProbMetric: 5.0782

Epoch 243: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.0782 - val_MinusLogProbMetric: 5.0782 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 244/1000
2023-09-12 10:31:43.336 
Epoch 244/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.0803, val_MinusLogProbMetric: 5.0803

Epoch 244: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.0803 - val_MinusLogProbMetric: 5.0803 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 245/1000
2023-09-12 10:31:54.483 
Epoch 245/1000 
	 loss: 5.0175, MinusLogProbMetric: 5.0175, val_loss: 5.0763, val_MinusLogProbMetric: 5.0763

Epoch 245: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0175 - MinusLogProbMetric: 5.0175 - val_loss: 5.0763 - val_MinusLogProbMetric: 5.0763 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 246/1000
2023-09-12 10:32:04.205 
Epoch 246/1000 
	 loss: 5.0175, MinusLogProbMetric: 5.0175, val_loss: 5.0776, val_MinusLogProbMetric: 5.0776

Epoch 246: val_loss did not improve from 5.07185
196/196 - 10s - loss: 5.0175 - MinusLogProbMetric: 5.0175 - val_loss: 5.0776 - val_MinusLogProbMetric: 5.0776 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 247/1000
2023-09-12 10:32:14.143 
Epoch 247/1000 
	 loss: 5.0191, MinusLogProbMetric: 5.0191, val_loss: 5.0750, val_MinusLogProbMetric: 5.0750

Epoch 247: val_loss did not improve from 5.07185
196/196 - 10s - loss: 5.0191 - MinusLogProbMetric: 5.0191 - val_loss: 5.0750 - val_MinusLogProbMetric: 5.0750 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 248/1000
2023-09-12 10:32:25.447 
Epoch 248/1000 
	 loss: 5.0177, MinusLogProbMetric: 5.0177, val_loss: 5.0754, val_MinusLogProbMetric: 5.0754

Epoch 248: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0177 - MinusLogProbMetric: 5.0177 - val_loss: 5.0754 - val_MinusLogProbMetric: 5.0754 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 249/1000
2023-09-12 10:32:35.299 
Epoch 249/1000 
	 loss: 5.0202, MinusLogProbMetric: 5.0202, val_loss: 5.0750, val_MinusLogProbMetric: 5.0750

Epoch 249: val_loss did not improve from 5.07185
196/196 - 10s - loss: 5.0202 - MinusLogProbMetric: 5.0202 - val_loss: 5.0750 - val_MinusLogProbMetric: 5.0750 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 250/1000
2023-09-12 10:32:46.176 
Epoch 250/1000 
	 loss: 5.0187, MinusLogProbMetric: 5.0187, val_loss: 5.0743, val_MinusLogProbMetric: 5.0743

Epoch 250: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0187 - MinusLogProbMetric: 5.0187 - val_loss: 5.0743 - val_MinusLogProbMetric: 5.0743 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 251/1000
2023-09-12 10:32:57.692 
Epoch 251/1000 
	 loss: 5.0170, MinusLogProbMetric: 5.0170, val_loss: 5.0796, val_MinusLogProbMetric: 5.0796

Epoch 251: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0170 - MinusLogProbMetric: 5.0170 - val_loss: 5.0796 - val_MinusLogProbMetric: 5.0796 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 252/1000
2023-09-12 10:33:09.184 
Epoch 252/1000 
	 loss: 5.0186, MinusLogProbMetric: 5.0186, val_loss: 5.0750, val_MinusLogProbMetric: 5.0750

Epoch 252: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0186 - MinusLogProbMetric: 5.0186 - val_loss: 5.0750 - val_MinusLogProbMetric: 5.0750 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 253/1000
2023-09-12 10:33:20.750 
Epoch 253/1000 
	 loss: 5.0175, MinusLogProbMetric: 5.0175, val_loss: 5.0835, val_MinusLogProbMetric: 5.0835

Epoch 253: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0175 - MinusLogProbMetric: 5.0175 - val_loss: 5.0835 - val_MinusLogProbMetric: 5.0835 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 254/1000
2023-09-12 10:33:32.049 
Epoch 254/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.0851, val_MinusLogProbMetric: 5.0851

Epoch 254: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.0851 - val_MinusLogProbMetric: 5.0851 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 255/1000
2023-09-12 10:33:43.613 
Epoch 255/1000 
	 loss: 5.0201, MinusLogProbMetric: 5.0201, val_loss: 5.0827, val_MinusLogProbMetric: 5.0827

Epoch 255: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0201 - MinusLogProbMetric: 5.0201 - val_loss: 5.0827 - val_MinusLogProbMetric: 5.0827 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 256/1000
2023-09-12 10:33:55.018 
Epoch 256/1000 
	 loss: 5.0182, MinusLogProbMetric: 5.0182, val_loss: 5.0761, val_MinusLogProbMetric: 5.0761

Epoch 256: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0182 - MinusLogProbMetric: 5.0182 - val_loss: 5.0761 - val_MinusLogProbMetric: 5.0761 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 257/1000
2023-09-12 10:34:06.434 
Epoch 257/1000 
	 loss: 5.0176, MinusLogProbMetric: 5.0176, val_loss: 5.0799, val_MinusLogProbMetric: 5.0799

Epoch 257: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0176 - MinusLogProbMetric: 5.0176 - val_loss: 5.0799 - val_MinusLogProbMetric: 5.0799 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 258/1000
2023-09-12 10:34:17.962 
Epoch 258/1000 
	 loss: 5.0170, MinusLogProbMetric: 5.0170, val_loss: 5.0740, val_MinusLogProbMetric: 5.0740

Epoch 258: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0170 - MinusLogProbMetric: 5.0170 - val_loss: 5.0740 - val_MinusLogProbMetric: 5.0740 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 259/1000
2023-09-12 10:34:29.604 
Epoch 259/1000 
	 loss: 5.0178, MinusLogProbMetric: 5.0178, val_loss: 5.0726, val_MinusLogProbMetric: 5.0726

Epoch 259: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0178 - MinusLogProbMetric: 5.0178 - val_loss: 5.0726 - val_MinusLogProbMetric: 5.0726 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 260/1000
2023-09-12 10:34:41.177 
Epoch 260/1000 
	 loss: 5.0171, MinusLogProbMetric: 5.0171, val_loss: 5.0771, val_MinusLogProbMetric: 5.0771

Epoch 260: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0171 - MinusLogProbMetric: 5.0171 - val_loss: 5.0771 - val_MinusLogProbMetric: 5.0771 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 261/1000
2023-09-12 10:34:52.730 
Epoch 261/1000 
	 loss: 5.0173, MinusLogProbMetric: 5.0173, val_loss: 5.0782, val_MinusLogProbMetric: 5.0782

Epoch 261: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0173 - MinusLogProbMetric: 5.0173 - val_loss: 5.0782 - val_MinusLogProbMetric: 5.0782 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 262/1000
2023-09-12 10:35:04.180 
Epoch 262/1000 
	 loss: 5.0190, MinusLogProbMetric: 5.0190, val_loss: 5.0773, val_MinusLogProbMetric: 5.0773

Epoch 262: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0190 - MinusLogProbMetric: 5.0190 - val_loss: 5.0773 - val_MinusLogProbMetric: 5.0773 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 263/1000
2023-09-12 10:35:15.748 
Epoch 263/1000 
	 loss: 5.0166, MinusLogProbMetric: 5.0166, val_loss: 5.0779, val_MinusLogProbMetric: 5.0779

Epoch 263: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0166 - MinusLogProbMetric: 5.0166 - val_loss: 5.0779 - val_MinusLogProbMetric: 5.0779 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 264/1000
2023-09-12 10:35:27.321 
Epoch 264/1000 
	 loss: 5.0169, MinusLogProbMetric: 5.0169, val_loss: 5.0813, val_MinusLogProbMetric: 5.0813

Epoch 264: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0169 - MinusLogProbMetric: 5.0169 - val_loss: 5.0813 - val_MinusLogProbMetric: 5.0813 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 265/1000
2023-09-12 10:35:38.912 
Epoch 265/1000 
	 loss: 5.0173, MinusLogProbMetric: 5.0173, val_loss: 5.0773, val_MinusLogProbMetric: 5.0773

Epoch 265: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0173 - MinusLogProbMetric: 5.0173 - val_loss: 5.0773 - val_MinusLogProbMetric: 5.0773 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 266/1000
2023-09-12 10:35:50.478 
Epoch 266/1000 
	 loss: 5.0192, MinusLogProbMetric: 5.0192, val_loss: 5.0777, val_MinusLogProbMetric: 5.0777

Epoch 266: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0192 - MinusLogProbMetric: 5.0192 - val_loss: 5.0777 - val_MinusLogProbMetric: 5.0777 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 267/1000
2023-09-12 10:36:01.950 
Epoch 267/1000 
	 loss: 5.0170, MinusLogProbMetric: 5.0170, val_loss: 5.0806, val_MinusLogProbMetric: 5.0806

Epoch 267: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0170 - MinusLogProbMetric: 5.0170 - val_loss: 5.0806 - val_MinusLogProbMetric: 5.0806 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 268/1000
2023-09-12 10:36:13.462 
Epoch 268/1000 
	 loss: 5.0164, MinusLogProbMetric: 5.0164, val_loss: 5.0748, val_MinusLogProbMetric: 5.0748

Epoch 268: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0164 - MinusLogProbMetric: 5.0164 - val_loss: 5.0748 - val_MinusLogProbMetric: 5.0748 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 269/1000
2023-09-12 10:36:24.949 
Epoch 269/1000 
	 loss: 5.0166, MinusLogProbMetric: 5.0166, val_loss: 5.0763, val_MinusLogProbMetric: 5.0763

Epoch 269: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0166 - MinusLogProbMetric: 5.0166 - val_loss: 5.0763 - val_MinusLogProbMetric: 5.0763 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 270/1000
2023-09-12 10:36:36.414 
Epoch 270/1000 
	 loss: 5.0166, MinusLogProbMetric: 5.0166, val_loss: 5.0821, val_MinusLogProbMetric: 5.0821

Epoch 270: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0166 - MinusLogProbMetric: 5.0166 - val_loss: 5.0821 - val_MinusLogProbMetric: 5.0821 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 271/1000
2023-09-12 10:36:47.870 
Epoch 271/1000 
	 loss: 5.0171, MinusLogProbMetric: 5.0171, val_loss: 5.0777, val_MinusLogProbMetric: 5.0777

Epoch 271: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0171 - MinusLogProbMetric: 5.0171 - val_loss: 5.0777 - val_MinusLogProbMetric: 5.0777 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 272/1000
2023-09-12 10:36:59.328 
Epoch 272/1000 
	 loss: 5.0166, MinusLogProbMetric: 5.0166, val_loss: 5.0796, val_MinusLogProbMetric: 5.0796

Epoch 272: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0166 - MinusLogProbMetric: 5.0166 - val_loss: 5.0796 - val_MinusLogProbMetric: 5.0796 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 273/1000
2023-09-12 10:37:10.763 
Epoch 273/1000 
	 loss: 5.0173, MinusLogProbMetric: 5.0173, val_loss: 5.0764, val_MinusLogProbMetric: 5.0764

Epoch 273: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0173 - MinusLogProbMetric: 5.0173 - val_loss: 5.0764 - val_MinusLogProbMetric: 5.0764 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 274/1000
2023-09-12 10:37:22.272 
Epoch 274/1000 
	 loss: 5.0185, MinusLogProbMetric: 5.0185, val_loss: 5.0775, val_MinusLogProbMetric: 5.0775

Epoch 274: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0185 - MinusLogProbMetric: 5.0185 - val_loss: 5.0775 - val_MinusLogProbMetric: 5.0775 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 275/1000
2023-09-12 10:37:33.751 
Epoch 275/1000 
	 loss: 5.0159, MinusLogProbMetric: 5.0159, val_loss: 5.0765, val_MinusLogProbMetric: 5.0765

Epoch 275: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0159 - MinusLogProbMetric: 5.0159 - val_loss: 5.0765 - val_MinusLogProbMetric: 5.0765 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 276/1000
2023-09-12 10:37:45.218 
Epoch 276/1000 
	 loss: 5.0166, MinusLogProbMetric: 5.0166, val_loss: 5.0842, val_MinusLogProbMetric: 5.0842

Epoch 276: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0166 - MinusLogProbMetric: 5.0166 - val_loss: 5.0842 - val_MinusLogProbMetric: 5.0842 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 277/1000
2023-09-12 10:37:56.668 
Epoch 277/1000 
	 loss: 5.0109, MinusLogProbMetric: 5.0109, val_loss: 5.0737, val_MinusLogProbMetric: 5.0737

Epoch 277: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0109 - MinusLogProbMetric: 5.0109 - val_loss: 5.0737 - val_MinusLogProbMetric: 5.0737 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 278/1000
2023-09-12 10:38:08.213 
Epoch 278/1000 
	 loss: 5.0106, MinusLogProbMetric: 5.0106, val_loss: 5.0726, val_MinusLogProbMetric: 5.0726

Epoch 278: val_loss did not improve from 5.07185
196/196 - 12s - loss: 5.0106 - MinusLogProbMetric: 5.0106 - val_loss: 5.0726 - val_MinusLogProbMetric: 5.0726 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 279/1000
2023-09-12 10:38:18.979 
Epoch 279/1000 
	 loss: 5.0099, MinusLogProbMetric: 5.0099, val_loss: 5.0729, val_MinusLogProbMetric: 5.0729

Epoch 279: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0099 - MinusLogProbMetric: 5.0099 - val_loss: 5.0729 - val_MinusLogProbMetric: 5.0729 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 280/1000
2023-09-12 10:38:30.146 
Epoch 280/1000 
	 loss: 5.0099, MinusLogProbMetric: 5.0099, val_loss: 5.0729, val_MinusLogProbMetric: 5.0729

Epoch 280: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0099 - MinusLogProbMetric: 5.0099 - val_loss: 5.0729 - val_MinusLogProbMetric: 5.0729 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 281/1000
2023-09-12 10:38:41.572 
Epoch 281/1000 
	 loss: 5.0097, MinusLogProbMetric: 5.0097, val_loss: 5.0738, val_MinusLogProbMetric: 5.0738

Epoch 281: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0097 - MinusLogProbMetric: 5.0097 - val_loss: 5.0738 - val_MinusLogProbMetric: 5.0738 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 282/1000
2023-09-12 10:38:52.289 
Epoch 282/1000 
	 loss: 5.0100, MinusLogProbMetric: 5.0100, val_loss: 5.0756, val_MinusLogProbMetric: 5.0756

Epoch 282: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0100 - MinusLogProbMetric: 5.0100 - val_loss: 5.0756 - val_MinusLogProbMetric: 5.0756 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 283/1000
2023-09-12 10:39:02.598 
Epoch 283/1000 
	 loss: 5.0094, MinusLogProbMetric: 5.0094, val_loss: 5.0778, val_MinusLogProbMetric: 5.0778

Epoch 283: val_loss did not improve from 5.07185
196/196 - 10s - loss: 5.0094 - MinusLogProbMetric: 5.0094 - val_loss: 5.0778 - val_MinusLogProbMetric: 5.0778 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 284/1000
2023-09-12 10:39:14.091 
Epoch 284/1000 
	 loss: 5.0095, MinusLogProbMetric: 5.0095, val_loss: 5.0762, val_MinusLogProbMetric: 5.0762

Epoch 284: val_loss did not improve from 5.07185
196/196 - 11s - loss: 5.0095 - MinusLogProbMetric: 5.0095 - val_loss: 5.0762 - val_MinusLogProbMetric: 5.0762 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 285/1000
2023-09-12 10:39:25.587 
Epoch 285/1000 
	 loss: 5.0098, MinusLogProbMetric: 5.0098, val_loss: 5.0717, val_MinusLogProbMetric: 5.0717

Epoch 285: val_loss improved from 5.07185 to 5.07175, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_107/weights/best_weights.h5
196/196 - 12s - loss: 5.0098 - MinusLogProbMetric: 5.0098 - val_loss: 5.0717 - val_MinusLogProbMetric: 5.0717 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 286/1000
2023-09-12 10:39:37.146 
Epoch 286/1000 
	 loss: 5.0102, MinusLogProbMetric: 5.0102, val_loss: 5.0742, val_MinusLogProbMetric: 5.0742

Epoch 286: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0102 - MinusLogProbMetric: 5.0102 - val_loss: 5.0742 - val_MinusLogProbMetric: 5.0742 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 287/1000
2023-09-12 10:39:48.648 
Epoch 287/1000 
	 loss: 5.0101, MinusLogProbMetric: 5.0101, val_loss: 5.0755, val_MinusLogProbMetric: 5.0755

Epoch 287: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0101 - MinusLogProbMetric: 5.0101 - val_loss: 5.0755 - val_MinusLogProbMetric: 5.0755 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 288/1000
2023-09-12 10:40:00.144 
Epoch 288/1000 
	 loss: 5.0094, MinusLogProbMetric: 5.0094, val_loss: 5.0767, val_MinusLogProbMetric: 5.0767

Epoch 288: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0094 - MinusLogProbMetric: 5.0094 - val_loss: 5.0767 - val_MinusLogProbMetric: 5.0767 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 289/1000
2023-09-12 10:40:11.614 
Epoch 289/1000 
	 loss: 5.0098, MinusLogProbMetric: 5.0098, val_loss: 5.0764, val_MinusLogProbMetric: 5.0764

Epoch 289: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0098 - MinusLogProbMetric: 5.0098 - val_loss: 5.0764 - val_MinusLogProbMetric: 5.0764 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 290/1000
2023-09-12 10:40:23.100 
Epoch 290/1000 
	 loss: 5.0109, MinusLogProbMetric: 5.0109, val_loss: 5.0758, val_MinusLogProbMetric: 5.0758

Epoch 290: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0109 - MinusLogProbMetric: 5.0109 - val_loss: 5.0758 - val_MinusLogProbMetric: 5.0758 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 291/1000
2023-09-12 10:40:34.691 
Epoch 291/1000 
	 loss: 5.0105, MinusLogProbMetric: 5.0105, val_loss: 5.0740, val_MinusLogProbMetric: 5.0740

Epoch 291: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0105 - MinusLogProbMetric: 5.0105 - val_loss: 5.0740 - val_MinusLogProbMetric: 5.0740 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 292/1000
2023-09-12 10:40:46.249 
Epoch 292/1000 
	 loss: 5.0099, MinusLogProbMetric: 5.0099, val_loss: 5.0742, val_MinusLogProbMetric: 5.0742

Epoch 292: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0099 - MinusLogProbMetric: 5.0099 - val_loss: 5.0742 - val_MinusLogProbMetric: 5.0742 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 293/1000
2023-09-12 10:40:57.784 
Epoch 293/1000 
	 loss: 5.0098, MinusLogProbMetric: 5.0098, val_loss: 5.0734, val_MinusLogProbMetric: 5.0734

Epoch 293: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0098 - MinusLogProbMetric: 5.0098 - val_loss: 5.0734 - val_MinusLogProbMetric: 5.0734 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 294/1000
2023-09-12 10:41:09.223 
Epoch 294/1000 
	 loss: 5.0093, MinusLogProbMetric: 5.0093, val_loss: 5.0741, val_MinusLogProbMetric: 5.0741

Epoch 294: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0093 - MinusLogProbMetric: 5.0093 - val_loss: 5.0741 - val_MinusLogProbMetric: 5.0741 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 295/1000
2023-09-12 10:41:20.800 
Epoch 295/1000 
	 loss: 5.0092, MinusLogProbMetric: 5.0092, val_loss: 5.0744, val_MinusLogProbMetric: 5.0744

Epoch 295: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0092 - MinusLogProbMetric: 5.0092 - val_loss: 5.0744 - val_MinusLogProbMetric: 5.0744 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 296/1000
2023-09-12 10:41:32.189 
Epoch 296/1000 
	 loss: 5.0101, MinusLogProbMetric: 5.0101, val_loss: 5.0772, val_MinusLogProbMetric: 5.0772

Epoch 296: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0101 - MinusLogProbMetric: 5.0101 - val_loss: 5.0772 - val_MinusLogProbMetric: 5.0772 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 297/1000
2023-09-12 10:41:43.689 
Epoch 297/1000 
	 loss: 5.0099, MinusLogProbMetric: 5.0099, val_loss: 5.0772, val_MinusLogProbMetric: 5.0772

Epoch 297: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0099 - MinusLogProbMetric: 5.0099 - val_loss: 5.0772 - val_MinusLogProbMetric: 5.0772 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 298/1000
2023-09-12 10:41:55.173 
Epoch 298/1000 
	 loss: 5.0095, MinusLogProbMetric: 5.0095, val_loss: 5.0743, val_MinusLogProbMetric: 5.0743

Epoch 298: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0095 - MinusLogProbMetric: 5.0095 - val_loss: 5.0743 - val_MinusLogProbMetric: 5.0743 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 299/1000
2023-09-12 10:42:06.627 
Epoch 299/1000 
	 loss: 5.0098, MinusLogProbMetric: 5.0098, val_loss: 5.0769, val_MinusLogProbMetric: 5.0769

Epoch 299: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0098 - MinusLogProbMetric: 5.0098 - val_loss: 5.0769 - val_MinusLogProbMetric: 5.0769 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 300/1000
2023-09-12 10:42:18.133 
Epoch 300/1000 
	 loss: 5.0101, MinusLogProbMetric: 5.0101, val_loss: 5.0756, val_MinusLogProbMetric: 5.0756

Epoch 300: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0101 - MinusLogProbMetric: 5.0101 - val_loss: 5.0756 - val_MinusLogProbMetric: 5.0756 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 301/1000
2023-09-12 10:42:29.610 
Epoch 301/1000 
	 loss: 5.0094, MinusLogProbMetric: 5.0094, val_loss: 5.0740, val_MinusLogProbMetric: 5.0740

Epoch 301: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0094 - MinusLogProbMetric: 5.0094 - val_loss: 5.0740 - val_MinusLogProbMetric: 5.0740 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 302/1000
2023-09-12 10:42:41.068 
Epoch 302/1000 
	 loss: 5.0091, MinusLogProbMetric: 5.0091, val_loss: 5.0764, val_MinusLogProbMetric: 5.0764

Epoch 302: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0091 - MinusLogProbMetric: 5.0091 - val_loss: 5.0764 - val_MinusLogProbMetric: 5.0764 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 303/1000
2023-09-12 10:42:52.582 
Epoch 303/1000 
	 loss: 5.0095, MinusLogProbMetric: 5.0095, val_loss: 5.0744, val_MinusLogProbMetric: 5.0744

Epoch 303: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0095 - MinusLogProbMetric: 5.0095 - val_loss: 5.0744 - val_MinusLogProbMetric: 5.0744 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 304/1000
2023-09-12 10:43:04.098 
Epoch 304/1000 
	 loss: 5.0088, MinusLogProbMetric: 5.0088, val_loss: 5.0744, val_MinusLogProbMetric: 5.0744

Epoch 304: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0088 - MinusLogProbMetric: 5.0088 - val_loss: 5.0744 - val_MinusLogProbMetric: 5.0744 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 305/1000
2023-09-12 10:43:15.692 
Epoch 305/1000 
	 loss: 5.0092, MinusLogProbMetric: 5.0092, val_loss: 5.0765, val_MinusLogProbMetric: 5.0765

Epoch 305: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0092 - MinusLogProbMetric: 5.0092 - val_loss: 5.0765 - val_MinusLogProbMetric: 5.0765 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 306/1000
2023-09-12 10:43:27.125 
Epoch 306/1000 
	 loss: 5.0097, MinusLogProbMetric: 5.0097, val_loss: 5.0762, val_MinusLogProbMetric: 5.0762

Epoch 306: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0097 - MinusLogProbMetric: 5.0097 - val_loss: 5.0762 - val_MinusLogProbMetric: 5.0762 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 307/1000
2023-09-12 10:43:38.684 
Epoch 307/1000 
	 loss: 5.0094, MinusLogProbMetric: 5.0094, val_loss: 5.0757, val_MinusLogProbMetric: 5.0757

Epoch 307: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0094 - MinusLogProbMetric: 5.0094 - val_loss: 5.0757 - val_MinusLogProbMetric: 5.0757 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 308/1000
2023-09-12 10:43:50.102 
Epoch 308/1000 
	 loss: 5.0095, MinusLogProbMetric: 5.0095, val_loss: 5.0750, val_MinusLogProbMetric: 5.0750

Epoch 308: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0095 - MinusLogProbMetric: 5.0095 - val_loss: 5.0750 - val_MinusLogProbMetric: 5.0750 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 309/1000
2023-09-12 10:44:01.684 
Epoch 309/1000 
	 loss: 5.0092, MinusLogProbMetric: 5.0092, val_loss: 5.0787, val_MinusLogProbMetric: 5.0787

Epoch 309: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0092 - MinusLogProbMetric: 5.0092 - val_loss: 5.0787 - val_MinusLogProbMetric: 5.0787 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 310/1000
2023-09-12 10:44:13.151 
Epoch 310/1000 
	 loss: 5.0094, MinusLogProbMetric: 5.0094, val_loss: 5.0751, val_MinusLogProbMetric: 5.0751

Epoch 310: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0094 - MinusLogProbMetric: 5.0094 - val_loss: 5.0751 - val_MinusLogProbMetric: 5.0751 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 311/1000
2023-09-12 10:44:24.716 
Epoch 311/1000 
	 loss: 5.0093, MinusLogProbMetric: 5.0093, val_loss: 5.0759, val_MinusLogProbMetric: 5.0759

Epoch 311: val_loss did not improve from 5.07175
196/196 - 12s - loss: 5.0093 - MinusLogProbMetric: 5.0093 - val_loss: 5.0759 - val_MinusLogProbMetric: 5.0759 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 312/1000
2023-09-12 10:44:36.153 
Epoch 312/1000 
	 loss: 5.0088, MinusLogProbMetric: 5.0088, val_loss: 5.0735, val_MinusLogProbMetric: 5.0735

Epoch 312: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0088 - MinusLogProbMetric: 5.0088 - val_loss: 5.0735 - val_MinusLogProbMetric: 5.0735 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 313/1000
2023-09-12 10:44:47.539 
Epoch 313/1000 
	 loss: 5.0093, MinusLogProbMetric: 5.0093, val_loss: 5.0768, val_MinusLogProbMetric: 5.0768

Epoch 313: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0093 - MinusLogProbMetric: 5.0093 - val_loss: 5.0768 - val_MinusLogProbMetric: 5.0768 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 314/1000
2023-09-12 10:44:58.998 
Epoch 314/1000 
	 loss: 5.0087, MinusLogProbMetric: 5.0087, val_loss: 5.0755, val_MinusLogProbMetric: 5.0755

Epoch 314: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0087 - MinusLogProbMetric: 5.0087 - val_loss: 5.0755 - val_MinusLogProbMetric: 5.0755 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 315/1000
2023-09-12 10:45:10.502 
Epoch 315/1000 
	 loss: 5.0088, MinusLogProbMetric: 5.0088, val_loss: 5.0754, val_MinusLogProbMetric: 5.0754

Epoch 315: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0088 - MinusLogProbMetric: 5.0088 - val_loss: 5.0754 - val_MinusLogProbMetric: 5.0754 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 316/1000
2023-09-12 10:45:21.999 
Epoch 316/1000 
	 loss: 5.0087, MinusLogProbMetric: 5.0087, val_loss: 5.0754, val_MinusLogProbMetric: 5.0754

Epoch 316: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0087 - MinusLogProbMetric: 5.0087 - val_loss: 5.0754 - val_MinusLogProbMetric: 5.0754 - lr: 1.2500e-04 - 11s/epoch - 59ms/step
Epoch 317/1000
2023-09-12 10:45:33.349 
Epoch 317/1000 
	 loss: 5.0114, MinusLogProbMetric: 5.0114, val_loss: 5.0733, val_MinusLogProbMetric: 5.0733

Epoch 317: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0114 - MinusLogProbMetric: 5.0114 - val_loss: 5.0733 - val_MinusLogProbMetric: 5.0733 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 318/1000
2023-09-12 10:45:44.734 
Epoch 318/1000 
	 loss: 5.0088, MinusLogProbMetric: 5.0088, val_loss: 5.0748, val_MinusLogProbMetric: 5.0748

Epoch 318: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0088 - MinusLogProbMetric: 5.0088 - val_loss: 5.0748 - val_MinusLogProbMetric: 5.0748 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 319/1000
2023-09-12 10:45:56.172 
Epoch 319/1000 
	 loss: 5.0093, MinusLogProbMetric: 5.0093, val_loss: 5.0762, val_MinusLogProbMetric: 5.0762

Epoch 319: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0093 - MinusLogProbMetric: 5.0093 - val_loss: 5.0762 - val_MinusLogProbMetric: 5.0762 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 320/1000
2023-09-12 10:46:07.576 
Epoch 320/1000 
	 loss: 5.0088, MinusLogProbMetric: 5.0088, val_loss: 5.0761, val_MinusLogProbMetric: 5.0761

Epoch 320: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0088 - MinusLogProbMetric: 5.0088 - val_loss: 5.0761 - val_MinusLogProbMetric: 5.0761 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 321/1000
2023-09-12 10:46:18.927 
Epoch 321/1000 
	 loss: 5.0088, MinusLogProbMetric: 5.0088, val_loss: 5.0777, val_MinusLogProbMetric: 5.0777

Epoch 321: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0088 - MinusLogProbMetric: 5.0088 - val_loss: 5.0777 - val_MinusLogProbMetric: 5.0777 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 322/1000
2023-09-12 10:46:30.081 
Epoch 322/1000 
	 loss: 5.0095, MinusLogProbMetric: 5.0095, val_loss: 5.0755, val_MinusLogProbMetric: 5.0755

Epoch 322: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0095 - MinusLogProbMetric: 5.0095 - val_loss: 5.0755 - val_MinusLogProbMetric: 5.0755 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 323/1000
2023-09-12 10:46:41.342 
Epoch 323/1000 
	 loss: 5.0084, MinusLogProbMetric: 5.0084, val_loss: 5.0755, val_MinusLogProbMetric: 5.0755

Epoch 323: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0084 - MinusLogProbMetric: 5.0084 - val_loss: 5.0755 - val_MinusLogProbMetric: 5.0755 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 324/1000
2023-09-12 10:46:52.520 
Epoch 324/1000 
	 loss: 5.0091, MinusLogProbMetric: 5.0091, val_loss: 5.0733, val_MinusLogProbMetric: 5.0733

Epoch 324: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0091 - MinusLogProbMetric: 5.0091 - val_loss: 5.0733 - val_MinusLogProbMetric: 5.0733 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 325/1000
2023-09-12 10:47:03.804 
Epoch 325/1000 
	 loss: 5.0091, MinusLogProbMetric: 5.0091, val_loss: 5.0758, val_MinusLogProbMetric: 5.0758

Epoch 325: val_loss did not improve from 5.07175
196/196 - 11s - loss: 5.0091 - MinusLogProbMetric: 5.0091 - val_loss: 5.0758 - val_MinusLogProbMetric: 5.0758 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 326/1000
2023-09-12 10:47:15.000 
Epoch 326/1000 
	 loss: 5.0092, MinusLogProbMetric: 5.0092, val_loss: 5.0755, val_MinusLogProbMetric: 5.0755

Epoch 326: val_loss did not improve from 5.07175
Restoring model weights from the end of the best epoch: 226.
196/196 - 11s - loss: 5.0092 - MinusLogProbMetric: 5.0092 - val_loss: 5.0755 - val_MinusLogProbMetric: 5.0755 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 326: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 5.363116113003343 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.364763972000219 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.0407668739790097 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.0430417699972168 seconds.
Training succeeded with seed 721.
Model trained in 3705.20 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Metrics computed in 166.60 s.
Plots done in 33.13 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 199.73 s.
===========
Run 107/360 done in 3905.81 s.
===========

Directory ../../results/MsplineN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

===========
Generating train data for run 116.
===========
Train data generated in 0.11 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 16)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_116/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_116/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.3666077 , 6.1695876 , 0.27122405, ..., 5.577797  , 2.1701648 ,
        1.2868358 ],
       [5.0281353 , 5.7328377 , 0.3051757 , ..., 7.0866113 , 1.7836838 ,
        1.4592106 ],
       [4.2135534 , 5.5750036 , 0.2128448 , ..., 5.702535  , 1.9414682 ,
        1.4426389 ],
       ...,
       [4.785428  , 5.7426505 , 0.23152825, ..., 5.4925036 , 2.6306229 ,
        1.3358337 ],
       [4.0240746 , 5.852261  , 0.27691367, ..., 5.7175026 , 2.0052557 ,
        1.3195817 ],
       [4.512517  , 6.331559  , 0.16687389, ..., 7.565742  , 2.5641623 ,
        1.4620413 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[16], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_116/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_116
self.data_kwargs: {'seed': 926}
self.x_data: [[4.3352976  5.207491   0.26835275 ... 6.13532    1.9596003  1.0861415 ]
 [5.689245   6.716931   5.5779715  ... 9.05787    0.6619543  0.7687346 ]
 [5.303978   6.4669     6.316775   ... 9.227701   0.8503313  0.8159978 ]
 ...
 [5.3024693  7.011682   6.1129336  ... 9.28271    0.9590223  0.6377857 ]
 [5.5499325  7.0990925  6.2601123  ... 9.419509   1.4502236  0.9426094 ]
 [5.896061   7.6677456  6.213584   ... 9.470459   1.177044   0.7804839 ]]
self.y_data: []
self.ndims: 16
Model defined.
Model: "model_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_46 (InputLayer)       [(None, 16)]              0         
                                                                 
 log_prob_layer_15 (LogProbL  (None,)                  559712    
 ayer)                                                           
                                                                 
=================================================================
Total params: 559,712
Trainable params: 559,712
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_15/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_15'")
self.model: <keras.engine.functional.Functional object at 0x7fc62196ce80>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc62198d360>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc62198d360>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc640af2260>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc640af2320>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc61ac5df90>, <keras.callbacks.ModelCheckpoint object at 0x7fc61ac5e050>, <keras.callbacks.EarlyStopping object at 0x7fc61ac5e2c0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc61ac5e2f0>, <keras.callbacks.TerminateOnNaN object at 0x7fc61ac5df30>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[4.3666077 , 6.1695876 , 0.27122405, ..., 5.577797  , 2.1701648 ,
        1.2868358 ],
       [5.0281353 , 5.7328377 , 0.3051757 , ..., 7.0866113 , 1.7836838 ,
        1.4592106 ],
       [4.2135534 , 5.5750036 , 0.2128448 , ..., 5.702535  , 1.9414682 ,
        1.4426389 ],
       ...,
       [4.785428  , 5.7426505 , 0.23152825, ..., 5.4925036 , 2.6306229 ,
        1.3358337 ],
       [4.0240746 , 5.852261  , 0.27691367, ..., 5.7175026 , 2.0052557 ,
        1.3195817 ],
       [4.512517  , 6.331559  , 0.16687389, ..., 7.565742  , 2.5641623 ,
        1.4620413 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_116/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 116/360 with hyperparameters:
timestamp = 2023-09-12 10:50:35.658210
ndims = 16
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 559712
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [4.3352976  5.207491   0.26835275 6.3799963  7.002734   5.8573203
 9.293297   6.9121284  3.8079677  5.572638   6.5406003  0.34338894
 6.946575   6.13532    1.9596003  1.0861415 ]
Epoch 1/1000
2023-09-12 10:51:07.076 
Epoch 1/1000 
	 loss: 17.4063, MinusLogProbMetric: 17.4063, val_loss: 6.2839, val_MinusLogProbMetric: 6.2839

Epoch 1: val_loss improved from inf to 6.28388, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 32s - loss: 17.4063 - MinusLogProbMetric: 17.4063 - val_loss: 6.2839 - val_MinusLogProbMetric: 6.2839 - lr: 0.0010 - 32s/epoch - 161ms/step
Epoch 2/1000
2023-09-12 10:51:18.978 
Epoch 2/1000 
	 loss: 5.8885, MinusLogProbMetric: 5.8885, val_loss: 5.6689, val_MinusLogProbMetric: 5.6689

Epoch 2: val_loss improved from 6.28388 to 5.66889, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.8885 - MinusLogProbMetric: 5.8885 - val_loss: 5.6689 - val_MinusLogProbMetric: 5.6689 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 3/1000
2023-09-12 10:51:30.728 
Epoch 3/1000 
	 loss: 5.5604, MinusLogProbMetric: 5.5604, val_loss: 5.7409, val_MinusLogProbMetric: 5.7409

Epoch 3: val_loss did not improve from 5.66889
196/196 - 12s - loss: 5.5604 - MinusLogProbMetric: 5.5604 - val_loss: 5.7409 - val_MinusLogProbMetric: 5.7409 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 4/1000
2023-09-12 10:51:42.614 
Epoch 4/1000 
	 loss: 5.4712, MinusLogProbMetric: 5.4712, val_loss: 5.3288, val_MinusLogProbMetric: 5.3288

Epoch 4: val_loss improved from 5.66889 to 5.32880, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.4712 - MinusLogProbMetric: 5.4712 - val_loss: 5.3288 - val_MinusLogProbMetric: 5.3288 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 5/1000
2023-09-12 10:51:54.377 
Epoch 5/1000 
	 loss: 5.3561, MinusLogProbMetric: 5.3561, val_loss: 5.3520, val_MinusLogProbMetric: 5.3520

Epoch 5: val_loss did not improve from 5.32880
196/196 - 12s - loss: 5.3561 - MinusLogProbMetric: 5.3561 - val_loss: 5.3520 - val_MinusLogProbMetric: 5.3520 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 6/1000
2023-09-12 10:52:05.879 
Epoch 6/1000 
	 loss: 5.3528, MinusLogProbMetric: 5.3528, val_loss: 5.3872, val_MinusLogProbMetric: 5.3872

Epoch 6: val_loss did not improve from 5.32880
196/196 - 11s - loss: 5.3528 - MinusLogProbMetric: 5.3528 - val_loss: 5.3872 - val_MinusLogProbMetric: 5.3872 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 7/1000
2023-09-12 10:52:17.631 
Epoch 7/1000 
	 loss: 5.2999, MinusLogProbMetric: 5.2999, val_loss: 5.2526, val_MinusLogProbMetric: 5.2526

Epoch 7: val_loss improved from 5.32880 to 5.25257, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.2999 - MinusLogProbMetric: 5.2999 - val_loss: 5.2526 - val_MinusLogProbMetric: 5.2526 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 8/1000
2023-09-12 10:52:29.472 
Epoch 8/1000 
	 loss: 5.2865, MinusLogProbMetric: 5.2865, val_loss: 5.2975, val_MinusLogProbMetric: 5.2975

Epoch 8: val_loss did not improve from 5.25257
196/196 - 12s - loss: 5.2865 - MinusLogProbMetric: 5.2865 - val_loss: 5.2975 - val_MinusLogProbMetric: 5.2975 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-12 10:52:41.178 
Epoch 9/1000 
	 loss: 5.2694, MinusLogProbMetric: 5.2694, val_loss: 5.2415, val_MinusLogProbMetric: 5.2415

Epoch 9: val_loss improved from 5.25257 to 5.24152, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.2694 - MinusLogProbMetric: 5.2694 - val_loss: 5.2415 - val_MinusLogProbMetric: 5.2415 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 10/1000
2023-09-12 10:52:53.090 
Epoch 10/1000 
	 loss: 5.2354, MinusLogProbMetric: 5.2354, val_loss: 5.1692, val_MinusLogProbMetric: 5.1692

Epoch 10: val_loss improved from 5.24152 to 5.16918, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.2354 - MinusLogProbMetric: 5.2354 - val_loss: 5.1692 - val_MinusLogProbMetric: 5.1692 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 11/1000
2023-09-12 10:53:05.019 
Epoch 11/1000 
	 loss: 5.2241, MinusLogProbMetric: 5.2241, val_loss: 5.2471, val_MinusLogProbMetric: 5.2471

Epoch 11: val_loss did not improve from 5.16918
196/196 - 12s - loss: 5.2241 - MinusLogProbMetric: 5.2241 - val_loss: 5.2471 - val_MinusLogProbMetric: 5.2471 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-12 10:53:16.942 
Epoch 12/1000 
	 loss: 5.2249, MinusLogProbMetric: 5.2249, val_loss: 5.1568, val_MinusLogProbMetric: 5.1568

Epoch 12: val_loss improved from 5.16918 to 5.15684, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.2249 - MinusLogProbMetric: 5.2249 - val_loss: 5.1568 - val_MinusLogProbMetric: 5.1568 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 13/1000
2023-09-12 10:53:28.937 
Epoch 13/1000 
	 loss: 5.2097, MinusLogProbMetric: 5.2097, val_loss: 5.3278, val_MinusLogProbMetric: 5.3278

Epoch 13: val_loss did not improve from 5.15684
196/196 - 12s - loss: 5.2097 - MinusLogProbMetric: 5.2097 - val_loss: 5.3278 - val_MinusLogProbMetric: 5.3278 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 10:53:40.897 
Epoch 14/1000 
	 loss: 5.1815, MinusLogProbMetric: 5.1815, val_loss: 5.1978, val_MinusLogProbMetric: 5.1978

Epoch 14: val_loss did not improve from 5.15684
196/196 - 12s - loss: 5.1815 - MinusLogProbMetric: 5.1815 - val_loss: 5.1978 - val_MinusLogProbMetric: 5.1978 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 15/1000
2023-09-12 10:53:52.749 
Epoch 15/1000 
	 loss: 5.1928, MinusLogProbMetric: 5.1928, val_loss: 5.2733, val_MinusLogProbMetric: 5.2733

Epoch 15: val_loss did not improve from 5.15684
196/196 - 12s - loss: 5.1928 - MinusLogProbMetric: 5.1928 - val_loss: 5.2733 - val_MinusLogProbMetric: 5.2733 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-12 10:54:04.571 
Epoch 16/1000 
	 loss: 5.1896, MinusLogProbMetric: 5.1896, val_loss: 5.2315, val_MinusLogProbMetric: 5.2315

Epoch 16: val_loss did not improve from 5.15684
196/196 - 12s - loss: 5.1896 - MinusLogProbMetric: 5.1896 - val_loss: 5.2315 - val_MinusLogProbMetric: 5.2315 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 10:54:16.430 
Epoch 17/1000 
	 loss: 5.1787, MinusLogProbMetric: 5.1787, val_loss: 5.1925, val_MinusLogProbMetric: 5.1925

Epoch 17: val_loss did not improve from 5.15684
196/196 - 12s - loss: 5.1787 - MinusLogProbMetric: 5.1787 - val_loss: 5.1925 - val_MinusLogProbMetric: 5.1925 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 18/1000
2023-09-12 10:54:28.174 
Epoch 18/1000 
	 loss: 5.1788, MinusLogProbMetric: 5.1788, val_loss: 5.1473, val_MinusLogProbMetric: 5.1473

Epoch 18: val_loss improved from 5.15684 to 5.14733, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.1788 - MinusLogProbMetric: 5.1788 - val_loss: 5.1473 - val_MinusLogProbMetric: 5.1473 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 19/1000
2023-09-12 10:54:40.097 
Epoch 19/1000 
	 loss: 5.1792, MinusLogProbMetric: 5.1792, val_loss: 5.1441, val_MinusLogProbMetric: 5.1441

Epoch 19: val_loss improved from 5.14733 to 5.14405, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.1792 - MinusLogProbMetric: 5.1792 - val_loss: 5.1441 - val_MinusLogProbMetric: 5.1441 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 20/1000
2023-09-12 10:54:51.919 
Epoch 20/1000 
	 loss: 5.1515, MinusLogProbMetric: 5.1515, val_loss: 5.1416, val_MinusLogProbMetric: 5.1416

Epoch 20: val_loss improved from 5.14405 to 5.14157, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.1515 - MinusLogProbMetric: 5.1515 - val_loss: 5.1416 - val_MinusLogProbMetric: 5.1416 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 21/1000
2023-09-12 10:55:03.966 
Epoch 21/1000 
	 loss: 5.1515, MinusLogProbMetric: 5.1515, val_loss: 5.1659, val_MinusLogProbMetric: 5.1659

Epoch 21: val_loss did not improve from 5.14157
196/196 - 12s - loss: 5.1515 - MinusLogProbMetric: 5.1515 - val_loss: 5.1659 - val_MinusLogProbMetric: 5.1659 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 22/1000
2023-09-12 10:55:15.721 
Epoch 22/1000 
	 loss: 5.1384, MinusLogProbMetric: 5.1384, val_loss: 5.2388, val_MinusLogProbMetric: 5.2388

Epoch 22: val_loss did not improve from 5.14157
196/196 - 12s - loss: 5.1384 - MinusLogProbMetric: 5.1384 - val_loss: 5.2388 - val_MinusLogProbMetric: 5.2388 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 10:55:27.517 
Epoch 23/1000 
	 loss: 5.1406, MinusLogProbMetric: 5.1406, val_loss: 5.1373, val_MinusLogProbMetric: 5.1373

Epoch 23: val_loss improved from 5.14157 to 5.13726, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.1406 - MinusLogProbMetric: 5.1406 - val_loss: 5.1373 - val_MinusLogProbMetric: 5.1373 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 24/1000
2023-09-12 10:55:39.419 
Epoch 24/1000 
	 loss: 5.1346, MinusLogProbMetric: 5.1346, val_loss: 5.1186, val_MinusLogProbMetric: 5.1186

Epoch 24: val_loss improved from 5.13726 to 5.11861, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.1346 - MinusLogProbMetric: 5.1346 - val_loss: 5.1186 - val_MinusLogProbMetric: 5.1186 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 25/1000
2023-09-12 10:55:51.304 
Epoch 25/1000 
	 loss: 5.1343, MinusLogProbMetric: 5.1343, val_loss: 5.1478, val_MinusLogProbMetric: 5.1478

Epoch 25: val_loss did not improve from 5.11861
196/196 - 12s - loss: 5.1343 - MinusLogProbMetric: 5.1343 - val_loss: 5.1478 - val_MinusLogProbMetric: 5.1478 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 10:56:03.043 
Epoch 26/1000 
	 loss: 5.1409, MinusLogProbMetric: 5.1409, val_loss: 5.1623, val_MinusLogProbMetric: 5.1623

Epoch 26: val_loss did not improve from 5.11861
196/196 - 12s - loss: 5.1409 - MinusLogProbMetric: 5.1409 - val_loss: 5.1623 - val_MinusLogProbMetric: 5.1623 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 10:56:14.781 
Epoch 27/1000 
	 loss: 5.1420, MinusLogProbMetric: 5.1420, val_loss: 5.1877, val_MinusLogProbMetric: 5.1877

Epoch 27: val_loss did not improve from 5.11861
196/196 - 12s - loss: 5.1420 - MinusLogProbMetric: 5.1420 - val_loss: 5.1877 - val_MinusLogProbMetric: 5.1877 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-12 10:56:26.425 
Epoch 28/1000 
	 loss: 5.1347, MinusLogProbMetric: 5.1347, val_loss: 5.1559, val_MinusLogProbMetric: 5.1559

Epoch 28: val_loss did not improve from 5.11861
196/196 - 12s - loss: 5.1347 - MinusLogProbMetric: 5.1347 - val_loss: 5.1559 - val_MinusLogProbMetric: 5.1559 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 10:56:38.119 
Epoch 29/1000 
	 loss: 5.1261, MinusLogProbMetric: 5.1261, val_loss: 5.0649, val_MinusLogProbMetric: 5.0649

Epoch 29: val_loss improved from 5.11861 to 5.06493, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.1261 - MinusLogProbMetric: 5.1261 - val_loss: 5.0649 - val_MinusLogProbMetric: 5.0649 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 30/1000
2023-09-12 10:56:48.848 
Epoch 30/1000 
	 loss: 5.1167, MinusLogProbMetric: 5.1167, val_loss: 5.1843, val_MinusLogProbMetric: 5.1843

Epoch 30: val_loss did not improve from 5.06493
196/196 - 11s - loss: 5.1167 - MinusLogProbMetric: 5.1167 - val_loss: 5.1843 - val_MinusLogProbMetric: 5.1843 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 31/1000
2023-09-12 10:56:58.960 
Epoch 31/1000 
	 loss: 5.1292, MinusLogProbMetric: 5.1292, val_loss: 5.1916, val_MinusLogProbMetric: 5.1916

Epoch 31: val_loss did not improve from 5.06493
196/196 - 10s - loss: 5.1292 - MinusLogProbMetric: 5.1292 - val_loss: 5.1916 - val_MinusLogProbMetric: 5.1916 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 32/1000
2023-09-12 10:57:09.287 
Epoch 32/1000 
	 loss: 5.1118, MinusLogProbMetric: 5.1118, val_loss: 5.1104, val_MinusLogProbMetric: 5.1104

Epoch 32: val_loss did not improve from 5.06493
196/196 - 10s - loss: 5.1118 - MinusLogProbMetric: 5.1118 - val_loss: 5.1104 - val_MinusLogProbMetric: 5.1104 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 33/1000
2023-09-12 10:57:20.183 
Epoch 33/1000 
	 loss: 5.1148, MinusLogProbMetric: 5.1148, val_loss: 5.1263, val_MinusLogProbMetric: 5.1263

Epoch 33: val_loss did not improve from 5.06493
196/196 - 11s - loss: 5.1148 - MinusLogProbMetric: 5.1148 - val_loss: 5.1263 - val_MinusLogProbMetric: 5.1263 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 34/1000
2023-09-12 10:57:31.358 
Epoch 34/1000 
	 loss: 5.1289, MinusLogProbMetric: 5.1289, val_loss: 5.1500, val_MinusLogProbMetric: 5.1500

Epoch 34: val_loss did not improve from 5.06493
196/196 - 11s - loss: 5.1289 - MinusLogProbMetric: 5.1289 - val_loss: 5.1500 - val_MinusLogProbMetric: 5.1500 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 35/1000
2023-09-12 10:57:43.139 
Epoch 35/1000 
	 loss: 5.1086, MinusLogProbMetric: 5.1086, val_loss: 5.0778, val_MinusLogProbMetric: 5.0778

Epoch 35: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1086 - MinusLogProbMetric: 5.1086 - val_loss: 5.0778 - val_MinusLogProbMetric: 5.0778 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-12 10:57:54.945 
Epoch 36/1000 
	 loss: 5.1042, MinusLogProbMetric: 5.1042, val_loss: 5.0966, val_MinusLogProbMetric: 5.0966

Epoch 36: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1042 - MinusLogProbMetric: 5.1042 - val_loss: 5.0966 - val_MinusLogProbMetric: 5.0966 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 10:58:06.706 
Epoch 37/1000 
	 loss: 5.1051, MinusLogProbMetric: 5.1051, val_loss: 5.2532, val_MinusLogProbMetric: 5.2532

Epoch 37: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1051 - MinusLogProbMetric: 5.1051 - val_loss: 5.2532 - val_MinusLogProbMetric: 5.2532 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 38/1000
2023-09-12 10:58:18.351 
Epoch 38/1000 
	 loss: 5.1132, MinusLogProbMetric: 5.1132, val_loss: 5.0797, val_MinusLogProbMetric: 5.0797

Epoch 38: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1132 - MinusLogProbMetric: 5.1132 - val_loss: 5.0797 - val_MinusLogProbMetric: 5.0797 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 39/1000
2023-09-12 10:58:29.911 
Epoch 39/1000 
	 loss: 5.1057, MinusLogProbMetric: 5.1057, val_loss: 5.1263, val_MinusLogProbMetric: 5.1263

Epoch 39: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1057 - MinusLogProbMetric: 5.1057 - val_loss: 5.1263 - val_MinusLogProbMetric: 5.1263 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-12 10:58:41.718 
Epoch 40/1000 
	 loss: 5.1051, MinusLogProbMetric: 5.1051, val_loss: 5.1178, val_MinusLogProbMetric: 5.1178

Epoch 40: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1051 - MinusLogProbMetric: 5.1051 - val_loss: 5.1178 - val_MinusLogProbMetric: 5.1178 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-12 10:58:53.415 
Epoch 41/1000 
	 loss: 5.1067, MinusLogProbMetric: 5.1067, val_loss: 5.1156, val_MinusLogProbMetric: 5.1156

Epoch 41: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1067 - MinusLogProbMetric: 5.1067 - val_loss: 5.1156 - val_MinusLogProbMetric: 5.1156 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-12 10:59:05.028 
Epoch 42/1000 
	 loss: 5.1055, MinusLogProbMetric: 5.1055, val_loss: 5.0952, val_MinusLogProbMetric: 5.0952

Epoch 42: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1055 - MinusLogProbMetric: 5.1055 - val_loss: 5.0952 - val_MinusLogProbMetric: 5.0952 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 43/1000
2023-09-12 10:59:16.856 
Epoch 43/1000 
	 loss: 5.1054, MinusLogProbMetric: 5.1054, val_loss: 5.1042, val_MinusLogProbMetric: 5.1042

Epoch 43: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.1054 - MinusLogProbMetric: 5.1054 - val_loss: 5.1042 - val_MinusLogProbMetric: 5.1042 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 44/1000
2023-09-12 10:59:28.583 
Epoch 44/1000 
	 loss: 5.0973, MinusLogProbMetric: 5.0973, val_loss: 5.1170, val_MinusLogProbMetric: 5.1170

Epoch 44: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.0973 - MinusLogProbMetric: 5.0973 - val_loss: 5.1170 - val_MinusLogProbMetric: 5.1170 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-12 10:59:40.439 
Epoch 45/1000 
	 loss: 5.0987, MinusLogProbMetric: 5.0987, val_loss: 5.0932, val_MinusLogProbMetric: 5.0932

Epoch 45: val_loss did not improve from 5.06493
196/196 - 12s - loss: 5.0987 - MinusLogProbMetric: 5.0987 - val_loss: 5.0932 - val_MinusLogProbMetric: 5.0932 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-12 10:59:52.282 
Epoch 46/1000 
	 loss: 5.0877, MinusLogProbMetric: 5.0877, val_loss: 5.0633, val_MinusLogProbMetric: 5.0633

Epoch 46: val_loss improved from 5.06493 to 5.06330, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_116/weights/best_weights.h5
196/196 - 12s - loss: 5.0877 - MinusLogProbMetric: 5.0877 - val_loss: 5.0633 - val_MinusLogProbMetric: 5.0633 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 47/1000
2023-09-12 11:00:04.158 
Epoch 47/1000 
	 loss: 5.0835, MinusLogProbMetric: 5.0835, val_loss: 5.1149, val_MinusLogProbMetric: 5.1149

Epoch 47: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0835 - MinusLogProbMetric: 5.0835 - val_loss: 5.1149 - val_MinusLogProbMetric: 5.1149 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-12 11:00:15.872 
Epoch 48/1000 
	 loss: 5.0923, MinusLogProbMetric: 5.0923, val_loss: 5.1035, val_MinusLogProbMetric: 5.1035

Epoch 48: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0923 - MinusLogProbMetric: 5.0923 - val_loss: 5.1035 - val_MinusLogProbMetric: 5.1035 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 49/1000
2023-09-12 11:00:27.672 
Epoch 49/1000 
	 loss: 5.0972, MinusLogProbMetric: 5.0972, val_loss: 5.1031, val_MinusLogProbMetric: 5.1031

Epoch 49: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0972 - MinusLogProbMetric: 5.0972 - val_loss: 5.1031 - val_MinusLogProbMetric: 5.1031 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-12 11:00:39.316 
Epoch 50/1000 
	 loss: 5.0832, MinusLogProbMetric: 5.0832, val_loss: 5.1031, val_MinusLogProbMetric: 5.1031

Epoch 50: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0832 - MinusLogProbMetric: 5.0832 - val_loss: 5.1031 - val_MinusLogProbMetric: 5.1031 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 51/1000
2023-09-12 11:00:51.063 
Epoch 51/1000 
	 loss: 5.0897, MinusLogProbMetric: 5.0897, val_loss: 5.0800, val_MinusLogProbMetric: 5.0800

Epoch 51: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0897 - MinusLogProbMetric: 5.0897 - val_loss: 5.0800 - val_MinusLogProbMetric: 5.0800 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 52/1000
2023-09-12 11:01:02.763 
Epoch 52/1000 
	 loss: 5.0827, MinusLogProbMetric: 5.0827, val_loss: 5.0925, val_MinusLogProbMetric: 5.0925

Epoch 52: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0827 - MinusLogProbMetric: 5.0827 - val_loss: 5.0925 - val_MinusLogProbMetric: 5.0925 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 53/1000
2023-09-12 11:01:14.586 
Epoch 53/1000 
	 loss: 5.0865, MinusLogProbMetric: 5.0865, val_loss: 5.1408, val_MinusLogProbMetric: 5.1408

Epoch 53: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0865 - MinusLogProbMetric: 5.0865 - val_loss: 5.1408 - val_MinusLogProbMetric: 5.1408 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-12 11:01:26.353 
Epoch 54/1000 
	 loss: 5.0794, MinusLogProbMetric: 5.0794, val_loss: 5.1756, val_MinusLogProbMetric: 5.1756

Epoch 54: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0794 - MinusLogProbMetric: 5.0794 - val_loss: 5.1756 - val_MinusLogProbMetric: 5.1756 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 55/1000
2023-09-12 11:01:38.081 
Epoch 55/1000 
	 loss: 5.0852, MinusLogProbMetric: 5.0852, val_loss: 5.0994, val_MinusLogProbMetric: 5.0994

Epoch 55: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0852 - MinusLogProbMetric: 5.0852 - val_loss: 5.0994 - val_MinusLogProbMetric: 5.0994 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-12 11:01:49.877 
Epoch 56/1000 
	 loss: 5.0843, MinusLogProbMetric: 5.0843, val_loss: 5.1377, val_MinusLogProbMetric: 5.1377

Epoch 56: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0843 - MinusLogProbMetric: 5.0843 - val_loss: 5.1377 - val_MinusLogProbMetric: 5.1377 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-12 11:02:01.665 
Epoch 57/1000 
	 loss: 5.0762, MinusLogProbMetric: 5.0762, val_loss: 5.0886, val_MinusLogProbMetric: 5.0886

Epoch 57: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0762 - MinusLogProbMetric: 5.0762 - val_loss: 5.0886 - val_MinusLogProbMetric: 5.0886 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-12 11:02:13.405 
Epoch 58/1000 
	 loss: 5.0782, MinusLogProbMetric: 5.0782, val_loss: 5.1044, val_MinusLogProbMetric: 5.1044

Epoch 58: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0782 - MinusLogProbMetric: 5.0782 - val_loss: 5.1044 - val_MinusLogProbMetric: 5.1044 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-12 11:02:25.179 
Epoch 59/1000 
	 loss: 5.0839, MinusLogProbMetric: 5.0839, val_loss: 5.0888, val_MinusLogProbMetric: 5.0888

Epoch 59: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0839 - MinusLogProbMetric: 5.0839 - val_loss: 5.0888 - val_MinusLogProbMetric: 5.0888 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-12 11:02:36.890 
Epoch 60/1000 
	 loss: 5.0818, MinusLogProbMetric: 5.0818, val_loss: 5.1148, val_MinusLogProbMetric: 5.1148

Epoch 60: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0818 - MinusLogProbMetric: 5.0818 - val_loss: 5.1148 - val_MinusLogProbMetric: 5.1148 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-12 11:02:48.812 
Epoch 61/1000 
	 loss: 5.0782, MinusLogProbMetric: 5.0782, val_loss: 5.1125, val_MinusLogProbMetric: 5.1125

Epoch 61: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0782 - MinusLogProbMetric: 5.0782 - val_loss: 5.1125 - val_MinusLogProbMetric: 5.1125 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 62/1000
2023-09-12 11:03:00.686 
Epoch 62/1000 
	 loss: 5.0731, MinusLogProbMetric: 5.0731, val_loss: 5.0685, val_MinusLogProbMetric: 5.0685

Epoch 62: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0731 - MinusLogProbMetric: 5.0731 - val_loss: 5.0685 - val_MinusLogProbMetric: 5.0685 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 63/1000
2023-09-12 11:03:12.386 
Epoch 63/1000 
	 loss: 5.0731, MinusLogProbMetric: 5.0731, val_loss: 5.1867, val_MinusLogProbMetric: 5.1867

Epoch 63: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0731 - MinusLogProbMetric: 5.0731 - val_loss: 5.1867 - val_MinusLogProbMetric: 5.1867 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-12 11:03:24.002 
Epoch 64/1000 
	 loss: 5.0745, MinusLogProbMetric: 5.0745, val_loss: 5.1016, val_MinusLogProbMetric: 5.1016

Epoch 64: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0745 - MinusLogProbMetric: 5.0745 - val_loss: 5.1016 - val_MinusLogProbMetric: 5.1016 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 65/1000
2023-09-12 11:03:35.851 
Epoch 65/1000 
	 loss: 5.0763, MinusLogProbMetric: 5.0763, val_loss: 5.1574, val_MinusLogProbMetric: 5.1574

Epoch 65: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0763 - MinusLogProbMetric: 5.0763 - val_loss: 5.1574 - val_MinusLogProbMetric: 5.1574 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-12 11:03:47.552 
Epoch 66/1000 
	 loss: 5.0663, MinusLogProbMetric: 5.0663, val_loss: 5.1573, val_MinusLogProbMetric: 5.1573

Epoch 66: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0663 - MinusLogProbMetric: 5.0663 - val_loss: 5.1573 - val_MinusLogProbMetric: 5.1573 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-12 11:03:59.205 
Epoch 67/1000 
	 loss: 5.0738, MinusLogProbMetric: 5.0738, val_loss: 5.1405, val_MinusLogProbMetric: 5.1405

Epoch 67: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0738 - MinusLogProbMetric: 5.0738 - val_loss: 5.1405 - val_MinusLogProbMetric: 5.1405 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 68/1000
2023-09-12 11:04:11.002 
Epoch 68/1000 
	 loss: 5.0669, MinusLogProbMetric: 5.0669, val_loss: 5.0847, val_MinusLogProbMetric: 5.0847

Epoch 68: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0669 - MinusLogProbMetric: 5.0669 - val_loss: 5.0847 - val_MinusLogProbMetric: 5.0847 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-12 11:04:22.760 
Epoch 69/1000 
	 loss: 5.0592, MinusLogProbMetric: 5.0592, val_loss: 5.1106, val_MinusLogProbMetric: 5.1106

Epoch 69: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0592 - MinusLogProbMetric: 5.0592 - val_loss: 5.1106 - val_MinusLogProbMetric: 5.1106 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 11:04:34.508 
Epoch 70/1000 
	 loss: 5.0643, MinusLogProbMetric: 5.0643, val_loss: 5.0995, val_MinusLogProbMetric: 5.0995

Epoch 70: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0643 - MinusLogProbMetric: 5.0643 - val_loss: 5.0995 - val_MinusLogProbMetric: 5.0995 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-12 11:04:46.209 
Epoch 71/1000 
	 loss: 5.0662, MinusLogProbMetric: 5.0662, val_loss: 5.1042, val_MinusLogProbMetric: 5.1042

Epoch 71: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0662 - MinusLogProbMetric: 5.0662 - val_loss: 5.1042 - val_MinusLogProbMetric: 5.1042 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-12 11:04:58.012 
Epoch 72/1000 
	 loss: 5.0689, MinusLogProbMetric: 5.0689, val_loss: 5.0999, val_MinusLogProbMetric: 5.0999

Epoch 72: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0689 - MinusLogProbMetric: 5.0689 - val_loss: 5.0999 - val_MinusLogProbMetric: 5.0999 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-12 11:05:09.761 
Epoch 73/1000 
	 loss: 5.0637, MinusLogProbMetric: 5.0637, val_loss: 5.1107, val_MinusLogProbMetric: 5.1107

Epoch 73: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0637 - MinusLogProbMetric: 5.0637 - val_loss: 5.1107 - val_MinusLogProbMetric: 5.1107 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-12 11:05:21.503 
Epoch 74/1000 
	 loss: 5.0655, MinusLogProbMetric: 5.0655, val_loss: 5.0729, val_MinusLogProbMetric: 5.0729

Epoch 74: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0655 - MinusLogProbMetric: 5.0655 - val_loss: 5.0729 - val_MinusLogProbMetric: 5.0729 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-12 11:05:33.225 
Epoch 75/1000 
	 loss: 5.0677, MinusLogProbMetric: 5.0677, val_loss: 5.0980, val_MinusLogProbMetric: 5.0980

Epoch 75: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0677 - MinusLogProbMetric: 5.0677 - val_loss: 5.0980 - val_MinusLogProbMetric: 5.0980 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-12 11:05:44.924 
Epoch 76/1000 
	 loss: 5.0694, MinusLogProbMetric: 5.0694, val_loss: 5.0773, val_MinusLogProbMetric: 5.0773

Epoch 76: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0694 - MinusLogProbMetric: 5.0694 - val_loss: 5.0773 - val_MinusLogProbMetric: 5.0773 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-12 11:05:56.617 
Epoch 77/1000 
	 loss: 5.0629, MinusLogProbMetric: 5.0629, val_loss: 5.1701, val_MinusLogProbMetric: 5.1701

Epoch 77: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0629 - MinusLogProbMetric: 5.0629 - val_loss: 5.1701 - val_MinusLogProbMetric: 5.1701 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-12 11:06:08.361 
Epoch 78/1000 
	 loss: 5.0585, MinusLogProbMetric: 5.0585, val_loss: 5.0980, val_MinusLogProbMetric: 5.0980

Epoch 78: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0585 - MinusLogProbMetric: 5.0585 - val_loss: 5.0980 - val_MinusLogProbMetric: 5.0980 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 79/1000
2023-09-12 11:06:20.181 
Epoch 79/1000 
	 loss: 5.0610, MinusLogProbMetric: 5.0610, val_loss: 5.1005, val_MinusLogProbMetric: 5.1005

Epoch 79: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0610 - MinusLogProbMetric: 5.0610 - val_loss: 5.1005 - val_MinusLogProbMetric: 5.1005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 11:06:31.879 
Epoch 80/1000 
	 loss: 5.0598, MinusLogProbMetric: 5.0598, val_loss: 5.1634, val_MinusLogProbMetric: 5.1634

Epoch 80: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0598 - MinusLogProbMetric: 5.0598 - val_loss: 5.1634 - val_MinusLogProbMetric: 5.1634 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 81/1000
2023-09-12 11:06:43.510 
Epoch 81/1000 
	 loss: 5.0608, MinusLogProbMetric: 5.0608, val_loss: 5.1522, val_MinusLogProbMetric: 5.1522

Epoch 81: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0608 - MinusLogProbMetric: 5.0608 - val_loss: 5.1522 - val_MinusLogProbMetric: 5.1522 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 82/1000
2023-09-12 11:06:55.181 
Epoch 82/1000 
	 loss: 5.0610, MinusLogProbMetric: 5.0610, val_loss: 5.0760, val_MinusLogProbMetric: 5.0760

Epoch 82: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0610 - MinusLogProbMetric: 5.0610 - val_loss: 5.0760 - val_MinusLogProbMetric: 5.0760 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-12 11:07:06.827 
Epoch 83/1000 
	 loss: 5.0587, MinusLogProbMetric: 5.0587, val_loss: 5.0968, val_MinusLogProbMetric: 5.0968

Epoch 83: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0587 - MinusLogProbMetric: 5.0587 - val_loss: 5.0968 - val_MinusLogProbMetric: 5.0968 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-12 11:07:18.553 
Epoch 84/1000 
	 loss: 5.0543, MinusLogProbMetric: 5.0543, val_loss: 5.0877, val_MinusLogProbMetric: 5.0877

Epoch 84: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0543 - MinusLogProbMetric: 5.0543 - val_loss: 5.0877 - val_MinusLogProbMetric: 5.0877 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 85/1000
2023-09-12 11:07:30.244 
Epoch 85/1000 
	 loss: 5.0617, MinusLogProbMetric: 5.0617, val_loss: 5.0838, val_MinusLogProbMetric: 5.0838

Epoch 85: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0617 - MinusLogProbMetric: 5.0617 - val_loss: 5.0838 - val_MinusLogProbMetric: 5.0838 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-12 11:07:42.020 
Epoch 86/1000 
	 loss: 5.0628, MinusLogProbMetric: 5.0628, val_loss: 5.1057, val_MinusLogProbMetric: 5.1057

Epoch 86: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0628 - MinusLogProbMetric: 5.0628 - val_loss: 5.1057 - val_MinusLogProbMetric: 5.1057 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 87/1000
2023-09-12 11:07:53.711 
Epoch 87/1000 
	 loss: 5.0483, MinusLogProbMetric: 5.0483, val_loss: 5.0883, val_MinusLogProbMetric: 5.0883

Epoch 87: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0483 - MinusLogProbMetric: 5.0483 - val_loss: 5.0883 - val_MinusLogProbMetric: 5.0883 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 88/1000
2023-09-12 11:08:05.499 
Epoch 88/1000 
	 loss: 5.0445, MinusLogProbMetric: 5.0445, val_loss: 5.0766, val_MinusLogProbMetric: 5.0766

Epoch 88: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0445 - MinusLogProbMetric: 5.0445 - val_loss: 5.0766 - val_MinusLogProbMetric: 5.0766 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-12 11:08:17.381 
Epoch 89/1000 
	 loss: 5.0543, MinusLogProbMetric: 5.0543, val_loss: 5.1067, val_MinusLogProbMetric: 5.1067

Epoch 89: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0543 - MinusLogProbMetric: 5.0543 - val_loss: 5.1067 - val_MinusLogProbMetric: 5.1067 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 90/1000
2023-09-12 11:08:28.954 
Epoch 90/1000 
	 loss: 5.0461, MinusLogProbMetric: 5.0461, val_loss: 5.0893, val_MinusLogProbMetric: 5.0893

Epoch 90: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0461 - MinusLogProbMetric: 5.0461 - val_loss: 5.0893 - val_MinusLogProbMetric: 5.0893 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 91/1000
2023-09-12 11:08:40.667 
Epoch 91/1000 
	 loss: 5.0484, MinusLogProbMetric: 5.0484, val_loss: 5.0950, val_MinusLogProbMetric: 5.0950

Epoch 91: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0484 - MinusLogProbMetric: 5.0484 - val_loss: 5.0950 - val_MinusLogProbMetric: 5.0950 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 11:08:52.300 
Epoch 92/1000 
	 loss: 5.0432, MinusLogProbMetric: 5.0432, val_loss: 5.1055, val_MinusLogProbMetric: 5.1055

Epoch 92: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0432 - MinusLogProbMetric: 5.0432 - val_loss: 5.1055 - val_MinusLogProbMetric: 5.1055 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 93/1000
2023-09-12 11:09:03.991 
Epoch 93/1000 
	 loss: 5.0460, MinusLogProbMetric: 5.0460, val_loss: 5.0884, val_MinusLogProbMetric: 5.0884

Epoch 93: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0460 - MinusLogProbMetric: 5.0460 - val_loss: 5.0884 - val_MinusLogProbMetric: 5.0884 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-12 11:09:15.644 
Epoch 94/1000 
	 loss: 5.0455, MinusLogProbMetric: 5.0455, val_loss: 5.0767, val_MinusLogProbMetric: 5.0767

Epoch 94: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0455 - MinusLogProbMetric: 5.0455 - val_loss: 5.0767 - val_MinusLogProbMetric: 5.0767 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-12 11:09:27.296 
Epoch 95/1000 
	 loss: 5.0410, MinusLogProbMetric: 5.0410, val_loss: 5.0713, val_MinusLogProbMetric: 5.0713

Epoch 95: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0410 - MinusLogProbMetric: 5.0410 - val_loss: 5.0713 - val_MinusLogProbMetric: 5.0713 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 96/1000
2023-09-12 11:09:38.978 
Epoch 96/1000 
	 loss: 5.0408, MinusLogProbMetric: 5.0408, val_loss: 5.0796, val_MinusLogProbMetric: 5.0796

Epoch 96: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0408 - MinusLogProbMetric: 5.0408 - val_loss: 5.0796 - val_MinusLogProbMetric: 5.0796 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 97/1000
2023-09-12 11:09:50.619 
Epoch 97/1000 
	 loss: 5.0115, MinusLogProbMetric: 5.0115, val_loss: 5.0731, val_MinusLogProbMetric: 5.0731

Epoch 97: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0115 - MinusLogProbMetric: 5.0115 - val_loss: 5.0731 - val_MinusLogProbMetric: 5.0731 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 98/1000
2023-09-12 11:10:02.225 
Epoch 98/1000 
	 loss: 5.0072, MinusLogProbMetric: 5.0072, val_loss: 5.0811, val_MinusLogProbMetric: 5.0811

Epoch 98: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0072 - MinusLogProbMetric: 5.0072 - val_loss: 5.0811 - val_MinusLogProbMetric: 5.0811 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 99/1000
2023-09-12 11:10:13.740 
Epoch 99/1000 
	 loss: 5.0054, MinusLogProbMetric: 5.0054, val_loss: 5.0786, val_MinusLogProbMetric: 5.0786

Epoch 99: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0054 - MinusLogProbMetric: 5.0054 - val_loss: 5.0786 - val_MinusLogProbMetric: 5.0786 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 11:10:25.430 
Epoch 100/1000 
	 loss: 5.0062, MinusLogProbMetric: 5.0062, val_loss: 5.0790, val_MinusLogProbMetric: 5.0790

Epoch 100: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0062 - MinusLogProbMetric: 5.0062 - val_loss: 5.0790 - val_MinusLogProbMetric: 5.0790 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 101/1000
2023-09-12 11:10:36.974 
Epoch 101/1000 
	 loss: 5.0074, MinusLogProbMetric: 5.0074, val_loss: 5.0778, val_MinusLogProbMetric: 5.0778

Epoch 101: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0074 - MinusLogProbMetric: 5.0074 - val_loss: 5.0778 - val_MinusLogProbMetric: 5.0778 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 102/1000
2023-09-12 11:10:48.458 
Epoch 102/1000 
	 loss: 5.0039, MinusLogProbMetric: 5.0039, val_loss: 5.1081, val_MinusLogProbMetric: 5.1081

Epoch 102: val_loss did not improve from 5.06330
196/196 - 11s - loss: 5.0039 - MinusLogProbMetric: 5.0039 - val_loss: 5.1081 - val_MinusLogProbMetric: 5.1081 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 103/1000
2023-09-12 11:10:59.969 
Epoch 103/1000 
	 loss: 5.0063, MinusLogProbMetric: 5.0063, val_loss: 5.0847, val_MinusLogProbMetric: 5.0847

Epoch 103: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0063 - MinusLogProbMetric: 5.0063 - val_loss: 5.0847 - val_MinusLogProbMetric: 5.0847 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 104/1000
2023-09-12 11:11:11.518 
Epoch 104/1000 
	 loss: 5.0076, MinusLogProbMetric: 5.0076, val_loss: 5.0885, val_MinusLogProbMetric: 5.0885

Epoch 104: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0076 - MinusLogProbMetric: 5.0076 - val_loss: 5.0885 - val_MinusLogProbMetric: 5.0885 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 105/1000
2023-09-12 11:11:22.961 
Epoch 105/1000 
	 loss: 5.0042, MinusLogProbMetric: 5.0042, val_loss: 5.0785, val_MinusLogProbMetric: 5.0785

Epoch 105: val_loss did not improve from 5.06330
196/196 - 11s - loss: 5.0042 - MinusLogProbMetric: 5.0042 - val_loss: 5.0785 - val_MinusLogProbMetric: 5.0785 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 106/1000
2023-09-12 11:11:34.244 
Epoch 106/1000 
	 loss: 5.0082, MinusLogProbMetric: 5.0082, val_loss: 5.0830, val_MinusLogProbMetric: 5.0830

Epoch 106: val_loss did not improve from 5.06330
196/196 - 11s - loss: 5.0082 - MinusLogProbMetric: 5.0082 - val_loss: 5.0830 - val_MinusLogProbMetric: 5.0830 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 107/1000
2023-09-12 11:11:45.767 
Epoch 107/1000 
	 loss: 5.0050, MinusLogProbMetric: 5.0050, val_loss: 5.0939, val_MinusLogProbMetric: 5.0939

Epoch 107: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0050 - MinusLogProbMetric: 5.0050 - val_loss: 5.0939 - val_MinusLogProbMetric: 5.0939 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 108/1000
2023-09-12 11:11:57.369 
Epoch 108/1000 
	 loss: 5.0049, MinusLogProbMetric: 5.0049, val_loss: 5.0720, val_MinusLogProbMetric: 5.0720

Epoch 108: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0049 - MinusLogProbMetric: 5.0049 - val_loss: 5.0720 - val_MinusLogProbMetric: 5.0720 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 109/1000
2023-09-12 11:12:08.819 
Epoch 109/1000 
	 loss: 5.0000, MinusLogProbMetric: 5.0000, val_loss: 5.0816, val_MinusLogProbMetric: 5.0816

Epoch 109: val_loss did not improve from 5.06330
196/196 - 11s - loss: 5.0000 - MinusLogProbMetric: 5.0000 - val_loss: 5.0816 - val_MinusLogProbMetric: 5.0816 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 11:12:20.165 
Epoch 110/1000 
	 loss: 5.0002, MinusLogProbMetric: 5.0002, val_loss: 5.0854, val_MinusLogProbMetric: 5.0854

Epoch 110: val_loss did not improve from 5.06330
196/196 - 11s - loss: 5.0002 - MinusLogProbMetric: 5.0002 - val_loss: 5.0854 - val_MinusLogProbMetric: 5.0854 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 111/1000
2023-09-12 11:12:31.661 
Epoch 111/1000 
	 loss: 5.0033, MinusLogProbMetric: 5.0033, val_loss: 5.0837, val_MinusLogProbMetric: 5.0837

Epoch 111: val_loss did not improve from 5.06330
196/196 - 11s - loss: 5.0033 - MinusLogProbMetric: 5.0033 - val_loss: 5.0837 - val_MinusLogProbMetric: 5.0837 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 112/1000
2023-09-12 11:12:41.171 
Epoch 112/1000 
	 loss: 5.0018, MinusLogProbMetric: 5.0018, val_loss: 5.0758, val_MinusLogProbMetric: 5.0758

Epoch 112: val_loss did not improve from 5.06330
196/196 - 10s - loss: 5.0018 - MinusLogProbMetric: 5.0018 - val_loss: 5.0758 - val_MinusLogProbMetric: 5.0758 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 113/1000
2023-09-12 11:12:50.769 
Epoch 113/1000 
	 loss: 4.9996, MinusLogProbMetric: 4.9996, val_loss: 5.0789, val_MinusLogProbMetric: 5.0789

Epoch 113: val_loss did not improve from 5.06330
196/196 - 10s - loss: 4.9996 - MinusLogProbMetric: 4.9996 - val_loss: 5.0789 - val_MinusLogProbMetric: 5.0789 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 114/1000
2023-09-12 11:13:01.329 
Epoch 114/1000 
	 loss: 5.0016, MinusLogProbMetric: 5.0016, val_loss: 5.0778, val_MinusLogProbMetric: 5.0778

Epoch 114: val_loss did not improve from 5.06330
196/196 - 11s - loss: 5.0016 - MinusLogProbMetric: 5.0016 - val_loss: 5.0778 - val_MinusLogProbMetric: 5.0778 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 115/1000
2023-09-12 11:13:10.935 
Epoch 115/1000 
	 loss: 4.9988, MinusLogProbMetric: 4.9988, val_loss: 5.0734, val_MinusLogProbMetric: 5.0734

Epoch 115: val_loss did not improve from 5.06330
196/196 - 10s - loss: 4.9988 - MinusLogProbMetric: 4.9988 - val_loss: 5.0734 - val_MinusLogProbMetric: 5.0734 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 116/1000
2023-09-12 11:13:20.361 
Epoch 116/1000 
	 loss: 5.0000, MinusLogProbMetric: 5.0000, val_loss: 5.0829, val_MinusLogProbMetric: 5.0829

Epoch 116: val_loss did not improve from 5.06330
196/196 - 9s - loss: 5.0000 - MinusLogProbMetric: 5.0000 - val_loss: 5.0829 - val_MinusLogProbMetric: 5.0829 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 117/1000
2023-09-12 11:13:31.511 
Epoch 117/1000 
	 loss: 4.9980, MinusLogProbMetric: 4.9980, val_loss: 5.0763, val_MinusLogProbMetric: 5.0763

Epoch 117: val_loss did not improve from 5.06330
196/196 - 11s - loss: 4.9980 - MinusLogProbMetric: 4.9980 - val_loss: 5.0763 - val_MinusLogProbMetric: 5.0763 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 118/1000
2023-09-12 11:13:43.151 
Epoch 118/1000 
	 loss: 4.9992, MinusLogProbMetric: 4.9992, val_loss: 5.1060, val_MinusLogProbMetric: 5.1060

Epoch 118: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9992 - MinusLogProbMetric: 4.9992 - val_loss: 5.1060 - val_MinusLogProbMetric: 5.1060 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-12 11:13:54.754 
Epoch 119/1000 
	 loss: 4.9983, MinusLogProbMetric: 4.9983, val_loss: 5.0832, val_MinusLogProbMetric: 5.0832

Epoch 119: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9983 - MinusLogProbMetric: 4.9983 - val_loss: 5.0832 - val_MinusLogProbMetric: 5.0832 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 120/1000
2023-09-12 11:14:06.431 
Epoch 120/1000 
	 loss: 4.9997, MinusLogProbMetric: 4.9997, val_loss: 5.0900, val_MinusLogProbMetric: 5.0900

Epoch 120: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9997 - MinusLogProbMetric: 4.9997 - val_loss: 5.0900 - val_MinusLogProbMetric: 5.0900 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 121/1000
2023-09-12 11:14:18.156 
Epoch 121/1000 
	 loss: 5.0005, MinusLogProbMetric: 5.0005, val_loss: 5.0764, val_MinusLogProbMetric: 5.0764

Epoch 121: val_loss did not improve from 5.06330
196/196 - 12s - loss: 5.0005 - MinusLogProbMetric: 5.0005 - val_loss: 5.0764 - val_MinusLogProbMetric: 5.0764 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-12 11:14:29.824 
Epoch 122/1000 
	 loss: 4.9960, MinusLogProbMetric: 4.9960, val_loss: 5.0749, val_MinusLogProbMetric: 5.0749

Epoch 122: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9960 - MinusLogProbMetric: 4.9960 - val_loss: 5.0749 - val_MinusLogProbMetric: 5.0749 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-12 11:14:41.611 
Epoch 123/1000 
	 loss: 4.9961, MinusLogProbMetric: 4.9961, val_loss: 5.0801, val_MinusLogProbMetric: 5.0801

Epoch 123: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9961 - MinusLogProbMetric: 4.9961 - val_loss: 5.0801 - val_MinusLogProbMetric: 5.0801 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 124/1000
2023-09-12 11:14:53.323 
Epoch 124/1000 
	 loss: 4.9954, MinusLogProbMetric: 4.9954, val_loss: 5.1061, val_MinusLogProbMetric: 5.1061

Epoch 124: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9954 - MinusLogProbMetric: 4.9954 - val_loss: 5.1061 - val_MinusLogProbMetric: 5.1061 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-12 11:15:05.193 
Epoch 125/1000 
	 loss: 4.9918, MinusLogProbMetric: 4.9918, val_loss: 5.0825, val_MinusLogProbMetric: 5.0825

Epoch 125: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9918 - MinusLogProbMetric: 4.9918 - val_loss: 5.0825 - val_MinusLogProbMetric: 5.0825 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 126/1000
2023-09-12 11:15:16.929 
Epoch 126/1000 
	 loss: 4.9963, MinusLogProbMetric: 4.9963, val_loss: 5.1012, val_MinusLogProbMetric: 5.1012

Epoch 126: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9963 - MinusLogProbMetric: 4.9963 - val_loss: 5.1012 - val_MinusLogProbMetric: 5.1012 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-12 11:15:28.697 
Epoch 127/1000 
	 loss: 4.9953, MinusLogProbMetric: 4.9953, val_loss: 5.0890, val_MinusLogProbMetric: 5.0890

Epoch 127: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9953 - MinusLogProbMetric: 4.9953 - val_loss: 5.0890 - val_MinusLogProbMetric: 5.0890 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 128/1000
2023-09-12 11:15:40.525 
Epoch 128/1000 
	 loss: 4.9915, MinusLogProbMetric: 4.9915, val_loss: 5.0706, val_MinusLogProbMetric: 5.0706

Epoch 128: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9915 - MinusLogProbMetric: 4.9915 - val_loss: 5.0706 - val_MinusLogProbMetric: 5.0706 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-12 11:15:52.147 
Epoch 129/1000 
	 loss: 4.9920, MinusLogProbMetric: 4.9920, val_loss: 5.0855, val_MinusLogProbMetric: 5.0855

Epoch 129: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9920 - MinusLogProbMetric: 4.9920 - val_loss: 5.0855 - val_MinusLogProbMetric: 5.0855 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 130/1000
2023-09-12 11:16:03.857 
Epoch 130/1000 
	 loss: 4.9921, MinusLogProbMetric: 4.9921, val_loss: 5.0865, val_MinusLogProbMetric: 5.0865

Epoch 130: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9921 - MinusLogProbMetric: 4.9921 - val_loss: 5.0865 - val_MinusLogProbMetric: 5.0865 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 131/1000
2023-09-12 11:16:15.519 
Epoch 131/1000 
	 loss: 4.9903, MinusLogProbMetric: 4.9903, val_loss: 5.0935, val_MinusLogProbMetric: 5.0935

Epoch 131: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9903 - MinusLogProbMetric: 4.9903 - val_loss: 5.0935 - val_MinusLogProbMetric: 5.0935 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 132/1000
2023-09-12 11:16:27.098 
Epoch 132/1000 
	 loss: 4.9898, MinusLogProbMetric: 4.9898, val_loss: 5.0873, val_MinusLogProbMetric: 5.0873

Epoch 132: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9898 - MinusLogProbMetric: 4.9898 - val_loss: 5.0873 - val_MinusLogProbMetric: 5.0873 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 133/1000
2023-09-12 11:16:38.850 
Epoch 133/1000 
	 loss: 4.9908, MinusLogProbMetric: 4.9908, val_loss: 5.0764, val_MinusLogProbMetric: 5.0764

Epoch 133: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9908 - MinusLogProbMetric: 4.9908 - val_loss: 5.0764 - val_MinusLogProbMetric: 5.0764 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 134/1000
2023-09-12 11:16:50.566 
Epoch 134/1000 
	 loss: 4.9914, MinusLogProbMetric: 4.9914, val_loss: 5.0927, val_MinusLogProbMetric: 5.0927

Epoch 134: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9914 - MinusLogProbMetric: 4.9914 - val_loss: 5.0927 - val_MinusLogProbMetric: 5.0927 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-12 11:17:02.284 
Epoch 135/1000 
	 loss: 4.9895, MinusLogProbMetric: 4.9895, val_loss: 5.0848, val_MinusLogProbMetric: 5.0848

Epoch 135: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9895 - MinusLogProbMetric: 4.9895 - val_loss: 5.0848 - val_MinusLogProbMetric: 5.0848 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-12 11:17:13.913 
Epoch 136/1000 
	 loss: 4.9885, MinusLogProbMetric: 4.9885, val_loss: 5.0870, val_MinusLogProbMetric: 5.0870

Epoch 136: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9885 - MinusLogProbMetric: 4.9885 - val_loss: 5.0870 - val_MinusLogProbMetric: 5.0870 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 137/1000
2023-09-12 11:17:25.418 
Epoch 137/1000 
	 loss: 4.9924, MinusLogProbMetric: 4.9924, val_loss: 5.0885, val_MinusLogProbMetric: 5.0885

Epoch 137: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9924 - MinusLogProbMetric: 4.9924 - val_loss: 5.0885 - val_MinusLogProbMetric: 5.0885 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 138/1000
2023-09-12 11:17:37.086 
Epoch 138/1000 
	 loss: 4.9893, MinusLogProbMetric: 4.9893, val_loss: 5.0809, val_MinusLogProbMetric: 5.0809

Epoch 138: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9893 - MinusLogProbMetric: 4.9893 - val_loss: 5.0809 - val_MinusLogProbMetric: 5.0809 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 139/1000
2023-09-12 11:17:48.773 
Epoch 139/1000 
	 loss: 4.9908, MinusLogProbMetric: 4.9908, val_loss: 5.0911, val_MinusLogProbMetric: 5.0911

Epoch 139: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9908 - MinusLogProbMetric: 4.9908 - val_loss: 5.0911 - val_MinusLogProbMetric: 5.0911 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-12 11:17:59.942 
Epoch 140/1000 
	 loss: 4.9874, MinusLogProbMetric: 4.9874, val_loss: 5.0865, val_MinusLogProbMetric: 5.0865

Epoch 140: val_loss did not improve from 5.06330
196/196 - 11s - loss: 4.9874 - MinusLogProbMetric: 4.9874 - val_loss: 5.0865 - val_MinusLogProbMetric: 5.0865 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 141/1000
2023-09-12 11:18:11.549 
Epoch 141/1000 
	 loss: 4.9881, MinusLogProbMetric: 4.9881, val_loss: 5.0897, val_MinusLogProbMetric: 5.0897

Epoch 141: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9881 - MinusLogProbMetric: 4.9881 - val_loss: 5.0897 - val_MinusLogProbMetric: 5.0897 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 142/1000
2023-09-12 11:18:23.165 
Epoch 142/1000 
	 loss: 4.9885, MinusLogProbMetric: 4.9885, val_loss: 5.0838, val_MinusLogProbMetric: 5.0838

Epoch 142: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9885 - MinusLogProbMetric: 4.9885 - val_loss: 5.0838 - val_MinusLogProbMetric: 5.0838 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 143/1000
2023-09-12 11:18:34.493 
Epoch 143/1000 
	 loss: 4.9874, MinusLogProbMetric: 4.9874, val_loss: 5.0846, val_MinusLogProbMetric: 5.0846

Epoch 143: val_loss did not improve from 5.06330
196/196 - 11s - loss: 4.9874 - MinusLogProbMetric: 4.9874 - val_loss: 5.0846 - val_MinusLogProbMetric: 5.0846 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-12 11:18:46.104 
Epoch 144/1000 
	 loss: 4.9861, MinusLogProbMetric: 4.9861, val_loss: 5.0917, val_MinusLogProbMetric: 5.0917

Epoch 144: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9861 - MinusLogProbMetric: 4.9861 - val_loss: 5.0917 - val_MinusLogProbMetric: 5.0917 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 145/1000
2023-09-12 11:18:57.784 
Epoch 145/1000 
	 loss: 4.9877, MinusLogProbMetric: 4.9877, val_loss: 5.0996, val_MinusLogProbMetric: 5.0996

Epoch 145: val_loss did not improve from 5.06330
196/196 - 12s - loss: 4.9877 - MinusLogProbMetric: 4.9877 - val_loss: 5.0996 - val_MinusLogProbMetric: 5.0996 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 146/1000
2023-09-12 11:19:09.527 
Epoch 146/1000 
	 loss: 4.9856, MinusLogProbMetric: 4.9856, val_loss: 5.1088, val_MinusLogProbMetric: 5.1088

Epoch 146: val_loss did not improve from 5.06330
Restoring model weights from the end of the best epoch: 46.
196/196 - 12s - loss: 4.9856 - MinusLogProbMetric: 4.9856 - val_loss: 5.1088 - val_MinusLogProbMetric: 5.1088 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 146: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 6.08927197707817 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.7574963859515265 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.1472763320198283 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.2146186919417232 seconds.
Training succeeded with seed 926.
Model trained in 1713.97 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Metrics computed in 132.59 s.
Plots done in 36.11 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 168.70 s.
===========
Run 116/360 done in 1883.49 s.
===========

Directory ../../results/MsplineN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

===========
Generating train data for run 122.
===========
Train data generated in 0.27 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_122/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_122/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.9518368 , 3.3973382 , 9.531531  , ..., 7.757203  , 2.6203427 ,
        1.8047177 ],
       [2.0608988 , 4.2499633 , 8.220001  , ..., 7.0034    , 2.2546027 ,
        2.1452668 ],
       [2.843429  , 3.9051921 , 7.4207163 , ..., 7.300193  , 3.1696632 ,
        1.5780848 ],
       ...,
       [5.2732286 , 6.077929  , 1.3790838 , ..., 0.65630984, 7.270858  ,
        1.3828237 ],
       [4.184838  , 7.1681747 , 6.2432003 , ..., 4.410938  , 2.659537  ,
        7.4785604 ],
       [5.6083927 , 7.161964  , 6.0947328 , ..., 4.4707136 , 2.6326852 ,
        7.344711  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_122/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_122
self.data_kwargs: {'seed': 0}
self.x_data: [[2.147613   3.0747468  7.824332   ... 7.103659   2.4434035  1.8856683 ]
 [5.330741   5.782131   0.60243964 ... 0.4385597  6.6599607  1.2875487 ]
 [5.9696746  7.1899557  6.848176   ... 3.815116   2.6560376  7.342258  ]
 ...
 [3.6073484  5.5595417  0.9042071  ... 0.7584033  6.576529   1.36466   ]
 [3.793339   5.232353   1.1439581  ... 1.5372672  6.3050704  1.3603225 ]
 [1.2775126  3.7349403  9.479768   ... 7.3904037  2.7995863  1.7972767 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_49 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_16 (LogProbL  (None,)                  658368    
 ayer)                                                           
                                                                 
=================================================================
Total params: 658,368
Trainable params: 658,368
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_16/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_16'")
self.model: <keras.engine.functional.Functional object at 0x7fc5854a2b90>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc64124a2c0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc64124a2c0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc64124ab90>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc64124b850>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc64124bdc0>, <keras.callbacks.ModelCheckpoint object at 0x7fc64124be80>, <keras.callbacks.EarlyStopping object at 0x7fc64124bf70>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc64124bf10>, <keras.callbacks.TerminateOnNaN object at 0x7fc64124bd90>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.9518368 , 3.3973382 , 9.531531  , ..., 7.757203  , 2.6203427 ,
        1.8047177 ],
       [2.0608988 , 4.2499633 , 8.220001  , ..., 7.0034    , 2.2546027 ,
        2.1452668 ],
       [2.843429  , 3.9051921 , 7.4207163 , ..., 7.300193  , 3.1696632 ,
        1.5780848 ],
       ...,
       [5.2732286 , 6.077929  , 1.3790838 , ..., 0.65630984, 7.270858  ,
        1.3828237 ],
       [4.184838  , 7.1681747 , 6.2432003 , ..., 4.410938  , 2.659537  ,
        7.4785604 ],
       [5.6083927 , 7.161964  , 6.0947328 , ..., 4.4707136 , 2.6326852 ,
        7.344711  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_122/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 122/360 with hyperparameters:
timestamp = 2023-09-12 11:21:59.689640
ndims = 32
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 658368
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 2.147613    3.0747468   7.824332    1.8133726   9.163057    0.34882736
  9.789957    4.1820974   9.68468     6.146849    7.005386    0.3680902
  2.6196527   1.2054405   2.7207217   1.3141394   2.9878392   4.696398
 -0.43681622  6.9252343   5.6900735   2.943952    6.358174    1.1145298
  6.7379575   9.321477    3.595148    7.318303    0.9570862   7.103659
  2.4434035   1.8856683 ]
Epoch 1/1000
2023-09-12 11:22:30.230 
Epoch 1/1000 
	 loss: 43.5447, MinusLogProbMetric: 43.5447, val_loss: 20.9322, val_MinusLogProbMetric: 20.9322

Epoch 1: val_loss improved from inf to 20.93225, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 31s - loss: 43.5447 - MinusLogProbMetric: 43.5447 - val_loss: 20.9322 - val_MinusLogProbMetric: 20.9322 - lr: 0.0010 - 31s/epoch - 156ms/step
Epoch 2/1000
2023-09-12 11:22:42.212 
Epoch 2/1000 
	 loss: 19.6842, MinusLogProbMetric: 19.6842, val_loss: 18.5202, val_MinusLogProbMetric: 18.5202

Epoch 2: val_loss improved from 20.93225 to 18.52015, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 19.6842 - MinusLogProbMetric: 19.6842 - val_loss: 18.5202 - val_MinusLogProbMetric: 18.5202 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 3/1000
2023-09-12 11:22:54.124 
Epoch 3/1000 
	 loss: 18.6374, MinusLogProbMetric: 18.6374, val_loss: 18.1465, val_MinusLogProbMetric: 18.1465

Epoch 3: val_loss improved from 18.52015 to 18.14651, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 18.6374 - MinusLogProbMetric: 18.6374 - val_loss: 18.1465 - val_MinusLogProbMetric: 18.1465 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 4/1000
2023-09-12 11:23:04.981 
Epoch 4/1000 
	 loss: 18.1941, MinusLogProbMetric: 18.1941, val_loss: 17.9945, val_MinusLogProbMetric: 17.9945

Epoch 4: val_loss improved from 18.14651 to 17.99450, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 11s - loss: 18.1941 - MinusLogProbMetric: 18.1941 - val_loss: 17.9945 - val_MinusLogProbMetric: 17.9945 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 5/1000
2023-09-12 11:23:14.893 
Epoch 5/1000 
	 loss: 17.8448, MinusLogProbMetric: 17.8448, val_loss: 17.5233, val_MinusLogProbMetric: 17.5233

Epoch 5: val_loss improved from 17.99450 to 17.52325, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 10s - loss: 17.8448 - MinusLogProbMetric: 17.8448 - val_loss: 17.5233 - val_MinusLogProbMetric: 17.5233 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 6/1000
2023-09-12 11:23:26.399 
Epoch 6/1000 
	 loss: 17.7204, MinusLogProbMetric: 17.7204, val_loss: 17.6033, val_MinusLogProbMetric: 17.6033

Epoch 6: val_loss did not improve from 17.52325
196/196 - 11s - loss: 17.7204 - MinusLogProbMetric: 17.7204 - val_loss: 17.6033 - val_MinusLogProbMetric: 17.6033 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 7/1000
2023-09-12 11:23:37.974 
Epoch 7/1000 
	 loss: 17.5848, MinusLogProbMetric: 17.5848, val_loss: 17.5033, val_MinusLogProbMetric: 17.5033

Epoch 7: val_loss improved from 17.52325 to 17.50332, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 17.5848 - MinusLogProbMetric: 17.5848 - val_loss: 17.5033 - val_MinusLogProbMetric: 17.5033 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 8/1000
2023-09-12 11:23:49.748 
Epoch 8/1000 
	 loss: 17.6420, MinusLogProbMetric: 17.6420, val_loss: 17.9796, val_MinusLogProbMetric: 17.9796

Epoch 8: val_loss did not improve from 17.50332
196/196 - 12s - loss: 17.6420 - MinusLogProbMetric: 17.6420 - val_loss: 17.9796 - val_MinusLogProbMetric: 17.9796 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-12 11:24:01.357 
Epoch 9/1000 
	 loss: 17.4051, MinusLogProbMetric: 17.4051, val_loss: 17.6031, val_MinusLogProbMetric: 17.6031

Epoch 9: val_loss did not improve from 17.50332
196/196 - 12s - loss: 17.4051 - MinusLogProbMetric: 17.4051 - val_loss: 17.6031 - val_MinusLogProbMetric: 17.6031 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 10/1000
2023-09-12 11:24:12.912 
Epoch 10/1000 
	 loss: 17.2362, MinusLogProbMetric: 17.2362, val_loss: 17.4018, val_MinusLogProbMetric: 17.4018

Epoch 10: val_loss improved from 17.50332 to 17.40177, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 17.2362 - MinusLogProbMetric: 17.2362 - val_loss: 17.4018 - val_MinusLogProbMetric: 17.4018 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 11/1000
2023-09-12 11:24:24.845 
Epoch 11/1000 
	 loss: 17.2644, MinusLogProbMetric: 17.2644, val_loss: 17.3181, val_MinusLogProbMetric: 17.3181

Epoch 11: val_loss improved from 17.40177 to 17.31805, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 17.2644 - MinusLogProbMetric: 17.2644 - val_loss: 17.3181 - val_MinusLogProbMetric: 17.3181 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 12/1000
2023-09-12 11:24:36.730 
Epoch 12/1000 
	 loss: 17.2945, MinusLogProbMetric: 17.2945, val_loss: 17.6544, val_MinusLogProbMetric: 17.6544

Epoch 12: val_loss did not improve from 17.31805
196/196 - 12s - loss: 17.2945 - MinusLogProbMetric: 17.2945 - val_loss: 17.6544 - val_MinusLogProbMetric: 17.6544 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-12 11:24:48.467 
Epoch 13/1000 
	 loss: 17.1055, MinusLogProbMetric: 17.1055, val_loss: 17.2399, val_MinusLogProbMetric: 17.2399

Epoch 13: val_loss improved from 17.31805 to 17.23991, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 17.1055 - MinusLogProbMetric: 17.1055 - val_loss: 17.2399 - val_MinusLogProbMetric: 17.2399 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 14/1000
2023-09-12 11:25:00.348 
Epoch 14/1000 
	 loss: 17.0791, MinusLogProbMetric: 17.0791, val_loss: 17.3075, val_MinusLogProbMetric: 17.3075

Epoch 14: val_loss did not improve from 17.23991
196/196 - 12s - loss: 17.0791 - MinusLogProbMetric: 17.0791 - val_loss: 17.3075 - val_MinusLogProbMetric: 17.3075 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-12 11:25:12.065 
Epoch 15/1000 
	 loss: 17.0601, MinusLogProbMetric: 17.0601, val_loss: 16.9834, val_MinusLogProbMetric: 16.9834

Epoch 15: val_loss improved from 17.23991 to 16.98337, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 17.0601 - MinusLogProbMetric: 17.0601 - val_loss: 16.9834 - val_MinusLogProbMetric: 16.9834 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-12 11:25:23.964 
Epoch 16/1000 
	 loss: 17.0061, MinusLogProbMetric: 17.0061, val_loss: 17.0593, val_MinusLogProbMetric: 17.0593

Epoch 16: val_loss did not improve from 16.98337
196/196 - 12s - loss: 17.0061 - MinusLogProbMetric: 17.0061 - val_loss: 17.0593 - val_MinusLogProbMetric: 17.0593 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 11:25:35.588 
Epoch 17/1000 
	 loss: 16.9779, MinusLogProbMetric: 16.9779, val_loss: 17.1463, val_MinusLogProbMetric: 17.1463

Epoch 17: val_loss did not improve from 16.98337
196/196 - 12s - loss: 16.9779 - MinusLogProbMetric: 16.9779 - val_loss: 17.1463 - val_MinusLogProbMetric: 17.1463 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 18/1000
2023-09-12 11:25:47.404 
Epoch 18/1000 
	 loss: 16.9587, MinusLogProbMetric: 16.9587, val_loss: 17.0141, val_MinusLogProbMetric: 17.0141

Epoch 18: val_loss did not improve from 16.98337
196/196 - 12s - loss: 16.9587 - MinusLogProbMetric: 16.9587 - val_loss: 17.0141 - val_MinusLogProbMetric: 17.0141 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 19/1000
2023-09-12 11:25:59.102 
Epoch 19/1000 
	 loss: 16.9345, MinusLogProbMetric: 16.9345, val_loss: 16.9726, val_MinusLogProbMetric: 16.9726

Epoch 19: val_loss improved from 16.98337 to 16.97258, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.9345 - MinusLogProbMetric: 16.9345 - val_loss: 16.9726 - val_MinusLogProbMetric: 16.9726 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 20/1000
2023-09-12 11:26:10.916 
Epoch 20/1000 
	 loss: 16.9393, MinusLogProbMetric: 16.9393, val_loss: 17.0354, val_MinusLogProbMetric: 17.0354

Epoch 20: val_loss did not improve from 16.97258
196/196 - 12s - loss: 16.9393 - MinusLogProbMetric: 16.9393 - val_loss: 17.0354 - val_MinusLogProbMetric: 17.0354 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 11:26:22.611 
Epoch 21/1000 
	 loss: 16.8851, MinusLogProbMetric: 16.8851, val_loss: 17.0703, val_MinusLogProbMetric: 17.0703

Epoch 21: val_loss did not improve from 16.97258
196/196 - 12s - loss: 16.8851 - MinusLogProbMetric: 16.8851 - val_loss: 17.0703 - val_MinusLogProbMetric: 17.0703 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 22/1000
2023-09-12 11:26:34.410 
Epoch 22/1000 
	 loss: 16.8824, MinusLogProbMetric: 16.8824, val_loss: 17.0753, val_MinusLogProbMetric: 17.0753

Epoch 22: val_loss did not improve from 16.97258
196/196 - 12s - loss: 16.8824 - MinusLogProbMetric: 16.8824 - val_loss: 17.0753 - val_MinusLogProbMetric: 17.0753 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 23/1000
2023-09-12 11:26:46.010 
Epoch 23/1000 
	 loss: 16.8798, MinusLogProbMetric: 16.8798, val_loss: 17.0269, val_MinusLogProbMetric: 17.0269

Epoch 23: val_loss did not improve from 16.97258
196/196 - 12s - loss: 16.8798 - MinusLogProbMetric: 16.8798 - val_loss: 17.0269 - val_MinusLogProbMetric: 17.0269 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 24/1000
2023-09-12 11:26:57.672 
Epoch 24/1000 
	 loss: 16.8631, MinusLogProbMetric: 16.8631, val_loss: 16.8705, val_MinusLogProbMetric: 16.8705

Epoch 24: val_loss improved from 16.97258 to 16.87049, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.8631 - MinusLogProbMetric: 16.8631 - val_loss: 16.8705 - val_MinusLogProbMetric: 16.8705 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 25/1000
2023-09-12 11:27:09.343 
Epoch 25/1000 
	 loss: 16.8192, MinusLogProbMetric: 16.8192, val_loss: 16.9461, val_MinusLogProbMetric: 16.9461

Epoch 25: val_loss did not improve from 16.87049
196/196 - 12s - loss: 16.8192 - MinusLogProbMetric: 16.8192 - val_loss: 16.9461 - val_MinusLogProbMetric: 16.9461 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 26/1000
2023-09-12 11:27:21.072 
Epoch 26/1000 
	 loss: 16.8123, MinusLogProbMetric: 16.8123, val_loss: 16.9117, val_MinusLogProbMetric: 16.9117

Epoch 26: val_loss did not improve from 16.87049
196/196 - 12s - loss: 16.8123 - MinusLogProbMetric: 16.8123 - val_loss: 16.9117 - val_MinusLogProbMetric: 16.9117 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 11:27:32.831 
Epoch 27/1000 
	 loss: 16.8698, MinusLogProbMetric: 16.8698, val_loss: 16.9459, val_MinusLogProbMetric: 16.9459

Epoch 27: val_loss did not improve from 16.87049
196/196 - 12s - loss: 16.8698 - MinusLogProbMetric: 16.8698 - val_loss: 16.9459 - val_MinusLogProbMetric: 16.9459 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-12 11:27:44.632 
Epoch 28/1000 
	 loss: 16.8124, MinusLogProbMetric: 16.8124, val_loss: 16.8903, val_MinusLogProbMetric: 16.8903

Epoch 28: val_loss did not improve from 16.87049
196/196 - 12s - loss: 16.8124 - MinusLogProbMetric: 16.8124 - val_loss: 16.8903 - val_MinusLogProbMetric: 16.8903 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 29/1000
2023-09-12 11:27:56.310 
Epoch 29/1000 
	 loss: 16.8681, MinusLogProbMetric: 16.8681, val_loss: 16.9456, val_MinusLogProbMetric: 16.9456

Epoch 29: val_loss did not improve from 16.87049
196/196 - 12s - loss: 16.8681 - MinusLogProbMetric: 16.8681 - val_loss: 16.9456 - val_MinusLogProbMetric: 16.9456 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 30/1000
2023-09-12 11:28:07.929 
Epoch 30/1000 
	 loss: 16.7993, MinusLogProbMetric: 16.7993, val_loss: 16.8694, val_MinusLogProbMetric: 16.8694

Epoch 30: val_loss improved from 16.87049 to 16.86939, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.7993 - MinusLogProbMetric: 16.7993 - val_loss: 16.8694 - val_MinusLogProbMetric: 16.8694 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 31/1000
2023-09-12 11:28:19.747 
Epoch 31/1000 
	 loss: 16.7918, MinusLogProbMetric: 16.7918, val_loss: 16.8875, val_MinusLogProbMetric: 16.8875

Epoch 31: val_loss did not improve from 16.86939
196/196 - 12s - loss: 16.7918 - MinusLogProbMetric: 16.7918 - val_loss: 16.8875 - val_MinusLogProbMetric: 16.8875 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 32/1000
2023-09-12 11:28:31.515 
Epoch 32/1000 
	 loss: 16.7841, MinusLogProbMetric: 16.7841, val_loss: 17.0077, val_MinusLogProbMetric: 17.0077

Epoch 32: val_loss did not improve from 16.86939
196/196 - 12s - loss: 16.7841 - MinusLogProbMetric: 16.7841 - val_loss: 17.0077 - val_MinusLogProbMetric: 17.0077 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 33/1000
2023-09-12 11:28:43.247 
Epoch 33/1000 
	 loss: 16.7413, MinusLogProbMetric: 16.7413, val_loss: 16.8659, val_MinusLogProbMetric: 16.8659

Epoch 33: val_loss improved from 16.86939 to 16.86588, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.7413 - MinusLogProbMetric: 16.7413 - val_loss: 16.8659 - val_MinusLogProbMetric: 16.8659 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 34/1000
2023-09-12 11:28:55.065 
Epoch 34/1000 
	 loss: 16.7601, MinusLogProbMetric: 16.7601, val_loss: 16.8893, val_MinusLogProbMetric: 16.8893

Epoch 34: val_loss did not improve from 16.86588
196/196 - 12s - loss: 16.7601 - MinusLogProbMetric: 16.7601 - val_loss: 16.8893 - val_MinusLogProbMetric: 16.8893 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 35/1000
2023-09-12 11:29:06.651 
Epoch 35/1000 
	 loss: 16.7771, MinusLogProbMetric: 16.7771, val_loss: 17.1440, val_MinusLogProbMetric: 17.1440

Epoch 35: val_loss did not improve from 16.86588
196/196 - 12s - loss: 16.7771 - MinusLogProbMetric: 16.7771 - val_loss: 17.1440 - val_MinusLogProbMetric: 17.1440 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 36/1000
2023-09-12 11:29:18.398 
Epoch 36/1000 
	 loss: 16.7551, MinusLogProbMetric: 16.7551, val_loss: 16.9773, val_MinusLogProbMetric: 16.9773

Epoch 36: val_loss did not improve from 16.86588
196/196 - 12s - loss: 16.7551 - MinusLogProbMetric: 16.7551 - val_loss: 16.9773 - val_MinusLogProbMetric: 16.9773 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 11:29:30.176 
Epoch 37/1000 
	 loss: 16.7533, MinusLogProbMetric: 16.7533, val_loss: 16.9482, val_MinusLogProbMetric: 16.9482

Epoch 37: val_loss did not improve from 16.86588
196/196 - 12s - loss: 16.7533 - MinusLogProbMetric: 16.7533 - val_loss: 16.9482 - val_MinusLogProbMetric: 16.9482 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 38/1000
2023-09-12 11:29:41.846 
Epoch 38/1000 
	 loss: 16.7404, MinusLogProbMetric: 16.7404, val_loss: 16.8808, val_MinusLogProbMetric: 16.8808

Epoch 38: val_loss did not improve from 16.86588
196/196 - 12s - loss: 16.7404 - MinusLogProbMetric: 16.7404 - val_loss: 16.8808 - val_MinusLogProbMetric: 16.8808 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 11:29:53.566 
Epoch 39/1000 
	 loss: 16.7362, MinusLogProbMetric: 16.7362, val_loss: 16.9213, val_MinusLogProbMetric: 16.9213

Epoch 39: val_loss did not improve from 16.86588
196/196 - 12s - loss: 16.7362 - MinusLogProbMetric: 16.7362 - val_loss: 16.9213 - val_MinusLogProbMetric: 16.9213 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 40/1000
2023-09-12 11:30:05.296 
Epoch 40/1000 
	 loss: 16.7165, MinusLogProbMetric: 16.7165, val_loss: 16.7950, val_MinusLogProbMetric: 16.7950

Epoch 40: val_loss improved from 16.86588 to 16.79499, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.7165 - MinusLogProbMetric: 16.7165 - val_loss: 16.7950 - val_MinusLogProbMetric: 16.7950 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 41/1000
2023-09-12 11:30:17.184 
Epoch 41/1000 
	 loss: 16.7378, MinusLogProbMetric: 16.7378, val_loss: 16.8520, val_MinusLogProbMetric: 16.8520

Epoch 41: val_loss did not improve from 16.79499
196/196 - 12s - loss: 16.7378 - MinusLogProbMetric: 16.7378 - val_loss: 16.8520 - val_MinusLogProbMetric: 16.8520 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-12 11:30:28.923 
Epoch 42/1000 
	 loss: 16.7139, MinusLogProbMetric: 16.7139, val_loss: 16.8981, val_MinusLogProbMetric: 16.8981

Epoch 42: val_loss did not improve from 16.79499
196/196 - 12s - loss: 16.7139 - MinusLogProbMetric: 16.7139 - val_loss: 16.8981 - val_MinusLogProbMetric: 16.8981 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-12 11:30:40.595 
Epoch 43/1000 
	 loss: 16.7354, MinusLogProbMetric: 16.7354, val_loss: 16.8750, val_MinusLogProbMetric: 16.8750

Epoch 43: val_loss did not improve from 16.79499
196/196 - 12s - loss: 16.7354 - MinusLogProbMetric: 16.7354 - val_loss: 16.8750 - val_MinusLogProbMetric: 16.8750 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 44/1000
2023-09-12 11:30:52.334 
Epoch 44/1000 
	 loss: 16.7157, MinusLogProbMetric: 16.7157, val_loss: 16.8173, val_MinusLogProbMetric: 16.8173

Epoch 44: val_loss did not improve from 16.79499
196/196 - 12s - loss: 16.7157 - MinusLogProbMetric: 16.7157 - val_loss: 16.8173 - val_MinusLogProbMetric: 16.8173 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 45/1000
2023-09-12 11:31:04.023 
Epoch 45/1000 
	 loss: 16.7070, MinusLogProbMetric: 16.7070, val_loss: 16.8620, val_MinusLogProbMetric: 16.8620

Epoch 45: val_loss did not improve from 16.79499
196/196 - 12s - loss: 16.7070 - MinusLogProbMetric: 16.7070 - val_loss: 16.8620 - val_MinusLogProbMetric: 16.8620 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 46/1000
2023-09-12 11:31:15.781 
Epoch 46/1000 
	 loss: 16.7098, MinusLogProbMetric: 16.7098, val_loss: 16.8336, val_MinusLogProbMetric: 16.8336

Epoch 46: val_loss did not improve from 16.79499
196/196 - 12s - loss: 16.7098 - MinusLogProbMetric: 16.7098 - val_loss: 16.8336 - val_MinusLogProbMetric: 16.8336 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 47/1000
2023-09-12 11:31:27.479 
Epoch 47/1000 
	 loss: 16.7048, MinusLogProbMetric: 16.7048, val_loss: 16.8355, val_MinusLogProbMetric: 16.8355

Epoch 47: val_loss did not improve from 16.79499
196/196 - 12s - loss: 16.7048 - MinusLogProbMetric: 16.7048 - val_loss: 16.8355 - val_MinusLogProbMetric: 16.8355 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 48/1000
2023-09-12 11:31:39.237 
Epoch 48/1000 
	 loss: 16.7061, MinusLogProbMetric: 16.7061, val_loss: 16.7941, val_MinusLogProbMetric: 16.7941

Epoch 48: val_loss improved from 16.79499 to 16.79412, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.7061 - MinusLogProbMetric: 16.7061 - val_loss: 16.7941 - val_MinusLogProbMetric: 16.7941 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 49/1000
2023-09-12 11:31:51.110 
Epoch 49/1000 
	 loss: 16.7089, MinusLogProbMetric: 16.7089, val_loss: 16.9918, val_MinusLogProbMetric: 16.9918

Epoch 49: val_loss did not improve from 16.79412
196/196 - 12s - loss: 16.7089 - MinusLogProbMetric: 16.7089 - val_loss: 16.9918 - val_MinusLogProbMetric: 16.9918 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-12 11:32:02.835 
Epoch 50/1000 
	 loss: 16.6752, MinusLogProbMetric: 16.6752, val_loss: 16.8667, val_MinusLogProbMetric: 16.8667

Epoch 50: val_loss did not improve from 16.79412
196/196 - 12s - loss: 16.6752 - MinusLogProbMetric: 16.6752 - val_loss: 16.8667 - val_MinusLogProbMetric: 16.8667 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 51/1000
2023-09-12 11:32:14.480 
Epoch 51/1000 
	 loss: 16.6941, MinusLogProbMetric: 16.6941, val_loss: 17.1251, val_MinusLogProbMetric: 17.1251

Epoch 51: val_loss did not improve from 16.79412
196/196 - 12s - loss: 16.6941 - MinusLogProbMetric: 16.6941 - val_loss: 17.1251 - val_MinusLogProbMetric: 17.1251 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 52/1000
2023-09-12 11:32:26.216 
Epoch 52/1000 
	 loss: 16.7062, MinusLogProbMetric: 16.7062, val_loss: 16.7795, val_MinusLogProbMetric: 16.7795

Epoch 52: val_loss improved from 16.79412 to 16.77947, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.7062 - MinusLogProbMetric: 16.7062 - val_loss: 16.7795 - val_MinusLogProbMetric: 16.7795 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 53/1000
2023-09-12 11:32:38.081 
Epoch 53/1000 
	 loss: 16.6827, MinusLogProbMetric: 16.6827, val_loss: 16.8983, val_MinusLogProbMetric: 16.8983

Epoch 53: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6827 - MinusLogProbMetric: 16.6827 - val_loss: 16.8983 - val_MinusLogProbMetric: 16.8983 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-12 11:32:49.792 
Epoch 54/1000 
	 loss: 16.6970, MinusLogProbMetric: 16.6970, val_loss: 16.8103, val_MinusLogProbMetric: 16.8103

Epoch 54: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6970 - MinusLogProbMetric: 16.6970 - val_loss: 16.8103 - val_MinusLogProbMetric: 16.8103 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 55/1000
2023-09-12 11:33:01.521 
Epoch 55/1000 
	 loss: 16.6767, MinusLogProbMetric: 16.6767, val_loss: 16.7911, val_MinusLogProbMetric: 16.7911

Epoch 55: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6767 - MinusLogProbMetric: 16.6767 - val_loss: 16.7911 - val_MinusLogProbMetric: 16.7911 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-12 11:33:13.228 
Epoch 56/1000 
	 loss: 16.6494, MinusLogProbMetric: 16.6494, val_loss: 16.7942, val_MinusLogProbMetric: 16.7942

Epoch 56: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6494 - MinusLogProbMetric: 16.6494 - val_loss: 16.7942 - val_MinusLogProbMetric: 16.7942 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 57/1000
2023-09-12 11:33:24.988 
Epoch 57/1000 
	 loss: 16.6856, MinusLogProbMetric: 16.6856, val_loss: 16.8001, val_MinusLogProbMetric: 16.8001

Epoch 57: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6856 - MinusLogProbMetric: 16.6856 - val_loss: 16.8001 - val_MinusLogProbMetric: 16.8001 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 58/1000
2023-09-12 11:33:36.718 
Epoch 58/1000 
	 loss: 16.6782, MinusLogProbMetric: 16.6782, val_loss: 16.8128, val_MinusLogProbMetric: 16.8128

Epoch 58: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6782 - MinusLogProbMetric: 16.6782 - val_loss: 16.8128 - val_MinusLogProbMetric: 16.8128 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 59/1000
2023-09-12 11:33:48.553 
Epoch 59/1000 
	 loss: 16.6763, MinusLogProbMetric: 16.6763, val_loss: 16.7952, val_MinusLogProbMetric: 16.7952

Epoch 59: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6763 - MinusLogProbMetric: 16.6763 - val_loss: 16.7952 - val_MinusLogProbMetric: 16.7952 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-12 11:34:00.234 
Epoch 60/1000 
	 loss: 16.6602, MinusLogProbMetric: 16.6602, val_loss: 16.8227, val_MinusLogProbMetric: 16.8227

Epoch 60: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6602 - MinusLogProbMetric: 16.6602 - val_loss: 16.8227 - val_MinusLogProbMetric: 16.8227 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-12 11:34:11.935 
Epoch 61/1000 
	 loss: 16.6573, MinusLogProbMetric: 16.6573, val_loss: 16.9565, val_MinusLogProbMetric: 16.9565

Epoch 61: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6573 - MinusLogProbMetric: 16.6573 - val_loss: 16.9565 - val_MinusLogProbMetric: 16.9565 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-12 11:34:23.528 
Epoch 62/1000 
	 loss: 16.6639, MinusLogProbMetric: 16.6639, val_loss: 16.8640, val_MinusLogProbMetric: 16.8640

Epoch 62: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6639 - MinusLogProbMetric: 16.6639 - val_loss: 16.8640 - val_MinusLogProbMetric: 16.8640 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 63/1000
2023-09-12 11:34:35.143 
Epoch 63/1000 
	 loss: 16.6571, MinusLogProbMetric: 16.6571, val_loss: 16.7998, val_MinusLogProbMetric: 16.7998

Epoch 63: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6571 - MinusLogProbMetric: 16.6571 - val_loss: 16.7998 - val_MinusLogProbMetric: 16.7998 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 64/1000
2023-09-12 11:34:46.824 
Epoch 64/1000 
	 loss: 16.6469, MinusLogProbMetric: 16.6469, val_loss: 16.8436, val_MinusLogProbMetric: 16.8436

Epoch 64: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6469 - MinusLogProbMetric: 16.6469 - val_loss: 16.8436 - val_MinusLogProbMetric: 16.8436 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 65/1000
2023-09-12 11:34:58.404 
Epoch 65/1000 
	 loss: 16.6625, MinusLogProbMetric: 16.6625, val_loss: 16.8357, val_MinusLogProbMetric: 16.8357

Epoch 65: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6625 - MinusLogProbMetric: 16.6625 - val_loss: 16.8357 - val_MinusLogProbMetric: 16.8357 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 66/1000
2023-09-12 11:35:10.097 
Epoch 66/1000 
	 loss: 16.6744, MinusLogProbMetric: 16.6744, val_loss: 16.9919, val_MinusLogProbMetric: 16.9919

Epoch 66: val_loss did not improve from 16.77947
196/196 - 12s - loss: 16.6744 - MinusLogProbMetric: 16.6744 - val_loss: 16.9919 - val_MinusLogProbMetric: 16.9919 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 67/1000
2023-09-12 11:35:21.839 
Epoch 67/1000 
	 loss: 16.6745, MinusLogProbMetric: 16.6745, val_loss: 16.7531, val_MinusLogProbMetric: 16.7531

Epoch 67: val_loss improved from 16.77947 to 16.75311, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.6745 - MinusLogProbMetric: 16.6745 - val_loss: 16.7531 - val_MinusLogProbMetric: 16.7531 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 68/1000
2023-09-12 11:35:33.610 
Epoch 68/1000 
	 loss: 16.6458, MinusLogProbMetric: 16.6458, val_loss: 16.8450, val_MinusLogProbMetric: 16.8450

Epoch 68: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6458 - MinusLogProbMetric: 16.6458 - val_loss: 16.8450 - val_MinusLogProbMetric: 16.8450 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-12 11:35:45.433 
Epoch 69/1000 
	 loss: 16.6312, MinusLogProbMetric: 16.6312, val_loss: 16.8035, val_MinusLogProbMetric: 16.8035

Epoch 69: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6312 - MinusLogProbMetric: 16.6312 - val_loss: 16.8035 - val_MinusLogProbMetric: 16.8035 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 70/1000
2023-09-12 11:35:57.248 
Epoch 70/1000 
	 loss: 16.6264, MinusLogProbMetric: 16.6264, val_loss: 16.7881, val_MinusLogProbMetric: 16.7881

Epoch 70: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6264 - MinusLogProbMetric: 16.6264 - val_loss: 16.7881 - val_MinusLogProbMetric: 16.7881 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-12 11:36:08.901 
Epoch 71/1000 
	 loss: 16.6260, MinusLogProbMetric: 16.6260, val_loss: 16.7828, val_MinusLogProbMetric: 16.7828

Epoch 71: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6260 - MinusLogProbMetric: 16.6260 - val_loss: 16.7828 - val_MinusLogProbMetric: 16.7828 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 72/1000
2023-09-12 11:36:20.646 
Epoch 72/1000 
	 loss: 16.6342, MinusLogProbMetric: 16.6342, val_loss: 16.8269, val_MinusLogProbMetric: 16.8269

Epoch 72: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6342 - MinusLogProbMetric: 16.6342 - val_loss: 16.8269 - val_MinusLogProbMetric: 16.8269 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 73/1000
2023-09-12 11:36:32.266 
Epoch 73/1000 
	 loss: 16.6352, MinusLogProbMetric: 16.6352, val_loss: 16.8452, val_MinusLogProbMetric: 16.8452

Epoch 73: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6352 - MinusLogProbMetric: 16.6352 - val_loss: 16.8452 - val_MinusLogProbMetric: 16.8452 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 11:36:44.025 
Epoch 74/1000 
	 loss: 16.6638, MinusLogProbMetric: 16.6638, val_loss: 16.7595, val_MinusLogProbMetric: 16.7595

Epoch 74: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6638 - MinusLogProbMetric: 16.6638 - val_loss: 16.7595 - val_MinusLogProbMetric: 16.7595 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-12 11:36:55.689 
Epoch 75/1000 
	 loss: 16.6337, MinusLogProbMetric: 16.6337, val_loss: 16.8917, val_MinusLogProbMetric: 16.8917

Epoch 75: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6337 - MinusLogProbMetric: 16.6337 - val_loss: 16.8917 - val_MinusLogProbMetric: 16.8917 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 76/1000
2023-09-12 11:37:06.344 
Epoch 76/1000 
	 loss: 16.6384, MinusLogProbMetric: 16.6384, val_loss: 16.7840, val_MinusLogProbMetric: 16.7840

Epoch 76: val_loss did not improve from 16.75311
196/196 - 11s - loss: 16.6384 - MinusLogProbMetric: 16.6384 - val_loss: 16.7840 - val_MinusLogProbMetric: 16.7840 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 77/1000
2023-09-12 11:37:17.268 
Epoch 77/1000 
	 loss: 16.6123, MinusLogProbMetric: 16.6123, val_loss: 16.8757, val_MinusLogProbMetric: 16.8757

Epoch 77: val_loss did not improve from 16.75311
196/196 - 11s - loss: 16.6123 - MinusLogProbMetric: 16.6123 - val_loss: 16.8757 - val_MinusLogProbMetric: 16.8757 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 78/1000
2023-09-12 11:37:27.248 
Epoch 78/1000 
	 loss: 16.6466, MinusLogProbMetric: 16.6466, val_loss: 16.8445, val_MinusLogProbMetric: 16.8445

Epoch 78: val_loss did not improve from 16.75311
196/196 - 10s - loss: 16.6466 - MinusLogProbMetric: 16.6466 - val_loss: 16.8445 - val_MinusLogProbMetric: 16.8445 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 79/1000
2023-09-12 11:37:38.341 
Epoch 79/1000 
	 loss: 16.6449, MinusLogProbMetric: 16.6449, val_loss: 16.8521, val_MinusLogProbMetric: 16.8521

Epoch 79: val_loss did not improve from 16.75311
196/196 - 11s - loss: 16.6449 - MinusLogProbMetric: 16.6449 - val_loss: 16.8521 - val_MinusLogProbMetric: 16.8521 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 80/1000
2023-09-12 11:37:49.424 
Epoch 80/1000 
	 loss: 16.6351, MinusLogProbMetric: 16.6351, val_loss: 16.7673, val_MinusLogProbMetric: 16.7673

Epoch 80: val_loss did not improve from 16.75311
196/196 - 11s - loss: 16.6351 - MinusLogProbMetric: 16.6351 - val_loss: 16.7673 - val_MinusLogProbMetric: 16.7673 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 81/1000
2023-09-12 11:37:59.855 
Epoch 81/1000 
	 loss: 16.6312, MinusLogProbMetric: 16.6312, val_loss: 16.7722, val_MinusLogProbMetric: 16.7722

Epoch 81: val_loss did not improve from 16.75311
196/196 - 10s - loss: 16.6312 - MinusLogProbMetric: 16.6312 - val_loss: 16.7722 - val_MinusLogProbMetric: 16.7722 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 82/1000
2023-09-12 11:38:11.543 
Epoch 82/1000 
	 loss: 16.6030, MinusLogProbMetric: 16.6030, val_loss: 16.8258, val_MinusLogProbMetric: 16.8258

Epoch 82: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6030 - MinusLogProbMetric: 16.6030 - val_loss: 16.8258 - val_MinusLogProbMetric: 16.8258 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-12 11:38:23.225 
Epoch 83/1000 
	 loss: 16.6176, MinusLogProbMetric: 16.6176, val_loss: 16.7765, val_MinusLogProbMetric: 16.7765

Epoch 83: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6176 - MinusLogProbMetric: 16.6176 - val_loss: 16.7765 - val_MinusLogProbMetric: 16.7765 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 84/1000
2023-09-12 11:38:34.890 
Epoch 84/1000 
	 loss: 16.5963, MinusLogProbMetric: 16.5963, val_loss: 16.7999, val_MinusLogProbMetric: 16.7999

Epoch 84: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.5963 - MinusLogProbMetric: 16.5963 - val_loss: 16.7999 - val_MinusLogProbMetric: 16.7999 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 85/1000
2023-09-12 11:38:46.515 
Epoch 85/1000 
	 loss: 16.6079, MinusLogProbMetric: 16.6079, val_loss: 16.7981, val_MinusLogProbMetric: 16.7981

Epoch 85: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6079 - MinusLogProbMetric: 16.6079 - val_loss: 16.7981 - val_MinusLogProbMetric: 16.7981 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-12 11:38:58.430 
Epoch 86/1000 
	 loss: 16.6005, MinusLogProbMetric: 16.6005, val_loss: 16.7614, val_MinusLogProbMetric: 16.7614

Epoch 86: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6005 - MinusLogProbMetric: 16.6005 - val_loss: 16.7614 - val_MinusLogProbMetric: 16.7614 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 87/1000
2023-09-12 11:39:10.196 
Epoch 87/1000 
	 loss: 16.6087, MinusLogProbMetric: 16.6087, val_loss: 16.8337, val_MinusLogProbMetric: 16.8337

Epoch 87: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6087 - MinusLogProbMetric: 16.6087 - val_loss: 16.8337 - val_MinusLogProbMetric: 16.8337 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 88/1000
2023-09-12 11:39:21.974 
Epoch 88/1000 
	 loss: 16.6081, MinusLogProbMetric: 16.6081, val_loss: 16.8142, val_MinusLogProbMetric: 16.8142

Epoch 88: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6081 - MinusLogProbMetric: 16.6081 - val_loss: 16.8142 - val_MinusLogProbMetric: 16.8142 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 89/1000
2023-09-12 11:39:33.585 
Epoch 89/1000 
	 loss: 16.6008, MinusLogProbMetric: 16.6008, val_loss: 16.8582, val_MinusLogProbMetric: 16.8582

Epoch 89: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6008 - MinusLogProbMetric: 16.6008 - val_loss: 16.8582 - val_MinusLogProbMetric: 16.8582 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 90/1000
2023-09-12 11:39:45.233 
Epoch 90/1000 
	 loss: 16.5904, MinusLogProbMetric: 16.5904, val_loss: 16.8370, val_MinusLogProbMetric: 16.8370

Epoch 90: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.5904 - MinusLogProbMetric: 16.5904 - val_loss: 16.8370 - val_MinusLogProbMetric: 16.8370 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 91/1000
2023-09-12 11:39:57.055 
Epoch 91/1000 
	 loss: 16.5958, MinusLogProbMetric: 16.5958, val_loss: 16.8508, val_MinusLogProbMetric: 16.8508

Epoch 91: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.5958 - MinusLogProbMetric: 16.5958 - val_loss: 16.8508 - val_MinusLogProbMetric: 16.8508 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-12 11:40:08.756 
Epoch 92/1000 
	 loss: 16.6074, MinusLogProbMetric: 16.6074, val_loss: 16.8684, val_MinusLogProbMetric: 16.8684

Epoch 92: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.6074 - MinusLogProbMetric: 16.6074 - val_loss: 16.8684 - val_MinusLogProbMetric: 16.8684 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-12 11:40:20.530 
Epoch 93/1000 
	 loss: 16.5938, MinusLogProbMetric: 16.5938, val_loss: 16.8012, val_MinusLogProbMetric: 16.8012

Epoch 93: val_loss did not improve from 16.75311
196/196 - 12s - loss: 16.5938 - MinusLogProbMetric: 16.5938 - val_loss: 16.8012 - val_MinusLogProbMetric: 16.8012 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 94/1000
2023-09-12 11:40:32.156 
Epoch 94/1000 
	 loss: 16.5902, MinusLogProbMetric: 16.5902, val_loss: 16.7358, val_MinusLogProbMetric: 16.7358

Epoch 94: val_loss improved from 16.75311 to 16.73582, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.5902 - MinusLogProbMetric: 16.5902 - val_loss: 16.7358 - val_MinusLogProbMetric: 16.7358 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-12 11:40:44.106 
Epoch 95/1000 
	 loss: 16.5886, MinusLogProbMetric: 16.5886, val_loss: 16.7749, val_MinusLogProbMetric: 16.7749

Epoch 95: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5886 - MinusLogProbMetric: 16.5886 - val_loss: 16.7749 - val_MinusLogProbMetric: 16.7749 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-12 11:40:55.515 
Epoch 96/1000 
	 loss: 16.5967, MinusLogProbMetric: 16.5967, val_loss: 16.7840, val_MinusLogProbMetric: 16.7840

Epoch 96: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5967 - MinusLogProbMetric: 16.5967 - val_loss: 16.7840 - val_MinusLogProbMetric: 16.7840 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 97/1000
2023-09-12 11:41:07.067 
Epoch 97/1000 
	 loss: 16.5972, MinusLogProbMetric: 16.5972, val_loss: 16.7438, val_MinusLogProbMetric: 16.7438

Epoch 97: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5972 - MinusLogProbMetric: 16.5972 - val_loss: 16.7438 - val_MinusLogProbMetric: 16.7438 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 98/1000
2023-09-12 11:41:16.956 
Epoch 98/1000 
	 loss: 16.5751, MinusLogProbMetric: 16.5751, val_loss: 16.8599, val_MinusLogProbMetric: 16.8599

Epoch 98: val_loss did not improve from 16.73582
196/196 - 10s - loss: 16.5751 - MinusLogProbMetric: 16.5751 - val_loss: 16.8599 - val_MinusLogProbMetric: 16.8599 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 99/1000
2023-09-12 11:41:27.436 
Epoch 99/1000 
	 loss: 16.5885, MinusLogProbMetric: 16.5885, val_loss: 16.8145, val_MinusLogProbMetric: 16.8145

Epoch 99: val_loss did not improve from 16.73582
196/196 - 10s - loss: 16.5885 - MinusLogProbMetric: 16.5885 - val_loss: 16.8145 - val_MinusLogProbMetric: 16.8145 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 100/1000
2023-09-12 11:41:38.923 
Epoch 100/1000 
	 loss: 16.6061, MinusLogProbMetric: 16.6061, val_loss: 16.7622, val_MinusLogProbMetric: 16.7622

Epoch 100: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.6061 - MinusLogProbMetric: 16.6061 - val_loss: 16.7622 - val_MinusLogProbMetric: 16.7622 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 101/1000
2023-09-12 11:41:49.134 
Epoch 101/1000 
	 loss: 16.5819, MinusLogProbMetric: 16.5819, val_loss: 16.8084, val_MinusLogProbMetric: 16.8084

Epoch 101: val_loss did not improve from 16.73582
196/196 - 10s - loss: 16.5819 - MinusLogProbMetric: 16.5819 - val_loss: 16.8084 - val_MinusLogProbMetric: 16.8084 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 102/1000
2023-09-12 11:42:00.520 
Epoch 102/1000 
	 loss: 16.5715, MinusLogProbMetric: 16.5715, val_loss: 16.7624, val_MinusLogProbMetric: 16.7624

Epoch 102: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5715 - MinusLogProbMetric: 16.5715 - val_loss: 16.7624 - val_MinusLogProbMetric: 16.7624 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 103/1000
2023-09-12 11:42:11.832 
Epoch 103/1000 
	 loss: 16.5806, MinusLogProbMetric: 16.5806, val_loss: 16.8143, val_MinusLogProbMetric: 16.8143

Epoch 103: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5806 - MinusLogProbMetric: 16.5806 - val_loss: 16.8143 - val_MinusLogProbMetric: 16.8143 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 104/1000
2023-09-12 11:42:23.046 
Epoch 104/1000 
	 loss: 16.5777, MinusLogProbMetric: 16.5777, val_loss: 16.8063, val_MinusLogProbMetric: 16.8063

Epoch 104: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5777 - MinusLogProbMetric: 16.5777 - val_loss: 16.8063 - val_MinusLogProbMetric: 16.8063 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 105/1000
2023-09-12 11:42:34.016 
Epoch 105/1000 
	 loss: 16.5657, MinusLogProbMetric: 16.5657, val_loss: 16.7774, val_MinusLogProbMetric: 16.7774

Epoch 105: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5657 - MinusLogProbMetric: 16.5657 - val_loss: 16.7774 - val_MinusLogProbMetric: 16.7774 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 106/1000
2023-09-12 11:42:45.954 
Epoch 106/1000 
	 loss: 16.5825, MinusLogProbMetric: 16.5825, val_loss: 16.8324, val_MinusLogProbMetric: 16.8324

Epoch 106: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5825 - MinusLogProbMetric: 16.5825 - val_loss: 16.8324 - val_MinusLogProbMetric: 16.8324 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 107/1000
2023-09-12 11:42:57.407 
Epoch 107/1000 
	 loss: 16.5822, MinusLogProbMetric: 16.5822, val_loss: 16.7480, val_MinusLogProbMetric: 16.7480

Epoch 107: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5822 - MinusLogProbMetric: 16.5822 - val_loss: 16.7480 - val_MinusLogProbMetric: 16.7480 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 108/1000
2023-09-12 11:43:09.143 
Epoch 108/1000 
	 loss: 16.5703, MinusLogProbMetric: 16.5703, val_loss: 16.7820, val_MinusLogProbMetric: 16.7820

Epoch 108: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5703 - MinusLogProbMetric: 16.5703 - val_loss: 16.7820 - val_MinusLogProbMetric: 16.7820 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-12 11:43:20.803 
Epoch 109/1000 
	 loss: 16.5634, MinusLogProbMetric: 16.5634, val_loss: 16.8459, val_MinusLogProbMetric: 16.8459

Epoch 109: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5634 - MinusLogProbMetric: 16.5634 - val_loss: 16.8459 - val_MinusLogProbMetric: 16.8459 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-12 11:43:32.060 
Epoch 110/1000 
	 loss: 16.5770, MinusLogProbMetric: 16.5770, val_loss: 16.8146, val_MinusLogProbMetric: 16.8146

Epoch 110: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5770 - MinusLogProbMetric: 16.5770 - val_loss: 16.8146 - val_MinusLogProbMetric: 16.8146 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 111/1000
2023-09-12 11:43:43.766 
Epoch 111/1000 
	 loss: 16.5735, MinusLogProbMetric: 16.5735, val_loss: 16.7651, val_MinusLogProbMetric: 16.7651

Epoch 111: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5735 - MinusLogProbMetric: 16.5735 - val_loss: 16.7651 - val_MinusLogProbMetric: 16.7651 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-12 11:43:54.280 
Epoch 112/1000 
	 loss: 16.5703, MinusLogProbMetric: 16.5703, val_loss: 16.7955, val_MinusLogProbMetric: 16.7955

Epoch 112: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5703 - MinusLogProbMetric: 16.5703 - val_loss: 16.7955 - val_MinusLogProbMetric: 16.7955 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 113/1000
2023-09-12 11:44:04.566 
Epoch 113/1000 
	 loss: 16.5504, MinusLogProbMetric: 16.5504, val_loss: 16.8100, val_MinusLogProbMetric: 16.8100

Epoch 113: val_loss did not improve from 16.73582
196/196 - 10s - loss: 16.5504 - MinusLogProbMetric: 16.5504 - val_loss: 16.8100 - val_MinusLogProbMetric: 16.8100 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 114/1000
2023-09-12 11:44:16.066 
Epoch 114/1000 
	 loss: 16.5647, MinusLogProbMetric: 16.5647, val_loss: 16.8217, val_MinusLogProbMetric: 16.8217

Epoch 114: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5647 - MinusLogProbMetric: 16.5647 - val_loss: 16.8217 - val_MinusLogProbMetric: 16.8217 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 115/1000
2023-09-12 11:44:27.797 
Epoch 115/1000 
	 loss: 16.5680, MinusLogProbMetric: 16.5680, val_loss: 16.9132, val_MinusLogProbMetric: 16.9132

Epoch 115: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5680 - MinusLogProbMetric: 16.5680 - val_loss: 16.9132 - val_MinusLogProbMetric: 16.9132 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 116/1000
2023-09-12 11:44:38.705 
Epoch 116/1000 
	 loss: 16.5547, MinusLogProbMetric: 16.5547, val_loss: 16.7705, val_MinusLogProbMetric: 16.7705

Epoch 116: val_loss did not improve from 16.73582
196/196 - 11s - loss: 16.5547 - MinusLogProbMetric: 16.5547 - val_loss: 16.7705 - val_MinusLogProbMetric: 16.7705 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 117/1000
2023-09-12 11:44:50.565 
Epoch 117/1000 
	 loss: 16.5757, MinusLogProbMetric: 16.5757, val_loss: 16.8396, val_MinusLogProbMetric: 16.8396

Epoch 117: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5757 - MinusLogProbMetric: 16.5757 - val_loss: 16.8396 - val_MinusLogProbMetric: 16.8396 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-12 11:45:02.333 
Epoch 118/1000 
	 loss: 16.5513, MinusLogProbMetric: 16.5513, val_loss: 16.7616, val_MinusLogProbMetric: 16.7616

Epoch 118: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5513 - MinusLogProbMetric: 16.5513 - val_loss: 16.7616 - val_MinusLogProbMetric: 16.7616 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-12 11:45:14.218 
Epoch 119/1000 
	 loss: 16.5419, MinusLogProbMetric: 16.5419, val_loss: 16.8505, val_MinusLogProbMetric: 16.8505

Epoch 119: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5419 - MinusLogProbMetric: 16.5419 - val_loss: 16.8505 - val_MinusLogProbMetric: 16.8505 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 120/1000
2023-09-12 11:45:26.082 
Epoch 120/1000 
	 loss: 16.5537, MinusLogProbMetric: 16.5537, val_loss: 16.8507, val_MinusLogProbMetric: 16.8507

Epoch 120: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5537 - MinusLogProbMetric: 16.5537 - val_loss: 16.8507 - val_MinusLogProbMetric: 16.8507 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 121/1000
2023-09-12 11:45:38.060 
Epoch 121/1000 
	 loss: 16.5439, MinusLogProbMetric: 16.5439, val_loss: 16.7643, val_MinusLogProbMetric: 16.7643

Epoch 121: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5439 - MinusLogProbMetric: 16.5439 - val_loss: 16.7643 - val_MinusLogProbMetric: 16.7643 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 122/1000
2023-09-12 11:45:49.863 
Epoch 122/1000 
	 loss: 16.5358, MinusLogProbMetric: 16.5358, val_loss: 16.8062, val_MinusLogProbMetric: 16.8062

Epoch 122: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5358 - MinusLogProbMetric: 16.5358 - val_loss: 16.8062 - val_MinusLogProbMetric: 16.8062 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 123/1000
2023-09-12 11:46:01.932 
Epoch 123/1000 
	 loss: 16.5462, MinusLogProbMetric: 16.5462, val_loss: 16.8164, val_MinusLogProbMetric: 16.8164

Epoch 123: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5462 - MinusLogProbMetric: 16.5462 - val_loss: 16.8164 - val_MinusLogProbMetric: 16.8164 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 124/1000
2023-09-12 11:46:13.835 
Epoch 124/1000 
	 loss: 16.5399, MinusLogProbMetric: 16.5399, val_loss: 16.7377, val_MinusLogProbMetric: 16.7377

Epoch 124: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5399 - MinusLogProbMetric: 16.5399 - val_loss: 16.7377 - val_MinusLogProbMetric: 16.7377 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 125/1000
2023-09-12 11:46:25.775 
Epoch 125/1000 
	 loss: 16.5435, MinusLogProbMetric: 16.5435, val_loss: 16.8141, val_MinusLogProbMetric: 16.8141

Epoch 125: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5435 - MinusLogProbMetric: 16.5435 - val_loss: 16.8141 - val_MinusLogProbMetric: 16.8141 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 126/1000
2023-09-12 11:46:37.647 
Epoch 126/1000 
	 loss: 16.5644, MinusLogProbMetric: 16.5644, val_loss: 16.8346, val_MinusLogProbMetric: 16.8346

Epoch 126: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5644 - MinusLogProbMetric: 16.5644 - val_loss: 16.8346 - val_MinusLogProbMetric: 16.8346 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 127/1000
2023-09-12 11:46:49.402 
Epoch 127/1000 
	 loss: 16.5350, MinusLogProbMetric: 16.5350, val_loss: 16.7927, val_MinusLogProbMetric: 16.7927

Epoch 127: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5350 - MinusLogProbMetric: 16.5350 - val_loss: 16.7927 - val_MinusLogProbMetric: 16.7927 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 128/1000
2023-09-12 11:47:01.068 
Epoch 128/1000 
	 loss: 16.5310, MinusLogProbMetric: 16.5310, val_loss: 16.7547, val_MinusLogProbMetric: 16.7547

Epoch 128: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5310 - MinusLogProbMetric: 16.5310 - val_loss: 16.7547 - val_MinusLogProbMetric: 16.7547 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 129/1000
2023-09-12 11:47:12.852 
Epoch 129/1000 
	 loss: 16.5337, MinusLogProbMetric: 16.5337, val_loss: 16.8002, val_MinusLogProbMetric: 16.8002

Epoch 129: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5337 - MinusLogProbMetric: 16.5337 - val_loss: 16.8002 - val_MinusLogProbMetric: 16.8002 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 130/1000
2023-09-12 11:47:24.767 
Epoch 130/1000 
	 loss: 16.5275, MinusLogProbMetric: 16.5275, val_loss: 16.7777, val_MinusLogProbMetric: 16.7777

Epoch 130: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5275 - MinusLogProbMetric: 16.5275 - val_loss: 16.7777 - val_MinusLogProbMetric: 16.7777 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 131/1000
2023-09-12 11:47:36.602 
Epoch 131/1000 
	 loss: 16.5315, MinusLogProbMetric: 16.5315, val_loss: 16.8806, val_MinusLogProbMetric: 16.8806

Epoch 131: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5315 - MinusLogProbMetric: 16.5315 - val_loss: 16.8806 - val_MinusLogProbMetric: 16.8806 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 132/1000
2023-09-12 11:47:48.353 
Epoch 132/1000 
	 loss: 16.5384, MinusLogProbMetric: 16.5384, val_loss: 16.8235, val_MinusLogProbMetric: 16.8235

Epoch 132: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5384 - MinusLogProbMetric: 16.5384 - val_loss: 16.8235 - val_MinusLogProbMetric: 16.8235 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 133/1000
2023-09-12 11:48:00.235 
Epoch 133/1000 
	 loss: 16.5408, MinusLogProbMetric: 16.5408, val_loss: 16.8372, val_MinusLogProbMetric: 16.8372

Epoch 133: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5408 - MinusLogProbMetric: 16.5408 - val_loss: 16.8372 - val_MinusLogProbMetric: 16.8372 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 134/1000
2023-09-12 11:48:12.058 
Epoch 134/1000 
	 loss: 16.5313, MinusLogProbMetric: 16.5313, val_loss: 16.7973, val_MinusLogProbMetric: 16.7973

Epoch 134: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5313 - MinusLogProbMetric: 16.5313 - val_loss: 16.7973 - val_MinusLogProbMetric: 16.7973 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-12 11:48:23.812 
Epoch 135/1000 
	 loss: 16.5389, MinusLogProbMetric: 16.5389, val_loss: 16.7667, val_MinusLogProbMetric: 16.7667

Epoch 135: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5389 - MinusLogProbMetric: 16.5389 - val_loss: 16.7667 - val_MinusLogProbMetric: 16.7667 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 136/1000
2023-09-12 11:48:35.427 
Epoch 136/1000 
	 loss: 16.5361, MinusLogProbMetric: 16.5361, val_loss: 16.8175, val_MinusLogProbMetric: 16.8175

Epoch 136: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5361 - MinusLogProbMetric: 16.5361 - val_loss: 16.8175 - val_MinusLogProbMetric: 16.8175 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 137/1000
2023-09-12 11:48:47.161 
Epoch 137/1000 
	 loss: 16.5341, MinusLogProbMetric: 16.5341, val_loss: 16.8267, val_MinusLogProbMetric: 16.8267

Epoch 137: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5341 - MinusLogProbMetric: 16.5341 - val_loss: 16.8267 - val_MinusLogProbMetric: 16.8267 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 138/1000
2023-09-12 11:48:58.977 
Epoch 138/1000 
	 loss: 16.5180, MinusLogProbMetric: 16.5180, val_loss: 16.8423, val_MinusLogProbMetric: 16.8423

Epoch 138: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5180 - MinusLogProbMetric: 16.5180 - val_loss: 16.8423 - val_MinusLogProbMetric: 16.8423 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 139/1000
2023-09-12 11:49:10.789 
Epoch 139/1000 
	 loss: 16.5233, MinusLogProbMetric: 16.5233, val_loss: 16.8018, val_MinusLogProbMetric: 16.8018

Epoch 139: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5233 - MinusLogProbMetric: 16.5233 - val_loss: 16.8018 - val_MinusLogProbMetric: 16.8018 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-12 11:49:22.492 
Epoch 140/1000 
	 loss: 16.5425, MinusLogProbMetric: 16.5425, val_loss: 16.9315, val_MinusLogProbMetric: 16.9315

Epoch 140: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5425 - MinusLogProbMetric: 16.5425 - val_loss: 16.9315 - val_MinusLogProbMetric: 16.9315 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 141/1000
2023-09-12 11:49:34.193 
Epoch 141/1000 
	 loss: 16.5266, MinusLogProbMetric: 16.5266, val_loss: 16.7872, val_MinusLogProbMetric: 16.7872

Epoch 141: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5266 - MinusLogProbMetric: 16.5266 - val_loss: 16.7872 - val_MinusLogProbMetric: 16.7872 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 142/1000
2023-09-12 11:49:45.913 
Epoch 142/1000 
	 loss: 16.5179, MinusLogProbMetric: 16.5179, val_loss: 16.7547, val_MinusLogProbMetric: 16.7547

Epoch 142: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5179 - MinusLogProbMetric: 16.5179 - val_loss: 16.7547 - val_MinusLogProbMetric: 16.7547 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 143/1000
2023-09-12 11:49:57.619 
Epoch 143/1000 
	 loss: 16.5381, MinusLogProbMetric: 16.5381, val_loss: 16.7824, val_MinusLogProbMetric: 16.7824

Epoch 143: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5381 - MinusLogProbMetric: 16.5381 - val_loss: 16.7824 - val_MinusLogProbMetric: 16.7824 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 144/1000
2023-09-12 11:50:09.240 
Epoch 144/1000 
	 loss: 16.5173, MinusLogProbMetric: 16.5173, val_loss: 16.8464, val_MinusLogProbMetric: 16.8464

Epoch 144: val_loss did not improve from 16.73582
196/196 - 12s - loss: 16.5173 - MinusLogProbMetric: 16.5173 - val_loss: 16.8464 - val_MinusLogProbMetric: 16.8464 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 145/1000
2023-09-12 11:50:20.804 
Epoch 145/1000 
	 loss: 16.4479, MinusLogProbMetric: 16.4479, val_loss: 16.7324, val_MinusLogProbMetric: 16.7324

Epoch 145: val_loss improved from 16.73582 to 16.73236, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_122/weights/best_weights.h5
196/196 - 12s - loss: 16.4479 - MinusLogProbMetric: 16.4479 - val_loss: 16.7324 - val_MinusLogProbMetric: 16.7324 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 146/1000
2023-09-12 11:50:32.581 
Epoch 146/1000 
	 loss: 16.4427, MinusLogProbMetric: 16.4427, val_loss: 16.7570, val_MinusLogProbMetric: 16.7570

Epoch 146: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4427 - MinusLogProbMetric: 16.4427 - val_loss: 16.7570 - val_MinusLogProbMetric: 16.7570 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 147/1000
2023-09-12 11:50:44.278 
Epoch 147/1000 
	 loss: 16.4474, MinusLogProbMetric: 16.4474, val_loss: 16.7494, val_MinusLogProbMetric: 16.7494

Epoch 147: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4474 - MinusLogProbMetric: 16.4474 - val_loss: 16.7494 - val_MinusLogProbMetric: 16.7494 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 148/1000
2023-09-12 11:50:55.977 
Epoch 148/1000 
	 loss: 16.4416, MinusLogProbMetric: 16.4416, val_loss: 16.7618, val_MinusLogProbMetric: 16.7618

Epoch 148: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4416 - MinusLogProbMetric: 16.4416 - val_loss: 16.7618 - val_MinusLogProbMetric: 16.7618 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-12 11:51:07.671 
Epoch 149/1000 
	 loss: 16.4417, MinusLogProbMetric: 16.4417, val_loss: 16.7391, val_MinusLogProbMetric: 16.7391

Epoch 149: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4417 - MinusLogProbMetric: 16.4417 - val_loss: 16.7391 - val_MinusLogProbMetric: 16.7391 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 150/1000
2023-09-12 11:51:19.407 
Epoch 150/1000 
	 loss: 16.4363, MinusLogProbMetric: 16.4363, val_loss: 16.7424, val_MinusLogProbMetric: 16.7424

Epoch 150: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4363 - MinusLogProbMetric: 16.4363 - val_loss: 16.7424 - val_MinusLogProbMetric: 16.7424 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-12 11:51:31.134 
Epoch 151/1000 
	 loss: 16.4393, MinusLogProbMetric: 16.4393, val_loss: 16.7358, val_MinusLogProbMetric: 16.7358

Epoch 151: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4393 - MinusLogProbMetric: 16.4393 - val_loss: 16.7358 - val_MinusLogProbMetric: 16.7358 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 152/1000
2023-09-12 11:51:42.849 
Epoch 152/1000 
	 loss: 16.4374, MinusLogProbMetric: 16.4374, val_loss: 16.7454, val_MinusLogProbMetric: 16.7454

Epoch 152: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4374 - MinusLogProbMetric: 16.4374 - val_loss: 16.7454 - val_MinusLogProbMetric: 16.7454 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 153/1000
2023-09-12 11:51:54.501 
Epoch 153/1000 
	 loss: 16.4372, MinusLogProbMetric: 16.4372, val_loss: 16.7751, val_MinusLogProbMetric: 16.7751

Epoch 153: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4372 - MinusLogProbMetric: 16.4372 - val_loss: 16.7751 - val_MinusLogProbMetric: 16.7751 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-12 11:52:06.135 
Epoch 154/1000 
	 loss: 16.4422, MinusLogProbMetric: 16.4422, val_loss: 16.7455, val_MinusLogProbMetric: 16.7455

Epoch 154: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4422 - MinusLogProbMetric: 16.4422 - val_loss: 16.7455 - val_MinusLogProbMetric: 16.7455 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 155/1000
2023-09-12 11:52:17.743 
Epoch 155/1000 
	 loss: 16.4342, MinusLogProbMetric: 16.4342, val_loss: 16.7602, val_MinusLogProbMetric: 16.7602

Epoch 155: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4342 - MinusLogProbMetric: 16.4342 - val_loss: 16.7602 - val_MinusLogProbMetric: 16.7602 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 156/1000
2023-09-12 11:52:29.437 
Epoch 156/1000 
	 loss: 16.4399, MinusLogProbMetric: 16.4399, val_loss: 16.7781, val_MinusLogProbMetric: 16.7781

Epoch 156: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4399 - MinusLogProbMetric: 16.4399 - val_loss: 16.7781 - val_MinusLogProbMetric: 16.7781 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 157/1000
2023-09-12 11:52:41.087 
Epoch 157/1000 
	 loss: 16.4412, MinusLogProbMetric: 16.4412, val_loss: 16.7524, val_MinusLogProbMetric: 16.7524

Epoch 157: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4412 - MinusLogProbMetric: 16.4412 - val_loss: 16.7524 - val_MinusLogProbMetric: 16.7524 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 158/1000
2023-09-12 11:52:52.771 
Epoch 158/1000 
	 loss: 16.4355, MinusLogProbMetric: 16.4355, val_loss: 16.7706, val_MinusLogProbMetric: 16.7706

Epoch 158: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4355 - MinusLogProbMetric: 16.4355 - val_loss: 16.7706 - val_MinusLogProbMetric: 16.7706 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 159/1000
2023-09-12 11:53:04.455 
Epoch 159/1000 
	 loss: 16.4279, MinusLogProbMetric: 16.4279, val_loss: 16.7744, val_MinusLogProbMetric: 16.7744

Epoch 159: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4279 - MinusLogProbMetric: 16.4279 - val_loss: 16.7744 - val_MinusLogProbMetric: 16.7744 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-12 11:53:16.112 
Epoch 160/1000 
	 loss: 16.4335, MinusLogProbMetric: 16.4335, val_loss: 16.7716, val_MinusLogProbMetric: 16.7716

Epoch 160: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4335 - MinusLogProbMetric: 16.4335 - val_loss: 16.7716 - val_MinusLogProbMetric: 16.7716 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 161/1000
2023-09-12 11:53:27.841 
Epoch 161/1000 
	 loss: 16.4305, MinusLogProbMetric: 16.4305, val_loss: 16.7496, val_MinusLogProbMetric: 16.7496

Epoch 161: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4305 - MinusLogProbMetric: 16.4305 - val_loss: 16.7496 - val_MinusLogProbMetric: 16.7496 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 162/1000
2023-09-12 11:53:39.376 
Epoch 162/1000 
	 loss: 16.4318, MinusLogProbMetric: 16.4318, val_loss: 16.7580, val_MinusLogProbMetric: 16.7580

Epoch 162: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4318 - MinusLogProbMetric: 16.4318 - val_loss: 16.7580 - val_MinusLogProbMetric: 16.7580 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 163/1000
2023-09-12 11:53:51.015 
Epoch 163/1000 
	 loss: 16.4284, MinusLogProbMetric: 16.4284, val_loss: 16.7886, val_MinusLogProbMetric: 16.7886

Epoch 163: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4284 - MinusLogProbMetric: 16.4284 - val_loss: 16.7886 - val_MinusLogProbMetric: 16.7886 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 164/1000
2023-09-12 11:54:02.524 
Epoch 164/1000 
	 loss: 16.4321, MinusLogProbMetric: 16.4321, val_loss: 16.7729, val_MinusLogProbMetric: 16.7729

Epoch 164: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4321 - MinusLogProbMetric: 16.4321 - val_loss: 16.7729 - val_MinusLogProbMetric: 16.7729 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-12 11:54:13.871 
Epoch 165/1000 
	 loss: 16.4330, MinusLogProbMetric: 16.4330, val_loss: 16.8079, val_MinusLogProbMetric: 16.8079

Epoch 165: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4330 - MinusLogProbMetric: 16.4330 - val_loss: 16.8079 - val_MinusLogProbMetric: 16.8079 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 166/1000
2023-09-12 11:54:25.449 
Epoch 166/1000 
	 loss: 16.4287, MinusLogProbMetric: 16.4287, val_loss: 16.7575, val_MinusLogProbMetric: 16.7575

Epoch 166: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4287 - MinusLogProbMetric: 16.4287 - val_loss: 16.7575 - val_MinusLogProbMetric: 16.7575 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-12 11:54:36.651 
Epoch 167/1000 
	 loss: 16.4308, MinusLogProbMetric: 16.4308, val_loss: 16.7792, val_MinusLogProbMetric: 16.7792

Epoch 167: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4308 - MinusLogProbMetric: 16.4308 - val_loss: 16.7792 - val_MinusLogProbMetric: 16.7792 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 168/1000
2023-09-12 11:54:48.045 
Epoch 168/1000 
	 loss: 16.4220, MinusLogProbMetric: 16.4220, val_loss: 16.7780, val_MinusLogProbMetric: 16.7780

Epoch 168: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4220 - MinusLogProbMetric: 16.4220 - val_loss: 16.7780 - val_MinusLogProbMetric: 16.7780 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 169/1000
2023-09-12 11:54:59.601 
Epoch 169/1000 
	 loss: 16.4295, MinusLogProbMetric: 16.4295, val_loss: 16.7882, val_MinusLogProbMetric: 16.7882

Epoch 169: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4295 - MinusLogProbMetric: 16.4295 - val_loss: 16.7882 - val_MinusLogProbMetric: 16.7882 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 170/1000
2023-09-12 11:55:11.148 
Epoch 170/1000 
	 loss: 16.4245, MinusLogProbMetric: 16.4245, val_loss: 16.8032, val_MinusLogProbMetric: 16.8032

Epoch 170: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4245 - MinusLogProbMetric: 16.4245 - val_loss: 16.8032 - val_MinusLogProbMetric: 16.8032 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 171/1000
2023-09-12 11:55:22.700 
Epoch 171/1000 
	 loss: 16.4208, MinusLogProbMetric: 16.4208, val_loss: 16.7757, val_MinusLogProbMetric: 16.7757

Epoch 171: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4208 - MinusLogProbMetric: 16.4208 - val_loss: 16.7757 - val_MinusLogProbMetric: 16.7757 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 172/1000
2023-09-12 11:55:34.221 
Epoch 172/1000 
	 loss: 16.4319, MinusLogProbMetric: 16.4319, val_loss: 16.7648, val_MinusLogProbMetric: 16.7648

Epoch 172: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4319 - MinusLogProbMetric: 16.4319 - val_loss: 16.7648 - val_MinusLogProbMetric: 16.7648 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 11:55:45.389 
Epoch 173/1000 
	 loss: 16.4215, MinusLogProbMetric: 16.4215, val_loss: 16.7684, val_MinusLogProbMetric: 16.7684

Epoch 173: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4215 - MinusLogProbMetric: 16.4215 - val_loss: 16.7684 - val_MinusLogProbMetric: 16.7684 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 174/1000
2023-09-12 11:55:56.723 
Epoch 174/1000 
	 loss: 16.4158, MinusLogProbMetric: 16.4158, val_loss: 16.7725, val_MinusLogProbMetric: 16.7725

Epoch 174: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4158 - MinusLogProbMetric: 16.4158 - val_loss: 16.7725 - val_MinusLogProbMetric: 16.7725 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 175/1000
2023-09-12 11:56:08.125 
Epoch 175/1000 
	 loss: 16.4173, MinusLogProbMetric: 16.4173, val_loss: 16.7741, val_MinusLogProbMetric: 16.7741

Epoch 175: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4173 - MinusLogProbMetric: 16.4173 - val_loss: 16.7741 - val_MinusLogProbMetric: 16.7741 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 176/1000
2023-09-12 11:56:19.753 
Epoch 176/1000 
	 loss: 16.4201, MinusLogProbMetric: 16.4201, val_loss: 16.7943, val_MinusLogProbMetric: 16.7943

Epoch 176: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4201 - MinusLogProbMetric: 16.4201 - val_loss: 16.7943 - val_MinusLogProbMetric: 16.7943 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 177/1000
2023-09-12 11:56:31.288 
Epoch 177/1000 
	 loss: 16.4170, MinusLogProbMetric: 16.4170, val_loss: 16.7905, val_MinusLogProbMetric: 16.7905

Epoch 177: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4170 - MinusLogProbMetric: 16.4170 - val_loss: 16.7905 - val_MinusLogProbMetric: 16.7905 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 178/1000
2023-09-12 11:56:43.104 
Epoch 178/1000 
	 loss: 16.4236, MinusLogProbMetric: 16.4236, val_loss: 16.8111, val_MinusLogProbMetric: 16.8111

Epoch 178: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4236 - MinusLogProbMetric: 16.4236 - val_loss: 16.8111 - val_MinusLogProbMetric: 16.8111 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 179/1000
2023-09-12 11:56:54.764 
Epoch 179/1000 
	 loss: 16.4162, MinusLogProbMetric: 16.4162, val_loss: 16.7879, val_MinusLogProbMetric: 16.7879

Epoch 179: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4162 - MinusLogProbMetric: 16.4162 - val_loss: 16.7879 - val_MinusLogProbMetric: 16.7879 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 180/1000
2023-09-12 11:57:06.242 
Epoch 180/1000 
	 loss: 16.4186, MinusLogProbMetric: 16.4186, val_loss: 16.7818, val_MinusLogProbMetric: 16.7818

Epoch 180: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4186 - MinusLogProbMetric: 16.4186 - val_loss: 16.7818 - val_MinusLogProbMetric: 16.7818 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 181/1000
2023-09-12 11:57:17.642 
Epoch 181/1000 
	 loss: 16.4229, MinusLogProbMetric: 16.4229, val_loss: 16.7756, val_MinusLogProbMetric: 16.7756

Epoch 181: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4229 - MinusLogProbMetric: 16.4229 - val_loss: 16.7756 - val_MinusLogProbMetric: 16.7756 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 182/1000
2023-09-12 11:57:29.121 
Epoch 182/1000 
	 loss: 16.4123, MinusLogProbMetric: 16.4123, val_loss: 16.7807, val_MinusLogProbMetric: 16.7807

Epoch 182: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4123 - MinusLogProbMetric: 16.4123 - val_loss: 16.7807 - val_MinusLogProbMetric: 16.7807 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 183/1000
2023-09-12 11:57:40.146 
Epoch 183/1000 
	 loss: 16.4179, MinusLogProbMetric: 16.4179, val_loss: 16.7801, val_MinusLogProbMetric: 16.7801

Epoch 183: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4179 - MinusLogProbMetric: 16.4179 - val_loss: 16.7801 - val_MinusLogProbMetric: 16.7801 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 184/1000
2023-09-12 11:57:51.948 
Epoch 184/1000 
	 loss: 16.4173, MinusLogProbMetric: 16.4173, val_loss: 16.7862, val_MinusLogProbMetric: 16.7862

Epoch 184: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4173 - MinusLogProbMetric: 16.4173 - val_loss: 16.7862 - val_MinusLogProbMetric: 16.7862 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 185/1000
2023-09-12 11:58:03.691 
Epoch 185/1000 
	 loss: 16.4107, MinusLogProbMetric: 16.4107, val_loss: 16.8229, val_MinusLogProbMetric: 16.8229

Epoch 185: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4107 - MinusLogProbMetric: 16.4107 - val_loss: 16.8229 - val_MinusLogProbMetric: 16.8229 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 186/1000
2023-09-12 11:58:15.537 
Epoch 186/1000 
	 loss: 16.4095, MinusLogProbMetric: 16.4095, val_loss: 16.8003, val_MinusLogProbMetric: 16.8003

Epoch 186: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4095 - MinusLogProbMetric: 16.4095 - val_loss: 16.8003 - val_MinusLogProbMetric: 16.8003 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 187/1000
2023-09-12 11:58:27.212 
Epoch 187/1000 
	 loss: 16.4062, MinusLogProbMetric: 16.4062, val_loss: 16.7769, val_MinusLogProbMetric: 16.7769

Epoch 187: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4062 - MinusLogProbMetric: 16.4062 - val_loss: 16.7769 - val_MinusLogProbMetric: 16.7769 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 188/1000
2023-09-12 11:58:38.974 
Epoch 188/1000 
	 loss: 16.4104, MinusLogProbMetric: 16.4104, val_loss: 16.8006, val_MinusLogProbMetric: 16.8006

Epoch 188: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4104 - MinusLogProbMetric: 16.4104 - val_loss: 16.8006 - val_MinusLogProbMetric: 16.8006 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 189/1000
2023-09-12 11:58:50.137 
Epoch 189/1000 
	 loss: 16.4098, MinusLogProbMetric: 16.4098, val_loss: 16.8021, val_MinusLogProbMetric: 16.8021

Epoch 189: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4098 - MinusLogProbMetric: 16.4098 - val_loss: 16.8021 - val_MinusLogProbMetric: 16.8021 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 190/1000
2023-09-12 11:59:00.678 
Epoch 190/1000 
	 loss: 16.4079, MinusLogProbMetric: 16.4079, val_loss: 16.8169, val_MinusLogProbMetric: 16.8169

Epoch 190: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4079 - MinusLogProbMetric: 16.4079 - val_loss: 16.8169 - val_MinusLogProbMetric: 16.8169 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 191/1000
2023-09-12 11:59:11.966 
Epoch 191/1000 
	 loss: 16.4120, MinusLogProbMetric: 16.4120, val_loss: 16.7824, val_MinusLogProbMetric: 16.7824

Epoch 191: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.4120 - MinusLogProbMetric: 16.4120 - val_loss: 16.7824 - val_MinusLogProbMetric: 16.7824 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 192/1000
2023-09-12 11:59:23.547 
Epoch 192/1000 
	 loss: 16.4096, MinusLogProbMetric: 16.4096, val_loss: 16.7697, val_MinusLogProbMetric: 16.7697

Epoch 192: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4096 - MinusLogProbMetric: 16.4096 - val_loss: 16.7697 - val_MinusLogProbMetric: 16.7697 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 193/1000
2023-09-12 11:59:35.216 
Epoch 193/1000 
	 loss: 16.4043, MinusLogProbMetric: 16.4043, val_loss: 16.7946, val_MinusLogProbMetric: 16.7946

Epoch 193: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4043 - MinusLogProbMetric: 16.4043 - val_loss: 16.7946 - val_MinusLogProbMetric: 16.7946 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 194/1000
2023-09-12 11:59:47.093 
Epoch 194/1000 
	 loss: 16.4036, MinusLogProbMetric: 16.4036, val_loss: 16.8066, val_MinusLogProbMetric: 16.8066

Epoch 194: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4036 - MinusLogProbMetric: 16.4036 - val_loss: 16.8066 - val_MinusLogProbMetric: 16.8066 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 195/1000
2023-09-12 11:59:58.806 
Epoch 195/1000 
	 loss: 16.4089, MinusLogProbMetric: 16.4089, val_loss: 16.8422, val_MinusLogProbMetric: 16.8422

Epoch 195: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.4089 - MinusLogProbMetric: 16.4089 - val_loss: 16.8422 - val_MinusLogProbMetric: 16.8422 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 196/1000
2023-09-12 12:00:10.445 
Epoch 196/1000 
	 loss: 16.3726, MinusLogProbMetric: 16.3726, val_loss: 16.7673, val_MinusLogProbMetric: 16.7673

Epoch 196: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3726 - MinusLogProbMetric: 16.3726 - val_loss: 16.7673 - val_MinusLogProbMetric: 16.7673 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 197/1000
2023-09-12 12:00:22.053 
Epoch 197/1000 
	 loss: 16.3672, MinusLogProbMetric: 16.3672, val_loss: 16.7641, val_MinusLogProbMetric: 16.7641

Epoch 197: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3672 - MinusLogProbMetric: 16.3672 - val_loss: 16.7641 - val_MinusLogProbMetric: 16.7641 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 198/1000
2023-09-12 12:00:33.750 
Epoch 198/1000 
	 loss: 16.3667, MinusLogProbMetric: 16.3667, val_loss: 16.7718, val_MinusLogProbMetric: 16.7718

Epoch 198: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3667 - MinusLogProbMetric: 16.3667 - val_loss: 16.7718 - val_MinusLogProbMetric: 16.7718 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 199/1000
2023-09-12 12:00:45.332 
Epoch 199/1000 
	 loss: 16.3657, MinusLogProbMetric: 16.3657, val_loss: 16.7775, val_MinusLogProbMetric: 16.7775

Epoch 199: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3657 - MinusLogProbMetric: 16.3657 - val_loss: 16.7775 - val_MinusLogProbMetric: 16.7775 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 200/1000
2023-09-12 12:00:56.661 
Epoch 200/1000 
	 loss: 16.3669, MinusLogProbMetric: 16.3669, val_loss: 16.7782, val_MinusLogProbMetric: 16.7782

Epoch 200: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.3669 - MinusLogProbMetric: 16.3669 - val_loss: 16.7782 - val_MinusLogProbMetric: 16.7782 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 201/1000
2023-09-12 12:01:08.328 
Epoch 201/1000 
	 loss: 16.3643, MinusLogProbMetric: 16.3643, val_loss: 16.7871, val_MinusLogProbMetric: 16.7871

Epoch 201: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3643 - MinusLogProbMetric: 16.3643 - val_loss: 16.7871 - val_MinusLogProbMetric: 16.7871 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 202/1000
2023-09-12 12:01:20.072 
Epoch 202/1000 
	 loss: 16.3691, MinusLogProbMetric: 16.3691, val_loss: 16.7729, val_MinusLogProbMetric: 16.7729

Epoch 202: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3691 - MinusLogProbMetric: 16.3691 - val_loss: 16.7729 - val_MinusLogProbMetric: 16.7729 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 203/1000
2023-09-12 12:01:30.634 
Epoch 203/1000 
	 loss: 16.3645, MinusLogProbMetric: 16.3645, val_loss: 16.7702, val_MinusLogProbMetric: 16.7702

Epoch 203: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.3645 - MinusLogProbMetric: 16.3645 - val_loss: 16.7702 - val_MinusLogProbMetric: 16.7702 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 204/1000
2023-09-12 12:01:42.207 
Epoch 204/1000 
	 loss: 16.3640, MinusLogProbMetric: 16.3640, val_loss: 16.7827, val_MinusLogProbMetric: 16.7827

Epoch 204: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3640 - MinusLogProbMetric: 16.3640 - val_loss: 16.7827 - val_MinusLogProbMetric: 16.7827 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 205/1000
2023-09-12 12:01:53.884 
Epoch 205/1000 
	 loss: 16.3657, MinusLogProbMetric: 16.3657, val_loss: 16.7840, val_MinusLogProbMetric: 16.7840

Epoch 205: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3657 - MinusLogProbMetric: 16.3657 - val_loss: 16.7840 - val_MinusLogProbMetric: 16.7840 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 206/1000
2023-09-12 12:02:05.541 
Epoch 206/1000 
	 loss: 16.3634, MinusLogProbMetric: 16.3634, val_loss: 16.7749, val_MinusLogProbMetric: 16.7749

Epoch 206: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3634 - MinusLogProbMetric: 16.3634 - val_loss: 16.7749 - val_MinusLogProbMetric: 16.7749 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-12 12:02:16.433 
Epoch 207/1000 
	 loss: 16.3629, MinusLogProbMetric: 16.3629, val_loss: 16.7787, val_MinusLogProbMetric: 16.7787

Epoch 207: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.3629 - MinusLogProbMetric: 16.3629 - val_loss: 16.7787 - val_MinusLogProbMetric: 16.7787 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 208/1000
2023-09-12 12:02:27.451 
Epoch 208/1000 
	 loss: 16.3627, MinusLogProbMetric: 16.3627, val_loss: 16.7853, val_MinusLogProbMetric: 16.7853

Epoch 208: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.3627 - MinusLogProbMetric: 16.3627 - val_loss: 16.7853 - val_MinusLogProbMetric: 16.7853 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 209/1000
2023-09-12 12:02:37.484 
Epoch 209/1000 
	 loss: 16.3626, MinusLogProbMetric: 16.3626, val_loss: 16.7916, val_MinusLogProbMetric: 16.7916

Epoch 209: val_loss did not improve from 16.73236
196/196 - 10s - loss: 16.3626 - MinusLogProbMetric: 16.3626 - val_loss: 16.7916 - val_MinusLogProbMetric: 16.7916 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 210/1000
2023-09-12 12:02:47.528 
Epoch 210/1000 
	 loss: 16.3601, MinusLogProbMetric: 16.3601, val_loss: 16.7907, val_MinusLogProbMetric: 16.7907

Epoch 210: val_loss did not improve from 16.73236
196/196 - 10s - loss: 16.3601 - MinusLogProbMetric: 16.3601 - val_loss: 16.7907 - val_MinusLogProbMetric: 16.7907 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 211/1000
2023-09-12 12:02:58.130 
Epoch 211/1000 
	 loss: 16.3613, MinusLogProbMetric: 16.3613, val_loss: 16.7901, val_MinusLogProbMetric: 16.7901

Epoch 211: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.3613 - MinusLogProbMetric: 16.3613 - val_loss: 16.7901 - val_MinusLogProbMetric: 16.7901 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 212/1000
2023-09-12 12:03:08.674 
Epoch 212/1000 
	 loss: 16.3617, MinusLogProbMetric: 16.3617, val_loss: 16.7845, val_MinusLogProbMetric: 16.7845

Epoch 212: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.3617 - MinusLogProbMetric: 16.3617 - val_loss: 16.7845 - val_MinusLogProbMetric: 16.7845 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 213/1000
2023-09-12 12:03:19.893 
Epoch 213/1000 
	 loss: 16.3617, MinusLogProbMetric: 16.3617, val_loss: 16.7798, val_MinusLogProbMetric: 16.7798

Epoch 213: val_loss did not improve from 16.73236
196/196 - 11s - loss: 16.3617 - MinusLogProbMetric: 16.3617 - val_loss: 16.7798 - val_MinusLogProbMetric: 16.7798 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 214/1000
2023-09-12 12:03:31.549 
Epoch 214/1000 
	 loss: 16.3592, MinusLogProbMetric: 16.3592, val_loss: 16.7828, val_MinusLogProbMetric: 16.7828

Epoch 214: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3592 - MinusLogProbMetric: 16.3592 - val_loss: 16.7828 - val_MinusLogProbMetric: 16.7828 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 215/1000
2023-09-12 12:03:43.197 
Epoch 215/1000 
	 loss: 16.3590, MinusLogProbMetric: 16.3590, val_loss: 16.7800, val_MinusLogProbMetric: 16.7800

Epoch 215: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3590 - MinusLogProbMetric: 16.3590 - val_loss: 16.7800 - val_MinusLogProbMetric: 16.7800 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 216/1000
2023-09-12 12:03:54.827 
Epoch 216/1000 
	 loss: 16.3611, MinusLogProbMetric: 16.3611, val_loss: 16.7786, val_MinusLogProbMetric: 16.7786

Epoch 216: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3611 - MinusLogProbMetric: 16.3611 - val_loss: 16.7786 - val_MinusLogProbMetric: 16.7786 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 217/1000
2023-09-12 12:04:06.442 
Epoch 217/1000 
	 loss: 16.3592, MinusLogProbMetric: 16.3592, val_loss: 16.7883, val_MinusLogProbMetric: 16.7883

Epoch 217: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3592 - MinusLogProbMetric: 16.3592 - val_loss: 16.7883 - val_MinusLogProbMetric: 16.7883 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 218/1000
2023-09-12 12:04:18.000 
Epoch 218/1000 
	 loss: 16.3569, MinusLogProbMetric: 16.3569, val_loss: 16.7915, val_MinusLogProbMetric: 16.7915

Epoch 218: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3569 - MinusLogProbMetric: 16.3569 - val_loss: 16.7915 - val_MinusLogProbMetric: 16.7915 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 219/1000
2023-09-12 12:04:29.704 
Epoch 219/1000 
	 loss: 16.3567, MinusLogProbMetric: 16.3567, val_loss: 16.7829, val_MinusLogProbMetric: 16.7829

Epoch 219: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3567 - MinusLogProbMetric: 16.3567 - val_loss: 16.7829 - val_MinusLogProbMetric: 16.7829 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 220/1000
2023-09-12 12:04:41.386 
Epoch 220/1000 
	 loss: 16.3586, MinusLogProbMetric: 16.3586, val_loss: 16.7959, val_MinusLogProbMetric: 16.7959

Epoch 220: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3586 - MinusLogProbMetric: 16.3586 - val_loss: 16.7959 - val_MinusLogProbMetric: 16.7959 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 221/1000
2023-09-12 12:04:53.233 
Epoch 221/1000 
	 loss: 16.3545, MinusLogProbMetric: 16.3545, val_loss: 16.7974, val_MinusLogProbMetric: 16.7974

Epoch 221: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3545 - MinusLogProbMetric: 16.3545 - val_loss: 16.7974 - val_MinusLogProbMetric: 16.7974 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-12 12:05:04.887 
Epoch 222/1000 
	 loss: 16.3552, MinusLogProbMetric: 16.3552, val_loss: 16.8017, val_MinusLogProbMetric: 16.8017

Epoch 222: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3552 - MinusLogProbMetric: 16.3552 - val_loss: 16.8017 - val_MinusLogProbMetric: 16.8017 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 223/1000
2023-09-12 12:05:16.630 
Epoch 223/1000 
	 loss: 16.3565, MinusLogProbMetric: 16.3565, val_loss: 16.7961, val_MinusLogProbMetric: 16.7961

Epoch 223: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3565 - MinusLogProbMetric: 16.3565 - val_loss: 16.7961 - val_MinusLogProbMetric: 16.7961 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 224/1000
2023-09-12 12:05:28.229 
Epoch 224/1000 
	 loss: 16.3560, MinusLogProbMetric: 16.3560, val_loss: 16.8002, val_MinusLogProbMetric: 16.8002

Epoch 224: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3560 - MinusLogProbMetric: 16.3560 - val_loss: 16.8002 - val_MinusLogProbMetric: 16.8002 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 225/1000
2023-09-12 12:05:39.971 
Epoch 225/1000 
	 loss: 16.3579, MinusLogProbMetric: 16.3579, val_loss: 16.8018, val_MinusLogProbMetric: 16.8018

Epoch 225: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3579 - MinusLogProbMetric: 16.3579 - val_loss: 16.8018 - val_MinusLogProbMetric: 16.8018 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 226/1000
2023-09-12 12:05:51.684 
Epoch 226/1000 
	 loss: 16.3534, MinusLogProbMetric: 16.3534, val_loss: 16.8020, val_MinusLogProbMetric: 16.8020

Epoch 226: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3534 - MinusLogProbMetric: 16.3534 - val_loss: 16.8020 - val_MinusLogProbMetric: 16.8020 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 227/1000
2023-09-12 12:06:03.282 
Epoch 227/1000 
	 loss: 16.3565, MinusLogProbMetric: 16.3565, val_loss: 16.8049, val_MinusLogProbMetric: 16.8049

Epoch 227: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3565 - MinusLogProbMetric: 16.3565 - val_loss: 16.8049 - val_MinusLogProbMetric: 16.8049 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-12 12:06:14.976 
Epoch 228/1000 
	 loss: 16.3552, MinusLogProbMetric: 16.3552, val_loss: 16.7983, val_MinusLogProbMetric: 16.7983

Epoch 228: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3552 - MinusLogProbMetric: 16.3552 - val_loss: 16.7983 - val_MinusLogProbMetric: 16.7983 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 229/1000
2023-09-12 12:06:26.605 
Epoch 229/1000 
	 loss: 16.3523, MinusLogProbMetric: 16.3523, val_loss: 16.8075, val_MinusLogProbMetric: 16.8075

Epoch 229: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3523 - MinusLogProbMetric: 16.3523 - val_loss: 16.8075 - val_MinusLogProbMetric: 16.8075 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 230/1000
2023-09-12 12:06:38.232 
Epoch 230/1000 
	 loss: 16.3535, MinusLogProbMetric: 16.3535, val_loss: 16.8077, val_MinusLogProbMetric: 16.8077

Epoch 230: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3535 - MinusLogProbMetric: 16.3535 - val_loss: 16.8077 - val_MinusLogProbMetric: 16.8077 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 231/1000
2023-09-12 12:06:49.889 
Epoch 231/1000 
	 loss: 16.3517, MinusLogProbMetric: 16.3517, val_loss: 16.8020, val_MinusLogProbMetric: 16.8020

Epoch 231: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3517 - MinusLogProbMetric: 16.3517 - val_loss: 16.8020 - val_MinusLogProbMetric: 16.8020 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 232/1000
2023-09-12 12:07:01.559 
Epoch 232/1000 
	 loss: 16.3567, MinusLogProbMetric: 16.3567, val_loss: 16.8168, val_MinusLogProbMetric: 16.8168

Epoch 232: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3567 - MinusLogProbMetric: 16.3567 - val_loss: 16.8168 - val_MinusLogProbMetric: 16.8168 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 233/1000
2023-09-12 12:07:13.157 
Epoch 233/1000 
	 loss: 16.3529, MinusLogProbMetric: 16.3529, val_loss: 16.7984, val_MinusLogProbMetric: 16.7984

Epoch 233: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3529 - MinusLogProbMetric: 16.3529 - val_loss: 16.7984 - val_MinusLogProbMetric: 16.7984 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 234/1000
2023-09-12 12:07:24.847 
Epoch 234/1000 
	 loss: 16.3493, MinusLogProbMetric: 16.3493, val_loss: 16.8105, val_MinusLogProbMetric: 16.8105

Epoch 234: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3493 - MinusLogProbMetric: 16.3493 - val_loss: 16.8105 - val_MinusLogProbMetric: 16.8105 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-12 12:07:36.567 
Epoch 235/1000 
	 loss: 16.3519, MinusLogProbMetric: 16.3519, val_loss: 16.7975, val_MinusLogProbMetric: 16.7975

Epoch 235: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3519 - MinusLogProbMetric: 16.3519 - val_loss: 16.7975 - val_MinusLogProbMetric: 16.7975 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 236/1000
2023-09-12 12:07:48.140 
Epoch 236/1000 
	 loss: 16.3505, MinusLogProbMetric: 16.3505, val_loss: 16.8249, val_MinusLogProbMetric: 16.8249

Epoch 236: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3505 - MinusLogProbMetric: 16.3505 - val_loss: 16.8249 - val_MinusLogProbMetric: 16.8249 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 237/1000
2023-09-12 12:07:59.800 
Epoch 237/1000 
	 loss: 16.3500, MinusLogProbMetric: 16.3500, val_loss: 16.8008, val_MinusLogProbMetric: 16.8008

Epoch 237: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3500 - MinusLogProbMetric: 16.3500 - val_loss: 16.8008 - val_MinusLogProbMetric: 16.8008 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 238/1000
2023-09-12 12:08:11.557 
Epoch 238/1000 
	 loss: 16.3490, MinusLogProbMetric: 16.3490, val_loss: 16.8182, val_MinusLogProbMetric: 16.8182

Epoch 238: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3490 - MinusLogProbMetric: 16.3490 - val_loss: 16.8182 - val_MinusLogProbMetric: 16.8182 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-12 12:08:23.148 
Epoch 239/1000 
	 loss: 16.3533, MinusLogProbMetric: 16.3533, val_loss: 16.8054, val_MinusLogProbMetric: 16.8054

Epoch 239: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3533 - MinusLogProbMetric: 16.3533 - val_loss: 16.8054 - val_MinusLogProbMetric: 16.8054 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 240/1000
2023-09-12 12:08:34.906 
Epoch 240/1000 
	 loss: 16.3468, MinusLogProbMetric: 16.3468, val_loss: 16.8042, val_MinusLogProbMetric: 16.8042

Epoch 240: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3468 - MinusLogProbMetric: 16.3468 - val_loss: 16.8042 - val_MinusLogProbMetric: 16.8042 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 241/1000
2023-09-12 12:08:46.751 
Epoch 241/1000 
	 loss: 16.3504, MinusLogProbMetric: 16.3504, val_loss: 16.8203, val_MinusLogProbMetric: 16.8203

Epoch 241: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3504 - MinusLogProbMetric: 16.3504 - val_loss: 16.8203 - val_MinusLogProbMetric: 16.8203 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 242/1000
2023-09-12 12:08:58.471 
Epoch 242/1000 
	 loss: 16.3468, MinusLogProbMetric: 16.3468, val_loss: 16.8081, val_MinusLogProbMetric: 16.8081

Epoch 242: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3468 - MinusLogProbMetric: 16.3468 - val_loss: 16.8081 - val_MinusLogProbMetric: 16.8081 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 243/1000
2023-09-12 12:09:10.105 
Epoch 243/1000 
	 loss: 16.3481, MinusLogProbMetric: 16.3481, val_loss: 16.8053, val_MinusLogProbMetric: 16.8053

Epoch 243: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3481 - MinusLogProbMetric: 16.3481 - val_loss: 16.8053 - val_MinusLogProbMetric: 16.8053 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 244/1000
2023-09-12 12:09:21.702 
Epoch 244/1000 
	 loss: 16.3458, MinusLogProbMetric: 16.3458, val_loss: 16.8142, val_MinusLogProbMetric: 16.8142

Epoch 244: val_loss did not improve from 16.73236
196/196 - 12s - loss: 16.3458 - MinusLogProbMetric: 16.3458 - val_loss: 16.8142 - val_MinusLogProbMetric: 16.8142 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 245/1000
2023-09-12 12:09:33.389 
Epoch 245/1000 
	 loss: 16.3465, MinusLogProbMetric: 16.3465, val_loss: 16.8164, val_MinusLogProbMetric: 16.8164

Epoch 245: val_loss did not improve from 16.73236
Restoring model weights from the end of the best epoch: 145.
196/196 - 12s - loss: 16.3465 - MinusLogProbMetric: 16.3465 - val_loss: 16.8164 - val_MinusLogProbMetric: 16.8164 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 245: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 6.904929558048025 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.775566924014129 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.402757723000832 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.2251327299745753 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 0.
Model trained in 2853.79 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Metrics computed in 295.61 s.
Plots done in 120.61 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 416.22 s.
===========
Run 122/360 done in 3271.34 s.
===========

Directory ../../results/MsplineN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

===========
Generating train data for run 128.
===========
Train data generated in 0.12 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_128/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_128/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.0084114 ,  5.320987  ,  0.8314564 , ...,  0.9127468 ,
         6.9149337 ,  1.3388323 ],
       [ 4.558577  ,  6.0481462 , -0.24609119, ...,  0.780586  ,
         6.8429356 ,  1.4122885 ],
       [ 3.8734546 ,  5.4054976 , -0.40817448, ...,  1.9913466 ,
         7.003298  ,  1.4506763 ],
       ...,
       [ 3.7691634 ,  5.9463778 ,  0.6548691 , ...,  0.7201797 ,
         6.072925  ,  1.4608443 ],
       [ 2.9241705 ,  3.7473345 ,  7.8737187 , ...,  7.5013213 ,
         2.9760437 ,  2.1283636 ],
       [ 3.1212893 ,  3.2782502 ,  9.1048565 , ...,  7.664732  ,
         2.69802   ,  2.0766048 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_128/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_128
self.data_kwargs: {'seed': 187}
self.x_data: [[ 2.5169935   3.488076    8.180127   ...  7.3930964   2.761347
   1.7877934 ]
 [ 5.2753277   5.678404   -0.1461575  ...  0.47010314  6.983442
   1.3932854 ]
 [ 4.8219504   4.747791    0.71833336 ...  0.3916219   6.80817
   1.3940593 ]
 ...
 [ 4.749002    5.5570974  -0.74672246 ...  1.5353614   6.3259535
   1.2508217 ]
 [ 4.93606     5.3214583  -0.18663862 ...  0.82333434  6.593017
   1.3043829 ]
 [ 4.726056    5.6195855   0.15371738 ... -0.07547045  6.5362086
   1.383484  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_17"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_52 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_17 (LogProbL  (None,)                  855744    
 ayer)                                                           
                                                                 
=================================================================
Total params: 855,744
Trainable params: 855,744
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_17/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_17'")
self.model: <keras.engine.functional.Functional object at 0x7fbbfdab8f10>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fbbfd8d3a30>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fbbfd8d3a30>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fbbfd708640>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fbbfd709000>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fbbfd709570>, <keras.callbacks.ModelCheckpoint object at 0x7fbbfd709630>, <keras.callbacks.EarlyStopping object at 0x7fbbfd7098a0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fbbfd7098d0>, <keras.callbacks.TerminateOnNaN object at 0x7fbbfd709510>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 4.0084114 ,  5.320987  ,  0.8314564 , ...,  0.9127468 ,
         6.9149337 ,  1.3388323 ],
       [ 4.558577  ,  6.0481462 , -0.24609119, ...,  0.780586  ,
         6.8429356 ,  1.4122885 ],
       [ 3.8734546 ,  5.4054976 , -0.40817448, ...,  1.9913466 ,
         7.003298  ,  1.4506763 ],
       ...,
       [ 3.7691634 ,  5.9463778 ,  0.6548691 , ...,  0.7201797 ,
         6.072925  ,  1.4608443 ],
       [ 2.9241705 ,  3.7473345 ,  7.8737187 , ...,  7.5013213 ,
         2.9760437 ,  2.1283636 ],
       [ 3.1212893 ,  3.2782502 ,  9.1048565 , ...,  7.664732  ,
         2.69802   ,  2.0766048 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_128/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 128/360 with hyperparameters:
timestamp = 2023-09-12 12:16:30.562527
ndims = 32
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 855744
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 2.5169935   3.488076    8.180127    0.84921616  9.398114    1.5950611
  9.78848     4.958353   10.506386    6.0036592   7.4747586   0.434458
  2.7849894   1.1959196   3.4402583   0.94847643  3.3037004   5.01443
  1.0595841   6.962085    5.836716    2.7462766   4.817147    0.5488042
  6.4634314  10.065731    3.5173426   6.2808447   1.8747289   7.3930964
  2.761347    1.7877934 ]
Epoch 1/1000
2023-09-12 12:16:59.108 
Epoch 1/1000 
	 loss: 46.0762, MinusLogProbMetric: 46.0762, val_loss: 21.3527, val_MinusLogProbMetric: 21.3527

Epoch 1: val_loss improved from inf to 21.35270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 29s - loss: 46.0762 - MinusLogProbMetric: 46.0762 - val_loss: 21.3527 - val_MinusLogProbMetric: 21.3527 - lr: 0.0010 - 29s/epoch - 146ms/step
Epoch 2/1000
2023-09-12 12:17:10.437 
Epoch 2/1000 
	 loss: 19.4827, MinusLogProbMetric: 19.4827, val_loss: 18.3698, val_MinusLogProbMetric: 18.3698

Epoch 2: val_loss improved from 21.35270 to 18.36979, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 11s - loss: 19.4827 - MinusLogProbMetric: 19.4827 - val_loss: 18.3698 - val_MinusLogProbMetric: 18.3698 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 3/1000
2023-09-12 12:17:21.733 
Epoch 3/1000 
	 loss: 18.1699, MinusLogProbMetric: 18.1699, val_loss: 17.8836, val_MinusLogProbMetric: 17.8836

Epoch 3: val_loss improved from 18.36979 to 17.88358, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 11s - loss: 18.1699 - MinusLogProbMetric: 18.1699 - val_loss: 17.8836 - val_MinusLogProbMetric: 17.8836 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 4/1000
2023-09-12 12:17:33.219 
Epoch 4/1000 
	 loss: 17.7694, MinusLogProbMetric: 17.7694, val_loss: 17.4396, val_MinusLogProbMetric: 17.4396

Epoch 4: val_loss improved from 17.88358 to 17.43956, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 11s - loss: 17.7694 - MinusLogProbMetric: 17.7694 - val_loss: 17.4396 - val_MinusLogProbMetric: 17.4396 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 5/1000
2023-09-12 12:17:44.744 
Epoch 5/1000 
	 loss: 17.6283, MinusLogProbMetric: 17.6283, val_loss: 17.5587, val_MinusLogProbMetric: 17.5587

Epoch 5: val_loss did not improve from 17.43956
196/196 - 11s - loss: 17.6283 - MinusLogProbMetric: 17.6283 - val_loss: 17.5587 - val_MinusLogProbMetric: 17.5587 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 6/1000
2023-09-12 12:17:54.390 
Epoch 6/1000 
	 loss: 17.4169, MinusLogProbMetric: 17.4169, val_loss: 17.4278, val_MinusLogProbMetric: 17.4278

Epoch 6: val_loss improved from 17.43956 to 17.42784, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 10s - loss: 17.4169 - MinusLogProbMetric: 17.4169 - val_loss: 17.4278 - val_MinusLogProbMetric: 17.4278 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 7/1000
2023-09-12 12:18:03.708 
Epoch 7/1000 
	 loss: 17.2708, MinusLogProbMetric: 17.2708, val_loss: 17.1137, val_MinusLogProbMetric: 17.1137

Epoch 7: val_loss improved from 17.42784 to 17.11374, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 9s - loss: 17.2708 - MinusLogProbMetric: 17.2708 - val_loss: 17.1137 - val_MinusLogProbMetric: 17.1137 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 8/1000
2023-09-12 12:18:13.221 
Epoch 8/1000 
	 loss: 17.2239, MinusLogProbMetric: 17.2239, val_loss: 17.4308, val_MinusLogProbMetric: 17.4308

Epoch 8: val_loss did not improve from 17.11374
196/196 - 9s - loss: 17.2239 - MinusLogProbMetric: 17.2239 - val_loss: 17.4308 - val_MinusLogProbMetric: 17.4308 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 9/1000
2023-09-12 12:18:22.536 
Epoch 9/1000 
	 loss: 17.1436, MinusLogProbMetric: 17.1436, val_loss: 17.1602, val_MinusLogProbMetric: 17.1602

Epoch 9: val_loss did not improve from 17.11374
196/196 - 9s - loss: 17.1436 - MinusLogProbMetric: 17.1436 - val_loss: 17.1602 - val_MinusLogProbMetric: 17.1602 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 10/1000
2023-09-12 12:18:31.570 
Epoch 10/1000 
	 loss: 17.1150, MinusLogProbMetric: 17.1150, val_loss: 17.3271, val_MinusLogProbMetric: 17.3271

Epoch 10: val_loss did not improve from 17.11374
196/196 - 9s - loss: 17.1150 - MinusLogProbMetric: 17.1150 - val_loss: 17.3271 - val_MinusLogProbMetric: 17.3271 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 11/1000
2023-09-12 12:18:41.033 
Epoch 11/1000 
	 loss: 17.1027, MinusLogProbMetric: 17.1027, val_loss: 17.2331, val_MinusLogProbMetric: 17.2331

Epoch 11: val_loss did not improve from 17.11374
196/196 - 9s - loss: 17.1027 - MinusLogProbMetric: 17.1027 - val_loss: 17.2331 - val_MinusLogProbMetric: 17.2331 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 12/1000
2023-09-12 12:18:50.606 
Epoch 12/1000 
	 loss: 17.0289, MinusLogProbMetric: 17.0289, val_loss: 16.9532, val_MinusLogProbMetric: 16.9532

Epoch 12: val_loss improved from 17.11374 to 16.95322, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 10s - loss: 17.0289 - MinusLogProbMetric: 17.0289 - val_loss: 16.9532 - val_MinusLogProbMetric: 16.9532 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 13/1000
2023-09-12 12:19:00.417 
Epoch 13/1000 
	 loss: 17.0208, MinusLogProbMetric: 17.0208, val_loss: 17.0401, val_MinusLogProbMetric: 17.0401

Epoch 13: val_loss did not improve from 16.95322
196/196 - 10s - loss: 17.0208 - MinusLogProbMetric: 17.0208 - val_loss: 17.0401 - val_MinusLogProbMetric: 17.0401 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 14/1000
2023-09-12 12:19:10.044 
Epoch 14/1000 
	 loss: 16.9936, MinusLogProbMetric: 16.9936, val_loss: 16.9220, val_MinusLogProbMetric: 16.9220

Epoch 14: val_loss improved from 16.95322 to 16.92204, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 10s - loss: 16.9936 - MinusLogProbMetric: 16.9936 - val_loss: 16.9220 - val_MinusLogProbMetric: 16.9220 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 15/1000
2023-09-12 12:19:19.767 
Epoch 15/1000 
	 loss: 16.9590, MinusLogProbMetric: 16.9590, val_loss: 17.0852, val_MinusLogProbMetric: 17.0852

Epoch 15: val_loss did not improve from 16.92204
196/196 - 10s - loss: 16.9590 - MinusLogProbMetric: 16.9590 - val_loss: 17.0852 - val_MinusLogProbMetric: 17.0852 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 16/1000
2023-09-12 12:19:29.496 
Epoch 16/1000 
	 loss: 16.9438, MinusLogProbMetric: 16.9438, val_loss: 16.9503, val_MinusLogProbMetric: 16.9503

Epoch 16: val_loss did not improve from 16.92204
196/196 - 10s - loss: 16.9438 - MinusLogProbMetric: 16.9438 - val_loss: 16.9503 - val_MinusLogProbMetric: 16.9503 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 17/1000
2023-09-12 12:19:39.096 
Epoch 17/1000 
	 loss: 16.9007, MinusLogProbMetric: 16.9007, val_loss: 16.9079, val_MinusLogProbMetric: 16.9079

Epoch 17: val_loss improved from 16.92204 to 16.90789, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 10s - loss: 16.9007 - MinusLogProbMetric: 16.9007 - val_loss: 16.9079 - val_MinusLogProbMetric: 16.9079 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 18/1000
2023-09-12 12:19:49.198 
Epoch 18/1000 
	 loss: 16.9076, MinusLogProbMetric: 16.9076, val_loss: 16.9094, val_MinusLogProbMetric: 16.9094

Epoch 18: val_loss did not improve from 16.90789
196/196 - 10s - loss: 16.9076 - MinusLogProbMetric: 16.9076 - val_loss: 16.9094 - val_MinusLogProbMetric: 16.9094 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 19/1000
2023-09-12 12:19:58.970 
Epoch 19/1000 
	 loss: 16.8775, MinusLogProbMetric: 16.8775, val_loss: 16.8351, val_MinusLogProbMetric: 16.8351

Epoch 19: val_loss improved from 16.90789 to 16.83507, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 10s - loss: 16.8775 - MinusLogProbMetric: 16.8775 - val_loss: 16.8351 - val_MinusLogProbMetric: 16.8351 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 20/1000
2023-09-12 12:20:09.719 
Epoch 20/1000 
	 loss: 16.8608, MinusLogProbMetric: 16.8608, val_loss: 16.9023, val_MinusLogProbMetric: 16.9023

Epoch 20: val_loss did not improve from 16.83507
196/196 - 11s - loss: 16.8608 - MinusLogProbMetric: 16.8608 - val_loss: 16.9023 - val_MinusLogProbMetric: 16.9023 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 21/1000
2023-09-12 12:20:21.096 
Epoch 21/1000 
	 loss: 16.8630, MinusLogProbMetric: 16.8630, val_loss: 16.9244, val_MinusLogProbMetric: 16.9244

Epoch 21: val_loss did not improve from 16.83507
196/196 - 11s - loss: 16.8630 - MinusLogProbMetric: 16.8630 - val_loss: 16.9244 - val_MinusLogProbMetric: 16.9244 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 22/1000
2023-09-12 12:20:32.425 
Epoch 22/1000 
	 loss: 16.8425, MinusLogProbMetric: 16.8425, val_loss: 16.8322, val_MinusLogProbMetric: 16.8322

Epoch 22: val_loss improved from 16.83507 to 16.83217, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 11s - loss: 16.8425 - MinusLogProbMetric: 16.8425 - val_loss: 16.8322 - val_MinusLogProbMetric: 16.8322 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 23/1000
2023-09-12 12:20:44.059 
Epoch 23/1000 
	 loss: 16.8053, MinusLogProbMetric: 16.8053, val_loss: 16.9022, val_MinusLogProbMetric: 16.9022

Epoch 23: val_loss did not improve from 16.83217
196/196 - 11s - loss: 16.8053 - MinusLogProbMetric: 16.8053 - val_loss: 16.9022 - val_MinusLogProbMetric: 16.9022 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 24/1000
2023-09-12 12:20:55.451 
Epoch 24/1000 
	 loss: 16.7916, MinusLogProbMetric: 16.7916, val_loss: 16.8604, val_MinusLogProbMetric: 16.8604

Epoch 24: val_loss did not improve from 16.83217
196/196 - 11s - loss: 16.7916 - MinusLogProbMetric: 16.7916 - val_loss: 16.8604 - val_MinusLogProbMetric: 16.8604 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 25/1000
2023-09-12 12:21:06.888 
Epoch 25/1000 
	 loss: 16.7900, MinusLogProbMetric: 16.7900, val_loss: 16.8487, val_MinusLogProbMetric: 16.8487

Epoch 25: val_loss did not improve from 16.83217
196/196 - 11s - loss: 16.7900 - MinusLogProbMetric: 16.7900 - val_loss: 16.8487 - val_MinusLogProbMetric: 16.8487 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 26/1000
2023-09-12 12:21:18.212 
Epoch 26/1000 
	 loss: 16.8144, MinusLogProbMetric: 16.8144, val_loss: 16.8535, val_MinusLogProbMetric: 16.8535

Epoch 26: val_loss did not improve from 16.83217
196/196 - 11s - loss: 16.8144 - MinusLogProbMetric: 16.8144 - val_loss: 16.8535 - val_MinusLogProbMetric: 16.8535 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 27/1000
2023-09-12 12:21:29.730 
Epoch 27/1000 
	 loss: 16.7648, MinusLogProbMetric: 16.7648, val_loss: 16.7437, val_MinusLogProbMetric: 16.7437

Epoch 27: val_loss improved from 16.83217 to 16.74368, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 12s - loss: 16.7648 - MinusLogProbMetric: 16.7648 - val_loss: 16.7437 - val_MinusLogProbMetric: 16.7437 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 28/1000
2023-09-12 12:21:41.268 
Epoch 28/1000 
	 loss: 16.8060, MinusLogProbMetric: 16.8060, val_loss: 16.8322, val_MinusLogProbMetric: 16.8322

Epoch 28: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.8060 - MinusLogProbMetric: 16.8060 - val_loss: 16.8322 - val_MinusLogProbMetric: 16.8322 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 29/1000
2023-09-12 12:21:52.663 
Epoch 29/1000 
	 loss: 16.8054, MinusLogProbMetric: 16.8054, val_loss: 16.8761, val_MinusLogProbMetric: 16.8761

Epoch 29: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.8054 - MinusLogProbMetric: 16.8054 - val_loss: 16.8761 - val_MinusLogProbMetric: 16.8761 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 30/1000
2023-09-12 12:22:04.053 
Epoch 30/1000 
	 loss: 16.7703, MinusLogProbMetric: 16.7703, val_loss: 16.8091, val_MinusLogProbMetric: 16.8091

Epoch 30: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7703 - MinusLogProbMetric: 16.7703 - val_loss: 16.8091 - val_MinusLogProbMetric: 16.8091 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 31/1000
2023-09-12 12:22:15.494 
Epoch 31/1000 
	 loss: 16.7584, MinusLogProbMetric: 16.7584, val_loss: 16.7969, val_MinusLogProbMetric: 16.7969

Epoch 31: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7584 - MinusLogProbMetric: 16.7584 - val_loss: 16.7969 - val_MinusLogProbMetric: 16.7969 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 32/1000
2023-09-12 12:22:27.021 
Epoch 32/1000 
	 loss: 16.7616, MinusLogProbMetric: 16.7616, val_loss: 16.8635, val_MinusLogProbMetric: 16.8635

Epoch 32: val_loss did not improve from 16.74368
196/196 - 12s - loss: 16.7616 - MinusLogProbMetric: 16.7616 - val_loss: 16.8635 - val_MinusLogProbMetric: 16.8635 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 33/1000
2023-09-12 12:22:38.313 
Epoch 33/1000 
	 loss: 16.7778, MinusLogProbMetric: 16.7778, val_loss: 16.7963, val_MinusLogProbMetric: 16.7963

Epoch 33: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7778 - MinusLogProbMetric: 16.7778 - val_loss: 16.7963 - val_MinusLogProbMetric: 16.7963 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 34/1000
2023-09-12 12:22:49.249 
Epoch 34/1000 
	 loss: 16.7484, MinusLogProbMetric: 16.7484, val_loss: 16.8315, val_MinusLogProbMetric: 16.8315

Epoch 34: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7484 - MinusLogProbMetric: 16.7484 - val_loss: 16.8315 - val_MinusLogProbMetric: 16.8315 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 35/1000
2023-09-12 12:23:00.596 
Epoch 35/1000 
	 loss: 16.7407, MinusLogProbMetric: 16.7407, val_loss: 16.7876, val_MinusLogProbMetric: 16.7876

Epoch 35: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7407 - MinusLogProbMetric: 16.7407 - val_loss: 16.7876 - val_MinusLogProbMetric: 16.7876 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 36/1000
2023-09-12 12:23:11.852 
Epoch 36/1000 
	 loss: 16.7378, MinusLogProbMetric: 16.7378, val_loss: 16.7721, val_MinusLogProbMetric: 16.7721

Epoch 36: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7378 - MinusLogProbMetric: 16.7378 - val_loss: 16.7721 - val_MinusLogProbMetric: 16.7721 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 37/1000
2023-09-12 12:23:23.250 
Epoch 37/1000 
	 loss: 16.7211, MinusLogProbMetric: 16.7211, val_loss: 16.8130, val_MinusLogProbMetric: 16.8130

Epoch 37: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7211 - MinusLogProbMetric: 16.7211 - val_loss: 16.8130 - val_MinusLogProbMetric: 16.8130 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 38/1000
2023-09-12 12:23:34.705 
Epoch 38/1000 
	 loss: 16.7251, MinusLogProbMetric: 16.7251, val_loss: 16.8052, val_MinusLogProbMetric: 16.8052

Epoch 38: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7251 - MinusLogProbMetric: 16.7251 - val_loss: 16.8052 - val_MinusLogProbMetric: 16.8052 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 39/1000
2023-09-12 12:23:46.211 
Epoch 39/1000 
	 loss: 16.7204, MinusLogProbMetric: 16.7204, val_loss: 16.8303, val_MinusLogProbMetric: 16.8303

Epoch 39: val_loss did not improve from 16.74368
196/196 - 12s - loss: 16.7204 - MinusLogProbMetric: 16.7204 - val_loss: 16.8303 - val_MinusLogProbMetric: 16.8303 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-12 12:23:57.697 
Epoch 40/1000 
	 loss: 16.7231, MinusLogProbMetric: 16.7231, val_loss: 16.7771, val_MinusLogProbMetric: 16.7771

Epoch 40: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7231 - MinusLogProbMetric: 16.7231 - val_loss: 16.7771 - val_MinusLogProbMetric: 16.7771 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 41/1000
2023-09-12 12:24:09.248 
Epoch 41/1000 
	 loss: 16.7186, MinusLogProbMetric: 16.7186, val_loss: 16.8909, val_MinusLogProbMetric: 16.8909

Epoch 41: val_loss did not improve from 16.74368
196/196 - 12s - loss: 16.7186 - MinusLogProbMetric: 16.7186 - val_loss: 16.8909 - val_MinusLogProbMetric: 16.8909 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 42/1000
2023-09-12 12:24:20.694 
Epoch 42/1000 
	 loss: 16.7092, MinusLogProbMetric: 16.7092, val_loss: 16.8176, val_MinusLogProbMetric: 16.8176

Epoch 42: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7092 - MinusLogProbMetric: 16.7092 - val_loss: 16.8176 - val_MinusLogProbMetric: 16.8176 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 43/1000
2023-09-12 12:24:32.136 
Epoch 43/1000 
	 loss: 16.7156, MinusLogProbMetric: 16.7156, val_loss: 16.8611, val_MinusLogProbMetric: 16.8611

Epoch 43: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7156 - MinusLogProbMetric: 16.7156 - val_loss: 16.8611 - val_MinusLogProbMetric: 16.8611 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 44/1000
2023-09-12 12:24:43.562 
Epoch 44/1000 
	 loss: 16.7156, MinusLogProbMetric: 16.7156, val_loss: 16.7823, val_MinusLogProbMetric: 16.7823

Epoch 44: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.7156 - MinusLogProbMetric: 16.7156 - val_loss: 16.7823 - val_MinusLogProbMetric: 16.7823 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 45/1000
2023-09-12 12:24:55.062 
Epoch 45/1000 
	 loss: 16.6888, MinusLogProbMetric: 16.6888, val_loss: 16.8040, val_MinusLogProbMetric: 16.8040

Epoch 45: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.6888 - MinusLogProbMetric: 16.6888 - val_loss: 16.8040 - val_MinusLogProbMetric: 16.8040 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 46/1000
2023-09-12 12:25:06.662 
Epoch 46/1000 
	 loss: 16.7060, MinusLogProbMetric: 16.7060, val_loss: 16.7445, val_MinusLogProbMetric: 16.7445

Epoch 46: val_loss did not improve from 16.74368
196/196 - 12s - loss: 16.7060 - MinusLogProbMetric: 16.7060 - val_loss: 16.7445 - val_MinusLogProbMetric: 16.7445 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 12:25:18.072 
Epoch 47/1000 
	 loss: 16.6994, MinusLogProbMetric: 16.6994, val_loss: 16.8122, val_MinusLogProbMetric: 16.8122

Epoch 47: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.6994 - MinusLogProbMetric: 16.6994 - val_loss: 16.8122 - val_MinusLogProbMetric: 16.8122 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 48/1000
2023-09-12 12:25:29.325 
Epoch 48/1000 
	 loss: 16.6831, MinusLogProbMetric: 16.6831, val_loss: 16.7443, val_MinusLogProbMetric: 16.7443

Epoch 48: val_loss did not improve from 16.74368
196/196 - 11s - loss: 16.6831 - MinusLogProbMetric: 16.6831 - val_loss: 16.7443 - val_MinusLogProbMetric: 16.7443 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 49/1000
2023-09-12 12:25:40.896 
Epoch 49/1000 
	 loss: 16.6907, MinusLogProbMetric: 16.6907, val_loss: 16.7929, val_MinusLogProbMetric: 16.7929

Epoch 49: val_loss did not improve from 16.74368
196/196 - 12s - loss: 16.6907 - MinusLogProbMetric: 16.6907 - val_loss: 16.7929 - val_MinusLogProbMetric: 16.7929 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-12 12:25:52.259 
Epoch 50/1000 
	 loss: 16.6800, MinusLogProbMetric: 16.6800, val_loss: 16.7191, val_MinusLogProbMetric: 16.7191

Epoch 50: val_loss improved from 16.74368 to 16.71909, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 11s - loss: 16.6800 - MinusLogProbMetric: 16.6800 - val_loss: 16.7191 - val_MinusLogProbMetric: 16.7191 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 51/1000
2023-09-12 12:26:03.729 
Epoch 51/1000 
	 loss: 16.6819, MinusLogProbMetric: 16.6819, val_loss: 16.8037, val_MinusLogProbMetric: 16.8037

Epoch 51: val_loss did not improve from 16.71909
196/196 - 11s - loss: 16.6819 - MinusLogProbMetric: 16.6819 - val_loss: 16.8037 - val_MinusLogProbMetric: 16.8037 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 52/1000
2023-09-12 12:26:15.250 
Epoch 52/1000 
	 loss: 16.6805, MinusLogProbMetric: 16.6805, val_loss: 16.7347, val_MinusLogProbMetric: 16.7347

Epoch 52: val_loss did not improve from 16.71909
196/196 - 12s - loss: 16.6805 - MinusLogProbMetric: 16.6805 - val_loss: 16.7347 - val_MinusLogProbMetric: 16.7347 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 53/1000
2023-09-12 12:26:26.631 
Epoch 53/1000 
	 loss: 16.6768, MinusLogProbMetric: 16.6768, val_loss: 16.9898, val_MinusLogProbMetric: 16.9898

Epoch 53: val_loss did not improve from 16.71909
196/196 - 11s - loss: 16.6768 - MinusLogProbMetric: 16.6768 - val_loss: 16.9898 - val_MinusLogProbMetric: 16.9898 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 54/1000
2023-09-12 12:26:38.143 
Epoch 54/1000 
	 loss: 16.6663, MinusLogProbMetric: 16.6663, val_loss: 16.7751, val_MinusLogProbMetric: 16.7751

Epoch 54: val_loss did not improve from 16.71909
196/196 - 12s - loss: 16.6663 - MinusLogProbMetric: 16.6663 - val_loss: 16.7751 - val_MinusLogProbMetric: 16.7751 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 55/1000
2023-09-12 12:26:49.207 
Epoch 55/1000 
	 loss: 16.6780, MinusLogProbMetric: 16.6780, val_loss: 16.7093, val_MinusLogProbMetric: 16.7093

Epoch 55: val_loss improved from 16.71909 to 16.70928, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 11s - loss: 16.6780 - MinusLogProbMetric: 16.6780 - val_loss: 16.7093 - val_MinusLogProbMetric: 16.7093 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 56/1000
2023-09-12 12:27:01.002 
Epoch 56/1000 
	 loss: 16.6695, MinusLogProbMetric: 16.6695, val_loss: 16.8135, val_MinusLogProbMetric: 16.8135

Epoch 56: val_loss did not improve from 16.70928
196/196 - 12s - loss: 16.6695 - MinusLogProbMetric: 16.6695 - val_loss: 16.8135 - val_MinusLogProbMetric: 16.8135 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 57/1000
2023-09-12 12:27:12.662 
Epoch 57/1000 
	 loss: 16.6708, MinusLogProbMetric: 16.6708, val_loss: 16.8021, val_MinusLogProbMetric: 16.8021

Epoch 57: val_loss did not improve from 16.70928
196/196 - 12s - loss: 16.6708 - MinusLogProbMetric: 16.6708 - val_loss: 16.8021 - val_MinusLogProbMetric: 16.8021 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 58/1000
2023-09-12 12:27:23.169 
Epoch 58/1000 
	 loss: 16.6729, MinusLogProbMetric: 16.6729, val_loss: 16.7184, val_MinusLogProbMetric: 16.7184

Epoch 58: val_loss did not improve from 16.70928
196/196 - 11s - loss: 16.6729 - MinusLogProbMetric: 16.6729 - val_loss: 16.7184 - val_MinusLogProbMetric: 16.7184 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 59/1000
2023-09-12 12:27:33.543 
Epoch 59/1000 
	 loss: 16.6561, MinusLogProbMetric: 16.6561, val_loss: 16.7767, val_MinusLogProbMetric: 16.7767

Epoch 59: val_loss did not improve from 16.70928
196/196 - 10s - loss: 16.6561 - MinusLogProbMetric: 16.6561 - val_loss: 16.7767 - val_MinusLogProbMetric: 16.7767 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 60/1000
2023-09-12 12:27:44.125 
Epoch 60/1000 
	 loss: 16.6571, MinusLogProbMetric: 16.6571, val_loss: 16.7421, val_MinusLogProbMetric: 16.7421

Epoch 60: val_loss did not improve from 16.70928
196/196 - 11s - loss: 16.6571 - MinusLogProbMetric: 16.6571 - val_loss: 16.7421 - val_MinusLogProbMetric: 16.7421 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 61/1000
2023-09-12 12:27:54.566 
Epoch 61/1000 
	 loss: 16.6602, MinusLogProbMetric: 16.6602, val_loss: 16.8026, val_MinusLogProbMetric: 16.8026

Epoch 61: val_loss did not improve from 16.70928
196/196 - 10s - loss: 16.6602 - MinusLogProbMetric: 16.6602 - val_loss: 16.8026 - val_MinusLogProbMetric: 16.8026 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 62/1000
2023-09-12 12:28:05.626 
Epoch 62/1000 
	 loss: 16.6585, MinusLogProbMetric: 16.6585, val_loss: 16.7339, val_MinusLogProbMetric: 16.7339

Epoch 62: val_loss did not improve from 16.70928
196/196 - 11s - loss: 16.6585 - MinusLogProbMetric: 16.6585 - val_loss: 16.7339 - val_MinusLogProbMetric: 16.7339 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 63/1000
2023-09-12 12:28:15.421 
Epoch 63/1000 
	 loss: 16.6286, MinusLogProbMetric: 16.6286, val_loss: 16.7595, val_MinusLogProbMetric: 16.7595

Epoch 63: val_loss did not improve from 16.70928
196/196 - 10s - loss: 16.6286 - MinusLogProbMetric: 16.6286 - val_loss: 16.7595 - val_MinusLogProbMetric: 16.7595 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 64/1000
2023-09-12 12:28:26.674 
Epoch 64/1000 
	 loss: 16.6428, MinusLogProbMetric: 16.6428, val_loss: 16.7121, val_MinusLogProbMetric: 16.7121

Epoch 64: val_loss did not improve from 16.70928
196/196 - 11s - loss: 16.6428 - MinusLogProbMetric: 16.6428 - val_loss: 16.7121 - val_MinusLogProbMetric: 16.7121 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 65/1000
2023-09-12 12:28:37.410 
Epoch 65/1000 
	 loss: 16.6304, MinusLogProbMetric: 16.6304, val_loss: 16.7021, val_MinusLogProbMetric: 16.7021

Epoch 65: val_loss improved from 16.70928 to 16.70210, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 11s - loss: 16.6304 - MinusLogProbMetric: 16.6304 - val_loss: 16.7021 - val_MinusLogProbMetric: 16.7021 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 66/1000
2023-09-12 12:28:49.130 
Epoch 66/1000 
	 loss: 16.6269, MinusLogProbMetric: 16.6269, val_loss: 16.7667, val_MinusLogProbMetric: 16.7667

Epoch 66: val_loss did not improve from 16.70210
196/196 - 12s - loss: 16.6269 - MinusLogProbMetric: 16.6269 - val_loss: 16.7667 - val_MinusLogProbMetric: 16.7667 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-12 12:28:59.858 
Epoch 67/1000 
	 loss: 16.6432, MinusLogProbMetric: 16.6432, val_loss: 16.7860, val_MinusLogProbMetric: 16.7860

Epoch 67: val_loss did not improve from 16.70210
196/196 - 11s - loss: 16.6432 - MinusLogProbMetric: 16.6432 - val_loss: 16.7860 - val_MinusLogProbMetric: 16.7860 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 68/1000
2023-09-12 12:29:10.486 
Epoch 68/1000 
	 loss: 16.6271, MinusLogProbMetric: 16.6271, val_loss: 16.7289, val_MinusLogProbMetric: 16.7289

Epoch 68: val_loss did not improve from 16.70210
196/196 - 11s - loss: 16.6271 - MinusLogProbMetric: 16.6271 - val_loss: 16.7289 - val_MinusLogProbMetric: 16.7289 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 69/1000
2023-09-12 12:29:21.880 
Epoch 69/1000 
	 loss: 16.6195, MinusLogProbMetric: 16.6195, val_loss: 16.8165, val_MinusLogProbMetric: 16.8165

Epoch 69: val_loss did not improve from 16.70210
196/196 - 11s - loss: 16.6195 - MinusLogProbMetric: 16.6195 - val_loss: 16.8165 - val_MinusLogProbMetric: 16.8165 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 70/1000
2023-09-12 12:29:32.190 
Epoch 70/1000 
	 loss: 16.6248, MinusLogProbMetric: 16.6248, val_loss: 16.7032, val_MinusLogProbMetric: 16.7032

Epoch 70: val_loss did not improve from 16.70210
196/196 - 10s - loss: 16.6248 - MinusLogProbMetric: 16.6248 - val_loss: 16.7032 - val_MinusLogProbMetric: 16.7032 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 71/1000
2023-09-12 12:29:43.553 
Epoch 71/1000 
	 loss: 16.6159, MinusLogProbMetric: 16.6159, val_loss: 16.7505, val_MinusLogProbMetric: 16.7505

Epoch 71: val_loss did not improve from 16.70210
196/196 - 11s - loss: 16.6159 - MinusLogProbMetric: 16.6159 - val_loss: 16.7505 - val_MinusLogProbMetric: 16.7505 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 72/1000
2023-09-12 12:29:55.021 
Epoch 72/1000 
	 loss: 16.6206, MinusLogProbMetric: 16.6206, val_loss: 16.7090, val_MinusLogProbMetric: 16.7090

Epoch 72: val_loss did not improve from 16.70210
196/196 - 11s - loss: 16.6206 - MinusLogProbMetric: 16.6206 - val_loss: 16.7090 - val_MinusLogProbMetric: 16.7090 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 73/1000
2023-09-12 12:30:06.607 
Epoch 73/1000 
	 loss: 16.6257, MinusLogProbMetric: 16.6257, val_loss: 16.8023, val_MinusLogProbMetric: 16.8023

Epoch 73: val_loss did not improve from 16.70210
196/196 - 12s - loss: 16.6257 - MinusLogProbMetric: 16.6257 - val_loss: 16.8023 - val_MinusLogProbMetric: 16.8023 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 12:30:18.212 
Epoch 74/1000 
	 loss: 16.6285, MinusLogProbMetric: 16.6285, val_loss: 16.7230, val_MinusLogProbMetric: 16.7230

Epoch 74: val_loss did not improve from 16.70210
196/196 - 12s - loss: 16.6285 - MinusLogProbMetric: 16.6285 - val_loss: 16.7230 - val_MinusLogProbMetric: 16.7230 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 75/1000
2023-09-12 12:30:29.733 
Epoch 75/1000 
	 loss: 16.6265, MinusLogProbMetric: 16.6265, val_loss: 16.7738, val_MinusLogProbMetric: 16.7738

Epoch 75: val_loss did not improve from 16.70210
196/196 - 12s - loss: 16.6265 - MinusLogProbMetric: 16.6265 - val_loss: 16.7738 - val_MinusLogProbMetric: 16.7738 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 76/1000
2023-09-12 12:30:41.268 
Epoch 76/1000 
	 loss: 16.6187, MinusLogProbMetric: 16.6187, val_loss: 16.7382, val_MinusLogProbMetric: 16.7382

Epoch 76: val_loss did not improve from 16.70210
196/196 - 12s - loss: 16.6187 - MinusLogProbMetric: 16.6187 - val_loss: 16.7382 - val_MinusLogProbMetric: 16.7382 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 77/1000
2023-09-12 12:30:52.787 
Epoch 77/1000 
	 loss: 16.6186, MinusLogProbMetric: 16.6186, val_loss: 16.7214, val_MinusLogProbMetric: 16.7214

Epoch 77: val_loss did not improve from 16.70210
196/196 - 12s - loss: 16.6186 - MinusLogProbMetric: 16.6186 - val_loss: 16.7214 - val_MinusLogProbMetric: 16.7214 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 78/1000
2023-09-12 12:31:04.353 
Epoch 78/1000 
	 loss: 16.6089, MinusLogProbMetric: 16.6089, val_loss: 16.7072, val_MinusLogProbMetric: 16.7072

Epoch 78: val_loss did not improve from 16.70210
196/196 - 12s - loss: 16.6089 - MinusLogProbMetric: 16.6089 - val_loss: 16.7072 - val_MinusLogProbMetric: 16.7072 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 79/1000
2023-09-12 12:31:15.897 
Epoch 79/1000 
	 loss: 16.6108, MinusLogProbMetric: 16.6108, val_loss: 16.6977, val_MinusLogProbMetric: 16.6977

Epoch 79: val_loss improved from 16.70210 to 16.69773, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 12s - loss: 16.6108 - MinusLogProbMetric: 16.6108 - val_loss: 16.6977 - val_MinusLogProbMetric: 16.6977 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 80/1000
2023-09-12 12:31:27.575 
Epoch 80/1000 
	 loss: 16.6132, MinusLogProbMetric: 16.6132, val_loss: 16.7420, val_MinusLogProbMetric: 16.7420

Epoch 80: val_loss did not improve from 16.69773
196/196 - 12s - loss: 16.6132 - MinusLogProbMetric: 16.6132 - val_loss: 16.7420 - val_MinusLogProbMetric: 16.7420 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-12 12:31:39.000 
Epoch 81/1000 
	 loss: 16.6058, MinusLogProbMetric: 16.6058, val_loss: 16.7175, val_MinusLogProbMetric: 16.7175

Epoch 81: val_loss did not improve from 16.69773
196/196 - 11s - loss: 16.6058 - MinusLogProbMetric: 16.6058 - val_loss: 16.7175 - val_MinusLogProbMetric: 16.7175 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 82/1000
2023-09-12 12:31:50.578 
Epoch 82/1000 
	 loss: 16.6058, MinusLogProbMetric: 16.6058, val_loss: 16.8657, val_MinusLogProbMetric: 16.8657

Epoch 82: val_loss did not improve from 16.69773
196/196 - 12s - loss: 16.6058 - MinusLogProbMetric: 16.6058 - val_loss: 16.8657 - val_MinusLogProbMetric: 16.8657 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 83/1000
2023-09-12 12:32:01.994 
Epoch 83/1000 
	 loss: 16.6078, MinusLogProbMetric: 16.6078, val_loss: 16.7594, val_MinusLogProbMetric: 16.7594

Epoch 83: val_loss did not improve from 16.69773
196/196 - 11s - loss: 16.6078 - MinusLogProbMetric: 16.6078 - val_loss: 16.7594 - val_MinusLogProbMetric: 16.7594 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 84/1000
2023-09-12 12:32:13.449 
Epoch 84/1000 
	 loss: 16.5895, MinusLogProbMetric: 16.5895, val_loss: 16.6948, val_MinusLogProbMetric: 16.6948

Epoch 84: val_loss improved from 16.69773 to 16.69483, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_128/weights/best_weights.h5
196/196 - 12s - loss: 16.5895 - MinusLogProbMetric: 16.5895 - val_loss: 16.6948 - val_MinusLogProbMetric: 16.6948 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 85/1000
2023-09-12 12:32:25.183 
Epoch 85/1000 
	 loss: 16.5948, MinusLogProbMetric: 16.5948, val_loss: 16.7911, val_MinusLogProbMetric: 16.7911

Epoch 85: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5948 - MinusLogProbMetric: 16.5948 - val_loss: 16.7911 - val_MinusLogProbMetric: 16.7911 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-12 12:32:36.882 
Epoch 86/1000 
	 loss: 16.5792, MinusLogProbMetric: 16.5792, val_loss: 16.7608, val_MinusLogProbMetric: 16.7608

Epoch 86: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5792 - MinusLogProbMetric: 16.5792 - val_loss: 16.7608 - val_MinusLogProbMetric: 16.7608 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 87/1000
2023-09-12 12:32:48.365 
Epoch 87/1000 
	 loss: 16.5966, MinusLogProbMetric: 16.5966, val_loss: 16.7742, val_MinusLogProbMetric: 16.7742

Epoch 87: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5966 - MinusLogProbMetric: 16.5966 - val_loss: 16.7742 - val_MinusLogProbMetric: 16.7742 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 88/1000
2023-09-12 12:32:59.890 
Epoch 88/1000 
	 loss: 16.5792, MinusLogProbMetric: 16.5792, val_loss: 16.7529, val_MinusLogProbMetric: 16.7529

Epoch 88: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5792 - MinusLogProbMetric: 16.5792 - val_loss: 16.7529 - val_MinusLogProbMetric: 16.7529 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-12 12:33:11.288 
Epoch 89/1000 
	 loss: 16.5864, MinusLogProbMetric: 16.5864, val_loss: 16.8184, val_MinusLogProbMetric: 16.8184

Epoch 89: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5864 - MinusLogProbMetric: 16.5864 - val_loss: 16.8184 - val_MinusLogProbMetric: 16.8184 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 90/1000
2023-09-12 12:33:22.860 
Epoch 90/1000 
	 loss: 16.5756, MinusLogProbMetric: 16.5756, val_loss: 16.8065, val_MinusLogProbMetric: 16.8065

Epoch 90: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5756 - MinusLogProbMetric: 16.5756 - val_loss: 16.8065 - val_MinusLogProbMetric: 16.8065 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 91/1000
2023-09-12 12:33:34.394 
Epoch 91/1000 
	 loss: 16.5888, MinusLogProbMetric: 16.5888, val_loss: 16.7688, val_MinusLogProbMetric: 16.7688

Epoch 91: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5888 - MinusLogProbMetric: 16.5888 - val_loss: 16.7688 - val_MinusLogProbMetric: 16.7688 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 92/1000
2023-09-12 12:33:45.873 
Epoch 92/1000 
	 loss: 16.6006, MinusLogProbMetric: 16.6006, val_loss: 16.7408, val_MinusLogProbMetric: 16.7408

Epoch 92: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.6006 - MinusLogProbMetric: 16.6006 - val_loss: 16.7408 - val_MinusLogProbMetric: 16.7408 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 93/1000
2023-09-12 12:33:57.416 
Epoch 93/1000 
	 loss: 16.5768, MinusLogProbMetric: 16.5768, val_loss: 16.7167, val_MinusLogProbMetric: 16.7167

Epoch 93: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5768 - MinusLogProbMetric: 16.5768 - val_loss: 16.7167 - val_MinusLogProbMetric: 16.7167 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 94/1000
2023-09-12 12:34:08.953 
Epoch 94/1000 
	 loss: 16.5714, MinusLogProbMetric: 16.5714, val_loss: 16.8125, val_MinusLogProbMetric: 16.8125

Epoch 94: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5714 - MinusLogProbMetric: 16.5714 - val_loss: 16.8125 - val_MinusLogProbMetric: 16.8125 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-12 12:34:20.466 
Epoch 95/1000 
	 loss: 16.5786, MinusLogProbMetric: 16.5786, val_loss: 16.8447, val_MinusLogProbMetric: 16.8447

Epoch 95: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5786 - MinusLogProbMetric: 16.5786 - val_loss: 16.8447 - val_MinusLogProbMetric: 16.8447 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 96/1000
2023-09-12 12:34:32.089 
Epoch 96/1000 
	 loss: 16.5729, MinusLogProbMetric: 16.5729, val_loss: 16.8228, val_MinusLogProbMetric: 16.8228

Epoch 96: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5729 - MinusLogProbMetric: 16.5729 - val_loss: 16.8228 - val_MinusLogProbMetric: 16.8228 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 97/1000
2023-09-12 12:34:43.762 
Epoch 97/1000 
	 loss: 16.5832, MinusLogProbMetric: 16.5832, val_loss: 16.7887, val_MinusLogProbMetric: 16.7887

Epoch 97: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5832 - MinusLogProbMetric: 16.5832 - val_loss: 16.7887 - val_MinusLogProbMetric: 16.7887 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 98/1000
2023-09-12 12:34:55.445 
Epoch 98/1000 
	 loss: 16.5644, MinusLogProbMetric: 16.5644, val_loss: 16.8394, val_MinusLogProbMetric: 16.8394

Epoch 98: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5644 - MinusLogProbMetric: 16.5644 - val_loss: 16.8394 - val_MinusLogProbMetric: 16.8394 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 99/1000
2023-09-12 12:35:07.058 
Epoch 99/1000 
	 loss: 16.5543, MinusLogProbMetric: 16.5543, val_loss: 16.7886, val_MinusLogProbMetric: 16.7886

Epoch 99: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5543 - MinusLogProbMetric: 16.5543 - val_loss: 16.7886 - val_MinusLogProbMetric: 16.7886 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-12 12:35:18.712 
Epoch 100/1000 
	 loss: 16.5566, MinusLogProbMetric: 16.5566, val_loss: 16.7478, val_MinusLogProbMetric: 16.7478

Epoch 100: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5566 - MinusLogProbMetric: 16.5566 - val_loss: 16.7478 - val_MinusLogProbMetric: 16.7478 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 101/1000
2023-09-12 12:35:30.277 
Epoch 101/1000 
	 loss: 16.5795, MinusLogProbMetric: 16.5795, val_loss: 16.8371, val_MinusLogProbMetric: 16.8371

Epoch 101: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5795 - MinusLogProbMetric: 16.5795 - val_loss: 16.8371 - val_MinusLogProbMetric: 16.8371 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 102/1000
2023-09-12 12:35:41.991 
Epoch 102/1000 
	 loss: 16.5707, MinusLogProbMetric: 16.5707, val_loss: 16.7091, val_MinusLogProbMetric: 16.7091

Epoch 102: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5707 - MinusLogProbMetric: 16.5707 - val_loss: 16.7091 - val_MinusLogProbMetric: 16.7091 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 103/1000
2023-09-12 12:35:53.830 
Epoch 103/1000 
	 loss: 16.5597, MinusLogProbMetric: 16.5597, val_loss: 16.8705, val_MinusLogProbMetric: 16.8705

Epoch 103: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5597 - MinusLogProbMetric: 16.5597 - val_loss: 16.8705 - val_MinusLogProbMetric: 16.8705 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-12 12:36:05.274 
Epoch 104/1000 
	 loss: 16.5570, MinusLogProbMetric: 16.5570, val_loss: 16.7294, val_MinusLogProbMetric: 16.7294

Epoch 104: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5570 - MinusLogProbMetric: 16.5570 - val_loss: 16.7294 - val_MinusLogProbMetric: 16.7294 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 105/1000
2023-09-12 12:36:16.708 
Epoch 105/1000 
	 loss: 16.5620, MinusLogProbMetric: 16.5620, val_loss: 16.7880, val_MinusLogProbMetric: 16.7880

Epoch 105: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5620 - MinusLogProbMetric: 16.5620 - val_loss: 16.7880 - val_MinusLogProbMetric: 16.7880 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 106/1000
2023-09-12 12:36:28.264 
Epoch 106/1000 
	 loss: 16.5494, MinusLogProbMetric: 16.5494, val_loss: 16.7725, val_MinusLogProbMetric: 16.7725

Epoch 106: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5494 - MinusLogProbMetric: 16.5494 - val_loss: 16.7725 - val_MinusLogProbMetric: 16.7725 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 107/1000
2023-09-12 12:36:39.703 
Epoch 107/1000 
	 loss: 16.5487, MinusLogProbMetric: 16.5487, val_loss: 16.7377, val_MinusLogProbMetric: 16.7377

Epoch 107: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5487 - MinusLogProbMetric: 16.5487 - val_loss: 16.7377 - val_MinusLogProbMetric: 16.7377 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 108/1000
2023-09-12 12:36:50.794 
Epoch 108/1000 
	 loss: 16.5514, MinusLogProbMetric: 16.5514, val_loss: 16.7880, val_MinusLogProbMetric: 16.7880

Epoch 108: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5514 - MinusLogProbMetric: 16.5514 - val_loss: 16.7880 - val_MinusLogProbMetric: 16.7880 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 109/1000
2023-09-12 12:37:01.839 
Epoch 109/1000 
	 loss: 16.5461, MinusLogProbMetric: 16.5461, val_loss: 16.8073, val_MinusLogProbMetric: 16.8073

Epoch 109: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5461 - MinusLogProbMetric: 16.5461 - val_loss: 16.8073 - val_MinusLogProbMetric: 16.8073 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 110/1000
2023-09-12 12:37:12.243 
Epoch 110/1000 
	 loss: 16.5392, MinusLogProbMetric: 16.5392, val_loss: 16.8418, val_MinusLogProbMetric: 16.8418

Epoch 110: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.5392 - MinusLogProbMetric: 16.5392 - val_loss: 16.8418 - val_MinusLogProbMetric: 16.8418 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 111/1000
2023-09-12 12:37:23.435 
Epoch 111/1000 
	 loss: 16.5604, MinusLogProbMetric: 16.5604, val_loss: 16.7577, val_MinusLogProbMetric: 16.7577

Epoch 111: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5604 - MinusLogProbMetric: 16.5604 - val_loss: 16.7577 - val_MinusLogProbMetric: 16.7577 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 112/1000
2023-09-12 12:37:34.470 
Epoch 112/1000 
	 loss: 16.5420, MinusLogProbMetric: 16.5420, val_loss: 16.8007, val_MinusLogProbMetric: 16.8007

Epoch 112: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5420 - MinusLogProbMetric: 16.5420 - val_loss: 16.8007 - val_MinusLogProbMetric: 16.8007 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 113/1000
2023-09-12 12:37:44.943 
Epoch 113/1000 
	 loss: 16.5322, MinusLogProbMetric: 16.5322, val_loss: 16.7801, val_MinusLogProbMetric: 16.7801

Epoch 113: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.5322 - MinusLogProbMetric: 16.5322 - val_loss: 16.7801 - val_MinusLogProbMetric: 16.7801 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 114/1000
2023-09-12 12:37:55.863 
Epoch 114/1000 
	 loss: 16.5433, MinusLogProbMetric: 16.5433, val_loss: 16.7847, val_MinusLogProbMetric: 16.7847

Epoch 114: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5433 - MinusLogProbMetric: 16.5433 - val_loss: 16.7847 - val_MinusLogProbMetric: 16.7847 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 115/1000
2023-09-12 12:38:06.864 
Epoch 115/1000 
	 loss: 16.5277, MinusLogProbMetric: 16.5277, val_loss: 16.7670, val_MinusLogProbMetric: 16.7670

Epoch 115: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5277 - MinusLogProbMetric: 16.5277 - val_loss: 16.7670 - val_MinusLogProbMetric: 16.7670 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 116/1000
2023-09-12 12:38:17.963 
Epoch 116/1000 
	 loss: 16.5410, MinusLogProbMetric: 16.5410, val_loss: 16.7842, val_MinusLogProbMetric: 16.7842

Epoch 116: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5410 - MinusLogProbMetric: 16.5410 - val_loss: 16.7842 - val_MinusLogProbMetric: 16.7842 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 117/1000
2023-09-12 12:38:27.083 
Epoch 117/1000 
	 loss: 16.5283, MinusLogProbMetric: 16.5283, val_loss: 16.8726, val_MinusLogProbMetric: 16.8726

Epoch 117: val_loss did not improve from 16.69483
196/196 - 9s - loss: 16.5283 - MinusLogProbMetric: 16.5283 - val_loss: 16.8726 - val_MinusLogProbMetric: 16.8726 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 118/1000
2023-09-12 12:38:37.299 
Epoch 118/1000 
	 loss: 16.5343, MinusLogProbMetric: 16.5343, val_loss: 16.7708, val_MinusLogProbMetric: 16.7708

Epoch 118: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.5343 - MinusLogProbMetric: 16.5343 - val_loss: 16.7708 - val_MinusLogProbMetric: 16.7708 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 119/1000
2023-09-12 12:38:48.122 
Epoch 119/1000 
	 loss: 16.5308, MinusLogProbMetric: 16.5308, val_loss: 16.8154, val_MinusLogProbMetric: 16.8154

Epoch 119: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5308 - MinusLogProbMetric: 16.5308 - val_loss: 16.8154 - val_MinusLogProbMetric: 16.8154 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 120/1000
2023-09-12 12:38:59.380 
Epoch 120/1000 
	 loss: 16.5198, MinusLogProbMetric: 16.5198, val_loss: 16.7384, val_MinusLogProbMetric: 16.7384

Epoch 120: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5198 - MinusLogProbMetric: 16.5198 - val_loss: 16.7384 - val_MinusLogProbMetric: 16.7384 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 121/1000
2023-09-12 12:39:10.981 
Epoch 121/1000 
	 loss: 16.5229, MinusLogProbMetric: 16.5229, val_loss: 16.7993, val_MinusLogProbMetric: 16.7993

Epoch 121: val_loss did not improve from 16.69483
196/196 - 12s - loss: 16.5229 - MinusLogProbMetric: 16.5229 - val_loss: 16.7993 - val_MinusLogProbMetric: 16.7993 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 122/1000
2023-09-12 12:39:21.356 
Epoch 122/1000 
	 loss: 16.5198, MinusLogProbMetric: 16.5198, val_loss: 16.7845, val_MinusLogProbMetric: 16.7845

Epoch 122: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.5198 - MinusLogProbMetric: 16.5198 - val_loss: 16.7845 - val_MinusLogProbMetric: 16.7845 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 123/1000
2023-09-12 12:39:32.710 
Epoch 123/1000 
	 loss: 16.5118, MinusLogProbMetric: 16.5118, val_loss: 16.7326, val_MinusLogProbMetric: 16.7326

Epoch 123: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5118 - MinusLogProbMetric: 16.5118 - val_loss: 16.7326 - val_MinusLogProbMetric: 16.7326 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 124/1000
2023-09-12 12:39:43.966 
Epoch 124/1000 
	 loss: 16.5246, MinusLogProbMetric: 16.5246, val_loss: 16.7692, val_MinusLogProbMetric: 16.7692

Epoch 124: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5246 - MinusLogProbMetric: 16.5246 - val_loss: 16.7692 - val_MinusLogProbMetric: 16.7692 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 125/1000
2023-09-12 12:39:55.333 
Epoch 125/1000 
	 loss: 16.5237, MinusLogProbMetric: 16.5237, val_loss: 16.7648, val_MinusLogProbMetric: 16.7648

Epoch 125: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5237 - MinusLogProbMetric: 16.5237 - val_loss: 16.7648 - val_MinusLogProbMetric: 16.7648 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 126/1000
2023-09-12 12:40:06.582 
Epoch 126/1000 
	 loss: 16.5103, MinusLogProbMetric: 16.5103, val_loss: 16.7688, val_MinusLogProbMetric: 16.7688

Epoch 126: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5103 - MinusLogProbMetric: 16.5103 - val_loss: 16.7688 - val_MinusLogProbMetric: 16.7688 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 127/1000
2023-09-12 12:40:17.771 
Epoch 127/1000 
	 loss: 16.5193, MinusLogProbMetric: 16.5193, val_loss: 16.7853, val_MinusLogProbMetric: 16.7853

Epoch 127: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5193 - MinusLogProbMetric: 16.5193 - val_loss: 16.7853 - val_MinusLogProbMetric: 16.7853 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 128/1000
2023-09-12 12:40:28.763 
Epoch 128/1000 
	 loss: 16.5029, MinusLogProbMetric: 16.5029, val_loss: 16.8349, val_MinusLogProbMetric: 16.8349

Epoch 128: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5029 - MinusLogProbMetric: 16.5029 - val_loss: 16.8349 - val_MinusLogProbMetric: 16.8349 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 129/1000
2023-09-12 12:40:39.248 
Epoch 129/1000 
	 loss: 16.5162, MinusLogProbMetric: 16.5162, val_loss: 16.8863, val_MinusLogProbMetric: 16.8863

Epoch 129: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.5162 - MinusLogProbMetric: 16.5162 - val_loss: 16.8863 - val_MinusLogProbMetric: 16.8863 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 130/1000
2023-09-12 12:40:50.296 
Epoch 130/1000 
	 loss: 16.5061, MinusLogProbMetric: 16.5061, val_loss: 16.8025, val_MinusLogProbMetric: 16.8025

Epoch 130: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5061 - MinusLogProbMetric: 16.5061 - val_loss: 16.8025 - val_MinusLogProbMetric: 16.8025 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 131/1000
2023-09-12 12:41:01.539 
Epoch 131/1000 
	 loss: 16.5146, MinusLogProbMetric: 16.5146, val_loss: 16.8266, val_MinusLogProbMetric: 16.8266

Epoch 131: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5146 - MinusLogProbMetric: 16.5146 - val_loss: 16.8266 - val_MinusLogProbMetric: 16.8266 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 132/1000
2023-09-12 12:41:12.610 
Epoch 132/1000 
	 loss: 16.4991, MinusLogProbMetric: 16.4991, val_loss: 16.8489, val_MinusLogProbMetric: 16.8489

Epoch 132: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4991 - MinusLogProbMetric: 16.4991 - val_loss: 16.8489 - val_MinusLogProbMetric: 16.8489 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 133/1000
2023-09-12 12:41:23.117 
Epoch 133/1000 
	 loss: 16.5012, MinusLogProbMetric: 16.5012, val_loss: 16.8151, val_MinusLogProbMetric: 16.8151

Epoch 133: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5012 - MinusLogProbMetric: 16.5012 - val_loss: 16.8151 - val_MinusLogProbMetric: 16.8151 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 134/1000
2023-09-12 12:41:33.633 
Epoch 134/1000 
	 loss: 16.5051, MinusLogProbMetric: 16.5051, val_loss: 16.7460, val_MinusLogProbMetric: 16.7460

Epoch 134: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.5051 - MinusLogProbMetric: 16.5051 - val_loss: 16.7460 - val_MinusLogProbMetric: 16.7460 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 135/1000
2023-09-12 12:41:44.160 
Epoch 135/1000 
	 loss: 16.4224, MinusLogProbMetric: 16.4224, val_loss: 16.7410, val_MinusLogProbMetric: 16.7410

Epoch 135: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4224 - MinusLogProbMetric: 16.4224 - val_loss: 16.7410 - val_MinusLogProbMetric: 16.7410 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 136/1000
2023-09-12 12:41:55.206 
Epoch 136/1000 
	 loss: 16.4166, MinusLogProbMetric: 16.4166, val_loss: 16.7467, val_MinusLogProbMetric: 16.7467

Epoch 136: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4166 - MinusLogProbMetric: 16.4166 - val_loss: 16.7467 - val_MinusLogProbMetric: 16.7467 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 137/1000
2023-09-12 12:42:06.268 
Epoch 137/1000 
	 loss: 16.4126, MinusLogProbMetric: 16.4126, val_loss: 16.7499, val_MinusLogProbMetric: 16.7499

Epoch 137: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4126 - MinusLogProbMetric: 16.4126 - val_loss: 16.7499 - val_MinusLogProbMetric: 16.7499 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 138/1000
2023-09-12 12:42:17.428 
Epoch 138/1000 
	 loss: 16.4170, MinusLogProbMetric: 16.4170, val_loss: 16.7677, val_MinusLogProbMetric: 16.7677

Epoch 138: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4170 - MinusLogProbMetric: 16.4170 - val_loss: 16.7677 - val_MinusLogProbMetric: 16.7677 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 139/1000
2023-09-12 12:42:28.687 
Epoch 139/1000 
	 loss: 16.4177, MinusLogProbMetric: 16.4177, val_loss: 16.7824, val_MinusLogProbMetric: 16.7824

Epoch 139: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4177 - MinusLogProbMetric: 16.4177 - val_loss: 16.7824 - val_MinusLogProbMetric: 16.7824 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 140/1000
2023-09-12 12:42:39.716 
Epoch 140/1000 
	 loss: 16.4111, MinusLogProbMetric: 16.4111, val_loss: 16.7610, val_MinusLogProbMetric: 16.7610

Epoch 140: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4111 - MinusLogProbMetric: 16.4111 - val_loss: 16.7610 - val_MinusLogProbMetric: 16.7610 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 141/1000
2023-09-12 12:42:50.410 
Epoch 141/1000 
	 loss: 16.4117, MinusLogProbMetric: 16.4117, val_loss: 16.7651, val_MinusLogProbMetric: 16.7651

Epoch 141: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4117 - MinusLogProbMetric: 16.4117 - val_loss: 16.7651 - val_MinusLogProbMetric: 16.7651 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 142/1000
2023-09-12 12:43:01.506 
Epoch 142/1000 
	 loss: 16.4079, MinusLogProbMetric: 16.4079, val_loss: 16.7442, val_MinusLogProbMetric: 16.7442

Epoch 142: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4079 - MinusLogProbMetric: 16.4079 - val_loss: 16.7442 - val_MinusLogProbMetric: 16.7442 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 143/1000
2023-09-12 12:43:12.726 
Epoch 143/1000 
	 loss: 16.4160, MinusLogProbMetric: 16.4160, val_loss: 16.7674, val_MinusLogProbMetric: 16.7674

Epoch 143: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4160 - MinusLogProbMetric: 16.4160 - val_loss: 16.7674 - val_MinusLogProbMetric: 16.7674 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 144/1000
2023-09-12 12:43:23.895 
Epoch 144/1000 
	 loss: 16.4040, MinusLogProbMetric: 16.4040, val_loss: 16.7672, val_MinusLogProbMetric: 16.7672

Epoch 144: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4040 - MinusLogProbMetric: 16.4040 - val_loss: 16.7672 - val_MinusLogProbMetric: 16.7672 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 145/1000
2023-09-12 12:43:35.066 
Epoch 145/1000 
	 loss: 16.4048, MinusLogProbMetric: 16.4048, val_loss: 16.7606, val_MinusLogProbMetric: 16.7606

Epoch 145: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4048 - MinusLogProbMetric: 16.4048 - val_loss: 16.7606 - val_MinusLogProbMetric: 16.7606 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 146/1000
2023-09-12 12:43:46.304 
Epoch 146/1000 
	 loss: 16.4031, MinusLogProbMetric: 16.4031, val_loss: 16.7733, val_MinusLogProbMetric: 16.7733

Epoch 146: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4031 - MinusLogProbMetric: 16.4031 - val_loss: 16.7733 - val_MinusLogProbMetric: 16.7733 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 147/1000
2023-09-12 12:43:57.529 
Epoch 147/1000 
	 loss: 16.4054, MinusLogProbMetric: 16.4054, val_loss: 16.7686, val_MinusLogProbMetric: 16.7686

Epoch 147: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4054 - MinusLogProbMetric: 16.4054 - val_loss: 16.7686 - val_MinusLogProbMetric: 16.7686 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 148/1000
2023-09-12 12:44:08.564 
Epoch 148/1000 
	 loss: 16.3997, MinusLogProbMetric: 16.3997, val_loss: 16.7865, val_MinusLogProbMetric: 16.7865

Epoch 148: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3997 - MinusLogProbMetric: 16.3997 - val_loss: 16.7865 - val_MinusLogProbMetric: 16.7865 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 149/1000
2023-09-12 12:44:19.647 
Epoch 149/1000 
	 loss: 16.4050, MinusLogProbMetric: 16.4050, val_loss: 16.7630, val_MinusLogProbMetric: 16.7630

Epoch 149: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4050 - MinusLogProbMetric: 16.4050 - val_loss: 16.7630 - val_MinusLogProbMetric: 16.7630 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 150/1000
2023-09-12 12:44:30.648 
Epoch 150/1000 
	 loss: 16.4021, MinusLogProbMetric: 16.4021, val_loss: 16.7935, val_MinusLogProbMetric: 16.7935

Epoch 150: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4021 - MinusLogProbMetric: 16.4021 - val_loss: 16.7935 - val_MinusLogProbMetric: 16.7935 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 151/1000
2023-09-12 12:44:41.872 
Epoch 151/1000 
	 loss: 16.3971, MinusLogProbMetric: 16.3971, val_loss: 16.7898, val_MinusLogProbMetric: 16.7898

Epoch 151: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3971 - MinusLogProbMetric: 16.3971 - val_loss: 16.7898 - val_MinusLogProbMetric: 16.7898 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 152/1000
2023-09-12 12:44:52.997 
Epoch 152/1000 
	 loss: 16.4002, MinusLogProbMetric: 16.4002, val_loss: 16.7767, val_MinusLogProbMetric: 16.7767

Epoch 152: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.4002 - MinusLogProbMetric: 16.4002 - val_loss: 16.7767 - val_MinusLogProbMetric: 16.7767 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 153/1000
2023-09-12 12:45:04.104 
Epoch 153/1000 
	 loss: 16.3975, MinusLogProbMetric: 16.3975, val_loss: 16.7985, val_MinusLogProbMetric: 16.7985

Epoch 153: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3975 - MinusLogProbMetric: 16.3975 - val_loss: 16.7985 - val_MinusLogProbMetric: 16.7985 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 154/1000
2023-09-12 12:45:15.333 
Epoch 154/1000 
	 loss: 16.3969, MinusLogProbMetric: 16.3969, val_loss: 16.7759, val_MinusLogProbMetric: 16.7759

Epoch 154: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3969 - MinusLogProbMetric: 16.3969 - val_loss: 16.7759 - val_MinusLogProbMetric: 16.7759 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 155/1000
2023-09-12 12:45:25.720 
Epoch 155/1000 
	 loss: 16.3931, MinusLogProbMetric: 16.3931, val_loss: 16.7933, val_MinusLogProbMetric: 16.7933

Epoch 155: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.3931 - MinusLogProbMetric: 16.3931 - val_loss: 16.7933 - val_MinusLogProbMetric: 16.7933 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 156/1000
2023-09-12 12:45:36.430 
Epoch 156/1000 
	 loss: 16.3930, MinusLogProbMetric: 16.3930, val_loss: 16.7783, val_MinusLogProbMetric: 16.7783

Epoch 156: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3930 - MinusLogProbMetric: 16.3930 - val_loss: 16.7783 - val_MinusLogProbMetric: 16.7783 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 157/1000
2023-09-12 12:45:47.396 
Epoch 157/1000 
	 loss: 16.3853, MinusLogProbMetric: 16.3853, val_loss: 16.7953, val_MinusLogProbMetric: 16.7953

Epoch 157: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3853 - MinusLogProbMetric: 16.3853 - val_loss: 16.7953 - val_MinusLogProbMetric: 16.7953 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 158/1000
2023-09-12 12:45:58.437 
Epoch 158/1000 
	 loss: 16.3913, MinusLogProbMetric: 16.3913, val_loss: 16.8104, val_MinusLogProbMetric: 16.8104

Epoch 158: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3913 - MinusLogProbMetric: 16.3913 - val_loss: 16.8104 - val_MinusLogProbMetric: 16.8104 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 159/1000
2023-09-12 12:46:09.160 
Epoch 159/1000 
	 loss: 16.3876, MinusLogProbMetric: 16.3876, val_loss: 16.7910, val_MinusLogProbMetric: 16.7910

Epoch 159: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3876 - MinusLogProbMetric: 16.3876 - val_loss: 16.7910 - val_MinusLogProbMetric: 16.7910 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 160/1000
2023-09-12 12:46:18.561 
Epoch 160/1000 
	 loss: 16.3911, MinusLogProbMetric: 16.3911, val_loss: 16.7889, val_MinusLogProbMetric: 16.7889

Epoch 160: val_loss did not improve from 16.69483
196/196 - 9s - loss: 16.3911 - MinusLogProbMetric: 16.3911 - val_loss: 16.7889 - val_MinusLogProbMetric: 16.7889 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 161/1000
2023-09-12 12:46:29.580 
Epoch 161/1000 
	 loss: 16.3912, MinusLogProbMetric: 16.3912, val_loss: 16.8139, val_MinusLogProbMetric: 16.8139

Epoch 161: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3912 - MinusLogProbMetric: 16.3912 - val_loss: 16.8139 - val_MinusLogProbMetric: 16.8139 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 162/1000
2023-09-12 12:46:40.946 
Epoch 162/1000 
	 loss: 16.3851, MinusLogProbMetric: 16.3851, val_loss: 16.7986, val_MinusLogProbMetric: 16.7986

Epoch 162: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3851 - MinusLogProbMetric: 16.3851 - val_loss: 16.7986 - val_MinusLogProbMetric: 16.7986 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 163/1000
2023-09-12 12:46:52.115 
Epoch 163/1000 
	 loss: 16.3895, MinusLogProbMetric: 16.3895, val_loss: 16.8101, val_MinusLogProbMetric: 16.8101

Epoch 163: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3895 - MinusLogProbMetric: 16.3895 - val_loss: 16.8101 - val_MinusLogProbMetric: 16.8101 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 164/1000
2023-09-12 12:47:03.368 
Epoch 164/1000 
	 loss: 16.3814, MinusLogProbMetric: 16.3814, val_loss: 16.8116, val_MinusLogProbMetric: 16.8116

Epoch 164: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3814 - MinusLogProbMetric: 16.3814 - val_loss: 16.8116 - val_MinusLogProbMetric: 16.8116 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 165/1000
2023-09-12 12:47:14.486 
Epoch 165/1000 
	 loss: 16.3834, MinusLogProbMetric: 16.3834, val_loss: 16.8012, val_MinusLogProbMetric: 16.8012

Epoch 165: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3834 - MinusLogProbMetric: 16.3834 - val_loss: 16.8012 - val_MinusLogProbMetric: 16.8012 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 166/1000
2023-09-12 12:47:25.549 
Epoch 166/1000 
	 loss: 16.3838, MinusLogProbMetric: 16.3838, val_loss: 16.8210, val_MinusLogProbMetric: 16.8210

Epoch 166: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3838 - MinusLogProbMetric: 16.3838 - val_loss: 16.8210 - val_MinusLogProbMetric: 16.8210 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 167/1000
2023-09-12 12:47:35.480 
Epoch 167/1000 
	 loss: 16.3812, MinusLogProbMetric: 16.3812, val_loss: 16.8236, val_MinusLogProbMetric: 16.8236

Epoch 167: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.3812 - MinusLogProbMetric: 16.3812 - val_loss: 16.8236 - val_MinusLogProbMetric: 16.8236 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 168/1000
2023-09-12 12:47:46.789 
Epoch 168/1000 
	 loss: 16.3796, MinusLogProbMetric: 16.3796, val_loss: 16.8193, val_MinusLogProbMetric: 16.8193

Epoch 168: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3796 - MinusLogProbMetric: 16.3796 - val_loss: 16.8193 - val_MinusLogProbMetric: 16.8193 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 169/1000
2023-09-12 12:47:57.969 
Epoch 169/1000 
	 loss: 16.3807, MinusLogProbMetric: 16.3807, val_loss: 16.7973, val_MinusLogProbMetric: 16.7973

Epoch 169: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3807 - MinusLogProbMetric: 16.3807 - val_loss: 16.7973 - val_MinusLogProbMetric: 16.7973 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 170/1000
2023-09-12 12:48:09.176 
Epoch 170/1000 
	 loss: 16.3803, MinusLogProbMetric: 16.3803, val_loss: 16.8273, val_MinusLogProbMetric: 16.8273

Epoch 170: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3803 - MinusLogProbMetric: 16.3803 - val_loss: 16.8273 - val_MinusLogProbMetric: 16.8273 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 171/1000
2023-09-12 12:48:19.791 
Epoch 171/1000 
	 loss: 16.3751, MinusLogProbMetric: 16.3751, val_loss: 16.8452, val_MinusLogProbMetric: 16.8452

Epoch 171: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3751 - MinusLogProbMetric: 16.3751 - val_loss: 16.8452 - val_MinusLogProbMetric: 16.8452 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 172/1000
2023-09-12 12:48:30.384 
Epoch 172/1000 
	 loss: 16.3740, MinusLogProbMetric: 16.3740, val_loss: 16.8139, val_MinusLogProbMetric: 16.8139

Epoch 172: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3740 - MinusLogProbMetric: 16.3740 - val_loss: 16.8139 - val_MinusLogProbMetric: 16.8139 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 173/1000
2023-09-12 12:48:39.425 
Epoch 173/1000 
	 loss: 16.3753, MinusLogProbMetric: 16.3753, val_loss: 16.8179, val_MinusLogProbMetric: 16.8179

Epoch 173: val_loss did not improve from 16.69483
196/196 - 9s - loss: 16.3753 - MinusLogProbMetric: 16.3753 - val_loss: 16.8179 - val_MinusLogProbMetric: 16.8179 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 174/1000
2023-09-12 12:48:50.022 
Epoch 174/1000 
	 loss: 16.3729, MinusLogProbMetric: 16.3729, val_loss: 16.7995, val_MinusLogProbMetric: 16.7995

Epoch 174: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3729 - MinusLogProbMetric: 16.3729 - val_loss: 16.7995 - val_MinusLogProbMetric: 16.7995 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 175/1000
2023-09-12 12:49:00.131 
Epoch 175/1000 
	 loss: 16.3746, MinusLogProbMetric: 16.3746, val_loss: 16.8105, val_MinusLogProbMetric: 16.8105

Epoch 175: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.3746 - MinusLogProbMetric: 16.3746 - val_loss: 16.8105 - val_MinusLogProbMetric: 16.8105 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 176/1000
2023-09-12 12:49:09.179 
Epoch 176/1000 
	 loss: 16.3788, MinusLogProbMetric: 16.3788, val_loss: 16.8145, val_MinusLogProbMetric: 16.8145

Epoch 176: val_loss did not improve from 16.69483
196/196 - 9s - loss: 16.3788 - MinusLogProbMetric: 16.3788 - val_loss: 16.8145 - val_MinusLogProbMetric: 16.8145 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 177/1000
2023-09-12 12:49:18.258 
Epoch 177/1000 
	 loss: 16.3780, MinusLogProbMetric: 16.3780, val_loss: 16.8458, val_MinusLogProbMetric: 16.8458

Epoch 177: val_loss did not improve from 16.69483
196/196 - 9s - loss: 16.3780 - MinusLogProbMetric: 16.3780 - val_loss: 16.8458 - val_MinusLogProbMetric: 16.8458 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 178/1000
2023-09-12 12:49:27.877 
Epoch 178/1000 
	 loss: 16.3698, MinusLogProbMetric: 16.3698, val_loss: 16.8349, val_MinusLogProbMetric: 16.8349

Epoch 178: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.3698 - MinusLogProbMetric: 16.3698 - val_loss: 16.8349 - val_MinusLogProbMetric: 16.8349 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 179/1000
2023-09-12 12:49:39.084 
Epoch 179/1000 
	 loss: 16.3657, MinusLogProbMetric: 16.3657, val_loss: 16.8380, val_MinusLogProbMetric: 16.8380

Epoch 179: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3657 - MinusLogProbMetric: 16.3657 - val_loss: 16.8380 - val_MinusLogProbMetric: 16.8380 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 180/1000
2023-09-12 12:49:49.765 
Epoch 180/1000 
	 loss: 16.3682, MinusLogProbMetric: 16.3682, val_loss: 16.8291, val_MinusLogProbMetric: 16.8291

Epoch 180: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3682 - MinusLogProbMetric: 16.3682 - val_loss: 16.8291 - val_MinusLogProbMetric: 16.8291 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 181/1000
2023-09-12 12:50:00.650 
Epoch 181/1000 
	 loss: 16.3653, MinusLogProbMetric: 16.3653, val_loss: 16.8574, val_MinusLogProbMetric: 16.8574

Epoch 181: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3653 - MinusLogProbMetric: 16.3653 - val_loss: 16.8574 - val_MinusLogProbMetric: 16.8574 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 182/1000
2023-09-12 12:50:11.508 
Epoch 182/1000 
	 loss: 16.3671, MinusLogProbMetric: 16.3671, val_loss: 16.8180, val_MinusLogProbMetric: 16.8180

Epoch 182: val_loss did not improve from 16.69483
196/196 - 11s - loss: 16.3671 - MinusLogProbMetric: 16.3671 - val_loss: 16.8180 - val_MinusLogProbMetric: 16.8180 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 183/1000
2023-09-12 12:50:21.303 
Epoch 183/1000 
	 loss: 16.3625, MinusLogProbMetric: 16.3625, val_loss: 16.8580, val_MinusLogProbMetric: 16.8580

Epoch 183: val_loss did not improve from 16.69483
196/196 - 10s - loss: 16.3625 - MinusLogProbMetric: 16.3625 - val_loss: 16.8580 - val_MinusLogProbMetric: 16.8580 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 184/1000
2023-09-12 12:50:31.595 
Epoch 184/1000 
	 loss: 16.3668, MinusLogProbMetric: 16.3668, val_loss: 16.8214, val_MinusLogProbMetric: 16.8214

Epoch 184: val_loss did not improve from 16.69483
Restoring model weights from the end of the best epoch: 84.
196/196 - 10s - loss: 16.3668 - MinusLogProbMetric: 16.3668 - val_loss: 16.8214 - val_MinusLogProbMetric: 16.8214 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 184: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 6.049522430985235 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.17707791691646 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.8377611010801047 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.6532627739943564 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 187.
Model trained in 2041.10 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 976 and retrying.
Metrics computed in 2583.18 s.
Plots done in 121.11 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 2704.29 s.
===========
Run 128/360 done in 4746.26 s.
===========

Directory ../../results/MsplineN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

===========
Generating train data for run 137.
===========
Train data generated in 0.24 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_137/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_137/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.1594152 , 5.9057984 , 0.49419823, ..., 0.8514399 , 6.256712  ,
        1.480321  ],
       [1.5519624 , 3.4821532 , 9.090884  , ..., 7.550202  , 2.0195832 ,
        2.0028124 ],
       [5.024437  , 5.545016  , 0.72914684, ..., 1.4977117 , 6.11016   ,
        1.3848512 ],
       ...,
       [2.3904152 , 4.0066795 , 9.690181  , ..., 7.0904365 , 2.575569  ,
        2.2018228 ],
       [4.1976676 , 5.7945614 , 0.3756783 , ..., 0.93405473, 6.8727407 ,
        1.3970704 ],
       [3.406288  , 3.566776  , 8.402107  , ..., 6.6656675 , 2.1215582 ,
        1.6292461 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_137/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_137
self.data_kwargs: {'seed': 520}
self.x_data: [[ 4.809414    5.7868204  -0.6009127  ...  0.01358616  6.3306513
   1.3594574 ]
 [ 1.8875682   2.8721213   8.829799   ...  7.258137    2.9943306
   1.6774887 ]
 [ 2.357473    2.908167    8.286111   ...  6.6552515   2.3523934
   1.7594271 ]
 ...
 [ 2.579169    2.6245098   8.052887   ...  7.156755    3.455019
   2.0439432 ]
 [ 4.846754    6.070016    0.6291522  ...  1.6990016   6.231039
   1.4995929 ]
 [ 1.1347094   4.0317616   7.9557943  ...  7.616784    2.4229698
   1.7107131 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_55 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_18 (LogProbL  (None,)                  264384    
 ayer)                                                           
                                                                 
=================================================================
Total params: 264,384
Trainable params: 264,384
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_18/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_18'")
self.model: <keras.engine.functional.Functional object at 0x7fbc0f45aa70>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fbc0f1b3190>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fbc0f1b3190>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fbc0f1b3a60>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fbc0f1e0760>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fbc0f1e0cd0>, <keras.callbacks.ModelCheckpoint object at 0x7fbc0f1e0d90>, <keras.callbacks.EarlyStopping object at 0x7fbc0f1e1000>, <keras.callbacks.ReduceLROnPlateau object at 0x7fbc0f1e1030>, <keras.callbacks.TerminateOnNaN object at 0x7fbc0f1e0c70>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.1594152 , 5.9057984 , 0.49419823, ..., 0.8514399 , 6.256712  ,
        1.480321  ],
       [1.5519624 , 3.4821532 , 9.090884  , ..., 7.550202  , 2.0195832 ,
        2.0028124 ],
       [5.024437  , 5.545016  , 0.72914684, ..., 1.4977117 , 6.11016   ,
        1.3848512 ],
       ...,
       [2.3904152 , 4.0066795 , 9.690181  , ..., 7.0904365 , 2.575569  ,
        2.2018228 ],
       [4.1976676 , 5.7945614 , 0.3756783 , ..., 0.93405473, 6.8727407 ,
        1.3970704 ],
       [3.406288  , 3.566776  , 8.402107  , ..., 6.6656675 , 2.1215582 ,
        1.6292461 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_137/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 137/360 with hyperparameters:
timestamp = 2023-09-12 13:35:37.118957
ndims = 32
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 264384
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.809414    5.7868204  -0.6009127   6.8734436   6.2845616   6.273516
  8.837362    7.2392435   4.5055285   4.1620827   7.082687    0.01994354
  7.5021      7.0694785   1.6521051   2.620006    3.6251688   5.320881
  5.746099    7.388146   10.06614     2.6692557   2.2652717   2.733516
  6.343552    1.4077059   4.5032105   1.9999803   0.88892937  0.01358616
  6.3306513   1.3594574 ]
Epoch 1/1000
2023-09-12 13:36:02.159 
Epoch 1/1000 
	 loss: 53.8589, MinusLogProbMetric: 53.8589, val_loss: 21.4760, val_MinusLogProbMetric: 21.4760

Epoch 1: val_loss improved from inf to 21.47602, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 25s - loss: 53.8589 - MinusLogProbMetric: 53.8589 - val_loss: 21.4760 - val_MinusLogProbMetric: 21.4760 - lr: 0.0010 - 25s/epoch - 128ms/step
Epoch 2/1000
2023-09-12 13:36:10.864 
Epoch 2/1000 
	 loss: 20.0274, MinusLogProbMetric: 20.0274, val_loss: 18.8190, val_MinusLogProbMetric: 18.8190

Epoch 2: val_loss improved from 21.47602 to 18.81901, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 20.0274 - MinusLogProbMetric: 20.0274 - val_loss: 18.8190 - val_MinusLogProbMetric: 18.8190 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 3/1000
2023-09-12 13:36:19.672 
Epoch 3/1000 
	 loss: 18.6287, MinusLogProbMetric: 18.6287, val_loss: 18.0599, val_MinusLogProbMetric: 18.0599

Epoch 3: val_loss improved from 18.81901 to 18.05985, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 18.6287 - MinusLogProbMetric: 18.6287 - val_loss: 18.0599 - val_MinusLogProbMetric: 18.0599 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 4/1000
2023-09-12 13:36:28.417 
Epoch 4/1000 
	 loss: 18.2053, MinusLogProbMetric: 18.2053, val_loss: 17.8782, val_MinusLogProbMetric: 17.8782

Epoch 4: val_loss improved from 18.05985 to 17.87819, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 18.2053 - MinusLogProbMetric: 18.2053 - val_loss: 17.8782 - val_MinusLogProbMetric: 17.8782 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 5/1000
2023-09-12 13:36:37.164 
Epoch 5/1000 
	 loss: 17.9221, MinusLogProbMetric: 17.9221, val_loss: 17.5883, val_MinusLogProbMetric: 17.5883

Epoch 5: val_loss improved from 17.87819 to 17.58833, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 17.9221 - MinusLogProbMetric: 17.9221 - val_loss: 17.5883 - val_MinusLogProbMetric: 17.5883 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 6/1000
2023-09-12 13:36:46.041 
Epoch 6/1000 
	 loss: 17.7502, MinusLogProbMetric: 17.7502, val_loss: 17.4335, val_MinusLogProbMetric: 17.4335

Epoch 6: val_loss improved from 17.58833 to 17.43351, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 17.7502 - MinusLogProbMetric: 17.7502 - val_loss: 17.4335 - val_MinusLogProbMetric: 17.4335 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 7/1000
2023-09-12 13:36:55.053 
Epoch 7/1000 
	 loss: 17.6246, MinusLogProbMetric: 17.6246, val_loss: 18.4514, val_MinusLogProbMetric: 18.4514

Epoch 7: val_loss did not improve from 17.43351
196/196 - 9s - loss: 17.6246 - MinusLogProbMetric: 17.6246 - val_loss: 18.4514 - val_MinusLogProbMetric: 18.4514 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 8/1000
2023-09-12 13:37:05.494 
Epoch 8/1000 
	 loss: 17.4854, MinusLogProbMetric: 17.4854, val_loss: 17.6459, val_MinusLogProbMetric: 17.6459

Epoch 8: val_loss did not improve from 17.43351
196/196 - 10s - loss: 17.4854 - MinusLogProbMetric: 17.4854 - val_loss: 17.6459 - val_MinusLogProbMetric: 17.6459 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 9/1000
2023-09-12 13:37:14.471 
Epoch 9/1000 
	 loss: 17.3762, MinusLogProbMetric: 17.3762, val_loss: 17.5670, val_MinusLogProbMetric: 17.5670

Epoch 9: val_loss did not improve from 17.43351
196/196 - 9s - loss: 17.3762 - MinusLogProbMetric: 17.3762 - val_loss: 17.5670 - val_MinusLogProbMetric: 17.5670 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 10/1000
2023-09-12 13:37:23.386 
Epoch 10/1000 
	 loss: 17.3429, MinusLogProbMetric: 17.3429, val_loss: 17.3806, val_MinusLogProbMetric: 17.3806

Epoch 10: val_loss improved from 17.43351 to 17.38063, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 17.3429 - MinusLogProbMetric: 17.3429 - val_loss: 17.3806 - val_MinusLogProbMetric: 17.3806 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 11/1000
2023-09-12 13:37:32.481 
Epoch 11/1000 
	 loss: 17.3014, MinusLogProbMetric: 17.3014, val_loss: 17.3824, val_MinusLogProbMetric: 17.3824

Epoch 11: val_loss did not improve from 17.38063
196/196 - 9s - loss: 17.3014 - MinusLogProbMetric: 17.3014 - val_loss: 17.3824 - val_MinusLogProbMetric: 17.3824 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 12/1000
2023-09-12 13:37:42.898 
Epoch 12/1000 
	 loss: 17.2219, MinusLogProbMetric: 17.2219, val_loss: 17.4945, val_MinusLogProbMetric: 17.4945

Epoch 12: val_loss did not improve from 17.38063
196/196 - 10s - loss: 17.2219 - MinusLogProbMetric: 17.2219 - val_loss: 17.4945 - val_MinusLogProbMetric: 17.4945 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 13/1000
2023-09-12 13:37:54.187 
Epoch 13/1000 
	 loss: 17.2233, MinusLogProbMetric: 17.2233, val_loss: 17.1389, val_MinusLogProbMetric: 17.1389

Epoch 13: val_loss improved from 17.38063 to 17.13890, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 17.2233 - MinusLogProbMetric: 17.2233 - val_loss: 17.1389 - val_MinusLogProbMetric: 17.1389 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 14/1000
2023-09-12 13:38:04.499 
Epoch 14/1000 
	 loss: 17.1178, MinusLogProbMetric: 17.1178, val_loss: 17.3400, val_MinusLogProbMetric: 17.3400

Epoch 14: val_loss did not improve from 17.13890
196/196 - 10s - loss: 17.1178 - MinusLogProbMetric: 17.1178 - val_loss: 17.3400 - val_MinusLogProbMetric: 17.3400 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 15/1000
2023-09-12 13:38:15.569 
Epoch 15/1000 
	 loss: 17.1605, MinusLogProbMetric: 17.1605, val_loss: 17.2839, val_MinusLogProbMetric: 17.2839

Epoch 15: val_loss did not improve from 17.13890
196/196 - 11s - loss: 17.1605 - MinusLogProbMetric: 17.1605 - val_loss: 17.2839 - val_MinusLogProbMetric: 17.2839 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 16/1000
2023-09-12 13:38:24.964 
Epoch 16/1000 
	 loss: 17.0999, MinusLogProbMetric: 17.0999, val_loss: 17.1740, val_MinusLogProbMetric: 17.1740

Epoch 16: val_loss did not improve from 17.13890
196/196 - 9s - loss: 17.0999 - MinusLogProbMetric: 17.0999 - val_loss: 17.1740 - val_MinusLogProbMetric: 17.1740 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 17/1000
2023-09-12 13:38:33.822 
Epoch 17/1000 
	 loss: 17.0592, MinusLogProbMetric: 17.0592, val_loss: 17.1342, val_MinusLogProbMetric: 17.1342

Epoch 17: val_loss improved from 17.13890 to 17.13423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 17.0592 - MinusLogProbMetric: 17.0592 - val_loss: 17.1342 - val_MinusLogProbMetric: 17.1342 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 18/1000
2023-09-12 13:38:43.167 
Epoch 18/1000 
	 loss: 17.0320, MinusLogProbMetric: 17.0320, val_loss: 16.9236, val_MinusLogProbMetric: 16.9236

Epoch 18: val_loss improved from 17.13423 to 16.92358, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 17.0320 - MinusLogProbMetric: 17.0320 - val_loss: 16.9236 - val_MinusLogProbMetric: 16.9236 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 19/1000
2023-09-12 13:38:54.547 
Epoch 19/1000 
	 loss: 17.0517, MinusLogProbMetric: 17.0517, val_loss: 16.9520, val_MinusLogProbMetric: 16.9520

Epoch 19: val_loss did not improve from 16.92358
196/196 - 11s - loss: 17.0517 - MinusLogProbMetric: 17.0517 - val_loss: 16.9520 - val_MinusLogProbMetric: 16.9520 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 20/1000
2023-09-12 13:39:04.553 
Epoch 20/1000 
	 loss: 17.0092, MinusLogProbMetric: 17.0092, val_loss: 17.3111, val_MinusLogProbMetric: 17.3111

Epoch 20: val_loss did not improve from 16.92358
196/196 - 10s - loss: 17.0092 - MinusLogProbMetric: 17.0092 - val_loss: 17.3111 - val_MinusLogProbMetric: 17.3111 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 21/1000
2023-09-12 13:39:13.800 
Epoch 21/1000 
	 loss: 16.9903, MinusLogProbMetric: 16.9903, val_loss: 17.1673, val_MinusLogProbMetric: 17.1673

Epoch 21: val_loss did not improve from 16.92358
196/196 - 9s - loss: 16.9903 - MinusLogProbMetric: 16.9903 - val_loss: 17.1673 - val_MinusLogProbMetric: 17.1673 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 22/1000
2023-09-12 13:39:24.329 
Epoch 22/1000 
	 loss: 16.9731, MinusLogProbMetric: 16.9731, val_loss: 17.0011, val_MinusLogProbMetric: 17.0011

Epoch 22: val_loss did not improve from 16.92358
196/196 - 11s - loss: 16.9731 - MinusLogProbMetric: 16.9731 - val_loss: 17.0011 - val_MinusLogProbMetric: 17.0011 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 23/1000
2023-09-12 13:39:35.536 
Epoch 23/1000 
	 loss: 16.9384, MinusLogProbMetric: 16.9384, val_loss: 16.9224, val_MinusLogProbMetric: 16.9224

Epoch 23: val_loss improved from 16.92358 to 16.92235, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.9384 - MinusLogProbMetric: 16.9384 - val_loss: 16.9224 - val_MinusLogProbMetric: 16.9224 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 24/1000
2023-09-12 13:39:45.659 
Epoch 24/1000 
	 loss: 16.9203, MinusLogProbMetric: 16.9203, val_loss: 17.1603, val_MinusLogProbMetric: 17.1603

Epoch 24: val_loss did not improve from 16.92235
196/196 - 10s - loss: 16.9203 - MinusLogProbMetric: 16.9203 - val_loss: 17.1603 - val_MinusLogProbMetric: 17.1603 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 25/1000
2023-09-12 13:39:54.529 
Epoch 25/1000 
	 loss: 16.9252, MinusLogProbMetric: 16.9252, val_loss: 16.8228, val_MinusLogProbMetric: 16.8228

Epoch 25: val_loss improved from 16.92235 to 16.82283, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 9s - loss: 16.9252 - MinusLogProbMetric: 16.9252 - val_loss: 16.8228 - val_MinusLogProbMetric: 16.8228 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 26/1000
2023-09-12 13:40:04.808 
Epoch 26/1000 
	 loss: 16.9396, MinusLogProbMetric: 16.9396, val_loss: 17.0456, val_MinusLogProbMetric: 17.0456

Epoch 26: val_loss did not improve from 16.82283
196/196 - 10s - loss: 16.9396 - MinusLogProbMetric: 16.9396 - val_loss: 17.0456 - val_MinusLogProbMetric: 17.0456 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 27/1000
2023-09-12 13:40:15.887 
Epoch 27/1000 
	 loss: 16.9001, MinusLogProbMetric: 16.9001, val_loss: 16.9559, val_MinusLogProbMetric: 16.9559

Epoch 27: val_loss did not improve from 16.82283
196/196 - 11s - loss: 16.9001 - MinusLogProbMetric: 16.9001 - val_loss: 16.9559 - val_MinusLogProbMetric: 16.9559 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 28/1000
2023-09-12 13:40:25.878 
Epoch 28/1000 
	 loss: 16.9161, MinusLogProbMetric: 16.9161, val_loss: 16.9348, val_MinusLogProbMetric: 16.9348

Epoch 28: val_loss did not improve from 16.82283
196/196 - 10s - loss: 16.9161 - MinusLogProbMetric: 16.9161 - val_loss: 16.9348 - val_MinusLogProbMetric: 16.9348 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 29/1000
2023-09-12 13:40:37.012 
Epoch 29/1000 
	 loss: 16.9013, MinusLogProbMetric: 16.9013, val_loss: 17.1911, val_MinusLogProbMetric: 17.1911

Epoch 29: val_loss did not improve from 16.82283
196/196 - 11s - loss: 16.9013 - MinusLogProbMetric: 16.9013 - val_loss: 17.1911 - val_MinusLogProbMetric: 17.1911 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 30/1000
2023-09-12 13:40:48.073 
Epoch 30/1000 
	 loss: 16.8512, MinusLogProbMetric: 16.8512, val_loss: 16.8840, val_MinusLogProbMetric: 16.8840

Epoch 30: val_loss did not improve from 16.82283
196/196 - 11s - loss: 16.8512 - MinusLogProbMetric: 16.8512 - val_loss: 16.8840 - val_MinusLogProbMetric: 16.8840 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 31/1000
2023-09-12 13:40:59.283 
Epoch 31/1000 
	 loss: 16.8483, MinusLogProbMetric: 16.8483, val_loss: 16.7933, val_MinusLogProbMetric: 16.7933

Epoch 31: val_loss improved from 16.82283 to 16.79326, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.8483 - MinusLogProbMetric: 16.8483 - val_loss: 16.7933 - val_MinusLogProbMetric: 16.7933 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 32/1000
2023-09-12 13:41:10.630 
Epoch 32/1000 
	 loss: 16.8285, MinusLogProbMetric: 16.8285, val_loss: 16.7814, val_MinusLogProbMetric: 16.7814

Epoch 32: val_loss improved from 16.79326 to 16.78142, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.8285 - MinusLogProbMetric: 16.8285 - val_loss: 16.7814 - val_MinusLogProbMetric: 16.7814 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 33/1000
2023-09-12 13:41:21.283 
Epoch 33/1000 
	 loss: 16.8406, MinusLogProbMetric: 16.8406, val_loss: 16.9654, val_MinusLogProbMetric: 16.9654

Epoch 33: val_loss did not improve from 16.78142
196/196 - 11s - loss: 16.8406 - MinusLogProbMetric: 16.8406 - val_loss: 16.9654 - val_MinusLogProbMetric: 16.9654 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 34/1000
2023-09-12 13:41:30.527 
Epoch 34/1000 
	 loss: 16.8288, MinusLogProbMetric: 16.8288, val_loss: 16.9220, val_MinusLogProbMetric: 16.9220

Epoch 34: val_loss did not improve from 16.78142
196/196 - 9s - loss: 16.8288 - MinusLogProbMetric: 16.8288 - val_loss: 16.9220 - val_MinusLogProbMetric: 16.9220 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 35/1000
2023-09-12 13:41:39.440 
Epoch 35/1000 
	 loss: 16.7890, MinusLogProbMetric: 16.7890, val_loss: 17.2109, val_MinusLogProbMetric: 17.2109

Epoch 35: val_loss did not improve from 16.78142
196/196 - 9s - loss: 16.7890 - MinusLogProbMetric: 16.7890 - val_loss: 17.2109 - val_MinusLogProbMetric: 17.2109 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 36/1000
2023-09-12 13:41:48.453 
Epoch 36/1000 
	 loss: 16.8454, MinusLogProbMetric: 16.8454, val_loss: 16.9026, val_MinusLogProbMetric: 16.9026

Epoch 36: val_loss did not improve from 16.78142
196/196 - 9s - loss: 16.8454 - MinusLogProbMetric: 16.8454 - val_loss: 16.9026 - val_MinusLogProbMetric: 16.9026 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 37/1000
2023-09-12 13:41:58.087 
Epoch 37/1000 
	 loss: 16.7997, MinusLogProbMetric: 16.7997, val_loss: 16.7843, val_MinusLogProbMetric: 16.7843

Epoch 37: val_loss did not improve from 16.78142
196/196 - 10s - loss: 16.7997 - MinusLogProbMetric: 16.7997 - val_loss: 16.7843 - val_MinusLogProbMetric: 16.7843 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 38/1000
2023-09-12 13:42:07.583 
Epoch 38/1000 
	 loss: 16.8065, MinusLogProbMetric: 16.8065, val_loss: 16.7709, val_MinusLogProbMetric: 16.7709

Epoch 38: val_loss improved from 16.78142 to 16.77093, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 10s - loss: 16.8065 - MinusLogProbMetric: 16.8065 - val_loss: 16.7709 - val_MinusLogProbMetric: 16.7709 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 39/1000
2023-09-12 13:42:17.456 
Epoch 39/1000 
	 loss: 16.7990, MinusLogProbMetric: 16.7990, val_loss: 16.8095, val_MinusLogProbMetric: 16.8095

Epoch 39: val_loss did not improve from 16.77093
196/196 - 10s - loss: 16.7990 - MinusLogProbMetric: 16.7990 - val_loss: 16.8095 - val_MinusLogProbMetric: 16.8095 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 40/1000
2023-09-12 13:42:26.929 
Epoch 40/1000 
	 loss: 16.8010, MinusLogProbMetric: 16.8010, val_loss: 16.8208, val_MinusLogProbMetric: 16.8208

Epoch 40: val_loss did not improve from 16.77093
196/196 - 9s - loss: 16.8010 - MinusLogProbMetric: 16.8010 - val_loss: 16.8208 - val_MinusLogProbMetric: 16.8208 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 41/1000
2023-09-12 13:42:36.470 
Epoch 41/1000 
	 loss: 16.7903, MinusLogProbMetric: 16.7903, val_loss: 16.8551, val_MinusLogProbMetric: 16.8551

Epoch 41: val_loss did not improve from 16.77093
196/196 - 10s - loss: 16.7903 - MinusLogProbMetric: 16.7903 - val_loss: 16.8551 - val_MinusLogProbMetric: 16.8551 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 42/1000
2023-09-12 13:42:45.666 
Epoch 42/1000 
	 loss: 16.7825, MinusLogProbMetric: 16.7825, val_loss: 16.7933, val_MinusLogProbMetric: 16.7933

Epoch 42: val_loss did not improve from 16.77093
196/196 - 9s - loss: 16.7825 - MinusLogProbMetric: 16.7825 - val_loss: 16.7933 - val_MinusLogProbMetric: 16.7933 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 43/1000
2023-09-12 13:42:55.522 
Epoch 43/1000 
	 loss: 16.7853, MinusLogProbMetric: 16.7853, val_loss: 16.9096, val_MinusLogProbMetric: 16.9096

Epoch 43: val_loss did not improve from 16.77093
196/196 - 10s - loss: 16.7853 - MinusLogProbMetric: 16.7853 - val_loss: 16.9096 - val_MinusLogProbMetric: 16.9096 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 44/1000
2023-09-12 13:43:05.010 
Epoch 44/1000 
	 loss: 16.7760, MinusLogProbMetric: 16.7760, val_loss: 16.7795, val_MinusLogProbMetric: 16.7795

Epoch 44: val_loss did not improve from 16.77093
196/196 - 9s - loss: 16.7760 - MinusLogProbMetric: 16.7760 - val_loss: 16.7795 - val_MinusLogProbMetric: 16.7795 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 45/1000
2023-09-12 13:43:14.529 
Epoch 45/1000 
	 loss: 16.7789, MinusLogProbMetric: 16.7789, val_loss: 16.7963, val_MinusLogProbMetric: 16.7963

Epoch 45: val_loss did not improve from 16.77093
196/196 - 10s - loss: 16.7789 - MinusLogProbMetric: 16.7789 - val_loss: 16.7963 - val_MinusLogProbMetric: 16.7963 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 46/1000
2023-09-12 13:43:24.633 
Epoch 46/1000 
	 loss: 16.7550, MinusLogProbMetric: 16.7550, val_loss: 16.7962, val_MinusLogProbMetric: 16.7962

Epoch 46: val_loss did not improve from 16.77093
196/196 - 10s - loss: 16.7550 - MinusLogProbMetric: 16.7550 - val_loss: 16.7962 - val_MinusLogProbMetric: 16.7962 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 47/1000
2023-09-12 13:43:34.462 
Epoch 47/1000 
	 loss: 16.7873, MinusLogProbMetric: 16.7873, val_loss: 16.8148, val_MinusLogProbMetric: 16.8148

Epoch 47: val_loss did not improve from 16.77093
196/196 - 10s - loss: 16.7873 - MinusLogProbMetric: 16.7873 - val_loss: 16.8148 - val_MinusLogProbMetric: 16.8148 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 48/1000
2023-09-12 13:43:44.755 
Epoch 48/1000 
	 loss: 16.7567, MinusLogProbMetric: 16.7567, val_loss: 16.8458, val_MinusLogProbMetric: 16.8458

Epoch 48: val_loss did not improve from 16.77093
196/196 - 10s - loss: 16.7567 - MinusLogProbMetric: 16.7567 - val_loss: 16.8458 - val_MinusLogProbMetric: 16.8458 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 49/1000
2023-09-12 13:43:55.448 
Epoch 49/1000 
	 loss: 16.7547, MinusLogProbMetric: 16.7547, val_loss: 16.8769, val_MinusLogProbMetric: 16.8769

Epoch 49: val_loss did not improve from 16.77093
196/196 - 11s - loss: 16.7547 - MinusLogProbMetric: 16.7547 - val_loss: 16.8769 - val_MinusLogProbMetric: 16.8769 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 50/1000
2023-09-12 13:44:06.795 
Epoch 50/1000 
	 loss: 16.7798, MinusLogProbMetric: 16.7798, val_loss: 16.7802, val_MinusLogProbMetric: 16.7802

Epoch 50: val_loss did not improve from 16.77093
196/196 - 11s - loss: 16.7798 - MinusLogProbMetric: 16.7798 - val_loss: 16.7802 - val_MinusLogProbMetric: 16.7802 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 51/1000
2023-09-12 13:44:17.998 
Epoch 51/1000 
	 loss: 16.7384, MinusLogProbMetric: 16.7384, val_loss: 16.8599, val_MinusLogProbMetric: 16.8599

Epoch 51: val_loss did not improve from 16.77093
196/196 - 11s - loss: 16.7384 - MinusLogProbMetric: 16.7384 - val_loss: 16.8599 - val_MinusLogProbMetric: 16.8599 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 52/1000
2023-09-12 13:44:29.220 
Epoch 52/1000 
	 loss: 16.7381, MinusLogProbMetric: 16.7381, val_loss: 16.6955, val_MinusLogProbMetric: 16.6955

Epoch 52: val_loss improved from 16.77093 to 16.69553, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.7381 - MinusLogProbMetric: 16.7381 - val_loss: 16.6955 - val_MinusLogProbMetric: 16.6955 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 53/1000
2023-09-12 13:44:40.515 
Epoch 53/1000 
	 loss: 16.7532, MinusLogProbMetric: 16.7532, val_loss: 16.7298, val_MinusLogProbMetric: 16.7298

Epoch 53: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7532 - MinusLogProbMetric: 16.7532 - val_loss: 16.7298 - val_MinusLogProbMetric: 16.7298 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 54/1000
2023-09-12 13:44:51.633 
Epoch 54/1000 
	 loss: 16.7431, MinusLogProbMetric: 16.7431, val_loss: 16.7695, val_MinusLogProbMetric: 16.7695

Epoch 54: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7431 - MinusLogProbMetric: 16.7431 - val_loss: 16.7695 - val_MinusLogProbMetric: 16.7695 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 55/1000
2023-09-12 13:45:02.682 
Epoch 55/1000 
	 loss: 16.7214, MinusLogProbMetric: 16.7214, val_loss: 16.7348, val_MinusLogProbMetric: 16.7348

Epoch 55: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7214 - MinusLogProbMetric: 16.7214 - val_loss: 16.7348 - val_MinusLogProbMetric: 16.7348 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 56/1000
2023-09-12 13:45:13.803 
Epoch 56/1000 
	 loss: 16.7347, MinusLogProbMetric: 16.7347, val_loss: 16.8043, val_MinusLogProbMetric: 16.8043

Epoch 56: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7347 - MinusLogProbMetric: 16.7347 - val_loss: 16.8043 - val_MinusLogProbMetric: 16.8043 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 57/1000
2023-09-12 13:45:24.347 
Epoch 57/1000 
	 loss: 16.7291, MinusLogProbMetric: 16.7291, val_loss: 16.7639, val_MinusLogProbMetric: 16.7639

Epoch 57: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7291 - MinusLogProbMetric: 16.7291 - val_loss: 16.7639 - val_MinusLogProbMetric: 16.7639 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 58/1000
2023-09-12 13:45:35.507 
Epoch 58/1000 
	 loss: 16.7296, MinusLogProbMetric: 16.7296, val_loss: 16.7954, val_MinusLogProbMetric: 16.7954

Epoch 58: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7296 - MinusLogProbMetric: 16.7296 - val_loss: 16.7954 - val_MinusLogProbMetric: 16.7954 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 59/1000
2023-09-12 13:45:46.526 
Epoch 59/1000 
	 loss: 16.7255, MinusLogProbMetric: 16.7255, val_loss: 16.7191, val_MinusLogProbMetric: 16.7191

Epoch 59: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7255 - MinusLogProbMetric: 16.7255 - val_loss: 16.7191 - val_MinusLogProbMetric: 16.7191 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 60/1000
2023-09-12 13:45:57.666 
Epoch 60/1000 
	 loss: 16.7150, MinusLogProbMetric: 16.7150, val_loss: 16.7192, val_MinusLogProbMetric: 16.7192

Epoch 60: val_loss did not improve from 16.69553
196/196 - 11s - loss: 16.7150 - MinusLogProbMetric: 16.7150 - val_loss: 16.7192 - val_MinusLogProbMetric: 16.7192 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 61/1000
2023-09-12 13:46:08.862 
Epoch 61/1000 
	 loss: 16.7178, MinusLogProbMetric: 16.7178, val_loss: 16.6757, val_MinusLogProbMetric: 16.6757

Epoch 61: val_loss improved from 16.69553 to 16.67568, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.7178 - MinusLogProbMetric: 16.7178 - val_loss: 16.6757 - val_MinusLogProbMetric: 16.6757 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 62/1000
2023-09-12 13:46:20.186 
Epoch 62/1000 
	 loss: 16.7182, MinusLogProbMetric: 16.7182, val_loss: 16.6455, val_MinusLogProbMetric: 16.6455

Epoch 62: val_loss improved from 16.67568 to 16.64548, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.7182 - MinusLogProbMetric: 16.7182 - val_loss: 16.6455 - val_MinusLogProbMetric: 16.6455 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 63/1000
2023-09-12 13:46:29.845 
Epoch 63/1000 
	 loss: 16.7213, MinusLogProbMetric: 16.7213, val_loss: 16.6737, val_MinusLogProbMetric: 16.6737

Epoch 63: val_loss did not improve from 16.64548
196/196 - 10s - loss: 16.7213 - MinusLogProbMetric: 16.7213 - val_loss: 16.6737 - val_MinusLogProbMetric: 16.6737 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 64/1000
2023-09-12 13:46:40.650 
Epoch 64/1000 
	 loss: 16.7083, MinusLogProbMetric: 16.7083, val_loss: 16.7379, val_MinusLogProbMetric: 16.7379

Epoch 64: val_loss did not improve from 16.64548
196/196 - 11s - loss: 16.7083 - MinusLogProbMetric: 16.7083 - val_loss: 16.7379 - val_MinusLogProbMetric: 16.7379 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 65/1000
2023-09-12 13:46:51.838 
Epoch 65/1000 
	 loss: 16.7078, MinusLogProbMetric: 16.7078, val_loss: 16.7660, val_MinusLogProbMetric: 16.7660

Epoch 65: val_loss did not improve from 16.64548
196/196 - 11s - loss: 16.7078 - MinusLogProbMetric: 16.7078 - val_loss: 16.7660 - val_MinusLogProbMetric: 16.7660 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 66/1000
2023-09-12 13:47:02.973 
Epoch 66/1000 
	 loss: 16.7225, MinusLogProbMetric: 16.7225, val_loss: 16.6621, val_MinusLogProbMetric: 16.6621

Epoch 66: val_loss did not improve from 16.64548
196/196 - 11s - loss: 16.7225 - MinusLogProbMetric: 16.7225 - val_loss: 16.6621 - val_MinusLogProbMetric: 16.6621 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 67/1000
2023-09-12 13:47:12.684 
Epoch 67/1000 
	 loss: 16.7013, MinusLogProbMetric: 16.7013, val_loss: 16.7003, val_MinusLogProbMetric: 16.7003

Epoch 67: val_loss did not improve from 16.64548
196/196 - 10s - loss: 16.7013 - MinusLogProbMetric: 16.7013 - val_loss: 16.7003 - val_MinusLogProbMetric: 16.7003 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 68/1000
2023-09-12 13:47:22.127 
Epoch 68/1000 
	 loss: 16.7036, MinusLogProbMetric: 16.7036, val_loss: 16.7847, val_MinusLogProbMetric: 16.7847

Epoch 68: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.7036 - MinusLogProbMetric: 16.7036 - val_loss: 16.7847 - val_MinusLogProbMetric: 16.7847 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 69/1000
2023-09-12 13:47:31.357 
Epoch 69/1000 
	 loss: 16.7104, MinusLogProbMetric: 16.7104, val_loss: 17.0020, val_MinusLogProbMetric: 17.0020

Epoch 69: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.7104 - MinusLogProbMetric: 16.7104 - val_loss: 17.0020 - val_MinusLogProbMetric: 17.0020 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 70/1000
2023-09-12 13:47:40.429 
Epoch 70/1000 
	 loss: 16.6922, MinusLogProbMetric: 16.6922, val_loss: 16.7681, val_MinusLogProbMetric: 16.7681

Epoch 70: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6922 - MinusLogProbMetric: 16.6922 - val_loss: 16.7681 - val_MinusLogProbMetric: 16.7681 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 71/1000
2023-09-12 13:47:49.307 
Epoch 71/1000 
	 loss: 16.6878, MinusLogProbMetric: 16.6878, val_loss: 16.6917, val_MinusLogProbMetric: 16.6917

Epoch 71: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6878 - MinusLogProbMetric: 16.6878 - val_loss: 16.6917 - val_MinusLogProbMetric: 16.6917 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 72/1000
2023-09-12 13:47:58.744 
Epoch 72/1000 
	 loss: 16.7024, MinusLogProbMetric: 16.7024, val_loss: 16.6865, val_MinusLogProbMetric: 16.6865

Epoch 72: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.7024 - MinusLogProbMetric: 16.7024 - val_loss: 16.6865 - val_MinusLogProbMetric: 16.6865 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 73/1000
2023-09-12 13:48:08.072 
Epoch 73/1000 
	 loss: 16.6929, MinusLogProbMetric: 16.6929, val_loss: 16.7084, val_MinusLogProbMetric: 16.7084

Epoch 73: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6929 - MinusLogProbMetric: 16.6929 - val_loss: 16.7084 - val_MinusLogProbMetric: 16.7084 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 74/1000
2023-09-12 13:48:17.453 
Epoch 74/1000 
	 loss: 16.6986, MinusLogProbMetric: 16.6986, val_loss: 16.6937, val_MinusLogProbMetric: 16.6937

Epoch 74: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6986 - MinusLogProbMetric: 16.6986 - val_loss: 16.6937 - val_MinusLogProbMetric: 16.6937 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 75/1000
2023-09-12 13:48:26.901 
Epoch 75/1000 
	 loss: 16.6813, MinusLogProbMetric: 16.6813, val_loss: 16.7602, val_MinusLogProbMetric: 16.7602

Epoch 75: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6813 - MinusLogProbMetric: 16.6813 - val_loss: 16.7602 - val_MinusLogProbMetric: 16.7602 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 76/1000
2023-09-12 13:48:36.648 
Epoch 76/1000 
	 loss: 16.6867, MinusLogProbMetric: 16.6867, val_loss: 16.6555, val_MinusLogProbMetric: 16.6555

Epoch 76: val_loss did not improve from 16.64548
196/196 - 10s - loss: 16.6867 - MinusLogProbMetric: 16.6867 - val_loss: 16.6555 - val_MinusLogProbMetric: 16.6555 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 77/1000
2023-09-12 13:48:46.832 
Epoch 77/1000 
	 loss: 16.6891, MinusLogProbMetric: 16.6891, val_loss: 16.8497, val_MinusLogProbMetric: 16.8497

Epoch 77: val_loss did not improve from 16.64548
196/196 - 10s - loss: 16.6891 - MinusLogProbMetric: 16.6891 - val_loss: 16.8497 - val_MinusLogProbMetric: 16.8497 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 78/1000
2023-09-12 13:48:56.323 
Epoch 78/1000 
	 loss: 16.6761, MinusLogProbMetric: 16.6761, val_loss: 16.7048, val_MinusLogProbMetric: 16.7048

Epoch 78: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6761 - MinusLogProbMetric: 16.6761 - val_loss: 16.7048 - val_MinusLogProbMetric: 16.7048 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 79/1000
2023-09-12 13:49:05.880 
Epoch 79/1000 
	 loss: 16.7007, MinusLogProbMetric: 16.7007, val_loss: 16.6992, val_MinusLogProbMetric: 16.6992

Epoch 79: val_loss did not improve from 16.64548
196/196 - 10s - loss: 16.7007 - MinusLogProbMetric: 16.7007 - val_loss: 16.6992 - val_MinusLogProbMetric: 16.6992 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 80/1000
2023-09-12 13:49:15.300 
Epoch 80/1000 
	 loss: 16.6863, MinusLogProbMetric: 16.6863, val_loss: 16.6648, val_MinusLogProbMetric: 16.6648

Epoch 80: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6863 - MinusLogProbMetric: 16.6863 - val_loss: 16.6648 - val_MinusLogProbMetric: 16.6648 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 81/1000
2023-09-12 13:49:24.693 
Epoch 81/1000 
	 loss: 16.6736, MinusLogProbMetric: 16.6736, val_loss: 16.7084, val_MinusLogProbMetric: 16.7084

Epoch 81: val_loss did not improve from 16.64548
196/196 - 9s - loss: 16.6736 - MinusLogProbMetric: 16.6736 - val_loss: 16.7084 - val_MinusLogProbMetric: 16.7084 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 82/1000
2023-09-12 13:49:34.525 
Epoch 82/1000 
	 loss: 16.6681, MinusLogProbMetric: 16.6681, val_loss: 16.7199, val_MinusLogProbMetric: 16.7199

Epoch 82: val_loss did not improve from 16.64548
196/196 - 10s - loss: 16.6681 - MinusLogProbMetric: 16.6681 - val_loss: 16.7199 - val_MinusLogProbMetric: 16.7199 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 83/1000
2023-09-12 13:49:44.601 
Epoch 83/1000 
	 loss: 16.6715, MinusLogProbMetric: 16.6715, val_loss: 16.7420, val_MinusLogProbMetric: 16.7420

Epoch 83: val_loss did not improve from 16.64548
196/196 - 10s - loss: 16.6715 - MinusLogProbMetric: 16.6715 - val_loss: 16.7420 - val_MinusLogProbMetric: 16.7420 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 84/1000
2023-09-12 13:49:55.523 
Epoch 84/1000 
	 loss: 16.6860, MinusLogProbMetric: 16.6860, val_loss: 16.6335, val_MinusLogProbMetric: 16.6335

Epoch 84: val_loss improved from 16.64548 to 16.63352, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.6860 - MinusLogProbMetric: 16.6860 - val_loss: 16.6335 - val_MinusLogProbMetric: 16.6335 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 85/1000
2023-09-12 13:50:05.758 
Epoch 85/1000 
	 loss: 16.6733, MinusLogProbMetric: 16.6733, val_loss: 16.7101, val_MinusLogProbMetric: 16.7101

Epoch 85: val_loss did not improve from 16.63352
196/196 - 10s - loss: 16.6733 - MinusLogProbMetric: 16.6733 - val_loss: 16.7101 - val_MinusLogProbMetric: 16.7101 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 86/1000
2023-09-12 13:50:15.246 
Epoch 86/1000 
	 loss: 16.6816, MinusLogProbMetric: 16.6816, val_loss: 16.6964, val_MinusLogProbMetric: 16.6964

Epoch 86: val_loss did not improve from 16.63352
196/196 - 9s - loss: 16.6816 - MinusLogProbMetric: 16.6816 - val_loss: 16.6964 - val_MinusLogProbMetric: 16.6964 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 87/1000
2023-09-12 13:50:24.653 
Epoch 87/1000 
	 loss: 16.6718, MinusLogProbMetric: 16.6718, val_loss: 16.6712, val_MinusLogProbMetric: 16.6712

Epoch 87: val_loss did not improve from 16.63352
196/196 - 9s - loss: 16.6718 - MinusLogProbMetric: 16.6718 - val_loss: 16.6712 - val_MinusLogProbMetric: 16.6712 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 88/1000
2023-09-12 13:50:34.170 
Epoch 88/1000 
	 loss: 16.6619, MinusLogProbMetric: 16.6619, val_loss: 16.7696, val_MinusLogProbMetric: 16.7696

Epoch 88: val_loss did not improve from 16.63352
196/196 - 10s - loss: 16.6619 - MinusLogProbMetric: 16.6619 - val_loss: 16.7696 - val_MinusLogProbMetric: 16.7696 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 89/1000
2023-09-12 13:50:43.644 
Epoch 89/1000 
	 loss: 16.6703, MinusLogProbMetric: 16.6703, val_loss: 16.6512, val_MinusLogProbMetric: 16.6512

Epoch 89: val_loss did not improve from 16.63352
196/196 - 9s - loss: 16.6703 - MinusLogProbMetric: 16.6703 - val_loss: 16.6512 - val_MinusLogProbMetric: 16.6512 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 90/1000
2023-09-12 13:50:53.067 
Epoch 90/1000 
	 loss: 16.6678, MinusLogProbMetric: 16.6678, val_loss: 16.6795, val_MinusLogProbMetric: 16.6795

Epoch 90: val_loss did not improve from 16.63352
196/196 - 9s - loss: 16.6678 - MinusLogProbMetric: 16.6678 - val_loss: 16.6795 - val_MinusLogProbMetric: 16.6795 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 91/1000
2023-09-12 13:51:02.409 
Epoch 91/1000 
	 loss: 16.6581, MinusLogProbMetric: 16.6581, val_loss: 16.7560, val_MinusLogProbMetric: 16.7560

Epoch 91: val_loss did not improve from 16.63352
196/196 - 9s - loss: 16.6581 - MinusLogProbMetric: 16.6581 - val_loss: 16.7560 - val_MinusLogProbMetric: 16.7560 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 92/1000
2023-09-12 13:51:11.820 
Epoch 92/1000 
	 loss: 16.6561, MinusLogProbMetric: 16.6561, val_loss: 16.7744, val_MinusLogProbMetric: 16.7744

Epoch 92: val_loss did not improve from 16.63352
196/196 - 9s - loss: 16.6561 - MinusLogProbMetric: 16.6561 - val_loss: 16.7744 - val_MinusLogProbMetric: 16.7744 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 93/1000
2023-09-12 13:51:22.514 
Epoch 93/1000 
	 loss: 16.6571, MinusLogProbMetric: 16.6571, val_loss: 16.7081, val_MinusLogProbMetric: 16.7081

Epoch 93: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6571 - MinusLogProbMetric: 16.6571 - val_loss: 16.7081 - val_MinusLogProbMetric: 16.7081 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 94/1000
2023-09-12 13:51:33.596 
Epoch 94/1000 
	 loss: 16.6698, MinusLogProbMetric: 16.6698, val_loss: 16.6587, val_MinusLogProbMetric: 16.6587

Epoch 94: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6698 - MinusLogProbMetric: 16.6698 - val_loss: 16.6587 - val_MinusLogProbMetric: 16.6587 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 95/1000
2023-09-12 13:51:44.822 
Epoch 95/1000 
	 loss: 16.6536, MinusLogProbMetric: 16.6536, val_loss: 16.6703, val_MinusLogProbMetric: 16.6703

Epoch 95: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6536 - MinusLogProbMetric: 16.6536 - val_loss: 16.6703 - val_MinusLogProbMetric: 16.6703 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 96/1000
2023-09-12 13:51:56.039 
Epoch 96/1000 
	 loss: 16.6704, MinusLogProbMetric: 16.6704, val_loss: 16.6876, val_MinusLogProbMetric: 16.6876

Epoch 96: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6704 - MinusLogProbMetric: 16.6704 - val_loss: 16.6876 - val_MinusLogProbMetric: 16.6876 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 97/1000
2023-09-12 13:52:07.343 
Epoch 97/1000 
	 loss: 16.6487, MinusLogProbMetric: 16.6487, val_loss: 16.6930, val_MinusLogProbMetric: 16.6930

Epoch 97: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6487 - MinusLogProbMetric: 16.6487 - val_loss: 16.6930 - val_MinusLogProbMetric: 16.6930 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 98/1000
2023-09-12 13:52:18.475 
Epoch 98/1000 
	 loss: 16.6424, MinusLogProbMetric: 16.6424, val_loss: 16.6667, val_MinusLogProbMetric: 16.6667

Epoch 98: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6424 - MinusLogProbMetric: 16.6424 - val_loss: 16.6667 - val_MinusLogProbMetric: 16.6667 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 99/1000
2023-09-12 13:52:29.803 
Epoch 99/1000 
	 loss: 16.6590, MinusLogProbMetric: 16.6590, val_loss: 16.7301, val_MinusLogProbMetric: 16.7301

Epoch 99: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6590 - MinusLogProbMetric: 16.6590 - val_loss: 16.7301 - val_MinusLogProbMetric: 16.7301 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 100/1000
2023-09-12 13:52:40.988 
Epoch 100/1000 
	 loss: 16.6778, MinusLogProbMetric: 16.6778, val_loss: 16.6985, val_MinusLogProbMetric: 16.6985

Epoch 100: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6778 - MinusLogProbMetric: 16.6778 - val_loss: 16.6985 - val_MinusLogProbMetric: 16.6985 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 101/1000
2023-09-12 13:52:52.307 
Epoch 101/1000 
	 loss: 16.6542, MinusLogProbMetric: 16.6542, val_loss: 16.6533, val_MinusLogProbMetric: 16.6533

Epoch 101: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6542 - MinusLogProbMetric: 16.6542 - val_loss: 16.6533 - val_MinusLogProbMetric: 16.6533 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 102/1000
2023-09-12 13:53:03.516 
Epoch 102/1000 
	 loss: 16.6601, MinusLogProbMetric: 16.6601, val_loss: 16.6489, val_MinusLogProbMetric: 16.6489

Epoch 102: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6601 - MinusLogProbMetric: 16.6601 - val_loss: 16.6489 - val_MinusLogProbMetric: 16.6489 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 103/1000
2023-09-12 13:53:14.019 
Epoch 103/1000 
	 loss: 16.6368, MinusLogProbMetric: 16.6368, val_loss: 16.7089, val_MinusLogProbMetric: 16.7089

Epoch 103: val_loss did not improve from 16.63352
196/196 - 10s - loss: 16.6368 - MinusLogProbMetric: 16.6368 - val_loss: 16.7089 - val_MinusLogProbMetric: 16.7089 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 104/1000
2023-09-12 13:53:24.604 
Epoch 104/1000 
	 loss: 16.6613, MinusLogProbMetric: 16.6613, val_loss: 16.7297, val_MinusLogProbMetric: 16.7297

Epoch 104: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6613 - MinusLogProbMetric: 16.6613 - val_loss: 16.7297 - val_MinusLogProbMetric: 16.7297 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 105/1000
2023-09-12 13:53:35.866 
Epoch 105/1000 
	 loss: 16.6431, MinusLogProbMetric: 16.6431, val_loss: 16.6836, val_MinusLogProbMetric: 16.6836

Epoch 105: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6431 - MinusLogProbMetric: 16.6431 - val_loss: 16.6836 - val_MinusLogProbMetric: 16.6836 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 106/1000
2023-09-12 13:53:46.506 
Epoch 106/1000 
	 loss: 16.6432, MinusLogProbMetric: 16.6432, val_loss: 16.6503, val_MinusLogProbMetric: 16.6503

Epoch 106: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6432 - MinusLogProbMetric: 16.6432 - val_loss: 16.6503 - val_MinusLogProbMetric: 16.6503 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 107/1000
2023-09-12 13:53:57.683 
Epoch 107/1000 
	 loss: 16.6464, MinusLogProbMetric: 16.6464, val_loss: 16.6739, val_MinusLogProbMetric: 16.6739

Epoch 107: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6464 - MinusLogProbMetric: 16.6464 - val_loss: 16.6739 - val_MinusLogProbMetric: 16.6739 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 108/1000
2023-09-12 13:54:08.860 
Epoch 108/1000 
	 loss: 16.6454, MinusLogProbMetric: 16.6454, val_loss: 16.6807, val_MinusLogProbMetric: 16.6807

Epoch 108: val_loss did not improve from 16.63352
196/196 - 11s - loss: 16.6454 - MinusLogProbMetric: 16.6454 - val_loss: 16.6807 - val_MinusLogProbMetric: 16.6807 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 109/1000
2023-09-12 13:54:20.127 
Epoch 109/1000 
	 loss: 16.6410, MinusLogProbMetric: 16.6410, val_loss: 16.6284, val_MinusLogProbMetric: 16.6284

Epoch 109: val_loss improved from 16.63352 to 16.62839, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.6410 - MinusLogProbMetric: 16.6410 - val_loss: 16.6284 - val_MinusLogProbMetric: 16.6284 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 13:54:31.486 
Epoch 110/1000 
	 loss: 16.6499, MinusLogProbMetric: 16.6499, val_loss: 16.7196, val_MinusLogProbMetric: 16.7196

Epoch 110: val_loss did not improve from 16.62839
196/196 - 11s - loss: 16.6499 - MinusLogProbMetric: 16.6499 - val_loss: 16.7196 - val_MinusLogProbMetric: 16.7196 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 111/1000
2023-09-12 13:54:42.615 
Epoch 111/1000 
	 loss: 16.6350, MinusLogProbMetric: 16.6350, val_loss: 16.6999, val_MinusLogProbMetric: 16.6999

Epoch 111: val_loss did not improve from 16.62839
196/196 - 11s - loss: 16.6350 - MinusLogProbMetric: 16.6350 - val_loss: 16.6999 - val_MinusLogProbMetric: 16.6999 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 112/1000
2023-09-12 13:54:53.902 
Epoch 112/1000 
	 loss: 16.6379, MinusLogProbMetric: 16.6379, val_loss: 16.7494, val_MinusLogProbMetric: 16.7494

Epoch 112: val_loss did not improve from 16.62839
196/196 - 11s - loss: 16.6379 - MinusLogProbMetric: 16.6379 - val_loss: 16.7494 - val_MinusLogProbMetric: 16.7494 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-12 13:55:05.268 
Epoch 113/1000 
	 loss: 16.6437, MinusLogProbMetric: 16.6437, val_loss: 16.6488, val_MinusLogProbMetric: 16.6488

Epoch 113: val_loss did not improve from 16.62839
196/196 - 11s - loss: 16.6437 - MinusLogProbMetric: 16.6437 - val_loss: 16.6488 - val_MinusLogProbMetric: 16.6488 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 114/1000
2023-09-12 13:55:16.397 
Epoch 114/1000 
	 loss: 16.6415, MinusLogProbMetric: 16.6415, val_loss: 16.6629, val_MinusLogProbMetric: 16.6629

Epoch 114: val_loss did not improve from 16.62839
196/196 - 11s - loss: 16.6415 - MinusLogProbMetric: 16.6415 - val_loss: 16.6629 - val_MinusLogProbMetric: 16.6629 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 115/1000
2023-09-12 13:55:26.336 
Epoch 115/1000 
	 loss: 16.6340, MinusLogProbMetric: 16.6340, val_loss: 16.6593, val_MinusLogProbMetric: 16.6593

Epoch 115: val_loss did not improve from 16.62839
196/196 - 10s - loss: 16.6340 - MinusLogProbMetric: 16.6340 - val_loss: 16.6593 - val_MinusLogProbMetric: 16.6593 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 116/1000
2023-09-12 13:55:35.881 
Epoch 116/1000 
	 loss: 16.6310, MinusLogProbMetric: 16.6310, val_loss: 16.6155, val_MinusLogProbMetric: 16.6155

Epoch 116: val_loss improved from 16.62839 to 16.61554, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 10s - loss: 16.6310 - MinusLogProbMetric: 16.6310 - val_loss: 16.6155 - val_MinusLogProbMetric: 16.6155 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 117/1000
2023-09-12 13:55:45.546 
Epoch 117/1000 
	 loss: 16.6331, MinusLogProbMetric: 16.6331, val_loss: 16.6811, val_MinusLogProbMetric: 16.6811

Epoch 117: val_loss did not improve from 16.61554
196/196 - 10s - loss: 16.6331 - MinusLogProbMetric: 16.6331 - val_loss: 16.6811 - val_MinusLogProbMetric: 16.6811 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 118/1000
2023-09-12 13:55:55.022 
Epoch 118/1000 
	 loss: 16.6434, MinusLogProbMetric: 16.6434, val_loss: 16.7017, val_MinusLogProbMetric: 16.7017

Epoch 118: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6434 - MinusLogProbMetric: 16.6434 - val_loss: 16.7017 - val_MinusLogProbMetric: 16.7017 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 119/1000
2023-09-12 13:56:04.544 
Epoch 119/1000 
	 loss: 16.6293, MinusLogProbMetric: 16.6293, val_loss: 16.6554, val_MinusLogProbMetric: 16.6554

Epoch 119: val_loss did not improve from 16.61554
196/196 - 10s - loss: 16.6293 - MinusLogProbMetric: 16.6293 - val_loss: 16.6554 - val_MinusLogProbMetric: 16.6554 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 120/1000
2023-09-12 13:56:14.096 
Epoch 120/1000 
	 loss: 16.6232, MinusLogProbMetric: 16.6232, val_loss: 16.7675, val_MinusLogProbMetric: 16.7675

Epoch 120: val_loss did not improve from 16.61554
196/196 - 10s - loss: 16.6232 - MinusLogProbMetric: 16.6232 - val_loss: 16.7675 - val_MinusLogProbMetric: 16.7675 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 121/1000
2023-09-12 13:56:23.546 
Epoch 121/1000 
	 loss: 16.6322, MinusLogProbMetric: 16.6322, val_loss: 16.6354, val_MinusLogProbMetric: 16.6354

Epoch 121: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6322 - MinusLogProbMetric: 16.6322 - val_loss: 16.6354 - val_MinusLogProbMetric: 16.6354 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 122/1000
2023-09-12 13:56:32.982 
Epoch 122/1000 
	 loss: 16.6238, MinusLogProbMetric: 16.6238, val_loss: 16.6437, val_MinusLogProbMetric: 16.6437

Epoch 122: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6238 - MinusLogProbMetric: 16.6238 - val_loss: 16.6437 - val_MinusLogProbMetric: 16.6437 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 123/1000
2023-09-12 13:56:42.366 
Epoch 123/1000 
	 loss: 16.6286, MinusLogProbMetric: 16.6286, val_loss: 16.6639, val_MinusLogProbMetric: 16.6639

Epoch 123: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6286 - MinusLogProbMetric: 16.6286 - val_loss: 16.6639 - val_MinusLogProbMetric: 16.6639 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 124/1000
2023-09-12 13:56:51.870 
Epoch 124/1000 
	 loss: 16.6321, MinusLogProbMetric: 16.6321, val_loss: 16.6529, val_MinusLogProbMetric: 16.6529

Epoch 124: val_loss did not improve from 16.61554
196/196 - 10s - loss: 16.6321 - MinusLogProbMetric: 16.6321 - val_loss: 16.6529 - val_MinusLogProbMetric: 16.6529 - lr: 0.0010 - 10s/epoch - 48ms/step
Epoch 125/1000
2023-09-12 13:57:01.400 
Epoch 125/1000 
	 loss: 16.6375, MinusLogProbMetric: 16.6375, val_loss: 16.6513, val_MinusLogProbMetric: 16.6513

Epoch 125: val_loss did not improve from 16.61554
196/196 - 10s - loss: 16.6375 - MinusLogProbMetric: 16.6375 - val_loss: 16.6513 - val_MinusLogProbMetric: 16.6513 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 126/1000
2023-09-12 13:57:10.818 
Epoch 126/1000 
	 loss: 16.6160, MinusLogProbMetric: 16.6160, val_loss: 16.7062, val_MinusLogProbMetric: 16.7062

Epoch 126: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6160 - MinusLogProbMetric: 16.6160 - val_loss: 16.7062 - val_MinusLogProbMetric: 16.7062 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 127/1000
2023-09-12 13:57:20.284 
Epoch 127/1000 
	 loss: 16.6315, MinusLogProbMetric: 16.6315, val_loss: 16.6911, val_MinusLogProbMetric: 16.6911

Epoch 127: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6315 - MinusLogProbMetric: 16.6315 - val_loss: 16.6911 - val_MinusLogProbMetric: 16.6911 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 128/1000
2023-09-12 13:57:29.728 
Epoch 128/1000 
	 loss: 16.6199, MinusLogProbMetric: 16.6199, val_loss: 16.7179, val_MinusLogProbMetric: 16.7179

Epoch 128: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6199 - MinusLogProbMetric: 16.6199 - val_loss: 16.7179 - val_MinusLogProbMetric: 16.7179 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 129/1000
2023-09-12 13:57:39.217 
Epoch 129/1000 
	 loss: 16.6177, MinusLogProbMetric: 16.6177, val_loss: 16.7108, val_MinusLogProbMetric: 16.7108

Epoch 129: val_loss did not improve from 16.61554
196/196 - 9s - loss: 16.6177 - MinusLogProbMetric: 16.6177 - val_loss: 16.7108 - val_MinusLogProbMetric: 16.7108 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 130/1000
2023-09-12 13:57:49.790 
Epoch 130/1000 
	 loss: 16.6255, MinusLogProbMetric: 16.6255, val_loss: 16.6222, val_MinusLogProbMetric: 16.6222

Epoch 130: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6255 - MinusLogProbMetric: 16.6255 - val_loss: 16.6222 - val_MinusLogProbMetric: 16.6222 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 131/1000
2023-09-12 13:58:00.984 
Epoch 131/1000 
	 loss: 16.6518, MinusLogProbMetric: 16.6518, val_loss: 16.6436, val_MinusLogProbMetric: 16.6436

Epoch 131: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6518 - MinusLogProbMetric: 16.6518 - val_loss: 16.6436 - val_MinusLogProbMetric: 16.6436 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 132/1000
2023-09-12 13:58:12.196 
Epoch 132/1000 
	 loss: 16.6279, MinusLogProbMetric: 16.6279, val_loss: 16.6656, val_MinusLogProbMetric: 16.6656

Epoch 132: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6279 - MinusLogProbMetric: 16.6279 - val_loss: 16.6656 - val_MinusLogProbMetric: 16.6656 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 133/1000
2023-09-12 13:58:23.424 
Epoch 133/1000 
	 loss: 16.6173, MinusLogProbMetric: 16.6173, val_loss: 16.6277, val_MinusLogProbMetric: 16.6277

Epoch 133: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6173 - MinusLogProbMetric: 16.6173 - val_loss: 16.6277 - val_MinusLogProbMetric: 16.6277 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 134/1000
2023-09-12 13:58:34.752 
Epoch 134/1000 
	 loss: 16.6124, MinusLogProbMetric: 16.6124, val_loss: 16.6356, val_MinusLogProbMetric: 16.6356

Epoch 134: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6124 - MinusLogProbMetric: 16.6124 - val_loss: 16.6356 - val_MinusLogProbMetric: 16.6356 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 135/1000
2023-09-12 13:58:45.904 
Epoch 135/1000 
	 loss: 16.6095, MinusLogProbMetric: 16.6095, val_loss: 16.6872, val_MinusLogProbMetric: 16.6872

Epoch 135: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6095 - MinusLogProbMetric: 16.6095 - val_loss: 16.6872 - val_MinusLogProbMetric: 16.6872 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 136/1000
2023-09-12 13:58:57.243 
Epoch 136/1000 
	 loss: 16.6104, MinusLogProbMetric: 16.6104, val_loss: 16.6300, val_MinusLogProbMetric: 16.6300

Epoch 136: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6104 - MinusLogProbMetric: 16.6104 - val_loss: 16.6300 - val_MinusLogProbMetric: 16.6300 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 137/1000
2023-09-12 13:59:08.553 
Epoch 137/1000 
	 loss: 16.6168, MinusLogProbMetric: 16.6168, val_loss: 16.8204, val_MinusLogProbMetric: 16.8204

Epoch 137: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6168 - MinusLogProbMetric: 16.6168 - val_loss: 16.8204 - val_MinusLogProbMetric: 16.8204 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 138/1000
2023-09-12 13:59:19.813 
Epoch 138/1000 
	 loss: 16.6199, MinusLogProbMetric: 16.6199, val_loss: 16.7050, val_MinusLogProbMetric: 16.7050

Epoch 138: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6199 - MinusLogProbMetric: 16.6199 - val_loss: 16.7050 - val_MinusLogProbMetric: 16.7050 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 139/1000
2023-09-12 13:59:30.927 
Epoch 139/1000 
	 loss: 16.6265, MinusLogProbMetric: 16.6265, val_loss: 16.6543, val_MinusLogProbMetric: 16.6543

Epoch 139: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6265 - MinusLogProbMetric: 16.6265 - val_loss: 16.6543 - val_MinusLogProbMetric: 16.6543 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 140/1000
2023-09-12 13:59:42.133 
Epoch 140/1000 
	 loss: 16.6062, MinusLogProbMetric: 16.6062, val_loss: 16.7122, val_MinusLogProbMetric: 16.7122

Epoch 140: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6062 - MinusLogProbMetric: 16.6062 - val_loss: 16.7122 - val_MinusLogProbMetric: 16.7122 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 141/1000
2023-09-12 13:59:53.513 
Epoch 141/1000 
	 loss: 16.6284, MinusLogProbMetric: 16.6284, val_loss: 16.6925, val_MinusLogProbMetric: 16.6925

Epoch 141: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6284 - MinusLogProbMetric: 16.6284 - val_loss: 16.6925 - val_MinusLogProbMetric: 16.6925 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 142/1000
2023-09-12 14:00:04.752 
Epoch 142/1000 
	 loss: 16.6049, MinusLogProbMetric: 16.6049, val_loss: 16.6901, val_MinusLogProbMetric: 16.6901

Epoch 142: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6049 - MinusLogProbMetric: 16.6049 - val_loss: 16.6901 - val_MinusLogProbMetric: 16.6901 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 143/1000
2023-09-12 14:00:16.068 
Epoch 143/1000 
	 loss: 16.6114, MinusLogProbMetric: 16.6114, val_loss: 16.6601, val_MinusLogProbMetric: 16.6601

Epoch 143: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6114 - MinusLogProbMetric: 16.6114 - val_loss: 16.6601 - val_MinusLogProbMetric: 16.6601 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-12 14:00:27.421 
Epoch 144/1000 
	 loss: 16.6148, MinusLogProbMetric: 16.6148, val_loss: 16.6710, val_MinusLogProbMetric: 16.6710

Epoch 144: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6148 - MinusLogProbMetric: 16.6148 - val_loss: 16.6710 - val_MinusLogProbMetric: 16.6710 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 145/1000
2023-09-12 14:00:38.737 
Epoch 145/1000 
	 loss: 16.6062, MinusLogProbMetric: 16.6062, val_loss: 16.6226, val_MinusLogProbMetric: 16.6226

Epoch 145: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6062 - MinusLogProbMetric: 16.6062 - val_loss: 16.6226 - val_MinusLogProbMetric: 16.6226 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 146/1000
2023-09-12 14:00:50.102 
Epoch 146/1000 
	 loss: 16.6169, MinusLogProbMetric: 16.6169, val_loss: 16.6983, val_MinusLogProbMetric: 16.6983

Epoch 146: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6169 - MinusLogProbMetric: 16.6169 - val_loss: 16.6983 - val_MinusLogProbMetric: 16.6983 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-12 14:01:01.336 
Epoch 147/1000 
	 loss: 16.6124, MinusLogProbMetric: 16.6124, val_loss: 16.6186, val_MinusLogProbMetric: 16.6186

Epoch 147: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6124 - MinusLogProbMetric: 16.6124 - val_loss: 16.6186 - val_MinusLogProbMetric: 16.6186 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 148/1000
2023-09-12 14:01:12.685 
Epoch 148/1000 
	 loss: 16.6097, MinusLogProbMetric: 16.6097, val_loss: 16.6609, val_MinusLogProbMetric: 16.6609

Epoch 148: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6097 - MinusLogProbMetric: 16.6097 - val_loss: 16.6609 - val_MinusLogProbMetric: 16.6609 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 149/1000
2023-09-12 14:01:24.048 
Epoch 149/1000 
	 loss: 16.6079, MinusLogProbMetric: 16.6079, val_loss: 16.6213, val_MinusLogProbMetric: 16.6213

Epoch 149: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6079 - MinusLogProbMetric: 16.6079 - val_loss: 16.6213 - val_MinusLogProbMetric: 16.6213 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-12 14:01:35.295 
Epoch 150/1000 
	 loss: 16.6052, MinusLogProbMetric: 16.6052, val_loss: 16.6966, val_MinusLogProbMetric: 16.6966

Epoch 150: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6052 - MinusLogProbMetric: 16.6052 - val_loss: 16.6966 - val_MinusLogProbMetric: 16.6966 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 151/1000
2023-09-12 14:01:46.531 
Epoch 151/1000 
	 loss: 16.6163, MinusLogProbMetric: 16.6163, val_loss: 16.6604, val_MinusLogProbMetric: 16.6604

Epoch 151: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6163 - MinusLogProbMetric: 16.6163 - val_loss: 16.6604 - val_MinusLogProbMetric: 16.6604 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 152/1000
2023-09-12 14:01:57.790 
Epoch 152/1000 
	 loss: 16.6194, MinusLogProbMetric: 16.6194, val_loss: 16.6372, val_MinusLogProbMetric: 16.6372

Epoch 152: val_loss did not improve from 16.61554
196/196 - 11s - loss: 16.6194 - MinusLogProbMetric: 16.6194 - val_loss: 16.6372 - val_MinusLogProbMetric: 16.6372 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 153/1000
2023-09-12 14:02:09.062 
Epoch 153/1000 
	 loss: 16.6118, MinusLogProbMetric: 16.6118, val_loss: 16.6044, val_MinusLogProbMetric: 16.6044

Epoch 153: val_loss improved from 16.61554 to 16.60442, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.6118 - MinusLogProbMetric: 16.6118 - val_loss: 16.6044 - val_MinusLogProbMetric: 16.6044 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 154/1000
2023-09-12 14:02:20.639 
Epoch 154/1000 
	 loss: 16.6058, MinusLogProbMetric: 16.6058, val_loss: 16.6659, val_MinusLogProbMetric: 16.6659

Epoch 154: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6058 - MinusLogProbMetric: 16.6058 - val_loss: 16.6659 - val_MinusLogProbMetric: 16.6659 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 155/1000
2023-09-12 14:02:31.895 
Epoch 155/1000 
	 loss: 16.5973, MinusLogProbMetric: 16.5973, val_loss: 16.6123, val_MinusLogProbMetric: 16.6123

Epoch 155: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5973 - MinusLogProbMetric: 16.5973 - val_loss: 16.6123 - val_MinusLogProbMetric: 16.6123 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 156/1000
2023-09-12 14:02:43.341 
Epoch 156/1000 
	 loss: 16.6096, MinusLogProbMetric: 16.6096, val_loss: 16.7061, val_MinusLogProbMetric: 16.7061

Epoch 156: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6096 - MinusLogProbMetric: 16.6096 - val_loss: 16.7061 - val_MinusLogProbMetric: 16.7061 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 157/1000
2023-09-12 14:02:54.654 
Epoch 157/1000 
	 loss: 16.5994, MinusLogProbMetric: 16.5994, val_loss: 16.6948, val_MinusLogProbMetric: 16.6948

Epoch 157: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5994 - MinusLogProbMetric: 16.5994 - val_loss: 16.6948 - val_MinusLogProbMetric: 16.6948 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 158/1000
2023-09-12 14:03:06.006 
Epoch 158/1000 
	 loss: 16.6099, MinusLogProbMetric: 16.6099, val_loss: 16.6552, val_MinusLogProbMetric: 16.6552

Epoch 158: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6099 - MinusLogProbMetric: 16.6099 - val_loss: 16.6552 - val_MinusLogProbMetric: 16.6552 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 159/1000
2023-09-12 14:03:17.138 
Epoch 159/1000 
	 loss: 16.5924, MinusLogProbMetric: 16.5924, val_loss: 16.7407, val_MinusLogProbMetric: 16.7407

Epoch 159: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5924 - MinusLogProbMetric: 16.5924 - val_loss: 16.7407 - val_MinusLogProbMetric: 16.7407 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 160/1000
2023-09-12 14:03:28.499 
Epoch 160/1000 
	 loss: 16.5976, MinusLogProbMetric: 16.5976, val_loss: 16.6398, val_MinusLogProbMetric: 16.6398

Epoch 160: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5976 - MinusLogProbMetric: 16.5976 - val_loss: 16.6398 - val_MinusLogProbMetric: 16.6398 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 161/1000
2023-09-12 14:03:39.599 
Epoch 161/1000 
	 loss: 16.5943, MinusLogProbMetric: 16.5943, val_loss: 16.7062, val_MinusLogProbMetric: 16.7062

Epoch 161: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5943 - MinusLogProbMetric: 16.5943 - val_loss: 16.7062 - val_MinusLogProbMetric: 16.7062 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 162/1000
2023-09-12 14:03:50.562 
Epoch 162/1000 
	 loss: 16.6053, MinusLogProbMetric: 16.6053, val_loss: 16.6594, val_MinusLogProbMetric: 16.6594

Epoch 162: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6053 - MinusLogProbMetric: 16.6053 - val_loss: 16.6594 - val_MinusLogProbMetric: 16.6594 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 163/1000
2023-09-12 14:04:01.511 
Epoch 163/1000 
	 loss: 16.6022, MinusLogProbMetric: 16.6022, val_loss: 16.7897, val_MinusLogProbMetric: 16.7897

Epoch 163: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6022 - MinusLogProbMetric: 16.6022 - val_loss: 16.7897 - val_MinusLogProbMetric: 16.7897 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 164/1000
2023-09-12 14:04:12.484 
Epoch 164/1000 
	 loss: 16.6038, MinusLogProbMetric: 16.6038, val_loss: 16.6807, val_MinusLogProbMetric: 16.6807

Epoch 164: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6038 - MinusLogProbMetric: 16.6038 - val_loss: 16.6807 - val_MinusLogProbMetric: 16.6807 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 165/1000
2023-09-12 14:04:23.520 
Epoch 165/1000 
	 loss: 16.5967, MinusLogProbMetric: 16.5967, val_loss: 16.7331, val_MinusLogProbMetric: 16.7331

Epoch 165: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5967 - MinusLogProbMetric: 16.5967 - val_loss: 16.7331 - val_MinusLogProbMetric: 16.7331 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 166/1000
2023-09-12 14:04:34.419 
Epoch 166/1000 
	 loss: 16.5922, MinusLogProbMetric: 16.5922, val_loss: 16.6589, val_MinusLogProbMetric: 16.6589

Epoch 166: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5922 - MinusLogProbMetric: 16.5922 - val_loss: 16.6589 - val_MinusLogProbMetric: 16.6589 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 167/1000
2023-09-12 14:04:45.201 
Epoch 167/1000 
	 loss: 16.5946, MinusLogProbMetric: 16.5946, val_loss: 16.8906, val_MinusLogProbMetric: 16.8906

Epoch 167: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5946 - MinusLogProbMetric: 16.5946 - val_loss: 16.8906 - val_MinusLogProbMetric: 16.8906 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 168/1000
2023-09-12 14:04:56.053 
Epoch 168/1000 
	 loss: 16.5916, MinusLogProbMetric: 16.5916, val_loss: 16.6818, val_MinusLogProbMetric: 16.6818

Epoch 168: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5916 - MinusLogProbMetric: 16.5916 - val_loss: 16.6818 - val_MinusLogProbMetric: 16.6818 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 169/1000
2023-09-12 14:05:06.883 
Epoch 169/1000 
	 loss: 16.5968, MinusLogProbMetric: 16.5968, val_loss: 16.6179, val_MinusLogProbMetric: 16.6179

Epoch 169: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5968 - MinusLogProbMetric: 16.5968 - val_loss: 16.6179 - val_MinusLogProbMetric: 16.6179 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 170/1000
2023-09-12 14:05:17.689 
Epoch 170/1000 
	 loss: 16.6023, MinusLogProbMetric: 16.6023, val_loss: 16.6979, val_MinusLogProbMetric: 16.6979

Epoch 170: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6023 - MinusLogProbMetric: 16.6023 - val_loss: 16.6979 - val_MinusLogProbMetric: 16.6979 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 171/1000
2023-09-12 14:05:28.807 
Epoch 171/1000 
	 loss: 16.5932, MinusLogProbMetric: 16.5932, val_loss: 16.6998, val_MinusLogProbMetric: 16.6998

Epoch 171: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5932 - MinusLogProbMetric: 16.5932 - val_loss: 16.6998 - val_MinusLogProbMetric: 16.6998 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 172/1000
2023-09-12 14:05:39.773 
Epoch 172/1000 
	 loss: 16.5926, MinusLogProbMetric: 16.5926, val_loss: 16.6340, val_MinusLogProbMetric: 16.6340

Epoch 172: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5926 - MinusLogProbMetric: 16.5926 - val_loss: 16.6340 - val_MinusLogProbMetric: 16.6340 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 173/1000
2023-09-12 14:05:50.737 
Epoch 173/1000 
	 loss: 16.5891, MinusLogProbMetric: 16.5891, val_loss: 16.7172, val_MinusLogProbMetric: 16.7172

Epoch 173: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5891 - MinusLogProbMetric: 16.5891 - val_loss: 16.7172 - val_MinusLogProbMetric: 16.7172 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 174/1000
2023-09-12 14:06:01.491 
Epoch 174/1000 
	 loss: 16.5942, MinusLogProbMetric: 16.5942, val_loss: 16.7834, val_MinusLogProbMetric: 16.7834

Epoch 174: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5942 - MinusLogProbMetric: 16.5942 - val_loss: 16.7834 - val_MinusLogProbMetric: 16.7834 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 175/1000
2023-09-12 14:06:12.199 
Epoch 175/1000 
	 loss: 16.5924, MinusLogProbMetric: 16.5924, val_loss: 16.7100, val_MinusLogProbMetric: 16.7100

Epoch 175: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5924 - MinusLogProbMetric: 16.5924 - val_loss: 16.7100 - val_MinusLogProbMetric: 16.7100 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 176/1000
2023-09-12 14:06:23.232 
Epoch 176/1000 
	 loss: 16.5987, MinusLogProbMetric: 16.5987, val_loss: 16.6419, val_MinusLogProbMetric: 16.6419

Epoch 176: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5987 - MinusLogProbMetric: 16.5987 - val_loss: 16.6419 - val_MinusLogProbMetric: 16.6419 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 177/1000
2023-09-12 14:06:34.027 
Epoch 177/1000 
	 loss: 16.5914, MinusLogProbMetric: 16.5914, val_loss: 16.6223, val_MinusLogProbMetric: 16.6223

Epoch 177: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5914 - MinusLogProbMetric: 16.5914 - val_loss: 16.6223 - val_MinusLogProbMetric: 16.6223 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 178/1000
2023-09-12 14:06:44.736 
Epoch 178/1000 
	 loss: 16.5906, MinusLogProbMetric: 16.5906, val_loss: 16.6921, val_MinusLogProbMetric: 16.6921

Epoch 178: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5906 - MinusLogProbMetric: 16.5906 - val_loss: 16.6921 - val_MinusLogProbMetric: 16.6921 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 179/1000
2023-09-12 14:06:55.612 
Epoch 179/1000 
	 loss: 16.5948, MinusLogProbMetric: 16.5948, val_loss: 16.6673, val_MinusLogProbMetric: 16.6673

Epoch 179: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5948 - MinusLogProbMetric: 16.5948 - val_loss: 16.6673 - val_MinusLogProbMetric: 16.6673 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 180/1000
2023-09-12 14:07:06.351 
Epoch 180/1000 
	 loss: 16.5875, MinusLogProbMetric: 16.5875, val_loss: 16.6602, val_MinusLogProbMetric: 16.6602

Epoch 180: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5875 - MinusLogProbMetric: 16.5875 - val_loss: 16.6602 - val_MinusLogProbMetric: 16.6602 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 181/1000
2023-09-12 14:07:16.960 
Epoch 181/1000 
	 loss: 16.6059, MinusLogProbMetric: 16.6059, val_loss: 16.6415, val_MinusLogProbMetric: 16.6415

Epoch 181: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.6059 - MinusLogProbMetric: 16.6059 - val_loss: 16.6415 - val_MinusLogProbMetric: 16.6415 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 182/1000
2023-09-12 14:07:27.912 
Epoch 182/1000 
	 loss: 16.5864, MinusLogProbMetric: 16.5864, val_loss: 16.6882, val_MinusLogProbMetric: 16.6882

Epoch 182: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5864 - MinusLogProbMetric: 16.5864 - val_loss: 16.6882 - val_MinusLogProbMetric: 16.6882 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 183/1000
2023-09-12 14:07:38.737 
Epoch 183/1000 
	 loss: 16.5885, MinusLogProbMetric: 16.5885, val_loss: 16.6612, val_MinusLogProbMetric: 16.6612

Epoch 183: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5885 - MinusLogProbMetric: 16.5885 - val_loss: 16.6612 - val_MinusLogProbMetric: 16.6612 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 184/1000
2023-09-12 14:07:49.617 
Epoch 184/1000 
	 loss: 16.5924, MinusLogProbMetric: 16.5924, val_loss: 16.6288, val_MinusLogProbMetric: 16.6288

Epoch 184: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5924 - MinusLogProbMetric: 16.5924 - val_loss: 16.6288 - val_MinusLogProbMetric: 16.6288 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 185/1000
2023-09-12 14:08:00.323 
Epoch 185/1000 
	 loss: 16.5823, MinusLogProbMetric: 16.5823, val_loss: 16.6247, val_MinusLogProbMetric: 16.6247

Epoch 185: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5823 - MinusLogProbMetric: 16.5823 - val_loss: 16.6247 - val_MinusLogProbMetric: 16.6247 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 186/1000
2023-09-12 14:08:11.227 
Epoch 186/1000 
	 loss: 16.5910, MinusLogProbMetric: 16.5910, val_loss: 16.6368, val_MinusLogProbMetric: 16.6368

Epoch 186: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5910 - MinusLogProbMetric: 16.5910 - val_loss: 16.6368 - val_MinusLogProbMetric: 16.6368 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 187/1000
2023-09-12 14:08:22.286 
Epoch 187/1000 
	 loss: 16.5909, MinusLogProbMetric: 16.5909, val_loss: 16.6717, val_MinusLogProbMetric: 16.6717

Epoch 187: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5909 - MinusLogProbMetric: 16.5909 - val_loss: 16.6717 - val_MinusLogProbMetric: 16.6717 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 188/1000
2023-09-12 14:08:33.270 
Epoch 188/1000 
	 loss: 16.5777, MinusLogProbMetric: 16.5777, val_loss: 16.6793, val_MinusLogProbMetric: 16.6793

Epoch 188: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5777 - MinusLogProbMetric: 16.5777 - val_loss: 16.6793 - val_MinusLogProbMetric: 16.6793 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 189/1000
2023-09-12 14:08:44.236 
Epoch 189/1000 
	 loss: 16.5970, MinusLogProbMetric: 16.5970, val_loss: 16.6301, val_MinusLogProbMetric: 16.6301

Epoch 189: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5970 - MinusLogProbMetric: 16.5970 - val_loss: 16.6301 - val_MinusLogProbMetric: 16.6301 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 190/1000
2023-09-12 14:08:55.183 
Epoch 190/1000 
	 loss: 16.5869, MinusLogProbMetric: 16.5869, val_loss: 16.7142, val_MinusLogProbMetric: 16.7142

Epoch 190: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5869 - MinusLogProbMetric: 16.5869 - val_loss: 16.7142 - val_MinusLogProbMetric: 16.7142 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 191/1000
2023-09-12 14:09:06.207 
Epoch 191/1000 
	 loss: 16.5741, MinusLogProbMetric: 16.5741, val_loss: 16.6444, val_MinusLogProbMetric: 16.6444

Epoch 191: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5741 - MinusLogProbMetric: 16.5741 - val_loss: 16.6444 - val_MinusLogProbMetric: 16.6444 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 192/1000
2023-09-12 14:09:17.165 
Epoch 192/1000 
	 loss: 16.5812, MinusLogProbMetric: 16.5812, val_loss: 16.6639, val_MinusLogProbMetric: 16.6639

Epoch 192: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5812 - MinusLogProbMetric: 16.5812 - val_loss: 16.6639 - val_MinusLogProbMetric: 16.6639 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 193/1000
2023-09-12 14:09:28.152 
Epoch 193/1000 
	 loss: 16.5789, MinusLogProbMetric: 16.5789, val_loss: 16.6633, val_MinusLogProbMetric: 16.6633

Epoch 193: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5789 - MinusLogProbMetric: 16.5789 - val_loss: 16.6633 - val_MinusLogProbMetric: 16.6633 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 194/1000
2023-09-12 14:09:39.176 
Epoch 194/1000 
	 loss: 16.5785, MinusLogProbMetric: 16.5785, val_loss: 16.6336, val_MinusLogProbMetric: 16.6336

Epoch 194: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5785 - MinusLogProbMetric: 16.5785 - val_loss: 16.6336 - val_MinusLogProbMetric: 16.6336 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 195/1000
2023-09-12 14:09:50.043 
Epoch 195/1000 
	 loss: 16.5784, MinusLogProbMetric: 16.5784, val_loss: 16.6214, val_MinusLogProbMetric: 16.6214

Epoch 195: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5784 - MinusLogProbMetric: 16.5784 - val_loss: 16.6214 - val_MinusLogProbMetric: 16.6214 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 196/1000
2023-09-12 14:10:01.132 
Epoch 196/1000 
	 loss: 16.5786, MinusLogProbMetric: 16.5786, val_loss: 16.7333, val_MinusLogProbMetric: 16.7333

Epoch 196: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5786 - MinusLogProbMetric: 16.5786 - val_loss: 16.7333 - val_MinusLogProbMetric: 16.7333 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 197/1000
2023-09-12 14:10:12.425 
Epoch 197/1000 
	 loss: 16.5936, MinusLogProbMetric: 16.5936, val_loss: 16.6811, val_MinusLogProbMetric: 16.6811

Epoch 197: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5936 - MinusLogProbMetric: 16.5936 - val_loss: 16.6811 - val_MinusLogProbMetric: 16.6811 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 198/1000
2023-09-12 14:10:23.300 
Epoch 198/1000 
	 loss: 16.5912, MinusLogProbMetric: 16.5912, val_loss: 16.6388, val_MinusLogProbMetric: 16.6388

Epoch 198: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5912 - MinusLogProbMetric: 16.5912 - val_loss: 16.6388 - val_MinusLogProbMetric: 16.6388 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 199/1000
2023-09-12 14:10:34.306 
Epoch 199/1000 
	 loss: 16.5717, MinusLogProbMetric: 16.5717, val_loss: 16.6791, val_MinusLogProbMetric: 16.6791

Epoch 199: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5717 - MinusLogProbMetric: 16.5717 - val_loss: 16.6791 - val_MinusLogProbMetric: 16.6791 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 200/1000
2023-09-12 14:10:45.294 
Epoch 200/1000 
	 loss: 16.5741, MinusLogProbMetric: 16.5741, val_loss: 16.6609, val_MinusLogProbMetric: 16.6609

Epoch 200: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5741 - MinusLogProbMetric: 16.5741 - val_loss: 16.6609 - val_MinusLogProbMetric: 16.6609 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 201/1000
2023-09-12 14:10:56.421 
Epoch 201/1000 
	 loss: 16.5853, MinusLogProbMetric: 16.5853, val_loss: 16.6672, val_MinusLogProbMetric: 16.6672

Epoch 201: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5853 - MinusLogProbMetric: 16.5853 - val_loss: 16.6672 - val_MinusLogProbMetric: 16.6672 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 202/1000
2023-09-12 14:11:07.477 
Epoch 202/1000 
	 loss: 16.5863, MinusLogProbMetric: 16.5863, val_loss: 16.6271, val_MinusLogProbMetric: 16.6271

Epoch 202: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5863 - MinusLogProbMetric: 16.5863 - val_loss: 16.6271 - val_MinusLogProbMetric: 16.6271 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 203/1000
2023-09-12 14:11:18.298 
Epoch 203/1000 
	 loss: 16.5623, MinusLogProbMetric: 16.5623, val_loss: 16.6838, val_MinusLogProbMetric: 16.6838

Epoch 203: val_loss did not improve from 16.60442
196/196 - 11s - loss: 16.5623 - MinusLogProbMetric: 16.5623 - val_loss: 16.6838 - val_MinusLogProbMetric: 16.6838 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 204/1000
2023-09-12 14:11:29.129 
Epoch 204/1000 
	 loss: 16.5192, MinusLogProbMetric: 16.5192, val_loss: 16.5842, val_MinusLogProbMetric: 16.5842

Epoch 204: val_loss improved from 16.60442 to 16.58417, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_137/weights/best_weights.h5
196/196 - 11s - loss: 16.5192 - MinusLogProbMetric: 16.5192 - val_loss: 16.5842 - val_MinusLogProbMetric: 16.5842 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 205/1000
2023-09-12 14:11:40.311 
Epoch 205/1000 
	 loss: 16.5283, MinusLogProbMetric: 16.5283, val_loss: 16.6294, val_MinusLogProbMetric: 16.6294

Epoch 205: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5283 - MinusLogProbMetric: 16.5283 - val_loss: 16.6294 - val_MinusLogProbMetric: 16.6294 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 206/1000
2023-09-12 14:11:51.424 
Epoch 206/1000 
	 loss: 16.5203, MinusLogProbMetric: 16.5203, val_loss: 16.5848, val_MinusLogProbMetric: 16.5848

Epoch 206: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5203 - MinusLogProbMetric: 16.5203 - val_loss: 16.5848 - val_MinusLogProbMetric: 16.5848 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 207/1000
2023-09-12 14:12:02.515 
Epoch 207/1000 
	 loss: 16.5170, MinusLogProbMetric: 16.5170, val_loss: 16.6081, val_MinusLogProbMetric: 16.6081

Epoch 207: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5170 - MinusLogProbMetric: 16.5170 - val_loss: 16.6081 - val_MinusLogProbMetric: 16.6081 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 208/1000
2023-09-12 14:12:13.410 
Epoch 208/1000 
	 loss: 16.5216, MinusLogProbMetric: 16.5216, val_loss: 16.5963, val_MinusLogProbMetric: 16.5963

Epoch 208: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5216 - MinusLogProbMetric: 16.5216 - val_loss: 16.5963 - val_MinusLogProbMetric: 16.5963 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 209/1000
2023-09-12 14:12:24.454 
Epoch 209/1000 
	 loss: 16.5168, MinusLogProbMetric: 16.5168, val_loss: 16.6054, val_MinusLogProbMetric: 16.6054

Epoch 209: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5168 - MinusLogProbMetric: 16.5168 - val_loss: 16.6054 - val_MinusLogProbMetric: 16.6054 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 210/1000
2023-09-12 14:12:33.895 
Epoch 210/1000 
	 loss: 16.5148, MinusLogProbMetric: 16.5148, val_loss: 16.6007, val_MinusLogProbMetric: 16.6007

Epoch 210: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.5148 - MinusLogProbMetric: 16.5148 - val_loss: 16.6007 - val_MinusLogProbMetric: 16.6007 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 211/1000
2023-09-12 14:12:45.028 
Epoch 211/1000 
	 loss: 16.5203, MinusLogProbMetric: 16.5203, val_loss: 16.5884, val_MinusLogProbMetric: 16.5884

Epoch 211: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5203 - MinusLogProbMetric: 16.5203 - val_loss: 16.5884 - val_MinusLogProbMetric: 16.5884 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 212/1000
2023-09-12 14:12:56.066 
Epoch 212/1000 
	 loss: 16.5175, MinusLogProbMetric: 16.5175, val_loss: 16.6002, val_MinusLogProbMetric: 16.6002

Epoch 212: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5175 - MinusLogProbMetric: 16.5175 - val_loss: 16.6002 - val_MinusLogProbMetric: 16.6002 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 213/1000
2023-09-12 14:13:07.104 
Epoch 213/1000 
	 loss: 16.5182, MinusLogProbMetric: 16.5182, val_loss: 16.5955, val_MinusLogProbMetric: 16.5955

Epoch 213: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5182 - MinusLogProbMetric: 16.5182 - val_loss: 16.5955 - val_MinusLogProbMetric: 16.5955 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 214/1000
2023-09-12 14:13:17.997 
Epoch 214/1000 
	 loss: 16.5140, MinusLogProbMetric: 16.5140, val_loss: 16.6118, val_MinusLogProbMetric: 16.6118

Epoch 214: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5140 - MinusLogProbMetric: 16.5140 - val_loss: 16.6118 - val_MinusLogProbMetric: 16.6118 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 215/1000
2023-09-12 14:13:28.996 
Epoch 215/1000 
	 loss: 16.5165, MinusLogProbMetric: 16.5165, val_loss: 16.6001, val_MinusLogProbMetric: 16.6001

Epoch 215: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5165 - MinusLogProbMetric: 16.5165 - val_loss: 16.6001 - val_MinusLogProbMetric: 16.6001 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 216/1000
2023-09-12 14:13:39.863 
Epoch 216/1000 
	 loss: 16.5146, MinusLogProbMetric: 16.5146, val_loss: 16.5961, val_MinusLogProbMetric: 16.5961

Epoch 216: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5146 - MinusLogProbMetric: 16.5146 - val_loss: 16.5961 - val_MinusLogProbMetric: 16.5961 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 217/1000
2023-09-12 14:13:50.916 
Epoch 217/1000 
	 loss: 16.5174, MinusLogProbMetric: 16.5174, val_loss: 16.6210, val_MinusLogProbMetric: 16.6210

Epoch 217: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5174 - MinusLogProbMetric: 16.5174 - val_loss: 16.6210 - val_MinusLogProbMetric: 16.6210 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 218/1000
2023-09-12 14:14:01.774 
Epoch 218/1000 
	 loss: 16.5231, MinusLogProbMetric: 16.5231, val_loss: 16.5894, val_MinusLogProbMetric: 16.5894

Epoch 218: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5231 - MinusLogProbMetric: 16.5231 - val_loss: 16.5894 - val_MinusLogProbMetric: 16.5894 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 219/1000
2023-09-12 14:14:12.844 
Epoch 219/1000 
	 loss: 16.5099, MinusLogProbMetric: 16.5099, val_loss: 16.5877, val_MinusLogProbMetric: 16.5877

Epoch 219: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5099 - MinusLogProbMetric: 16.5099 - val_loss: 16.5877 - val_MinusLogProbMetric: 16.5877 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 220/1000
2023-09-12 14:14:23.912 
Epoch 220/1000 
	 loss: 16.5131, MinusLogProbMetric: 16.5131, val_loss: 16.6387, val_MinusLogProbMetric: 16.6387

Epoch 220: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5131 - MinusLogProbMetric: 16.5131 - val_loss: 16.6387 - val_MinusLogProbMetric: 16.6387 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 221/1000
2023-09-12 14:14:34.883 
Epoch 221/1000 
	 loss: 16.5183, MinusLogProbMetric: 16.5183, val_loss: 16.6163, val_MinusLogProbMetric: 16.6163

Epoch 221: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5183 - MinusLogProbMetric: 16.5183 - val_loss: 16.6163 - val_MinusLogProbMetric: 16.6163 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 222/1000
2023-09-12 14:14:45.766 
Epoch 222/1000 
	 loss: 16.5116, MinusLogProbMetric: 16.5116, val_loss: 16.6177, val_MinusLogProbMetric: 16.6177

Epoch 222: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5116 - MinusLogProbMetric: 16.5116 - val_loss: 16.6177 - val_MinusLogProbMetric: 16.6177 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 223/1000
2023-09-12 14:14:56.729 
Epoch 223/1000 
	 loss: 16.5156, MinusLogProbMetric: 16.5156, val_loss: 16.6166, val_MinusLogProbMetric: 16.6166

Epoch 223: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5156 - MinusLogProbMetric: 16.5156 - val_loss: 16.6166 - val_MinusLogProbMetric: 16.6166 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 224/1000
2023-09-12 14:15:07.747 
Epoch 224/1000 
	 loss: 16.5161, MinusLogProbMetric: 16.5161, val_loss: 16.6005, val_MinusLogProbMetric: 16.6005

Epoch 224: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5161 - MinusLogProbMetric: 16.5161 - val_loss: 16.6005 - val_MinusLogProbMetric: 16.6005 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 225/1000
2023-09-12 14:15:18.630 
Epoch 225/1000 
	 loss: 16.5136, MinusLogProbMetric: 16.5136, val_loss: 16.6035, val_MinusLogProbMetric: 16.6035

Epoch 225: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5136 - MinusLogProbMetric: 16.5136 - val_loss: 16.6035 - val_MinusLogProbMetric: 16.6035 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 226/1000
2023-09-12 14:15:29.497 
Epoch 226/1000 
	 loss: 16.5155, MinusLogProbMetric: 16.5155, val_loss: 16.5983, val_MinusLogProbMetric: 16.5983

Epoch 226: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5155 - MinusLogProbMetric: 16.5155 - val_loss: 16.5983 - val_MinusLogProbMetric: 16.5983 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 227/1000
2023-09-12 14:15:40.461 
Epoch 227/1000 
	 loss: 16.5122, MinusLogProbMetric: 16.5122, val_loss: 16.5898, val_MinusLogProbMetric: 16.5898

Epoch 227: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5122 - MinusLogProbMetric: 16.5122 - val_loss: 16.5898 - val_MinusLogProbMetric: 16.5898 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 228/1000
2023-09-12 14:15:51.423 
Epoch 228/1000 
	 loss: 16.5125, MinusLogProbMetric: 16.5125, val_loss: 16.6050, val_MinusLogProbMetric: 16.6050

Epoch 228: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5125 - MinusLogProbMetric: 16.5125 - val_loss: 16.6050 - val_MinusLogProbMetric: 16.6050 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 229/1000
2023-09-12 14:16:02.111 
Epoch 229/1000 
	 loss: 16.5131, MinusLogProbMetric: 16.5131, val_loss: 16.5975, val_MinusLogProbMetric: 16.5975

Epoch 229: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5131 - MinusLogProbMetric: 16.5131 - val_loss: 16.5975 - val_MinusLogProbMetric: 16.5975 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 230/1000
2023-09-12 14:16:12.875 
Epoch 230/1000 
	 loss: 16.5153, MinusLogProbMetric: 16.5153, val_loss: 16.6155, val_MinusLogProbMetric: 16.6155

Epoch 230: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5153 - MinusLogProbMetric: 16.5153 - val_loss: 16.6155 - val_MinusLogProbMetric: 16.6155 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 231/1000
2023-09-12 14:16:23.840 
Epoch 231/1000 
	 loss: 16.5113, MinusLogProbMetric: 16.5113, val_loss: 16.5981, val_MinusLogProbMetric: 16.5981

Epoch 231: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5113 - MinusLogProbMetric: 16.5113 - val_loss: 16.5981 - val_MinusLogProbMetric: 16.5981 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 232/1000
2023-09-12 14:16:34.711 
Epoch 232/1000 
	 loss: 16.5140, MinusLogProbMetric: 16.5140, val_loss: 16.6206, val_MinusLogProbMetric: 16.6206

Epoch 232: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5140 - MinusLogProbMetric: 16.5140 - val_loss: 16.6206 - val_MinusLogProbMetric: 16.6206 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 233/1000
2023-09-12 14:16:45.691 
Epoch 233/1000 
	 loss: 16.5131, MinusLogProbMetric: 16.5131, val_loss: 16.5953, val_MinusLogProbMetric: 16.5953

Epoch 233: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5131 - MinusLogProbMetric: 16.5131 - val_loss: 16.5953 - val_MinusLogProbMetric: 16.5953 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 234/1000
2023-09-12 14:16:56.631 
Epoch 234/1000 
	 loss: 16.5102, MinusLogProbMetric: 16.5102, val_loss: 16.6034, val_MinusLogProbMetric: 16.6034

Epoch 234: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5102 - MinusLogProbMetric: 16.5102 - val_loss: 16.6034 - val_MinusLogProbMetric: 16.6034 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 235/1000
2023-09-12 14:17:07.542 
Epoch 235/1000 
	 loss: 16.5132, MinusLogProbMetric: 16.5132, val_loss: 16.6021, val_MinusLogProbMetric: 16.6021

Epoch 235: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5132 - MinusLogProbMetric: 16.5132 - val_loss: 16.6021 - val_MinusLogProbMetric: 16.6021 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 236/1000
2023-09-12 14:17:18.676 
Epoch 236/1000 
	 loss: 16.5140, MinusLogProbMetric: 16.5140, val_loss: 16.6061, val_MinusLogProbMetric: 16.6061

Epoch 236: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5140 - MinusLogProbMetric: 16.5140 - val_loss: 16.6061 - val_MinusLogProbMetric: 16.6061 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 237/1000
2023-09-12 14:17:29.141 
Epoch 237/1000 
	 loss: 16.5118, MinusLogProbMetric: 16.5118, val_loss: 16.6083, val_MinusLogProbMetric: 16.6083

Epoch 237: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.5118 - MinusLogProbMetric: 16.5118 - val_loss: 16.6083 - val_MinusLogProbMetric: 16.6083 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 238/1000
2023-09-12 14:17:39.948 
Epoch 238/1000 
	 loss: 16.5129, MinusLogProbMetric: 16.5129, val_loss: 16.5978, val_MinusLogProbMetric: 16.5978

Epoch 238: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5129 - MinusLogProbMetric: 16.5129 - val_loss: 16.5978 - val_MinusLogProbMetric: 16.5978 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 239/1000
2023-09-12 14:17:50.971 
Epoch 239/1000 
	 loss: 16.5079, MinusLogProbMetric: 16.5079, val_loss: 16.6008, val_MinusLogProbMetric: 16.6008

Epoch 239: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5079 - MinusLogProbMetric: 16.5079 - val_loss: 16.6008 - val_MinusLogProbMetric: 16.6008 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 240/1000
2023-09-12 14:18:01.823 
Epoch 240/1000 
	 loss: 16.5100, MinusLogProbMetric: 16.5100, val_loss: 16.6116, val_MinusLogProbMetric: 16.6116

Epoch 240: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5100 - MinusLogProbMetric: 16.5100 - val_loss: 16.6116 - val_MinusLogProbMetric: 16.6116 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 241/1000
2023-09-12 14:18:12.202 
Epoch 241/1000 
	 loss: 16.5122, MinusLogProbMetric: 16.5122, val_loss: 16.6160, val_MinusLogProbMetric: 16.6160

Epoch 241: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.5122 - MinusLogProbMetric: 16.5122 - val_loss: 16.6160 - val_MinusLogProbMetric: 16.6160 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 242/1000
2023-09-12 14:18:23.205 
Epoch 242/1000 
	 loss: 16.5085, MinusLogProbMetric: 16.5085, val_loss: 16.5990, val_MinusLogProbMetric: 16.5990

Epoch 242: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5085 - MinusLogProbMetric: 16.5085 - val_loss: 16.5990 - val_MinusLogProbMetric: 16.5990 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 243/1000
2023-09-12 14:18:34.090 
Epoch 243/1000 
	 loss: 16.5146, MinusLogProbMetric: 16.5146, val_loss: 16.6019, val_MinusLogProbMetric: 16.6019

Epoch 243: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5146 - MinusLogProbMetric: 16.5146 - val_loss: 16.6019 - val_MinusLogProbMetric: 16.6019 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 244/1000
2023-09-12 14:18:45.226 
Epoch 244/1000 
	 loss: 16.5087, MinusLogProbMetric: 16.5087, val_loss: 16.6100, val_MinusLogProbMetric: 16.6100

Epoch 244: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5087 - MinusLogProbMetric: 16.5087 - val_loss: 16.6100 - val_MinusLogProbMetric: 16.6100 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 245/1000
2023-09-12 14:18:56.060 
Epoch 245/1000 
	 loss: 16.5089, MinusLogProbMetric: 16.5089, val_loss: 16.6060, val_MinusLogProbMetric: 16.6060

Epoch 245: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5089 - MinusLogProbMetric: 16.5089 - val_loss: 16.6060 - val_MinusLogProbMetric: 16.6060 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 246/1000
2023-09-12 14:19:07.106 
Epoch 246/1000 
	 loss: 16.5087, MinusLogProbMetric: 16.5087, val_loss: 16.6190, val_MinusLogProbMetric: 16.6190

Epoch 246: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5087 - MinusLogProbMetric: 16.5087 - val_loss: 16.6190 - val_MinusLogProbMetric: 16.6190 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 247/1000
2023-09-12 14:19:18.041 
Epoch 247/1000 
	 loss: 16.5040, MinusLogProbMetric: 16.5040, val_loss: 16.6008, val_MinusLogProbMetric: 16.6008

Epoch 247: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5040 - MinusLogProbMetric: 16.5040 - val_loss: 16.6008 - val_MinusLogProbMetric: 16.6008 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 248/1000
2023-09-12 14:19:28.896 
Epoch 248/1000 
	 loss: 16.5105, MinusLogProbMetric: 16.5105, val_loss: 16.6006, val_MinusLogProbMetric: 16.6006

Epoch 248: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5105 - MinusLogProbMetric: 16.5105 - val_loss: 16.6006 - val_MinusLogProbMetric: 16.6006 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 249/1000
2023-09-12 14:19:37.697 
Epoch 249/1000 
	 loss: 16.5108, MinusLogProbMetric: 16.5108, val_loss: 16.6063, val_MinusLogProbMetric: 16.6063

Epoch 249: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.5108 - MinusLogProbMetric: 16.5108 - val_loss: 16.6063 - val_MinusLogProbMetric: 16.6063 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 250/1000
2023-09-12 14:19:47.987 
Epoch 250/1000 
	 loss: 16.5060, MinusLogProbMetric: 16.5060, val_loss: 16.6045, val_MinusLogProbMetric: 16.6045

Epoch 250: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.5060 - MinusLogProbMetric: 16.5060 - val_loss: 16.6045 - val_MinusLogProbMetric: 16.6045 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 251/1000
2023-09-12 14:19:58.699 
Epoch 251/1000 
	 loss: 16.5113, MinusLogProbMetric: 16.5113, val_loss: 16.6198, val_MinusLogProbMetric: 16.6198

Epoch 251: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5113 - MinusLogProbMetric: 16.5113 - val_loss: 16.6198 - val_MinusLogProbMetric: 16.6198 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 252/1000
2023-09-12 14:20:09.567 
Epoch 252/1000 
	 loss: 16.5072, MinusLogProbMetric: 16.5072, val_loss: 16.6357, val_MinusLogProbMetric: 16.6357

Epoch 252: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5072 - MinusLogProbMetric: 16.5072 - val_loss: 16.6357 - val_MinusLogProbMetric: 16.6357 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 253/1000
2023-09-12 14:20:20.334 
Epoch 253/1000 
	 loss: 16.5128, MinusLogProbMetric: 16.5128, val_loss: 16.6113, val_MinusLogProbMetric: 16.6113

Epoch 253: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5128 - MinusLogProbMetric: 16.5128 - val_loss: 16.6113 - val_MinusLogProbMetric: 16.6113 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 254/1000
2023-09-12 14:20:30.975 
Epoch 254/1000 
	 loss: 16.5026, MinusLogProbMetric: 16.5026, val_loss: 16.6080, val_MinusLogProbMetric: 16.6080

Epoch 254: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.5026 - MinusLogProbMetric: 16.5026 - val_loss: 16.6080 - val_MinusLogProbMetric: 16.6080 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 255/1000
2023-09-12 14:20:41.373 
Epoch 255/1000 
	 loss: 16.4829, MinusLogProbMetric: 16.4829, val_loss: 16.5935, val_MinusLogProbMetric: 16.5935

Epoch 255: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4829 - MinusLogProbMetric: 16.4829 - val_loss: 16.5935 - val_MinusLogProbMetric: 16.5935 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 256/1000
2023-09-12 14:20:51.805 
Epoch 256/1000 
	 loss: 16.4806, MinusLogProbMetric: 16.4806, val_loss: 16.5878, val_MinusLogProbMetric: 16.5878

Epoch 256: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4806 - MinusLogProbMetric: 16.4806 - val_loss: 16.5878 - val_MinusLogProbMetric: 16.5878 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 257/1000
2023-09-12 14:21:01.851 
Epoch 257/1000 
	 loss: 16.4819, MinusLogProbMetric: 16.4819, val_loss: 16.6067, val_MinusLogProbMetric: 16.6067

Epoch 257: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4819 - MinusLogProbMetric: 16.4819 - val_loss: 16.6067 - val_MinusLogProbMetric: 16.6067 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 258/1000
2023-09-12 14:21:12.340 
Epoch 258/1000 
	 loss: 16.4792, MinusLogProbMetric: 16.4792, val_loss: 16.5947, val_MinusLogProbMetric: 16.5947

Epoch 258: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4792 - MinusLogProbMetric: 16.4792 - val_loss: 16.5947 - val_MinusLogProbMetric: 16.5947 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 259/1000
2023-09-12 14:21:22.951 
Epoch 259/1000 
	 loss: 16.4793, MinusLogProbMetric: 16.4793, val_loss: 16.5960, val_MinusLogProbMetric: 16.5960

Epoch 259: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4793 - MinusLogProbMetric: 16.4793 - val_loss: 16.5960 - val_MinusLogProbMetric: 16.5960 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 260/1000
2023-09-12 14:21:33.497 
Epoch 260/1000 
	 loss: 16.4834, MinusLogProbMetric: 16.4834, val_loss: 16.6117, val_MinusLogProbMetric: 16.6117

Epoch 260: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4834 - MinusLogProbMetric: 16.4834 - val_loss: 16.6117 - val_MinusLogProbMetric: 16.6117 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 261/1000
2023-09-12 14:21:44.272 
Epoch 261/1000 
	 loss: 16.4815, MinusLogProbMetric: 16.4815, val_loss: 16.6119, val_MinusLogProbMetric: 16.6119

Epoch 261: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4815 - MinusLogProbMetric: 16.4815 - val_loss: 16.6119 - val_MinusLogProbMetric: 16.6119 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 262/1000
2023-09-12 14:21:54.902 
Epoch 262/1000 
	 loss: 16.4777, MinusLogProbMetric: 16.4777, val_loss: 16.5913, val_MinusLogProbMetric: 16.5913

Epoch 262: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4777 - MinusLogProbMetric: 16.4777 - val_loss: 16.5913 - val_MinusLogProbMetric: 16.5913 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 263/1000
2023-09-12 14:22:03.460 
Epoch 263/1000 
	 loss: 16.4790, MinusLogProbMetric: 16.4790, val_loss: 16.5988, val_MinusLogProbMetric: 16.5988

Epoch 263: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4790 - MinusLogProbMetric: 16.4790 - val_loss: 16.5988 - val_MinusLogProbMetric: 16.5988 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 264/1000
2023-09-12 14:22:13.701 
Epoch 264/1000 
	 loss: 16.4780, MinusLogProbMetric: 16.4780, val_loss: 16.5901, val_MinusLogProbMetric: 16.5901

Epoch 264: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4780 - MinusLogProbMetric: 16.4780 - val_loss: 16.5901 - val_MinusLogProbMetric: 16.5901 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 265/1000
2023-09-12 14:22:22.440 
Epoch 265/1000 
	 loss: 16.4810, MinusLogProbMetric: 16.4810, val_loss: 16.6014, val_MinusLogProbMetric: 16.6014

Epoch 265: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4810 - MinusLogProbMetric: 16.4810 - val_loss: 16.6014 - val_MinusLogProbMetric: 16.6014 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 266/1000
2023-09-12 14:22:32.994 
Epoch 266/1000 
	 loss: 16.4803, MinusLogProbMetric: 16.4803, val_loss: 16.6184, val_MinusLogProbMetric: 16.6184

Epoch 266: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4803 - MinusLogProbMetric: 16.4803 - val_loss: 16.6184 - val_MinusLogProbMetric: 16.6184 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 267/1000
2023-09-12 14:22:43.485 
Epoch 267/1000 
	 loss: 16.4799, MinusLogProbMetric: 16.4799, val_loss: 16.5929, val_MinusLogProbMetric: 16.5929

Epoch 267: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4799 - MinusLogProbMetric: 16.4799 - val_loss: 16.5929 - val_MinusLogProbMetric: 16.5929 - lr: 2.5000e-04 - 10s/epoch - 54ms/step
Epoch 268/1000
2023-09-12 14:22:54.165 
Epoch 268/1000 
	 loss: 16.4772, MinusLogProbMetric: 16.4772, val_loss: 16.5923, val_MinusLogProbMetric: 16.5923

Epoch 268: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4772 - MinusLogProbMetric: 16.4772 - val_loss: 16.5923 - val_MinusLogProbMetric: 16.5923 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 269/1000
2023-09-12 14:23:05.250 
Epoch 269/1000 
	 loss: 16.4782, MinusLogProbMetric: 16.4782, val_loss: 16.5921, val_MinusLogProbMetric: 16.5921

Epoch 269: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4782 - MinusLogProbMetric: 16.4782 - val_loss: 16.5921 - val_MinusLogProbMetric: 16.5921 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 270/1000
2023-09-12 14:23:16.351 
Epoch 270/1000 
	 loss: 16.4794, MinusLogProbMetric: 16.4794, val_loss: 16.5913, val_MinusLogProbMetric: 16.5913

Epoch 270: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4794 - MinusLogProbMetric: 16.4794 - val_loss: 16.5913 - val_MinusLogProbMetric: 16.5913 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 271/1000
2023-09-12 14:23:27.465 
Epoch 271/1000 
	 loss: 16.4756, MinusLogProbMetric: 16.4756, val_loss: 16.6000, val_MinusLogProbMetric: 16.6000

Epoch 271: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4756 - MinusLogProbMetric: 16.4756 - val_loss: 16.6000 - val_MinusLogProbMetric: 16.6000 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 272/1000
2023-09-12 14:23:37.652 
Epoch 272/1000 
	 loss: 16.4812, MinusLogProbMetric: 16.4812, val_loss: 16.5947, val_MinusLogProbMetric: 16.5947

Epoch 272: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4812 - MinusLogProbMetric: 16.4812 - val_loss: 16.5947 - val_MinusLogProbMetric: 16.5947 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 273/1000
2023-09-12 14:23:46.981 
Epoch 273/1000 
	 loss: 16.4778, MinusLogProbMetric: 16.4778, val_loss: 16.6011, val_MinusLogProbMetric: 16.6011

Epoch 273: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4778 - MinusLogProbMetric: 16.4778 - val_loss: 16.6011 - val_MinusLogProbMetric: 16.6011 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 274/1000
2023-09-12 14:23:57.895 
Epoch 274/1000 
	 loss: 16.4759, MinusLogProbMetric: 16.4759, val_loss: 16.5937, val_MinusLogProbMetric: 16.5937

Epoch 274: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4759 - MinusLogProbMetric: 16.4759 - val_loss: 16.5937 - val_MinusLogProbMetric: 16.5937 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 275/1000
2023-09-12 14:24:08.887 
Epoch 275/1000 
	 loss: 16.4788, MinusLogProbMetric: 16.4788, val_loss: 16.5934, val_MinusLogProbMetric: 16.5934

Epoch 275: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4788 - MinusLogProbMetric: 16.4788 - val_loss: 16.5934 - val_MinusLogProbMetric: 16.5934 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 276/1000
2023-09-12 14:24:18.571 
Epoch 276/1000 
	 loss: 16.4769, MinusLogProbMetric: 16.4769, val_loss: 16.5941, val_MinusLogProbMetric: 16.5941

Epoch 276: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4769 - MinusLogProbMetric: 16.4769 - val_loss: 16.5941 - val_MinusLogProbMetric: 16.5941 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 277/1000
2023-09-12 14:24:27.190 
Epoch 277/1000 
	 loss: 16.4745, MinusLogProbMetric: 16.4745, val_loss: 16.5941, val_MinusLogProbMetric: 16.5941

Epoch 277: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4745 - MinusLogProbMetric: 16.4745 - val_loss: 16.5941 - val_MinusLogProbMetric: 16.5941 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 278/1000
2023-09-12 14:24:35.675 
Epoch 278/1000 
	 loss: 16.4777, MinusLogProbMetric: 16.4777, val_loss: 16.5985, val_MinusLogProbMetric: 16.5985

Epoch 278: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4777 - MinusLogProbMetric: 16.4777 - val_loss: 16.5985 - val_MinusLogProbMetric: 16.5985 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 279/1000
2023-09-12 14:24:44.083 
Epoch 279/1000 
	 loss: 16.4797, MinusLogProbMetric: 16.4797, val_loss: 16.5885, val_MinusLogProbMetric: 16.5885

Epoch 279: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4797 - MinusLogProbMetric: 16.4797 - val_loss: 16.5885 - val_MinusLogProbMetric: 16.5885 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 280/1000
2023-09-12 14:24:52.592 
Epoch 280/1000 
	 loss: 16.4801, MinusLogProbMetric: 16.4801, val_loss: 16.5956, val_MinusLogProbMetric: 16.5956

Epoch 280: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4801 - MinusLogProbMetric: 16.4801 - val_loss: 16.5956 - val_MinusLogProbMetric: 16.5956 - lr: 2.5000e-04 - 9s/epoch - 43ms/step
Epoch 281/1000
2023-09-12 14:25:00.988 
Epoch 281/1000 
	 loss: 16.4779, MinusLogProbMetric: 16.4779, val_loss: 16.5975, val_MinusLogProbMetric: 16.5975

Epoch 281: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4779 - MinusLogProbMetric: 16.4779 - val_loss: 16.5975 - val_MinusLogProbMetric: 16.5975 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 282/1000
2023-09-12 14:25:09.428 
Epoch 282/1000 
	 loss: 16.4775, MinusLogProbMetric: 16.4775, val_loss: 16.6172, val_MinusLogProbMetric: 16.6172

Epoch 282: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4775 - MinusLogProbMetric: 16.4775 - val_loss: 16.6172 - val_MinusLogProbMetric: 16.6172 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 283/1000
2023-09-12 14:25:17.860 
Epoch 283/1000 
	 loss: 16.4788, MinusLogProbMetric: 16.4788, val_loss: 16.5914, val_MinusLogProbMetric: 16.5914

Epoch 283: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4788 - MinusLogProbMetric: 16.4788 - val_loss: 16.5914 - val_MinusLogProbMetric: 16.5914 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 284/1000
2023-09-12 14:25:26.166 
Epoch 284/1000 
	 loss: 16.4787, MinusLogProbMetric: 16.4787, val_loss: 16.5958, val_MinusLogProbMetric: 16.5958

Epoch 284: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4787 - MinusLogProbMetric: 16.4787 - val_loss: 16.5958 - val_MinusLogProbMetric: 16.5958 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 285/1000
2023-09-12 14:25:34.445 
Epoch 285/1000 
	 loss: 16.4746, MinusLogProbMetric: 16.4746, val_loss: 16.6086, val_MinusLogProbMetric: 16.6086

Epoch 285: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4746 - MinusLogProbMetric: 16.4746 - val_loss: 16.6086 - val_MinusLogProbMetric: 16.6086 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 286/1000
2023-09-12 14:25:42.905 
Epoch 286/1000 
	 loss: 16.4751, MinusLogProbMetric: 16.4751, val_loss: 16.6020, val_MinusLogProbMetric: 16.6020

Epoch 286: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4751 - MinusLogProbMetric: 16.4751 - val_loss: 16.6020 - val_MinusLogProbMetric: 16.6020 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 287/1000
2023-09-12 14:25:51.299 
Epoch 287/1000 
	 loss: 16.4771, MinusLogProbMetric: 16.4771, val_loss: 16.5938, val_MinusLogProbMetric: 16.5938

Epoch 287: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4771 - MinusLogProbMetric: 16.4771 - val_loss: 16.5938 - val_MinusLogProbMetric: 16.5938 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 288/1000
2023-09-12 14:25:59.495 
Epoch 288/1000 
	 loss: 16.4757, MinusLogProbMetric: 16.4757, val_loss: 16.5943, val_MinusLogProbMetric: 16.5943

Epoch 288: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4757 - MinusLogProbMetric: 16.4757 - val_loss: 16.5943 - val_MinusLogProbMetric: 16.5943 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 289/1000
2023-09-12 14:26:07.802 
Epoch 289/1000 
	 loss: 16.4773, MinusLogProbMetric: 16.4773, val_loss: 16.5892, val_MinusLogProbMetric: 16.5892

Epoch 289: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4773 - MinusLogProbMetric: 16.4773 - val_loss: 16.5892 - val_MinusLogProbMetric: 16.5892 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 290/1000
2023-09-12 14:26:16.287 
Epoch 290/1000 
	 loss: 16.4771, MinusLogProbMetric: 16.4771, val_loss: 16.6017, val_MinusLogProbMetric: 16.6017

Epoch 290: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4771 - MinusLogProbMetric: 16.4771 - val_loss: 16.6017 - val_MinusLogProbMetric: 16.6017 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 291/1000
2023-09-12 14:26:24.588 
Epoch 291/1000 
	 loss: 16.4746, MinusLogProbMetric: 16.4746, val_loss: 16.6085, val_MinusLogProbMetric: 16.6085

Epoch 291: val_loss did not improve from 16.58417
196/196 - 8s - loss: 16.4746 - MinusLogProbMetric: 16.4746 - val_loss: 16.6085 - val_MinusLogProbMetric: 16.6085 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 292/1000
2023-09-12 14:26:33.176 
Epoch 292/1000 
	 loss: 16.4761, MinusLogProbMetric: 16.4761, val_loss: 16.6005, val_MinusLogProbMetric: 16.6005

Epoch 292: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4761 - MinusLogProbMetric: 16.4761 - val_loss: 16.6005 - val_MinusLogProbMetric: 16.6005 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 293/1000
2023-09-12 14:26:41.844 
Epoch 293/1000 
	 loss: 16.4758, MinusLogProbMetric: 16.4758, val_loss: 16.6072, val_MinusLogProbMetric: 16.6072

Epoch 293: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4758 - MinusLogProbMetric: 16.4758 - val_loss: 16.6072 - val_MinusLogProbMetric: 16.6072 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 294/1000
2023-09-12 14:26:52.067 
Epoch 294/1000 
	 loss: 16.4788, MinusLogProbMetric: 16.4788, val_loss: 16.5967, val_MinusLogProbMetric: 16.5967

Epoch 294: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4788 - MinusLogProbMetric: 16.4788 - val_loss: 16.5967 - val_MinusLogProbMetric: 16.5967 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 295/1000
2023-09-12 14:27:01.525 
Epoch 295/1000 
	 loss: 16.4744, MinusLogProbMetric: 16.4744, val_loss: 16.5964, val_MinusLogProbMetric: 16.5964

Epoch 295: val_loss did not improve from 16.58417
196/196 - 9s - loss: 16.4744 - MinusLogProbMetric: 16.4744 - val_loss: 16.5964 - val_MinusLogProbMetric: 16.5964 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 296/1000
2023-09-12 14:27:12.330 
Epoch 296/1000 
	 loss: 16.4754, MinusLogProbMetric: 16.4754, val_loss: 16.5958, val_MinusLogProbMetric: 16.5958

Epoch 296: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4754 - MinusLogProbMetric: 16.4754 - val_loss: 16.5958 - val_MinusLogProbMetric: 16.5958 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 297/1000
2023-09-12 14:27:23.050 
Epoch 297/1000 
	 loss: 16.4759, MinusLogProbMetric: 16.4759, val_loss: 16.6010, val_MinusLogProbMetric: 16.6010

Epoch 297: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4759 - MinusLogProbMetric: 16.4759 - val_loss: 16.6010 - val_MinusLogProbMetric: 16.6010 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 298/1000
2023-09-12 14:27:33.984 
Epoch 298/1000 
	 loss: 16.4752, MinusLogProbMetric: 16.4752, val_loss: 16.6030, val_MinusLogProbMetric: 16.6030

Epoch 298: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4752 - MinusLogProbMetric: 16.4752 - val_loss: 16.6030 - val_MinusLogProbMetric: 16.6030 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 299/1000
2023-09-12 14:27:45.228 
Epoch 299/1000 
	 loss: 16.4733, MinusLogProbMetric: 16.4733, val_loss: 16.5975, val_MinusLogProbMetric: 16.5975

Epoch 299: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4733 - MinusLogProbMetric: 16.4733 - val_loss: 16.5975 - val_MinusLogProbMetric: 16.5975 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 300/1000
2023-09-12 14:27:56.565 
Epoch 300/1000 
	 loss: 16.4749, MinusLogProbMetric: 16.4749, val_loss: 16.6082, val_MinusLogProbMetric: 16.6082

Epoch 300: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4749 - MinusLogProbMetric: 16.4749 - val_loss: 16.6082 - val_MinusLogProbMetric: 16.6082 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 301/1000
2023-09-12 14:28:08.027 
Epoch 301/1000 
	 loss: 16.4735, MinusLogProbMetric: 16.4735, val_loss: 16.6087, val_MinusLogProbMetric: 16.6087

Epoch 301: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4735 - MinusLogProbMetric: 16.4735 - val_loss: 16.6087 - val_MinusLogProbMetric: 16.6087 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 302/1000
2023-09-12 14:28:19.300 
Epoch 302/1000 
	 loss: 16.4759, MinusLogProbMetric: 16.4759, val_loss: 16.6033, val_MinusLogProbMetric: 16.6033

Epoch 302: val_loss did not improve from 16.58417
196/196 - 11s - loss: 16.4759 - MinusLogProbMetric: 16.4759 - val_loss: 16.6033 - val_MinusLogProbMetric: 16.6033 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 303/1000
2023-09-12 14:28:29.577 
Epoch 303/1000 
	 loss: 16.4729, MinusLogProbMetric: 16.4729, val_loss: 16.5931, val_MinusLogProbMetric: 16.5931

Epoch 303: val_loss did not improve from 16.58417
196/196 - 10s - loss: 16.4729 - MinusLogProbMetric: 16.4729 - val_loss: 16.5931 - val_MinusLogProbMetric: 16.5931 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 304/1000
2023-09-12 14:28:40.765 
Epoch 304/1000 
	 loss: 16.4753, MinusLogProbMetric: 16.4753, val_loss: 16.6083, val_MinusLogProbMetric: 16.6083

Epoch 304: val_loss did not improve from 16.58417
Restoring model weights from the end of the best epoch: 204.
196/196 - 11s - loss: 16.4753 - MinusLogProbMetric: 16.4753 - val_loss: 16.6083 - val_MinusLogProbMetric: 16.6083 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 304: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 6.1472653860691935 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.33097514603287 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.882902698009275 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.7643920340342447 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 520.
Model trained in 3183.71 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Metrics computed in 276.66 s.
Plots done in 136.32 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 412.99 s.
===========
Run 137/360 done in 3597.87 s.
===========

Directory ../../results/MsplineN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

===========
Generating train data for run 145.
===========
Train data generated in 0.21 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_145/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 721}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_145/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.3570018 ,  5.6703625 ,  0.48762453, ...,  0.76730525,
         6.4537516 ,  1.4289263 ],
       [ 4.8933635 ,  4.954244  , -0.7742728 , ...,  1.033045  ,
         7.5179    ,  1.3446053 ],
       [ 2.6192126 ,  3.6659784 ,  9.3581505 , ...,  6.4096394 ,
         2.8983781 ,  1.8163822 ],
       ...,
       [ 4.4286733 ,  5.582822  , -0.08033401, ...,  1.0755457 ,
         6.482341  ,  1.3259909 ],
       [ 5.2667904 ,  5.78094   ,  0.52473783, ...,  1.3584392 ,
         6.6371064 ,  1.4527634 ],
       [ 1.3711529 ,  3.985786  ,  8.434673  , ...,  6.650886  ,
         2.8764064 ,  2.071397  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_145/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_145
self.data_kwargs: {'seed': 721}
self.x_data: [[ 5.4479074  7.1622143  6.6614265 ...  3.6775346  2.6042771  7.6607866]
 [ 1.558796   3.7643342  7.765504  ...  7.3985186  2.2847533  2.1737251]
 [ 2.023865   3.5498223  9.736043  ...  7.378399   2.9893079  1.7681804]
 ...
 [ 3.157689   3.8140697  9.128405  ...  7.3280826  3.3431854  1.6145309]
 [ 4.9035525  5.63367    1.3061054 ...  1.7336241  7.263643   1.3624198]
 [ 4.873677   6.0271535 -0.4844559 ...  1.4305246  6.6029577  1.4994687]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_58 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_19 (LogProbL  (None,)                  264384    
 ayer)                                                           
                                                                 
=================================================================
Total params: 264,384
Trainable params: 264,384
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_19/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_19'")
self.model: <keras.engine.functional.Functional object at 0x7fbc48986cb0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fbc487bd960>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fbc487bd960>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fbc487be230>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fbc487beef0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fbc487bf460>, <keras.callbacks.ModelCheckpoint object at 0x7fbc487bf520>, <keras.callbacks.EarlyStopping object at 0x7fbc487bf790>, <keras.callbacks.ReduceLROnPlateau object at 0x7fbc487bf7c0>, <keras.callbacks.TerminateOnNaN object at 0x7fbc487bf400>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.3570018 ,  5.6703625 ,  0.48762453, ...,  0.76730525,
         6.4537516 ,  1.4289263 ],
       [ 4.8933635 ,  4.954244  , -0.7742728 , ...,  1.033045  ,
         7.5179    ,  1.3446053 ],
       [ 2.6192126 ,  3.6659784 ,  9.3581505 , ...,  6.4096394 ,
         2.8983781 ,  1.8163822 ],
       ...,
       [ 4.4286733 ,  5.582822  , -0.08033401, ...,  1.0755457 ,
         6.482341  ,  1.3259909 ],
       [ 5.2667904 ,  5.78094   ,  0.52473783, ...,  1.3584392 ,
         6.6371064 ,  1.4527634 ],
       [ 1.3711529 ,  3.985786  ,  8.434673  , ...,  6.650886  ,
         2.8764064 ,  2.071397  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_145/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 145/360 with hyperparameters:
timestamp = 2023-09-12 14:35:34.984235
ndims = 32
seed_train = 721
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 264384
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.4479074  7.1622143  6.6614265  5.4466543  4.679343   6.5534453
  4.5869303  8.297877   9.431402   3.191049   9.163281   4.112924
  5.872972  10.008474   0.4502598  1.3920732 -0.6747763  8.487896
  9.224454   7.913118   8.449968   7.6997313  5.9028535  7.439646
  2.3174791  6.975212   1.6619607  9.750696   4.816901   3.6775346
  2.6042771  7.6607866]
Epoch 1/1000
2023-09-12 14:36:02.078 
Epoch 1/1000 
	 loss: 52.5101, MinusLogProbMetric: 52.5101, val_loss: 22.0184, val_MinusLogProbMetric: 22.0184

Epoch 1: val_loss improved from inf to 22.01836, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 27s - loss: 52.5101 - MinusLogProbMetric: 52.5101 - val_loss: 22.0184 - val_MinusLogProbMetric: 22.0184 - lr: 0.0010 - 27s/epoch - 138ms/step
Epoch 2/1000
2023-09-12 14:36:11.182 
Epoch 2/1000 
	 loss: 20.1861, MinusLogProbMetric: 20.1861, val_loss: 19.2006, val_MinusLogProbMetric: 19.2006

Epoch 2: val_loss improved from 22.01836 to 19.20055, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 20.1861 - MinusLogProbMetric: 20.1861 - val_loss: 19.2006 - val_MinusLogProbMetric: 19.2006 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 3/1000
2023-09-12 14:36:20.663 
Epoch 3/1000 
	 loss: 18.7153, MinusLogProbMetric: 18.7153, val_loss: 18.2517, val_MinusLogProbMetric: 18.2517

Epoch 3: val_loss improved from 19.20055 to 18.25165, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 18.7153 - MinusLogProbMetric: 18.7153 - val_loss: 18.2517 - val_MinusLogProbMetric: 18.2517 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 4/1000
2023-09-12 14:36:31.266 
Epoch 4/1000 
	 loss: 18.2069, MinusLogProbMetric: 18.2069, val_loss: 17.8453, val_MinusLogProbMetric: 17.8453

Epoch 4: val_loss improved from 18.25165 to 17.84534, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 11s - loss: 18.2069 - MinusLogProbMetric: 18.2069 - val_loss: 17.8453 - val_MinusLogProbMetric: 17.8453 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 5/1000
2023-09-12 14:36:42.878 
Epoch 5/1000 
	 loss: 17.8713, MinusLogProbMetric: 17.8713, val_loss: 19.3212, val_MinusLogProbMetric: 19.3212

Epoch 5: val_loss did not improve from 17.84534
196/196 - 11s - loss: 17.8713 - MinusLogProbMetric: 17.8713 - val_loss: 19.3212 - val_MinusLogProbMetric: 19.3212 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 6/1000
2023-09-12 14:36:54.323 
Epoch 6/1000 
	 loss: 17.7297, MinusLogProbMetric: 17.7297, val_loss: 17.7559, val_MinusLogProbMetric: 17.7559

Epoch 6: val_loss improved from 17.84534 to 17.75593, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 17.7297 - MinusLogProbMetric: 17.7297 - val_loss: 17.7559 - val_MinusLogProbMetric: 17.7559 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 7/1000
2023-09-12 14:37:06.049 
Epoch 7/1000 
	 loss: 17.5807, MinusLogProbMetric: 17.5807, val_loss: 17.4464, val_MinusLogProbMetric: 17.4464

Epoch 7: val_loss improved from 17.75593 to 17.44635, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 17.5807 - MinusLogProbMetric: 17.5807 - val_loss: 17.4464 - val_MinusLogProbMetric: 17.4464 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 8/1000
2023-09-12 14:37:16.563 
Epoch 8/1000 
	 loss: 17.4632, MinusLogProbMetric: 17.4632, val_loss: 17.4739, val_MinusLogProbMetric: 17.4739

Epoch 8: val_loss did not improve from 17.44635
196/196 - 10s - loss: 17.4632 - MinusLogProbMetric: 17.4632 - val_loss: 17.4739 - val_MinusLogProbMetric: 17.4739 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 9/1000
2023-09-12 14:37:26.649 
Epoch 9/1000 
	 loss: 17.3739, MinusLogProbMetric: 17.3739, val_loss: 17.7037, val_MinusLogProbMetric: 17.7037

Epoch 9: val_loss did not improve from 17.44635
196/196 - 10s - loss: 17.3739 - MinusLogProbMetric: 17.3739 - val_loss: 17.7037 - val_MinusLogProbMetric: 17.7037 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 10/1000
2023-09-12 14:37:37.957 
Epoch 10/1000 
	 loss: 17.2629, MinusLogProbMetric: 17.2629, val_loss: 17.3588, val_MinusLogProbMetric: 17.3588

Epoch 10: val_loss improved from 17.44635 to 17.35882, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 11s - loss: 17.2629 - MinusLogProbMetric: 17.2629 - val_loss: 17.3588 - val_MinusLogProbMetric: 17.3588 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 11/1000
2023-09-12 14:37:48.675 
Epoch 11/1000 
	 loss: 17.2769, MinusLogProbMetric: 17.2769, val_loss: 17.2579, val_MinusLogProbMetric: 17.2579

Epoch 11: val_loss improved from 17.35882 to 17.25785, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 11s - loss: 17.2769 - MinusLogProbMetric: 17.2769 - val_loss: 17.2579 - val_MinusLogProbMetric: 17.2579 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 12/1000
2023-09-12 14:37:59.977 
Epoch 12/1000 
	 loss: 17.2060, MinusLogProbMetric: 17.2060, val_loss: 17.2046, val_MinusLogProbMetric: 17.2046

Epoch 12: val_loss improved from 17.25785 to 17.20459, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 11s - loss: 17.2060 - MinusLogProbMetric: 17.2060 - val_loss: 17.2046 - val_MinusLogProbMetric: 17.2046 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 13/1000
2023-09-12 14:38:08.855 
Epoch 13/1000 
	 loss: 17.1277, MinusLogProbMetric: 17.1277, val_loss: 17.1050, val_MinusLogProbMetric: 17.1050

Epoch 13: val_loss improved from 17.20459 to 17.10499, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 17.1277 - MinusLogProbMetric: 17.1277 - val_loss: 17.1050 - val_MinusLogProbMetric: 17.1050 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 14/1000
2023-09-12 14:38:19.703 
Epoch 14/1000 
	 loss: 17.1206, MinusLogProbMetric: 17.1206, val_loss: 17.2614, val_MinusLogProbMetric: 17.2614

Epoch 14: val_loss did not improve from 17.10499
196/196 - 11s - loss: 17.1206 - MinusLogProbMetric: 17.1206 - val_loss: 17.2614 - val_MinusLogProbMetric: 17.2614 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 15/1000
2023-09-12 14:38:29.551 
Epoch 15/1000 
	 loss: 17.0756, MinusLogProbMetric: 17.0756, val_loss: 17.0415, val_MinusLogProbMetric: 17.0415

Epoch 15: val_loss improved from 17.10499 to 17.04147, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 10s - loss: 17.0756 - MinusLogProbMetric: 17.0756 - val_loss: 17.0415 - val_MinusLogProbMetric: 17.0415 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 16/1000
2023-09-12 14:38:39.124 
Epoch 16/1000 
	 loss: 17.0777, MinusLogProbMetric: 17.0777, val_loss: 17.0868, val_MinusLogProbMetric: 17.0868

Epoch 16: val_loss did not improve from 17.04147
196/196 - 9s - loss: 17.0777 - MinusLogProbMetric: 17.0777 - val_loss: 17.0868 - val_MinusLogProbMetric: 17.0868 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 17/1000
2023-09-12 14:38:49.522 
Epoch 17/1000 
	 loss: 17.0434, MinusLogProbMetric: 17.0434, val_loss: 17.2664, val_MinusLogProbMetric: 17.2664

Epoch 17: val_loss did not improve from 17.04147
196/196 - 10s - loss: 17.0434 - MinusLogProbMetric: 17.0434 - val_loss: 17.2664 - val_MinusLogProbMetric: 17.2664 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 18/1000
2023-09-12 14:38:58.866 
Epoch 18/1000 
	 loss: 17.0365, MinusLogProbMetric: 17.0365, val_loss: 16.9835, val_MinusLogProbMetric: 16.9835

Epoch 18: val_loss improved from 17.04147 to 16.98349, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 17.0365 - MinusLogProbMetric: 17.0365 - val_loss: 16.9835 - val_MinusLogProbMetric: 16.9835 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 19/1000
2023-09-12 14:39:08.195 
Epoch 19/1000 
	 loss: 16.9802, MinusLogProbMetric: 16.9802, val_loss: 17.0032, val_MinusLogProbMetric: 17.0032

Epoch 19: val_loss did not improve from 16.98349
196/196 - 9s - loss: 16.9802 - MinusLogProbMetric: 16.9802 - val_loss: 17.0032 - val_MinusLogProbMetric: 17.0032 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 20/1000
2023-09-12 14:39:17.406 
Epoch 20/1000 
	 loss: 16.9509, MinusLogProbMetric: 16.9509, val_loss: 16.8988, val_MinusLogProbMetric: 16.8988

Epoch 20: val_loss improved from 16.98349 to 16.89876, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 16.9509 - MinusLogProbMetric: 16.9509 - val_loss: 16.8988 - val_MinusLogProbMetric: 16.8988 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 21/1000
2023-09-12 14:39:27.008 
Epoch 21/1000 
	 loss: 16.9657, MinusLogProbMetric: 16.9657, val_loss: 17.3010, val_MinusLogProbMetric: 17.3010

Epoch 21: val_loss did not improve from 16.89876
196/196 - 9s - loss: 16.9657 - MinusLogProbMetric: 16.9657 - val_loss: 17.3010 - val_MinusLogProbMetric: 17.3010 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 22/1000
2023-09-12 14:39:36.383 
Epoch 22/1000 
	 loss: 16.9225, MinusLogProbMetric: 16.9225, val_loss: 16.9569, val_MinusLogProbMetric: 16.9569

Epoch 22: val_loss did not improve from 16.89876
196/196 - 9s - loss: 16.9225 - MinusLogProbMetric: 16.9225 - val_loss: 16.9569 - val_MinusLogProbMetric: 16.9569 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 23/1000
2023-09-12 14:39:45.732 
Epoch 23/1000 
	 loss: 16.9076, MinusLogProbMetric: 16.9076, val_loss: 16.9788, val_MinusLogProbMetric: 16.9788

Epoch 23: val_loss did not improve from 16.89876
196/196 - 9s - loss: 16.9076 - MinusLogProbMetric: 16.9076 - val_loss: 16.9788 - val_MinusLogProbMetric: 16.9788 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 24/1000
2023-09-12 14:39:55.299 
Epoch 24/1000 
	 loss: 16.9092, MinusLogProbMetric: 16.9092, val_loss: 16.9407, val_MinusLogProbMetric: 16.9407

Epoch 24: val_loss did not improve from 16.89876
196/196 - 10s - loss: 16.9092 - MinusLogProbMetric: 16.9092 - val_loss: 16.9407 - val_MinusLogProbMetric: 16.9407 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 25/1000
2023-09-12 14:40:04.638 
Epoch 25/1000 
	 loss: 16.8990, MinusLogProbMetric: 16.8990, val_loss: 16.8439, val_MinusLogProbMetric: 16.8439

Epoch 25: val_loss improved from 16.89876 to 16.84386, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 16.8990 - MinusLogProbMetric: 16.8990 - val_loss: 16.8439 - val_MinusLogProbMetric: 16.8439 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 26/1000
2023-09-12 14:40:14.139 
Epoch 26/1000 
	 loss: 16.8645, MinusLogProbMetric: 16.8645, val_loss: 16.8297, val_MinusLogProbMetric: 16.8297

Epoch 26: val_loss improved from 16.84386 to 16.82969, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 10s - loss: 16.8645 - MinusLogProbMetric: 16.8645 - val_loss: 16.8297 - val_MinusLogProbMetric: 16.8297 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 27/1000
2023-09-12 14:40:23.627 
Epoch 27/1000 
	 loss: 16.8840, MinusLogProbMetric: 16.8840, val_loss: 16.8752, val_MinusLogProbMetric: 16.8752

Epoch 27: val_loss did not improve from 16.82969
196/196 - 9s - loss: 16.8840 - MinusLogProbMetric: 16.8840 - val_loss: 16.8752 - val_MinusLogProbMetric: 16.8752 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 28/1000
2023-09-12 14:40:32.876 
Epoch 28/1000 
	 loss: 16.8386, MinusLogProbMetric: 16.8386, val_loss: 16.9713, val_MinusLogProbMetric: 16.9713

Epoch 28: val_loss did not improve from 16.82969
196/196 - 9s - loss: 16.8386 - MinusLogProbMetric: 16.8386 - val_loss: 16.9713 - val_MinusLogProbMetric: 16.9713 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 29/1000
2023-09-12 14:40:41.972 
Epoch 29/1000 
	 loss: 16.8494, MinusLogProbMetric: 16.8494, val_loss: 16.9850, val_MinusLogProbMetric: 16.9850

Epoch 29: val_loss did not improve from 16.82969
196/196 - 9s - loss: 16.8494 - MinusLogProbMetric: 16.8494 - val_loss: 16.9850 - val_MinusLogProbMetric: 16.9850 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 30/1000
2023-09-12 14:40:51.090 
Epoch 30/1000 
	 loss: 16.8338, MinusLogProbMetric: 16.8338, val_loss: 17.0120, val_MinusLogProbMetric: 17.0120

Epoch 30: val_loss did not improve from 16.82969
196/196 - 9s - loss: 16.8338 - MinusLogProbMetric: 16.8338 - val_loss: 17.0120 - val_MinusLogProbMetric: 17.0120 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 31/1000
2023-09-12 14:41:00.468 
Epoch 31/1000 
	 loss: 16.8266, MinusLogProbMetric: 16.8266, val_loss: 16.9372, val_MinusLogProbMetric: 16.9372

Epoch 31: val_loss did not improve from 16.82969
196/196 - 9s - loss: 16.8266 - MinusLogProbMetric: 16.8266 - val_loss: 16.9372 - val_MinusLogProbMetric: 16.9372 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 32/1000
2023-09-12 14:41:09.662 
Epoch 32/1000 
	 loss: 16.8284, MinusLogProbMetric: 16.8284, val_loss: 16.8049, val_MinusLogProbMetric: 16.8049

Epoch 32: val_loss improved from 16.82969 to 16.80494, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 16.8284 - MinusLogProbMetric: 16.8284 - val_loss: 16.8049 - val_MinusLogProbMetric: 16.8049 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 33/1000
2023-09-12 14:41:19.059 
Epoch 33/1000 
	 loss: 16.8212, MinusLogProbMetric: 16.8212, val_loss: 16.8941, val_MinusLogProbMetric: 16.8941

Epoch 33: val_loss did not improve from 16.80494
196/196 - 9s - loss: 16.8212 - MinusLogProbMetric: 16.8212 - val_loss: 16.8941 - val_MinusLogProbMetric: 16.8941 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 34/1000
2023-09-12 14:41:28.502 
Epoch 34/1000 
	 loss: 16.8201, MinusLogProbMetric: 16.8201, val_loss: 16.8153, val_MinusLogProbMetric: 16.8153

Epoch 34: val_loss did not improve from 16.80494
196/196 - 9s - loss: 16.8201 - MinusLogProbMetric: 16.8201 - val_loss: 16.8153 - val_MinusLogProbMetric: 16.8153 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 35/1000
2023-09-12 14:41:38.135 
Epoch 35/1000 
	 loss: 16.7921, MinusLogProbMetric: 16.7921, val_loss: 17.1775, val_MinusLogProbMetric: 17.1775

Epoch 35: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7921 - MinusLogProbMetric: 16.7921 - val_loss: 17.1775 - val_MinusLogProbMetric: 17.1775 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 36/1000
2023-09-12 14:41:47.706 
Epoch 36/1000 
	 loss: 16.8180, MinusLogProbMetric: 16.8180, val_loss: 17.0772, val_MinusLogProbMetric: 17.0772

Epoch 36: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.8180 - MinusLogProbMetric: 16.8180 - val_loss: 17.0772 - val_MinusLogProbMetric: 17.0772 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 37/1000
2023-09-12 14:41:57.543 
Epoch 37/1000 
	 loss: 16.8145, MinusLogProbMetric: 16.8145, val_loss: 16.9943, val_MinusLogProbMetric: 16.9943

Epoch 37: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.8145 - MinusLogProbMetric: 16.8145 - val_loss: 16.9943 - val_MinusLogProbMetric: 16.9943 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 38/1000
2023-09-12 14:42:07.420 
Epoch 38/1000 
	 loss: 16.7991, MinusLogProbMetric: 16.7991, val_loss: 17.0223, val_MinusLogProbMetric: 17.0223

Epoch 38: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7991 - MinusLogProbMetric: 16.7991 - val_loss: 17.0223 - val_MinusLogProbMetric: 17.0223 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 39/1000
2023-09-12 14:42:17.299 
Epoch 39/1000 
	 loss: 16.7933, MinusLogProbMetric: 16.7933, val_loss: 17.0500, val_MinusLogProbMetric: 17.0500

Epoch 39: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7933 - MinusLogProbMetric: 16.7933 - val_loss: 17.0500 - val_MinusLogProbMetric: 17.0500 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 40/1000
2023-09-12 14:42:27.245 
Epoch 40/1000 
	 loss: 16.7885, MinusLogProbMetric: 16.7885, val_loss: 17.0248, val_MinusLogProbMetric: 17.0248

Epoch 40: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7885 - MinusLogProbMetric: 16.7885 - val_loss: 17.0248 - val_MinusLogProbMetric: 17.0248 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 41/1000
2023-09-12 14:42:37.188 
Epoch 41/1000 
	 loss: 16.7819, MinusLogProbMetric: 16.7819, val_loss: 16.8113, val_MinusLogProbMetric: 16.8113

Epoch 41: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7819 - MinusLogProbMetric: 16.7819 - val_loss: 16.8113 - val_MinusLogProbMetric: 16.8113 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 42/1000
2023-09-12 14:42:47.602 
Epoch 42/1000 
	 loss: 16.7654, MinusLogProbMetric: 16.7654, val_loss: 16.9762, val_MinusLogProbMetric: 16.9762

Epoch 42: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7654 - MinusLogProbMetric: 16.7654 - val_loss: 16.9762 - val_MinusLogProbMetric: 16.9762 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 43/1000
2023-09-12 14:42:57.478 
Epoch 43/1000 
	 loss: 16.7587, MinusLogProbMetric: 16.7587, val_loss: 16.8817, val_MinusLogProbMetric: 16.8817

Epoch 43: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7587 - MinusLogProbMetric: 16.7587 - val_loss: 16.8817 - val_MinusLogProbMetric: 16.8817 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 44/1000
2023-09-12 14:43:08.602 
Epoch 44/1000 
	 loss: 16.7400, MinusLogProbMetric: 16.7400, val_loss: 16.8318, val_MinusLogProbMetric: 16.8318

Epoch 44: val_loss did not improve from 16.80494
196/196 - 11s - loss: 16.7400 - MinusLogProbMetric: 16.7400 - val_loss: 16.8318 - val_MinusLogProbMetric: 16.8318 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 45/1000
2023-09-12 14:43:18.422 
Epoch 45/1000 
	 loss: 16.7624, MinusLogProbMetric: 16.7624, val_loss: 16.8099, val_MinusLogProbMetric: 16.8099

Epoch 45: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7624 - MinusLogProbMetric: 16.7624 - val_loss: 16.8099 - val_MinusLogProbMetric: 16.8099 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 46/1000
2023-09-12 14:43:28.175 
Epoch 46/1000 
	 loss: 16.7531, MinusLogProbMetric: 16.7531, val_loss: 16.8834, val_MinusLogProbMetric: 16.8834

Epoch 46: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7531 - MinusLogProbMetric: 16.7531 - val_loss: 16.8834 - val_MinusLogProbMetric: 16.8834 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 47/1000
2023-09-12 14:43:38.456 
Epoch 47/1000 
	 loss: 16.7514, MinusLogProbMetric: 16.7514, val_loss: 16.8890, val_MinusLogProbMetric: 16.8890

Epoch 47: val_loss did not improve from 16.80494
196/196 - 10s - loss: 16.7514 - MinusLogProbMetric: 16.7514 - val_loss: 16.8890 - val_MinusLogProbMetric: 16.8890 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 48/1000
2023-09-12 14:43:48.817 
Epoch 48/1000 
	 loss: 16.7428, MinusLogProbMetric: 16.7428, val_loss: 16.7888, val_MinusLogProbMetric: 16.7888

Epoch 48: val_loss improved from 16.80494 to 16.78881, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 10s - loss: 16.7428 - MinusLogProbMetric: 16.7428 - val_loss: 16.7888 - val_MinusLogProbMetric: 16.7888 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 49/1000
2023-09-12 14:43:59.830 
Epoch 49/1000 
	 loss: 16.7226, MinusLogProbMetric: 16.7226, val_loss: 16.8166, val_MinusLogProbMetric: 16.8166

Epoch 49: val_loss did not improve from 16.78881
196/196 - 11s - loss: 16.7226 - MinusLogProbMetric: 16.7226 - val_loss: 16.8166 - val_MinusLogProbMetric: 16.8166 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 50/1000
2023-09-12 14:44:11.201 
Epoch 50/1000 
	 loss: 16.7473, MinusLogProbMetric: 16.7473, val_loss: 16.7795, val_MinusLogProbMetric: 16.7795

Epoch 50: val_loss improved from 16.78881 to 16.77948, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 11s - loss: 16.7473 - MinusLogProbMetric: 16.7473 - val_loss: 16.7795 - val_MinusLogProbMetric: 16.7795 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 51/1000
2023-09-12 14:44:22.798 
Epoch 51/1000 
	 loss: 16.7378, MinusLogProbMetric: 16.7378, val_loss: 16.8135, val_MinusLogProbMetric: 16.8135

Epoch 51: val_loss did not improve from 16.77948
196/196 - 11s - loss: 16.7378 - MinusLogProbMetric: 16.7378 - val_loss: 16.8135 - val_MinusLogProbMetric: 16.8135 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 52/1000
2023-09-12 14:44:34.388 
Epoch 52/1000 
	 loss: 16.7259, MinusLogProbMetric: 16.7259, val_loss: 16.8158, val_MinusLogProbMetric: 16.8158

Epoch 52: val_loss did not improve from 16.77948
196/196 - 12s - loss: 16.7259 - MinusLogProbMetric: 16.7259 - val_loss: 16.8158 - val_MinusLogProbMetric: 16.8158 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 53/1000
2023-09-12 14:44:45.872 
Epoch 53/1000 
	 loss: 16.7281, MinusLogProbMetric: 16.7281, val_loss: 16.8898, val_MinusLogProbMetric: 16.8898

Epoch 53: val_loss did not improve from 16.77948
196/196 - 11s - loss: 16.7281 - MinusLogProbMetric: 16.7281 - val_loss: 16.8898 - val_MinusLogProbMetric: 16.8898 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 54/1000
2023-09-12 14:44:57.253 
Epoch 54/1000 
	 loss: 16.7310, MinusLogProbMetric: 16.7310, val_loss: 16.8600, val_MinusLogProbMetric: 16.8600

Epoch 54: val_loss did not improve from 16.77948
196/196 - 11s - loss: 16.7310 - MinusLogProbMetric: 16.7310 - val_loss: 16.8600 - val_MinusLogProbMetric: 16.8600 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 55/1000
2023-09-12 14:45:08.603 
Epoch 55/1000 
	 loss: 16.7229, MinusLogProbMetric: 16.7229, val_loss: 16.7404, val_MinusLogProbMetric: 16.7404

Epoch 55: val_loss improved from 16.77948 to 16.74037, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 11s - loss: 16.7229 - MinusLogProbMetric: 16.7229 - val_loss: 16.7404 - val_MinusLogProbMetric: 16.7404 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 56/1000
2023-09-12 14:45:20.079 
Epoch 56/1000 
	 loss: 16.7179, MinusLogProbMetric: 16.7179, val_loss: 16.7386, val_MinusLogProbMetric: 16.7386

Epoch 56: val_loss improved from 16.74037 to 16.73858, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 11s - loss: 16.7179 - MinusLogProbMetric: 16.7179 - val_loss: 16.7386 - val_MinusLogProbMetric: 16.7386 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 57/1000
2023-09-12 14:45:31.652 
Epoch 57/1000 
	 loss: 16.7188, MinusLogProbMetric: 16.7188, val_loss: 16.7367, val_MinusLogProbMetric: 16.7367

Epoch 57: val_loss improved from 16.73858 to 16.73669, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.7188 - MinusLogProbMetric: 16.7188 - val_loss: 16.7367 - val_MinusLogProbMetric: 16.7367 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 58/1000
2023-09-12 14:45:43.242 
Epoch 58/1000 
	 loss: 16.7105, MinusLogProbMetric: 16.7105, val_loss: 16.7392, val_MinusLogProbMetric: 16.7392

Epoch 58: val_loss did not improve from 16.73669
196/196 - 11s - loss: 16.7105 - MinusLogProbMetric: 16.7105 - val_loss: 16.7392 - val_MinusLogProbMetric: 16.7392 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 59/1000
2023-09-12 14:45:54.733 
Epoch 59/1000 
	 loss: 16.7073, MinusLogProbMetric: 16.7073, val_loss: 16.7838, val_MinusLogProbMetric: 16.7838

Epoch 59: val_loss did not improve from 16.73669
196/196 - 11s - loss: 16.7073 - MinusLogProbMetric: 16.7073 - val_loss: 16.7838 - val_MinusLogProbMetric: 16.7838 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 60/1000
2023-09-12 14:46:06.312 
Epoch 60/1000 
	 loss: 16.7127, MinusLogProbMetric: 16.7127, val_loss: 16.7242, val_MinusLogProbMetric: 16.7242

Epoch 60: val_loss improved from 16.73669 to 16.72417, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.7127 - MinusLogProbMetric: 16.7127 - val_loss: 16.7242 - val_MinusLogProbMetric: 16.7242 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 61/1000
2023-09-12 14:46:17.772 
Epoch 61/1000 
	 loss: 16.7141, MinusLogProbMetric: 16.7141, val_loss: 16.7352, val_MinusLogProbMetric: 16.7352

Epoch 61: val_loss did not improve from 16.72417
196/196 - 11s - loss: 16.7141 - MinusLogProbMetric: 16.7141 - val_loss: 16.7352 - val_MinusLogProbMetric: 16.7352 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 62/1000
2023-09-12 14:46:29.272 
Epoch 62/1000 
	 loss: 16.7011, MinusLogProbMetric: 16.7011, val_loss: 16.9174, val_MinusLogProbMetric: 16.9174

Epoch 62: val_loss did not improve from 16.72417
196/196 - 11s - loss: 16.7011 - MinusLogProbMetric: 16.7011 - val_loss: 16.9174 - val_MinusLogProbMetric: 16.9174 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 63/1000
2023-09-12 14:46:40.909 
Epoch 63/1000 
	 loss: 16.7007, MinusLogProbMetric: 16.7007, val_loss: 16.8223, val_MinusLogProbMetric: 16.8223

Epoch 63: val_loss did not improve from 16.72417
196/196 - 12s - loss: 16.7007 - MinusLogProbMetric: 16.7007 - val_loss: 16.8223 - val_MinusLogProbMetric: 16.8223 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 64/1000
2023-09-12 14:46:52.425 
Epoch 64/1000 
	 loss: 16.6959, MinusLogProbMetric: 16.6959, val_loss: 16.6896, val_MinusLogProbMetric: 16.6896

Epoch 64: val_loss improved from 16.72417 to 16.68964, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.6959 - MinusLogProbMetric: 16.6959 - val_loss: 16.6896 - val_MinusLogProbMetric: 16.6896 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 65/1000
2023-09-12 14:47:04.164 
Epoch 65/1000 
	 loss: 16.6921, MinusLogProbMetric: 16.6921, val_loss: 16.7271, val_MinusLogProbMetric: 16.7271

Epoch 65: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6921 - MinusLogProbMetric: 16.6921 - val_loss: 16.7271 - val_MinusLogProbMetric: 16.7271 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 66/1000
2023-09-12 14:47:15.823 
Epoch 66/1000 
	 loss: 16.7032, MinusLogProbMetric: 16.7032, val_loss: 16.7511, val_MinusLogProbMetric: 16.7511

Epoch 66: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.7032 - MinusLogProbMetric: 16.7032 - val_loss: 16.7511 - val_MinusLogProbMetric: 16.7511 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-12 14:47:27.701 
Epoch 67/1000 
	 loss: 16.6732, MinusLogProbMetric: 16.6732, val_loss: 16.7495, val_MinusLogProbMetric: 16.7495

Epoch 67: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6732 - MinusLogProbMetric: 16.6732 - val_loss: 16.7495 - val_MinusLogProbMetric: 16.7495 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 68/1000
2023-09-12 14:47:39.431 
Epoch 68/1000 
	 loss: 16.6783, MinusLogProbMetric: 16.6783, val_loss: 16.7904, val_MinusLogProbMetric: 16.7904

Epoch 68: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6783 - MinusLogProbMetric: 16.6783 - val_loss: 16.7904 - val_MinusLogProbMetric: 16.7904 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 69/1000
2023-09-12 14:47:50.958 
Epoch 69/1000 
	 loss: 16.6850, MinusLogProbMetric: 16.6850, val_loss: 16.8052, val_MinusLogProbMetric: 16.8052

Epoch 69: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6850 - MinusLogProbMetric: 16.6850 - val_loss: 16.8052 - val_MinusLogProbMetric: 16.8052 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 70/1000
2023-09-12 14:48:02.482 
Epoch 70/1000 
	 loss: 16.6894, MinusLogProbMetric: 16.6894, val_loss: 16.8014, val_MinusLogProbMetric: 16.8014

Epoch 70: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6894 - MinusLogProbMetric: 16.6894 - val_loss: 16.8014 - val_MinusLogProbMetric: 16.8014 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 71/1000
2023-09-12 14:48:14.224 
Epoch 71/1000 
	 loss: 16.6890, MinusLogProbMetric: 16.6890, val_loss: 16.7540, val_MinusLogProbMetric: 16.7540

Epoch 71: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6890 - MinusLogProbMetric: 16.6890 - val_loss: 16.7540 - val_MinusLogProbMetric: 16.7540 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 72/1000
2023-09-12 14:48:25.806 
Epoch 72/1000 
	 loss: 16.6732, MinusLogProbMetric: 16.6732, val_loss: 16.7346, val_MinusLogProbMetric: 16.7346

Epoch 72: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6732 - MinusLogProbMetric: 16.6732 - val_loss: 16.7346 - val_MinusLogProbMetric: 16.7346 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 73/1000
2023-09-12 14:48:37.452 
Epoch 73/1000 
	 loss: 16.6782, MinusLogProbMetric: 16.6782, val_loss: 16.6953, val_MinusLogProbMetric: 16.6953

Epoch 73: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6782 - MinusLogProbMetric: 16.6782 - val_loss: 16.6953 - val_MinusLogProbMetric: 16.6953 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 74/1000
2023-09-12 14:48:49.253 
Epoch 74/1000 
	 loss: 16.6763, MinusLogProbMetric: 16.6763, val_loss: 16.7930, val_MinusLogProbMetric: 16.7930

Epoch 74: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6763 - MinusLogProbMetric: 16.6763 - val_loss: 16.7930 - val_MinusLogProbMetric: 16.7930 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-12 14:49:00.990 
Epoch 75/1000 
	 loss: 16.6838, MinusLogProbMetric: 16.6838, val_loss: 16.7442, val_MinusLogProbMetric: 16.7442

Epoch 75: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6838 - MinusLogProbMetric: 16.6838 - val_loss: 16.7442 - val_MinusLogProbMetric: 16.7442 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 76/1000
2023-09-12 14:49:12.565 
Epoch 76/1000 
	 loss: 16.6583, MinusLogProbMetric: 16.6583, val_loss: 16.7271, val_MinusLogProbMetric: 16.7271

Epoch 76: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6583 - MinusLogProbMetric: 16.6583 - val_loss: 16.7271 - val_MinusLogProbMetric: 16.7271 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 77/1000
2023-09-12 14:49:24.172 
Epoch 77/1000 
	 loss: 16.6659, MinusLogProbMetric: 16.6659, val_loss: 16.7811, val_MinusLogProbMetric: 16.7811

Epoch 77: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6659 - MinusLogProbMetric: 16.6659 - val_loss: 16.7811 - val_MinusLogProbMetric: 16.7811 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 78/1000
2023-09-12 14:49:35.707 
Epoch 78/1000 
	 loss: 16.6790, MinusLogProbMetric: 16.6790, val_loss: 16.8920, val_MinusLogProbMetric: 16.8920

Epoch 78: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6790 - MinusLogProbMetric: 16.6790 - val_loss: 16.8920 - val_MinusLogProbMetric: 16.8920 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 79/1000
2023-09-12 14:49:47.340 
Epoch 79/1000 
	 loss: 16.6643, MinusLogProbMetric: 16.6643, val_loss: 16.8047, val_MinusLogProbMetric: 16.8047

Epoch 79: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6643 - MinusLogProbMetric: 16.6643 - val_loss: 16.8047 - val_MinusLogProbMetric: 16.8047 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 80/1000
2023-09-12 14:49:58.957 
Epoch 80/1000 
	 loss: 16.6626, MinusLogProbMetric: 16.6626, val_loss: 16.8793, val_MinusLogProbMetric: 16.8793

Epoch 80: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6626 - MinusLogProbMetric: 16.6626 - val_loss: 16.8793 - val_MinusLogProbMetric: 16.8793 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-12 14:50:10.468 
Epoch 81/1000 
	 loss: 16.6685, MinusLogProbMetric: 16.6685, val_loss: 16.7450, val_MinusLogProbMetric: 16.7450

Epoch 81: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6685 - MinusLogProbMetric: 16.6685 - val_loss: 16.7450 - val_MinusLogProbMetric: 16.7450 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 82/1000
2023-09-12 14:50:22.166 
Epoch 82/1000 
	 loss: 16.6774, MinusLogProbMetric: 16.6774, val_loss: 16.7772, val_MinusLogProbMetric: 16.7772

Epoch 82: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6774 - MinusLogProbMetric: 16.6774 - val_loss: 16.7772 - val_MinusLogProbMetric: 16.7772 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-12 14:50:33.691 
Epoch 83/1000 
	 loss: 16.6536, MinusLogProbMetric: 16.6536, val_loss: 16.8675, val_MinusLogProbMetric: 16.8675

Epoch 83: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6536 - MinusLogProbMetric: 16.6536 - val_loss: 16.8675 - val_MinusLogProbMetric: 16.8675 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-12 14:50:45.159 
Epoch 84/1000 
	 loss: 16.6708, MinusLogProbMetric: 16.6708, val_loss: 16.7788, val_MinusLogProbMetric: 16.7788

Epoch 84: val_loss did not improve from 16.68964
196/196 - 11s - loss: 16.6708 - MinusLogProbMetric: 16.6708 - val_loss: 16.7788 - val_MinusLogProbMetric: 16.7788 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 85/1000
2023-09-12 14:50:56.940 
Epoch 85/1000 
	 loss: 16.6722, MinusLogProbMetric: 16.6722, val_loss: 16.7754, val_MinusLogProbMetric: 16.7754

Epoch 85: val_loss did not improve from 16.68964
196/196 - 12s - loss: 16.6722 - MinusLogProbMetric: 16.6722 - val_loss: 16.7754 - val_MinusLogProbMetric: 16.7754 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-12 14:51:07.538 
Epoch 86/1000 
	 loss: 16.6472, MinusLogProbMetric: 16.6472, val_loss: 16.6986, val_MinusLogProbMetric: 16.6986

Epoch 86: val_loss did not improve from 16.68964
196/196 - 11s - loss: 16.6472 - MinusLogProbMetric: 16.6472 - val_loss: 16.6986 - val_MinusLogProbMetric: 16.6986 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 87/1000
2023-09-12 14:51:17.504 
Epoch 87/1000 
	 loss: 16.6517, MinusLogProbMetric: 16.6517, val_loss: 16.7100, val_MinusLogProbMetric: 16.7100

Epoch 87: val_loss did not improve from 16.68964
196/196 - 10s - loss: 16.6517 - MinusLogProbMetric: 16.6517 - val_loss: 16.7100 - val_MinusLogProbMetric: 16.7100 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 88/1000
2023-09-12 14:51:25.537 
Epoch 88/1000 
	 loss: 16.6621, MinusLogProbMetric: 16.6621, val_loss: 16.7468, val_MinusLogProbMetric: 16.7468

Epoch 88: val_loss did not improve from 16.68964
196/196 - 8s - loss: 16.6621 - MinusLogProbMetric: 16.6621 - val_loss: 16.7468 - val_MinusLogProbMetric: 16.7468 - lr: 0.0010 - 8s/epoch - 41ms/step
Epoch 89/1000
2023-09-12 14:51:34.470 
Epoch 89/1000 
	 loss: 16.6437, MinusLogProbMetric: 16.6437, val_loss: 16.7845, val_MinusLogProbMetric: 16.7845

Epoch 89: val_loss did not improve from 16.68964
196/196 - 9s - loss: 16.6437 - MinusLogProbMetric: 16.6437 - val_loss: 16.7845 - val_MinusLogProbMetric: 16.7845 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 90/1000
2023-09-12 14:51:44.146 
Epoch 90/1000 
	 loss: 16.6543, MinusLogProbMetric: 16.6543, val_loss: 16.7039, val_MinusLogProbMetric: 16.7039

Epoch 90: val_loss did not improve from 16.68964
196/196 - 10s - loss: 16.6543 - MinusLogProbMetric: 16.6543 - val_loss: 16.7039 - val_MinusLogProbMetric: 16.7039 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 91/1000
2023-09-12 14:51:52.095 
Epoch 91/1000 
	 loss: 16.6446, MinusLogProbMetric: 16.6446, val_loss: 16.7104, val_MinusLogProbMetric: 16.7104

Epoch 91: val_loss did not improve from 16.68964
196/196 - 8s - loss: 16.6446 - MinusLogProbMetric: 16.6446 - val_loss: 16.7104 - val_MinusLogProbMetric: 16.7104 - lr: 0.0010 - 8s/epoch - 40ms/step
Epoch 92/1000
2023-09-12 14:52:01.302 
Epoch 92/1000 
	 loss: 16.6520, MinusLogProbMetric: 16.6520, val_loss: 16.6832, val_MinusLogProbMetric: 16.6832

Epoch 92: val_loss improved from 16.68964 to 16.68319, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 16.6520 - MinusLogProbMetric: 16.6520 - val_loss: 16.6832 - val_MinusLogProbMetric: 16.6832 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 93/1000
2023-09-12 14:52:10.865 
Epoch 93/1000 
	 loss: 16.6748, MinusLogProbMetric: 16.6748, val_loss: 16.8515, val_MinusLogProbMetric: 16.8515

Epoch 93: val_loss did not improve from 16.68319
196/196 - 10s - loss: 16.6748 - MinusLogProbMetric: 16.6748 - val_loss: 16.8515 - val_MinusLogProbMetric: 16.8515 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 94/1000
2023-09-12 14:52:20.741 
Epoch 94/1000 
	 loss: 16.6499, MinusLogProbMetric: 16.6499, val_loss: 16.7888, val_MinusLogProbMetric: 16.7888

Epoch 94: val_loss did not improve from 16.68319
196/196 - 10s - loss: 16.6499 - MinusLogProbMetric: 16.6499 - val_loss: 16.7888 - val_MinusLogProbMetric: 16.7888 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 95/1000
2023-09-12 14:52:29.271 
Epoch 95/1000 
	 loss: 16.6412, MinusLogProbMetric: 16.6412, val_loss: 16.6904, val_MinusLogProbMetric: 16.6904

Epoch 95: val_loss did not improve from 16.68319
196/196 - 9s - loss: 16.6412 - MinusLogProbMetric: 16.6412 - val_loss: 16.6904 - val_MinusLogProbMetric: 16.6904 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 96/1000
2023-09-12 14:52:36.476 
Epoch 96/1000 
	 loss: 16.6391, MinusLogProbMetric: 16.6391, val_loss: 16.6709, val_MinusLogProbMetric: 16.6709

Epoch 96: val_loss improved from 16.68319 to 16.67089, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 16.6391 - MinusLogProbMetric: 16.6391 - val_loss: 16.6709 - val_MinusLogProbMetric: 16.6709 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 97/1000
2023-09-12 14:52:45.161 
Epoch 97/1000 
	 loss: 16.6466, MinusLogProbMetric: 16.6466, val_loss: 16.6802, val_MinusLogProbMetric: 16.6802

Epoch 97: val_loss did not improve from 16.67089
196/196 - 7s - loss: 16.6466 - MinusLogProbMetric: 16.6466 - val_loss: 16.6802 - val_MinusLogProbMetric: 16.6802 - lr: 0.0010 - 7s/epoch - 37ms/step
Epoch 98/1000
2023-09-12 14:52:52.560 
Epoch 98/1000 
	 loss: 16.6509, MinusLogProbMetric: 16.6509, val_loss: 16.7233, val_MinusLogProbMetric: 16.7233

Epoch 98: val_loss did not improve from 16.67089
196/196 - 7s - loss: 16.6509 - MinusLogProbMetric: 16.6509 - val_loss: 16.7233 - val_MinusLogProbMetric: 16.7233 - lr: 0.0010 - 7s/epoch - 38ms/step
Epoch 99/1000
2023-09-12 14:53:01.141 
Epoch 99/1000 
	 loss: 16.6433, MinusLogProbMetric: 16.6433, val_loss: 16.7768, val_MinusLogProbMetric: 16.7768

Epoch 99: val_loss did not improve from 16.67089
196/196 - 9s - loss: 16.6433 - MinusLogProbMetric: 16.6433 - val_loss: 16.7768 - val_MinusLogProbMetric: 16.7768 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 100/1000
2023-09-12 14:53:11.290 
Epoch 100/1000 
	 loss: 16.6380, MinusLogProbMetric: 16.6380, val_loss: 16.7451, val_MinusLogProbMetric: 16.7451

Epoch 100: val_loss did not improve from 16.67089
196/196 - 10s - loss: 16.6380 - MinusLogProbMetric: 16.6380 - val_loss: 16.7451 - val_MinusLogProbMetric: 16.7451 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 101/1000
2023-09-12 14:53:20.537 
Epoch 101/1000 
	 loss: 16.6433, MinusLogProbMetric: 16.6433, val_loss: 16.6682, val_MinusLogProbMetric: 16.6682

Epoch 101: val_loss improved from 16.67089 to 16.66821, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 16.6433 - MinusLogProbMetric: 16.6433 - val_loss: 16.6682 - val_MinusLogProbMetric: 16.6682 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 102/1000
2023-09-12 14:53:30.760 
Epoch 102/1000 
	 loss: 16.6359, MinusLogProbMetric: 16.6359, val_loss: 16.7742, val_MinusLogProbMetric: 16.7742

Epoch 102: val_loss did not improve from 16.66821
196/196 - 10s - loss: 16.6359 - MinusLogProbMetric: 16.6359 - val_loss: 16.7742 - val_MinusLogProbMetric: 16.7742 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 103/1000
2023-09-12 14:53:42.530 
Epoch 103/1000 
	 loss: 16.6650, MinusLogProbMetric: 16.6650, val_loss: 16.6698, val_MinusLogProbMetric: 16.6698

Epoch 103: val_loss did not improve from 16.66821
196/196 - 12s - loss: 16.6650 - MinusLogProbMetric: 16.6650 - val_loss: 16.6698 - val_MinusLogProbMetric: 16.6698 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 104/1000
2023-09-12 14:53:53.968 
Epoch 104/1000 
	 loss: 16.6279, MinusLogProbMetric: 16.6279, val_loss: 16.7112, val_MinusLogProbMetric: 16.7112

Epoch 104: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6279 - MinusLogProbMetric: 16.6279 - val_loss: 16.7112 - val_MinusLogProbMetric: 16.7112 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 105/1000
2023-09-12 14:54:05.505 
Epoch 105/1000 
	 loss: 16.6457, MinusLogProbMetric: 16.6457, val_loss: 16.7713, val_MinusLogProbMetric: 16.7713

Epoch 105: val_loss did not improve from 16.66821
196/196 - 12s - loss: 16.6457 - MinusLogProbMetric: 16.6457 - val_loss: 16.7713 - val_MinusLogProbMetric: 16.7713 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 106/1000
2023-09-12 14:54:17.021 
Epoch 106/1000 
	 loss: 16.6425, MinusLogProbMetric: 16.6425, val_loss: 16.7740, val_MinusLogProbMetric: 16.7740

Epoch 106: val_loss did not improve from 16.66821
196/196 - 12s - loss: 16.6425 - MinusLogProbMetric: 16.6425 - val_loss: 16.7740 - val_MinusLogProbMetric: 16.7740 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 107/1000
2023-09-12 14:54:28.542 
Epoch 107/1000 
	 loss: 16.6497, MinusLogProbMetric: 16.6497, val_loss: 16.6700, val_MinusLogProbMetric: 16.6700

Epoch 107: val_loss did not improve from 16.66821
196/196 - 12s - loss: 16.6497 - MinusLogProbMetric: 16.6497 - val_loss: 16.6700 - val_MinusLogProbMetric: 16.6700 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 108/1000
2023-09-12 14:54:39.971 
Epoch 108/1000 
	 loss: 16.6384, MinusLogProbMetric: 16.6384, val_loss: 16.8201, val_MinusLogProbMetric: 16.8201

Epoch 108: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6384 - MinusLogProbMetric: 16.6384 - val_loss: 16.8201 - val_MinusLogProbMetric: 16.8201 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 109/1000
2023-09-12 14:54:51.385 
Epoch 109/1000 
	 loss: 16.6417, MinusLogProbMetric: 16.6417, val_loss: 16.7405, val_MinusLogProbMetric: 16.7405

Epoch 109: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6417 - MinusLogProbMetric: 16.6417 - val_loss: 16.7405 - val_MinusLogProbMetric: 16.7405 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 14:55:02.977 
Epoch 110/1000 
	 loss: 16.6276, MinusLogProbMetric: 16.6276, val_loss: 16.7463, val_MinusLogProbMetric: 16.7463

Epoch 110: val_loss did not improve from 16.66821
196/196 - 12s - loss: 16.6276 - MinusLogProbMetric: 16.6276 - val_loss: 16.7463 - val_MinusLogProbMetric: 16.7463 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 111/1000
2023-09-12 14:55:14.501 
Epoch 111/1000 
	 loss: 16.6505, MinusLogProbMetric: 16.6505, val_loss: 16.7201, val_MinusLogProbMetric: 16.7201

Epoch 111: val_loss did not improve from 16.66821
196/196 - 12s - loss: 16.6505 - MinusLogProbMetric: 16.6505 - val_loss: 16.7201 - val_MinusLogProbMetric: 16.7201 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 112/1000
2023-09-12 14:55:25.914 
Epoch 112/1000 
	 loss: 16.6188, MinusLogProbMetric: 16.6188, val_loss: 16.6682, val_MinusLogProbMetric: 16.6682

Epoch 112: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6188 - MinusLogProbMetric: 16.6188 - val_loss: 16.6682 - val_MinusLogProbMetric: 16.6682 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-12 14:55:37.465 
Epoch 113/1000 
	 loss: 16.6284, MinusLogProbMetric: 16.6284, val_loss: 16.7265, val_MinusLogProbMetric: 16.7265

Epoch 113: val_loss did not improve from 16.66821
196/196 - 12s - loss: 16.6284 - MinusLogProbMetric: 16.6284 - val_loss: 16.7265 - val_MinusLogProbMetric: 16.7265 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 114/1000
2023-09-12 14:55:48.947 
Epoch 114/1000 
	 loss: 16.6285, MinusLogProbMetric: 16.6285, val_loss: 16.6865, val_MinusLogProbMetric: 16.6865

Epoch 114: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6285 - MinusLogProbMetric: 16.6285 - val_loss: 16.6865 - val_MinusLogProbMetric: 16.6865 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 115/1000
2023-09-12 14:56:00.445 
Epoch 115/1000 
	 loss: 16.6291, MinusLogProbMetric: 16.6291, val_loss: 16.7304, val_MinusLogProbMetric: 16.7304

Epoch 115: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6291 - MinusLogProbMetric: 16.6291 - val_loss: 16.7304 - val_MinusLogProbMetric: 16.7304 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 116/1000
2023-09-12 14:56:11.888 
Epoch 116/1000 
	 loss: 16.6162, MinusLogProbMetric: 16.6162, val_loss: 16.7067, val_MinusLogProbMetric: 16.7067

Epoch 116: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6162 - MinusLogProbMetric: 16.6162 - val_loss: 16.7067 - val_MinusLogProbMetric: 16.7067 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 117/1000
2023-09-12 14:56:23.280 
Epoch 117/1000 
	 loss: 16.6300, MinusLogProbMetric: 16.6300, val_loss: 16.6925, val_MinusLogProbMetric: 16.6925

Epoch 117: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6300 - MinusLogProbMetric: 16.6300 - val_loss: 16.6925 - val_MinusLogProbMetric: 16.6925 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 118/1000
2023-09-12 14:56:34.717 
Epoch 118/1000 
	 loss: 16.6214, MinusLogProbMetric: 16.6214, val_loss: 16.8338, val_MinusLogProbMetric: 16.8338

Epoch 118: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6214 - MinusLogProbMetric: 16.6214 - val_loss: 16.8338 - val_MinusLogProbMetric: 16.8338 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 119/1000
2023-09-12 14:56:46.096 
Epoch 119/1000 
	 loss: 16.6261, MinusLogProbMetric: 16.6261, val_loss: 16.7185, val_MinusLogProbMetric: 16.7185

Epoch 119: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6261 - MinusLogProbMetric: 16.6261 - val_loss: 16.7185 - val_MinusLogProbMetric: 16.7185 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 120/1000
2023-09-12 14:56:57.486 
Epoch 120/1000 
	 loss: 16.6172, MinusLogProbMetric: 16.6172, val_loss: 16.8152, val_MinusLogProbMetric: 16.8152

Epoch 120: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6172 - MinusLogProbMetric: 16.6172 - val_loss: 16.8152 - val_MinusLogProbMetric: 16.8152 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 121/1000
2023-09-12 14:57:08.823 
Epoch 121/1000 
	 loss: 16.6269, MinusLogProbMetric: 16.6269, val_loss: 17.0083, val_MinusLogProbMetric: 17.0083

Epoch 121: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6269 - MinusLogProbMetric: 16.6269 - val_loss: 17.0083 - val_MinusLogProbMetric: 17.0083 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 122/1000
2023-09-12 14:57:20.214 
Epoch 122/1000 
	 loss: 16.6154, MinusLogProbMetric: 16.6154, val_loss: 16.7315, val_MinusLogProbMetric: 16.7315

Epoch 122: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6154 - MinusLogProbMetric: 16.6154 - val_loss: 16.7315 - val_MinusLogProbMetric: 16.7315 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 123/1000
2023-09-12 14:57:31.546 
Epoch 123/1000 
	 loss: 16.6192, MinusLogProbMetric: 16.6192, val_loss: 16.8215, val_MinusLogProbMetric: 16.8215

Epoch 123: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6192 - MinusLogProbMetric: 16.6192 - val_loss: 16.8215 - val_MinusLogProbMetric: 16.8215 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 124/1000
2023-09-12 14:57:42.977 
Epoch 124/1000 
	 loss: 16.6220, MinusLogProbMetric: 16.6220, val_loss: 16.8175, val_MinusLogProbMetric: 16.8175

Epoch 124: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6220 - MinusLogProbMetric: 16.6220 - val_loss: 16.8175 - val_MinusLogProbMetric: 16.8175 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 125/1000
2023-09-12 14:57:54.317 
Epoch 125/1000 
	 loss: 16.6309, MinusLogProbMetric: 16.6309, val_loss: 16.7073, val_MinusLogProbMetric: 16.7073

Epoch 125: val_loss did not improve from 16.66821
196/196 - 11s - loss: 16.6309 - MinusLogProbMetric: 16.6309 - val_loss: 16.7073 - val_MinusLogProbMetric: 16.7073 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 126/1000
2023-09-12 14:58:05.713 
Epoch 126/1000 
	 loss: 16.6158, MinusLogProbMetric: 16.6158, val_loss: 16.6670, val_MinusLogProbMetric: 16.6670

Epoch 126: val_loss improved from 16.66821 to 16.66699, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.6158 - MinusLogProbMetric: 16.6158 - val_loss: 16.6670 - val_MinusLogProbMetric: 16.6670 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 127/1000
2023-09-12 14:58:17.124 
Epoch 127/1000 
	 loss: 16.6159, MinusLogProbMetric: 16.6159, val_loss: 16.7173, val_MinusLogProbMetric: 16.7173

Epoch 127: val_loss did not improve from 16.66699
196/196 - 11s - loss: 16.6159 - MinusLogProbMetric: 16.6159 - val_loss: 16.7173 - val_MinusLogProbMetric: 16.7173 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 128/1000
2023-09-12 14:58:28.576 
Epoch 128/1000 
	 loss: 16.6197, MinusLogProbMetric: 16.6197, val_loss: 16.7958, val_MinusLogProbMetric: 16.7958

Epoch 128: val_loss did not improve from 16.66699
196/196 - 11s - loss: 16.6197 - MinusLogProbMetric: 16.6197 - val_loss: 16.7958 - val_MinusLogProbMetric: 16.7958 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 129/1000
2023-09-12 14:58:39.902 
Epoch 129/1000 
	 loss: 16.6125, MinusLogProbMetric: 16.6125, val_loss: 16.7177, val_MinusLogProbMetric: 16.7177

Epoch 129: val_loss did not improve from 16.66699
196/196 - 11s - loss: 16.6125 - MinusLogProbMetric: 16.6125 - val_loss: 16.7177 - val_MinusLogProbMetric: 16.7177 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 130/1000
2023-09-12 14:58:51.391 
Epoch 130/1000 
	 loss: 16.6173, MinusLogProbMetric: 16.6173, val_loss: 16.6959, val_MinusLogProbMetric: 16.6959

Epoch 130: val_loss did not improve from 16.66699
196/196 - 11s - loss: 16.6173 - MinusLogProbMetric: 16.6173 - val_loss: 16.6959 - val_MinusLogProbMetric: 16.6959 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 131/1000
2023-09-12 14:59:02.834 
Epoch 131/1000 
	 loss: 16.6042, MinusLogProbMetric: 16.6042, val_loss: 16.6670, val_MinusLogProbMetric: 16.6670

Epoch 131: val_loss improved from 16.66699 to 16.66698, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.6042 - MinusLogProbMetric: 16.6042 - val_loss: 16.6670 - val_MinusLogProbMetric: 16.6670 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 132/1000
2023-09-12 14:59:14.376 
Epoch 132/1000 
	 loss: 16.6031, MinusLogProbMetric: 16.6031, val_loss: 16.6940, val_MinusLogProbMetric: 16.6940

Epoch 132: val_loss did not improve from 16.66698
196/196 - 11s - loss: 16.6031 - MinusLogProbMetric: 16.6031 - val_loss: 16.6940 - val_MinusLogProbMetric: 16.6940 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 133/1000
2023-09-12 14:59:25.761 
Epoch 133/1000 
	 loss: 16.6164, MinusLogProbMetric: 16.6164, val_loss: 16.6592, val_MinusLogProbMetric: 16.6592

Epoch 133: val_loss improved from 16.66698 to 16.65919, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.6164 - MinusLogProbMetric: 16.6164 - val_loss: 16.6592 - val_MinusLogProbMetric: 16.6592 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 134/1000
2023-09-12 14:59:37.280 
Epoch 134/1000 
	 loss: 16.6024, MinusLogProbMetric: 16.6024, val_loss: 16.7066, val_MinusLogProbMetric: 16.7066

Epoch 134: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6024 - MinusLogProbMetric: 16.6024 - val_loss: 16.7066 - val_MinusLogProbMetric: 16.7066 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 135/1000
2023-09-12 14:59:48.676 
Epoch 135/1000 
	 loss: 16.6184, MinusLogProbMetric: 16.6184, val_loss: 16.7174, val_MinusLogProbMetric: 16.7174

Epoch 135: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6184 - MinusLogProbMetric: 16.6184 - val_loss: 16.7174 - val_MinusLogProbMetric: 16.7174 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 136/1000
2023-09-12 15:00:00.099 
Epoch 136/1000 
	 loss: 16.6139, MinusLogProbMetric: 16.6139, val_loss: 16.7087, val_MinusLogProbMetric: 16.7087

Epoch 136: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6139 - MinusLogProbMetric: 16.6139 - val_loss: 16.7087 - val_MinusLogProbMetric: 16.7087 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 137/1000
2023-09-12 15:00:11.595 
Epoch 137/1000 
	 loss: 16.6205, MinusLogProbMetric: 16.6205, val_loss: 16.7175, val_MinusLogProbMetric: 16.7175

Epoch 137: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6205 - MinusLogProbMetric: 16.6205 - val_loss: 16.7175 - val_MinusLogProbMetric: 16.7175 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 138/1000
2023-09-12 15:00:22.988 
Epoch 138/1000 
	 loss: 16.6035, MinusLogProbMetric: 16.6035, val_loss: 16.7014, val_MinusLogProbMetric: 16.7014

Epoch 138: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6035 - MinusLogProbMetric: 16.6035 - val_loss: 16.7014 - val_MinusLogProbMetric: 16.7014 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 139/1000
2023-09-12 15:00:34.382 
Epoch 139/1000 
	 loss: 16.6045, MinusLogProbMetric: 16.6045, val_loss: 16.7457, val_MinusLogProbMetric: 16.7457

Epoch 139: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6045 - MinusLogProbMetric: 16.6045 - val_loss: 16.7457 - val_MinusLogProbMetric: 16.7457 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 140/1000
2023-09-12 15:00:45.738 
Epoch 140/1000 
	 loss: 16.6034, MinusLogProbMetric: 16.6034, val_loss: 16.7287, val_MinusLogProbMetric: 16.7287

Epoch 140: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6034 - MinusLogProbMetric: 16.6034 - val_loss: 16.7287 - val_MinusLogProbMetric: 16.7287 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 141/1000
2023-09-12 15:00:57.193 
Epoch 141/1000 
	 loss: 16.6021, MinusLogProbMetric: 16.6021, val_loss: 16.6693, val_MinusLogProbMetric: 16.6693

Epoch 141: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6021 - MinusLogProbMetric: 16.6021 - val_loss: 16.6693 - val_MinusLogProbMetric: 16.6693 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 142/1000
2023-09-12 15:01:08.407 
Epoch 142/1000 
	 loss: 16.6055, MinusLogProbMetric: 16.6055, val_loss: 16.7398, val_MinusLogProbMetric: 16.7398

Epoch 142: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6055 - MinusLogProbMetric: 16.6055 - val_loss: 16.7398 - val_MinusLogProbMetric: 16.7398 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 143/1000
2023-09-12 15:01:19.856 
Epoch 143/1000 
	 loss: 16.6027, MinusLogProbMetric: 16.6027, val_loss: 16.7136, val_MinusLogProbMetric: 16.7136

Epoch 143: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6027 - MinusLogProbMetric: 16.6027 - val_loss: 16.7136 - val_MinusLogProbMetric: 16.7136 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-12 15:01:31.175 
Epoch 144/1000 
	 loss: 16.5985, MinusLogProbMetric: 16.5985, val_loss: 16.7542, val_MinusLogProbMetric: 16.7542

Epoch 144: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.5985 - MinusLogProbMetric: 16.5985 - val_loss: 16.7542 - val_MinusLogProbMetric: 16.7542 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 145/1000
2023-09-12 15:01:42.481 
Epoch 145/1000 
	 loss: 16.6099, MinusLogProbMetric: 16.6099, val_loss: 16.7463, val_MinusLogProbMetric: 16.7463

Epoch 145: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6099 - MinusLogProbMetric: 16.6099 - val_loss: 16.7463 - val_MinusLogProbMetric: 16.7463 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 146/1000
2023-09-12 15:01:53.762 
Epoch 146/1000 
	 loss: 16.6015, MinusLogProbMetric: 16.6015, val_loss: 16.7108, val_MinusLogProbMetric: 16.7108

Epoch 146: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6015 - MinusLogProbMetric: 16.6015 - val_loss: 16.7108 - val_MinusLogProbMetric: 16.7108 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-12 15:02:05.067 
Epoch 147/1000 
	 loss: 16.6144, MinusLogProbMetric: 16.6144, val_loss: 16.7848, val_MinusLogProbMetric: 16.7848

Epoch 147: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6144 - MinusLogProbMetric: 16.6144 - val_loss: 16.7848 - val_MinusLogProbMetric: 16.7848 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 148/1000
2023-09-12 15:02:16.530 
Epoch 148/1000 
	 loss: 16.6058, MinusLogProbMetric: 16.6058, val_loss: 16.8809, val_MinusLogProbMetric: 16.8809

Epoch 148: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6058 - MinusLogProbMetric: 16.6058 - val_loss: 16.8809 - val_MinusLogProbMetric: 16.8809 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 149/1000
2023-09-12 15:02:27.883 
Epoch 149/1000 
	 loss: 16.5996, MinusLogProbMetric: 16.5996, val_loss: 16.6867, val_MinusLogProbMetric: 16.6867

Epoch 149: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.5996 - MinusLogProbMetric: 16.5996 - val_loss: 16.6867 - val_MinusLogProbMetric: 16.6867 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-12 15:02:39.285 
Epoch 150/1000 
	 loss: 16.5979, MinusLogProbMetric: 16.5979, val_loss: 16.7103, val_MinusLogProbMetric: 16.7103

Epoch 150: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.5979 - MinusLogProbMetric: 16.5979 - val_loss: 16.7103 - val_MinusLogProbMetric: 16.7103 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 151/1000
2023-09-12 15:02:50.649 
Epoch 151/1000 
	 loss: 16.6002, MinusLogProbMetric: 16.6002, val_loss: 16.6865, val_MinusLogProbMetric: 16.6865

Epoch 151: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6002 - MinusLogProbMetric: 16.6002 - val_loss: 16.6865 - val_MinusLogProbMetric: 16.6865 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 152/1000
2023-09-12 15:03:02.140 
Epoch 152/1000 
	 loss: 16.6138, MinusLogProbMetric: 16.6138, val_loss: 16.7254, val_MinusLogProbMetric: 16.7254

Epoch 152: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6138 - MinusLogProbMetric: 16.6138 - val_loss: 16.7254 - val_MinusLogProbMetric: 16.7254 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 153/1000
2023-09-12 15:03:13.529 
Epoch 153/1000 
	 loss: 16.5977, MinusLogProbMetric: 16.5977, val_loss: 16.6908, val_MinusLogProbMetric: 16.6908

Epoch 153: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.5977 - MinusLogProbMetric: 16.5977 - val_loss: 16.6908 - val_MinusLogProbMetric: 16.6908 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 154/1000
2023-09-12 15:03:24.901 
Epoch 154/1000 
	 loss: 16.5989, MinusLogProbMetric: 16.5989, val_loss: 16.7554, val_MinusLogProbMetric: 16.7554

Epoch 154: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.5989 - MinusLogProbMetric: 16.5989 - val_loss: 16.7554 - val_MinusLogProbMetric: 16.7554 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 155/1000
2023-09-12 15:03:36.276 
Epoch 155/1000 
	 loss: 16.6002, MinusLogProbMetric: 16.6002, val_loss: 16.8272, val_MinusLogProbMetric: 16.8272

Epoch 155: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6002 - MinusLogProbMetric: 16.6002 - val_loss: 16.8272 - val_MinusLogProbMetric: 16.8272 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 156/1000
2023-09-12 15:03:47.638 
Epoch 156/1000 
	 loss: 16.6069, MinusLogProbMetric: 16.6069, val_loss: 16.8267, val_MinusLogProbMetric: 16.8267

Epoch 156: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.6069 - MinusLogProbMetric: 16.6069 - val_loss: 16.8267 - val_MinusLogProbMetric: 16.8267 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 157/1000
2023-09-12 15:03:58.979 
Epoch 157/1000 
	 loss: 16.5917, MinusLogProbMetric: 16.5917, val_loss: 16.6945, val_MinusLogProbMetric: 16.6945

Epoch 157: val_loss did not improve from 16.65919
196/196 - 11s - loss: 16.5917 - MinusLogProbMetric: 16.5917 - val_loss: 16.6945 - val_MinusLogProbMetric: 16.6945 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 158/1000
2023-09-12 15:04:10.546 
Epoch 158/1000 
	 loss: 16.5864, MinusLogProbMetric: 16.5864, val_loss: 16.7209, val_MinusLogProbMetric: 16.7209

Epoch 158: val_loss did not improve from 16.65919
196/196 - 12s - loss: 16.5864 - MinusLogProbMetric: 16.5864 - val_loss: 16.7209 - val_MinusLogProbMetric: 16.7209 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 159/1000
2023-09-12 15:04:21.939 
Epoch 159/1000 
	 loss: 16.5951, MinusLogProbMetric: 16.5951, val_loss: 16.6531, val_MinusLogProbMetric: 16.6531

Epoch 159: val_loss improved from 16.65919 to 16.65309, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.5951 - MinusLogProbMetric: 16.5951 - val_loss: 16.6531 - val_MinusLogProbMetric: 16.6531 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 160/1000
2023-09-12 15:04:33.385 
Epoch 160/1000 
	 loss: 16.5967, MinusLogProbMetric: 16.5967, val_loss: 16.6906, val_MinusLogProbMetric: 16.6906

Epoch 160: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5967 - MinusLogProbMetric: 16.5967 - val_loss: 16.6906 - val_MinusLogProbMetric: 16.6906 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 161/1000
2023-09-12 15:04:44.944 
Epoch 161/1000 
	 loss: 16.5956, MinusLogProbMetric: 16.5956, val_loss: 16.7581, val_MinusLogProbMetric: 16.7581

Epoch 161: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5956 - MinusLogProbMetric: 16.5956 - val_loss: 16.7581 - val_MinusLogProbMetric: 16.7581 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 162/1000
2023-09-12 15:04:56.320 
Epoch 162/1000 
	 loss: 16.6001, MinusLogProbMetric: 16.6001, val_loss: 16.6826, val_MinusLogProbMetric: 16.6826

Epoch 162: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.6001 - MinusLogProbMetric: 16.6001 - val_loss: 16.6826 - val_MinusLogProbMetric: 16.6826 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 163/1000
2023-09-12 15:05:07.879 
Epoch 163/1000 
	 loss: 16.5905, MinusLogProbMetric: 16.5905, val_loss: 16.7140, val_MinusLogProbMetric: 16.7140

Epoch 163: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5905 - MinusLogProbMetric: 16.5905 - val_loss: 16.7140 - val_MinusLogProbMetric: 16.7140 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 164/1000
2023-09-12 15:05:19.456 
Epoch 164/1000 
	 loss: 16.5865, MinusLogProbMetric: 16.5865, val_loss: 16.7318, val_MinusLogProbMetric: 16.7318

Epoch 164: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5865 - MinusLogProbMetric: 16.5865 - val_loss: 16.7318 - val_MinusLogProbMetric: 16.7318 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 165/1000
2023-09-12 15:05:30.942 
Epoch 165/1000 
	 loss: 16.5926, MinusLogProbMetric: 16.5926, val_loss: 16.7120, val_MinusLogProbMetric: 16.7120

Epoch 165: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5926 - MinusLogProbMetric: 16.5926 - val_loss: 16.7120 - val_MinusLogProbMetric: 16.7120 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 166/1000
2023-09-12 15:05:42.304 
Epoch 166/1000 
	 loss: 16.5865, MinusLogProbMetric: 16.5865, val_loss: 16.7209, val_MinusLogProbMetric: 16.7209

Epoch 166: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5865 - MinusLogProbMetric: 16.5865 - val_loss: 16.7209 - val_MinusLogProbMetric: 16.7209 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 167/1000
2023-09-12 15:05:53.696 
Epoch 167/1000 
	 loss: 16.5883, MinusLogProbMetric: 16.5883, val_loss: 16.7279, val_MinusLogProbMetric: 16.7279

Epoch 167: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5883 - MinusLogProbMetric: 16.5883 - val_loss: 16.7279 - val_MinusLogProbMetric: 16.7279 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 168/1000
2023-09-12 15:06:05.131 
Epoch 168/1000 
	 loss: 16.5870, MinusLogProbMetric: 16.5870, val_loss: 16.7543, val_MinusLogProbMetric: 16.7543

Epoch 168: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5870 - MinusLogProbMetric: 16.5870 - val_loss: 16.7543 - val_MinusLogProbMetric: 16.7543 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 169/1000
2023-09-12 15:06:16.562 
Epoch 169/1000 
	 loss: 16.5918, MinusLogProbMetric: 16.5918, val_loss: 16.7375, val_MinusLogProbMetric: 16.7375

Epoch 169: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5918 - MinusLogProbMetric: 16.5918 - val_loss: 16.7375 - val_MinusLogProbMetric: 16.7375 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 170/1000
2023-09-12 15:06:28.016 
Epoch 170/1000 
	 loss: 16.5961, MinusLogProbMetric: 16.5961, val_loss: 16.7343, val_MinusLogProbMetric: 16.7343

Epoch 170: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5961 - MinusLogProbMetric: 16.5961 - val_loss: 16.7343 - val_MinusLogProbMetric: 16.7343 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 171/1000
2023-09-12 15:06:39.446 
Epoch 171/1000 
	 loss: 16.5796, MinusLogProbMetric: 16.5796, val_loss: 16.7082, val_MinusLogProbMetric: 16.7082

Epoch 171: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5796 - MinusLogProbMetric: 16.5796 - val_loss: 16.7082 - val_MinusLogProbMetric: 16.7082 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 172/1000
2023-09-12 15:06:51.021 
Epoch 172/1000 
	 loss: 16.5922, MinusLogProbMetric: 16.5922, val_loss: 16.7883, val_MinusLogProbMetric: 16.7883

Epoch 172: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5922 - MinusLogProbMetric: 16.5922 - val_loss: 16.7883 - val_MinusLogProbMetric: 16.7883 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 173/1000
2023-09-12 15:07:02.459 
Epoch 173/1000 
	 loss: 16.5812, MinusLogProbMetric: 16.5812, val_loss: 16.6890, val_MinusLogProbMetric: 16.6890

Epoch 173: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5812 - MinusLogProbMetric: 16.5812 - val_loss: 16.6890 - val_MinusLogProbMetric: 16.6890 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 174/1000
2023-09-12 15:07:14.003 
Epoch 174/1000 
	 loss: 16.5869, MinusLogProbMetric: 16.5869, val_loss: 16.6866, val_MinusLogProbMetric: 16.6866

Epoch 174: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5869 - MinusLogProbMetric: 16.5869 - val_loss: 16.6866 - val_MinusLogProbMetric: 16.6866 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 175/1000
2023-09-12 15:07:25.609 
Epoch 175/1000 
	 loss: 16.5801, MinusLogProbMetric: 16.5801, val_loss: 16.6848, val_MinusLogProbMetric: 16.6848

Epoch 175: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5801 - MinusLogProbMetric: 16.5801 - val_loss: 16.6848 - val_MinusLogProbMetric: 16.6848 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 176/1000
2023-09-12 15:07:37.264 
Epoch 176/1000 
	 loss: 16.5860, MinusLogProbMetric: 16.5860, val_loss: 16.7401, val_MinusLogProbMetric: 16.7401

Epoch 176: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5860 - MinusLogProbMetric: 16.5860 - val_loss: 16.7401 - val_MinusLogProbMetric: 16.7401 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 177/1000
2023-09-12 15:07:48.819 
Epoch 177/1000 
	 loss: 16.5739, MinusLogProbMetric: 16.5739, val_loss: 16.7357, val_MinusLogProbMetric: 16.7357

Epoch 177: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5739 - MinusLogProbMetric: 16.5739 - val_loss: 16.7357 - val_MinusLogProbMetric: 16.7357 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 178/1000
2023-09-12 15:08:00.304 
Epoch 178/1000 
	 loss: 16.5776, MinusLogProbMetric: 16.5776, val_loss: 16.7512, val_MinusLogProbMetric: 16.7512

Epoch 178: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5776 - MinusLogProbMetric: 16.5776 - val_loss: 16.7512 - val_MinusLogProbMetric: 16.7512 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 179/1000
2023-09-12 15:08:11.833 
Epoch 179/1000 
	 loss: 16.5828, MinusLogProbMetric: 16.5828, val_loss: 16.6893, val_MinusLogProbMetric: 16.6893

Epoch 179: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5828 - MinusLogProbMetric: 16.5828 - val_loss: 16.6893 - val_MinusLogProbMetric: 16.6893 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 180/1000
2023-09-12 15:08:23.328 
Epoch 180/1000 
	 loss: 16.5720, MinusLogProbMetric: 16.5720, val_loss: 16.6897, val_MinusLogProbMetric: 16.6897

Epoch 180: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5720 - MinusLogProbMetric: 16.5720 - val_loss: 16.6897 - val_MinusLogProbMetric: 16.6897 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 181/1000
2023-09-12 15:08:34.846 
Epoch 181/1000 
	 loss: 16.5912, MinusLogProbMetric: 16.5912, val_loss: 16.6728, val_MinusLogProbMetric: 16.6728

Epoch 181: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5912 - MinusLogProbMetric: 16.5912 - val_loss: 16.6728 - val_MinusLogProbMetric: 16.6728 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 182/1000
2023-09-12 15:08:46.313 
Epoch 182/1000 
	 loss: 16.5710, MinusLogProbMetric: 16.5710, val_loss: 16.7022, val_MinusLogProbMetric: 16.7022

Epoch 182: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5710 - MinusLogProbMetric: 16.5710 - val_loss: 16.7022 - val_MinusLogProbMetric: 16.7022 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 183/1000
2023-09-12 15:08:57.801 
Epoch 183/1000 
	 loss: 16.5834, MinusLogProbMetric: 16.5834, val_loss: 16.6919, val_MinusLogProbMetric: 16.6919

Epoch 183: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5834 - MinusLogProbMetric: 16.5834 - val_loss: 16.6919 - val_MinusLogProbMetric: 16.6919 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 184/1000
2023-09-12 15:09:09.284 
Epoch 184/1000 
	 loss: 16.5840, MinusLogProbMetric: 16.5840, val_loss: 16.6751, val_MinusLogProbMetric: 16.6751

Epoch 184: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5840 - MinusLogProbMetric: 16.5840 - val_loss: 16.6751 - val_MinusLogProbMetric: 16.6751 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 185/1000
2023-09-12 15:09:20.778 
Epoch 185/1000 
	 loss: 16.5903, MinusLogProbMetric: 16.5903, val_loss: 16.7133, val_MinusLogProbMetric: 16.7133

Epoch 185: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5903 - MinusLogProbMetric: 16.5903 - val_loss: 16.7133 - val_MinusLogProbMetric: 16.7133 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 186/1000
2023-09-12 15:09:32.243 
Epoch 186/1000 
	 loss: 16.5757, MinusLogProbMetric: 16.5757, val_loss: 16.7123, val_MinusLogProbMetric: 16.7123

Epoch 186: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5757 - MinusLogProbMetric: 16.5757 - val_loss: 16.7123 - val_MinusLogProbMetric: 16.7123 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 187/1000
2023-09-12 15:09:43.865 
Epoch 187/1000 
	 loss: 16.5722, MinusLogProbMetric: 16.5722, val_loss: 16.6886, val_MinusLogProbMetric: 16.6886

Epoch 187: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5722 - MinusLogProbMetric: 16.5722 - val_loss: 16.6886 - val_MinusLogProbMetric: 16.6886 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 188/1000
2023-09-12 15:09:55.364 
Epoch 188/1000 
	 loss: 16.5846, MinusLogProbMetric: 16.5846, val_loss: 16.6877, val_MinusLogProbMetric: 16.6877

Epoch 188: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5846 - MinusLogProbMetric: 16.5846 - val_loss: 16.6877 - val_MinusLogProbMetric: 16.6877 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 189/1000
2023-09-12 15:10:06.903 
Epoch 189/1000 
	 loss: 16.5707, MinusLogProbMetric: 16.5707, val_loss: 16.6788, val_MinusLogProbMetric: 16.6788

Epoch 189: val_loss did not improve from 16.65309
196/196 - 12s - loss: 16.5707 - MinusLogProbMetric: 16.5707 - val_loss: 16.6788 - val_MinusLogProbMetric: 16.6788 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 190/1000
2023-09-12 15:10:18.305 
Epoch 190/1000 
	 loss: 16.5723, MinusLogProbMetric: 16.5723, val_loss: 16.7360, val_MinusLogProbMetric: 16.7360

Epoch 190: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5723 - MinusLogProbMetric: 16.5723 - val_loss: 16.7360 - val_MinusLogProbMetric: 16.7360 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 191/1000
2023-09-12 15:10:29.698 
Epoch 191/1000 
	 loss: 16.5805, MinusLogProbMetric: 16.5805, val_loss: 16.7360, val_MinusLogProbMetric: 16.7360

Epoch 191: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5805 - MinusLogProbMetric: 16.5805 - val_loss: 16.7360 - val_MinusLogProbMetric: 16.7360 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 192/1000
2023-09-12 15:10:41.060 
Epoch 192/1000 
	 loss: 16.5720, MinusLogProbMetric: 16.5720, val_loss: 16.6875, val_MinusLogProbMetric: 16.6875

Epoch 192: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5720 - MinusLogProbMetric: 16.5720 - val_loss: 16.6875 - val_MinusLogProbMetric: 16.6875 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 193/1000
2023-09-12 15:10:52.484 
Epoch 193/1000 
	 loss: 16.5787, MinusLogProbMetric: 16.5787, val_loss: 16.6648, val_MinusLogProbMetric: 16.6648

Epoch 193: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5787 - MinusLogProbMetric: 16.5787 - val_loss: 16.6648 - val_MinusLogProbMetric: 16.6648 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 194/1000
2023-09-12 15:11:03.848 
Epoch 194/1000 
	 loss: 16.5739, MinusLogProbMetric: 16.5739, val_loss: 16.6801, val_MinusLogProbMetric: 16.6801

Epoch 194: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5739 - MinusLogProbMetric: 16.5739 - val_loss: 16.6801 - val_MinusLogProbMetric: 16.6801 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 195/1000
2023-09-12 15:11:15.164 
Epoch 195/1000 
	 loss: 16.5692, MinusLogProbMetric: 16.5692, val_loss: 16.6716, val_MinusLogProbMetric: 16.6716

Epoch 195: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5692 - MinusLogProbMetric: 16.5692 - val_loss: 16.6716 - val_MinusLogProbMetric: 16.6716 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 196/1000
2023-09-12 15:11:26.542 
Epoch 196/1000 
	 loss: 16.5692, MinusLogProbMetric: 16.5692, val_loss: 16.6718, val_MinusLogProbMetric: 16.6718

Epoch 196: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5692 - MinusLogProbMetric: 16.5692 - val_loss: 16.6718 - val_MinusLogProbMetric: 16.6718 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 197/1000
2023-09-12 15:11:37.897 
Epoch 197/1000 
	 loss: 16.5710, MinusLogProbMetric: 16.5710, val_loss: 16.7226, val_MinusLogProbMetric: 16.7226

Epoch 197: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5710 - MinusLogProbMetric: 16.5710 - val_loss: 16.7226 - val_MinusLogProbMetric: 16.7226 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 198/1000
2023-09-12 15:11:49.344 
Epoch 198/1000 
	 loss: 16.5690, MinusLogProbMetric: 16.5690, val_loss: 16.7239, val_MinusLogProbMetric: 16.7239

Epoch 198: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5690 - MinusLogProbMetric: 16.5690 - val_loss: 16.7239 - val_MinusLogProbMetric: 16.7239 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 199/1000
2023-09-12 15:11:59.815 
Epoch 199/1000 
	 loss: 16.5733, MinusLogProbMetric: 16.5733, val_loss: 16.6809, val_MinusLogProbMetric: 16.6809

Epoch 199: val_loss did not improve from 16.65309
196/196 - 10s - loss: 16.5733 - MinusLogProbMetric: 16.5733 - val_loss: 16.6809 - val_MinusLogProbMetric: 16.6809 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 200/1000
2023-09-12 15:12:11.255 
Epoch 200/1000 
	 loss: 16.5684, MinusLogProbMetric: 16.5684, val_loss: 16.7236, val_MinusLogProbMetric: 16.7236

Epoch 200: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5684 - MinusLogProbMetric: 16.5684 - val_loss: 16.7236 - val_MinusLogProbMetric: 16.7236 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 201/1000
2023-09-12 15:12:21.156 
Epoch 201/1000 
	 loss: 16.5741, MinusLogProbMetric: 16.5741, val_loss: 16.6890, val_MinusLogProbMetric: 16.6890

Epoch 201: val_loss did not improve from 16.65309
196/196 - 10s - loss: 16.5741 - MinusLogProbMetric: 16.5741 - val_loss: 16.6890 - val_MinusLogProbMetric: 16.6890 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 202/1000
2023-09-12 15:12:32.597 
Epoch 202/1000 
	 loss: 16.5707, MinusLogProbMetric: 16.5707, val_loss: 16.6957, val_MinusLogProbMetric: 16.6957

Epoch 202: val_loss did not improve from 16.65309
196/196 - 11s - loss: 16.5707 - MinusLogProbMetric: 16.5707 - val_loss: 16.6957 - val_MinusLogProbMetric: 16.6957 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 203/1000
2023-09-12 15:12:44.004 
Epoch 203/1000 
	 loss: 16.5633, MinusLogProbMetric: 16.5633, val_loss: 16.6436, val_MinusLogProbMetric: 16.6436

Epoch 203: val_loss improved from 16.65309 to 16.64360, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 12s - loss: 16.5633 - MinusLogProbMetric: 16.5633 - val_loss: 16.6436 - val_MinusLogProbMetric: 16.6436 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 204/1000
2023-09-12 15:12:55.784 
Epoch 204/1000 
	 loss: 16.5794, MinusLogProbMetric: 16.5794, val_loss: 16.7158, val_MinusLogProbMetric: 16.7158

Epoch 204: val_loss did not improve from 16.64360
196/196 - 12s - loss: 16.5794 - MinusLogProbMetric: 16.5794 - val_loss: 16.7158 - val_MinusLogProbMetric: 16.7158 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 205/1000
2023-09-12 15:13:07.227 
Epoch 205/1000 
	 loss: 16.5624, MinusLogProbMetric: 16.5624, val_loss: 16.7005, val_MinusLogProbMetric: 16.7005

Epoch 205: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5624 - MinusLogProbMetric: 16.5624 - val_loss: 16.7005 - val_MinusLogProbMetric: 16.7005 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-12 15:13:18.732 
Epoch 206/1000 
	 loss: 16.5739, MinusLogProbMetric: 16.5739, val_loss: 16.6764, val_MinusLogProbMetric: 16.6764

Epoch 206: val_loss did not improve from 16.64360
196/196 - 12s - loss: 16.5739 - MinusLogProbMetric: 16.5739 - val_loss: 16.6764 - val_MinusLogProbMetric: 16.6764 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-12 15:13:29.145 
Epoch 207/1000 
	 loss: 16.5632, MinusLogProbMetric: 16.5632, val_loss: 16.6860, val_MinusLogProbMetric: 16.6860

Epoch 207: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5632 - MinusLogProbMetric: 16.5632 - val_loss: 16.6860 - val_MinusLogProbMetric: 16.6860 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 208/1000
2023-09-12 15:13:40.351 
Epoch 208/1000 
	 loss: 16.5601, MinusLogProbMetric: 16.5601, val_loss: 16.7131, val_MinusLogProbMetric: 16.7131

Epoch 208: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5601 - MinusLogProbMetric: 16.5601 - val_loss: 16.7131 - val_MinusLogProbMetric: 16.7131 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 209/1000
2023-09-12 15:13:51.697 
Epoch 209/1000 
	 loss: 16.5693, MinusLogProbMetric: 16.5693, val_loss: 16.6810, val_MinusLogProbMetric: 16.6810

Epoch 209: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5693 - MinusLogProbMetric: 16.5693 - val_loss: 16.6810 - val_MinusLogProbMetric: 16.6810 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 210/1000
2023-09-12 15:14:02.861 
Epoch 210/1000 
	 loss: 16.5664, MinusLogProbMetric: 16.5664, val_loss: 16.7328, val_MinusLogProbMetric: 16.7328

Epoch 210: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5664 - MinusLogProbMetric: 16.5664 - val_loss: 16.7328 - val_MinusLogProbMetric: 16.7328 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 211/1000
2023-09-12 15:14:13.690 
Epoch 211/1000 
	 loss: 16.5699, MinusLogProbMetric: 16.5699, val_loss: 16.6661, val_MinusLogProbMetric: 16.6661

Epoch 211: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5699 - MinusLogProbMetric: 16.5699 - val_loss: 16.6661 - val_MinusLogProbMetric: 16.6661 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 212/1000
2023-09-12 15:14:24.384 
Epoch 212/1000 
	 loss: 16.5617, MinusLogProbMetric: 16.5617, val_loss: 16.7708, val_MinusLogProbMetric: 16.7708

Epoch 212: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5617 - MinusLogProbMetric: 16.5617 - val_loss: 16.7708 - val_MinusLogProbMetric: 16.7708 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 213/1000
2023-09-12 15:14:35.563 
Epoch 213/1000 
	 loss: 16.5694, MinusLogProbMetric: 16.5694, val_loss: 16.7253, val_MinusLogProbMetric: 16.7253

Epoch 213: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5694 - MinusLogProbMetric: 16.5694 - val_loss: 16.7253 - val_MinusLogProbMetric: 16.7253 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 214/1000
2023-09-12 15:14:46.889 
Epoch 214/1000 
	 loss: 16.5617, MinusLogProbMetric: 16.5617, val_loss: 16.7151, val_MinusLogProbMetric: 16.7151

Epoch 214: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5617 - MinusLogProbMetric: 16.5617 - val_loss: 16.7151 - val_MinusLogProbMetric: 16.7151 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 215/1000
2023-09-12 15:14:57.933 
Epoch 215/1000 
	 loss: 16.5656, MinusLogProbMetric: 16.5656, val_loss: 16.6813, val_MinusLogProbMetric: 16.6813

Epoch 215: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5656 - MinusLogProbMetric: 16.5656 - val_loss: 16.6813 - val_MinusLogProbMetric: 16.6813 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 216/1000
2023-09-12 15:15:09.095 
Epoch 216/1000 
	 loss: 16.5624, MinusLogProbMetric: 16.5624, val_loss: 16.7581, val_MinusLogProbMetric: 16.7581

Epoch 216: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5624 - MinusLogProbMetric: 16.5624 - val_loss: 16.7581 - val_MinusLogProbMetric: 16.7581 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 217/1000
2023-09-12 15:15:19.524 
Epoch 217/1000 
	 loss: 16.5656, MinusLogProbMetric: 16.5656, val_loss: 16.6979, val_MinusLogProbMetric: 16.6979

Epoch 217: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5656 - MinusLogProbMetric: 16.5656 - val_loss: 16.6979 - val_MinusLogProbMetric: 16.6979 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 218/1000
2023-09-12 15:15:30.712 
Epoch 218/1000 
	 loss: 16.5594, MinusLogProbMetric: 16.5594, val_loss: 16.6746, val_MinusLogProbMetric: 16.6746

Epoch 218: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5594 - MinusLogProbMetric: 16.5594 - val_loss: 16.6746 - val_MinusLogProbMetric: 16.6746 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 219/1000
2023-09-12 15:15:41.861 
Epoch 219/1000 
	 loss: 16.5511, MinusLogProbMetric: 16.5511, val_loss: 16.6578, val_MinusLogProbMetric: 16.6578

Epoch 219: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5511 - MinusLogProbMetric: 16.5511 - val_loss: 16.6578 - val_MinusLogProbMetric: 16.6578 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 220/1000
2023-09-12 15:15:53.020 
Epoch 220/1000 
	 loss: 16.5594, MinusLogProbMetric: 16.5594, val_loss: 16.6937, val_MinusLogProbMetric: 16.6937

Epoch 220: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5594 - MinusLogProbMetric: 16.5594 - val_loss: 16.6937 - val_MinusLogProbMetric: 16.6937 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 221/1000
2023-09-12 15:16:04.226 
Epoch 221/1000 
	 loss: 16.5727, MinusLogProbMetric: 16.5727, val_loss: 16.6565, val_MinusLogProbMetric: 16.6565

Epoch 221: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5727 - MinusLogProbMetric: 16.5727 - val_loss: 16.6565 - val_MinusLogProbMetric: 16.6565 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 222/1000
2023-09-12 15:16:15.526 
Epoch 222/1000 
	 loss: 16.5509, MinusLogProbMetric: 16.5509, val_loss: 16.7210, val_MinusLogProbMetric: 16.7210

Epoch 222: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5509 - MinusLogProbMetric: 16.5509 - val_loss: 16.7210 - val_MinusLogProbMetric: 16.7210 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 223/1000
2023-09-12 15:16:26.672 
Epoch 223/1000 
	 loss: 16.5534, MinusLogProbMetric: 16.5534, val_loss: 16.6684, val_MinusLogProbMetric: 16.6684

Epoch 223: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5534 - MinusLogProbMetric: 16.5534 - val_loss: 16.6684 - val_MinusLogProbMetric: 16.6684 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 224/1000
2023-09-12 15:16:37.951 
Epoch 224/1000 
	 loss: 16.5638, MinusLogProbMetric: 16.5638, val_loss: 16.7075, val_MinusLogProbMetric: 16.7075

Epoch 224: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5638 - MinusLogProbMetric: 16.5638 - val_loss: 16.7075 - val_MinusLogProbMetric: 16.7075 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 225/1000
2023-09-12 15:16:49.055 
Epoch 225/1000 
	 loss: 16.5610, MinusLogProbMetric: 16.5610, val_loss: 16.6904, val_MinusLogProbMetric: 16.6904

Epoch 225: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5610 - MinusLogProbMetric: 16.5610 - val_loss: 16.6904 - val_MinusLogProbMetric: 16.6904 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 226/1000
2023-09-12 15:17:00.102 
Epoch 226/1000 
	 loss: 16.5626, MinusLogProbMetric: 16.5626, val_loss: 16.6898, val_MinusLogProbMetric: 16.6898

Epoch 226: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5626 - MinusLogProbMetric: 16.5626 - val_loss: 16.6898 - val_MinusLogProbMetric: 16.6898 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 227/1000
2023-09-12 15:17:11.039 
Epoch 227/1000 
	 loss: 16.5518, MinusLogProbMetric: 16.5518, val_loss: 16.6580, val_MinusLogProbMetric: 16.6580

Epoch 227: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5518 - MinusLogProbMetric: 16.5518 - val_loss: 16.6580 - val_MinusLogProbMetric: 16.6580 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 228/1000
2023-09-12 15:17:22.220 
Epoch 228/1000 
	 loss: 16.5573, MinusLogProbMetric: 16.5573, val_loss: 16.7435, val_MinusLogProbMetric: 16.7435

Epoch 228: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5573 - MinusLogProbMetric: 16.5573 - val_loss: 16.7435 - val_MinusLogProbMetric: 16.7435 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 229/1000
2023-09-12 15:17:33.360 
Epoch 229/1000 
	 loss: 16.5581, MinusLogProbMetric: 16.5581, val_loss: 16.7423, val_MinusLogProbMetric: 16.7423

Epoch 229: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5581 - MinusLogProbMetric: 16.5581 - val_loss: 16.7423 - val_MinusLogProbMetric: 16.7423 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 230/1000
2023-09-12 15:17:44.429 
Epoch 230/1000 
	 loss: 16.5493, MinusLogProbMetric: 16.5493, val_loss: 16.6864, val_MinusLogProbMetric: 16.6864

Epoch 230: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5493 - MinusLogProbMetric: 16.5493 - val_loss: 16.6864 - val_MinusLogProbMetric: 16.6864 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 231/1000
2023-09-12 15:17:53.850 
Epoch 231/1000 
	 loss: 16.5597, MinusLogProbMetric: 16.5597, val_loss: 16.7024, val_MinusLogProbMetric: 16.7024

Epoch 231: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5597 - MinusLogProbMetric: 16.5597 - val_loss: 16.7024 - val_MinusLogProbMetric: 16.7024 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 232/1000
2023-09-12 15:18:03.346 
Epoch 232/1000 
	 loss: 16.5481, MinusLogProbMetric: 16.5481, val_loss: 16.6685, val_MinusLogProbMetric: 16.6685

Epoch 232: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5481 - MinusLogProbMetric: 16.5481 - val_loss: 16.6685 - val_MinusLogProbMetric: 16.6685 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 233/1000
2023-09-12 15:18:12.879 
Epoch 233/1000 
	 loss: 16.5481, MinusLogProbMetric: 16.5481, val_loss: 16.6787, val_MinusLogProbMetric: 16.6787

Epoch 233: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5481 - MinusLogProbMetric: 16.5481 - val_loss: 16.6787 - val_MinusLogProbMetric: 16.6787 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 234/1000
2023-09-12 15:18:22.712 
Epoch 234/1000 
	 loss: 16.5578, MinusLogProbMetric: 16.5578, val_loss: 16.6849, val_MinusLogProbMetric: 16.6849

Epoch 234: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5578 - MinusLogProbMetric: 16.5578 - val_loss: 16.6849 - val_MinusLogProbMetric: 16.6849 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 235/1000
2023-09-12 15:18:34.148 
Epoch 235/1000 
	 loss: 16.5479, MinusLogProbMetric: 16.5479, val_loss: 16.6797, val_MinusLogProbMetric: 16.6797

Epoch 235: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5479 - MinusLogProbMetric: 16.5479 - val_loss: 16.6797 - val_MinusLogProbMetric: 16.6797 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 236/1000
2023-09-12 15:18:45.382 
Epoch 236/1000 
	 loss: 16.5516, MinusLogProbMetric: 16.5516, val_loss: 16.7174, val_MinusLogProbMetric: 16.7174

Epoch 236: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5516 - MinusLogProbMetric: 16.5516 - val_loss: 16.7174 - val_MinusLogProbMetric: 16.7174 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 237/1000
2023-09-12 15:18:56.224 
Epoch 237/1000 
	 loss: 16.5473, MinusLogProbMetric: 16.5473, val_loss: 16.6701, val_MinusLogProbMetric: 16.6701

Epoch 237: val_loss did not improve from 16.64360
196/196 - 11s - loss: 16.5473 - MinusLogProbMetric: 16.5473 - val_loss: 16.6701 - val_MinusLogProbMetric: 16.6701 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 238/1000
2023-09-12 15:19:05.923 
Epoch 238/1000 
	 loss: 16.5447, MinusLogProbMetric: 16.5447, val_loss: 16.6507, val_MinusLogProbMetric: 16.6507

Epoch 238: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5447 - MinusLogProbMetric: 16.5447 - val_loss: 16.6507 - val_MinusLogProbMetric: 16.6507 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 239/1000
2023-09-12 15:19:15.912 
Epoch 239/1000 
	 loss: 16.5430, MinusLogProbMetric: 16.5430, val_loss: 16.6670, val_MinusLogProbMetric: 16.6670

Epoch 239: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5430 - MinusLogProbMetric: 16.5430 - val_loss: 16.6670 - val_MinusLogProbMetric: 16.6670 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 240/1000
2023-09-12 15:19:25.926 
Epoch 240/1000 
	 loss: 16.5492, MinusLogProbMetric: 16.5492, val_loss: 16.7042, val_MinusLogProbMetric: 16.7042

Epoch 240: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5492 - MinusLogProbMetric: 16.5492 - val_loss: 16.7042 - val_MinusLogProbMetric: 16.7042 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 241/1000
2023-09-12 15:19:35.607 
Epoch 241/1000 
	 loss: 16.5491, MinusLogProbMetric: 16.5491, val_loss: 16.7323, val_MinusLogProbMetric: 16.7323

Epoch 241: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5491 - MinusLogProbMetric: 16.5491 - val_loss: 16.7323 - val_MinusLogProbMetric: 16.7323 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 242/1000
2023-09-12 15:19:45.290 
Epoch 242/1000 
	 loss: 16.5539, MinusLogProbMetric: 16.5539, val_loss: 16.8000, val_MinusLogProbMetric: 16.8000

Epoch 242: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5539 - MinusLogProbMetric: 16.5539 - val_loss: 16.8000 - val_MinusLogProbMetric: 16.8000 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 243/1000
2023-09-12 15:19:54.797 
Epoch 243/1000 
	 loss: 16.5507, MinusLogProbMetric: 16.5507, val_loss: 16.7346, val_MinusLogProbMetric: 16.7346

Epoch 243: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5507 - MinusLogProbMetric: 16.5507 - val_loss: 16.7346 - val_MinusLogProbMetric: 16.7346 - lr: 0.0010 - 10s/epoch - 48ms/step
Epoch 244/1000
2023-09-12 15:20:04.197 
Epoch 244/1000 
	 loss: 16.5536, MinusLogProbMetric: 16.5536, val_loss: 16.6991, val_MinusLogProbMetric: 16.6991

Epoch 244: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5536 - MinusLogProbMetric: 16.5536 - val_loss: 16.6991 - val_MinusLogProbMetric: 16.6991 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 245/1000
2023-09-12 15:20:13.681 
Epoch 245/1000 
	 loss: 16.5616, MinusLogProbMetric: 16.5616, val_loss: 16.6620, val_MinusLogProbMetric: 16.6620

Epoch 245: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5616 - MinusLogProbMetric: 16.5616 - val_loss: 16.6620 - val_MinusLogProbMetric: 16.6620 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 246/1000
2023-09-12 15:20:23.467 
Epoch 246/1000 
	 loss: 16.5420, MinusLogProbMetric: 16.5420, val_loss: 16.7057, val_MinusLogProbMetric: 16.7057

Epoch 246: val_loss did not improve from 16.64360
196/196 - 10s - loss: 16.5420 - MinusLogProbMetric: 16.5420 - val_loss: 16.7057 - val_MinusLogProbMetric: 16.7057 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 247/1000
2023-09-12 15:20:32.912 
Epoch 247/1000 
	 loss: 16.5468, MinusLogProbMetric: 16.5468, val_loss: 16.6825, val_MinusLogProbMetric: 16.6825

Epoch 247: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5468 - MinusLogProbMetric: 16.5468 - val_loss: 16.6825 - val_MinusLogProbMetric: 16.6825 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 248/1000
2023-09-12 15:20:42.293 
Epoch 248/1000 
	 loss: 16.5486, MinusLogProbMetric: 16.5486, val_loss: 16.6718, val_MinusLogProbMetric: 16.6718

Epoch 248: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5486 - MinusLogProbMetric: 16.5486 - val_loss: 16.6718 - val_MinusLogProbMetric: 16.6718 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 249/1000
2023-09-12 15:20:51.747 
Epoch 249/1000 
	 loss: 16.5427, MinusLogProbMetric: 16.5427, val_loss: 16.6751, val_MinusLogProbMetric: 16.6751

Epoch 249: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5427 - MinusLogProbMetric: 16.5427 - val_loss: 16.6751 - val_MinusLogProbMetric: 16.6751 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 250/1000
2023-09-12 15:21:01.133 
Epoch 250/1000 
	 loss: 16.5478, MinusLogProbMetric: 16.5478, val_loss: 16.7444, val_MinusLogProbMetric: 16.7444

Epoch 250: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5478 - MinusLogProbMetric: 16.5478 - val_loss: 16.7444 - val_MinusLogProbMetric: 16.7444 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 251/1000
2023-09-12 15:21:10.520 
Epoch 251/1000 
	 loss: 16.5453, MinusLogProbMetric: 16.5453, val_loss: 16.7012, val_MinusLogProbMetric: 16.7012

Epoch 251: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5453 - MinusLogProbMetric: 16.5453 - val_loss: 16.7012 - val_MinusLogProbMetric: 16.7012 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 252/1000
2023-09-12 15:21:19.868 
Epoch 252/1000 
	 loss: 16.5486, MinusLogProbMetric: 16.5486, val_loss: 16.7317, val_MinusLogProbMetric: 16.7317

Epoch 252: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5486 - MinusLogProbMetric: 16.5486 - val_loss: 16.7317 - val_MinusLogProbMetric: 16.7317 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 253/1000
2023-09-12 15:21:29.187 
Epoch 253/1000 
	 loss: 16.5582, MinusLogProbMetric: 16.5582, val_loss: 16.6630, val_MinusLogProbMetric: 16.6630

Epoch 253: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.5582 - MinusLogProbMetric: 16.5582 - val_loss: 16.6630 - val_MinusLogProbMetric: 16.6630 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 254/1000
2023-09-12 15:21:38.543 
Epoch 254/1000 
	 loss: 16.4982, MinusLogProbMetric: 16.4982, val_loss: 16.6542, val_MinusLogProbMetric: 16.6542

Epoch 254: val_loss did not improve from 16.64360
196/196 - 9s - loss: 16.4982 - MinusLogProbMetric: 16.4982 - val_loss: 16.6542 - val_MinusLogProbMetric: 16.6542 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 255/1000
2023-09-12 15:21:47.892 
Epoch 255/1000 
	 loss: 16.4943, MinusLogProbMetric: 16.4943, val_loss: 16.6410, val_MinusLogProbMetric: 16.6410

Epoch 255: val_loss improved from 16.64360 to 16.64100, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 9s - loss: 16.4943 - MinusLogProbMetric: 16.4943 - val_loss: 16.6410 - val_MinusLogProbMetric: 16.6410 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 256/1000
2023-09-12 15:21:57.914 
Epoch 256/1000 
	 loss: 16.4971, MinusLogProbMetric: 16.4971, val_loss: 16.6402, val_MinusLogProbMetric: 16.6402

Epoch 256: val_loss improved from 16.64100 to 16.64018, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 10s - loss: 16.4971 - MinusLogProbMetric: 16.4971 - val_loss: 16.6402 - val_MinusLogProbMetric: 16.6402 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 257/1000
2023-09-12 15:22:07.880 
Epoch 257/1000 
	 loss: 16.4921, MinusLogProbMetric: 16.4921, val_loss: 16.6267, val_MinusLogProbMetric: 16.6267

Epoch 257: val_loss improved from 16.64018 to 16.62674, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 10s - loss: 16.4921 - MinusLogProbMetric: 16.4921 - val_loss: 16.6267 - val_MinusLogProbMetric: 16.6267 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 258/1000
2023-09-12 15:22:17.378 
Epoch 258/1000 
	 loss: 16.4929, MinusLogProbMetric: 16.4929, val_loss: 16.6293, val_MinusLogProbMetric: 16.6293

Epoch 258: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4929 - MinusLogProbMetric: 16.4929 - val_loss: 16.6293 - val_MinusLogProbMetric: 16.6293 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 259/1000
2023-09-12 15:22:26.800 
Epoch 259/1000 
	 loss: 16.4902, MinusLogProbMetric: 16.4902, val_loss: 16.6415, val_MinusLogProbMetric: 16.6415

Epoch 259: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4902 - MinusLogProbMetric: 16.4902 - val_loss: 16.6415 - val_MinusLogProbMetric: 16.6415 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 260/1000
2023-09-12 15:22:36.295 
Epoch 260/1000 
	 loss: 16.4943, MinusLogProbMetric: 16.4943, val_loss: 16.6333, val_MinusLogProbMetric: 16.6333

Epoch 260: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4943 - MinusLogProbMetric: 16.4943 - val_loss: 16.6333 - val_MinusLogProbMetric: 16.6333 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 261/1000
2023-09-12 15:22:46.114 
Epoch 261/1000 
	 loss: 16.4926, MinusLogProbMetric: 16.4926, val_loss: 16.6392, val_MinusLogProbMetric: 16.6392

Epoch 261: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4926 - MinusLogProbMetric: 16.4926 - val_loss: 16.6392 - val_MinusLogProbMetric: 16.6392 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 262/1000
2023-09-12 15:22:55.640 
Epoch 262/1000 
	 loss: 16.4900, MinusLogProbMetric: 16.4900, val_loss: 16.6443, val_MinusLogProbMetric: 16.6443

Epoch 262: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4900 - MinusLogProbMetric: 16.4900 - val_loss: 16.6443 - val_MinusLogProbMetric: 16.6443 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 263/1000
2023-09-12 15:23:05.036 
Epoch 263/1000 
	 loss: 16.4934, MinusLogProbMetric: 16.4934, val_loss: 16.6305, val_MinusLogProbMetric: 16.6305

Epoch 263: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4934 - MinusLogProbMetric: 16.4934 - val_loss: 16.6305 - val_MinusLogProbMetric: 16.6305 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 264/1000
2023-09-12 15:23:15.927 
Epoch 264/1000 
	 loss: 16.4934, MinusLogProbMetric: 16.4934, val_loss: 16.6341, val_MinusLogProbMetric: 16.6341

Epoch 264: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4934 - MinusLogProbMetric: 16.4934 - val_loss: 16.6341 - val_MinusLogProbMetric: 16.6341 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 265/1000
2023-09-12 15:23:26.252 
Epoch 265/1000 
	 loss: 16.4903, MinusLogProbMetric: 16.4903, val_loss: 16.6599, val_MinusLogProbMetric: 16.6599

Epoch 265: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4903 - MinusLogProbMetric: 16.4903 - val_loss: 16.6599 - val_MinusLogProbMetric: 16.6599 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 266/1000
2023-09-12 15:23:36.004 
Epoch 266/1000 
	 loss: 16.4950, MinusLogProbMetric: 16.4950, val_loss: 16.6315, val_MinusLogProbMetric: 16.6315

Epoch 266: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4950 - MinusLogProbMetric: 16.4950 - val_loss: 16.6315 - val_MinusLogProbMetric: 16.6315 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 267/1000
2023-09-12 15:23:46.909 
Epoch 267/1000 
	 loss: 16.4902, MinusLogProbMetric: 16.4902, val_loss: 16.6519, val_MinusLogProbMetric: 16.6519

Epoch 267: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4902 - MinusLogProbMetric: 16.4902 - val_loss: 16.6519 - val_MinusLogProbMetric: 16.6519 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 268/1000
2023-09-12 15:23:58.215 
Epoch 268/1000 
	 loss: 16.4962, MinusLogProbMetric: 16.4962, val_loss: 16.6477, val_MinusLogProbMetric: 16.6477

Epoch 268: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4962 - MinusLogProbMetric: 16.4962 - val_loss: 16.6477 - val_MinusLogProbMetric: 16.6477 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 269/1000
2023-09-12 15:24:09.441 
Epoch 269/1000 
	 loss: 16.4924, MinusLogProbMetric: 16.4924, val_loss: 16.6372, val_MinusLogProbMetric: 16.6372

Epoch 269: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4924 - MinusLogProbMetric: 16.4924 - val_loss: 16.6372 - val_MinusLogProbMetric: 16.6372 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 270/1000
2023-09-12 15:24:20.637 
Epoch 270/1000 
	 loss: 16.4845, MinusLogProbMetric: 16.4845, val_loss: 16.6509, val_MinusLogProbMetric: 16.6509

Epoch 270: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4845 - MinusLogProbMetric: 16.4845 - val_loss: 16.6509 - val_MinusLogProbMetric: 16.6509 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 271/1000
2023-09-12 15:24:31.856 
Epoch 271/1000 
	 loss: 16.4936, MinusLogProbMetric: 16.4936, val_loss: 16.6435, val_MinusLogProbMetric: 16.6435

Epoch 271: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4936 - MinusLogProbMetric: 16.4936 - val_loss: 16.6435 - val_MinusLogProbMetric: 16.6435 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 272/1000
2023-09-12 15:24:42.897 
Epoch 272/1000 
	 loss: 16.4929, MinusLogProbMetric: 16.4929, val_loss: 16.6465, val_MinusLogProbMetric: 16.6465

Epoch 272: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4929 - MinusLogProbMetric: 16.4929 - val_loss: 16.6465 - val_MinusLogProbMetric: 16.6465 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 273/1000
2023-09-12 15:24:53.886 
Epoch 273/1000 
	 loss: 16.4876, MinusLogProbMetric: 16.4876, val_loss: 16.6439, val_MinusLogProbMetric: 16.6439

Epoch 273: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4876 - MinusLogProbMetric: 16.4876 - val_loss: 16.6439 - val_MinusLogProbMetric: 16.6439 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 274/1000
2023-09-12 15:25:05.115 
Epoch 274/1000 
	 loss: 16.4900, MinusLogProbMetric: 16.4900, val_loss: 16.6412, val_MinusLogProbMetric: 16.6412

Epoch 274: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4900 - MinusLogProbMetric: 16.4900 - val_loss: 16.6412 - val_MinusLogProbMetric: 16.6412 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 275/1000
2023-09-12 15:25:16.275 
Epoch 275/1000 
	 loss: 16.4948, MinusLogProbMetric: 16.4948, val_loss: 16.6554, val_MinusLogProbMetric: 16.6554

Epoch 275: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4948 - MinusLogProbMetric: 16.4948 - val_loss: 16.6554 - val_MinusLogProbMetric: 16.6554 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 276/1000
2023-09-12 15:25:27.596 
Epoch 276/1000 
	 loss: 16.4944, MinusLogProbMetric: 16.4944, val_loss: 16.6427, val_MinusLogProbMetric: 16.6427

Epoch 276: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4944 - MinusLogProbMetric: 16.4944 - val_loss: 16.6427 - val_MinusLogProbMetric: 16.6427 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 277/1000
2023-09-12 15:25:38.762 
Epoch 277/1000 
	 loss: 16.4899, MinusLogProbMetric: 16.4899, val_loss: 16.6604, val_MinusLogProbMetric: 16.6604

Epoch 277: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4899 - MinusLogProbMetric: 16.4899 - val_loss: 16.6604 - val_MinusLogProbMetric: 16.6604 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 278/1000
2023-09-12 15:25:50.125 
Epoch 278/1000 
	 loss: 16.4912, MinusLogProbMetric: 16.4912, val_loss: 16.6551, val_MinusLogProbMetric: 16.6551

Epoch 278: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4912 - MinusLogProbMetric: 16.4912 - val_loss: 16.6551 - val_MinusLogProbMetric: 16.6551 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 279/1000
2023-09-12 15:26:01.401 
Epoch 279/1000 
	 loss: 16.4869, MinusLogProbMetric: 16.4869, val_loss: 16.6472, val_MinusLogProbMetric: 16.6472

Epoch 279: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4869 - MinusLogProbMetric: 16.4869 - val_loss: 16.6472 - val_MinusLogProbMetric: 16.6472 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 280/1000
2023-09-12 15:26:12.436 
Epoch 280/1000 
	 loss: 16.4893, MinusLogProbMetric: 16.4893, val_loss: 16.6645, val_MinusLogProbMetric: 16.6645

Epoch 280: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4893 - MinusLogProbMetric: 16.4893 - val_loss: 16.6645 - val_MinusLogProbMetric: 16.6645 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 281/1000
2023-09-12 15:26:23.724 
Epoch 281/1000 
	 loss: 16.4894, MinusLogProbMetric: 16.4894, val_loss: 16.6355, val_MinusLogProbMetric: 16.6355

Epoch 281: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4894 - MinusLogProbMetric: 16.4894 - val_loss: 16.6355 - val_MinusLogProbMetric: 16.6355 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 282/1000
2023-09-12 15:26:34.870 
Epoch 282/1000 
	 loss: 16.4882, MinusLogProbMetric: 16.4882, val_loss: 16.6532, val_MinusLogProbMetric: 16.6532

Epoch 282: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4882 - MinusLogProbMetric: 16.4882 - val_loss: 16.6532 - val_MinusLogProbMetric: 16.6532 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 283/1000
2023-09-12 15:26:46.082 
Epoch 283/1000 
	 loss: 16.4886, MinusLogProbMetric: 16.4886, val_loss: 16.6290, val_MinusLogProbMetric: 16.6290

Epoch 283: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4886 - MinusLogProbMetric: 16.4886 - val_loss: 16.6290 - val_MinusLogProbMetric: 16.6290 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 284/1000
2023-09-12 15:26:57.273 
Epoch 284/1000 
	 loss: 16.4913, MinusLogProbMetric: 16.4913, val_loss: 16.6329, val_MinusLogProbMetric: 16.6329

Epoch 284: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4913 - MinusLogProbMetric: 16.4913 - val_loss: 16.6329 - val_MinusLogProbMetric: 16.6329 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 285/1000
2023-09-12 15:27:08.237 
Epoch 285/1000 
	 loss: 16.4891, MinusLogProbMetric: 16.4891, val_loss: 16.6689, val_MinusLogProbMetric: 16.6689

Epoch 285: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4891 - MinusLogProbMetric: 16.4891 - val_loss: 16.6689 - val_MinusLogProbMetric: 16.6689 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 286/1000
2023-09-12 15:27:19.343 
Epoch 286/1000 
	 loss: 16.4859, MinusLogProbMetric: 16.4859, val_loss: 16.6526, val_MinusLogProbMetric: 16.6526

Epoch 286: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4859 - MinusLogProbMetric: 16.4859 - val_loss: 16.6526 - val_MinusLogProbMetric: 16.6526 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 287/1000
2023-09-12 15:27:29.848 
Epoch 287/1000 
	 loss: 16.4870, MinusLogProbMetric: 16.4870, val_loss: 16.6279, val_MinusLogProbMetric: 16.6279

Epoch 287: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4870 - MinusLogProbMetric: 16.4870 - val_loss: 16.6279 - val_MinusLogProbMetric: 16.6279 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 288/1000
2023-09-12 15:27:40.868 
Epoch 288/1000 
	 loss: 16.4874, MinusLogProbMetric: 16.4874, val_loss: 16.6487, val_MinusLogProbMetric: 16.6487

Epoch 288: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4874 - MinusLogProbMetric: 16.4874 - val_loss: 16.6487 - val_MinusLogProbMetric: 16.6487 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 289/1000
2023-09-12 15:27:52.007 
Epoch 289/1000 
	 loss: 16.4873, MinusLogProbMetric: 16.4873, val_loss: 16.6479, val_MinusLogProbMetric: 16.6479

Epoch 289: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4873 - MinusLogProbMetric: 16.4873 - val_loss: 16.6479 - val_MinusLogProbMetric: 16.6479 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 290/1000
2023-09-12 15:28:01.738 
Epoch 290/1000 
	 loss: 16.4879, MinusLogProbMetric: 16.4879, val_loss: 16.6394, val_MinusLogProbMetric: 16.6394

Epoch 290: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4879 - MinusLogProbMetric: 16.4879 - val_loss: 16.6394 - val_MinusLogProbMetric: 16.6394 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 291/1000
2023-09-12 15:28:11.056 
Epoch 291/1000 
	 loss: 16.4888, MinusLogProbMetric: 16.4888, val_loss: 16.6358, val_MinusLogProbMetric: 16.6358

Epoch 291: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4888 - MinusLogProbMetric: 16.4888 - val_loss: 16.6358 - val_MinusLogProbMetric: 16.6358 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 292/1000
2023-09-12 15:28:21.713 
Epoch 292/1000 
	 loss: 16.4859, MinusLogProbMetric: 16.4859, val_loss: 16.6629, val_MinusLogProbMetric: 16.6629

Epoch 292: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4859 - MinusLogProbMetric: 16.4859 - val_loss: 16.6629 - val_MinusLogProbMetric: 16.6629 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 293/1000
2023-09-12 15:28:32.169 
Epoch 293/1000 
	 loss: 16.4866, MinusLogProbMetric: 16.4866, val_loss: 16.6669, val_MinusLogProbMetric: 16.6669

Epoch 293: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4866 - MinusLogProbMetric: 16.4866 - val_loss: 16.6669 - val_MinusLogProbMetric: 16.6669 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 294/1000
2023-09-12 15:28:41.998 
Epoch 294/1000 
	 loss: 16.4891, MinusLogProbMetric: 16.4891, val_loss: 16.6676, val_MinusLogProbMetric: 16.6676

Epoch 294: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4891 - MinusLogProbMetric: 16.4891 - val_loss: 16.6676 - val_MinusLogProbMetric: 16.6676 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 295/1000
2023-09-12 15:28:53.018 
Epoch 295/1000 
	 loss: 16.4841, MinusLogProbMetric: 16.4841, val_loss: 16.6431, val_MinusLogProbMetric: 16.6431

Epoch 295: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4841 - MinusLogProbMetric: 16.4841 - val_loss: 16.6431 - val_MinusLogProbMetric: 16.6431 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 296/1000
2023-09-12 15:29:04.221 
Epoch 296/1000 
	 loss: 16.4827, MinusLogProbMetric: 16.4827, val_loss: 16.6361, val_MinusLogProbMetric: 16.6361

Epoch 296: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4827 - MinusLogProbMetric: 16.4827 - val_loss: 16.6361 - val_MinusLogProbMetric: 16.6361 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 297/1000
2023-09-12 15:29:14.140 
Epoch 297/1000 
	 loss: 16.4860, MinusLogProbMetric: 16.4860, val_loss: 16.6820, val_MinusLogProbMetric: 16.6820

Epoch 297: val_loss did not improve from 16.62674
196/196 - 10s - loss: 16.4860 - MinusLogProbMetric: 16.4860 - val_loss: 16.6820 - val_MinusLogProbMetric: 16.6820 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 298/1000
2023-09-12 15:29:22.555 
Epoch 298/1000 
	 loss: 16.4850, MinusLogProbMetric: 16.4850, val_loss: 16.6346, val_MinusLogProbMetric: 16.6346

Epoch 298: val_loss did not improve from 16.62674
196/196 - 8s - loss: 16.4850 - MinusLogProbMetric: 16.4850 - val_loss: 16.6346 - val_MinusLogProbMetric: 16.6346 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 299/1000
2023-09-12 15:29:30.454 
Epoch 299/1000 
	 loss: 16.4839, MinusLogProbMetric: 16.4839, val_loss: 16.6508, val_MinusLogProbMetric: 16.6508

Epoch 299: val_loss did not improve from 16.62674
196/196 - 8s - loss: 16.4839 - MinusLogProbMetric: 16.4839 - val_loss: 16.6508 - val_MinusLogProbMetric: 16.6508 - lr: 5.0000e-04 - 8s/epoch - 40ms/step
Epoch 300/1000
2023-09-12 15:29:38.636 
Epoch 300/1000 
	 loss: 16.4849, MinusLogProbMetric: 16.4849, val_loss: 16.6511, val_MinusLogProbMetric: 16.6511

Epoch 300: val_loss did not improve from 16.62674
196/196 - 8s - loss: 16.4849 - MinusLogProbMetric: 16.4849 - val_loss: 16.6511 - val_MinusLogProbMetric: 16.6511 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 301/1000
2023-09-12 15:29:47.233 
Epoch 301/1000 
	 loss: 16.4850, MinusLogProbMetric: 16.4850, val_loss: 16.6575, val_MinusLogProbMetric: 16.6575

Epoch 301: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4850 - MinusLogProbMetric: 16.4850 - val_loss: 16.6575 - val_MinusLogProbMetric: 16.6575 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 302/1000
2023-09-12 15:29:58.017 
Epoch 302/1000 
	 loss: 16.4844, MinusLogProbMetric: 16.4844, val_loss: 16.6443, val_MinusLogProbMetric: 16.6443

Epoch 302: val_loss did not improve from 16.62674
196/196 - 11s - loss: 16.4844 - MinusLogProbMetric: 16.4844 - val_loss: 16.6443 - val_MinusLogProbMetric: 16.6443 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 303/1000
2023-09-12 15:30:07.152 
Epoch 303/1000 
	 loss: 16.4828, MinusLogProbMetric: 16.4828, val_loss: 16.6692, val_MinusLogProbMetric: 16.6692

Epoch 303: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4828 - MinusLogProbMetric: 16.4828 - val_loss: 16.6692 - val_MinusLogProbMetric: 16.6692 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 304/1000
2023-09-12 15:30:16.176 
Epoch 304/1000 
	 loss: 16.4847, MinusLogProbMetric: 16.4847, val_loss: 16.6507, val_MinusLogProbMetric: 16.6507

Epoch 304: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4847 - MinusLogProbMetric: 16.4847 - val_loss: 16.6507 - val_MinusLogProbMetric: 16.6507 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 305/1000
2023-09-12 15:30:24.309 
Epoch 305/1000 
	 loss: 16.4826, MinusLogProbMetric: 16.4826, val_loss: 16.6641, val_MinusLogProbMetric: 16.6641

Epoch 305: val_loss did not improve from 16.62674
196/196 - 8s - loss: 16.4826 - MinusLogProbMetric: 16.4826 - val_loss: 16.6641 - val_MinusLogProbMetric: 16.6641 - lr: 5.0000e-04 - 8s/epoch - 41ms/step
Epoch 306/1000
2023-09-12 15:30:32.550 
Epoch 306/1000 
	 loss: 16.4864, MinusLogProbMetric: 16.4864, val_loss: 16.6410, val_MinusLogProbMetric: 16.6410

Epoch 306: val_loss did not improve from 16.62674
196/196 - 8s - loss: 16.4864 - MinusLogProbMetric: 16.4864 - val_loss: 16.6410 - val_MinusLogProbMetric: 16.6410 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 307/1000
2023-09-12 15:30:40.646 
Epoch 307/1000 
	 loss: 16.4836, MinusLogProbMetric: 16.4836, val_loss: 16.6409, val_MinusLogProbMetric: 16.6409

Epoch 307: val_loss did not improve from 16.62674
196/196 - 8s - loss: 16.4836 - MinusLogProbMetric: 16.4836 - val_loss: 16.6409 - val_MinusLogProbMetric: 16.6409 - lr: 5.0000e-04 - 8s/epoch - 41ms/step
Epoch 308/1000
2023-09-12 15:30:48.577 
Epoch 308/1000 
	 loss: 16.4617, MinusLogProbMetric: 16.4617, val_loss: 16.6281, val_MinusLogProbMetric: 16.6281

Epoch 308: val_loss did not improve from 16.62674
196/196 - 8s - loss: 16.4617 - MinusLogProbMetric: 16.4617 - val_loss: 16.6281 - val_MinusLogProbMetric: 16.6281 - lr: 2.5000e-04 - 8s/epoch - 40ms/step
Epoch 309/1000
2023-09-12 15:30:57.336 
Epoch 309/1000 
	 loss: 16.4594, MinusLogProbMetric: 16.4594, val_loss: 16.6275, val_MinusLogProbMetric: 16.6275

Epoch 309: val_loss did not improve from 16.62674
196/196 - 9s - loss: 16.4594 - MinusLogProbMetric: 16.4594 - val_loss: 16.6275 - val_MinusLogProbMetric: 16.6275 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 310/1000
2023-09-12 15:31:05.463 
Epoch 310/1000 
	 loss: 16.4581, MinusLogProbMetric: 16.4581, val_loss: 16.6263, val_MinusLogProbMetric: 16.6263

Epoch 310: val_loss improved from 16.62674 to 16.62631, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 8s - loss: 16.4581 - MinusLogProbMetric: 16.4581 - val_loss: 16.6263 - val_MinusLogProbMetric: 16.6263 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 311/1000
2023-09-12 15:31:13.402 
Epoch 311/1000 
	 loss: 16.4596, MinusLogProbMetric: 16.4596, val_loss: 16.6273, val_MinusLogProbMetric: 16.6273

Epoch 311: val_loss did not improve from 16.62631
196/196 - 8s - loss: 16.4596 - MinusLogProbMetric: 16.4596 - val_loss: 16.6273 - val_MinusLogProbMetric: 16.6273 - lr: 2.5000e-04 - 8s/epoch - 40ms/step
Epoch 312/1000
2023-09-12 15:31:22.066 
Epoch 312/1000 
	 loss: 16.4621, MinusLogProbMetric: 16.4621, val_loss: 16.6451, val_MinusLogProbMetric: 16.6451

Epoch 312: val_loss did not improve from 16.62631
196/196 - 9s - loss: 16.4621 - MinusLogProbMetric: 16.4621 - val_loss: 16.6451 - val_MinusLogProbMetric: 16.6451 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 313/1000
2023-09-12 15:31:29.964 
Epoch 313/1000 
	 loss: 16.4611, MinusLogProbMetric: 16.4611, val_loss: 16.6254, val_MinusLogProbMetric: 16.6254

Epoch 313: val_loss improved from 16.62631 to 16.62541, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 8s - loss: 16.4611 - MinusLogProbMetric: 16.4611 - val_loss: 16.6254 - val_MinusLogProbMetric: 16.6254 - lr: 2.5000e-04 - 8s/epoch - 41ms/step
Epoch 314/1000
2023-09-12 15:31:37.931 
Epoch 314/1000 
	 loss: 16.4587, MinusLogProbMetric: 16.4587, val_loss: 16.6289, val_MinusLogProbMetric: 16.6289

Epoch 314: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4587 - MinusLogProbMetric: 16.4587 - val_loss: 16.6289 - val_MinusLogProbMetric: 16.6289 - lr: 2.5000e-04 - 8s/epoch - 40ms/step
Epoch 315/1000
2023-09-12 15:31:45.631 
Epoch 315/1000 
	 loss: 16.4599, MinusLogProbMetric: 16.4599, val_loss: 16.6356, val_MinusLogProbMetric: 16.6356

Epoch 315: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4599 - MinusLogProbMetric: 16.4599 - val_loss: 16.6356 - val_MinusLogProbMetric: 16.6356 - lr: 2.5000e-04 - 8s/epoch - 39ms/step
Epoch 316/1000
2023-09-12 15:31:54.203 
Epoch 316/1000 
	 loss: 16.4599, MinusLogProbMetric: 16.4599, val_loss: 16.6324, val_MinusLogProbMetric: 16.6324

Epoch 316: val_loss did not improve from 16.62541
196/196 - 9s - loss: 16.4599 - MinusLogProbMetric: 16.4599 - val_loss: 16.6324 - val_MinusLogProbMetric: 16.6324 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 317/1000
2023-09-12 15:32:02.214 
Epoch 317/1000 
	 loss: 16.4579, MinusLogProbMetric: 16.4579, val_loss: 16.6459, val_MinusLogProbMetric: 16.6459

Epoch 317: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4579 - MinusLogProbMetric: 16.4579 - val_loss: 16.6459 - val_MinusLogProbMetric: 16.6459 - lr: 2.5000e-04 - 8s/epoch - 41ms/step
Epoch 318/1000
2023-09-12 15:32:09.954 
Epoch 318/1000 
	 loss: 16.4598, MinusLogProbMetric: 16.4598, val_loss: 16.6352, val_MinusLogProbMetric: 16.6352

Epoch 318: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4598 - MinusLogProbMetric: 16.4598 - val_loss: 16.6352 - val_MinusLogProbMetric: 16.6352 - lr: 2.5000e-04 - 8s/epoch - 39ms/step
Epoch 319/1000
2023-09-12 15:32:17.637 
Epoch 319/1000 
	 loss: 16.4568, MinusLogProbMetric: 16.4568, val_loss: 16.6285, val_MinusLogProbMetric: 16.6285

Epoch 319: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4568 - MinusLogProbMetric: 16.4568 - val_loss: 16.6285 - val_MinusLogProbMetric: 16.6285 - lr: 2.5000e-04 - 8s/epoch - 39ms/step
Epoch 320/1000
2023-09-12 15:32:25.439 
Epoch 320/1000 
	 loss: 16.4586, MinusLogProbMetric: 16.4586, val_loss: 16.6342, val_MinusLogProbMetric: 16.6342

Epoch 320: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4586 - MinusLogProbMetric: 16.4586 - val_loss: 16.6342 - val_MinusLogProbMetric: 16.6342 - lr: 2.5000e-04 - 8s/epoch - 40ms/step
Epoch 321/1000
2023-09-12 15:32:33.286 
Epoch 321/1000 
	 loss: 16.4594, MinusLogProbMetric: 16.4594, val_loss: 16.6331, val_MinusLogProbMetric: 16.6331

Epoch 321: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4594 - MinusLogProbMetric: 16.4594 - val_loss: 16.6331 - val_MinusLogProbMetric: 16.6331 - lr: 2.5000e-04 - 8s/epoch - 40ms/step
Epoch 322/1000
2023-09-12 15:32:41.000 
Epoch 322/1000 
	 loss: 16.4615, MinusLogProbMetric: 16.4615, val_loss: 16.6471, val_MinusLogProbMetric: 16.6471

Epoch 322: val_loss did not improve from 16.62541
196/196 - 8s - loss: 16.4615 - MinusLogProbMetric: 16.4615 - val_loss: 16.6471 - val_MinusLogProbMetric: 16.6471 - lr: 2.5000e-04 - 8s/epoch - 39ms/step
Epoch 323/1000
2023-09-12 15:32:48.993 
Epoch 323/1000 
	 loss: 16.4584, MinusLogProbMetric: 16.4584, val_loss: 16.6251, val_MinusLogProbMetric: 16.6251

Epoch 323: val_loss improved from 16.62541 to 16.62506, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_145/weights/best_weights.h5
196/196 - 8s - loss: 16.4584 - MinusLogProbMetric: 16.4584 - val_loss: 16.6251 - val_MinusLogProbMetric: 16.6251 - lr: 2.5000e-04 - 8s/epoch - 41ms/step
Epoch 324/1000
2023-09-12 15:32:56.925 
Epoch 324/1000 
	 loss: 16.4580, MinusLogProbMetric: 16.4580, val_loss: 16.6359, val_MinusLogProbMetric: 16.6359

Epoch 324: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4580 - MinusLogProbMetric: 16.4580 - val_loss: 16.6359 - val_MinusLogProbMetric: 16.6359 - lr: 2.5000e-04 - 8s/epoch - 40ms/step
Epoch 325/1000
2023-09-12 15:33:05.087 
Epoch 325/1000 
	 loss: 16.4568, MinusLogProbMetric: 16.4568, val_loss: 16.6287, val_MinusLogProbMetric: 16.6287

Epoch 325: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4568 - MinusLogProbMetric: 16.4568 - val_loss: 16.6287 - val_MinusLogProbMetric: 16.6287 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 326/1000
2023-09-12 15:33:13.088 
Epoch 326/1000 
	 loss: 16.4578, MinusLogProbMetric: 16.4578, val_loss: 16.6362, val_MinusLogProbMetric: 16.6362

Epoch 326: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4578 - MinusLogProbMetric: 16.4578 - val_loss: 16.6362 - val_MinusLogProbMetric: 16.6362 - lr: 2.5000e-04 - 8s/epoch - 41ms/step
Epoch 327/1000
2023-09-12 15:33:21.114 
Epoch 327/1000 
	 loss: 16.4577, MinusLogProbMetric: 16.4577, val_loss: 16.6272, val_MinusLogProbMetric: 16.6272

Epoch 327: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4577 - MinusLogProbMetric: 16.4577 - val_loss: 16.6272 - val_MinusLogProbMetric: 16.6272 - lr: 2.5000e-04 - 8s/epoch - 41ms/step
Epoch 328/1000
2023-09-12 15:33:29.039 
Epoch 328/1000 
	 loss: 16.4585, MinusLogProbMetric: 16.4585, val_loss: 16.6306, val_MinusLogProbMetric: 16.6306

Epoch 328: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4585 - MinusLogProbMetric: 16.4585 - val_loss: 16.6306 - val_MinusLogProbMetric: 16.6306 - lr: 2.5000e-04 - 8s/epoch - 40ms/step
Epoch 329/1000
2023-09-12 15:33:37.841 
Epoch 329/1000 
	 loss: 16.4598, MinusLogProbMetric: 16.4598, val_loss: 16.6597, val_MinusLogProbMetric: 16.6597

Epoch 329: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4598 - MinusLogProbMetric: 16.4598 - val_loss: 16.6597 - val_MinusLogProbMetric: 16.6597 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 330/1000
2023-09-12 15:33:46.199 
Epoch 330/1000 
	 loss: 16.4576, MinusLogProbMetric: 16.4576, val_loss: 16.6300, val_MinusLogProbMetric: 16.6300

Epoch 330: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4576 - MinusLogProbMetric: 16.4576 - val_loss: 16.6300 - val_MinusLogProbMetric: 16.6300 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 331/1000
2023-09-12 15:33:54.526 
Epoch 331/1000 
	 loss: 16.4568, MinusLogProbMetric: 16.4568, val_loss: 16.6324, val_MinusLogProbMetric: 16.6324

Epoch 331: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4568 - MinusLogProbMetric: 16.4568 - val_loss: 16.6324 - val_MinusLogProbMetric: 16.6324 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 332/1000
2023-09-12 15:34:02.898 
Epoch 332/1000 
	 loss: 16.4589, MinusLogProbMetric: 16.4589, val_loss: 16.6338, val_MinusLogProbMetric: 16.6338

Epoch 332: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4589 - MinusLogProbMetric: 16.4589 - val_loss: 16.6338 - val_MinusLogProbMetric: 16.6338 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 333/1000
2023-09-12 15:34:11.111 
Epoch 333/1000 
	 loss: 16.4553, MinusLogProbMetric: 16.4553, val_loss: 16.6318, val_MinusLogProbMetric: 16.6318

Epoch 333: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4553 - MinusLogProbMetric: 16.4553 - val_loss: 16.6318 - val_MinusLogProbMetric: 16.6318 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 334/1000
2023-09-12 15:34:19.123 
Epoch 334/1000 
	 loss: 16.4572, MinusLogProbMetric: 16.4572, val_loss: 16.6341, val_MinusLogProbMetric: 16.6341

Epoch 334: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4572 - MinusLogProbMetric: 16.4572 - val_loss: 16.6341 - val_MinusLogProbMetric: 16.6341 - lr: 2.5000e-04 - 8s/epoch - 41ms/step
Epoch 335/1000
2023-09-12 15:34:27.741 
Epoch 335/1000 
	 loss: 16.4583, MinusLogProbMetric: 16.4583, val_loss: 16.6346, val_MinusLogProbMetric: 16.6346

Epoch 335: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4583 - MinusLogProbMetric: 16.4583 - val_loss: 16.6346 - val_MinusLogProbMetric: 16.6346 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 336/1000
2023-09-12 15:34:36.261 
Epoch 336/1000 
	 loss: 16.4575, MinusLogProbMetric: 16.4575, val_loss: 16.6306, val_MinusLogProbMetric: 16.6306

Epoch 336: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4575 - MinusLogProbMetric: 16.4575 - val_loss: 16.6306 - val_MinusLogProbMetric: 16.6306 - lr: 2.5000e-04 - 9s/epoch - 43ms/step
Epoch 337/1000
2023-09-12 15:34:44.717 
Epoch 337/1000 
	 loss: 16.4564, MinusLogProbMetric: 16.4564, val_loss: 16.6529, val_MinusLogProbMetric: 16.6529

Epoch 337: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4564 - MinusLogProbMetric: 16.4564 - val_loss: 16.6529 - val_MinusLogProbMetric: 16.6529 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 338/1000
2023-09-12 15:34:53.039 
Epoch 338/1000 
	 loss: 16.4600, MinusLogProbMetric: 16.4600, val_loss: 16.6333, val_MinusLogProbMetric: 16.6333

Epoch 338: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4600 - MinusLogProbMetric: 16.4600 - val_loss: 16.6333 - val_MinusLogProbMetric: 16.6333 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 339/1000
2023-09-12 15:35:01.461 
Epoch 339/1000 
	 loss: 16.4574, MinusLogProbMetric: 16.4574, val_loss: 16.6319, val_MinusLogProbMetric: 16.6319

Epoch 339: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4574 - MinusLogProbMetric: 16.4574 - val_loss: 16.6319 - val_MinusLogProbMetric: 16.6319 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 340/1000
2023-09-12 15:35:09.705 
Epoch 340/1000 
	 loss: 16.4585, MinusLogProbMetric: 16.4585, val_loss: 16.6424, val_MinusLogProbMetric: 16.6424

Epoch 340: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4585 - MinusLogProbMetric: 16.4585 - val_loss: 16.6424 - val_MinusLogProbMetric: 16.6424 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 341/1000
2023-09-12 15:35:17.990 
Epoch 341/1000 
	 loss: 16.4575, MinusLogProbMetric: 16.4575, val_loss: 16.6362, val_MinusLogProbMetric: 16.6362

Epoch 341: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4575 - MinusLogProbMetric: 16.4575 - val_loss: 16.6362 - val_MinusLogProbMetric: 16.6362 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 342/1000
2023-09-12 15:35:26.289 
Epoch 342/1000 
	 loss: 16.4544, MinusLogProbMetric: 16.4544, val_loss: 16.6317, val_MinusLogProbMetric: 16.6317

Epoch 342: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4544 - MinusLogProbMetric: 16.4544 - val_loss: 16.6317 - val_MinusLogProbMetric: 16.6317 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 343/1000
2023-09-12 15:35:35.080 
Epoch 343/1000 
	 loss: 16.4571, MinusLogProbMetric: 16.4571, val_loss: 16.6478, val_MinusLogProbMetric: 16.6478

Epoch 343: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4571 - MinusLogProbMetric: 16.4571 - val_loss: 16.6478 - val_MinusLogProbMetric: 16.6478 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 344/1000
2023-09-12 15:35:43.776 
Epoch 344/1000 
	 loss: 16.4556, MinusLogProbMetric: 16.4556, val_loss: 16.6300, val_MinusLogProbMetric: 16.6300

Epoch 344: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4556 - MinusLogProbMetric: 16.4556 - val_loss: 16.6300 - val_MinusLogProbMetric: 16.6300 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 345/1000
2023-09-12 15:35:52.434 
Epoch 345/1000 
	 loss: 16.4540, MinusLogProbMetric: 16.4540, val_loss: 16.6375, val_MinusLogProbMetric: 16.6375

Epoch 345: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4540 - MinusLogProbMetric: 16.4540 - val_loss: 16.6375 - val_MinusLogProbMetric: 16.6375 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 346/1000
2023-09-12 15:36:01.204 
Epoch 346/1000 
	 loss: 16.4569, MinusLogProbMetric: 16.4569, val_loss: 16.6385, val_MinusLogProbMetric: 16.6385

Epoch 346: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4569 - MinusLogProbMetric: 16.4569 - val_loss: 16.6385 - val_MinusLogProbMetric: 16.6385 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 347/1000
2023-09-12 15:36:10.527 
Epoch 347/1000 
	 loss: 16.4571, MinusLogProbMetric: 16.4571, val_loss: 16.6444, val_MinusLogProbMetric: 16.6444

Epoch 347: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4571 - MinusLogProbMetric: 16.4571 - val_loss: 16.6444 - val_MinusLogProbMetric: 16.6444 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 348/1000
2023-09-12 15:36:19.588 
Epoch 348/1000 
	 loss: 16.4569, MinusLogProbMetric: 16.4569, val_loss: 16.6386, val_MinusLogProbMetric: 16.6386

Epoch 348: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4569 - MinusLogProbMetric: 16.4569 - val_loss: 16.6386 - val_MinusLogProbMetric: 16.6386 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 349/1000
2023-09-12 15:36:29.398 
Epoch 349/1000 
	 loss: 16.4567, MinusLogProbMetric: 16.4567, val_loss: 16.6322, val_MinusLogProbMetric: 16.6322

Epoch 349: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4567 - MinusLogProbMetric: 16.4567 - val_loss: 16.6322 - val_MinusLogProbMetric: 16.6322 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 350/1000
2023-09-12 15:36:40.438 
Epoch 350/1000 
	 loss: 16.4584, MinusLogProbMetric: 16.4584, val_loss: 16.6433, val_MinusLogProbMetric: 16.6433

Epoch 350: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4584 - MinusLogProbMetric: 16.4584 - val_loss: 16.6433 - val_MinusLogProbMetric: 16.6433 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 351/1000
2023-09-12 15:36:51.570 
Epoch 351/1000 
	 loss: 16.4570, MinusLogProbMetric: 16.4570, val_loss: 16.6416, val_MinusLogProbMetric: 16.6416

Epoch 351: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4570 - MinusLogProbMetric: 16.4570 - val_loss: 16.6416 - val_MinusLogProbMetric: 16.6416 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 352/1000
2023-09-12 15:37:02.667 
Epoch 352/1000 
	 loss: 16.4571, MinusLogProbMetric: 16.4571, val_loss: 16.6438, val_MinusLogProbMetric: 16.6438

Epoch 352: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4571 - MinusLogProbMetric: 16.4571 - val_loss: 16.6438 - val_MinusLogProbMetric: 16.6438 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 353/1000
2023-09-12 15:37:13.836 
Epoch 353/1000 
	 loss: 16.4547, MinusLogProbMetric: 16.4547, val_loss: 16.6337, val_MinusLogProbMetric: 16.6337

Epoch 353: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4547 - MinusLogProbMetric: 16.4547 - val_loss: 16.6337 - val_MinusLogProbMetric: 16.6337 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 354/1000
2023-09-12 15:37:24.221 
Epoch 354/1000 
	 loss: 16.4560, MinusLogProbMetric: 16.4560, val_loss: 16.6312, val_MinusLogProbMetric: 16.6312

Epoch 354: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4560 - MinusLogProbMetric: 16.4560 - val_loss: 16.6312 - val_MinusLogProbMetric: 16.6312 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 355/1000
2023-09-12 15:37:32.721 
Epoch 355/1000 
	 loss: 16.4571, MinusLogProbMetric: 16.4571, val_loss: 16.6327, val_MinusLogProbMetric: 16.6327

Epoch 355: val_loss did not improve from 16.62506
196/196 - 8s - loss: 16.4571 - MinusLogProbMetric: 16.4571 - val_loss: 16.6327 - val_MinusLogProbMetric: 16.6327 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 356/1000
2023-09-12 15:37:42.103 
Epoch 356/1000 
	 loss: 16.4545, MinusLogProbMetric: 16.4545, val_loss: 16.6400, val_MinusLogProbMetric: 16.6400

Epoch 356: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4545 - MinusLogProbMetric: 16.4545 - val_loss: 16.6400 - val_MinusLogProbMetric: 16.6400 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 357/1000
2023-09-12 15:37:53.046 
Epoch 357/1000 
	 loss: 16.4573, MinusLogProbMetric: 16.4573, val_loss: 16.6373, val_MinusLogProbMetric: 16.6373

Epoch 357: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4573 - MinusLogProbMetric: 16.4573 - val_loss: 16.6373 - val_MinusLogProbMetric: 16.6373 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 358/1000
2023-09-12 15:38:04.042 
Epoch 358/1000 
	 loss: 16.4570, MinusLogProbMetric: 16.4570, val_loss: 16.6499, val_MinusLogProbMetric: 16.6499

Epoch 358: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4570 - MinusLogProbMetric: 16.4570 - val_loss: 16.6499 - val_MinusLogProbMetric: 16.6499 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 359/1000
2023-09-12 15:38:15.202 
Epoch 359/1000 
	 loss: 16.4558, MinusLogProbMetric: 16.4558, val_loss: 16.6407, val_MinusLogProbMetric: 16.6407

Epoch 359: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4558 - MinusLogProbMetric: 16.4558 - val_loss: 16.6407 - val_MinusLogProbMetric: 16.6407 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 360/1000
2023-09-12 15:38:26.208 
Epoch 360/1000 
	 loss: 16.4548, MinusLogProbMetric: 16.4548, val_loss: 16.6391, val_MinusLogProbMetric: 16.6391

Epoch 360: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4548 - MinusLogProbMetric: 16.4548 - val_loss: 16.6391 - val_MinusLogProbMetric: 16.6391 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 361/1000
2023-09-12 15:38:35.543 
Epoch 361/1000 
	 loss: 16.4553, MinusLogProbMetric: 16.4553, val_loss: 16.6410, val_MinusLogProbMetric: 16.6410

Epoch 361: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4553 - MinusLogProbMetric: 16.4553 - val_loss: 16.6410 - val_MinusLogProbMetric: 16.6410 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 362/1000
2023-09-12 15:38:44.107 
Epoch 362/1000 
	 loss: 16.4557, MinusLogProbMetric: 16.4557, val_loss: 16.6296, val_MinusLogProbMetric: 16.6296

Epoch 362: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4557 - MinusLogProbMetric: 16.4557 - val_loss: 16.6296 - val_MinusLogProbMetric: 16.6296 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 363/1000
2023-09-12 15:38:53.803 
Epoch 363/1000 
	 loss: 16.4541, MinusLogProbMetric: 16.4541, val_loss: 16.6417, val_MinusLogProbMetric: 16.6417

Epoch 363: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4541 - MinusLogProbMetric: 16.4541 - val_loss: 16.6417 - val_MinusLogProbMetric: 16.6417 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 364/1000
2023-09-12 15:39:04.782 
Epoch 364/1000 
	 loss: 16.4537, MinusLogProbMetric: 16.4537, val_loss: 16.6339, val_MinusLogProbMetric: 16.6339

Epoch 364: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4537 - MinusLogProbMetric: 16.4537 - val_loss: 16.6339 - val_MinusLogProbMetric: 16.6339 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 365/1000
2023-09-12 15:39:13.743 
Epoch 365/1000 
	 loss: 16.4545, MinusLogProbMetric: 16.4545, val_loss: 16.6299, val_MinusLogProbMetric: 16.6299

Epoch 365: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4545 - MinusLogProbMetric: 16.4545 - val_loss: 16.6299 - val_MinusLogProbMetric: 16.6299 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 366/1000
2023-09-12 15:39:22.880 
Epoch 366/1000 
	 loss: 16.4535, MinusLogProbMetric: 16.4535, val_loss: 16.6444, val_MinusLogProbMetric: 16.6444

Epoch 366: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4535 - MinusLogProbMetric: 16.4535 - val_loss: 16.6444 - val_MinusLogProbMetric: 16.6444 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 367/1000
2023-09-12 15:39:33.675 
Epoch 367/1000 
	 loss: 16.4547, MinusLogProbMetric: 16.4547, val_loss: 16.6336, val_MinusLogProbMetric: 16.6336

Epoch 367: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4547 - MinusLogProbMetric: 16.4547 - val_loss: 16.6336 - val_MinusLogProbMetric: 16.6336 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 368/1000
2023-09-12 15:39:43.361 
Epoch 368/1000 
	 loss: 16.4551, MinusLogProbMetric: 16.4551, val_loss: 16.6390, val_MinusLogProbMetric: 16.6390

Epoch 368: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4551 - MinusLogProbMetric: 16.4551 - val_loss: 16.6390 - val_MinusLogProbMetric: 16.6390 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 369/1000
2023-09-12 15:39:54.437 
Epoch 369/1000 
	 loss: 16.4526, MinusLogProbMetric: 16.4526, val_loss: 16.6429, val_MinusLogProbMetric: 16.6429

Epoch 369: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4526 - MinusLogProbMetric: 16.4526 - val_loss: 16.6429 - val_MinusLogProbMetric: 16.6429 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 370/1000
2023-09-12 15:40:05.343 
Epoch 370/1000 
	 loss: 16.4555, MinusLogProbMetric: 16.4555, val_loss: 16.6400, val_MinusLogProbMetric: 16.6400

Epoch 370: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4555 - MinusLogProbMetric: 16.4555 - val_loss: 16.6400 - val_MinusLogProbMetric: 16.6400 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 371/1000
2023-09-12 15:40:16.247 
Epoch 371/1000 
	 loss: 16.4551, MinusLogProbMetric: 16.4551, val_loss: 16.6288, val_MinusLogProbMetric: 16.6288

Epoch 371: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4551 - MinusLogProbMetric: 16.4551 - val_loss: 16.6288 - val_MinusLogProbMetric: 16.6288 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 372/1000
2023-09-12 15:40:27.335 
Epoch 372/1000 
	 loss: 16.4560, MinusLogProbMetric: 16.4560, val_loss: 16.6442, val_MinusLogProbMetric: 16.6442

Epoch 372: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4560 - MinusLogProbMetric: 16.4560 - val_loss: 16.6442 - val_MinusLogProbMetric: 16.6442 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 373/1000
2023-09-12 15:40:38.202 
Epoch 373/1000 
	 loss: 16.4562, MinusLogProbMetric: 16.4562, val_loss: 16.6305, val_MinusLogProbMetric: 16.6305

Epoch 373: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4562 - MinusLogProbMetric: 16.4562 - val_loss: 16.6305 - val_MinusLogProbMetric: 16.6305 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 374/1000
2023-09-12 15:40:49.156 
Epoch 374/1000 
	 loss: 16.4419, MinusLogProbMetric: 16.4419, val_loss: 16.6289, val_MinusLogProbMetric: 16.6289

Epoch 374: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4419 - MinusLogProbMetric: 16.4419 - val_loss: 16.6289 - val_MinusLogProbMetric: 16.6289 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 375/1000
2023-09-12 15:41:00.073 
Epoch 375/1000 
	 loss: 16.4411, MinusLogProbMetric: 16.4411, val_loss: 16.6263, val_MinusLogProbMetric: 16.6263

Epoch 375: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4411 - MinusLogProbMetric: 16.4411 - val_loss: 16.6263 - val_MinusLogProbMetric: 16.6263 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 376/1000
2023-09-12 15:41:11.071 
Epoch 376/1000 
	 loss: 16.4414, MinusLogProbMetric: 16.4414, val_loss: 16.6300, val_MinusLogProbMetric: 16.6300

Epoch 376: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4414 - MinusLogProbMetric: 16.4414 - val_loss: 16.6300 - val_MinusLogProbMetric: 16.6300 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 377/1000
2023-09-12 15:41:21.835 
Epoch 377/1000 
	 loss: 16.4420, MinusLogProbMetric: 16.4420, val_loss: 16.6285, val_MinusLogProbMetric: 16.6285

Epoch 377: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4420 - MinusLogProbMetric: 16.4420 - val_loss: 16.6285 - val_MinusLogProbMetric: 16.6285 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 378/1000
2023-09-12 15:41:32.678 
Epoch 378/1000 
	 loss: 16.4429, MinusLogProbMetric: 16.4429, val_loss: 16.6288, val_MinusLogProbMetric: 16.6288

Epoch 378: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4429 - MinusLogProbMetric: 16.4429 - val_loss: 16.6288 - val_MinusLogProbMetric: 16.6288 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 379/1000
2023-09-12 15:41:43.628 
Epoch 379/1000 
	 loss: 16.4417, MinusLogProbMetric: 16.4417, val_loss: 16.6281, val_MinusLogProbMetric: 16.6281

Epoch 379: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4417 - MinusLogProbMetric: 16.4417 - val_loss: 16.6281 - val_MinusLogProbMetric: 16.6281 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 380/1000
2023-09-12 15:41:54.502 
Epoch 380/1000 
	 loss: 16.4418, MinusLogProbMetric: 16.4418, val_loss: 16.6293, val_MinusLogProbMetric: 16.6293

Epoch 380: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4418 - MinusLogProbMetric: 16.4418 - val_loss: 16.6293 - val_MinusLogProbMetric: 16.6293 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 381/1000
2023-09-12 15:42:05.499 
Epoch 381/1000 
	 loss: 16.4417, MinusLogProbMetric: 16.4417, val_loss: 16.6351, val_MinusLogProbMetric: 16.6351

Epoch 381: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4417 - MinusLogProbMetric: 16.4417 - val_loss: 16.6351 - val_MinusLogProbMetric: 16.6351 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 382/1000
2023-09-12 15:42:16.243 
Epoch 382/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.6398, val_MinusLogProbMetric: 16.6398

Epoch 382: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.6398 - val_MinusLogProbMetric: 16.6398 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 383/1000
2023-09-12 15:42:27.028 
Epoch 383/1000 
	 loss: 16.4417, MinusLogProbMetric: 16.4417, val_loss: 16.6270, val_MinusLogProbMetric: 16.6270

Epoch 383: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4417 - MinusLogProbMetric: 16.4417 - val_loss: 16.6270 - val_MinusLogProbMetric: 16.6270 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 384/1000
2023-09-12 15:42:37.164 
Epoch 384/1000 
	 loss: 16.4412, MinusLogProbMetric: 16.4412, val_loss: 16.6283, val_MinusLogProbMetric: 16.6283

Epoch 384: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4412 - MinusLogProbMetric: 16.4412 - val_loss: 16.6283 - val_MinusLogProbMetric: 16.6283 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 385/1000
2023-09-12 15:42:46.861 
Epoch 385/1000 
	 loss: 16.4418, MinusLogProbMetric: 16.4418, val_loss: 16.6286, val_MinusLogProbMetric: 16.6286

Epoch 385: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4418 - MinusLogProbMetric: 16.4418 - val_loss: 16.6286 - val_MinusLogProbMetric: 16.6286 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 386/1000
2023-09-12 15:42:55.473 
Epoch 386/1000 
	 loss: 16.4409, MinusLogProbMetric: 16.4409, val_loss: 16.6387, val_MinusLogProbMetric: 16.6387

Epoch 386: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4409 - MinusLogProbMetric: 16.4409 - val_loss: 16.6387 - val_MinusLogProbMetric: 16.6387 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 387/1000
2023-09-12 15:43:06.215 
Epoch 387/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.6265, val_MinusLogProbMetric: 16.6265

Epoch 387: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.6265 - val_MinusLogProbMetric: 16.6265 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 388/1000
2023-09-12 15:43:17.050 
Epoch 388/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.6293, val_MinusLogProbMetric: 16.6293

Epoch 388: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.6293 - val_MinusLogProbMetric: 16.6293 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 389/1000
2023-09-12 15:43:26.159 
Epoch 389/1000 
	 loss: 16.4410, MinusLogProbMetric: 16.4410, val_loss: 16.6304, val_MinusLogProbMetric: 16.6304

Epoch 389: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4410 - MinusLogProbMetric: 16.4410 - val_loss: 16.6304 - val_MinusLogProbMetric: 16.6304 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 390/1000
2023-09-12 15:43:36.338 
Epoch 390/1000 
	 loss: 16.4412, MinusLogProbMetric: 16.4412, val_loss: 16.6296, val_MinusLogProbMetric: 16.6296

Epoch 390: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4412 - MinusLogProbMetric: 16.4412 - val_loss: 16.6296 - val_MinusLogProbMetric: 16.6296 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 391/1000
2023-09-12 15:43:47.231 
Epoch 391/1000 
	 loss: 16.4424, MinusLogProbMetric: 16.4424, val_loss: 16.6370, val_MinusLogProbMetric: 16.6370

Epoch 391: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4424 - MinusLogProbMetric: 16.4424 - val_loss: 16.6370 - val_MinusLogProbMetric: 16.6370 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 392/1000
2023-09-12 15:43:55.847 
Epoch 392/1000 
	 loss: 16.4411, MinusLogProbMetric: 16.4411, val_loss: 16.6335, val_MinusLogProbMetric: 16.6335

Epoch 392: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4411 - MinusLogProbMetric: 16.4411 - val_loss: 16.6335 - val_MinusLogProbMetric: 16.6335 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 393/1000
2023-09-12 15:44:04.450 
Epoch 393/1000 
	 loss: 16.4426, MinusLogProbMetric: 16.4426, val_loss: 16.6291, val_MinusLogProbMetric: 16.6291

Epoch 393: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4426 - MinusLogProbMetric: 16.4426 - val_loss: 16.6291 - val_MinusLogProbMetric: 16.6291 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 394/1000
2023-09-12 15:44:13.151 
Epoch 394/1000 
	 loss: 16.4413, MinusLogProbMetric: 16.4413, val_loss: 16.6336, val_MinusLogProbMetric: 16.6336

Epoch 394: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4413 - MinusLogProbMetric: 16.4413 - val_loss: 16.6336 - val_MinusLogProbMetric: 16.6336 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 395/1000
2023-09-12 15:44:23.648 
Epoch 395/1000 
	 loss: 16.4408, MinusLogProbMetric: 16.4408, val_loss: 16.6330, val_MinusLogProbMetric: 16.6330

Epoch 395: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4408 - MinusLogProbMetric: 16.4408 - val_loss: 16.6330 - val_MinusLogProbMetric: 16.6330 - lr: 1.2500e-04 - 10s/epoch - 54ms/step
Epoch 396/1000
2023-09-12 15:44:34.649 
Epoch 396/1000 
	 loss: 16.4405, MinusLogProbMetric: 16.4405, val_loss: 16.6301, val_MinusLogProbMetric: 16.6301

Epoch 396: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4405 - MinusLogProbMetric: 16.4405 - val_loss: 16.6301 - val_MinusLogProbMetric: 16.6301 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 397/1000
2023-09-12 15:44:43.712 
Epoch 397/1000 
	 loss: 16.4419, MinusLogProbMetric: 16.4419, val_loss: 16.6293, val_MinusLogProbMetric: 16.6293

Epoch 397: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4419 - MinusLogProbMetric: 16.4419 - val_loss: 16.6293 - val_MinusLogProbMetric: 16.6293 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 398/1000
2023-09-12 15:44:52.754 
Epoch 398/1000 
	 loss: 16.4406, MinusLogProbMetric: 16.4406, val_loss: 16.6299, val_MinusLogProbMetric: 16.6299

Epoch 398: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4406 - MinusLogProbMetric: 16.4406 - val_loss: 16.6299 - val_MinusLogProbMetric: 16.6299 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 399/1000
2023-09-12 15:45:03.695 
Epoch 399/1000 
	 loss: 16.4407, MinusLogProbMetric: 16.4407, val_loss: 16.6304, val_MinusLogProbMetric: 16.6304

Epoch 399: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4407 - MinusLogProbMetric: 16.4407 - val_loss: 16.6304 - val_MinusLogProbMetric: 16.6304 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 400/1000
2023-09-12 15:45:12.689 
Epoch 400/1000 
	 loss: 16.4405, MinusLogProbMetric: 16.4405, val_loss: 16.6312, val_MinusLogProbMetric: 16.6312

Epoch 400: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4405 - MinusLogProbMetric: 16.4405 - val_loss: 16.6312 - val_MinusLogProbMetric: 16.6312 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 401/1000
2023-09-12 15:45:22.827 
Epoch 401/1000 
	 loss: 16.4421, MinusLogProbMetric: 16.4421, val_loss: 16.6334, val_MinusLogProbMetric: 16.6334

Epoch 401: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4421 - MinusLogProbMetric: 16.4421 - val_loss: 16.6334 - val_MinusLogProbMetric: 16.6334 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 402/1000
2023-09-12 15:45:33.311 
Epoch 402/1000 
	 loss: 16.4399, MinusLogProbMetric: 16.4399, val_loss: 16.6310, val_MinusLogProbMetric: 16.6310

Epoch 402: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4399 - MinusLogProbMetric: 16.4399 - val_loss: 16.6310 - val_MinusLogProbMetric: 16.6310 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 403/1000
2023-09-12 15:45:42.098 
Epoch 403/1000 
	 loss: 16.4407, MinusLogProbMetric: 16.4407, val_loss: 16.6294, val_MinusLogProbMetric: 16.6294

Epoch 403: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4407 - MinusLogProbMetric: 16.4407 - val_loss: 16.6294 - val_MinusLogProbMetric: 16.6294 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 404/1000
2023-09-12 15:45:50.738 
Epoch 404/1000 
	 loss: 16.4401, MinusLogProbMetric: 16.4401, val_loss: 16.6289, val_MinusLogProbMetric: 16.6289

Epoch 404: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4401 - MinusLogProbMetric: 16.4401 - val_loss: 16.6289 - val_MinusLogProbMetric: 16.6289 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 405/1000
2023-09-12 15:45:59.287 
Epoch 405/1000 
	 loss: 16.4407, MinusLogProbMetric: 16.4407, val_loss: 16.6324, val_MinusLogProbMetric: 16.6324

Epoch 405: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4407 - MinusLogProbMetric: 16.4407 - val_loss: 16.6324 - val_MinusLogProbMetric: 16.6324 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 406/1000
2023-09-12 15:46:07.956 
Epoch 406/1000 
	 loss: 16.4404, MinusLogProbMetric: 16.4404, val_loss: 16.6377, val_MinusLogProbMetric: 16.6377

Epoch 406: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4404 - MinusLogProbMetric: 16.4404 - val_loss: 16.6377 - val_MinusLogProbMetric: 16.6377 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 407/1000
2023-09-12 15:46:18.298 
Epoch 407/1000 
	 loss: 16.4422, MinusLogProbMetric: 16.4422, val_loss: 16.6373, val_MinusLogProbMetric: 16.6373

Epoch 407: val_loss did not improve from 16.62506
196/196 - 10s - loss: 16.4422 - MinusLogProbMetric: 16.4422 - val_loss: 16.6373 - val_MinusLogProbMetric: 16.6373 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 408/1000
2023-09-12 15:46:26.931 
Epoch 408/1000 
	 loss: 16.4409, MinusLogProbMetric: 16.4409, val_loss: 16.6306, val_MinusLogProbMetric: 16.6306

Epoch 408: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4409 - MinusLogProbMetric: 16.4409 - val_loss: 16.6306 - val_MinusLogProbMetric: 16.6306 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 409/1000
2023-09-12 15:46:35.650 
Epoch 409/1000 
	 loss: 16.4413, MinusLogProbMetric: 16.4413, val_loss: 16.6280, val_MinusLogProbMetric: 16.6280

Epoch 409: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4413 - MinusLogProbMetric: 16.4413 - val_loss: 16.6280 - val_MinusLogProbMetric: 16.6280 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 410/1000
2023-09-12 15:46:44.403 
Epoch 410/1000 
	 loss: 16.4391, MinusLogProbMetric: 16.4391, val_loss: 16.6317, val_MinusLogProbMetric: 16.6317

Epoch 410: val_loss did not improve from 16.62506
196/196 - 9s - loss: 16.4391 - MinusLogProbMetric: 16.4391 - val_loss: 16.6317 - val_MinusLogProbMetric: 16.6317 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 411/1000
2023-09-12 15:46:55.411 
Epoch 411/1000 
	 loss: 16.4405, MinusLogProbMetric: 16.4405, val_loss: 16.6328, val_MinusLogProbMetric: 16.6328

Epoch 411: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4405 - MinusLogProbMetric: 16.4405 - val_loss: 16.6328 - val_MinusLogProbMetric: 16.6328 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 412/1000
2023-09-12 15:47:06.603 
Epoch 412/1000 
	 loss: 16.4399, MinusLogProbMetric: 16.4399, val_loss: 16.6323, val_MinusLogProbMetric: 16.6323

Epoch 412: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4399 - MinusLogProbMetric: 16.4399 - val_loss: 16.6323 - val_MinusLogProbMetric: 16.6323 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 413/1000
2023-09-12 15:47:17.915 
Epoch 413/1000 
	 loss: 16.4407, MinusLogProbMetric: 16.4407, val_loss: 16.6348, val_MinusLogProbMetric: 16.6348

Epoch 413: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4407 - MinusLogProbMetric: 16.4407 - val_loss: 16.6348 - val_MinusLogProbMetric: 16.6348 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 414/1000
2023-09-12 15:47:29.132 
Epoch 414/1000 
	 loss: 16.4398, MinusLogProbMetric: 16.4398, val_loss: 16.6317, val_MinusLogProbMetric: 16.6317

Epoch 414: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4398 - MinusLogProbMetric: 16.4398 - val_loss: 16.6317 - val_MinusLogProbMetric: 16.6317 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 415/1000
2023-09-12 15:47:40.523 
Epoch 415/1000 
	 loss: 16.4402, MinusLogProbMetric: 16.4402, val_loss: 16.6342, val_MinusLogProbMetric: 16.6342

Epoch 415: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4402 - MinusLogProbMetric: 16.4402 - val_loss: 16.6342 - val_MinusLogProbMetric: 16.6342 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 416/1000
2023-09-12 15:47:51.808 
Epoch 416/1000 
	 loss: 16.4395, MinusLogProbMetric: 16.4395, val_loss: 16.6325, val_MinusLogProbMetric: 16.6325

Epoch 416: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4395 - MinusLogProbMetric: 16.4395 - val_loss: 16.6325 - val_MinusLogProbMetric: 16.6325 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 417/1000
2023-09-12 15:48:03.094 
Epoch 417/1000 
	 loss: 16.4405, MinusLogProbMetric: 16.4405, val_loss: 16.6297, val_MinusLogProbMetric: 16.6297

Epoch 417: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4405 - MinusLogProbMetric: 16.4405 - val_loss: 16.6297 - val_MinusLogProbMetric: 16.6297 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 418/1000
2023-09-12 15:48:14.494 
Epoch 418/1000 
	 loss: 16.4398, MinusLogProbMetric: 16.4398, val_loss: 16.6330, val_MinusLogProbMetric: 16.6330

Epoch 418: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4398 - MinusLogProbMetric: 16.4398 - val_loss: 16.6330 - val_MinusLogProbMetric: 16.6330 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 419/1000
2023-09-12 15:48:26.057 
Epoch 419/1000 
	 loss: 16.4392, MinusLogProbMetric: 16.4392, val_loss: 16.6301, val_MinusLogProbMetric: 16.6301

Epoch 419: val_loss did not improve from 16.62506
196/196 - 12s - loss: 16.4392 - MinusLogProbMetric: 16.4392 - val_loss: 16.6301 - val_MinusLogProbMetric: 16.6301 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 420/1000
2023-09-12 15:48:37.231 
Epoch 420/1000 
	 loss: 16.4392, MinusLogProbMetric: 16.4392, val_loss: 16.6288, val_MinusLogProbMetric: 16.6288

Epoch 420: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4392 - MinusLogProbMetric: 16.4392 - val_loss: 16.6288 - val_MinusLogProbMetric: 16.6288 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 421/1000
2023-09-12 15:48:48.420 
Epoch 421/1000 
	 loss: 16.4401, MinusLogProbMetric: 16.4401, val_loss: 16.6332, val_MinusLogProbMetric: 16.6332

Epoch 421: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4401 - MinusLogProbMetric: 16.4401 - val_loss: 16.6332 - val_MinusLogProbMetric: 16.6332 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 422/1000
2023-09-12 15:48:59.779 
Epoch 422/1000 
	 loss: 16.4393, MinusLogProbMetric: 16.4393, val_loss: 16.6288, val_MinusLogProbMetric: 16.6288

Epoch 422: val_loss did not improve from 16.62506
196/196 - 11s - loss: 16.4393 - MinusLogProbMetric: 16.4393 - val_loss: 16.6288 - val_MinusLogProbMetric: 16.6288 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 423/1000
2023-09-12 15:49:10.884 
Epoch 423/1000 
	 loss: 16.4390, MinusLogProbMetric: 16.4390, val_loss: 16.6391, val_MinusLogProbMetric: 16.6391

Epoch 423: val_loss did not improve from 16.62506
Restoring model weights from the end of the best epoch: 323.
196/196 - 11s - loss: 16.4390 - MinusLogProbMetric: 16.4390 - val_loss: 16.6391 - val_MinusLogProbMetric: 16.6391 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 423: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 8.227266591973603 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.640482758055441 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.611305002006702 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 15.656207432039082 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 721.
Model trained in 4415.98 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Metrics computed in 322.42 s.
Plots done in 134.25 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 456.67 s.
===========
Run 145/360 done in 4873.80 s.
===========

Directory ../../results/MsplineN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

===========
Generating train data for run 154.
===========
Train data generated in 0.21 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_154/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 926}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_154/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.5383615 , 4.21851   , 9.147865  , ..., 7.328855  , 2.4535477 ,
        2.0265868 ],
       [1.2026695 , 3.5675488 , 8.490738  , ..., 7.486889  , 2.9732862 ,
        1.6526531 ],
       [5.7808385 , 5.6486273 , 0.85161066, ..., 0.44565296, 6.0336885 ,
        1.4597642 ],
       ...,
       [3.869998  , 5.7079043 , 0.7277752 , ..., 1.4709862 , 7.5385275 ,
        1.2852083 ],
       [2.111317  , 3.3553224 , 7.6223764 , ..., 7.4778986 , 3.6354768 ,
        1.7641349 ],
       [0.83836687, 3.4177158 , 7.4230075 , ..., 7.223582  , 3.3779047 ,
        2.0014815 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_154/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_154
self.data_kwargs: {'seed': 926}
self.x_data: [[1.4696891  3.165189   9.115545   ... 7.2440553  3.018408   2.0407877 ]
 [2.9008398  3.8232424  7.129506   ... 7.411926   2.8866556  1.4983263 ]
 [4.669435   5.457821   0.04349925 ... 0.866001   6.611358   1.4323243 ]
 ...
 [4.261785   5.5317554  0.77893746 ... 0.60558414 5.4824862  1.3011014 ]
 [4.4981847  5.716866   0.72522354 ... 0.9913055  5.7512865  1.5265256 ]
 [5.479814   7.150977   6.3064384  ... 3.1490364  2.6668518  8.143393  ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_20"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_61 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_20 (LogProbL  (None,)                  658368    
 ayer)                                                           
                                                                 
=================================================================
Total params: 658,368
Trainable params: 658,368
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_20/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_20'")
self.model: <keras.engine.functional.Functional object at 0x7fbc17f13340>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fbc17b33f70>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fbc17b33f70>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fbc17b6c880>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fbc17b6d330>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fbc17b6d8a0>, <keras.callbacks.ModelCheckpoint object at 0x7fbc17b6d960>, <keras.callbacks.EarlyStopping object at 0x7fbc17b6dbd0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fbc17b6dc00>, <keras.callbacks.TerminateOnNaN object at 0x7fbc17b6d840>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[1.5383615 , 4.21851   , 9.147865  , ..., 7.328855  , 2.4535477 ,
        2.0265868 ],
       [1.2026695 , 3.5675488 , 8.490738  , ..., 7.486889  , 2.9732862 ,
        1.6526531 ],
       [5.7808385 , 5.6486273 , 0.85161066, ..., 0.44565296, 6.0336885 ,
        1.4597642 ],
       ...,
       [3.869998  , 5.7079043 , 0.7277752 , ..., 1.4709862 , 7.5385275 ,
        1.2852083 ],
       [2.111317  , 3.3553224 , 7.6223764 , ..., 7.4778986 , 3.6354768 ,
        1.7641349 ],
       [0.83836687, 3.4177158 , 7.4230075 , ..., 7.223582  , 3.3779047 ,
        2.0014815 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_154/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 154/360 with hyperparameters:
timestamp = 2023-09-12 15:56:49.058888
ndims = 32
seed_train = 926
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 658368
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 1.4696891   3.165189    9.115545    1.2257975   9.89761    -0.04518861
  9.761367    5.046433   10.037439    6.270509    6.6800056   0.37080207
  3.2512977   1.1872      2.5658634   0.9389908   3.4711475   5.1744766
  0.38911742  6.94769     5.6341734   2.616604    4.513363    1.4770697
  4.2721643   9.222334    2.548921    6.22901     1.4673232   7.2440553
  3.018408    2.0407877 ]
Epoch 1/1000
2023-09-12 15:57:23.890 
Epoch 1/1000 
	 loss: 42.9268, MinusLogProbMetric: 42.9268, val_loss: 20.9053, val_MinusLogProbMetric: 20.9053

Epoch 1: val_loss improved from inf to 20.90531, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 35s - loss: 42.9268 - MinusLogProbMetric: 42.9268 - val_loss: 20.9053 - val_MinusLogProbMetric: 20.9053 - lr: 0.0010 - 35s/epoch - 177ms/step
Epoch 2/1000
2023-09-12 15:57:35.204 
Epoch 2/1000 
	 loss: 19.7416, MinusLogProbMetric: 19.7416, val_loss: 19.4733, val_MinusLogProbMetric: 19.4733

Epoch 2: val_loss improved from 20.90531 to 19.47326, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 19.7416 - MinusLogProbMetric: 19.7416 - val_loss: 19.4733 - val_MinusLogProbMetric: 19.4733 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 3/1000
2023-09-12 15:57:46.661 
Epoch 3/1000 
	 loss: 18.7903, MinusLogProbMetric: 18.7903, val_loss: 18.1765, val_MinusLogProbMetric: 18.1765

Epoch 3: val_loss improved from 19.47326 to 18.17648, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 12s - loss: 18.7903 - MinusLogProbMetric: 18.7903 - val_loss: 18.1765 - val_MinusLogProbMetric: 18.1765 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 4/1000
2023-09-12 15:57:58.046 
Epoch 4/1000 
	 loss: 18.2364, MinusLogProbMetric: 18.2364, val_loss: 17.9277, val_MinusLogProbMetric: 17.9277

Epoch 4: val_loss improved from 18.17648 to 17.92773, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 18.2364 - MinusLogProbMetric: 18.2364 - val_loss: 17.9277 - val_MinusLogProbMetric: 17.9277 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 5/1000
2023-09-12 15:58:08.946 
Epoch 5/1000 
	 loss: 17.9038, MinusLogProbMetric: 17.9038, val_loss: 17.9908, val_MinusLogProbMetric: 17.9908

Epoch 5: val_loss did not improve from 17.92773
196/196 - 11s - loss: 17.9038 - MinusLogProbMetric: 17.9038 - val_loss: 17.9908 - val_MinusLogProbMetric: 17.9908 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 6/1000
2023-09-12 15:58:19.309 
Epoch 6/1000 
	 loss: 17.7144, MinusLogProbMetric: 17.7144, val_loss: 17.6362, val_MinusLogProbMetric: 17.6362

Epoch 6: val_loss improved from 17.92773 to 17.63622, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 10s - loss: 17.7144 - MinusLogProbMetric: 17.7144 - val_loss: 17.6362 - val_MinusLogProbMetric: 17.6362 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 7/1000
2023-09-12 15:58:30.880 
Epoch 7/1000 
	 loss: 17.5872, MinusLogProbMetric: 17.5872, val_loss: 17.2432, val_MinusLogProbMetric: 17.2432

Epoch 7: val_loss improved from 17.63622 to 17.24316, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 12s - loss: 17.5872 - MinusLogProbMetric: 17.5872 - val_loss: 17.2432 - val_MinusLogProbMetric: 17.2432 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 8/1000
2023-09-12 15:58:42.446 
Epoch 8/1000 
	 loss: 17.4790, MinusLogProbMetric: 17.4790, val_loss: 17.8806, val_MinusLogProbMetric: 17.8806

Epoch 8: val_loss did not improve from 17.24316
196/196 - 11s - loss: 17.4790 - MinusLogProbMetric: 17.4790 - val_loss: 17.8806 - val_MinusLogProbMetric: 17.8806 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 9/1000
2023-09-12 15:58:53.784 
Epoch 9/1000 
	 loss: 17.3783, MinusLogProbMetric: 17.3783, val_loss: 17.4140, val_MinusLogProbMetric: 17.4140

Epoch 9: val_loss did not improve from 17.24316
196/196 - 11s - loss: 17.3783 - MinusLogProbMetric: 17.3783 - val_loss: 17.4140 - val_MinusLogProbMetric: 17.4140 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 10/1000
2023-09-12 15:59:05.030 
Epoch 10/1000 
	 loss: 17.2766, MinusLogProbMetric: 17.2766, val_loss: 17.7063, val_MinusLogProbMetric: 17.7063

Epoch 10: val_loss did not improve from 17.24316
196/196 - 11s - loss: 17.2766 - MinusLogProbMetric: 17.2766 - val_loss: 17.7063 - val_MinusLogProbMetric: 17.7063 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 11/1000
2023-09-12 15:59:16.215 
Epoch 11/1000 
	 loss: 17.2941, MinusLogProbMetric: 17.2941, val_loss: 17.2181, val_MinusLogProbMetric: 17.2181

Epoch 11: val_loss improved from 17.24316 to 17.21807, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 17.2941 - MinusLogProbMetric: 17.2941 - val_loss: 17.2181 - val_MinusLogProbMetric: 17.2181 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 12/1000
2023-09-12 15:59:27.547 
Epoch 12/1000 
	 loss: 17.2123, MinusLogProbMetric: 17.2123, val_loss: 17.0697, val_MinusLogProbMetric: 17.0697

Epoch 12: val_loss improved from 17.21807 to 17.06974, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 17.2123 - MinusLogProbMetric: 17.2123 - val_loss: 17.0697 - val_MinusLogProbMetric: 17.0697 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 13/1000
2023-09-12 15:59:39.100 
Epoch 13/1000 
	 loss: 17.1406, MinusLogProbMetric: 17.1406, val_loss: 17.1542, val_MinusLogProbMetric: 17.1542

Epoch 13: val_loss did not improve from 17.06974
196/196 - 11s - loss: 17.1406 - MinusLogProbMetric: 17.1406 - val_loss: 17.1542 - val_MinusLogProbMetric: 17.1542 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 14/1000
2023-09-12 15:59:50.301 
Epoch 14/1000 
	 loss: 17.1416, MinusLogProbMetric: 17.1416, val_loss: 17.2256, val_MinusLogProbMetric: 17.2256

Epoch 14: val_loss did not improve from 17.06974
196/196 - 11s - loss: 17.1416 - MinusLogProbMetric: 17.1416 - val_loss: 17.2256 - val_MinusLogProbMetric: 17.2256 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 15/1000
2023-09-12 16:00:01.577 
Epoch 15/1000 
	 loss: 17.1022, MinusLogProbMetric: 17.1022, val_loss: 17.1672, val_MinusLogProbMetric: 17.1672

Epoch 15: val_loss did not improve from 17.06974
196/196 - 11s - loss: 17.1022 - MinusLogProbMetric: 17.1022 - val_loss: 17.1672 - val_MinusLogProbMetric: 17.1672 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 16/1000
2023-09-12 16:00:12.779 
Epoch 16/1000 
	 loss: 17.0906, MinusLogProbMetric: 17.0906, val_loss: 17.2840, val_MinusLogProbMetric: 17.2840

Epoch 16: val_loss did not improve from 17.06974
196/196 - 11s - loss: 17.0906 - MinusLogProbMetric: 17.0906 - val_loss: 17.2840 - val_MinusLogProbMetric: 17.2840 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 17/1000
2023-09-12 16:00:24.012 
Epoch 17/1000 
	 loss: 17.0494, MinusLogProbMetric: 17.0494, val_loss: 17.0696, val_MinusLogProbMetric: 17.0696

Epoch 17: val_loss improved from 17.06974 to 17.06955, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 17.0494 - MinusLogProbMetric: 17.0494 - val_loss: 17.0696 - val_MinusLogProbMetric: 17.0696 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 18/1000
2023-09-12 16:00:35.377 
Epoch 18/1000 
	 loss: 16.9817, MinusLogProbMetric: 16.9817, val_loss: 17.0791, val_MinusLogProbMetric: 17.0791

Epoch 18: val_loss did not improve from 17.06955
196/196 - 11s - loss: 16.9817 - MinusLogProbMetric: 16.9817 - val_loss: 17.0791 - val_MinusLogProbMetric: 17.0791 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 19/1000
2023-09-12 16:00:46.607 
Epoch 19/1000 
	 loss: 16.9819, MinusLogProbMetric: 16.9819, val_loss: 17.0268, val_MinusLogProbMetric: 17.0268

Epoch 19: val_loss improved from 17.06955 to 17.02675, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 16.9819 - MinusLogProbMetric: 16.9819 - val_loss: 17.0268 - val_MinusLogProbMetric: 17.0268 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 20/1000
2023-09-12 16:00:58.162 
Epoch 20/1000 
	 loss: 16.9605, MinusLogProbMetric: 16.9605, val_loss: 17.0466, val_MinusLogProbMetric: 17.0466

Epoch 20: val_loss did not improve from 17.02675
196/196 - 11s - loss: 16.9605 - MinusLogProbMetric: 16.9605 - val_loss: 17.0466 - val_MinusLogProbMetric: 17.0466 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 21/1000
2023-09-12 16:01:09.382 
Epoch 21/1000 
	 loss: 16.9508, MinusLogProbMetric: 16.9508, val_loss: 17.2317, val_MinusLogProbMetric: 17.2317

Epoch 21: val_loss did not improve from 17.02675
196/196 - 11s - loss: 16.9508 - MinusLogProbMetric: 16.9508 - val_loss: 17.2317 - val_MinusLogProbMetric: 17.2317 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 22/1000
2023-09-12 16:01:20.592 
Epoch 22/1000 
	 loss: 16.9436, MinusLogProbMetric: 16.9436, val_loss: 17.0972, val_MinusLogProbMetric: 17.0972

Epoch 22: val_loss did not improve from 17.02675
196/196 - 11s - loss: 16.9436 - MinusLogProbMetric: 16.9436 - val_loss: 17.0972 - val_MinusLogProbMetric: 17.0972 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 23/1000
2023-09-12 16:01:31.958 
Epoch 23/1000 
	 loss: 16.9712, MinusLogProbMetric: 16.9712, val_loss: 16.9437, val_MinusLogProbMetric: 16.9437

Epoch 23: val_loss improved from 17.02675 to 16.94372, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 16.9712 - MinusLogProbMetric: 16.9712 - val_loss: 16.9437 - val_MinusLogProbMetric: 16.9437 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 24/1000
2023-09-12 16:01:43.455 
Epoch 24/1000 
	 loss: 16.9071, MinusLogProbMetric: 16.9071, val_loss: 16.9894, val_MinusLogProbMetric: 16.9894

Epoch 24: val_loss did not improve from 16.94372
196/196 - 11s - loss: 16.9071 - MinusLogProbMetric: 16.9071 - val_loss: 16.9894 - val_MinusLogProbMetric: 16.9894 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 25/1000
2023-09-12 16:01:54.723 
Epoch 25/1000 
	 loss: 16.9182, MinusLogProbMetric: 16.9182, val_loss: 17.0082, val_MinusLogProbMetric: 17.0082

Epoch 25: val_loss did not improve from 16.94372
196/196 - 11s - loss: 16.9182 - MinusLogProbMetric: 16.9182 - val_loss: 17.0082 - val_MinusLogProbMetric: 17.0082 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 26/1000
2023-09-12 16:02:06.027 
Epoch 26/1000 
	 loss: 16.8861, MinusLogProbMetric: 16.8861, val_loss: 16.9765, val_MinusLogProbMetric: 16.9765

Epoch 26: val_loss did not improve from 16.94372
196/196 - 11s - loss: 16.8861 - MinusLogProbMetric: 16.8861 - val_loss: 16.9765 - val_MinusLogProbMetric: 16.9765 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 27/1000
2023-09-12 16:02:17.278 
Epoch 27/1000 
	 loss: 16.8928, MinusLogProbMetric: 16.8928, val_loss: 17.0961, val_MinusLogProbMetric: 17.0961

Epoch 27: val_loss did not improve from 16.94372
196/196 - 11s - loss: 16.8928 - MinusLogProbMetric: 16.8928 - val_loss: 17.0961 - val_MinusLogProbMetric: 17.0961 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 28/1000
2023-09-12 16:02:28.707 
Epoch 28/1000 
	 loss: 16.8423, MinusLogProbMetric: 16.8423, val_loss: 16.8667, val_MinusLogProbMetric: 16.8667

Epoch 28: val_loss improved from 16.94372 to 16.86667, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 12s - loss: 16.8423 - MinusLogProbMetric: 16.8423 - val_loss: 16.8667 - val_MinusLogProbMetric: 16.8667 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 16:02:40.180 
Epoch 29/1000 
	 loss: 16.8451, MinusLogProbMetric: 16.8451, val_loss: 16.7870, val_MinusLogProbMetric: 16.7870

Epoch 29: val_loss improved from 16.86667 to 16.78699, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 16.8451 - MinusLogProbMetric: 16.8451 - val_loss: 16.7870 - val_MinusLogProbMetric: 16.7870 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 30/1000
2023-09-12 16:02:51.758 
Epoch 30/1000 
	 loss: 16.8484, MinusLogProbMetric: 16.8484, val_loss: 16.9172, val_MinusLogProbMetric: 16.9172

Epoch 30: val_loss did not improve from 16.78699
196/196 - 11s - loss: 16.8484 - MinusLogProbMetric: 16.8484 - val_loss: 16.9172 - val_MinusLogProbMetric: 16.9172 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 31/1000
2023-09-12 16:03:02.993 
Epoch 31/1000 
	 loss: 16.8294, MinusLogProbMetric: 16.8294, val_loss: 16.8523, val_MinusLogProbMetric: 16.8523

Epoch 31: val_loss did not improve from 16.78699
196/196 - 11s - loss: 16.8294 - MinusLogProbMetric: 16.8294 - val_loss: 16.8523 - val_MinusLogProbMetric: 16.8523 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 32/1000
2023-09-12 16:03:14.220 
Epoch 32/1000 
	 loss: 16.8306, MinusLogProbMetric: 16.8306, val_loss: 16.8366, val_MinusLogProbMetric: 16.8366

Epoch 32: val_loss did not improve from 16.78699
196/196 - 11s - loss: 16.8306 - MinusLogProbMetric: 16.8306 - val_loss: 16.8366 - val_MinusLogProbMetric: 16.8366 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 33/1000
2023-09-12 16:03:25.456 
Epoch 33/1000 
	 loss: 16.7978, MinusLogProbMetric: 16.7978, val_loss: 16.8278, val_MinusLogProbMetric: 16.8278

Epoch 33: val_loss did not improve from 16.78699
196/196 - 11s - loss: 16.7978 - MinusLogProbMetric: 16.7978 - val_loss: 16.8278 - val_MinusLogProbMetric: 16.8278 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 34/1000
2023-09-12 16:03:36.743 
Epoch 34/1000 
	 loss: 16.8205, MinusLogProbMetric: 16.8205, val_loss: 16.7579, val_MinusLogProbMetric: 16.7579

Epoch 34: val_loss improved from 16.78699 to 16.75788, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 16.8205 - MinusLogProbMetric: 16.8205 - val_loss: 16.7579 - val_MinusLogProbMetric: 16.7579 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 35/1000
2023-09-12 16:03:48.167 
Epoch 35/1000 
	 loss: 16.7805, MinusLogProbMetric: 16.7805, val_loss: 16.8397, val_MinusLogProbMetric: 16.8397

Epoch 35: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7805 - MinusLogProbMetric: 16.7805 - val_loss: 16.8397 - val_MinusLogProbMetric: 16.8397 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 36/1000
2023-09-12 16:03:59.526 
Epoch 36/1000 
	 loss: 16.8054, MinusLogProbMetric: 16.8054, val_loss: 16.8239, val_MinusLogProbMetric: 16.8239

Epoch 36: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.8054 - MinusLogProbMetric: 16.8054 - val_loss: 16.8239 - val_MinusLogProbMetric: 16.8239 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 37/1000
2023-09-12 16:04:10.862 
Epoch 37/1000 
	 loss: 16.7733, MinusLogProbMetric: 16.7733, val_loss: 16.8439, val_MinusLogProbMetric: 16.8439

Epoch 37: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7733 - MinusLogProbMetric: 16.7733 - val_loss: 16.8439 - val_MinusLogProbMetric: 16.8439 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 38/1000
2023-09-12 16:04:22.045 
Epoch 38/1000 
	 loss: 16.8026, MinusLogProbMetric: 16.8026, val_loss: 16.8586, val_MinusLogProbMetric: 16.8586

Epoch 38: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.8026 - MinusLogProbMetric: 16.8026 - val_loss: 16.8586 - val_MinusLogProbMetric: 16.8586 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 39/1000
2023-09-12 16:04:33.210 
Epoch 39/1000 
	 loss: 16.7552, MinusLogProbMetric: 16.7552, val_loss: 17.1568, val_MinusLogProbMetric: 17.1568

Epoch 39: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7552 - MinusLogProbMetric: 16.7552 - val_loss: 17.1568 - val_MinusLogProbMetric: 17.1568 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 40/1000
2023-09-12 16:04:44.475 
Epoch 40/1000 
	 loss: 16.7618, MinusLogProbMetric: 16.7618, val_loss: 16.9976, val_MinusLogProbMetric: 16.9976

Epoch 40: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7618 - MinusLogProbMetric: 16.7618 - val_loss: 16.9976 - val_MinusLogProbMetric: 16.9976 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 41/1000
2023-09-12 16:04:55.480 
Epoch 41/1000 
	 loss: 16.7565, MinusLogProbMetric: 16.7565, val_loss: 16.9621, val_MinusLogProbMetric: 16.9621

Epoch 41: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7565 - MinusLogProbMetric: 16.7565 - val_loss: 16.9621 - val_MinusLogProbMetric: 16.9621 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 42/1000
2023-09-12 16:05:06.634 
Epoch 42/1000 
	 loss: 16.7580, MinusLogProbMetric: 16.7580, val_loss: 16.8664, val_MinusLogProbMetric: 16.8664

Epoch 42: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7580 - MinusLogProbMetric: 16.7580 - val_loss: 16.8664 - val_MinusLogProbMetric: 16.8664 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 43/1000
2023-09-12 16:05:17.740 
Epoch 43/1000 
	 loss: 16.7519, MinusLogProbMetric: 16.7519, val_loss: 16.7669, val_MinusLogProbMetric: 16.7669

Epoch 43: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7519 - MinusLogProbMetric: 16.7519 - val_loss: 16.7669 - val_MinusLogProbMetric: 16.7669 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 44/1000
2023-09-12 16:05:28.868 
Epoch 44/1000 
	 loss: 16.7318, MinusLogProbMetric: 16.7318, val_loss: 16.8322, val_MinusLogProbMetric: 16.8322

Epoch 44: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7318 - MinusLogProbMetric: 16.7318 - val_loss: 16.8322 - val_MinusLogProbMetric: 16.8322 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 45/1000
2023-09-12 16:05:39.927 
Epoch 45/1000 
	 loss: 16.7445, MinusLogProbMetric: 16.7445, val_loss: 16.7997, val_MinusLogProbMetric: 16.7997

Epoch 45: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7445 - MinusLogProbMetric: 16.7445 - val_loss: 16.7997 - val_MinusLogProbMetric: 16.7997 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 46/1000
2023-09-12 16:05:51.181 
Epoch 46/1000 
	 loss: 16.7324, MinusLogProbMetric: 16.7324, val_loss: 16.7843, val_MinusLogProbMetric: 16.7843

Epoch 46: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7324 - MinusLogProbMetric: 16.7324 - val_loss: 16.7843 - val_MinusLogProbMetric: 16.7843 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 47/1000
2023-09-12 16:06:02.441 
Epoch 47/1000 
	 loss: 16.7366, MinusLogProbMetric: 16.7366, val_loss: 16.8690, val_MinusLogProbMetric: 16.8690

Epoch 47: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7366 - MinusLogProbMetric: 16.7366 - val_loss: 16.8690 - val_MinusLogProbMetric: 16.8690 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 48/1000
2023-09-12 16:06:13.945 
Epoch 48/1000 
	 loss: 16.7302, MinusLogProbMetric: 16.7302, val_loss: 16.8082, val_MinusLogProbMetric: 16.8082

Epoch 48: val_loss did not improve from 16.75788
196/196 - 11s - loss: 16.7302 - MinusLogProbMetric: 16.7302 - val_loss: 16.8082 - val_MinusLogProbMetric: 16.8082 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 49/1000
2023-09-12 16:06:25.353 
Epoch 49/1000 
	 loss: 16.7270, MinusLogProbMetric: 16.7270, val_loss: 16.7486, val_MinusLogProbMetric: 16.7486

Epoch 49: val_loss improved from 16.75788 to 16.74857, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 12s - loss: 16.7270 - MinusLogProbMetric: 16.7270 - val_loss: 16.7486 - val_MinusLogProbMetric: 16.7486 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-12 16:06:36.795 
Epoch 50/1000 
	 loss: 16.7052, MinusLogProbMetric: 16.7052, val_loss: 16.7963, val_MinusLogProbMetric: 16.7963

Epoch 50: val_loss did not improve from 16.74857
196/196 - 11s - loss: 16.7052 - MinusLogProbMetric: 16.7052 - val_loss: 16.7963 - val_MinusLogProbMetric: 16.7963 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 51/1000
2023-09-12 16:06:48.045 
Epoch 51/1000 
	 loss: 16.7319, MinusLogProbMetric: 16.7319, val_loss: 16.8326, val_MinusLogProbMetric: 16.8326

Epoch 51: val_loss did not improve from 16.74857
196/196 - 11s - loss: 16.7319 - MinusLogProbMetric: 16.7319 - val_loss: 16.8326 - val_MinusLogProbMetric: 16.8326 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 52/1000
2023-09-12 16:06:59.297 
Epoch 52/1000 
	 loss: 16.6896, MinusLogProbMetric: 16.6896, val_loss: 16.7697, val_MinusLogProbMetric: 16.7697

Epoch 52: val_loss did not improve from 16.74857
196/196 - 11s - loss: 16.6896 - MinusLogProbMetric: 16.6896 - val_loss: 16.7697 - val_MinusLogProbMetric: 16.7697 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 53/1000
2023-09-12 16:07:10.485 
Epoch 53/1000 
	 loss: 16.7132, MinusLogProbMetric: 16.7132, val_loss: 16.8429, val_MinusLogProbMetric: 16.8429

Epoch 53: val_loss did not improve from 16.74857
196/196 - 11s - loss: 16.7132 - MinusLogProbMetric: 16.7132 - val_loss: 16.8429 - val_MinusLogProbMetric: 16.8429 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 54/1000
2023-09-12 16:07:21.665 
Epoch 54/1000 
	 loss: 16.6927, MinusLogProbMetric: 16.6927, val_loss: 16.7173, val_MinusLogProbMetric: 16.7173

Epoch 54: val_loss improved from 16.74857 to 16.71732, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 11s - loss: 16.6927 - MinusLogProbMetric: 16.6927 - val_loss: 16.7173 - val_MinusLogProbMetric: 16.7173 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 55/1000
2023-09-12 16:07:32.829 
Epoch 55/1000 
	 loss: 16.6886, MinusLogProbMetric: 16.6886, val_loss: 16.8020, val_MinusLogProbMetric: 16.8020

Epoch 55: val_loss did not improve from 16.71732
196/196 - 11s - loss: 16.6886 - MinusLogProbMetric: 16.6886 - val_loss: 16.8020 - val_MinusLogProbMetric: 16.8020 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 56/1000
2023-09-12 16:07:42.878 
Epoch 56/1000 
	 loss: 16.6987, MinusLogProbMetric: 16.6987, val_loss: 16.7672, val_MinusLogProbMetric: 16.7672

Epoch 56: val_loss did not improve from 16.71732
196/196 - 10s - loss: 16.6987 - MinusLogProbMetric: 16.6987 - val_loss: 16.7672 - val_MinusLogProbMetric: 16.7672 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 57/1000
2023-09-12 16:07:52.359 
Epoch 57/1000 
	 loss: 16.6772, MinusLogProbMetric: 16.6772, val_loss: 16.6809, val_MinusLogProbMetric: 16.6809

Epoch 57: val_loss improved from 16.71732 to 16.68094, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 10s - loss: 16.6772 - MinusLogProbMetric: 16.6772 - val_loss: 16.6809 - val_MinusLogProbMetric: 16.6809 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 58/1000
2023-09-12 16:08:03.011 
Epoch 58/1000 
	 loss: 16.6749, MinusLogProbMetric: 16.6749, val_loss: 16.7976, val_MinusLogProbMetric: 16.7976

Epoch 58: val_loss did not improve from 16.68094
196/196 - 11s - loss: 16.6749 - MinusLogProbMetric: 16.6749 - val_loss: 16.7976 - val_MinusLogProbMetric: 16.7976 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 59/1000
2023-09-12 16:08:12.733 
Epoch 59/1000 
	 loss: 16.6763, MinusLogProbMetric: 16.6763, val_loss: 16.7027, val_MinusLogProbMetric: 16.7027

Epoch 59: val_loss did not improve from 16.68094
196/196 - 10s - loss: 16.6763 - MinusLogProbMetric: 16.6763 - val_loss: 16.7027 - val_MinusLogProbMetric: 16.7027 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 60/1000
2023-09-12 16:08:22.209 
Epoch 60/1000 
	 loss: 16.6639, MinusLogProbMetric: 16.6639, val_loss: 16.7920, val_MinusLogProbMetric: 16.7920

Epoch 60: val_loss did not improve from 16.68094
196/196 - 9s - loss: 16.6639 - MinusLogProbMetric: 16.6639 - val_loss: 16.7920 - val_MinusLogProbMetric: 16.7920 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 61/1000
2023-09-12 16:08:31.967 
Epoch 61/1000 
	 loss: 16.6737, MinusLogProbMetric: 16.6737, val_loss: 16.7592, val_MinusLogProbMetric: 16.7592

Epoch 61: val_loss did not improve from 16.68094
196/196 - 10s - loss: 16.6737 - MinusLogProbMetric: 16.6737 - val_loss: 16.7592 - val_MinusLogProbMetric: 16.7592 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 62/1000
2023-09-12 16:08:41.628 
Epoch 62/1000 
	 loss: 16.6682, MinusLogProbMetric: 16.6682, val_loss: 16.7188, val_MinusLogProbMetric: 16.7188

Epoch 62: val_loss did not improve from 16.68094
196/196 - 10s - loss: 16.6682 - MinusLogProbMetric: 16.6682 - val_loss: 16.7188 - val_MinusLogProbMetric: 16.7188 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 63/1000
2023-09-12 16:08:51.060 
Epoch 63/1000 
	 loss: 16.6586, MinusLogProbMetric: 16.6586, val_loss: 16.7043, val_MinusLogProbMetric: 16.7043

Epoch 63: val_loss did not improve from 16.68094
196/196 - 9s - loss: 16.6586 - MinusLogProbMetric: 16.6586 - val_loss: 16.7043 - val_MinusLogProbMetric: 16.7043 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 64/1000
2023-09-12 16:09:00.544 
Epoch 64/1000 
	 loss: 16.6618, MinusLogProbMetric: 16.6618, val_loss: 16.8638, val_MinusLogProbMetric: 16.8638

Epoch 64: val_loss did not improve from 16.68094
196/196 - 9s - loss: 16.6618 - MinusLogProbMetric: 16.6618 - val_loss: 16.8638 - val_MinusLogProbMetric: 16.8638 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 65/1000
2023-09-12 16:09:10.470 
Epoch 65/1000 
	 loss: 16.6474, MinusLogProbMetric: 16.6474, val_loss: 16.7522, val_MinusLogProbMetric: 16.7522

Epoch 65: val_loss did not improve from 16.68094
196/196 - 10s - loss: 16.6474 - MinusLogProbMetric: 16.6474 - val_loss: 16.7522 - val_MinusLogProbMetric: 16.7522 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 66/1000
2023-09-12 16:09:19.928 
Epoch 66/1000 
	 loss: 16.6540, MinusLogProbMetric: 16.6540, val_loss: 16.6591, val_MinusLogProbMetric: 16.6591

Epoch 66: val_loss improved from 16.68094 to 16.65912, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_154/weights/best_weights.h5
196/196 - 10s - loss: 16.6540 - MinusLogProbMetric: 16.6540 - val_loss: 16.6591 - val_MinusLogProbMetric: 16.6591 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 67/1000
2023-09-12 16:09:29.562 
Epoch 67/1000 
	 loss: 16.6503, MinusLogProbMetric: 16.6503, val_loss: 16.8136, val_MinusLogProbMetric: 16.8136

Epoch 67: val_loss did not improve from 16.65912
196/196 - 9s - loss: 16.6503 - MinusLogProbMetric: 16.6503 - val_loss: 16.8136 - val_MinusLogProbMetric: 16.8136 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 68/1000
2023-09-12 16:09:39.029 
Epoch 68/1000 
	 loss: 16.6537, MinusLogProbMetric: 16.6537, val_loss: 16.7787, val_MinusLogProbMetric: 16.7787

Epoch 68: val_loss did not improve from 16.65912
196/196 - 9s - loss: 16.6537 - MinusLogProbMetric: 16.6537 - val_loss: 16.7787 - val_MinusLogProbMetric: 16.7787 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 69/1000
2023-09-12 16:09:48.377 
Epoch 69/1000 
	 loss: 16.6620, MinusLogProbMetric: 16.6620, val_loss: 16.7663, val_MinusLogProbMetric: 16.7663

Epoch 69: val_loss did not improve from 16.65912
196/196 - 9s - loss: 16.6620 - MinusLogProbMetric: 16.6620 - val_loss: 16.7663 - val_MinusLogProbMetric: 16.7663 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 70/1000
2023-09-12 16:09:57.757 
Epoch 70/1000 
	 loss: 16.6451, MinusLogProbMetric: 16.6451, val_loss: 16.7003, val_MinusLogProbMetric: 16.7003

Epoch 70: val_loss did not improve from 16.65912
196/196 - 9s - loss: 16.6451 - MinusLogProbMetric: 16.6451 - val_loss: 16.7003 - val_MinusLogProbMetric: 16.7003 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 71/1000
2023-09-12 16:10:07.180 
Epoch 71/1000 
	 loss: 16.6303, MinusLogProbMetric: 16.6303, val_loss: 17.0707, val_MinusLogProbMetric: 17.0707

Epoch 71: val_loss did not improve from 16.65912
196/196 - 9s - loss: 16.6303 - MinusLogProbMetric: 16.6303 - val_loss: 17.0707 - val_MinusLogProbMetric: 17.0707 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 72/1000
2023-09-12 16:10:16.742 
Epoch 72/1000 
	 loss: 16.6496, MinusLogProbMetric: 16.6496, val_loss: 16.7132, val_MinusLogProbMetric: 16.7132

Epoch 72: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.6496 - MinusLogProbMetric: 16.6496 - val_loss: 16.7132 - val_MinusLogProbMetric: 16.7132 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 73/1000
2023-09-12 16:10:25.916 
Epoch 73/1000 
	 loss: 16.6322, MinusLogProbMetric: 16.6322, val_loss: 16.7875, val_MinusLogProbMetric: 16.7875

Epoch 73: val_loss did not improve from 16.65912
196/196 - 9s - loss: 16.6322 - MinusLogProbMetric: 16.6322 - val_loss: 16.7875 - val_MinusLogProbMetric: 16.7875 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 74/1000
2023-09-12 16:10:35.078 
Epoch 74/1000 
	 loss: 16.6290, MinusLogProbMetric: 16.6290, val_loss: 16.7252, val_MinusLogProbMetric: 16.7252

Epoch 74: val_loss did not improve from 16.65912
196/196 - 9s - loss: 16.6290 - MinusLogProbMetric: 16.6290 - val_loss: 16.7252 - val_MinusLogProbMetric: 16.7252 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 75/1000
2023-09-12 16:10:44.607 
Epoch 75/1000 
	 loss: 16.6358, MinusLogProbMetric: 16.6358, val_loss: 16.7411, val_MinusLogProbMetric: 16.7411

Epoch 75: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.6358 - MinusLogProbMetric: 16.6358 - val_loss: 16.7411 - val_MinusLogProbMetric: 16.7411 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 76/1000
2023-09-12 16:10:54.622 
Epoch 76/1000 
	 loss: 16.6149, MinusLogProbMetric: 16.6149, val_loss: 16.7094, val_MinusLogProbMetric: 16.7094

Epoch 76: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.6149 - MinusLogProbMetric: 16.6149 - val_loss: 16.7094 - val_MinusLogProbMetric: 16.7094 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 77/1000
2023-09-12 16:11:05.927 
Epoch 77/1000 
	 loss: 16.6233, MinusLogProbMetric: 16.6233, val_loss: 16.7931, val_MinusLogProbMetric: 16.7931

Epoch 77: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6233 - MinusLogProbMetric: 16.6233 - val_loss: 16.7931 - val_MinusLogProbMetric: 16.7931 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 78/1000
2023-09-12 16:11:17.401 
Epoch 78/1000 
	 loss: 16.6181, MinusLogProbMetric: 16.6181, val_loss: 16.8010, val_MinusLogProbMetric: 16.8010

Epoch 78: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6181 - MinusLogProbMetric: 16.6181 - val_loss: 16.8010 - val_MinusLogProbMetric: 16.8010 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 79/1000
2023-09-12 16:11:28.935 
Epoch 79/1000 
	 loss: 16.6323, MinusLogProbMetric: 16.6323, val_loss: 16.7342, val_MinusLogProbMetric: 16.7342

Epoch 79: val_loss did not improve from 16.65912
196/196 - 12s - loss: 16.6323 - MinusLogProbMetric: 16.6323 - val_loss: 16.7342 - val_MinusLogProbMetric: 16.7342 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 80/1000
2023-09-12 16:11:40.389 
Epoch 80/1000 
	 loss: 16.6383, MinusLogProbMetric: 16.6383, val_loss: 16.8086, val_MinusLogProbMetric: 16.8086

Epoch 80: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6383 - MinusLogProbMetric: 16.6383 - val_loss: 16.8086 - val_MinusLogProbMetric: 16.8086 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 81/1000
2023-09-12 16:11:51.788 
Epoch 81/1000 
	 loss: 16.6032, MinusLogProbMetric: 16.6032, val_loss: 16.7550, val_MinusLogProbMetric: 16.7550

Epoch 81: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6032 - MinusLogProbMetric: 16.6032 - val_loss: 16.7550 - val_MinusLogProbMetric: 16.7550 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 82/1000
2023-09-12 16:12:03.142 
Epoch 82/1000 
	 loss: 16.6201, MinusLogProbMetric: 16.6201, val_loss: 16.8192, val_MinusLogProbMetric: 16.8192

Epoch 82: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6201 - MinusLogProbMetric: 16.6201 - val_loss: 16.8192 - val_MinusLogProbMetric: 16.8192 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 83/1000
2023-09-12 16:12:14.596 
Epoch 83/1000 
	 loss: 16.6082, MinusLogProbMetric: 16.6082, val_loss: 16.8282, val_MinusLogProbMetric: 16.8282

Epoch 83: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6082 - MinusLogProbMetric: 16.6082 - val_loss: 16.8282 - val_MinusLogProbMetric: 16.8282 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 84/1000
2023-09-12 16:12:25.924 
Epoch 84/1000 
	 loss: 16.6068, MinusLogProbMetric: 16.6068, val_loss: 16.7558, val_MinusLogProbMetric: 16.7558

Epoch 84: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6068 - MinusLogProbMetric: 16.6068 - val_loss: 16.7558 - val_MinusLogProbMetric: 16.7558 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 85/1000
2023-09-12 16:12:37.265 
Epoch 85/1000 
	 loss: 16.5900, MinusLogProbMetric: 16.5900, val_loss: 16.7458, val_MinusLogProbMetric: 16.7458

Epoch 85: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5900 - MinusLogProbMetric: 16.5900 - val_loss: 16.7458 - val_MinusLogProbMetric: 16.7458 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 86/1000
2023-09-12 16:12:48.461 
Epoch 86/1000 
	 loss: 16.6104, MinusLogProbMetric: 16.6104, val_loss: 16.6866, val_MinusLogProbMetric: 16.6866

Epoch 86: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6104 - MinusLogProbMetric: 16.6104 - val_loss: 16.6866 - val_MinusLogProbMetric: 16.6866 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 87/1000
2023-09-12 16:12:59.842 
Epoch 87/1000 
	 loss: 16.6088, MinusLogProbMetric: 16.6088, val_loss: 16.7613, val_MinusLogProbMetric: 16.7613

Epoch 87: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6088 - MinusLogProbMetric: 16.6088 - val_loss: 16.7613 - val_MinusLogProbMetric: 16.7613 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 88/1000
2023-09-12 16:13:10.900 
Epoch 88/1000 
	 loss: 16.5964, MinusLogProbMetric: 16.5964, val_loss: 16.7155, val_MinusLogProbMetric: 16.7155

Epoch 88: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5964 - MinusLogProbMetric: 16.5964 - val_loss: 16.7155 - val_MinusLogProbMetric: 16.7155 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 89/1000
2023-09-12 16:13:22.003 
Epoch 89/1000 
	 loss: 16.6062, MinusLogProbMetric: 16.6062, val_loss: 16.7854, val_MinusLogProbMetric: 16.7854

Epoch 89: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6062 - MinusLogProbMetric: 16.6062 - val_loss: 16.7854 - val_MinusLogProbMetric: 16.7854 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 90/1000
2023-09-12 16:13:33.196 
Epoch 90/1000 
	 loss: 16.5986, MinusLogProbMetric: 16.5986, val_loss: 16.7352, val_MinusLogProbMetric: 16.7352

Epoch 90: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5986 - MinusLogProbMetric: 16.5986 - val_loss: 16.7352 - val_MinusLogProbMetric: 16.7352 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 91/1000
2023-09-12 16:13:44.715 
Epoch 91/1000 
	 loss: 16.5871, MinusLogProbMetric: 16.5871, val_loss: 16.8714, val_MinusLogProbMetric: 16.8714

Epoch 91: val_loss did not improve from 16.65912
196/196 - 12s - loss: 16.5871 - MinusLogProbMetric: 16.5871 - val_loss: 16.8714 - val_MinusLogProbMetric: 16.8714 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 92/1000
2023-09-12 16:13:56.123 
Epoch 92/1000 
	 loss: 16.6041, MinusLogProbMetric: 16.6041, val_loss: 16.8028, val_MinusLogProbMetric: 16.8028

Epoch 92: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6041 - MinusLogProbMetric: 16.6041 - val_loss: 16.8028 - val_MinusLogProbMetric: 16.8028 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 93/1000
2023-09-12 16:14:07.123 
Epoch 93/1000 
	 loss: 16.6103, MinusLogProbMetric: 16.6103, val_loss: 16.7488, val_MinusLogProbMetric: 16.7488

Epoch 93: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.6103 - MinusLogProbMetric: 16.6103 - val_loss: 16.7488 - val_MinusLogProbMetric: 16.7488 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 94/1000
2023-09-12 16:14:18.480 
Epoch 94/1000 
	 loss: 16.5693, MinusLogProbMetric: 16.5693, val_loss: 16.8896, val_MinusLogProbMetric: 16.8896

Epoch 94: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5693 - MinusLogProbMetric: 16.5693 - val_loss: 16.8896 - val_MinusLogProbMetric: 16.8896 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 95/1000
2023-09-12 16:14:29.767 
Epoch 95/1000 
	 loss: 16.5783, MinusLogProbMetric: 16.5783, val_loss: 16.6998, val_MinusLogProbMetric: 16.6998

Epoch 95: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5783 - MinusLogProbMetric: 16.5783 - val_loss: 16.6998 - val_MinusLogProbMetric: 16.6998 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 96/1000
2023-09-12 16:14:40.672 
Epoch 96/1000 
	 loss: 16.5669, MinusLogProbMetric: 16.5669, val_loss: 16.7906, val_MinusLogProbMetric: 16.7906

Epoch 96: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5669 - MinusLogProbMetric: 16.5669 - val_loss: 16.7906 - val_MinusLogProbMetric: 16.7906 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 97/1000
2023-09-12 16:14:51.898 
Epoch 97/1000 
	 loss: 16.5687, MinusLogProbMetric: 16.5687, val_loss: 16.7049, val_MinusLogProbMetric: 16.7049

Epoch 97: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5687 - MinusLogProbMetric: 16.5687 - val_loss: 16.7049 - val_MinusLogProbMetric: 16.7049 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 98/1000
2023-09-12 16:15:03.024 
Epoch 98/1000 
	 loss: 16.5918, MinusLogProbMetric: 16.5918, val_loss: 16.7490, val_MinusLogProbMetric: 16.7490

Epoch 98: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5918 - MinusLogProbMetric: 16.5918 - val_loss: 16.7490 - val_MinusLogProbMetric: 16.7490 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 99/1000
2023-09-12 16:15:13.437 
Epoch 99/1000 
	 loss: 16.5657, MinusLogProbMetric: 16.5657, val_loss: 16.7166, val_MinusLogProbMetric: 16.7166

Epoch 99: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5657 - MinusLogProbMetric: 16.5657 - val_loss: 16.7166 - val_MinusLogProbMetric: 16.7166 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 100/1000
2023-09-12 16:15:23.928 
Epoch 100/1000 
	 loss: 16.5661, MinusLogProbMetric: 16.5661, val_loss: 16.7711, val_MinusLogProbMetric: 16.7711

Epoch 100: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5661 - MinusLogProbMetric: 16.5661 - val_loss: 16.7711 - val_MinusLogProbMetric: 16.7711 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 101/1000
2023-09-12 16:15:35.294 
Epoch 101/1000 
	 loss: 16.5684, MinusLogProbMetric: 16.5684, val_loss: 16.7169, val_MinusLogProbMetric: 16.7169

Epoch 101: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5684 - MinusLogProbMetric: 16.5684 - val_loss: 16.7169 - val_MinusLogProbMetric: 16.7169 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 102/1000
2023-09-12 16:15:46.493 
Epoch 102/1000 
	 loss: 16.5718, MinusLogProbMetric: 16.5718, val_loss: 16.7937, val_MinusLogProbMetric: 16.7937

Epoch 102: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5718 - MinusLogProbMetric: 16.5718 - val_loss: 16.7937 - val_MinusLogProbMetric: 16.7937 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 103/1000
2023-09-12 16:15:57.729 
Epoch 103/1000 
	 loss: 16.5700, MinusLogProbMetric: 16.5700, val_loss: 16.7638, val_MinusLogProbMetric: 16.7638

Epoch 103: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5700 - MinusLogProbMetric: 16.5700 - val_loss: 16.7638 - val_MinusLogProbMetric: 16.7638 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 104/1000
2023-09-12 16:16:08.984 
Epoch 104/1000 
	 loss: 16.5675, MinusLogProbMetric: 16.5675, val_loss: 16.7151, val_MinusLogProbMetric: 16.7151

Epoch 104: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5675 - MinusLogProbMetric: 16.5675 - val_loss: 16.7151 - val_MinusLogProbMetric: 16.7151 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 105/1000
2023-09-12 16:16:20.165 
Epoch 105/1000 
	 loss: 16.5452, MinusLogProbMetric: 16.5452, val_loss: 16.7493, val_MinusLogProbMetric: 16.7493

Epoch 105: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5452 - MinusLogProbMetric: 16.5452 - val_loss: 16.7493 - val_MinusLogProbMetric: 16.7493 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 106/1000
2023-09-12 16:16:31.433 
Epoch 106/1000 
	 loss: 16.5467, MinusLogProbMetric: 16.5467, val_loss: 16.7236, val_MinusLogProbMetric: 16.7236

Epoch 106: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5467 - MinusLogProbMetric: 16.5467 - val_loss: 16.7236 - val_MinusLogProbMetric: 16.7236 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 107/1000
2023-09-12 16:16:42.086 
Epoch 107/1000 
	 loss: 16.5554, MinusLogProbMetric: 16.5554, val_loss: 16.8169, val_MinusLogProbMetric: 16.8169

Epoch 107: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5554 - MinusLogProbMetric: 16.5554 - val_loss: 16.8169 - val_MinusLogProbMetric: 16.8169 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 108/1000
2023-09-12 16:16:53.606 
Epoch 108/1000 
	 loss: 16.5531, MinusLogProbMetric: 16.5531, val_loss: 16.8318, val_MinusLogProbMetric: 16.8318

Epoch 108: val_loss did not improve from 16.65912
196/196 - 12s - loss: 16.5531 - MinusLogProbMetric: 16.5531 - val_loss: 16.8318 - val_MinusLogProbMetric: 16.8318 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 109/1000
2023-09-12 16:17:04.822 
Epoch 109/1000 
	 loss: 16.5488, MinusLogProbMetric: 16.5488, val_loss: 16.7511, val_MinusLogProbMetric: 16.7511

Epoch 109: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5488 - MinusLogProbMetric: 16.5488 - val_loss: 16.7511 - val_MinusLogProbMetric: 16.7511 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 110/1000
2023-09-12 16:17:15.398 
Epoch 110/1000 
	 loss: 16.5607, MinusLogProbMetric: 16.5607, val_loss: 16.6922, val_MinusLogProbMetric: 16.6922

Epoch 110: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.5607 - MinusLogProbMetric: 16.5607 - val_loss: 16.6922 - val_MinusLogProbMetric: 16.6922 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 111/1000
2023-09-12 16:17:25.484 
Epoch 111/1000 
	 loss: 16.5453, MinusLogProbMetric: 16.5453, val_loss: 16.8726, val_MinusLogProbMetric: 16.8726

Epoch 111: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5453 - MinusLogProbMetric: 16.5453 - val_loss: 16.8726 - val_MinusLogProbMetric: 16.8726 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 112/1000
2023-09-12 16:17:35.246 
Epoch 112/1000 
	 loss: 16.5398, MinusLogProbMetric: 16.5398, val_loss: 16.8658, val_MinusLogProbMetric: 16.8658

Epoch 112: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5398 - MinusLogProbMetric: 16.5398 - val_loss: 16.8658 - val_MinusLogProbMetric: 16.8658 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 113/1000
2023-09-12 16:17:44.914 
Epoch 113/1000 
	 loss: 16.5654, MinusLogProbMetric: 16.5654, val_loss: 16.7757, val_MinusLogProbMetric: 16.7757

Epoch 113: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5654 - MinusLogProbMetric: 16.5654 - val_loss: 16.7757 - val_MinusLogProbMetric: 16.7757 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 114/1000
2023-09-12 16:17:54.646 
Epoch 114/1000 
	 loss: 16.5337, MinusLogProbMetric: 16.5337, val_loss: 16.8146, val_MinusLogProbMetric: 16.8146

Epoch 114: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5337 - MinusLogProbMetric: 16.5337 - val_loss: 16.8146 - val_MinusLogProbMetric: 16.8146 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 115/1000
2023-09-12 16:18:04.170 
Epoch 115/1000 
	 loss: 16.5426, MinusLogProbMetric: 16.5426, val_loss: 16.7963, val_MinusLogProbMetric: 16.7963

Epoch 115: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5426 - MinusLogProbMetric: 16.5426 - val_loss: 16.7963 - val_MinusLogProbMetric: 16.7963 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 116/1000
2023-09-12 16:18:13.696 
Epoch 116/1000 
	 loss: 16.5412, MinusLogProbMetric: 16.5412, val_loss: 16.7481, val_MinusLogProbMetric: 16.7481

Epoch 116: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.5412 - MinusLogProbMetric: 16.5412 - val_loss: 16.7481 - val_MinusLogProbMetric: 16.7481 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 117/1000
2023-09-12 16:18:23.313 
Epoch 117/1000 
	 loss: 16.4568, MinusLogProbMetric: 16.4568, val_loss: 16.6799, val_MinusLogProbMetric: 16.6799

Epoch 117: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.4568 - MinusLogProbMetric: 16.4568 - val_loss: 16.6799 - val_MinusLogProbMetric: 16.6799 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 118/1000
2023-09-12 16:18:32.832 
Epoch 118/1000 
	 loss: 16.4494, MinusLogProbMetric: 16.4494, val_loss: 16.7115, val_MinusLogProbMetric: 16.7115

Epoch 118: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.4494 - MinusLogProbMetric: 16.4494 - val_loss: 16.7115 - val_MinusLogProbMetric: 16.7115 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 119/1000
2023-09-12 16:18:43.161 
Epoch 119/1000 
	 loss: 16.4481, MinusLogProbMetric: 16.4481, val_loss: 16.7256, val_MinusLogProbMetric: 16.7256

Epoch 119: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.4481 - MinusLogProbMetric: 16.4481 - val_loss: 16.7256 - val_MinusLogProbMetric: 16.7256 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 120/1000
2023-09-12 16:18:52.780 
Epoch 120/1000 
	 loss: 16.4415, MinusLogProbMetric: 16.4415, val_loss: 16.6836, val_MinusLogProbMetric: 16.6836

Epoch 120: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.4415 - MinusLogProbMetric: 16.4415 - val_loss: 16.6836 - val_MinusLogProbMetric: 16.6836 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 121/1000
2023-09-12 16:19:02.381 
Epoch 121/1000 
	 loss: 16.4421, MinusLogProbMetric: 16.4421, val_loss: 16.7249, val_MinusLogProbMetric: 16.7249

Epoch 121: val_loss did not improve from 16.65912
196/196 - 10s - loss: 16.4421 - MinusLogProbMetric: 16.4421 - val_loss: 16.7249 - val_MinusLogProbMetric: 16.7249 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 122/1000
2023-09-12 16:19:13.374 
Epoch 122/1000 
	 loss: 16.4377, MinusLogProbMetric: 16.4377, val_loss: 16.6924, val_MinusLogProbMetric: 16.6924

Epoch 122: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4377 - MinusLogProbMetric: 16.4377 - val_loss: 16.6924 - val_MinusLogProbMetric: 16.6924 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 123/1000
2023-09-12 16:19:24.828 
Epoch 123/1000 
	 loss: 16.4468, MinusLogProbMetric: 16.4468, val_loss: 16.7009, val_MinusLogProbMetric: 16.7009

Epoch 123: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4468 - MinusLogProbMetric: 16.4468 - val_loss: 16.7009 - val_MinusLogProbMetric: 16.7009 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 124/1000
2023-09-12 16:19:36.148 
Epoch 124/1000 
	 loss: 16.4419, MinusLogProbMetric: 16.4419, val_loss: 16.7002, val_MinusLogProbMetric: 16.7002

Epoch 124: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4419 - MinusLogProbMetric: 16.4419 - val_loss: 16.7002 - val_MinusLogProbMetric: 16.7002 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 125/1000
2023-09-12 16:19:47.634 
Epoch 125/1000 
	 loss: 16.4412, MinusLogProbMetric: 16.4412, val_loss: 16.7382, val_MinusLogProbMetric: 16.7382

Epoch 125: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4412 - MinusLogProbMetric: 16.4412 - val_loss: 16.7382 - val_MinusLogProbMetric: 16.7382 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 126/1000
2023-09-12 16:19:59.053 
Epoch 126/1000 
	 loss: 16.4349, MinusLogProbMetric: 16.4349, val_loss: 16.6695, val_MinusLogProbMetric: 16.6695

Epoch 126: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4349 - MinusLogProbMetric: 16.4349 - val_loss: 16.6695 - val_MinusLogProbMetric: 16.6695 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 127/1000
2023-09-12 16:20:10.447 
Epoch 127/1000 
	 loss: 16.4380, MinusLogProbMetric: 16.4380, val_loss: 16.6956, val_MinusLogProbMetric: 16.6956

Epoch 127: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4380 - MinusLogProbMetric: 16.4380 - val_loss: 16.6956 - val_MinusLogProbMetric: 16.6956 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 128/1000
2023-09-12 16:20:21.728 
Epoch 128/1000 
	 loss: 16.4404, MinusLogProbMetric: 16.4404, val_loss: 16.7338, val_MinusLogProbMetric: 16.7338

Epoch 128: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4404 - MinusLogProbMetric: 16.4404 - val_loss: 16.7338 - val_MinusLogProbMetric: 16.7338 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 129/1000
2023-09-12 16:20:33.090 
Epoch 129/1000 
	 loss: 16.4424, MinusLogProbMetric: 16.4424, val_loss: 16.7571, val_MinusLogProbMetric: 16.7571

Epoch 129: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4424 - MinusLogProbMetric: 16.4424 - val_loss: 16.7571 - val_MinusLogProbMetric: 16.7571 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 130/1000
2023-09-12 16:20:44.340 
Epoch 130/1000 
	 loss: 16.4298, MinusLogProbMetric: 16.4298, val_loss: 16.6952, val_MinusLogProbMetric: 16.6952

Epoch 130: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4298 - MinusLogProbMetric: 16.4298 - val_loss: 16.6952 - val_MinusLogProbMetric: 16.6952 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 131/1000
2023-09-12 16:20:55.715 
Epoch 131/1000 
	 loss: 16.4273, MinusLogProbMetric: 16.4273, val_loss: 16.7442, val_MinusLogProbMetric: 16.7442

Epoch 131: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4273 - MinusLogProbMetric: 16.4273 - val_loss: 16.7442 - val_MinusLogProbMetric: 16.7442 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 132/1000
2023-09-12 16:21:07.018 
Epoch 132/1000 
	 loss: 16.4255, MinusLogProbMetric: 16.4255, val_loss: 16.7191, val_MinusLogProbMetric: 16.7191

Epoch 132: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4255 - MinusLogProbMetric: 16.4255 - val_loss: 16.7191 - val_MinusLogProbMetric: 16.7191 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 133/1000
2023-09-12 16:21:18.287 
Epoch 133/1000 
	 loss: 16.4317, MinusLogProbMetric: 16.4317, val_loss: 16.7514, val_MinusLogProbMetric: 16.7514

Epoch 133: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4317 - MinusLogProbMetric: 16.4317 - val_loss: 16.7514 - val_MinusLogProbMetric: 16.7514 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 134/1000
2023-09-12 16:21:29.647 
Epoch 134/1000 
	 loss: 16.4306, MinusLogProbMetric: 16.4306, val_loss: 16.6945, val_MinusLogProbMetric: 16.6945

Epoch 134: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4306 - MinusLogProbMetric: 16.4306 - val_loss: 16.6945 - val_MinusLogProbMetric: 16.6945 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 135/1000
2023-09-12 16:21:40.963 
Epoch 135/1000 
	 loss: 16.4241, MinusLogProbMetric: 16.4241, val_loss: 16.7503, val_MinusLogProbMetric: 16.7503

Epoch 135: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4241 - MinusLogProbMetric: 16.4241 - val_loss: 16.7503 - val_MinusLogProbMetric: 16.7503 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 136/1000
2023-09-12 16:21:52.245 
Epoch 136/1000 
	 loss: 16.4256, MinusLogProbMetric: 16.4256, val_loss: 16.7372, val_MinusLogProbMetric: 16.7372

Epoch 136: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4256 - MinusLogProbMetric: 16.4256 - val_loss: 16.7372 - val_MinusLogProbMetric: 16.7372 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 137/1000
2023-09-12 16:22:03.559 
Epoch 137/1000 
	 loss: 16.4275, MinusLogProbMetric: 16.4275, val_loss: 16.7103, val_MinusLogProbMetric: 16.7103

Epoch 137: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4275 - MinusLogProbMetric: 16.4275 - val_loss: 16.7103 - val_MinusLogProbMetric: 16.7103 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 138/1000
2023-09-12 16:22:14.858 
Epoch 138/1000 
	 loss: 16.4247, MinusLogProbMetric: 16.4247, val_loss: 16.7201, val_MinusLogProbMetric: 16.7201

Epoch 138: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4247 - MinusLogProbMetric: 16.4247 - val_loss: 16.7201 - val_MinusLogProbMetric: 16.7201 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 139/1000
2023-09-12 16:22:26.252 
Epoch 139/1000 
	 loss: 16.4297, MinusLogProbMetric: 16.4297, val_loss: 16.7362, val_MinusLogProbMetric: 16.7362

Epoch 139: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4297 - MinusLogProbMetric: 16.4297 - val_loss: 16.7362 - val_MinusLogProbMetric: 16.7362 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 140/1000
2023-09-12 16:22:37.531 
Epoch 140/1000 
	 loss: 16.4227, MinusLogProbMetric: 16.4227, val_loss: 16.7482, val_MinusLogProbMetric: 16.7482

Epoch 140: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4227 - MinusLogProbMetric: 16.4227 - val_loss: 16.7482 - val_MinusLogProbMetric: 16.7482 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 141/1000
2023-09-12 16:22:48.913 
Epoch 141/1000 
	 loss: 16.4211, MinusLogProbMetric: 16.4211, val_loss: 16.7355, val_MinusLogProbMetric: 16.7355

Epoch 141: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4211 - MinusLogProbMetric: 16.4211 - val_loss: 16.7355 - val_MinusLogProbMetric: 16.7355 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 142/1000
2023-09-12 16:23:00.264 
Epoch 142/1000 
	 loss: 16.4203, MinusLogProbMetric: 16.4203, val_loss: 16.7201, val_MinusLogProbMetric: 16.7201

Epoch 142: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4203 - MinusLogProbMetric: 16.4203 - val_loss: 16.7201 - val_MinusLogProbMetric: 16.7201 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 143/1000
2023-09-12 16:23:11.556 
Epoch 143/1000 
	 loss: 16.4225, MinusLogProbMetric: 16.4225, val_loss: 16.7240, val_MinusLogProbMetric: 16.7240

Epoch 143: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4225 - MinusLogProbMetric: 16.4225 - val_loss: 16.7240 - val_MinusLogProbMetric: 16.7240 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-12 16:23:22.797 
Epoch 144/1000 
	 loss: 16.4210, MinusLogProbMetric: 16.4210, val_loss: 16.7281, val_MinusLogProbMetric: 16.7281

Epoch 144: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4210 - MinusLogProbMetric: 16.4210 - val_loss: 16.7281 - val_MinusLogProbMetric: 16.7281 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 145/1000
2023-09-12 16:23:34.062 
Epoch 145/1000 
	 loss: 16.4146, MinusLogProbMetric: 16.4146, val_loss: 16.7101, val_MinusLogProbMetric: 16.7101

Epoch 145: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4146 - MinusLogProbMetric: 16.4146 - val_loss: 16.7101 - val_MinusLogProbMetric: 16.7101 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 146/1000
2023-09-12 16:23:45.458 
Epoch 146/1000 
	 loss: 16.4133, MinusLogProbMetric: 16.4133, val_loss: 16.7485, val_MinusLogProbMetric: 16.7485

Epoch 146: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4133 - MinusLogProbMetric: 16.4133 - val_loss: 16.7485 - val_MinusLogProbMetric: 16.7485 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-12 16:23:56.744 
Epoch 147/1000 
	 loss: 16.4215, MinusLogProbMetric: 16.4215, val_loss: 16.8034, val_MinusLogProbMetric: 16.8034

Epoch 147: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4215 - MinusLogProbMetric: 16.4215 - val_loss: 16.8034 - val_MinusLogProbMetric: 16.8034 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 148/1000
2023-09-12 16:24:08.104 
Epoch 148/1000 
	 loss: 16.4151, MinusLogProbMetric: 16.4151, val_loss: 16.7339, val_MinusLogProbMetric: 16.7339

Epoch 148: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4151 - MinusLogProbMetric: 16.4151 - val_loss: 16.7339 - val_MinusLogProbMetric: 16.7339 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 149/1000
2023-09-12 16:24:19.326 
Epoch 149/1000 
	 loss: 16.4248, MinusLogProbMetric: 16.4248, val_loss: 16.7302, val_MinusLogProbMetric: 16.7302

Epoch 149: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4248 - MinusLogProbMetric: 16.4248 - val_loss: 16.7302 - val_MinusLogProbMetric: 16.7302 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 150/1000
2023-09-12 16:24:30.754 
Epoch 150/1000 
	 loss: 16.4141, MinusLogProbMetric: 16.4141, val_loss: 16.7380, val_MinusLogProbMetric: 16.7380

Epoch 150: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4141 - MinusLogProbMetric: 16.4141 - val_loss: 16.7380 - val_MinusLogProbMetric: 16.7380 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 151/1000
2023-09-12 16:24:42.119 
Epoch 151/1000 
	 loss: 16.4193, MinusLogProbMetric: 16.4193, val_loss: 16.7307, val_MinusLogProbMetric: 16.7307

Epoch 151: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4193 - MinusLogProbMetric: 16.4193 - val_loss: 16.7307 - val_MinusLogProbMetric: 16.7307 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 152/1000
2023-09-12 16:24:53.389 
Epoch 152/1000 
	 loss: 16.4111, MinusLogProbMetric: 16.4111, val_loss: 16.7283, val_MinusLogProbMetric: 16.7283

Epoch 152: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4111 - MinusLogProbMetric: 16.4111 - val_loss: 16.7283 - val_MinusLogProbMetric: 16.7283 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 153/1000
2023-09-12 16:25:04.655 
Epoch 153/1000 
	 loss: 16.4132, MinusLogProbMetric: 16.4132, val_loss: 16.7257, val_MinusLogProbMetric: 16.7257

Epoch 153: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4132 - MinusLogProbMetric: 16.4132 - val_loss: 16.7257 - val_MinusLogProbMetric: 16.7257 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 154/1000
2023-09-12 16:25:15.934 
Epoch 154/1000 
	 loss: 16.4121, MinusLogProbMetric: 16.4121, val_loss: 16.7370, val_MinusLogProbMetric: 16.7370

Epoch 154: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4121 - MinusLogProbMetric: 16.4121 - val_loss: 16.7370 - val_MinusLogProbMetric: 16.7370 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 155/1000
2023-09-12 16:25:27.278 
Epoch 155/1000 
	 loss: 16.4091, MinusLogProbMetric: 16.4091, val_loss: 16.7641, val_MinusLogProbMetric: 16.7641

Epoch 155: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4091 - MinusLogProbMetric: 16.4091 - val_loss: 16.7641 - val_MinusLogProbMetric: 16.7641 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 156/1000
2023-09-12 16:25:38.584 
Epoch 156/1000 
	 loss: 16.4151, MinusLogProbMetric: 16.4151, val_loss: 16.7400, val_MinusLogProbMetric: 16.7400

Epoch 156: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4151 - MinusLogProbMetric: 16.4151 - val_loss: 16.7400 - val_MinusLogProbMetric: 16.7400 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 157/1000
2023-09-12 16:25:49.710 
Epoch 157/1000 
	 loss: 16.4068, MinusLogProbMetric: 16.4068, val_loss: 16.7583, val_MinusLogProbMetric: 16.7583

Epoch 157: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4068 - MinusLogProbMetric: 16.4068 - val_loss: 16.7583 - val_MinusLogProbMetric: 16.7583 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 158/1000
2023-09-12 16:26:00.977 
Epoch 158/1000 
	 loss: 16.4025, MinusLogProbMetric: 16.4025, val_loss: 16.7420, val_MinusLogProbMetric: 16.7420

Epoch 158: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4025 - MinusLogProbMetric: 16.4025 - val_loss: 16.7420 - val_MinusLogProbMetric: 16.7420 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 159/1000
2023-09-12 16:26:12.122 
Epoch 159/1000 
	 loss: 16.4057, MinusLogProbMetric: 16.4057, val_loss: 16.7305, val_MinusLogProbMetric: 16.7305

Epoch 159: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4057 - MinusLogProbMetric: 16.4057 - val_loss: 16.7305 - val_MinusLogProbMetric: 16.7305 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 160/1000
2023-09-12 16:26:23.397 
Epoch 160/1000 
	 loss: 16.3988, MinusLogProbMetric: 16.3988, val_loss: 16.7328, val_MinusLogProbMetric: 16.7328

Epoch 160: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.3988 - MinusLogProbMetric: 16.3988 - val_loss: 16.7328 - val_MinusLogProbMetric: 16.7328 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 161/1000
2023-09-12 16:26:34.648 
Epoch 161/1000 
	 loss: 16.4063, MinusLogProbMetric: 16.4063, val_loss: 16.7618, val_MinusLogProbMetric: 16.7618

Epoch 161: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4063 - MinusLogProbMetric: 16.4063 - val_loss: 16.7618 - val_MinusLogProbMetric: 16.7618 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 162/1000
2023-09-12 16:26:45.917 
Epoch 162/1000 
	 loss: 16.3963, MinusLogProbMetric: 16.3963, val_loss: 16.7529, val_MinusLogProbMetric: 16.7529

Epoch 162: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.3963 - MinusLogProbMetric: 16.3963 - val_loss: 16.7529 - val_MinusLogProbMetric: 16.7529 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 163/1000
2023-09-12 16:26:57.269 
Epoch 163/1000 
	 loss: 16.4036, MinusLogProbMetric: 16.4036, val_loss: 16.7587, val_MinusLogProbMetric: 16.7587

Epoch 163: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4036 - MinusLogProbMetric: 16.4036 - val_loss: 16.7587 - val_MinusLogProbMetric: 16.7587 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 164/1000
2023-09-12 16:27:08.477 
Epoch 164/1000 
	 loss: 16.3979, MinusLogProbMetric: 16.3979, val_loss: 16.7399, val_MinusLogProbMetric: 16.7399

Epoch 164: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.3979 - MinusLogProbMetric: 16.3979 - val_loss: 16.7399 - val_MinusLogProbMetric: 16.7399 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 165/1000
2023-09-12 16:27:19.784 
Epoch 165/1000 
	 loss: 16.4021, MinusLogProbMetric: 16.4021, val_loss: 16.7403, val_MinusLogProbMetric: 16.7403

Epoch 165: val_loss did not improve from 16.65912
196/196 - 11s - loss: 16.4021 - MinusLogProbMetric: 16.4021 - val_loss: 16.7403 - val_MinusLogProbMetric: 16.7403 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 166/1000
2023-09-12 16:27:31.064 
Epoch 166/1000 
	 loss: 16.3977, MinusLogProbMetric: 16.3977, val_loss: 16.7575, val_MinusLogProbMetric: 16.7575

Epoch 166: val_loss did not improve from 16.65912
Restoring model weights from the end of the best epoch: 66.
196/196 - 11s - loss: 16.3977 - MinusLogProbMetric: 16.3977 - val_loss: 16.7575 - val_MinusLogProbMetric: 16.7575 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 166: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 7.550272434018552 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.146244181087241 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.379272738005966 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.7572984480066225 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 926.
Model trained in 1842.07 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Metrics computed in 308.70 s.
Plots done in 143.10 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 451.81 s.
===========
Run 154/360 done in 2295.32 s.
===========

Directory ../../results/MsplineN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

===========
Generating train data for run 158.
===========
Train data generated in 0.29 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 32)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_158/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 933}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_158/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[2.7429588 , 2.5700626 , 7.723717  , ..., 7.7501717 , 2.9186718 ,
        1.775845  ],
       [4.728784  , 6.065677  , 0.9645814 , ..., 1.2628946 , 6.7253027 ,
        1.4381479 ],
       [3.8513129 , 6.1744533 , 0.2601294 , ..., 1.1662469 , 6.572044  ,
        1.3500103 ],
       ...,
       [2.8332918 , 4.2526407 , 9.701975  , ..., 7.0738525 , 2.5952196 ,
        1.8190176 ],
       [3.118363  , 5.4312434 , 0.32481733, ..., 1.9350358 , 6.6219816 ,
        1.3230293 ],
       [1.792576  , 4.9344916 , 9.207544  , ..., 7.378074  , 2.857349  ,
        1.56005   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[32], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_158/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_158
self.data_kwargs: {'seed': 933}
self.x_data: [[4.6118093  6.294248   0.6753535  ... 1.3966799  6.5528636  1.404321  ]
 [5.0913153  7.181254   5.302016   ... 4.927679   2.6276157  7.5562596 ]
 [2.3468595  3.6813745  8.449473   ... 7.5625257  2.3049273  1.7164713 ]
 ...
 [1.7774892  4.58926    7.003348   ... 7.297376   3.211844   1.3889377 ]
 [5.1396513  5.5684643  1.4578001  ... 0.69219434 6.9603205  1.3834548 ]
 [3.2499232  3.5331872  8.207085   ... 6.760554   3.3946218  2.0297966 ]]
self.y_data: []
self.ndims: 32
Model defined.
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_64 (InputLayer)       [(None, 32)]              0         
                                                                 
 log_prob_layer_21 (LogProbL  (None,)                  658368    
 ayer)                                                           
                                                                 
=================================================================
Total params: 658,368
Trainable params: 658,368
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_21/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_21'")
self.model: <keras.engine.functional.Functional object at 0x7fc10040be50>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc100246380>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc100246380>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc100246c50>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc100247700>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc100247c70>, <keras.callbacks.ModelCheckpoint object at 0x7fc100247d30>, <keras.callbacks.EarlyStopping object at 0x7fc100247fa0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc100247fd0>, <keras.callbacks.TerminateOnNaN object at 0x7fc100247c10>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[2.7429588 , 2.5700626 , 7.723717  , ..., 7.7501717 , 2.9186718 ,
        1.775845  ],
       [4.728784  , 6.065677  , 0.9645814 , ..., 1.2628946 , 6.7253027 ,
        1.4381479 ],
       [3.8513129 , 6.1744533 , 0.2601294 , ..., 1.1662469 , 6.572044  ,
        1.3500103 ],
       ...,
       [2.8332918 , 4.2526407 , 9.701975  , ..., 7.0738525 , 2.5952196 ,
        1.8190176 ],
       [3.118363  , 5.4312434 , 0.32481733, ..., 1.9350358 , 6.6219816 ,
        1.3230293 ],
       [1.792576  , 4.9344916 , 9.207544  , ..., 7.378074  , 2.857349  ,
        1.56005   ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_158/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 158/360 with hyperparameters:
timestamp = 2023-09-12 16:35:04.635543
ndims = 32
seed_train = 933
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 658368
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 4.6118093   6.294248    0.6753535   5.561676    6.128757    6.145322
  9.785121    7.1052794   3.7474928   5.3494825   6.3791265   0.5788075
  5.683702    6.3188157   1.6447939   1.0492666   3.6812766   3.7191741
  5.81123     3.2186081  10.359394    0.68370855  2.036205    1.0944312
  6.489696    3.6441135   4.6169076   1.7655768   1.5199437   1.3966799
  6.5528636   1.404321  ]
Epoch 1/1000
2023-09-12 16:35:41.873 
Epoch 1/1000 
	 loss: 43.7667, MinusLogProbMetric: 43.7667, val_loss: 20.9751, val_MinusLogProbMetric: 20.9751

Epoch 1: val_loss improved from inf to 20.97505, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 37s - loss: 43.7667 - MinusLogProbMetric: 43.7667 - val_loss: 20.9751 - val_MinusLogProbMetric: 20.9751 - lr: 0.0010 - 37s/epoch - 190ms/step
Epoch 2/1000
2023-09-12 16:35:53.717 
Epoch 2/1000 
	 loss: 19.5981, MinusLogProbMetric: 19.5981, val_loss: 18.9371, val_MinusLogProbMetric: 18.9371

Epoch 2: val_loss improved from 20.97505 to 18.93707, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 19.5981 - MinusLogProbMetric: 19.5981 - val_loss: 18.9371 - val_MinusLogProbMetric: 18.9371 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 3/1000
2023-09-12 16:36:05.470 
Epoch 3/1000 
	 loss: 18.3366, MinusLogProbMetric: 18.3366, val_loss: 18.0645, val_MinusLogProbMetric: 18.0645

Epoch 3: val_loss improved from 18.93707 to 18.06450, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 18.3366 - MinusLogProbMetric: 18.3366 - val_loss: 18.0645 - val_MinusLogProbMetric: 18.0645 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-12 16:36:17.238 
Epoch 4/1000 
	 loss: 17.9812, MinusLogProbMetric: 17.9812, val_loss: 17.6348, val_MinusLogProbMetric: 17.6348

Epoch 4: val_loss improved from 18.06450 to 17.63485, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 17.9812 - MinusLogProbMetric: 17.9812 - val_loss: 17.6348 - val_MinusLogProbMetric: 17.6348 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-12 16:36:28.977 
Epoch 5/1000 
	 loss: 17.7443, MinusLogProbMetric: 17.7443, val_loss: 18.0530, val_MinusLogProbMetric: 18.0530

Epoch 5: val_loss did not improve from 17.63485
196/196 - 12s - loss: 17.7443 - MinusLogProbMetric: 17.7443 - val_loss: 18.0530 - val_MinusLogProbMetric: 18.0530 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 6/1000
2023-09-12 16:36:40.562 
Epoch 6/1000 
	 loss: 17.5815, MinusLogProbMetric: 17.5815, val_loss: 17.4324, val_MinusLogProbMetric: 17.4324

Epoch 6: val_loss improved from 17.63485 to 17.43237, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 17.5815 - MinusLogProbMetric: 17.5815 - val_loss: 17.4324 - val_MinusLogProbMetric: 17.4324 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-12 16:36:52.279 
Epoch 7/1000 
	 loss: 17.4123, MinusLogProbMetric: 17.4123, val_loss: 17.4633, val_MinusLogProbMetric: 17.4633

Epoch 7: val_loss did not improve from 17.43237
196/196 - 12s - loss: 17.4123 - MinusLogProbMetric: 17.4123 - val_loss: 17.4633 - val_MinusLogProbMetric: 17.4633 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 8/1000
2023-09-12 16:37:03.903 
Epoch 8/1000 
	 loss: 17.3658, MinusLogProbMetric: 17.3658, val_loss: 18.0108, val_MinusLogProbMetric: 18.0108

Epoch 8: val_loss did not improve from 17.43237
196/196 - 12s - loss: 17.3658 - MinusLogProbMetric: 17.3658 - val_loss: 18.0108 - val_MinusLogProbMetric: 18.0108 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 9/1000
2023-09-12 16:37:15.649 
Epoch 9/1000 
	 loss: 17.2091, MinusLogProbMetric: 17.2091, val_loss: 17.1602, val_MinusLogProbMetric: 17.1602

Epoch 9: val_loss improved from 17.43237 to 17.16025, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 17.2091 - MinusLogProbMetric: 17.2091 - val_loss: 17.1602 - val_MinusLogProbMetric: 17.1602 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-12 16:37:27.262 
Epoch 10/1000 
	 loss: 17.1760, MinusLogProbMetric: 17.1760, val_loss: 17.1456, val_MinusLogProbMetric: 17.1456

Epoch 10: val_loss improved from 17.16025 to 17.14564, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 17.1760 - MinusLogProbMetric: 17.1760 - val_loss: 17.1456 - val_MinusLogProbMetric: 17.1456 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 11/1000
2023-09-12 16:37:38.977 
Epoch 11/1000 
	 loss: 17.1353, MinusLogProbMetric: 17.1353, val_loss: 17.0982, val_MinusLogProbMetric: 17.0982

Epoch 11: val_loss improved from 17.14564 to 17.09823, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 17.1353 - MinusLogProbMetric: 17.1353 - val_loss: 17.0982 - val_MinusLogProbMetric: 17.0982 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 12/1000
2023-09-12 16:37:50.597 
Epoch 12/1000 
	 loss: 17.1796, MinusLogProbMetric: 17.1796, val_loss: 17.2032, val_MinusLogProbMetric: 17.2032

Epoch 12: val_loss did not improve from 17.09823
196/196 - 11s - loss: 17.1796 - MinusLogProbMetric: 17.1796 - val_loss: 17.2032 - val_MinusLogProbMetric: 17.2032 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 13/1000
2023-09-12 16:38:02.039 
Epoch 13/1000 
	 loss: 17.0363, MinusLogProbMetric: 17.0363, val_loss: 17.2892, val_MinusLogProbMetric: 17.2892

Epoch 13: val_loss did not improve from 17.09823
196/196 - 11s - loss: 17.0363 - MinusLogProbMetric: 17.0363 - val_loss: 17.2892 - val_MinusLogProbMetric: 17.2892 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 14/1000
2023-09-12 16:38:13.583 
Epoch 14/1000 
	 loss: 17.0820, MinusLogProbMetric: 17.0820, val_loss: 17.3726, val_MinusLogProbMetric: 17.3726

Epoch 14: val_loss did not improve from 17.09823
196/196 - 12s - loss: 17.0820 - MinusLogProbMetric: 17.0820 - val_loss: 17.3726 - val_MinusLogProbMetric: 17.3726 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-12 16:38:25.056 
Epoch 15/1000 
	 loss: 16.9823, MinusLogProbMetric: 16.9823, val_loss: 17.0255, val_MinusLogProbMetric: 17.0255

Epoch 15: val_loss improved from 17.09823 to 17.02551, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 16.9823 - MinusLogProbMetric: 16.9823 - val_loss: 17.0255 - val_MinusLogProbMetric: 17.0255 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 16/1000
2023-09-12 16:38:36.656 
Epoch 16/1000 
	 loss: 17.0142, MinusLogProbMetric: 17.0142, val_loss: 17.0203, val_MinusLogProbMetric: 17.0203

Epoch 16: val_loss improved from 17.02551 to 17.02028, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 17.0142 - MinusLogProbMetric: 17.0142 - val_loss: 17.0203 - val_MinusLogProbMetric: 17.0203 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 17/1000
2023-09-12 16:38:48.238 
Epoch 17/1000 
	 loss: 16.9866, MinusLogProbMetric: 16.9866, val_loss: 17.3570, val_MinusLogProbMetric: 17.3570

Epoch 17: val_loss did not improve from 17.02028
196/196 - 11s - loss: 16.9866 - MinusLogProbMetric: 16.9866 - val_loss: 17.3570 - val_MinusLogProbMetric: 17.3570 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 18/1000
2023-09-12 16:38:59.743 
Epoch 18/1000 
	 loss: 16.9317, MinusLogProbMetric: 16.9317, val_loss: 17.1425, val_MinusLogProbMetric: 17.1425

Epoch 18: val_loss did not improve from 17.02028
196/196 - 11s - loss: 16.9317 - MinusLogProbMetric: 16.9317 - val_loss: 17.1425 - val_MinusLogProbMetric: 17.1425 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 19/1000
2023-09-12 16:39:11.340 
Epoch 19/1000 
	 loss: 16.9267, MinusLogProbMetric: 16.9267, val_loss: 17.0455, val_MinusLogProbMetric: 17.0455

Epoch 19: val_loss did not improve from 17.02028
196/196 - 12s - loss: 16.9267 - MinusLogProbMetric: 16.9267 - val_loss: 17.0455 - val_MinusLogProbMetric: 17.0455 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 20/1000
2023-09-12 16:39:22.811 
Epoch 20/1000 
	 loss: 16.9488, MinusLogProbMetric: 16.9488, val_loss: 16.9560, val_MinusLogProbMetric: 16.9560

Epoch 20: val_loss improved from 17.02028 to 16.95599, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 16.9488 - MinusLogProbMetric: 16.9488 - val_loss: 16.9560 - val_MinusLogProbMetric: 16.9560 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 16:39:34.412 
Epoch 21/1000 
	 loss: 16.8788, MinusLogProbMetric: 16.8788, val_loss: 16.8768, val_MinusLogProbMetric: 16.8768

Epoch 21: val_loss improved from 16.95599 to 16.87680, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 16.8788 - MinusLogProbMetric: 16.8788 - val_loss: 16.8768 - val_MinusLogProbMetric: 16.8768 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 22/1000
2023-09-12 16:39:46.039 
Epoch 22/1000 
	 loss: 16.8753, MinusLogProbMetric: 16.8753, val_loss: 16.9966, val_MinusLogProbMetric: 16.9966

Epoch 22: val_loss did not improve from 16.87680
196/196 - 12s - loss: 16.8753 - MinusLogProbMetric: 16.8753 - val_loss: 16.9966 - val_MinusLogProbMetric: 16.9966 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 23/1000
2023-09-12 16:39:57.593 
Epoch 23/1000 
	 loss: 16.8779, MinusLogProbMetric: 16.8779, val_loss: 16.9489, val_MinusLogProbMetric: 16.9489

Epoch 23: val_loss did not improve from 16.87680
196/196 - 12s - loss: 16.8779 - MinusLogProbMetric: 16.8779 - val_loss: 16.9489 - val_MinusLogProbMetric: 16.9489 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 24/1000
2023-09-12 16:40:09.155 
Epoch 24/1000 
	 loss: 16.8830, MinusLogProbMetric: 16.8830, val_loss: 16.9681, val_MinusLogProbMetric: 16.9681

Epoch 24: val_loss did not improve from 16.87680
196/196 - 12s - loss: 16.8830 - MinusLogProbMetric: 16.8830 - val_loss: 16.9681 - val_MinusLogProbMetric: 16.9681 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 25/1000
2023-09-12 16:40:20.610 
Epoch 25/1000 
	 loss: 16.8832, MinusLogProbMetric: 16.8832, val_loss: 17.0507, val_MinusLogProbMetric: 17.0507

Epoch 25: val_loss did not improve from 16.87680
196/196 - 11s - loss: 16.8832 - MinusLogProbMetric: 16.8832 - val_loss: 17.0507 - val_MinusLogProbMetric: 17.0507 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 26/1000
2023-09-12 16:40:32.072 
Epoch 26/1000 
	 loss: 16.8206, MinusLogProbMetric: 16.8206, val_loss: 17.0957, val_MinusLogProbMetric: 17.0957

Epoch 26: val_loss did not improve from 16.87680
196/196 - 11s - loss: 16.8206 - MinusLogProbMetric: 16.8206 - val_loss: 17.0957 - val_MinusLogProbMetric: 17.0957 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 27/1000
2023-09-12 16:40:43.476 
Epoch 27/1000 
	 loss: 16.8570, MinusLogProbMetric: 16.8570, val_loss: 16.8765, val_MinusLogProbMetric: 16.8765

Epoch 27: val_loss improved from 16.87680 to 16.87652, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 16.8570 - MinusLogProbMetric: 16.8570 - val_loss: 16.8765 - val_MinusLogProbMetric: 16.8765 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 28/1000
2023-09-12 16:40:55.227 
Epoch 28/1000 
	 loss: 16.8173, MinusLogProbMetric: 16.8173, val_loss: 16.8508, val_MinusLogProbMetric: 16.8508

Epoch 28: val_loss improved from 16.87652 to 16.85085, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 16.8173 - MinusLogProbMetric: 16.8173 - val_loss: 16.8508 - val_MinusLogProbMetric: 16.8508 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 29/1000
2023-09-12 16:41:06.688 
Epoch 29/1000 
	 loss: 16.8091, MinusLogProbMetric: 16.8091, val_loss: 17.0231, val_MinusLogProbMetric: 17.0231

Epoch 29: val_loss did not improve from 16.85085
196/196 - 11s - loss: 16.8091 - MinusLogProbMetric: 16.8091 - val_loss: 17.0231 - val_MinusLogProbMetric: 17.0231 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 30/1000
2023-09-12 16:41:18.004 
Epoch 30/1000 
	 loss: 16.7975, MinusLogProbMetric: 16.7975, val_loss: 16.8498, val_MinusLogProbMetric: 16.8498

Epoch 30: val_loss improved from 16.85085 to 16.84982, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 11s - loss: 16.7975 - MinusLogProbMetric: 16.7975 - val_loss: 16.8498 - val_MinusLogProbMetric: 16.8498 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 31/1000
2023-09-12 16:41:28.823 
Epoch 31/1000 
	 loss: 16.8208, MinusLogProbMetric: 16.8208, val_loss: 16.9385, val_MinusLogProbMetric: 16.9385

Epoch 31: val_loss did not improve from 16.84982
196/196 - 11s - loss: 16.8208 - MinusLogProbMetric: 16.8208 - val_loss: 16.9385 - val_MinusLogProbMetric: 16.9385 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 32/1000
2023-09-12 16:41:39.792 
Epoch 32/1000 
	 loss: 16.7842, MinusLogProbMetric: 16.7842, val_loss: 16.7276, val_MinusLogProbMetric: 16.7276

Epoch 32: val_loss improved from 16.84982 to 16.72756, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 11s - loss: 16.7842 - MinusLogProbMetric: 16.7842 - val_loss: 16.7276 - val_MinusLogProbMetric: 16.7276 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 33/1000
2023-09-12 16:41:51.007 
Epoch 33/1000 
	 loss: 16.7704, MinusLogProbMetric: 16.7704, val_loss: 16.9387, val_MinusLogProbMetric: 16.9387

Epoch 33: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7704 - MinusLogProbMetric: 16.7704 - val_loss: 16.9387 - val_MinusLogProbMetric: 16.9387 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 34/1000
2023-09-12 16:42:02.330 
Epoch 34/1000 
	 loss: 16.7723, MinusLogProbMetric: 16.7723, val_loss: 16.7979, val_MinusLogProbMetric: 16.7979

Epoch 34: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7723 - MinusLogProbMetric: 16.7723 - val_loss: 16.7979 - val_MinusLogProbMetric: 16.7979 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 35/1000
2023-09-12 16:42:12.633 
Epoch 35/1000 
	 loss: 16.7567, MinusLogProbMetric: 16.7567, val_loss: 16.8946, val_MinusLogProbMetric: 16.8946

Epoch 35: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.7567 - MinusLogProbMetric: 16.7567 - val_loss: 16.8946 - val_MinusLogProbMetric: 16.8946 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 36/1000
2023-09-12 16:42:22.673 
Epoch 36/1000 
	 loss: 16.7907, MinusLogProbMetric: 16.7907, val_loss: 16.8804, val_MinusLogProbMetric: 16.8804

Epoch 36: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.7907 - MinusLogProbMetric: 16.7907 - val_loss: 16.8804 - val_MinusLogProbMetric: 16.8804 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 37/1000
2023-09-12 16:42:33.796 
Epoch 37/1000 
	 loss: 16.7313, MinusLogProbMetric: 16.7313, val_loss: 16.7736, val_MinusLogProbMetric: 16.7736

Epoch 37: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7313 - MinusLogProbMetric: 16.7313 - val_loss: 16.7736 - val_MinusLogProbMetric: 16.7736 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 38/1000
2023-09-12 16:42:44.851 
Epoch 38/1000 
	 loss: 16.7507, MinusLogProbMetric: 16.7507, val_loss: 16.8032, val_MinusLogProbMetric: 16.8032

Epoch 38: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7507 - MinusLogProbMetric: 16.7507 - val_loss: 16.8032 - val_MinusLogProbMetric: 16.8032 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 39/1000
2023-09-12 16:42:56.077 
Epoch 39/1000 
	 loss: 16.7508, MinusLogProbMetric: 16.7508, val_loss: 16.7390, val_MinusLogProbMetric: 16.7390

Epoch 39: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7508 - MinusLogProbMetric: 16.7508 - val_loss: 16.7390 - val_MinusLogProbMetric: 16.7390 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 40/1000
2023-09-12 16:43:06.305 
Epoch 40/1000 
	 loss: 16.7496, MinusLogProbMetric: 16.7496, val_loss: 16.7914, val_MinusLogProbMetric: 16.7914

Epoch 40: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.7496 - MinusLogProbMetric: 16.7496 - val_loss: 16.7914 - val_MinusLogProbMetric: 16.7914 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 41/1000
2023-09-12 16:43:16.106 
Epoch 41/1000 
	 loss: 16.7226, MinusLogProbMetric: 16.7226, val_loss: 16.7954, val_MinusLogProbMetric: 16.7954

Epoch 41: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.7226 - MinusLogProbMetric: 16.7226 - val_loss: 16.7954 - val_MinusLogProbMetric: 16.7954 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 42/1000
2023-09-12 16:43:26.615 
Epoch 42/1000 
	 loss: 16.7286, MinusLogProbMetric: 16.7286, val_loss: 16.7577, val_MinusLogProbMetric: 16.7577

Epoch 42: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7286 - MinusLogProbMetric: 16.7286 - val_loss: 16.7577 - val_MinusLogProbMetric: 16.7577 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 43/1000
2023-09-12 16:43:37.712 
Epoch 43/1000 
	 loss: 16.7217, MinusLogProbMetric: 16.7217, val_loss: 16.7613, val_MinusLogProbMetric: 16.7613

Epoch 43: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7217 - MinusLogProbMetric: 16.7217 - val_loss: 16.7613 - val_MinusLogProbMetric: 16.7613 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 44/1000
2023-09-12 16:43:48.434 
Epoch 44/1000 
	 loss: 16.7275, MinusLogProbMetric: 16.7275, val_loss: 16.7568, val_MinusLogProbMetric: 16.7568

Epoch 44: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7275 - MinusLogProbMetric: 16.7275 - val_loss: 16.7568 - val_MinusLogProbMetric: 16.7568 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 45/1000
2023-09-12 16:43:59.167 
Epoch 45/1000 
	 loss: 16.7293, MinusLogProbMetric: 16.7293, val_loss: 16.7351, val_MinusLogProbMetric: 16.7351

Epoch 45: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7293 - MinusLogProbMetric: 16.7293 - val_loss: 16.7351 - val_MinusLogProbMetric: 16.7351 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 46/1000
2023-09-12 16:44:08.921 
Epoch 46/1000 
	 loss: 16.7132, MinusLogProbMetric: 16.7132, val_loss: 16.8046, val_MinusLogProbMetric: 16.8046

Epoch 46: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.7132 - MinusLogProbMetric: 16.7132 - val_loss: 16.8046 - val_MinusLogProbMetric: 16.8046 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 47/1000
2023-09-12 16:44:19.617 
Epoch 47/1000 
	 loss: 16.7107, MinusLogProbMetric: 16.7107, val_loss: 16.7893, val_MinusLogProbMetric: 16.7893

Epoch 47: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7107 - MinusLogProbMetric: 16.7107 - val_loss: 16.7893 - val_MinusLogProbMetric: 16.7893 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 48/1000
2023-09-12 16:44:29.909 
Epoch 48/1000 
	 loss: 16.7171, MinusLogProbMetric: 16.7171, val_loss: 16.7404, val_MinusLogProbMetric: 16.7404

Epoch 48: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.7171 - MinusLogProbMetric: 16.7171 - val_loss: 16.7404 - val_MinusLogProbMetric: 16.7404 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 49/1000
2023-09-12 16:44:40.485 
Epoch 49/1000 
	 loss: 16.7030, MinusLogProbMetric: 16.7030, val_loss: 16.7360, val_MinusLogProbMetric: 16.7360

Epoch 49: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7030 - MinusLogProbMetric: 16.7030 - val_loss: 16.7360 - val_MinusLogProbMetric: 16.7360 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 50/1000
2023-09-12 16:44:50.421 
Epoch 50/1000 
	 loss: 16.6965, MinusLogProbMetric: 16.6965, val_loss: 16.7989, val_MinusLogProbMetric: 16.7989

Epoch 50: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.6965 - MinusLogProbMetric: 16.6965 - val_loss: 16.7989 - val_MinusLogProbMetric: 16.7989 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 51/1000
2023-09-12 16:45:00.577 
Epoch 51/1000 
	 loss: 16.6981, MinusLogProbMetric: 16.6981, val_loss: 16.7953, val_MinusLogProbMetric: 16.7953

Epoch 51: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.6981 - MinusLogProbMetric: 16.6981 - val_loss: 16.7953 - val_MinusLogProbMetric: 16.7953 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 52/1000
2023-09-12 16:45:10.620 
Epoch 52/1000 
	 loss: 16.7023, MinusLogProbMetric: 16.7023, val_loss: 16.7865, val_MinusLogProbMetric: 16.7865

Epoch 52: val_loss did not improve from 16.72756
196/196 - 10s - loss: 16.7023 - MinusLogProbMetric: 16.7023 - val_loss: 16.7865 - val_MinusLogProbMetric: 16.7865 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 53/1000
2023-09-12 16:45:21.311 
Epoch 53/1000 
	 loss: 16.7176, MinusLogProbMetric: 16.7176, val_loss: 16.7507, val_MinusLogProbMetric: 16.7507

Epoch 53: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.7176 - MinusLogProbMetric: 16.7176 - val_loss: 16.7507 - val_MinusLogProbMetric: 16.7507 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 54/1000
2023-09-12 16:45:32.651 
Epoch 54/1000 
	 loss: 16.6820, MinusLogProbMetric: 16.6820, val_loss: 16.8861, val_MinusLogProbMetric: 16.8861

Epoch 54: val_loss did not improve from 16.72756
196/196 - 11s - loss: 16.6820 - MinusLogProbMetric: 16.6820 - val_loss: 16.8861 - val_MinusLogProbMetric: 16.8861 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 55/1000
2023-09-12 16:45:43.152 
Epoch 55/1000 
	 loss: 16.6872, MinusLogProbMetric: 16.6872, val_loss: 16.7276, val_MinusLogProbMetric: 16.7276

Epoch 55: val_loss improved from 16.72756 to 16.72756, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 11s - loss: 16.6872 - MinusLogProbMetric: 16.6872 - val_loss: 16.7276 - val_MinusLogProbMetric: 16.7276 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 56/1000
2023-09-12 16:45:54.421 
Epoch 56/1000 
	 loss: 16.6725, MinusLogProbMetric: 16.6725, val_loss: 16.7163, val_MinusLogProbMetric: 16.7163

Epoch 56: val_loss improved from 16.72756 to 16.71627, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 11s - loss: 16.6725 - MinusLogProbMetric: 16.6725 - val_loss: 16.7163 - val_MinusLogProbMetric: 16.7163 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 57/1000
2023-09-12 16:46:05.616 
Epoch 57/1000 
	 loss: 16.6775, MinusLogProbMetric: 16.6775, val_loss: 17.5466, val_MinusLogProbMetric: 17.5466

Epoch 57: val_loss did not improve from 16.71627
196/196 - 11s - loss: 16.6775 - MinusLogProbMetric: 16.6775 - val_loss: 17.5466 - val_MinusLogProbMetric: 17.5466 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 58/1000
2023-09-12 16:46:16.449 
Epoch 58/1000 
	 loss: 16.7099, MinusLogProbMetric: 16.7099, val_loss: 16.8223, val_MinusLogProbMetric: 16.8223

Epoch 58: val_loss did not improve from 16.71627
196/196 - 11s - loss: 16.7099 - MinusLogProbMetric: 16.7099 - val_loss: 16.8223 - val_MinusLogProbMetric: 16.8223 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 59/1000
2023-09-12 16:46:26.036 
Epoch 59/1000 
	 loss: 16.6621, MinusLogProbMetric: 16.6621, val_loss: 16.7222, val_MinusLogProbMetric: 16.7222

Epoch 59: val_loss did not improve from 16.71627
196/196 - 10s - loss: 16.6621 - MinusLogProbMetric: 16.6621 - val_loss: 16.7222 - val_MinusLogProbMetric: 16.7222 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 60/1000
2023-09-12 16:46:35.603 
Epoch 60/1000 
	 loss: 16.6786, MinusLogProbMetric: 16.6786, val_loss: 16.7178, val_MinusLogProbMetric: 16.7178

Epoch 60: val_loss did not improve from 16.71627
196/196 - 10s - loss: 16.6786 - MinusLogProbMetric: 16.6786 - val_loss: 16.7178 - val_MinusLogProbMetric: 16.7178 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 61/1000
2023-09-12 16:46:45.182 
Epoch 61/1000 
	 loss: 16.6677, MinusLogProbMetric: 16.6677, val_loss: 16.7228, val_MinusLogProbMetric: 16.7228

Epoch 61: val_loss did not improve from 16.71627
196/196 - 10s - loss: 16.6677 - MinusLogProbMetric: 16.6677 - val_loss: 16.7228 - val_MinusLogProbMetric: 16.7228 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 62/1000
2023-09-12 16:46:54.739 
Epoch 62/1000 
	 loss: 16.6510, MinusLogProbMetric: 16.6510, val_loss: 16.6959, val_MinusLogProbMetric: 16.6959

Epoch 62: val_loss improved from 16.71627 to 16.69592, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 10s - loss: 16.6510 - MinusLogProbMetric: 16.6510 - val_loss: 16.6959 - val_MinusLogProbMetric: 16.6959 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 63/1000
2023-09-12 16:47:04.328 
Epoch 63/1000 
	 loss: 16.6526, MinusLogProbMetric: 16.6526, val_loss: 16.8424, val_MinusLogProbMetric: 16.8424

Epoch 63: val_loss did not improve from 16.69592
196/196 - 9s - loss: 16.6526 - MinusLogProbMetric: 16.6526 - val_loss: 16.8424 - val_MinusLogProbMetric: 16.8424 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 64/1000
2023-09-12 16:47:13.897 
Epoch 64/1000 
	 loss: 16.6581, MinusLogProbMetric: 16.6581, val_loss: 16.7415, val_MinusLogProbMetric: 16.7415

Epoch 64: val_loss did not improve from 16.69592
196/196 - 10s - loss: 16.6581 - MinusLogProbMetric: 16.6581 - val_loss: 16.7415 - val_MinusLogProbMetric: 16.7415 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 65/1000
2023-09-12 16:47:24.316 
Epoch 65/1000 
	 loss: 16.6481, MinusLogProbMetric: 16.6481, val_loss: 16.7934, val_MinusLogProbMetric: 16.7934

Epoch 65: val_loss did not improve from 16.69592
196/196 - 10s - loss: 16.6481 - MinusLogProbMetric: 16.6481 - val_loss: 16.7934 - val_MinusLogProbMetric: 16.7934 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 66/1000
2023-09-12 16:47:35.489 
Epoch 66/1000 
	 loss: 16.6480, MinusLogProbMetric: 16.6480, val_loss: 16.6951, val_MinusLogProbMetric: 16.6951

Epoch 66: val_loss improved from 16.69592 to 16.69506, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 11s - loss: 16.6480 - MinusLogProbMetric: 16.6480 - val_loss: 16.6951 - val_MinusLogProbMetric: 16.6951 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 67/1000
2023-09-12 16:47:45.751 
Epoch 67/1000 
	 loss: 16.6485, MinusLogProbMetric: 16.6485, val_loss: 16.8908, val_MinusLogProbMetric: 16.8908

Epoch 67: val_loss did not improve from 16.69506
196/196 - 10s - loss: 16.6485 - MinusLogProbMetric: 16.6485 - val_loss: 16.8908 - val_MinusLogProbMetric: 16.8908 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 68/1000
2023-09-12 16:47:56.230 
Epoch 68/1000 
	 loss: 16.6604, MinusLogProbMetric: 16.6604, val_loss: 16.8513, val_MinusLogProbMetric: 16.8513

Epoch 68: val_loss did not improve from 16.69506
196/196 - 10s - loss: 16.6604 - MinusLogProbMetric: 16.6604 - val_loss: 16.8513 - val_MinusLogProbMetric: 16.8513 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 69/1000
2023-09-12 16:48:07.490 
Epoch 69/1000 
	 loss: 16.6586, MinusLogProbMetric: 16.6586, val_loss: 16.7213, val_MinusLogProbMetric: 16.7213

Epoch 69: val_loss did not improve from 16.69506
196/196 - 11s - loss: 16.6586 - MinusLogProbMetric: 16.6586 - val_loss: 16.7213 - val_MinusLogProbMetric: 16.7213 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 70/1000
2023-09-12 16:48:17.103 
Epoch 70/1000 
	 loss: 16.6524, MinusLogProbMetric: 16.6524, val_loss: 16.7305, val_MinusLogProbMetric: 16.7305

Epoch 70: val_loss did not improve from 16.69506
196/196 - 10s - loss: 16.6524 - MinusLogProbMetric: 16.6524 - val_loss: 16.7305 - val_MinusLogProbMetric: 16.7305 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 71/1000
2023-09-12 16:48:26.688 
Epoch 71/1000 
	 loss: 16.6408, MinusLogProbMetric: 16.6408, val_loss: 16.7909, val_MinusLogProbMetric: 16.7909

Epoch 71: val_loss did not improve from 16.69506
196/196 - 10s - loss: 16.6408 - MinusLogProbMetric: 16.6408 - val_loss: 16.7909 - val_MinusLogProbMetric: 16.7909 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 72/1000
2023-09-12 16:48:36.299 
Epoch 72/1000 
	 loss: 16.6440, MinusLogProbMetric: 16.6440, val_loss: 16.7148, val_MinusLogProbMetric: 16.7148

Epoch 72: val_loss did not improve from 16.69506
196/196 - 10s - loss: 16.6440 - MinusLogProbMetric: 16.6440 - val_loss: 16.7148 - val_MinusLogProbMetric: 16.7148 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 73/1000
2023-09-12 16:48:46.607 
Epoch 73/1000 
	 loss: 16.6366, MinusLogProbMetric: 16.6366, val_loss: 16.6537, val_MinusLogProbMetric: 16.6537

Epoch 73: val_loss improved from 16.69506 to 16.65375, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 10s - loss: 16.6366 - MinusLogProbMetric: 16.6366 - val_loss: 16.6537 - val_MinusLogProbMetric: 16.6537 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 74/1000
2023-09-12 16:48:56.176 
Epoch 74/1000 
	 loss: 16.6588, MinusLogProbMetric: 16.6588, val_loss: 16.7130, val_MinusLogProbMetric: 16.7130

Epoch 74: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6588 - MinusLogProbMetric: 16.6588 - val_loss: 16.7130 - val_MinusLogProbMetric: 16.7130 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 75/1000
2023-09-12 16:49:05.586 
Epoch 75/1000 
	 loss: 16.6241, MinusLogProbMetric: 16.6241, val_loss: 16.7158, val_MinusLogProbMetric: 16.7158

Epoch 75: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6241 - MinusLogProbMetric: 16.6241 - val_loss: 16.7158 - val_MinusLogProbMetric: 16.7158 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 76/1000
2023-09-12 16:49:14.977 
Epoch 76/1000 
	 loss: 16.6350, MinusLogProbMetric: 16.6350, val_loss: 16.7174, val_MinusLogProbMetric: 16.7174

Epoch 76: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6350 - MinusLogProbMetric: 16.6350 - val_loss: 16.7174 - val_MinusLogProbMetric: 16.7174 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 77/1000
2023-09-12 16:49:24.566 
Epoch 77/1000 
	 loss: 16.6239, MinusLogProbMetric: 16.6239, val_loss: 16.8674, val_MinusLogProbMetric: 16.8674

Epoch 77: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.6239 - MinusLogProbMetric: 16.6239 - val_loss: 16.8674 - val_MinusLogProbMetric: 16.8674 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 78/1000
2023-09-12 16:49:34.177 
Epoch 78/1000 
	 loss: 16.6363, MinusLogProbMetric: 16.6363, val_loss: 16.7403, val_MinusLogProbMetric: 16.7403

Epoch 78: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.6363 - MinusLogProbMetric: 16.6363 - val_loss: 16.7403 - val_MinusLogProbMetric: 16.7403 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 79/1000
2023-09-12 16:49:43.621 
Epoch 79/1000 
	 loss: 16.6276, MinusLogProbMetric: 16.6276, val_loss: 16.7061, val_MinusLogProbMetric: 16.7061

Epoch 79: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6276 - MinusLogProbMetric: 16.6276 - val_loss: 16.7061 - val_MinusLogProbMetric: 16.7061 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 80/1000
2023-09-12 16:49:53.010 
Epoch 80/1000 
	 loss: 16.6204, MinusLogProbMetric: 16.6204, val_loss: 16.7160, val_MinusLogProbMetric: 16.7160

Epoch 80: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6204 - MinusLogProbMetric: 16.6204 - val_loss: 16.7160 - val_MinusLogProbMetric: 16.7160 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 81/1000
2023-09-12 16:50:02.341 
Epoch 81/1000 
	 loss: 16.6315, MinusLogProbMetric: 16.6315, val_loss: 16.7515, val_MinusLogProbMetric: 16.7515

Epoch 81: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6315 - MinusLogProbMetric: 16.6315 - val_loss: 16.7515 - val_MinusLogProbMetric: 16.7515 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 82/1000
2023-09-12 16:50:11.656 
Epoch 82/1000 
	 loss: 16.6128, MinusLogProbMetric: 16.6128, val_loss: 16.7996, val_MinusLogProbMetric: 16.7996

Epoch 82: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6128 - MinusLogProbMetric: 16.6128 - val_loss: 16.7996 - val_MinusLogProbMetric: 16.7996 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 83/1000
2023-09-12 16:50:21.098 
Epoch 83/1000 
	 loss: 16.6346, MinusLogProbMetric: 16.6346, val_loss: 16.6860, val_MinusLogProbMetric: 16.6860

Epoch 83: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6346 - MinusLogProbMetric: 16.6346 - val_loss: 16.6860 - val_MinusLogProbMetric: 16.6860 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 84/1000
2023-09-12 16:50:30.596 
Epoch 84/1000 
	 loss: 16.6132, MinusLogProbMetric: 16.6132, val_loss: 16.7082, val_MinusLogProbMetric: 16.7082

Epoch 84: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6132 - MinusLogProbMetric: 16.6132 - val_loss: 16.7082 - val_MinusLogProbMetric: 16.7082 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 85/1000
2023-09-12 16:50:40.060 
Epoch 85/1000 
	 loss: 16.6176, MinusLogProbMetric: 16.6176, val_loss: 16.8504, val_MinusLogProbMetric: 16.8504

Epoch 85: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6176 - MinusLogProbMetric: 16.6176 - val_loss: 16.8504 - val_MinusLogProbMetric: 16.8504 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 86/1000
2023-09-12 16:50:49.545 
Epoch 86/1000 
	 loss: 16.6153, MinusLogProbMetric: 16.6153, val_loss: 16.8870, val_MinusLogProbMetric: 16.8870

Epoch 86: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6153 - MinusLogProbMetric: 16.6153 - val_loss: 16.8870 - val_MinusLogProbMetric: 16.8870 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 87/1000
2023-09-12 16:50:59.081 
Epoch 87/1000 
	 loss: 16.6085, MinusLogProbMetric: 16.6085, val_loss: 16.7481, val_MinusLogProbMetric: 16.7481

Epoch 87: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.6085 - MinusLogProbMetric: 16.6085 - val_loss: 16.7481 - val_MinusLogProbMetric: 16.7481 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 88/1000
2023-09-12 16:51:08.683 
Epoch 88/1000 
	 loss: 16.6076, MinusLogProbMetric: 16.6076, val_loss: 16.7648, val_MinusLogProbMetric: 16.7648

Epoch 88: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.6076 - MinusLogProbMetric: 16.6076 - val_loss: 16.7648 - val_MinusLogProbMetric: 16.7648 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 89/1000
2023-09-12 16:51:18.220 
Epoch 89/1000 
	 loss: 16.6098, MinusLogProbMetric: 16.6098, val_loss: 16.7132, val_MinusLogProbMetric: 16.7132

Epoch 89: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.6098 - MinusLogProbMetric: 16.6098 - val_loss: 16.7132 - val_MinusLogProbMetric: 16.7132 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 90/1000
2023-09-12 16:51:27.790 
Epoch 90/1000 
	 loss: 16.6110, MinusLogProbMetric: 16.6110, val_loss: 16.6546, val_MinusLogProbMetric: 16.6546

Epoch 90: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.6110 - MinusLogProbMetric: 16.6110 - val_loss: 16.6546 - val_MinusLogProbMetric: 16.6546 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 91/1000
2023-09-12 16:51:37.272 
Epoch 91/1000 
	 loss: 16.5922, MinusLogProbMetric: 16.5922, val_loss: 16.7636, val_MinusLogProbMetric: 16.7636

Epoch 91: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.5922 - MinusLogProbMetric: 16.5922 - val_loss: 16.7636 - val_MinusLogProbMetric: 16.7636 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 92/1000
2023-09-12 16:51:46.737 
Epoch 92/1000 
	 loss: 16.6115, MinusLogProbMetric: 16.6115, val_loss: 16.6859, val_MinusLogProbMetric: 16.6859

Epoch 92: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6115 - MinusLogProbMetric: 16.6115 - val_loss: 16.6859 - val_MinusLogProbMetric: 16.6859 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 93/1000
2023-09-12 16:51:56.208 
Epoch 93/1000 
	 loss: 16.6001, MinusLogProbMetric: 16.6001, val_loss: 16.7227, val_MinusLogProbMetric: 16.7227

Epoch 93: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6001 - MinusLogProbMetric: 16.6001 - val_loss: 16.7227 - val_MinusLogProbMetric: 16.7227 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 94/1000
2023-09-12 16:52:05.726 
Epoch 94/1000 
	 loss: 16.5884, MinusLogProbMetric: 16.5884, val_loss: 16.7007, val_MinusLogProbMetric: 16.7007

Epoch 94: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.5884 - MinusLogProbMetric: 16.5884 - val_loss: 16.7007 - val_MinusLogProbMetric: 16.7007 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 95/1000
2023-09-12 16:52:15.210 
Epoch 95/1000 
	 loss: 16.6099, MinusLogProbMetric: 16.6099, val_loss: 16.7414, val_MinusLogProbMetric: 16.7414

Epoch 95: val_loss did not improve from 16.65375
196/196 - 9s - loss: 16.6099 - MinusLogProbMetric: 16.6099 - val_loss: 16.7414 - val_MinusLogProbMetric: 16.7414 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 96/1000
2023-09-12 16:52:24.727 
Epoch 96/1000 
	 loss: 16.6007, MinusLogProbMetric: 16.6007, val_loss: 16.6669, val_MinusLogProbMetric: 16.6669

Epoch 96: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.6007 - MinusLogProbMetric: 16.6007 - val_loss: 16.6669 - val_MinusLogProbMetric: 16.6669 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 97/1000
2023-09-12 16:52:34.344 
Epoch 97/1000 
	 loss: 16.5770, MinusLogProbMetric: 16.5770, val_loss: 16.7280, val_MinusLogProbMetric: 16.7280

Epoch 97: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.5770 - MinusLogProbMetric: 16.5770 - val_loss: 16.7280 - val_MinusLogProbMetric: 16.7280 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 98/1000
2023-09-12 16:52:44.200 
Epoch 98/1000 
	 loss: 16.5862, MinusLogProbMetric: 16.5862, val_loss: 16.7246, val_MinusLogProbMetric: 16.7246

Epoch 98: val_loss did not improve from 16.65375
196/196 - 10s - loss: 16.5862 - MinusLogProbMetric: 16.5862 - val_loss: 16.7246 - val_MinusLogProbMetric: 16.7246 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 99/1000
2023-09-12 16:52:55.294 
Epoch 99/1000 
	 loss: 16.5945, MinusLogProbMetric: 16.5945, val_loss: 16.7155, val_MinusLogProbMetric: 16.7155

Epoch 99: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5945 - MinusLogProbMetric: 16.5945 - val_loss: 16.7155 - val_MinusLogProbMetric: 16.7155 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 100/1000
2023-09-12 16:53:06.282 
Epoch 100/1000 
	 loss: 16.5841, MinusLogProbMetric: 16.5841, val_loss: 16.7104, val_MinusLogProbMetric: 16.7104

Epoch 100: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5841 - MinusLogProbMetric: 16.5841 - val_loss: 16.7104 - val_MinusLogProbMetric: 16.7104 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 101/1000
2023-09-12 16:53:17.336 
Epoch 101/1000 
	 loss: 16.6072, MinusLogProbMetric: 16.6072, val_loss: 16.7410, val_MinusLogProbMetric: 16.7410

Epoch 101: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.6072 - MinusLogProbMetric: 16.6072 - val_loss: 16.7410 - val_MinusLogProbMetric: 16.7410 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 102/1000
2023-09-12 16:53:28.424 
Epoch 102/1000 
	 loss: 16.5749, MinusLogProbMetric: 16.5749, val_loss: 16.7259, val_MinusLogProbMetric: 16.7259

Epoch 102: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5749 - MinusLogProbMetric: 16.5749 - val_loss: 16.7259 - val_MinusLogProbMetric: 16.7259 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 103/1000
2023-09-12 16:53:39.615 
Epoch 103/1000 
	 loss: 16.5726, MinusLogProbMetric: 16.5726, val_loss: 16.7542, val_MinusLogProbMetric: 16.7542

Epoch 103: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5726 - MinusLogProbMetric: 16.5726 - val_loss: 16.7542 - val_MinusLogProbMetric: 16.7542 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 104/1000
2023-09-12 16:53:50.662 
Epoch 104/1000 
	 loss: 16.5889, MinusLogProbMetric: 16.5889, val_loss: 16.7640, val_MinusLogProbMetric: 16.7640

Epoch 104: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5889 - MinusLogProbMetric: 16.5889 - val_loss: 16.7640 - val_MinusLogProbMetric: 16.7640 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 105/1000
2023-09-12 16:54:01.865 
Epoch 105/1000 
	 loss: 16.5696, MinusLogProbMetric: 16.5696, val_loss: 16.7088, val_MinusLogProbMetric: 16.7088

Epoch 105: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5696 - MinusLogProbMetric: 16.5696 - val_loss: 16.7088 - val_MinusLogProbMetric: 16.7088 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 106/1000
2023-09-12 16:54:13.061 
Epoch 106/1000 
	 loss: 16.5775, MinusLogProbMetric: 16.5775, val_loss: 16.6945, val_MinusLogProbMetric: 16.6945

Epoch 106: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5775 - MinusLogProbMetric: 16.5775 - val_loss: 16.6945 - val_MinusLogProbMetric: 16.6945 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 107/1000
2023-09-12 16:54:24.299 
Epoch 107/1000 
	 loss: 16.5603, MinusLogProbMetric: 16.5603, val_loss: 16.7792, val_MinusLogProbMetric: 16.7792

Epoch 107: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5603 - MinusLogProbMetric: 16.5603 - val_loss: 16.7792 - val_MinusLogProbMetric: 16.7792 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 108/1000
2023-09-12 16:54:35.478 
Epoch 108/1000 
	 loss: 16.5751, MinusLogProbMetric: 16.5751, val_loss: 16.8109, val_MinusLogProbMetric: 16.8109

Epoch 108: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5751 - MinusLogProbMetric: 16.5751 - val_loss: 16.8109 - val_MinusLogProbMetric: 16.8109 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 109/1000
2023-09-12 16:54:46.855 
Epoch 109/1000 
	 loss: 16.5804, MinusLogProbMetric: 16.5804, val_loss: 16.7415, val_MinusLogProbMetric: 16.7415

Epoch 109: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5804 - MinusLogProbMetric: 16.5804 - val_loss: 16.7415 - val_MinusLogProbMetric: 16.7415 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 110/1000
2023-09-12 16:54:58.171 
Epoch 110/1000 
	 loss: 16.5765, MinusLogProbMetric: 16.5765, val_loss: 16.7428, val_MinusLogProbMetric: 16.7428

Epoch 110: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5765 - MinusLogProbMetric: 16.5765 - val_loss: 16.7428 - val_MinusLogProbMetric: 16.7428 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 111/1000
2023-09-12 16:55:09.430 
Epoch 111/1000 
	 loss: 16.5608, MinusLogProbMetric: 16.5608, val_loss: 16.7772, val_MinusLogProbMetric: 16.7772

Epoch 111: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5608 - MinusLogProbMetric: 16.5608 - val_loss: 16.7772 - val_MinusLogProbMetric: 16.7772 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 112/1000
2023-09-12 16:55:20.924 
Epoch 112/1000 
	 loss: 16.5562, MinusLogProbMetric: 16.5562, val_loss: 16.6778, val_MinusLogProbMetric: 16.6778

Epoch 112: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5562 - MinusLogProbMetric: 16.5562 - val_loss: 16.6778 - val_MinusLogProbMetric: 16.6778 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 113/1000
2023-09-12 16:55:32.038 
Epoch 113/1000 
	 loss: 16.5514, MinusLogProbMetric: 16.5514, val_loss: 16.7778, val_MinusLogProbMetric: 16.7778

Epoch 113: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5514 - MinusLogProbMetric: 16.5514 - val_loss: 16.7778 - val_MinusLogProbMetric: 16.7778 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 114/1000
2023-09-12 16:55:43.274 
Epoch 114/1000 
	 loss: 16.5513, MinusLogProbMetric: 16.5513, val_loss: 16.6902, val_MinusLogProbMetric: 16.6902

Epoch 114: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5513 - MinusLogProbMetric: 16.5513 - val_loss: 16.6902 - val_MinusLogProbMetric: 16.6902 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 115/1000
2023-09-12 16:55:54.499 
Epoch 115/1000 
	 loss: 16.5548, MinusLogProbMetric: 16.5548, val_loss: 16.7643, val_MinusLogProbMetric: 16.7643

Epoch 115: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5548 - MinusLogProbMetric: 16.5548 - val_loss: 16.7643 - val_MinusLogProbMetric: 16.7643 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 116/1000
2023-09-12 16:56:05.758 
Epoch 116/1000 
	 loss: 16.5609, MinusLogProbMetric: 16.5609, val_loss: 16.8430, val_MinusLogProbMetric: 16.8430

Epoch 116: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5609 - MinusLogProbMetric: 16.5609 - val_loss: 16.8430 - val_MinusLogProbMetric: 16.8430 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 117/1000
2023-09-12 16:56:16.867 
Epoch 117/1000 
	 loss: 16.5715, MinusLogProbMetric: 16.5715, val_loss: 16.9769, val_MinusLogProbMetric: 16.9769

Epoch 117: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5715 - MinusLogProbMetric: 16.5715 - val_loss: 16.9769 - val_MinusLogProbMetric: 16.9769 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 118/1000
2023-09-12 16:56:28.136 
Epoch 118/1000 
	 loss: 16.5473, MinusLogProbMetric: 16.5473, val_loss: 16.6853, val_MinusLogProbMetric: 16.6853

Epoch 118: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5473 - MinusLogProbMetric: 16.5473 - val_loss: 16.6853 - val_MinusLogProbMetric: 16.6853 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 119/1000
2023-09-12 16:56:39.456 
Epoch 119/1000 
	 loss: 16.5494, MinusLogProbMetric: 16.5494, val_loss: 16.7739, val_MinusLogProbMetric: 16.7739

Epoch 119: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5494 - MinusLogProbMetric: 16.5494 - val_loss: 16.7739 - val_MinusLogProbMetric: 16.7739 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 120/1000
2023-09-12 16:56:50.799 
Epoch 120/1000 
	 loss: 16.5598, MinusLogProbMetric: 16.5598, val_loss: 16.7553, val_MinusLogProbMetric: 16.7553

Epoch 120: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5598 - MinusLogProbMetric: 16.5598 - val_loss: 16.7553 - val_MinusLogProbMetric: 16.7553 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 121/1000
2023-09-12 16:57:01.973 
Epoch 121/1000 
	 loss: 16.5482, MinusLogProbMetric: 16.5482, val_loss: 16.7216, val_MinusLogProbMetric: 16.7216

Epoch 121: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5482 - MinusLogProbMetric: 16.5482 - val_loss: 16.7216 - val_MinusLogProbMetric: 16.7216 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 122/1000
2023-09-12 16:57:13.135 
Epoch 122/1000 
	 loss: 16.5428, MinusLogProbMetric: 16.5428, val_loss: 16.7616, val_MinusLogProbMetric: 16.7616

Epoch 122: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5428 - MinusLogProbMetric: 16.5428 - val_loss: 16.7616 - val_MinusLogProbMetric: 16.7616 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 123/1000
2023-09-12 16:57:24.323 
Epoch 123/1000 
	 loss: 16.5523, MinusLogProbMetric: 16.5523, val_loss: 16.7154, val_MinusLogProbMetric: 16.7154

Epoch 123: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.5523 - MinusLogProbMetric: 16.5523 - val_loss: 16.7154 - val_MinusLogProbMetric: 16.7154 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 124/1000
2023-09-12 16:57:35.558 
Epoch 124/1000 
	 loss: 16.4630, MinusLogProbMetric: 16.4630, val_loss: 16.7016, val_MinusLogProbMetric: 16.7016

Epoch 124: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.4630 - MinusLogProbMetric: 16.4630 - val_loss: 16.7016 - val_MinusLogProbMetric: 16.7016 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 125/1000
2023-09-12 16:57:46.776 
Epoch 125/1000 
	 loss: 16.4623, MinusLogProbMetric: 16.4623, val_loss: 16.6559, val_MinusLogProbMetric: 16.6559

Epoch 125: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.4623 - MinusLogProbMetric: 16.4623 - val_loss: 16.6559 - val_MinusLogProbMetric: 16.6559 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 126/1000
2023-09-12 16:57:57.997 
Epoch 126/1000 
	 loss: 16.4589, MinusLogProbMetric: 16.4589, val_loss: 16.6733, val_MinusLogProbMetric: 16.6733

Epoch 126: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.4589 - MinusLogProbMetric: 16.4589 - val_loss: 16.6733 - val_MinusLogProbMetric: 16.6733 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 127/1000
2023-09-12 16:58:09.297 
Epoch 127/1000 
	 loss: 16.4538, MinusLogProbMetric: 16.4538, val_loss: 16.6772, val_MinusLogProbMetric: 16.6772

Epoch 127: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.4538 - MinusLogProbMetric: 16.4538 - val_loss: 16.6772 - val_MinusLogProbMetric: 16.6772 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 128/1000
2023-09-12 16:58:20.550 
Epoch 128/1000 
	 loss: 16.4534, MinusLogProbMetric: 16.4534, val_loss: 16.6951, val_MinusLogProbMetric: 16.6951

Epoch 128: val_loss did not improve from 16.65375
196/196 - 11s - loss: 16.4534 - MinusLogProbMetric: 16.4534 - val_loss: 16.6951 - val_MinusLogProbMetric: 16.6951 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 129/1000
2023-09-12 16:58:31.971 
Epoch 129/1000 
	 loss: 16.4585, MinusLogProbMetric: 16.4585, val_loss: 16.6475, val_MinusLogProbMetric: 16.6475

Epoch 129: val_loss improved from 16.65375 to 16.64750, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_158/weights/best_weights.h5
196/196 - 12s - loss: 16.4585 - MinusLogProbMetric: 16.4585 - val_loss: 16.6475 - val_MinusLogProbMetric: 16.6475 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 130/1000
2023-09-12 16:58:43.298 
Epoch 130/1000 
	 loss: 16.4539, MinusLogProbMetric: 16.4539, val_loss: 16.6537, val_MinusLogProbMetric: 16.6537

Epoch 130: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4539 - MinusLogProbMetric: 16.4539 - val_loss: 16.6537 - val_MinusLogProbMetric: 16.6537 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 131/1000
2023-09-12 16:58:54.488 
Epoch 131/1000 
	 loss: 16.4569, MinusLogProbMetric: 16.4569, val_loss: 16.6643, val_MinusLogProbMetric: 16.6643

Epoch 131: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4569 - MinusLogProbMetric: 16.4569 - val_loss: 16.6643 - val_MinusLogProbMetric: 16.6643 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 132/1000
2023-09-12 16:59:05.819 
Epoch 132/1000 
	 loss: 16.4519, MinusLogProbMetric: 16.4519, val_loss: 16.6757, val_MinusLogProbMetric: 16.6757

Epoch 132: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4519 - MinusLogProbMetric: 16.4519 - val_loss: 16.6757 - val_MinusLogProbMetric: 16.6757 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 133/1000
2023-09-12 16:59:17.082 
Epoch 133/1000 
	 loss: 16.4464, MinusLogProbMetric: 16.4464, val_loss: 16.6730, val_MinusLogProbMetric: 16.6730

Epoch 133: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4464 - MinusLogProbMetric: 16.4464 - val_loss: 16.6730 - val_MinusLogProbMetric: 16.6730 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 134/1000
2023-09-12 16:59:28.419 
Epoch 134/1000 
	 loss: 16.4504, MinusLogProbMetric: 16.4504, val_loss: 16.6873, val_MinusLogProbMetric: 16.6873

Epoch 134: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4504 - MinusLogProbMetric: 16.4504 - val_loss: 16.6873 - val_MinusLogProbMetric: 16.6873 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 135/1000
2023-09-12 16:59:39.814 
Epoch 135/1000 
	 loss: 16.4509, MinusLogProbMetric: 16.4509, val_loss: 16.6779, val_MinusLogProbMetric: 16.6779

Epoch 135: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4509 - MinusLogProbMetric: 16.4509 - val_loss: 16.6779 - val_MinusLogProbMetric: 16.6779 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 136/1000
2023-09-12 16:59:51.073 
Epoch 136/1000 
	 loss: 16.4437, MinusLogProbMetric: 16.4437, val_loss: 16.6670, val_MinusLogProbMetric: 16.6670

Epoch 136: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4437 - MinusLogProbMetric: 16.4437 - val_loss: 16.6670 - val_MinusLogProbMetric: 16.6670 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 137/1000
2023-09-12 17:00:02.139 
Epoch 137/1000 
	 loss: 16.4452, MinusLogProbMetric: 16.4452, val_loss: 16.7064, val_MinusLogProbMetric: 16.7064

Epoch 137: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4452 - MinusLogProbMetric: 16.4452 - val_loss: 16.7064 - val_MinusLogProbMetric: 16.7064 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 138/1000
2023-09-12 17:00:13.073 
Epoch 138/1000 
	 loss: 16.4535, MinusLogProbMetric: 16.4535, val_loss: 16.6650, val_MinusLogProbMetric: 16.6650

Epoch 138: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4535 - MinusLogProbMetric: 16.4535 - val_loss: 16.6650 - val_MinusLogProbMetric: 16.6650 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 139/1000
2023-09-12 17:00:24.032 
Epoch 139/1000 
	 loss: 16.4516, MinusLogProbMetric: 16.4516, val_loss: 16.6730, val_MinusLogProbMetric: 16.6730

Epoch 139: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4516 - MinusLogProbMetric: 16.4516 - val_loss: 16.6730 - val_MinusLogProbMetric: 16.6730 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 140/1000
2023-09-12 17:00:35.027 
Epoch 140/1000 
	 loss: 16.4461, MinusLogProbMetric: 16.4461, val_loss: 16.6606, val_MinusLogProbMetric: 16.6606

Epoch 140: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4461 - MinusLogProbMetric: 16.4461 - val_loss: 16.6606 - val_MinusLogProbMetric: 16.6606 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 141/1000
2023-09-12 17:00:46.107 
Epoch 141/1000 
	 loss: 16.4408, MinusLogProbMetric: 16.4408, val_loss: 16.6631, val_MinusLogProbMetric: 16.6631

Epoch 141: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4408 - MinusLogProbMetric: 16.4408 - val_loss: 16.6631 - val_MinusLogProbMetric: 16.6631 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 142/1000
2023-09-12 17:00:57.038 
Epoch 142/1000 
	 loss: 16.4431, MinusLogProbMetric: 16.4431, val_loss: 16.6864, val_MinusLogProbMetric: 16.6864

Epoch 142: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4431 - MinusLogProbMetric: 16.4431 - val_loss: 16.6864 - val_MinusLogProbMetric: 16.6864 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 143/1000
2023-09-12 17:01:08.011 
Epoch 143/1000 
	 loss: 16.4476, MinusLogProbMetric: 16.4476, val_loss: 16.6999, val_MinusLogProbMetric: 16.6999

Epoch 143: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4476 - MinusLogProbMetric: 16.4476 - val_loss: 16.6999 - val_MinusLogProbMetric: 16.6999 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 144/1000
2023-09-12 17:01:17.072 
Epoch 144/1000 
	 loss: 16.4383, MinusLogProbMetric: 16.4383, val_loss: 16.6739, val_MinusLogProbMetric: 16.6739

Epoch 144: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4383 - MinusLogProbMetric: 16.4383 - val_loss: 16.6739 - val_MinusLogProbMetric: 16.6739 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 145/1000
2023-09-12 17:01:26.867 
Epoch 145/1000 
	 loss: 16.4373, MinusLogProbMetric: 16.4373, val_loss: 16.6941, val_MinusLogProbMetric: 16.6941

Epoch 145: val_loss did not improve from 16.64750
196/196 - 10s - loss: 16.4373 - MinusLogProbMetric: 16.4373 - val_loss: 16.6941 - val_MinusLogProbMetric: 16.6941 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 146/1000
2023-09-12 17:01:37.775 
Epoch 146/1000 
	 loss: 16.4378, MinusLogProbMetric: 16.4378, val_loss: 16.6885, val_MinusLogProbMetric: 16.6885

Epoch 146: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4378 - MinusLogProbMetric: 16.4378 - val_loss: 16.6885 - val_MinusLogProbMetric: 16.6885 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 147/1000
2023-09-12 17:01:48.641 
Epoch 147/1000 
	 loss: 16.4341, MinusLogProbMetric: 16.4341, val_loss: 16.7151, val_MinusLogProbMetric: 16.7151

Epoch 147: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4341 - MinusLogProbMetric: 16.4341 - val_loss: 16.7151 - val_MinusLogProbMetric: 16.7151 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 148/1000
2023-09-12 17:01:59.713 
Epoch 148/1000 
	 loss: 16.4377, MinusLogProbMetric: 16.4377, val_loss: 16.6826, val_MinusLogProbMetric: 16.6826

Epoch 148: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4377 - MinusLogProbMetric: 16.4377 - val_loss: 16.6826 - val_MinusLogProbMetric: 16.6826 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 149/1000
2023-09-12 17:02:10.703 
Epoch 149/1000 
	 loss: 16.4357, MinusLogProbMetric: 16.4357, val_loss: 16.6992, val_MinusLogProbMetric: 16.6992

Epoch 149: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4357 - MinusLogProbMetric: 16.4357 - val_loss: 16.6992 - val_MinusLogProbMetric: 16.6992 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 150/1000
2023-09-12 17:02:21.753 
Epoch 150/1000 
	 loss: 16.4317, MinusLogProbMetric: 16.4317, val_loss: 16.6795, val_MinusLogProbMetric: 16.6795

Epoch 150: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4317 - MinusLogProbMetric: 16.4317 - val_loss: 16.6795 - val_MinusLogProbMetric: 16.6795 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 151/1000
2023-09-12 17:02:32.843 
Epoch 151/1000 
	 loss: 16.4419, MinusLogProbMetric: 16.4419, val_loss: 16.6858, val_MinusLogProbMetric: 16.6858

Epoch 151: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4419 - MinusLogProbMetric: 16.4419 - val_loss: 16.6858 - val_MinusLogProbMetric: 16.6858 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 152/1000
2023-09-12 17:02:43.922 
Epoch 152/1000 
	 loss: 16.4330, MinusLogProbMetric: 16.4330, val_loss: 16.6883, val_MinusLogProbMetric: 16.6883

Epoch 152: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4330 - MinusLogProbMetric: 16.4330 - val_loss: 16.6883 - val_MinusLogProbMetric: 16.6883 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 153/1000
2023-09-12 17:02:54.573 
Epoch 153/1000 
	 loss: 16.4318, MinusLogProbMetric: 16.4318, val_loss: 16.7198, val_MinusLogProbMetric: 16.7198

Epoch 153: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4318 - MinusLogProbMetric: 16.4318 - val_loss: 16.7198 - val_MinusLogProbMetric: 16.7198 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 154/1000
2023-09-12 17:03:05.358 
Epoch 154/1000 
	 loss: 16.4323, MinusLogProbMetric: 16.4323, val_loss: 16.7009, val_MinusLogProbMetric: 16.7009

Epoch 154: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4323 - MinusLogProbMetric: 16.4323 - val_loss: 16.7009 - val_MinusLogProbMetric: 16.7009 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 155/1000
2023-09-12 17:03:16.495 
Epoch 155/1000 
	 loss: 16.4316, MinusLogProbMetric: 16.4316, val_loss: 16.6816, val_MinusLogProbMetric: 16.6816

Epoch 155: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4316 - MinusLogProbMetric: 16.4316 - val_loss: 16.6816 - val_MinusLogProbMetric: 16.6816 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 156/1000
2023-09-12 17:03:27.457 
Epoch 156/1000 
	 loss: 16.4341, MinusLogProbMetric: 16.4341, val_loss: 16.7034, val_MinusLogProbMetric: 16.7034

Epoch 156: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4341 - MinusLogProbMetric: 16.4341 - val_loss: 16.7034 - val_MinusLogProbMetric: 16.7034 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 157/1000
2023-09-12 17:03:38.536 
Epoch 157/1000 
	 loss: 16.4275, MinusLogProbMetric: 16.4275, val_loss: 16.6904, val_MinusLogProbMetric: 16.6904

Epoch 157: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4275 - MinusLogProbMetric: 16.4275 - val_loss: 16.6904 - val_MinusLogProbMetric: 16.6904 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 158/1000
2023-09-12 17:03:49.656 
Epoch 158/1000 
	 loss: 16.4273, MinusLogProbMetric: 16.4273, val_loss: 16.7034, val_MinusLogProbMetric: 16.7034

Epoch 158: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4273 - MinusLogProbMetric: 16.4273 - val_loss: 16.7034 - val_MinusLogProbMetric: 16.7034 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 159/1000
2023-09-12 17:04:00.622 
Epoch 159/1000 
	 loss: 16.4259, MinusLogProbMetric: 16.4259, val_loss: 16.6874, val_MinusLogProbMetric: 16.6874

Epoch 159: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4259 - MinusLogProbMetric: 16.4259 - val_loss: 16.6874 - val_MinusLogProbMetric: 16.6874 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 160/1000
2023-09-12 17:04:11.608 
Epoch 160/1000 
	 loss: 16.4259, MinusLogProbMetric: 16.4259, val_loss: 16.7102, val_MinusLogProbMetric: 16.7102

Epoch 160: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4259 - MinusLogProbMetric: 16.4259 - val_loss: 16.7102 - val_MinusLogProbMetric: 16.7102 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 161/1000
2023-09-12 17:04:21.440 
Epoch 161/1000 
	 loss: 16.4293, MinusLogProbMetric: 16.4293, val_loss: 16.7209, val_MinusLogProbMetric: 16.7209

Epoch 161: val_loss did not improve from 16.64750
196/196 - 10s - loss: 16.4293 - MinusLogProbMetric: 16.4293 - val_loss: 16.7209 - val_MinusLogProbMetric: 16.7209 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 162/1000
2023-09-12 17:04:32.551 
Epoch 162/1000 
	 loss: 16.4224, MinusLogProbMetric: 16.4224, val_loss: 16.6913, val_MinusLogProbMetric: 16.6913

Epoch 162: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4224 - MinusLogProbMetric: 16.4224 - val_loss: 16.6913 - val_MinusLogProbMetric: 16.6913 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 163/1000
2023-09-12 17:04:42.770 
Epoch 163/1000 
	 loss: 16.4191, MinusLogProbMetric: 16.4191, val_loss: 16.7419, val_MinusLogProbMetric: 16.7419

Epoch 163: val_loss did not improve from 16.64750
196/196 - 10s - loss: 16.4191 - MinusLogProbMetric: 16.4191 - val_loss: 16.7419 - val_MinusLogProbMetric: 16.7419 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 164/1000
2023-09-12 17:04:51.708 
Epoch 164/1000 
	 loss: 16.4214, MinusLogProbMetric: 16.4214, val_loss: 16.7039, val_MinusLogProbMetric: 16.7039

Epoch 164: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4214 - MinusLogProbMetric: 16.4214 - val_loss: 16.7039 - val_MinusLogProbMetric: 16.7039 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 165/1000
2023-09-12 17:05:00.739 
Epoch 165/1000 
	 loss: 16.4254, MinusLogProbMetric: 16.4254, val_loss: 16.7016, val_MinusLogProbMetric: 16.7016

Epoch 165: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4254 - MinusLogProbMetric: 16.4254 - val_loss: 16.7016 - val_MinusLogProbMetric: 16.7016 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 166/1000
2023-09-12 17:05:09.635 
Epoch 166/1000 
	 loss: 16.4241, MinusLogProbMetric: 16.4241, val_loss: 16.6885, val_MinusLogProbMetric: 16.6885

Epoch 166: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4241 - MinusLogProbMetric: 16.4241 - val_loss: 16.6885 - val_MinusLogProbMetric: 16.6885 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 167/1000
2023-09-12 17:05:18.642 
Epoch 167/1000 
	 loss: 16.4219, MinusLogProbMetric: 16.4219, val_loss: 16.6912, val_MinusLogProbMetric: 16.6912

Epoch 167: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4219 - MinusLogProbMetric: 16.4219 - val_loss: 16.6912 - val_MinusLogProbMetric: 16.6912 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 168/1000
2023-09-12 17:05:27.605 
Epoch 168/1000 
	 loss: 16.4201, MinusLogProbMetric: 16.4201, val_loss: 16.6928, val_MinusLogProbMetric: 16.6928

Epoch 168: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4201 - MinusLogProbMetric: 16.4201 - val_loss: 16.6928 - val_MinusLogProbMetric: 16.6928 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 169/1000
2023-09-12 17:05:36.596 
Epoch 169/1000 
	 loss: 16.4168, MinusLogProbMetric: 16.4168, val_loss: 16.7080, val_MinusLogProbMetric: 16.7080

Epoch 169: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4168 - MinusLogProbMetric: 16.4168 - val_loss: 16.7080 - val_MinusLogProbMetric: 16.7080 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 170/1000
2023-09-12 17:05:45.467 
Epoch 170/1000 
	 loss: 16.4177, MinusLogProbMetric: 16.4177, val_loss: 16.6961, val_MinusLogProbMetric: 16.6961

Epoch 170: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4177 - MinusLogProbMetric: 16.4177 - val_loss: 16.6961 - val_MinusLogProbMetric: 16.6961 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 171/1000
2023-09-12 17:05:54.401 
Epoch 171/1000 
	 loss: 16.4181, MinusLogProbMetric: 16.4181, val_loss: 16.7081, val_MinusLogProbMetric: 16.7081

Epoch 171: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4181 - MinusLogProbMetric: 16.4181 - val_loss: 16.7081 - val_MinusLogProbMetric: 16.7081 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 172/1000
2023-09-12 17:06:03.181 
Epoch 172/1000 
	 loss: 16.4199, MinusLogProbMetric: 16.4199, val_loss: 16.7366, val_MinusLogProbMetric: 16.7366

Epoch 172: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4199 - MinusLogProbMetric: 16.4199 - val_loss: 16.7366 - val_MinusLogProbMetric: 16.7366 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 173/1000
2023-09-12 17:06:12.038 
Epoch 173/1000 
	 loss: 16.4217, MinusLogProbMetric: 16.4217, val_loss: 16.7152, val_MinusLogProbMetric: 16.7152

Epoch 173: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4217 - MinusLogProbMetric: 16.4217 - val_loss: 16.7152 - val_MinusLogProbMetric: 16.7152 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 174/1000
2023-09-12 17:06:21.161 
Epoch 174/1000 
	 loss: 16.4131, MinusLogProbMetric: 16.4131, val_loss: 16.7408, val_MinusLogProbMetric: 16.7408

Epoch 174: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4131 - MinusLogProbMetric: 16.4131 - val_loss: 16.7408 - val_MinusLogProbMetric: 16.7408 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 175/1000
2023-09-12 17:06:30.012 
Epoch 175/1000 
	 loss: 16.4106, MinusLogProbMetric: 16.4106, val_loss: 16.7256, val_MinusLogProbMetric: 16.7256

Epoch 175: val_loss did not improve from 16.64750
196/196 - 9s - loss: 16.4106 - MinusLogProbMetric: 16.4106 - val_loss: 16.7256 - val_MinusLogProbMetric: 16.7256 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 176/1000
2023-09-12 17:06:40.551 
Epoch 176/1000 
	 loss: 16.4112, MinusLogProbMetric: 16.4112, val_loss: 16.7200, val_MinusLogProbMetric: 16.7200

Epoch 176: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4112 - MinusLogProbMetric: 16.4112 - val_loss: 16.7200 - val_MinusLogProbMetric: 16.7200 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 177/1000
2023-09-12 17:06:51.579 
Epoch 177/1000 
	 loss: 16.4153, MinusLogProbMetric: 16.4153, val_loss: 16.7251, val_MinusLogProbMetric: 16.7251

Epoch 177: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4153 - MinusLogProbMetric: 16.4153 - val_loss: 16.7251 - val_MinusLogProbMetric: 16.7251 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 178/1000
2023-09-12 17:07:01.927 
Epoch 178/1000 
	 loss: 16.4129, MinusLogProbMetric: 16.4129, val_loss: 16.7164, val_MinusLogProbMetric: 16.7164

Epoch 178: val_loss did not improve from 16.64750
196/196 - 10s - loss: 16.4129 - MinusLogProbMetric: 16.4129 - val_loss: 16.7164 - val_MinusLogProbMetric: 16.7164 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 179/1000
2023-09-12 17:07:13.246 
Epoch 179/1000 
	 loss: 16.4110, MinusLogProbMetric: 16.4110, val_loss: 16.7274, val_MinusLogProbMetric: 16.7274

Epoch 179: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.4110 - MinusLogProbMetric: 16.4110 - val_loss: 16.7274 - val_MinusLogProbMetric: 16.7274 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 180/1000
2023-09-12 17:07:24.667 
Epoch 180/1000 
	 loss: 16.3685, MinusLogProbMetric: 16.3685, val_loss: 16.7030, val_MinusLogProbMetric: 16.7030

Epoch 180: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3685 - MinusLogProbMetric: 16.3685 - val_loss: 16.7030 - val_MinusLogProbMetric: 16.7030 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 181/1000
2023-09-12 17:07:36.138 
Epoch 181/1000 
	 loss: 16.3669, MinusLogProbMetric: 16.3669, val_loss: 16.6993, val_MinusLogProbMetric: 16.6993

Epoch 181: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3669 - MinusLogProbMetric: 16.3669 - val_loss: 16.6993 - val_MinusLogProbMetric: 16.6993 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 182/1000
2023-09-12 17:07:47.318 
Epoch 182/1000 
	 loss: 16.3648, MinusLogProbMetric: 16.3648, val_loss: 16.6948, val_MinusLogProbMetric: 16.6948

Epoch 182: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3648 - MinusLogProbMetric: 16.3648 - val_loss: 16.6948 - val_MinusLogProbMetric: 16.6948 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 183/1000
2023-09-12 17:07:58.628 
Epoch 183/1000 
	 loss: 16.3652, MinusLogProbMetric: 16.3652, val_loss: 16.7082, val_MinusLogProbMetric: 16.7082

Epoch 183: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3652 - MinusLogProbMetric: 16.3652 - val_loss: 16.7082 - val_MinusLogProbMetric: 16.7082 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 184/1000
2023-09-12 17:08:09.794 
Epoch 184/1000 
	 loss: 16.3639, MinusLogProbMetric: 16.3639, val_loss: 16.7102, val_MinusLogProbMetric: 16.7102

Epoch 184: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3639 - MinusLogProbMetric: 16.3639 - val_loss: 16.7102 - val_MinusLogProbMetric: 16.7102 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 185/1000
2023-09-12 17:08:21.214 
Epoch 185/1000 
	 loss: 16.3626, MinusLogProbMetric: 16.3626, val_loss: 16.7415, val_MinusLogProbMetric: 16.7415

Epoch 185: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3626 - MinusLogProbMetric: 16.3626 - val_loss: 16.7415 - val_MinusLogProbMetric: 16.7415 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 186/1000
2023-09-12 17:08:32.491 
Epoch 186/1000 
	 loss: 16.3652, MinusLogProbMetric: 16.3652, val_loss: 16.7049, val_MinusLogProbMetric: 16.7049

Epoch 186: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3652 - MinusLogProbMetric: 16.3652 - val_loss: 16.7049 - val_MinusLogProbMetric: 16.7049 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 187/1000
2023-09-12 17:08:43.766 
Epoch 187/1000 
	 loss: 16.3615, MinusLogProbMetric: 16.3615, val_loss: 16.7059, val_MinusLogProbMetric: 16.7059

Epoch 187: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3615 - MinusLogProbMetric: 16.3615 - val_loss: 16.7059 - val_MinusLogProbMetric: 16.7059 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 188/1000
2023-09-12 17:08:55.015 
Epoch 188/1000 
	 loss: 16.3638, MinusLogProbMetric: 16.3638, val_loss: 16.7160, val_MinusLogProbMetric: 16.7160

Epoch 188: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3638 - MinusLogProbMetric: 16.3638 - val_loss: 16.7160 - val_MinusLogProbMetric: 16.7160 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 189/1000
2023-09-12 17:09:06.309 
Epoch 189/1000 
	 loss: 16.3623, MinusLogProbMetric: 16.3623, val_loss: 16.6966, val_MinusLogProbMetric: 16.6966

Epoch 189: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3623 - MinusLogProbMetric: 16.3623 - val_loss: 16.6966 - val_MinusLogProbMetric: 16.6966 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 190/1000
2023-09-12 17:09:17.487 
Epoch 190/1000 
	 loss: 16.3612, MinusLogProbMetric: 16.3612, val_loss: 16.6989, val_MinusLogProbMetric: 16.6989

Epoch 190: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3612 - MinusLogProbMetric: 16.3612 - val_loss: 16.6989 - val_MinusLogProbMetric: 16.6989 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 191/1000
2023-09-12 17:09:28.853 
Epoch 191/1000 
	 loss: 16.3624, MinusLogProbMetric: 16.3624, val_loss: 16.7046, val_MinusLogProbMetric: 16.7046

Epoch 191: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3624 - MinusLogProbMetric: 16.3624 - val_loss: 16.7046 - val_MinusLogProbMetric: 16.7046 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 192/1000
2023-09-12 17:09:40.114 
Epoch 192/1000 
	 loss: 16.3597, MinusLogProbMetric: 16.3597, val_loss: 16.7334, val_MinusLogProbMetric: 16.7334

Epoch 192: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3597 - MinusLogProbMetric: 16.3597 - val_loss: 16.7334 - val_MinusLogProbMetric: 16.7334 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 193/1000
2023-09-12 17:09:51.330 
Epoch 193/1000 
	 loss: 16.3606, MinusLogProbMetric: 16.3606, val_loss: 16.7037, val_MinusLogProbMetric: 16.7037

Epoch 193: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3606 - MinusLogProbMetric: 16.3606 - val_loss: 16.7037 - val_MinusLogProbMetric: 16.7037 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 194/1000
2023-09-12 17:10:02.587 
Epoch 194/1000 
	 loss: 16.3593, MinusLogProbMetric: 16.3593, val_loss: 16.7233, val_MinusLogProbMetric: 16.7233

Epoch 194: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3593 - MinusLogProbMetric: 16.3593 - val_loss: 16.7233 - val_MinusLogProbMetric: 16.7233 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 195/1000
2023-09-12 17:10:13.817 
Epoch 195/1000 
	 loss: 16.3585, MinusLogProbMetric: 16.3585, val_loss: 16.7257, val_MinusLogProbMetric: 16.7257

Epoch 195: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3585 - MinusLogProbMetric: 16.3585 - val_loss: 16.7257 - val_MinusLogProbMetric: 16.7257 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 196/1000
2023-09-12 17:10:24.949 
Epoch 196/1000 
	 loss: 16.3545, MinusLogProbMetric: 16.3545, val_loss: 16.7161, val_MinusLogProbMetric: 16.7161

Epoch 196: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3545 - MinusLogProbMetric: 16.3545 - val_loss: 16.7161 - val_MinusLogProbMetric: 16.7161 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 197/1000
2023-09-12 17:10:36.180 
Epoch 197/1000 
	 loss: 16.3568, MinusLogProbMetric: 16.3568, val_loss: 16.7152, val_MinusLogProbMetric: 16.7152

Epoch 197: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3568 - MinusLogProbMetric: 16.3568 - val_loss: 16.7152 - val_MinusLogProbMetric: 16.7152 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 198/1000
2023-09-12 17:10:47.425 
Epoch 198/1000 
	 loss: 16.3567, MinusLogProbMetric: 16.3567, val_loss: 16.7172, val_MinusLogProbMetric: 16.7172

Epoch 198: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3567 - MinusLogProbMetric: 16.3567 - val_loss: 16.7172 - val_MinusLogProbMetric: 16.7172 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 199/1000
2023-09-12 17:10:58.490 
Epoch 199/1000 
	 loss: 16.3569, MinusLogProbMetric: 16.3569, val_loss: 16.7249, val_MinusLogProbMetric: 16.7249

Epoch 199: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3569 - MinusLogProbMetric: 16.3569 - val_loss: 16.7249 - val_MinusLogProbMetric: 16.7249 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 200/1000
2023-09-12 17:11:09.511 
Epoch 200/1000 
	 loss: 16.3560, MinusLogProbMetric: 16.3560, val_loss: 16.7470, val_MinusLogProbMetric: 16.7470

Epoch 200: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3560 - MinusLogProbMetric: 16.3560 - val_loss: 16.7470 - val_MinusLogProbMetric: 16.7470 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 201/1000
2023-09-12 17:11:20.918 
Epoch 201/1000 
	 loss: 16.3563, MinusLogProbMetric: 16.3563, val_loss: 16.7123, val_MinusLogProbMetric: 16.7123

Epoch 201: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3563 - MinusLogProbMetric: 16.3563 - val_loss: 16.7123 - val_MinusLogProbMetric: 16.7123 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 202/1000
2023-09-12 17:11:32.189 
Epoch 202/1000 
	 loss: 16.3573, MinusLogProbMetric: 16.3573, val_loss: 16.7114, val_MinusLogProbMetric: 16.7114

Epoch 202: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3573 - MinusLogProbMetric: 16.3573 - val_loss: 16.7114 - val_MinusLogProbMetric: 16.7114 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 203/1000
2023-09-12 17:11:43.334 
Epoch 203/1000 
	 loss: 16.3603, MinusLogProbMetric: 16.3603, val_loss: 16.7267, val_MinusLogProbMetric: 16.7267

Epoch 203: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3603 - MinusLogProbMetric: 16.3603 - val_loss: 16.7267 - val_MinusLogProbMetric: 16.7267 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 204/1000
2023-09-12 17:11:54.554 
Epoch 204/1000 
	 loss: 16.3522, MinusLogProbMetric: 16.3522, val_loss: 16.7322, val_MinusLogProbMetric: 16.7322

Epoch 204: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3522 - MinusLogProbMetric: 16.3522 - val_loss: 16.7322 - val_MinusLogProbMetric: 16.7322 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 205/1000
2023-09-12 17:12:05.848 
Epoch 205/1000 
	 loss: 16.3539, MinusLogProbMetric: 16.3539, val_loss: 16.7280, val_MinusLogProbMetric: 16.7280

Epoch 205: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3539 - MinusLogProbMetric: 16.3539 - val_loss: 16.7280 - val_MinusLogProbMetric: 16.7280 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-12 17:12:17.131 
Epoch 206/1000 
	 loss: 16.3504, MinusLogProbMetric: 16.3504, val_loss: 16.7345, val_MinusLogProbMetric: 16.7345

Epoch 206: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3504 - MinusLogProbMetric: 16.3504 - val_loss: 16.7345 - val_MinusLogProbMetric: 16.7345 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 207/1000
2023-09-12 17:12:28.290 
Epoch 207/1000 
	 loss: 16.3561, MinusLogProbMetric: 16.3561, val_loss: 16.7169, val_MinusLogProbMetric: 16.7169

Epoch 207: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3561 - MinusLogProbMetric: 16.3561 - val_loss: 16.7169 - val_MinusLogProbMetric: 16.7169 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 208/1000
2023-09-12 17:12:39.417 
Epoch 208/1000 
	 loss: 16.3516, MinusLogProbMetric: 16.3516, val_loss: 16.7171, val_MinusLogProbMetric: 16.7171

Epoch 208: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3516 - MinusLogProbMetric: 16.3516 - val_loss: 16.7171 - val_MinusLogProbMetric: 16.7171 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 209/1000
2023-09-12 17:12:50.719 
Epoch 209/1000 
	 loss: 16.3514, MinusLogProbMetric: 16.3514, val_loss: 16.7427, val_MinusLogProbMetric: 16.7427

Epoch 209: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3514 - MinusLogProbMetric: 16.3514 - val_loss: 16.7427 - val_MinusLogProbMetric: 16.7427 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 210/1000
2023-09-12 17:13:01.902 
Epoch 210/1000 
	 loss: 16.3499, MinusLogProbMetric: 16.3499, val_loss: 16.7177, val_MinusLogProbMetric: 16.7177

Epoch 210: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3499 - MinusLogProbMetric: 16.3499 - val_loss: 16.7177 - val_MinusLogProbMetric: 16.7177 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 211/1000
2023-09-12 17:13:13.083 
Epoch 211/1000 
	 loss: 16.3482, MinusLogProbMetric: 16.3482, val_loss: 16.7271, val_MinusLogProbMetric: 16.7271

Epoch 211: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3482 - MinusLogProbMetric: 16.3482 - val_loss: 16.7271 - val_MinusLogProbMetric: 16.7271 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 212/1000
2023-09-12 17:13:24.349 
Epoch 212/1000 
	 loss: 16.3506, MinusLogProbMetric: 16.3506, val_loss: 16.7169, val_MinusLogProbMetric: 16.7169

Epoch 212: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3506 - MinusLogProbMetric: 16.3506 - val_loss: 16.7169 - val_MinusLogProbMetric: 16.7169 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 213/1000
2023-09-12 17:13:35.706 
Epoch 213/1000 
	 loss: 16.3457, MinusLogProbMetric: 16.3457, val_loss: 16.7433, val_MinusLogProbMetric: 16.7433

Epoch 213: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3457 - MinusLogProbMetric: 16.3457 - val_loss: 16.7433 - val_MinusLogProbMetric: 16.7433 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 214/1000
2023-09-12 17:13:46.942 
Epoch 214/1000 
	 loss: 16.3482, MinusLogProbMetric: 16.3482, val_loss: 16.7250, val_MinusLogProbMetric: 16.7250

Epoch 214: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3482 - MinusLogProbMetric: 16.3482 - val_loss: 16.7250 - val_MinusLogProbMetric: 16.7250 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 215/1000
2023-09-12 17:13:58.151 
Epoch 215/1000 
	 loss: 16.3487, MinusLogProbMetric: 16.3487, val_loss: 16.7422, val_MinusLogProbMetric: 16.7422

Epoch 215: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3487 - MinusLogProbMetric: 16.3487 - val_loss: 16.7422 - val_MinusLogProbMetric: 16.7422 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 216/1000
2023-09-12 17:14:09.481 
Epoch 216/1000 
	 loss: 16.3504, MinusLogProbMetric: 16.3504, val_loss: 16.7351, val_MinusLogProbMetric: 16.7351

Epoch 216: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3504 - MinusLogProbMetric: 16.3504 - val_loss: 16.7351 - val_MinusLogProbMetric: 16.7351 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 217/1000
2023-09-12 17:14:20.667 
Epoch 217/1000 
	 loss: 16.3451, MinusLogProbMetric: 16.3451, val_loss: 16.7364, val_MinusLogProbMetric: 16.7364

Epoch 217: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3451 - MinusLogProbMetric: 16.3451 - val_loss: 16.7364 - val_MinusLogProbMetric: 16.7364 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 218/1000
2023-09-12 17:14:31.951 
Epoch 218/1000 
	 loss: 16.3487, MinusLogProbMetric: 16.3487, val_loss: 16.7442, val_MinusLogProbMetric: 16.7442

Epoch 218: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3487 - MinusLogProbMetric: 16.3487 - val_loss: 16.7442 - val_MinusLogProbMetric: 16.7442 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 219/1000
2023-09-12 17:14:43.231 
Epoch 219/1000 
	 loss: 16.3463, MinusLogProbMetric: 16.3463, val_loss: 16.7272, val_MinusLogProbMetric: 16.7272

Epoch 219: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3463 - MinusLogProbMetric: 16.3463 - val_loss: 16.7272 - val_MinusLogProbMetric: 16.7272 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 220/1000
2023-09-12 17:14:54.602 
Epoch 220/1000 
	 loss: 16.3453, MinusLogProbMetric: 16.3453, val_loss: 16.7319, val_MinusLogProbMetric: 16.7319

Epoch 220: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3453 - MinusLogProbMetric: 16.3453 - val_loss: 16.7319 - val_MinusLogProbMetric: 16.7319 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 221/1000
2023-09-12 17:15:06.011 
Epoch 221/1000 
	 loss: 16.3463, MinusLogProbMetric: 16.3463, val_loss: 16.7287, val_MinusLogProbMetric: 16.7287

Epoch 221: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3463 - MinusLogProbMetric: 16.3463 - val_loss: 16.7287 - val_MinusLogProbMetric: 16.7287 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 222/1000
2023-09-12 17:15:17.329 
Epoch 222/1000 
	 loss: 16.3462, MinusLogProbMetric: 16.3462, val_loss: 16.7666, val_MinusLogProbMetric: 16.7666

Epoch 222: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3462 - MinusLogProbMetric: 16.3462 - val_loss: 16.7666 - val_MinusLogProbMetric: 16.7666 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 223/1000
2023-09-12 17:15:28.645 
Epoch 223/1000 
	 loss: 16.3429, MinusLogProbMetric: 16.3429, val_loss: 16.7521, val_MinusLogProbMetric: 16.7521

Epoch 223: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3429 - MinusLogProbMetric: 16.3429 - val_loss: 16.7521 - val_MinusLogProbMetric: 16.7521 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 224/1000
2023-09-12 17:15:39.841 
Epoch 224/1000 
	 loss: 16.3433, MinusLogProbMetric: 16.3433, val_loss: 16.7337, val_MinusLogProbMetric: 16.7337

Epoch 224: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3433 - MinusLogProbMetric: 16.3433 - val_loss: 16.7337 - val_MinusLogProbMetric: 16.7337 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 225/1000
2023-09-12 17:15:51.140 
Epoch 225/1000 
	 loss: 16.3454, MinusLogProbMetric: 16.3454, val_loss: 16.7350, val_MinusLogProbMetric: 16.7350

Epoch 225: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3454 - MinusLogProbMetric: 16.3454 - val_loss: 16.7350 - val_MinusLogProbMetric: 16.7350 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 226/1000
2023-09-12 17:16:02.451 
Epoch 226/1000 
	 loss: 16.3426, MinusLogProbMetric: 16.3426, val_loss: 16.7443, val_MinusLogProbMetric: 16.7443

Epoch 226: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3426 - MinusLogProbMetric: 16.3426 - val_loss: 16.7443 - val_MinusLogProbMetric: 16.7443 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 227/1000
2023-09-12 17:16:13.807 
Epoch 227/1000 
	 loss: 16.3439, MinusLogProbMetric: 16.3439, val_loss: 16.7404, val_MinusLogProbMetric: 16.7404

Epoch 227: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3439 - MinusLogProbMetric: 16.3439 - val_loss: 16.7404 - val_MinusLogProbMetric: 16.7404 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 228/1000
2023-09-12 17:16:25.176 
Epoch 228/1000 
	 loss: 16.3425, MinusLogProbMetric: 16.3425, val_loss: 16.7480, val_MinusLogProbMetric: 16.7480

Epoch 228: val_loss did not improve from 16.64750
196/196 - 11s - loss: 16.3425 - MinusLogProbMetric: 16.3425 - val_loss: 16.7480 - val_MinusLogProbMetric: 16.7480 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 229/1000
2023-09-12 17:16:36.370 
Epoch 229/1000 
	 loss: 16.3419, MinusLogProbMetric: 16.3419, val_loss: 16.7392, val_MinusLogProbMetric: 16.7392

Epoch 229: val_loss did not improve from 16.64750
Restoring model weights from the end of the best epoch: 129.
196/196 - 11s - loss: 16.3419 - MinusLogProbMetric: 16.3419 - val_loss: 16.7392 - val_MinusLogProbMetric: 16.7392 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 229: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 7.712387846084312 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.6007245099172 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.203211866086349 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.148637027014047 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 933.
Model trained in 2491.81 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Metrics computed in 306.64 s.
Plots done in 120.59 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 427.23 s.
===========
Run 158/360 done in 2920.73 s.
===========

Directory ../../results/MsplineN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

===========
Generating train data for run 163.
===========
Train data generated in 0.28 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_163/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_163/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.843066  , 6.885543  , 5.4616323 , ..., 0.60136265, 7.6057563 ,
        1.4468012 ],
       [6.941901  , 2.9639573 , 6.1196294 , ..., 3.4089205 , 5.0531244 ,
        1.7321708 ],
       [6.6497912 , 2.6758661 , 6.1924143 , ..., 2.4044154 , 3.5041332 ,
        2.3901901 ],
       ...,
       [5.4960246 , 7.681503  , 5.4965014 , ..., 1.6430786 , 5.8353615 ,
        1.3267541 ],
       [5.6652064 , 7.894577  , 5.7936563 , ..., 1.3511211 , 6.9882894 ,
        1.2434273 ],
       [5.24072   , 7.783675  , 5.8090463 , ..., 1.1913109 , 5.8178825 ,
        1.3373194 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_163/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_163
self.data_kwargs: {'seed': 0}
self.x_data: [[ 6.6721983   2.7232099   6.150583   ...  3.6440284   4.565682
   2.645935  ]
 [ 1.86333     2.9602146   9.095053   ...  6.366897   -0.51058275
   3.6708503 ]
 [ 5.5981846   7.771953    4.990416   ...  1.6793485   6.8585963
   1.4719678 ]
 ...
 [ 1.690249    4.096276    8.408299   ...  5.907632    0.7324666
   3.17104   ]
 [ 1.5949699   2.976067    6.189886   ...  6.072563    1.3667407
   3.7841148 ]
 [ 6.6605377   2.9536047   6.141097   ...  3.8587723   3.7946694
   1.5606189 ]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model_22"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_67 (InputLayer)       [(None, 64)]              0         
                                                                 
 log_prob_layer_22 (LogProbL  (None,)                  660608    
 ayer)                                                           
                                                                 
=================================================================
Total params: 660,608
Trainable params: 660,608
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_22/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_22'")
self.model: <keras.engine.functional.Functional object at 0x7fc3b9cf5240>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc3b9bd6b00>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc3b9bd6b00>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc3b9b9bdc0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc3b991df30>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc3b991e4a0>, <keras.callbacks.ModelCheckpoint object at 0x7fc3b991e560>, <keras.callbacks.EarlyStopping object at 0x7fc3b991e7d0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc3b991e800>, <keras.callbacks.TerminateOnNaN object at 0x7fc3b991e440>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.843066  , 6.885543  , 5.4616323 , ..., 0.60136265, 7.6057563 ,
        1.4468012 ],
       [6.941901  , 2.9639573 , 6.1196294 , ..., 3.4089205 , 5.0531244 ,
        1.7321708 ],
       [6.6497912 , 2.6758661 , 6.1924143 , ..., 2.4044154 , 3.5041332 ,
        2.3901901 ],
       ...,
       [5.4960246 , 7.681503  , 5.4965014 , ..., 1.6430786 , 5.8353615 ,
        1.3267541 ],
       [5.6652064 , 7.894577  , 5.7936563 , ..., 1.3511211 , 6.9882894 ,
        1.2434273 ],
       [5.24072   , 7.783675  , 5.8090463 , ..., 1.1913109 , 5.8178825 ,
        1.3373194 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_163/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 163/360 with hyperparameters:
timestamp = 2023-09-12 17:23:45.067921
ndims = 64
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 660608
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 6.6721983   2.7232099   6.150583    4.580923    1.5652926   2.6565456
  7.1790314   4.9339914   5.7110434   6.7498174   6.386396    3.9689803
  8.906224    3.806384    4.1225185   9.359665    7.9177184   7.261933
  0.1027934   9.199222    7.196588   10.08044     2.3912797   8.714102
  2.4626331   6.1591697   1.6348177   8.815128    7.787716    5.5076594
  3.3412566   0.7007286   7.2919664   4.3464866   6.6338673   7.1474853
  9.7648      8.511822   -0.5374965   5.0141335   7.365311    0.6638582
  5.9037857   0.7669884   1.383983    0.33108917  8.1157875   2.689867
  4.5051117   9.846115    7.6886387   0.35349095  2.5627694   4.5428576
  5.8595724   2.7118683   9.446846    6.2642756   4.7844443   6.0548897
  8.103386    3.6440284   4.565682    2.645935  ]
Epoch 1/1000
2023-09-12 17:24:18.313 
Epoch 1/1000 
	 loss: 102.2650, MinusLogProbMetric: 102.2650, val_loss: 37.9316, val_MinusLogProbMetric: 37.9316

Epoch 1: val_loss improved from inf to 37.93159, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 33s - loss: 102.2650 - MinusLogProbMetric: 102.2650 - val_loss: 37.9316 - val_MinusLogProbMetric: 37.9316 - lr: 0.0010 - 33s/epoch - 170ms/step
Epoch 2/1000
2023-09-12 17:24:29.645 
Epoch 2/1000 
	 loss: 33.7571, MinusLogProbMetric: 33.7571, val_loss: 31.6586, val_MinusLogProbMetric: 31.6586

Epoch 2: val_loss improved from 37.93159 to 31.65864, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 33.7571 - MinusLogProbMetric: 33.7571 - val_loss: 31.6586 - val_MinusLogProbMetric: 31.6586 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 3/1000
2023-09-12 17:24:40.917 
Epoch 3/1000 
	 loss: 30.9349, MinusLogProbMetric: 30.9349, val_loss: 30.6023, val_MinusLogProbMetric: 30.6023

Epoch 3: val_loss improved from 31.65864 to 30.60235, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 30.9349 - MinusLogProbMetric: 30.9349 - val_loss: 30.6023 - val_MinusLogProbMetric: 30.6023 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 4/1000
2023-09-12 17:24:52.142 
Epoch 4/1000 
	 loss: 29.9018, MinusLogProbMetric: 29.9018, val_loss: 30.1376, val_MinusLogProbMetric: 30.1376

Epoch 4: val_loss improved from 30.60235 to 30.13759, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 29.9018 - MinusLogProbMetric: 29.9018 - val_loss: 30.1376 - val_MinusLogProbMetric: 30.1376 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 5/1000
2023-09-12 17:25:03.700 
Epoch 5/1000 
	 loss: 29.5052, MinusLogProbMetric: 29.5052, val_loss: 29.4356, val_MinusLogProbMetric: 29.4356

Epoch 5: val_loss improved from 30.13759 to 29.43563, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 29.5052 - MinusLogProbMetric: 29.5052 - val_loss: 29.4356 - val_MinusLogProbMetric: 29.4356 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 6/1000
2023-09-12 17:25:15.108 
Epoch 6/1000 
	 loss: 29.1465, MinusLogProbMetric: 29.1465, val_loss: 28.9140, val_MinusLogProbMetric: 28.9140

Epoch 6: val_loss improved from 29.43563 to 28.91402, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 29.1465 - MinusLogProbMetric: 29.1465 - val_loss: 28.9140 - val_MinusLogProbMetric: 28.9140 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 7/1000
2023-09-12 17:25:26.701 
Epoch 7/1000 
	 loss: 28.9062, MinusLogProbMetric: 28.9062, val_loss: 29.0297, val_MinusLogProbMetric: 29.0297

Epoch 7: val_loss did not improve from 28.91402
196/196 - 11s - loss: 28.9062 - MinusLogProbMetric: 28.9062 - val_loss: 29.0297 - val_MinusLogProbMetric: 29.0297 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 8/1000
2023-09-12 17:25:37.764 
Epoch 8/1000 
	 loss: 28.7825, MinusLogProbMetric: 28.7825, val_loss: 29.0323, val_MinusLogProbMetric: 29.0323

Epoch 8: val_loss did not improve from 28.91402
196/196 - 11s - loss: 28.7825 - MinusLogProbMetric: 28.7825 - val_loss: 29.0323 - val_MinusLogProbMetric: 29.0323 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 9/1000
2023-09-12 17:25:48.810 
Epoch 9/1000 
	 loss: 28.6681, MinusLogProbMetric: 28.6681, val_loss: 28.5727, val_MinusLogProbMetric: 28.5727

Epoch 9: val_loss improved from 28.91402 to 28.57265, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 28.6681 - MinusLogProbMetric: 28.6681 - val_loss: 28.5727 - val_MinusLogProbMetric: 28.5727 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 10/1000
2023-09-12 17:26:00.286 
Epoch 10/1000 
	 loss: 28.5837, MinusLogProbMetric: 28.5837, val_loss: 28.4896, val_MinusLogProbMetric: 28.4896

Epoch 10: val_loss improved from 28.57265 to 28.48961, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 28.5837 - MinusLogProbMetric: 28.5837 - val_loss: 28.4896 - val_MinusLogProbMetric: 28.4896 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 11/1000
2023-09-12 17:26:11.761 
Epoch 11/1000 
	 loss: 28.4704, MinusLogProbMetric: 28.4704, val_loss: 28.6873, val_MinusLogProbMetric: 28.6873

Epoch 11: val_loss did not improve from 28.48961
196/196 - 11s - loss: 28.4704 - MinusLogProbMetric: 28.4704 - val_loss: 28.6873 - val_MinusLogProbMetric: 28.6873 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 12/1000
2023-09-12 17:26:23.110 
Epoch 12/1000 
	 loss: 28.3758, MinusLogProbMetric: 28.3758, val_loss: 28.5424, val_MinusLogProbMetric: 28.5424

Epoch 12: val_loss did not improve from 28.48961
196/196 - 11s - loss: 28.3758 - MinusLogProbMetric: 28.3758 - val_loss: 28.5424 - val_MinusLogProbMetric: 28.5424 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 13/1000
2023-09-12 17:26:33.356 
Epoch 13/1000 
	 loss: 28.3188, MinusLogProbMetric: 28.3188, val_loss: 28.1818, val_MinusLogProbMetric: 28.1818

Epoch 13: val_loss improved from 28.48961 to 28.18181, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 10s - loss: 28.3188 - MinusLogProbMetric: 28.3188 - val_loss: 28.1818 - val_MinusLogProbMetric: 28.1818 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 14/1000
2023-09-12 17:26:44.498 
Epoch 14/1000 
	 loss: 28.2745, MinusLogProbMetric: 28.2745, val_loss: 28.3210, val_MinusLogProbMetric: 28.3210

Epoch 14: val_loss did not improve from 28.18181
196/196 - 11s - loss: 28.2745 - MinusLogProbMetric: 28.2745 - val_loss: 28.3210 - val_MinusLogProbMetric: 28.3210 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 15/1000
2023-09-12 17:26:55.412 
Epoch 15/1000 
	 loss: 28.2087, MinusLogProbMetric: 28.2087, val_loss: 28.1886, val_MinusLogProbMetric: 28.1886

Epoch 15: val_loss did not improve from 28.18181
196/196 - 11s - loss: 28.2087 - MinusLogProbMetric: 28.2087 - val_loss: 28.1886 - val_MinusLogProbMetric: 28.1886 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 16/1000
2023-09-12 17:27:05.170 
Epoch 16/1000 
	 loss: 28.1573, MinusLogProbMetric: 28.1573, val_loss: 28.2822, val_MinusLogProbMetric: 28.2822

Epoch 16: val_loss did not improve from 28.18181
196/196 - 10s - loss: 28.1573 - MinusLogProbMetric: 28.1573 - val_loss: 28.2822 - val_MinusLogProbMetric: 28.2822 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 17/1000
2023-09-12 17:27:16.002 
Epoch 17/1000 
	 loss: 28.1356, MinusLogProbMetric: 28.1356, val_loss: 28.1994, val_MinusLogProbMetric: 28.1994

Epoch 17: val_loss did not improve from 28.18181
196/196 - 11s - loss: 28.1356 - MinusLogProbMetric: 28.1356 - val_loss: 28.1994 - val_MinusLogProbMetric: 28.1994 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 18/1000
2023-09-12 17:27:27.318 
Epoch 18/1000 
	 loss: 28.0859, MinusLogProbMetric: 28.0859, val_loss: 28.0445, val_MinusLogProbMetric: 28.0445

Epoch 18: val_loss improved from 28.18181 to 28.04447, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 28.0859 - MinusLogProbMetric: 28.0859 - val_loss: 28.0445 - val_MinusLogProbMetric: 28.0445 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 19/1000
2023-09-12 17:27:38.593 
Epoch 19/1000 
	 loss: 28.0673, MinusLogProbMetric: 28.0673, val_loss: 28.3332, val_MinusLogProbMetric: 28.3332

Epoch 19: val_loss did not improve from 28.04447
196/196 - 11s - loss: 28.0673 - MinusLogProbMetric: 28.0673 - val_loss: 28.3332 - val_MinusLogProbMetric: 28.3332 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 20/1000
2023-09-12 17:27:48.234 
Epoch 20/1000 
	 loss: 28.0569, MinusLogProbMetric: 28.0569, val_loss: 28.0975, val_MinusLogProbMetric: 28.0975

Epoch 20: val_loss did not improve from 28.04447
196/196 - 10s - loss: 28.0569 - MinusLogProbMetric: 28.0569 - val_loss: 28.0975 - val_MinusLogProbMetric: 28.0975 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 21/1000
2023-09-12 17:27:58.688 
Epoch 21/1000 
	 loss: 27.9930, MinusLogProbMetric: 27.9930, val_loss: 27.9510, val_MinusLogProbMetric: 27.9510

Epoch 21: val_loss improved from 28.04447 to 27.95096, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.9930 - MinusLogProbMetric: 27.9930 - val_loss: 27.9510 - val_MinusLogProbMetric: 27.9510 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 22/1000
2023-09-12 17:28:09.922 
Epoch 22/1000 
	 loss: 27.9921, MinusLogProbMetric: 27.9921, val_loss: 28.2125, val_MinusLogProbMetric: 28.2125

Epoch 22: val_loss did not improve from 27.95096
196/196 - 11s - loss: 27.9921 - MinusLogProbMetric: 27.9921 - val_loss: 28.2125 - val_MinusLogProbMetric: 28.2125 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 23/1000
2023-09-12 17:28:21.070 
Epoch 23/1000 
	 loss: 27.9753, MinusLogProbMetric: 27.9753, val_loss: 28.0829, val_MinusLogProbMetric: 28.0829

Epoch 23: val_loss did not improve from 27.95096
196/196 - 11s - loss: 27.9753 - MinusLogProbMetric: 27.9753 - val_loss: 28.0829 - val_MinusLogProbMetric: 28.0829 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 24/1000
2023-09-12 17:28:31.958 
Epoch 24/1000 
	 loss: 27.9573, MinusLogProbMetric: 27.9573, val_loss: 28.0406, val_MinusLogProbMetric: 28.0406

Epoch 24: val_loss did not improve from 27.95096
196/196 - 11s - loss: 27.9573 - MinusLogProbMetric: 27.9573 - val_loss: 28.0406 - val_MinusLogProbMetric: 28.0406 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 25/1000
2023-09-12 17:28:43.370 
Epoch 25/1000 
	 loss: 27.9246, MinusLogProbMetric: 27.9246, val_loss: 28.0805, val_MinusLogProbMetric: 28.0805

Epoch 25: val_loss did not improve from 27.95096
196/196 - 11s - loss: 27.9246 - MinusLogProbMetric: 27.9246 - val_loss: 28.0805 - val_MinusLogProbMetric: 28.0805 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 26/1000
2023-09-12 17:28:54.697 
Epoch 26/1000 
	 loss: 27.9467, MinusLogProbMetric: 27.9467, val_loss: 27.9369, val_MinusLogProbMetric: 27.9369

Epoch 26: val_loss improved from 27.95096 to 27.93685, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.9467 - MinusLogProbMetric: 27.9467 - val_loss: 27.9369 - val_MinusLogProbMetric: 27.9369 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 27/1000
2023-09-12 17:29:05.745 
Epoch 27/1000 
	 loss: 27.9249, MinusLogProbMetric: 27.9249, val_loss: 27.9453, val_MinusLogProbMetric: 27.9453

Epoch 27: val_loss did not improve from 27.93685
196/196 - 11s - loss: 27.9249 - MinusLogProbMetric: 27.9249 - val_loss: 27.9453 - val_MinusLogProbMetric: 27.9453 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 28/1000
2023-09-12 17:29:16.678 
Epoch 28/1000 
	 loss: 27.8747, MinusLogProbMetric: 27.8747, val_loss: 27.9207, val_MinusLogProbMetric: 27.9207

Epoch 28: val_loss improved from 27.93685 to 27.92068, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.8747 - MinusLogProbMetric: 27.8747 - val_loss: 27.9207 - val_MinusLogProbMetric: 27.9207 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 29/1000
2023-09-12 17:29:27.574 
Epoch 29/1000 
	 loss: 27.8452, MinusLogProbMetric: 27.8452, val_loss: 28.0514, val_MinusLogProbMetric: 28.0514

Epoch 29: val_loss did not improve from 27.92068
196/196 - 11s - loss: 27.8452 - MinusLogProbMetric: 27.8452 - val_loss: 28.0514 - val_MinusLogProbMetric: 28.0514 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 30/1000
2023-09-12 17:29:37.101 
Epoch 30/1000 
	 loss: 27.8500, MinusLogProbMetric: 27.8500, val_loss: 27.9398, val_MinusLogProbMetric: 27.9398

Epoch 30: val_loss did not improve from 27.92068
196/196 - 10s - loss: 27.8500 - MinusLogProbMetric: 27.8500 - val_loss: 27.9398 - val_MinusLogProbMetric: 27.9398 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 31/1000
2023-09-12 17:29:46.719 
Epoch 31/1000 
	 loss: 27.8504, MinusLogProbMetric: 27.8504, val_loss: 27.9548, val_MinusLogProbMetric: 27.9548

Epoch 31: val_loss did not improve from 27.92068
196/196 - 10s - loss: 27.8504 - MinusLogProbMetric: 27.8504 - val_loss: 27.9548 - val_MinusLogProbMetric: 27.9548 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 32/1000
2023-09-12 17:29:57.643 
Epoch 32/1000 
	 loss: 27.8259, MinusLogProbMetric: 27.8259, val_loss: 27.9948, val_MinusLogProbMetric: 27.9948

Epoch 32: val_loss did not improve from 27.92068
196/196 - 11s - loss: 27.8259 - MinusLogProbMetric: 27.8259 - val_loss: 27.9948 - val_MinusLogProbMetric: 27.9948 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 33/1000
2023-09-12 17:30:08.264 
Epoch 33/1000 
	 loss: 27.8116, MinusLogProbMetric: 27.8116, val_loss: 27.9675, val_MinusLogProbMetric: 27.9675

Epoch 33: val_loss did not improve from 27.92068
196/196 - 11s - loss: 27.8116 - MinusLogProbMetric: 27.8116 - val_loss: 27.9675 - val_MinusLogProbMetric: 27.9675 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 34/1000
2023-09-12 17:30:17.631 
Epoch 34/1000 
	 loss: 27.8277, MinusLogProbMetric: 27.8277, val_loss: 27.8613, val_MinusLogProbMetric: 27.8613

Epoch 34: val_loss improved from 27.92068 to 27.86127, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 9s - loss: 27.8277 - MinusLogProbMetric: 27.8277 - val_loss: 27.8613 - val_MinusLogProbMetric: 27.8613 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 35/1000
2023-09-12 17:30:27.173 
Epoch 35/1000 
	 loss: 27.7956, MinusLogProbMetric: 27.7956, val_loss: 27.9786, val_MinusLogProbMetric: 27.9786

Epoch 35: val_loss did not improve from 27.86127
196/196 - 9s - loss: 27.7956 - MinusLogProbMetric: 27.7956 - val_loss: 27.9786 - val_MinusLogProbMetric: 27.9786 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 36/1000
2023-09-12 17:30:36.617 
Epoch 36/1000 
	 loss: 27.8027, MinusLogProbMetric: 27.8027, val_loss: 27.9178, val_MinusLogProbMetric: 27.9178

Epoch 36: val_loss did not improve from 27.86127
196/196 - 9s - loss: 27.8027 - MinusLogProbMetric: 27.8027 - val_loss: 27.9178 - val_MinusLogProbMetric: 27.9178 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 37/1000
2023-09-12 17:30:45.920 
Epoch 37/1000 
	 loss: 27.7971, MinusLogProbMetric: 27.7971, val_loss: 28.2932, val_MinusLogProbMetric: 28.2932

Epoch 37: val_loss did not improve from 27.86127
196/196 - 9s - loss: 27.7971 - MinusLogProbMetric: 27.7971 - val_loss: 28.2932 - val_MinusLogProbMetric: 28.2932 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 38/1000
2023-09-12 17:30:56.834 
Epoch 38/1000 
	 loss: 27.8174, MinusLogProbMetric: 27.8174, val_loss: 28.0482, val_MinusLogProbMetric: 28.0482

Epoch 38: val_loss did not improve from 27.86127
196/196 - 11s - loss: 27.8174 - MinusLogProbMetric: 27.8174 - val_loss: 28.0482 - val_MinusLogProbMetric: 28.0482 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 39/1000
2023-09-12 17:31:07.599 
Epoch 39/1000 
	 loss: 27.7531, MinusLogProbMetric: 27.7531, val_loss: 27.7678, val_MinusLogProbMetric: 27.7678

Epoch 39: val_loss improved from 27.86127 to 27.76777, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.7531 - MinusLogProbMetric: 27.7531 - val_loss: 27.7678 - val_MinusLogProbMetric: 27.7678 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 40/1000
2023-09-12 17:31:17.962 
Epoch 40/1000 
	 loss: 27.7681, MinusLogProbMetric: 27.7681, val_loss: 27.8196, val_MinusLogProbMetric: 27.8196

Epoch 40: val_loss did not improve from 27.76777
196/196 - 10s - loss: 27.7681 - MinusLogProbMetric: 27.7681 - val_loss: 27.8196 - val_MinusLogProbMetric: 27.8196 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 41/1000
2023-09-12 17:31:27.385 
Epoch 41/1000 
	 loss: 27.7639, MinusLogProbMetric: 27.7639, val_loss: 27.9219, val_MinusLogProbMetric: 27.9219

Epoch 41: val_loss did not improve from 27.76777
196/196 - 9s - loss: 27.7639 - MinusLogProbMetric: 27.7639 - val_loss: 27.9219 - val_MinusLogProbMetric: 27.9219 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 42/1000
2023-09-12 17:31:37.678 
Epoch 42/1000 
	 loss: 27.7705, MinusLogProbMetric: 27.7705, val_loss: 27.8491, val_MinusLogProbMetric: 27.8491

Epoch 42: val_loss did not improve from 27.76777
196/196 - 10s - loss: 27.7705 - MinusLogProbMetric: 27.7705 - val_loss: 27.8491 - val_MinusLogProbMetric: 27.8491 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 43/1000
2023-09-12 17:31:48.186 
Epoch 43/1000 
	 loss: 27.7448, MinusLogProbMetric: 27.7448, val_loss: 27.8222, val_MinusLogProbMetric: 27.8222

Epoch 43: val_loss did not improve from 27.76777
196/196 - 11s - loss: 27.7448 - MinusLogProbMetric: 27.7448 - val_loss: 27.8222 - val_MinusLogProbMetric: 27.8222 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 44/1000
2023-09-12 17:31:57.533 
Epoch 44/1000 
	 loss: 27.7433, MinusLogProbMetric: 27.7433, val_loss: 27.8436, val_MinusLogProbMetric: 27.8436

Epoch 44: val_loss did not improve from 27.76777
196/196 - 9s - loss: 27.7433 - MinusLogProbMetric: 27.7433 - val_loss: 27.8436 - val_MinusLogProbMetric: 27.8436 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 45/1000
2023-09-12 17:32:08.737 
Epoch 45/1000 
	 loss: 27.7470, MinusLogProbMetric: 27.7470, val_loss: 27.7963, val_MinusLogProbMetric: 27.7963

Epoch 45: val_loss did not improve from 27.76777
196/196 - 11s - loss: 27.7470 - MinusLogProbMetric: 27.7470 - val_loss: 27.7963 - val_MinusLogProbMetric: 27.7963 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 46/1000
2023-09-12 17:32:18.127 
Epoch 46/1000 
	 loss: 27.7387, MinusLogProbMetric: 27.7387, val_loss: 27.7817, val_MinusLogProbMetric: 27.7817

Epoch 46: val_loss did not improve from 27.76777
196/196 - 9s - loss: 27.7387 - MinusLogProbMetric: 27.7387 - val_loss: 27.7817 - val_MinusLogProbMetric: 27.7817 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 47/1000
2023-09-12 17:32:27.456 
Epoch 47/1000 
	 loss: 27.7134, MinusLogProbMetric: 27.7134, val_loss: 27.7561, val_MinusLogProbMetric: 27.7561

Epoch 47: val_loss improved from 27.76777 to 27.75612, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 9s - loss: 27.7134 - MinusLogProbMetric: 27.7134 - val_loss: 27.7561 - val_MinusLogProbMetric: 27.7561 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 48/1000
2023-09-12 17:32:37.084 
Epoch 48/1000 
	 loss: 27.7372, MinusLogProbMetric: 27.7372, val_loss: 27.8363, val_MinusLogProbMetric: 27.8363

Epoch 48: val_loss did not improve from 27.75612
196/196 - 9s - loss: 27.7372 - MinusLogProbMetric: 27.7372 - val_loss: 27.8363 - val_MinusLogProbMetric: 27.8363 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 49/1000
2023-09-12 17:32:46.981 
Epoch 49/1000 
	 loss: 27.6971, MinusLogProbMetric: 27.6971, val_loss: 27.8008, val_MinusLogProbMetric: 27.8008

Epoch 49: val_loss did not improve from 27.75612
196/196 - 10s - loss: 27.6971 - MinusLogProbMetric: 27.6971 - val_loss: 27.8008 - val_MinusLogProbMetric: 27.8008 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 50/1000
2023-09-12 17:32:56.723 
Epoch 50/1000 
	 loss: 27.7112, MinusLogProbMetric: 27.7112, val_loss: 28.1869, val_MinusLogProbMetric: 28.1869

Epoch 50: val_loss did not improve from 27.75612
196/196 - 10s - loss: 27.7112 - MinusLogProbMetric: 27.7112 - val_loss: 28.1869 - val_MinusLogProbMetric: 28.1869 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 51/1000
2023-09-12 17:33:06.387 
Epoch 51/1000 
	 loss: 27.6961, MinusLogProbMetric: 27.6961, val_loss: 27.9317, val_MinusLogProbMetric: 27.9317

Epoch 51: val_loss did not improve from 27.75612
196/196 - 10s - loss: 27.6961 - MinusLogProbMetric: 27.6961 - val_loss: 27.9317 - val_MinusLogProbMetric: 27.9317 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 52/1000
2023-09-12 17:33:15.973 
Epoch 52/1000 
	 loss: 27.7036, MinusLogProbMetric: 27.7036, val_loss: 27.8249, val_MinusLogProbMetric: 27.8249

Epoch 52: val_loss did not improve from 27.75612
196/196 - 10s - loss: 27.7036 - MinusLogProbMetric: 27.7036 - val_loss: 27.8249 - val_MinusLogProbMetric: 27.8249 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 53/1000
2023-09-12 17:33:25.489 
Epoch 53/1000 
	 loss: 27.6837, MinusLogProbMetric: 27.6837, val_loss: 27.8062, val_MinusLogProbMetric: 27.8062

Epoch 53: val_loss did not improve from 27.75612
196/196 - 10s - loss: 27.6837 - MinusLogProbMetric: 27.6837 - val_loss: 27.8062 - val_MinusLogProbMetric: 27.8062 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 54/1000
2023-09-12 17:33:34.872 
Epoch 54/1000 
	 loss: 27.6955, MinusLogProbMetric: 27.6955, val_loss: 27.7062, val_MinusLogProbMetric: 27.7062

Epoch 54: val_loss improved from 27.75612 to 27.70623, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 10s - loss: 27.6955 - MinusLogProbMetric: 27.6955 - val_loss: 27.7062 - val_MinusLogProbMetric: 27.7062 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 55/1000
2023-09-12 17:33:44.449 
Epoch 55/1000 
	 loss: 27.6684, MinusLogProbMetric: 27.6684, val_loss: 27.7169, val_MinusLogProbMetric: 27.7169

Epoch 55: val_loss did not improve from 27.70623
196/196 - 9s - loss: 27.6684 - MinusLogProbMetric: 27.6684 - val_loss: 27.7169 - val_MinusLogProbMetric: 27.7169 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 56/1000
2023-09-12 17:33:53.944 
Epoch 56/1000 
	 loss: 27.6787, MinusLogProbMetric: 27.6787, val_loss: 27.8263, val_MinusLogProbMetric: 27.8263

Epoch 56: val_loss did not improve from 27.70623
196/196 - 9s - loss: 27.6787 - MinusLogProbMetric: 27.6787 - val_loss: 27.8263 - val_MinusLogProbMetric: 27.8263 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 57/1000
2023-09-12 17:34:03.073 
Epoch 57/1000 
	 loss: 27.7035, MinusLogProbMetric: 27.7035, val_loss: 27.7175, val_MinusLogProbMetric: 27.7175

Epoch 57: val_loss did not improve from 27.70623
196/196 - 9s - loss: 27.7035 - MinusLogProbMetric: 27.7035 - val_loss: 27.7175 - val_MinusLogProbMetric: 27.7175 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 58/1000
2023-09-12 17:34:12.259 
Epoch 58/1000 
	 loss: 27.6909, MinusLogProbMetric: 27.6909, val_loss: 27.7544, val_MinusLogProbMetric: 27.7544

Epoch 58: val_loss did not improve from 27.70623
196/196 - 9s - loss: 27.6909 - MinusLogProbMetric: 27.6909 - val_loss: 27.7544 - val_MinusLogProbMetric: 27.7544 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 59/1000
2023-09-12 17:34:21.376 
Epoch 59/1000 
	 loss: 27.6667, MinusLogProbMetric: 27.6667, val_loss: 27.8206, val_MinusLogProbMetric: 27.8206

Epoch 59: val_loss did not improve from 27.70623
196/196 - 9s - loss: 27.6667 - MinusLogProbMetric: 27.6667 - val_loss: 27.8206 - val_MinusLogProbMetric: 27.8206 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 60/1000
2023-09-12 17:34:30.911 
Epoch 60/1000 
	 loss: 27.6812, MinusLogProbMetric: 27.6812, val_loss: 27.8156, val_MinusLogProbMetric: 27.8156

Epoch 60: val_loss did not improve from 27.70623
196/196 - 10s - loss: 27.6812 - MinusLogProbMetric: 27.6812 - val_loss: 27.8156 - val_MinusLogProbMetric: 27.8156 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 61/1000
2023-09-12 17:34:40.614 
Epoch 61/1000 
	 loss: 27.6623, MinusLogProbMetric: 27.6623, val_loss: 27.7146, val_MinusLogProbMetric: 27.7146

Epoch 61: val_loss did not improve from 27.70623
196/196 - 10s - loss: 27.6623 - MinusLogProbMetric: 27.6623 - val_loss: 27.7146 - val_MinusLogProbMetric: 27.7146 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 62/1000
2023-09-12 17:34:51.468 
Epoch 62/1000 
	 loss: 27.6462, MinusLogProbMetric: 27.6462, val_loss: 27.8709, val_MinusLogProbMetric: 27.8709

Epoch 62: val_loss did not improve from 27.70623
196/196 - 11s - loss: 27.6462 - MinusLogProbMetric: 27.6462 - val_loss: 27.8709 - val_MinusLogProbMetric: 27.8709 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 63/1000
2023-09-12 17:35:01.190 
Epoch 63/1000 
	 loss: 27.6719, MinusLogProbMetric: 27.6719, val_loss: 27.6553, val_MinusLogProbMetric: 27.6553

Epoch 63: val_loss improved from 27.70623 to 27.65529, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 10s - loss: 27.6719 - MinusLogProbMetric: 27.6719 - val_loss: 27.6553 - val_MinusLogProbMetric: 27.6553 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 64/1000
2023-09-12 17:35:12.536 
Epoch 64/1000 
	 loss: 27.6424, MinusLogProbMetric: 27.6424, val_loss: 27.8168, val_MinusLogProbMetric: 27.8168

Epoch 64: val_loss did not improve from 27.65529
196/196 - 11s - loss: 27.6424 - MinusLogProbMetric: 27.6424 - val_loss: 27.8168 - val_MinusLogProbMetric: 27.8168 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 65/1000
2023-09-12 17:35:24.213 
Epoch 65/1000 
	 loss: 27.6446, MinusLogProbMetric: 27.6446, val_loss: 27.8074, val_MinusLogProbMetric: 27.8074

Epoch 65: val_loss did not improve from 27.65529
196/196 - 12s - loss: 27.6446 - MinusLogProbMetric: 27.6446 - val_loss: 27.8074 - val_MinusLogProbMetric: 27.8074 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 66/1000
2023-09-12 17:35:35.522 
Epoch 66/1000 
	 loss: 27.6530, MinusLogProbMetric: 27.6530, val_loss: 27.7930, val_MinusLogProbMetric: 27.7930

Epoch 66: val_loss did not improve from 27.65529
196/196 - 11s - loss: 27.6530 - MinusLogProbMetric: 27.6530 - val_loss: 27.7930 - val_MinusLogProbMetric: 27.7930 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 67/1000
2023-09-12 17:35:45.281 
Epoch 67/1000 
	 loss: 27.6463, MinusLogProbMetric: 27.6463, val_loss: 27.7082, val_MinusLogProbMetric: 27.7082

Epoch 67: val_loss did not improve from 27.65529
196/196 - 10s - loss: 27.6463 - MinusLogProbMetric: 27.6463 - val_loss: 27.7082 - val_MinusLogProbMetric: 27.7082 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 68/1000
2023-09-12 17:35:54.400 
Epoch 68/1000 
	 loss: 27.6353, MinusLogProbMetric: 27.6353, val_loss: 27.7038, val_MinusLogProbMetric: 27.7038

Epoch 68: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6353 - MinusLogProbMetric: 27.6353 - val_loss: 27.7038 - val_MinusLogProbMetric: 27.7038 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 69/1000
2023-09-12 17:36:03.615 
Epoch 69/1000 
	 loss: 27.6344, MinusLogProbMetric: 27.6344, val_loss: 27.6966, val_MinusLogProbMetric: 27.6966

Epoch 69: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6344 - MinusLogProbMetric: 27.6344 - val_loss: 27.6966 - val_MinusLogProbMetric: 27.6966 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 70/1000
2023-09-12 17:36:12.760 
Epoch 70/1000 
	 loss: 27.6308, MinusLogProbMetric: 27.6308, val_loss: 27.9001, val_MinusLogProbMetric: 27.9001

Epoch 70: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6308 - MinusLogProbMetric: 27.6308 - val_loss: 27.9001 - val_MinusLogProbMetric: 27.9001 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 71/1000
2023-09-12 17:36:21.987 
Epoch 71/1000 
	 loss: 27.6263, MinusLogProbMetric: 27.6263, val_loss: 27.7088, val_MinusLogProbMetric: 27.7088

Epoch 71: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6263 - MinusLogProbMetric: 27.6263 - val_loss: 27.7088 - val_MinusLogProbMetric: 27.7088 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 72/1000
2023-09-12 17:36:31.101 
Epoch 72/1000 
	 loss: 27.6405, MinusLogProbMetric: 27.6405, val_loss: 27.6935, val_MinusLogProbMetric: 27.6935

Epoch 72: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6405 - MinusLogProbMetric: 27.6405 - val_loss: 27.6935 - val_MinusLogProbMetric: 27.6935 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 73/1000
2023-09-12 17:36:40.068 
Epoch 73/1000 
	 loss: 27.6225, MinusLogProbMetric: 27.6225, val_loss: 27.7273, val_MinusLogProbMetric: 27.7273

Epoch 73: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6225 - MinusLogProbMetric: 27.6225 - val_loss: 27.7273 - val_MinusLogProbMetric: 27.7273 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 74/1000
2023-09-12 17:36:49.037 
Epoch 74/1000 
	 loss: 27.6270, MinusLogProbMetric: 27.6270, val_loss: 27.7914, val_MinusLogProbMetric: 27.7914

Epoch 74: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6270 - MinusLogProbMetric: 27.6270 - val_loss: 27.7914 - val_MinusLogProbMetric: 27.7914 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 75/1000
2023-09-12 17:36:58.016 
Epoch 75/1000 
	 loss: 27.6291, MinusLogProbMetric: 27.6291, val_loss: 27.6671, val_MinusLogProbMetric: 27.6671

Epoch 75: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6291 - MinusLogProbMetric: 27.6291 - val_loss: 27.6671 - val_MinusLogProbMetric: 27.6671 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 76/1000
2023-09-12 17:37:07.166 
Epoch 76/1000 
	 loss: 27.6334, MinusLogProbMetric: 27.6334, val_loss: 27.7051, val_MinusLogProbMetric: 27.7051

Epoch 76: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6334 - MinusLogProbMetric: 27.6334 - val_loss: 27.7051 - val_MinusLogProbMetric: 27.7051 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 77/1000
2023-09-12 17:37:16.100 
Epoch 77/1000 
	 loss: 27.6072, MinusLogProbMetric: 27.6072, val_loss: 27.6948, val_MinusLogProbMetric: 27.6948

Epoch 77: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6072 - MinusLogProbMetric: 27.6072 - val_loss: 27.6948 - val_MinusLogProbMetric: 27.6948 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 78/1000
2023-09-12 17:37:25.114 
Epoch 78/1000 
	 loss: 27.6115, MinusLogProbMetric: 27.6115, val_loss: 27.7100, val_MinusLogProbMetric: 27.7100

Epoch 78: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6115 - MinusLogProbMetric: 27.6115 - val_loss: 27.7100 - val_MinusLogProbMetric: 27.7100 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 79/1000
2023-09-12 17:37:34.256 
Epoch 79/1000 
	 loss: 27.6131, MinusLogProbMetric: 27.6131, val_loss: 27.6672, val_MinusLogProbMetric: 27.6672

Epoch 79: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6131 - MinusLogProbMetric: 27.6131 - val_loss: 27.6672 - val_MinusLogProbMetric: 27.6672 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 80/1000
2023-09-12 17:37:43.700 
Epoch 80/1000 
	 loss: 27.6077, MinusLogProbMetric: 27.6077, val_loss: 27.6991, val_MinusLogProbMetric: 27.6991

Epoch 80: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6077 - MinusLogProbMetric: 27.6077 - val_loss: 27.6991 - val_MinusLogProbMetric: 27.6991 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 81/1000
2023-09-12 17:37:53.189 
Epoch 81/1000 
	 loss: 27.6221, MinusLogProbMetric: 27.6221, val_loss: 27.6581, val_MinusLogProbMetric: 27.6581

Epoch 81: val_loss did not improve from 27.65529
196/196 - 9s - loss: 27.6221 - MinusLogProbMetric: 27.6221 - val_loss: 27.6581 - val_MinusLogProbMetric: 27.6581 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 82/1000
2023-09-12 17:38:02.903 
Epoch 82/1000 
	 loss: 27.6205, MinusLogProbMetric: 27.6205, val_loss: 27.7789, val_MinusLogProbMetric: 27.7789

Epoch 82: val_loss did not improve from 27.65529
196/196 - 10s - loss: 27.6205 - MinusLogProbMetric: 27.6205 - val_loss: 27.7789 - val_MinusLogProbMetric: 27.7789 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 83/1000
2023-09-12 17:38:12.644 
Epoch 83/1000 
	 loss: 27.6181, MinusLogProbMetric: 27.6181, val_loss: 27.8212, val_MinusLogProbMetric: 27.8212

Epoch 83: val_loss did not improve from 27.65529
196/196 - 10s - loss: 27.6181 - MinusLogProbMetric: 27.6181 - val_loss: 27.8212 - val_MinusLogProbMetric: 27.8212 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 84/1000
2023-09-12 17:38:22.636 
Epoch 84/1000 
	 loss: 27.6007, MinusLogProbMetric: 27.6007, val_loss: 27.7596, val_MinusLogProbMetric: 27.7596

Epoch 84: val_loss did not improve from 27.65529
196/196 - 10s - loss: 27.6007 - MinusLogProbMetric: 27.6007 - val_loss: 27.7596 - val_MinusLogProbMetric: 27.7596 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 85/1000
2023-09-12 17:38:32.504 
Epoch 85/1000 
	 loss: 27.6119, MinusLogProbMetric: 27.6119, val_loss: 27.7803, val_MinusLogProbMetric: 27.7803

Epoch 85: val_loss did not improve from 27.65529
196/196 - 10s - loss: 27.6119 - MinusLogProbMetric: 27.6119 - val_loss: 27.7803 - val_MinusLogProbMetric: 27.7803 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 86/1000
2023-09-12 17:38:42.325 
Epoch 86/1000 
	 loss: 27.6059, MinusLogProbMetric: 27.6059, val_loss: 27.7041, val_MinusLogProbMetric: 27.7041

Epoch 86: val_loss did not improve from 27.65529
196/196 - 10s - loss: 27.6059 - MinusLogProbMetric: 27.6059 - val_loss: 27.7041 - val_MinusLogProbMetric: 27.7041 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 87/1000
2023-09-12 17:38:52.566 
Epoch 87/1000 
	 loss: 27.5912, MinusLogProbMetric: 27.5912, val_loss: 27.6430, val_MinusLogProbMetric: 27.6430

Epoch 87: val_loss improved from 27.65529 to 27.64296, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 10s - loss: 27.5912 - MinusLogProbMetric: 27.5912 - val_loss: 27.6430 - val_MinusLogProbMetric: 27.6430 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 88/1000
2023-09-12 17:39:02.617 
Epoch 88/1000 
	 loss: 27.5834, MinusLogProbMetric: 27.5834, val_loss: 27.6810, val_MinusLogProbMetric: 27.6810

Epoch 88: val_loss did not improve from 27.64296
196/196 - 10s - loss: 27.5834 - MinusLogProbMetric: 27.5834 - val_loss: 27.6810 - val_MinusLogProbMetric: 27.6810 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 89/1000
2023-09-12 17:39:14.026 
Epoch 89/1000 
	 loss: 27.6033, MinusLogProbMetric: 27.6033, val_loss: 27.7379, val_MinusLogProbMetric: 27.7379

Epoch 89: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.6033 - MinusLogProbMetric: 27.6033 - val_loss: 27.7379 - val_MinusLogProbMetric: 27.7379 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 90/1000
2023-09-12 17:39:25.354 
Epoch 90/1000 
	 loss: 27.5965, MinusLogProbMetric: 27.5965, val_loss: 27.7446, val_MinusLogProbMetric: 27.7446

Epoch 90: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5965 - MinusLogProbMetric: 27.5965 - val_loss: 27.7446 - val_MinusLogProbMetric: 27.7446 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 91/1000
2023-09-12 17:39:36.561 
Epoch 91/1000 
	 loss: 27.5993, MinusLogProbMetric: 27.5993, val_loss: 27.6703, val_MinusLogProbMetric: 27.6703

Epoch 91: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5993 - MinusLogProbMetric: 27.5993 - val_loss: 27.6703 - val_MinusLogProbMetric: 27.6703 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 92/1000
2023-09-12 17:39:47.826 
Epoch 92/1000 
	 loss: 27.6004, MinusLogProbMetric: 27.6004, val_loss: 27.7348, val_MinusLogProbMetric: 27.7348

Epoch 92: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.6004 - MinusLogProbMetric: 27.6004 - val_loss: 27.7348 - val_MinusLogProbMetric: 27.7348 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 93/1000
2023-09-12 17:39:59.237 
Epoch 93/1000 
	 loss: 27.5944, MinusLogProbMetric: 27.5944, val_loss: 27.7505, val_MinusLogProbMetric: 27.7505

Epoch 93: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5944 - MinusLogProbMetric: 27.5944 - val_loss: 27.7505 - val_MinusLogProbMetric: 27.7505 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 94/1000
2023-09-12 17:40:10.760 
Epoch 94/1000 
	 loss: 27.5863, MinusLogProbMetric: 27.5863, val_loss: 27.7241, val_MinusLogProbMetric: 27.7241

Epoch 94: val_loss did not improve from 27.64296
196/196 - 12s - loss: 27.5863 - MinusLogProbMetric: 27.5863 - val_loss: 27.7241 - val_MinusLogProbMetric: 27.7241 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-12 17:40:21.983 
Epoch 95/1000 
	 loss: 27.5855, MinusLogProbMetric: 27.5855, val_loss: 27.8162, val_MinusLogProbMetric: 27.8162

Epoch 95: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5855 - MinusLogProbMetric: 27.5855 - val_loss: 27.8162 - val_MinusLogProbMetric: 27.8162 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 96/1000
2023-09-12 17:40:33.078 
Epoch 96/1000 
	 loss: 27.5796, MinusLogProbMetric: 27.5796, val_loss: 27.6973, val_MinusLogProbMetric: 27.6973

Epoch 96: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5796 - MinusLogProbMetric: 27.5796 - val_loss: 27.6973 - val_MinusLogProbMetric: 27.6973 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 97/1000
2023-09-12 17:40:44.428 
Epoch 97/1000 
	 loss: 27.5761, MinusLogProbMetric: 27.5761, val_loss: 27.7266, val_MinusLogProbMetric: 27.7266

Epoch 97: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5761 - MinusLogProbMetric: 27.5761 - val_loss: 27.7266 - val_MinusLogProbMetric: 27.7266 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 98/1000
2023-09-12 17:40:55.846 
Epoch 98/1000 
	 loss: 27.5812, MinusLogProbMetric: 27.5812, val_loss: 27.6878, val_MinusLogProbMetric: 27.6878

Epoch 98: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5812 - MinusLogProbMetric: 27.5812 - val_loss: 27.6878 - val_MinusLogProbMetric: 27.6878 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 99/1000
2023-09-12 17:41:07.112 
Epoch 99/1000 
	 loss: 27.5680, MinusLogProbMetric: 27.5680, val_loss: 27.6758, val_MinusLogProbMetric: 27.6758

Epoch 99: val_loss did not improve from 27.64296
196/196 - 11s - loss: 27.5680 - MinusLogProbMetric: 27.5680 - val_loss: 27.6758 - val_MinusLogProbMetric: 27.6758 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 100/1000
2023-09-12 17:41:18.376 
Epoch 100/1000 
	 loss: 27.5777, MinusLogProbMetric: 27.5777, val_loss: 27.6384, val_MinusLogProbMetric: 27.6384

Epoch 100: val_loss improved from 27.64296 to 27.63844, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.5777 - MinusLogProbMetric: 27.5777 - val_loss: 27.6384 - val_MinusLogProbMetric: 27.6384 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 101/1000
2023-09-12 17:41:30.061 
Epoch 101/1000 
	 loss: 27.5692, MinusLogProbMetric: 27.5692, val_loss: 27.6324, val_MinusLogProbMetric: 27.6324

Epoch 101: val_loss improved from 27.63844 to 27.63243, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.5692 - MinusLogProbMetric: 27.5692 - val_loss: 27.6324 - val_MinusLogProbMetric: 27.6324 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 102/1000
2023-09-12 17:41:41.097 
Epoch 102/1000 
	 loss: 27.5700, MinusLogProbMetric: 27.5700, val_loss: 27.6955, val_MinusLogProbMetric: 27.6955

Epoch 102: val_loss did not improve from 27.63243
196/196 - 11s - loss: 27.5700 - MinusLogProbMetric: 27.5700 - val_loss: 27.6955 - val_MinusLogProbMetric: 27.6955 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 103/1000
2023-09-12 17:41:52.149 
Epoch 103/1000 
	 loss: 27.5684, MinusLogProbMetric: 27.5684, val_loss: 27.8217, val_MinusLogProbMetric: 27.8217

Epoch 103: val_loss did not improve from 27.63243
196/196 - 11s - loss: 27.5684 - MinusLogProbMetric: 27.5684 - val_loss: 27.8217 - val_MinusLogProbMetric: 27.8217 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 104/1000
2023-09-12 17:42:03.511 
Epoch 104/1000 
	 loss: 27.5707, MinusLogProbMetric: 27.5707, val_loss: 27.6286, val_MinusLogProbMetric: 27.6286

Epoch 104: val_loss improved from 27.63243 to 27.62864, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.5707 - MinusLogProbMetric: 27.5707 - val_loss: 27.6286 - val_MinusLogProbMetric: 27.6286 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 105/1000
2023-09-12 17:42:15.150 
Epoch 105/1000 
	 loss: 27.5701, MinusLogProbMetric: 27.5701, val_loss: 27.6641, val_MinusLogProbMetric: 27.6641

Epoch 105: val_loss did not improve from 27.62864
196/196 - 12s - loss: 27.5701 - MinusLogProbMetric: 27.5701 - val_loss: 27.6641 - val_MinusLogProbMetric: 27.6641 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 106/1000
2023-09-12 17:42:26.719 
Epoch 106/1000 
	 loss: 27.5569, MinusLogProbMetric: 27.5569, val_loss: 27.7428, val_MinusLogProbMetric: 27.7428

Epoch 106: val_loss did not improve from 27.62864
196/196 - 12s - loss: 27.5569 - MinusLogProbMetric: 27.5569 - val_loss: 27.7428 - val_MinusLogProbMetric: 27.7428 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 107/1000
2023-09-12 17:42:38.269 
Epoch 107/1000 
	 loss: 27.5671, MinusLogProbMetric: 27.5671, val_loss: 27.6762, val_MinusLogProbMetric: 27.6762

Epoch 107: val_loss did not improve from 27.62864
196/196 - 12s - loss: 27.5671 - MinusLogProbMetric: 27.5671 - val_loss: 27.6762 - val_MinusLogProbMetric: 27.6762 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 108/1000
2023-09-12 17:42:49.928 
Epoch 108/1000 
	 loss: 27.5569, MinusLogProbMetric: 27.5569, val_loss: 27.6263, val_MinusLogProbMetric: 27.6263

Epoch 108: val_loss improved from 27.62864 to 27.62634, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.5569 - MinusLogProbMetric: 27.5569 - val_loss: 27.6263 - val_MinusLogProbMetric: 27.6263 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 109/1000
2023-09-12 17:43:01.684 
Epoch 109/1000 
	 loss: 27.5604, MinusLogProbMetric: 27.5604, val_loss: 27.7515, val_MinusLogProbMetric: 27.7515

Epoch 109: val_loss did not improve from 27.62634
196/196 - 12s - loss: 27.5604 - MinusLogProbMetric: 27.5604 - val_loss: 27.7515 - val_MinusLogProbMetric: 27.7515 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-12 17:43:13.123 
Epoch 110/1000 
	 loss: 27.5672, MinusLogProbMetric: 27.5672, val_loss: 27.6227, val_MinusLogProbMetric: 27.6227

Epoch 110: val_loss improved from 27.62634 to 27.62265, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.5672 - MinusLogProbMetric: 27.5672 - val_loss: 27.6227 - val_MinusLogProbMetric: 27.6227 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 111/1000
2023-09-12 17:43:24.623 
Epoch 111/1000 
	 loss: 27.5586, MinusLogProbMetric: 27.5586, val_loss: 27.7176, val_MinusLogProbMetric: 27.7176

Epoch 111: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5586 - MinusLogProbMetric: 27.5586 - val_loss: 27.7176 - val_MinusLogProbMetric: 27.7176 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 112/1000
2023-09-12 17:43:35.976 
Epoch 112/1000 
	 loss: 27.5618, MinusLogProbMetric: 27.5618, val_loss: 27.7826, val_MinusLogProbMetric: 27.7826

Epoch 112: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5618 - MinusLogProbMetric: 27.5618 - val_loss: 27.7826 - val_MinusLogProbMetric: 27.7826 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 113/1000
2023-09-12 17:43:47.256 
Epoch 113/1000 
	 loss: 27.5617, MinusLogProbMetric: 27.5617, val_loss: 27.6252, val_MinusLogProbMetric: 27.6252

Epoch 113: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5617 - MinusLogProbMetric: 27.5617 - val_loss: 27.6252 - val_MinusLogProbMetric: 27.6252 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 114/1000
2023-09-12 17:43:58.591 
Epoch 114/1000 
	 loss: 27.5596, MinusLogProbMetric: 27.5596, val_loss: 27.6345, val_MinusLogProbMetric: 27.6345

Epoch 114: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5596 - MinusLogProbMetric: 27.5596 - val_loss: 27.6345 - val_MinusLogProbMetric: 27.6345 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 115/1000
2023-09-12 17:44:09.603 
Epoch 115/1000 
	 loss: 27.5431, MinusLogProbMetric: 27.5431, val_loss: 27.6428, val_MinusLogProbMetric: 27.6428

Epoch 115: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5431 - MinusLogProbMetric: 27.5431 - val_loss: 27.6428 - val_MinusLogProbMetric: 27.6428 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 116/1000
2023-09-12 17:44:21.079 
Epoch 116/1000 
	 loss: 27.5413, MinusLogProbMetric: 27.5413, val_loss: 27.6837, val_MinusLogProbMetric: 27.6837

Epoch 116: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5413 - MinusLogProbMetric: 27.5413 - val_loss: 27.6837 - val_MinusLogProbMetric: 27.6837 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 117/1000
2023-09-12 17:44:32.453 
Epoch 117/1000 
	 loss: 27.5578, MinusLogProbMetric: 27.5578, val_loss: 27.6438, val_MinusLogProbMetric: 27.6438

Epoch 117: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5578 - MinusLogProbMetric: 27.5578 - val_loss: 27.6438 - val_MinusLogProbMetric: 27.6438 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 118/1000
2023-09-12 17:44:44.060 
Epoch 118/1000 
	 loss: 27.5578, MinusLogProbMetric: 27.5578, val_loss: 27.6707, val_MinusLogProbMetric: 27.6707

Epoch 118: val_loss did not improve from 27.62265
196/196 - 12s - loss: 27.5578 - MinusLogProbMetric: 27.5578 - val_loss: 27.6707 - val_MinusLogProbMetric: 27.6707 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-12 17:44:55.437 
Epoch 119/1000 
	 loss: 27.5414, MinusLogProbMetric: 27.5414, val_loss: 27.7120, val_MinusLogProbMetric: 27.7120

Epoch 119: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5414 - MinusLogProbMetric: 27.5414 - val_loss: 27.7120 - val_MinusLogProbMetric: 27.7120 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 120/1000
2023-09-12 17:45:06.805 
Epoch 120/1000 
	 loss: 27.5532, MinusLogProbMetric: 27.5532, val_loss: 27.6595, val_MinusLogProbMetric: 27.6595

Epoch 120: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5532 - MinusLogProbMetric: 27.5532 - val_loss: 27.6595 - val_MinusLogProbMetric: 27.6595 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 121/1000
2023-09-12 17:45:18.239 
Epoch 121/1000 
	 loss: 27.5398, MinusLogProbMetric: 27.5398, val_loss: 27.6565, val_MinusLogProbMetric: 27.6565

Epoch 121: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5398 - MinusLogProbMetric: 27.5398 - val_loss: 27.6565 - val_MinusLogProbMetric: 27.6565 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 122/1000
2023-09-12 17:45:29.665 
Epoch 122/1000 
	 loss: 27.5418, MinusLogProbMetric: 27.5418, val_loss: 27.6582, val_MinusLogProbMetric: 27.6582

Epoch 122: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5418 - MinusLogProbMetric: 27.5418 - val_loss: 27.6582 - val_MinusLogProbMetric: 27.6582 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 123/1000
2023-09-12 17:45:41.037 
Epoch 123/1000 
	 loss: 27.5413, MinusLogProbMetric: 27.5413, val_loss: 27.7099, val_MinusLogProbMetric: 27.7099

Epoch 123: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5413 - MinusLogProbMetric: 27.5413 - val_loss: 27.7099 - val_MinusLogProbMetric: 27.7099 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 124/1000
2023-09-12 17:45:52.552 
Epoch 124/1000 
	 loss: 27.5439, MinusLogProbMetric: 27.5439, val_loss: 27.6360, val_MinusLogProbMetric: 27.6360

Epoch 124: val_loss did not improve from 27.62265
196/196 - 12s - loss: 27.5439 - MinusLogProbMetric: 27.5439 - val_loss: 27.6360 - val_MinusLogProbMetric: 27.6360 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 125/1000
2023-09-12 17:46:04.113 
Epoch 125/1000 
	 loss: 27.5367, MinusLogProbMetric: 27.5367, val_loss: 27.6451, val_MinusLogProbMetric: 27.6451

Epoch 125: val_loss did not improve from 27.62265
196/196 - 12s - loss: 27.5367 - MinusLogProbMetric: 27.5367 - val_loss: 27.6451 - val_MinusLogProbMetric: 27.6451 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 126/1000
2023-09-12 17:46:15.616 
Epoch 126/1000 
	 loss: 27.5371, MinusLogProbMetric: 27.5371, val_loss: 27.6422, val_MinusLogProbMetric: 27.6422

Epoch 126: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5371 - MinusLogProbMetric: 27.5371 - val_loss: 27.6422 - val_MinusLogProbMetric: 27.6422 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 127/1000
2023-09-12 17:46:27.126 
Epoch 127/1000 
	 loss: 27.5362, MinusLogProbMetric: 27.5362, val_loss: 27.6830, val_MinusLogProbMetric: 27.6830

Epoch 127: val_loss did not improve from 27.62265
196/196 - 12s - loss: 27.5362 - MinusLogProbMetric: 27.5362 - val_loss: 27.6830 - val_MinusLogProbMetric: 27.6830 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 128/1000
2023-09-12 17:46:38.670 
Epoch 128/1000 
	 loss: 27.5338, MinusLogProbMetric: 27.5338, val_loss: 27.6671, val_MinusLogProbMetric: 27.6671

Epoch 128: val_loss did not improve from 27.62265
196/196 - 12s - loss: 27.5338 - MinusLogProbMetric: 27.5338 - val_loss: 27.6671 - val_MinusLogProbMetric: 27.6671 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 129/1000
2023-09-12 17:46:50.149 
Epoch 129/1000 
	 loss: 27.5455, MinusLogProbMetric: 27.5455, val_loss: 27.6425, val_MinusLogProbMetric: 27.6425

Epoch 129: val_loss did not improve from 27.62265
196/196 - 11s - loss: 27.5455 - MinusLogProbMetric: 27.5455 - val_loss: 27.6425 - val_MinusLogProbMetric: 27.6425 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 130/1000
2023-09-12 17:47:01.487 
Epoch 130/1000 
	 loss: 27.5356, MinusLogProbMetric: 27.5356, val_loss: 27.6088, val_MinusLogProbMetric: 27.6088

Epoch 130: val_loss improved from 27.62265 to 27.60883, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.5356 - MinusLogProbMetric: 27.5356 - val_loss: 27.6088 - val_MinusLogProbMetric: 27.6088 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 131/1000
2023-09-12 17:47:12.737 
Epoch 131/1000 
	 loss: 27.5343, MinusLogProbMetric: 27.5343, val_loss: 27.6535, val_MinusLogProbMetric: 27.6535

Epoch 131: val_loss did not improve from 27.60883
196/196 - 11s - loss: 27.5343 - MinusLogProbMetric: 27.5343 - val_loss: 27.6535 - val_MinusLogProbMetric: 27.6535 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 132/1000
2023-09-12 17:47:23.891 
Epoch 132/1000 
	 loss: 27.5321, MinusLogProbMetric: 27.5321, val_loss: 27.6976, val_MinusLogProbMetric: 27.6976

Epoch 132: val_loss did not improve from 27.60883
196/196 - 11s - loss: 27.5321 - MinusLogProbMetric: 27.5321 - val_loss: 27.6976 - val_MinusLogProbMetric: 27.6976 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 133/1000
2023-09-12 17:47:35.163 
Epoch 133/1000 
	 loss: 27.5252, MinusLogProbMetric: 27.5252, val_loss: 27.6410, val_MinusLogProbMetric: 27.6410

Epoch 133: val_loss did not improve from 27.60883
196/196 - 11s - loss: 27.5252 - MinusLogProbMetric: 27.5252 - val_loss: 27.6410 - val_MinusLogProbMetric: 27.6410 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 134/1000
2023-09-12 17:47:46.428 
Epoch 134/1000 
	 loss: 27.5277, MinusLogProbMetric: 27.5277, val_loss: 27.6309, val_MinusLogProbMetric: 27.6309

Epoch 134: val_loss did not improve from 27.60883
196/196 - 11s - loss: 27.5277 - MinusLogProbMetric: 27.5277 - val_loss: 27.6309 - val_MinusLogProbMetric: 27.6309 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 135/1000
2023-09-12 17:47:57.548 
Epoch 135/1000 
	 loss: 27.5376, MinusLogProbMetric: 27.5376, val_loss: 27.6320, val_MinusLogProbMetric: 27.6320

Epoch 135: val_loss did not improve from 27.60883
196/196 - 11s - loss: 27.5376 - MinusLogProbMetric: 27.5376 - val_loss: 27.6320 - val_MinusLogProbMetric: 27.6320 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 136/1000
2023-09-12 17:48:08.853 
Epoch 136/1000 
	 loss: 27.5202, MinusLogProbMetric: 27.5202, val_loss: 27.6052, val_MinusLogProbMetric: 27.6052

Epoch 136: val_loss improved from 27.60883 to 27.60517, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.5202 - MinusLogProbMetric: 27.5202 - val_loss: 27.6052 - val_MinusLogProbMetric: 27.6052 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 137/1000
2023-09-12 17:48:20.258 
Epoch 137/1000 
	 loss: 27.5307, MinusLogProbMetric: 27.5307, val_loss: 27.6405, val_MinusLogProbMetric: 27.6405

Epoch 137: val_loss did not improve from 27.60517
196/196 - 11s - loss: 27.5307 - MinusLogProbMetric: 27.5307 - val_loss: 27.6405 - val_MinusLogProbMetric: 27.6405 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 138/1000
2023-09-12 17:48:31.482 
Epoch 138/1000 
	 loss: 27.5192, MinusLogProbMetric: 27.5192, val_loss: 27.6924, val_MinusLogProbMetric: 27.6924

Epoch 138: val_loss did not improve from 27.60517
196/196 - 11s - loss: 27.5192 - MinusLogProbMetric: 27.5192 - val_loss: 27.6924 - val_MinusLogProbMetric: 27.6924 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 139/1000
2023-09-12 17:48:42.788 
Epoch 139/1000 
	 loss: 27.5385, MinusLogProbMetric: 27.5385, val_loss: 27.6522, val_MinusLogProbMetric: 27.6522

Epoch 139: val_loss did not improve from 27.60517
196/196 - 11s - loss: 27.5385 - MinusLogProbMetric: 27.5385 - val_loss: 27.6522 - val_MinusLogProbMetric: 27.6522 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 140/1000
2023-09-12 17:48:54.040 
Epoch 140/1000 
	 loss: 27.5157, MinusLogProbMetric: 27.5157, val_loss: 27.6587, val_MinusLogProbMetric: 27.6587

Epoch 140: val_loss did not improve from 27.60517
196/196 - 11s - loss: 27.5157 - MinusLogProbMetric: 27.5157 - val_loss: 27.6587 - val_MinusLogProbMetric: 27.6587 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 141/1000
2023-09-12 17:49:05.342 
Epoch 141/1000 
	 loss: 27.5299, MinusLogProbMetric: 27.5299, val_loss: 27.6760, val_MinusLogProbMetric: 27.6760

Epoch 141: val_loss did not improve from 27.60517
196/196 - 11s - loss: 27.5299 - MinusLogProbMetric: 27.5299 - val_loss: 27.6760 - val_MinusLogProbMetric: 27.6760 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 142/1000
2023-09-12 17:49:16.629 
Epoch 142/1000 
	 loss: 27.5230, MinusLogProbMetric: 27.5230, val_loss: 27.6553, val_MinusLogProbMetric: 27.6553

Epoch 142: val_loss did not improve from 27.60517
196/196 - 11s - loss: 27.5230 - MinusLogProbMetric: 27.5230 - val_loss: 27.6553 - val_MinusLogProbMetric: 27.6553 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 143/1000
2023-09-12 17:49:28.042 
Epoch 143/1000 
	 loss: 27.5165, MinusLogProbMetric: 27.5165, val_loss: 27.6610, val_MinusLogProbMetric: 27.6610

Epoch 143: val_loss did not improve from 27.60517
196/196 - 11s - loss: 27.5165 - MinusLogProbMetric: 27.5165 - val_loss: 27.6610 - val_MinusLogProbMetric: 27.6610 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 144/1000
2023-09-12 17:49:38.575 
Epoch 144/1000 
	 loss: 27.5234, MinusLogProbMetric: 27.5234, val_loss: 27.5953, val_MinusLogProbMetric: 27.5953

Epoch 144: val_loss improved from 27.60517 to 27.59533, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.5234 - MinusLogProbMetric: 27.5234 - val_loss: 27.5953 - val_MinusLogProbMetric: 27.5953 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 145/1000
2023-09-12 17:49:49.017 
Epoch 145/1000 
	 loss: 27.5223, MinusLogProbMetric: 27.5223, val_loss: 27.6226, val_MinusLogProbMetric: 27.6226

Epoch 145: val_loss did not improve from 27.59533
196/196 - 10s - loss: 27.5223 - MinusLogProbMetric: 27.5223 - val_loss: 27.6226 - val_MinusLogProbMetric: 27.6226 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 146/1000
2023-09-12 17:50:00.370 
Epoch 146/1000 
	 loss: 27.5113, MinusLogProbMetric: 27.5113, val_loss: 27.6268, val_MinusLogProbMetric: 27.6268

Epoch 146: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5113 - MinusLogProbMetric: 27.5113 - val_loss: 27.6268 - val_MinusLogProbMetric: 27.6268 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-12 17:50:11.244 
Epoch 147/1000 
	 loss: 27.5177, MinusLogProbMetric: 27.5177, val_loss: 27.6574, val_MinusLogProbMetric: 27.6574

Epoch 147: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5177 - MinusLogProbMetric: 27.5177 - val_loss: 27.6574 - val_MinusLogProbMetric: 27.6574 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 148/1000
2023-09-12 17:50:22.723 
Epoch 148/1000 
	 loss: 27.5002, MinusLogProbMetric: 27.5002, val_loss: 27.6232, val_MinusLogProbMetric: 27.6232

Epoch 148: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5002 - MinusLogProbMetric: 27.5002 - val_loss: 27.6232 - val_MinusLogProbMetric: 27.6232 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 149/1000
2023-09-12 17:50:34.174 
Epoch 149/1000 
	 loss: 27.5123, MinusLogProbMetric: 27.5123, val_loss: 27.6785, val_MinusLogProbMetric: 27.6785

Epoch 149: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5123 - MinusLogProbMetric: 27.5123 - val_loss: 27.6785 - val_MinusLogProbMetric: 27.6785 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-12 17:50:45.565 
Epoch 150/1000 
	 loss: 27.5032, MinusLogProbMetric: 27.5032, val_loss: 27.7517, val_MinusLogProbMetric: 27.7517

Epoch 150: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5032 - MinusLogProbMetric: 27.5032 - val_loss: 27.7517 - val_MinusLogProbMetric: 27.7517 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 151/1000
2023-09-12 17:50:56.853 
Epoch 151/1000 
	 loss: 27.5102, MinusLogProbMetric: 27.5102, val_loss: 27.6584, val_MinusLogProbMetric: 27.6584

Epoch 151: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5102 - MinusLogProbMetric: 27.5102 - val_loss: 27.6584 - val_MinusLogProbMetric: 27.6584 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 152/1000
2023-09-12 17:51:08.157 
Epoch 152/1000 
	 loss: 27.4919, MinusLogProbMetric: 27.4919, val_loss: 27.6382, val_MinusLogProbMetric: 27.6382

Epoch 152: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4919 - MinusLogProbMetric: 27.4919 - val_loss: 27.6382 - val_MinusLogProbMetric: 27.6382 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 153/1000
2023-09-12 17:51:19.675 
Epoch 153/1000 
	 loss: 27.5097, MinusLogProbMetric: 27.5097, val_loss: 27.6344, val_MinusLogProbMetric: 27.6344

Epoch 153: val_loss did not improve from 27.59533
196/196 - 12s - loss: 27.5097 - MinusLogProbMetric: 27.5097 - val_loss: 27.6344 - val_MinusLogProbMetric: 27.6344 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-12 17:51:30.929 
Epoch 154/1000 
	 loss: 27.5203, MinusLogProbMetric: 27.5203, val_loss: 27.7266, val_MinusLogProbMetric: 27.7266

Epoch 154: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5203 - MinusLogProbMetric: 27.5203 - val_loss: 27.7266 - val_MinusLogProbMetric: 27.7266 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 155/1000
2023-09-12 17:51:41.115 
Epoch 155/1000 
	 loss: 27.5026, MinusLogProbMetric: 27.5026, val_loss: 27.7154, val_MinusLogProbMetric: 27.7154

Epoch 155: val_loss did not improve from 27.59533
196/196 - 10s - loss: 27.5026 - MinusLogProbMetric: 27.5026 - val_loss: 27.7154 - val_MinusLogProbMetric: 27.7154 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 156/1000
2023-09-12 17:51:52.264 
Epoch 156/1000 
	 loss: 27.4974, MinusLogProbMetric: 27.4974, val_loss: 27.6340, val_MinusLogProbMetric: 27.6340

Epoch 156: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4974 - MinusLogProbMetric: 27.4974 - val_loss: 27.6340 - val_MinusLogProbMetric: 27.6340 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 157/1000
2023-09-12 17:52:03.541 
Epoch 157/1000 
	 loss: 27.5091, MinusLogProbMetric: 27.5091, val_loss: 27.6559, val_MinusLogProbMetric: 27.6559

Epoch 157: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5091 - MinusLogProbMetric: 27.5091 - val_loss: 27.6559 - val_MinusLogProbMetric: 27.6559 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 158/1000
2023-09-12 17:52:14.480 
Epoch 158/1000 
	 loss: 27.5089, MinusLogProbMetric: 27.5089, val_loss: 27.6459, val_MinusLogProbMetric: 27.6459

Epoch 158: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5089 - MinusLogProbMetric: 27.5089 - val_loss: 27.6459 - val_MinusLogProbMetric: 27.6459 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 159/1000
2023-09-12 17:52:24.366 
Epoch 159/1000 
	 loss: 27.4936, MinusLogProbMetric: 27.4936, val_loss: 27.6981, val_MinusLogProbMetric: 27.6981

Epoch 159: val_loss did not improve from 27.59533
196/196 - 10s - loss: 27.4936 - MinusLogProbMetric: 27.4936 - val_loss: 27.6981 - val_MinusLogProbMetric: 27.6981 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 160/1000
2023-09-12 17:52:34.679 
Epoch 160/1000 
	 loss: 27.5028, MinusLogProbMetric: 27.5028, val_loss: 27.6334, val_MinusLogProbMetric: 27.6334

Epoch 160: val_loss did not improve from 27.59533
196/196 - 10s - loss: 27.5028 - MinusLogProbMetric: 27.5028 - val_loss: 27.6334 - val_MinusLogProbMetric: 27.6334 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 161/1000
2023-09-12 17:52:45.244 
Epoch 161/1000 
	 loss: 27.4927, MinusLogProbMetric: 27.4927, val_loss: 27.6801, val_MinusLogProbMetric: 27.6801

Epoch 161: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4927 - MinusLogProbMetric: 27.4927 - val_loss: 27.6801 - val_MinusLogProbMetric: 27.6801 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 162/1000
2023-09-12 17:52:56.484 
Epoch 162/1000 
	 loss: 27.4973, MinusLogProbMetric: 27.4973, val_loss: 27.6412, val_MinusLogProbMetric: 27.6412

Epoch 162: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4973 - MinusLogProbMetric: 27.4973 - val_loss: 27.6412 - val_MinusLogProbMetric: 27.6412 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 163/1000
2023-09-12 17:53:07.668 
Epoch 163/1000 
	 loss: 27.4987, MinusLogProbMetric: 27.4987, val_loss: 27.6100, val_MinusLogProbMetric: 27.6100

Epoch 163: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4987 - MinusLogProbMetric: 27.4987 - val_loss: 27.6100 - val_MinusLogProbMetric: 27.6100 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 164/1000
2023-09-12 17:53:19.019 
Epoch 164/1000 
	 loss: 27.5062, MinusLogProbMetric: 27.5062, val_loss: 27.6565, val_MinusLogProbMetric: 27.6565

Epoch 164: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5062 - MinusLogProbMetric: 27.5062 - val_loss: 27.6565 - val_MinusLogProbMetric: 27.6565 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 165/1000
2023-09-12 17:53:30.409 
Epoch 165/1000 
	 loss: 27.4952, MinusLogProbMetric: 27.4952, val_loss: 27.6152, val_MinusLogProbMetric: 27.6152

Epoch 165: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4952 - MinusLogProbMetric: 27.4952 - val_loss: 27.6152 - val_MinusLogProbMetric: 27.6152 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 166/1000
2023-09-12 17:53:41.752 
Epoch 166/1000 
	 loss: 27.5032, MinusLogProbMetric: 27.5032, val_loss: 27.6980, val_MinusLogProbMetric: 27.6980

Epoch 166: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5032 - MinusLogProbMetric: 27.5032 - val_loss: 27.6980 - val_MinusLogProbMetric: 27.6980 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 167/1000
2023-09-12 17:53:53.022 
Epoch 167/1000 
	 loss: 27.5016, MinusLogProbMetric: 27.5016, val_loss: 27.6188, val_MinusLogProbMetric: 27.6188

Epoch 167: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5016 - MinusLogProbMetric: 27.5016 - val_loss: 27.6188 - val_MinusLogProbMetric: 27.6188 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 168/1000
2023-09-12 17:54:03.873 
Epoch 168/1000 
	 loss: 27.4907, MinusLogProbMetric: 27.4907, val_loss: 27.6160, val_MinusLogProbMetric: 27.6160

Epoch 168: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4907 - MinusLogProbMetric: 27.4907 - val_loss: 27.6160 - val_MinusLogProbMetric: 27.6160 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 169/1000
2023-09-12 17:54:14.641 
Epoch 169/1000 
	 loss: 27.4984, MinusLogProbMetric: 27.4984, val_loss: 27.6336, val_MinusLogProbMetric: 27.6336

Epoch 169: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4984 - MinusLogProbMetric: 27.4984 - val_loss: 27.6336 - val_MinusLogProbMetric: 27.6336 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 170/1000
2023-09-12 17:54:25.944 
Epoch 170/1000 
	 loss: 27.4816, MinusLogProbMetric: 27.4816, val_loss: 27.6087, val_MinusLogProbMetric: 27.6087

Epoch 170: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4816 - MinusLogProbMetric: 27.4816 - val_loss: 27.6087 - val_MinusLogProbMetric: 27.6087 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 171/1000
2023-09-12 17:54:37.183 
Epoch 171/1000 
	 loss: 27.4831, MinusLogProbMetric: 27.4831, val_loss: 27.6874, val_MinusLogProbMetric: 27.6874

Epoch 171: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4831 - MinusLogProbMetric: 27.4831 - val_loss: 27.6874 - val_MinusLogProbMetric: 27.6874 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 172/1000
2023-09-12 17:54:48.566 
Epoch 172/1000 
	 loss: 27.5000, MinusLogProbMetric: 27.5000, val_loss: 27.6321, val_MinusLogProbMetric: 27.6321

Epoch 172: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.5000 - MinusLogProbMetric: 27.5000 - val_loss: 27.6321 - val_MinusLogProbMetric: 27.6321 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 173/1000
2023-09-12 17:54:59.878 
Epoch 173/1000 
	 loss: 27.4989, MinusLogProbMetric: 27.4989, val_loss: 27.7116, val_MinusLogProbMetric: 27.7116

Epoch 173: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4989 - MinusLogProbMetric: 27.4989 - val_loss: 27.7116 - val_MinusLogProbMetric: 27.7116 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 174/1000
2023-09-12 17:55:11.226 
Epoch 174/1000 
	 loss: 27.4958, MinusLogProbMetric: 27.4958, val_loss: 27.6897, val_MinusLogProbMetric: 27.6897

Epoch 174: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4958 - MinusLogProbMetric: 27.4958 - val_loss: 27.6897 - val_MinusLogProbMetric: 27.6897 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 175/1000
2023-09-12 17:55:22.537 
Epoch 175/1000 
	 loss: 27.4845, MinusLogProbMetric: 27.4845, val_loss: 27.6147, val_MinusLogProbMetric: 27.6147

Epoch 175: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4845 - MinusLogProbMetric: 27.4845 - val_loss: 27.6147 - val_MinusLogProbMetric: 27.6147 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 176/1000
2023-09-12 17:55:34.009 
Epoch 176/1000 
	 loss: 27.4897, MinusLogProbMetric: 27.4897, val_loss: 27.6154, val_MinusLogProbMetric: 27.6154

Epoch 176: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4897 - MinusLogProbMetric: 27.4897 - val_loss: 27.6154 - val_MinusLogProbMetric: 27.6154 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 177/1000
2023-09-12 17:55:44.543 
Epoch 177/1000 
	 loss: 27.4866, MinusLogProbMetric: 27.4866, val_loss: 27.6905, val_MinusLogProbMetric: 27.6905

Epoch 177: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4866 - MinusLogProbMetric: 27.4866 - val_loss: 27.6905 - val_MinusLogProbMetric: 27.6905 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 178/1000
2023-09-12 17:55:55.329 
Epoch 178/1000 
	 loss: 27.4852, MinusLogProbMetric: 27.4852, val_loss: 27.6214, val_MinusLogProbMetric: 27.6214

Epoch 178: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4852 - MinusLogProbMetric: 27.4852 - val_loss: 27.6214 - val_MinusLogProbMetric: 27.6214 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 179/1000
2023-09-12 17:56:06.500 
Epoch 179/1000 
	 loss: 27.4919, MinusLogProbMetric: 27.4919, val_loss: 27.6290, val_MinusLogProbMetric: 27.6290

Epoch 179: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4919 - MinusLogProbMetric: 27.4919 - val_loss: 27.6290 - val_MinusLogProbMetric: 27.6290 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 180/1000
2023-09-12 17:56:17.234 
Epoch 180/1000 
	 loss: 27.4832, MinusLogProbMetric: 27.4832, val_loss: 27.6322, val_MinusLogProbMetric: 27.6322

Epoch 180: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4832 - MinusLogProbMetric: 27.4832 - val_loss: 27.6322 - val_MinusLogProbMetric: 27.6322 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 181/1000
2023-09-12 17:56:28.532 
Epoch 181/1000 
	 loss: 27.4844, MinusLogProbMetric: 27.4844, val_loss: 27.6405, val_MinusLogProbMetric: 27.6405

Epoch 181: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4844 - MinusLogProbMetric: 27.4844 - val_loss: 27.6405 - val_MinusLogProbMetric: 27.6405 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 182/1000
2023-09-12 17:56:39.910 
Epoch 182/1000 
	 loss: 27.4774, MinusLogProbMetric: 27.4774, val_loss: 27.6484, val_MinusLogProbMetric: 27.6484

Epoch 182: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4774 - MinusLogProbMetric: 27.4774 - val_loss: 27.6484 - val_MinusLogProbMetric: 27.6484 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 183/1000
2023-09-12 17:56:51.280 
Epoch 183/1000 
	 loss: 27.4834, MinusLogProbMetric: 27.4834, val_loss: 27.6645, val_MinusLogProbMetric: 27.6645

Epoch 183: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4834 - MinusLogProbMetric: 27.4834 - val_loss: 27.6645 - val_MinusLogProbMetric: 27.6645 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 184/1000
2023-09-12 17:57:02.642 
Epoch 184/1000 
	 loss: 27.4854, MinusLogProbMetric: 27.4854, val_loss: 27.6055, val_MinusLogProbMetric: 27.6055

Epoch 184: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4854 - MinusLogProbMetric: 27.4854 - val_loss: 27.6055 - val_MinusLogProbMetric: 27.6055 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 185/1000
2023-09-12 17:57:13.969 
Epoch 185/1000 
	 loss: 27.4882, MinusLogProbMetric: 27.4882, val_loss: 27.6264, val_MinusLogProbMetric: 27.6264

Epoch 185: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4882 - MinusLogProbMetric: 27.4882 - val_loss: 27.6264 - val_MinusLogProbMetric: 27.6264 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 186/1000
2023-09-12 17:57:25.205 
Epoch 186/1000 
	 loss: 27.4806, MinusLogProbMetric: 27.4806, val_loss: 27.6584, val_MinusLogProbMetric: 27.6584

Epoch 186: val_loss did not improve from 27.59533
196/196 - 11s - loss: 27.4806 - MinusLogProbMetric: 27.4806 - val_loss: 27.6584 - val_MinusLogProbMetric: 27.6584 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 187/1000
2023-09-12 17:57:36.661 
Epoch 187/1000 
	 loss: 27.4907, MinusLogProbMetric: 27.4907, val_loss: 27.5850, val_MinusLogProbMetric: 27.5850

Epoch 187: val_loss improved from 27.59533 to 27.58500, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.4907 - MinusLogProbMetric: 27.4907 - val_loss: 27.5850 - val_MinusLogProbMetric: 27.5850 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 188/1000
2023-09-12 17:57:48.042 
Epoch 188/1000 
	 loss: 27.4772, MinusLogProbMetric: 27.4772, val_loss: 27.5984, val_MinusLogProbMetric: 27.5984

Epoch 188: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4772 - MinusLogProbMetric: 27.4772 - val_loss: 27.5984 - val_MinusLogProbMetric: 27.5984 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 189/1000
2023-09-12 17:57:59.330 
Epoch 189/1000 
	 loss: 27.4832, MinusLogProbMetric: 27.4832, val_loss: 27.6143, val_MinusLogProbMetric: 27.6143

Epoch 189: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4832 - MinusLogProbMetric: 27.4832 - val_loss: 27.6143 - val_MinusLogProbMetric: 27.6143 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 190/1000
2023-09-12 17:58:10.575 
Epoch 190/1000 
	 loss: 27.4758, MinusLogProbMetric: 27.4758, val_loss: 27.6224, val_MinusLogProbMetric: 27.6224

Epoch 190: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4758 - MinusLogProbMetric: 27.4758 - val_loss: 27.6224 - val_MinusLogProbMetric: 27.6224 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 191/1000
2023-09-12 17:58:21.818 
Epoch 191/1000 
	 loss: 27.4868, MinusLogProbMetric: 27.4868, val_loss: 27.6176, val_MinusLogProbMetric: 27.6176

Epoch 191: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4868 - MinusLogProbMetric: 27.4868 - val_loss: 27.6176 - val_MinusLogProbMetric: 27.6176 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 192/1000
2023-09-12 17:58:33.179 
Epoch 192/1000 
	 loss: 27.4701, MinusLogProbMetric: 27.4701, val_loss: 27.6728, val_MinusLogProbMetric: 27.6728

Epoch 192: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4701 - MinusLogProbMetric: 27.4701 - val_loss: 27.6728 - val_MinusLogProbMetric: 27.6728 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 193/1000
2023-09-12 17:58:43.001 
Epoch 193/1000 
	 loss: 27.4760, MinusLogProbMetric: 27.4760, val_loss: 27.6074, val_MinusLogProbMetric: 27.6074

Epoch 193: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4760 - MinusLogProbMetric: 27.4760 - val_loss: 27.6074 - val_MinusLogProbMetric: 27.6074 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 194/1000
2023-09-12 17:58:54.372 
Epoch 194/1000 
	 loss: 27.4731, MinusLogProbMetric: 27.4731, val_loss: 27.6090, val_MinusLogProbMetric: 27.6090

Epoch 194: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4731 - MinusLogProbMetric: 27.4731 - val_loss: 27.6090 - val_MinusLogProbMetric: 27.6090 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 195/1000
2023-09-12 17:59:05.653 
Epoch 195/1000 
	 loss: 27.4721, MinusLogProbMetric: 27.4721, val_loss: 27.6851, val_MinusLogProbMetric: 27.6851

Epoch 195: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4721 - MinusLogProbMetric: 27.4721 - val_loss: 27.6851 - val_MinusLogProbMetric: 27.6851 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 196/1000
2023-09-12 17:59:16.821 
Epoch 196/1000 
	 loss: 27.4769, MinusLogProbMetric: 27.4769, val_loss: 27.6159, val_MinusLogProbMetric: 27.6159

Epoch 196: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4769 - MinusLogProbMetric: 27.4769 - val_loss: 27.6159 - val_MinusLogProbMetric: 27.6159 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 197/1000
2023-09-12 17:59:28.124 
Epoch 197/1000 
	 loss: 27.4777, MinusLogProbMetric: 27.4777, val_loss: 27.6474, val_MinusLogProbMetric: 27.6474

Epoch 197: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4777 - MinusLogProbMetric: 27.4777 - val_loss: 27.6474 - val_MinusLogProbMetric: 27.6474 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 198/1000
2023-09-12 17:59:39.460 
Epoch 198/1000 
	 loss: 27.4763, MinusLogProbMetric: 27.4763, val_loss: 27.7138, val_MinusLogProbMetric: 27.7138

Epoch 198: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4763 - MinusLogProbMetric: 27.4763 - val_loss: 27.7138 - val_MinusLogProbMetric: 27.7138 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 199/1000
2023-09-12 17:59:49.772 
Epoch 199/1000 
	 loss: 27.4729, MinusLogProbMetric: 27.4729, val_loss: 27.6191, val_MinusLogProbMetric: 27.6191

Epoch 199: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4729 - MinusLogProbMetric: 27.4729 - val_loss: 27.6191 - val_MinusLogProbMetric: 27.6191 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 200/1000
2023-09-12 17:59:59.056 
Epoch 200/1000 
	 loss: 27.4794, MinusLogProbMetric: 27.4794, val_loss: 27.6614, val_MinusLogProbMetric: 27.6614

Epoch 200: val_loss did not improve from 27.58500
196/196 - 9s - loss: 27.4794 - MinusLogProbMetric: 27.4794 - val_loss: 27.6614 - val_MinusLogProbMetric: 27.6614 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 201/1000
2023-09-12 18:00:09.887 
Epoch 201/1000 
	 loss: 27.4707, MinusLogProbMetric: 27.4707, val_loss: 27.6362, val_MinusLogProbMetric: 27.6362

Epoch 201: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4707 - MinusLogProbMetric: 27.4707 - val_loss: 27.6362 - val_MinusLogProbMetric: 27.6362 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 202/1000
2023-09-12 18:00:21.336 
Epoch 202/1000 
	 loss: 27.4751, MinusLogProbMetric: 27.4751, val_loss: 27.6704, val_MinusLogProbMetric: 27.6704

Epoch 202: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4751 - MinusLogProbMetric: 27.4751 - val_loss: 27.6704 - val_MinusLogProbMetric: 27.6704 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 203/1000
2023-09-12 18:00:32.615 
Epoch 203/1000 
	 loss: 27.4724, MinusLogProbMetric: 27.4724, val_loss: 27.6666, val_MinusLogProbMetric: 27.6666

Epoch 203: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4724 - MinusLogProbMetric: 27.4724 - val_loss: 27.6666 - val_MinusLogProbMetric: 27.6666 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 204/1000
2023-09-12 18:00:43.910 
Epoch 204/1000 
	 loss: 27.4703, MinusLogProbMetric: 27.4703, val_loss: 27.6211, val_MinusLogProbMetric: 27.6211

Epoch 204: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4703 - MinusLogProbMetric: 27.4703 - val_loss: 27.6211 - val_MinusLogProbMetric: 27.6211 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 205/1000
2023-09-12 18:00:55.205 
Epoch 205/1000 
	 loss: 27.4803, MinusLogProbMetric: 27.4803, val_loss: 27.5931, val_MinusLogProbMetric: 27.5931

Epoch 205: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4803 - MinusLogProbMetric: 27.4803 - val_loss: 27.5931 - val_MinusLogProbMetric: 27.5931 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-12 18:01:06.730 
Epoch 206/1000 
	 loss: 27.4814, MinusLogProbMetric: 27.4814, val_loss: 27.6997, val_MinusLogProbMetric: 27.6997

Epoch 206: val_loss did not improve from 27.58500
196/196 - 12s - loss: 27.4814 - MinusLogProbMetric: 27.4814 - val_loss: 27.6997 - val_MinusLogProbMetric: 27.6997 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 207/1000
2023-09-12 18:01:17.235 
Epoch 207/1000 
	 loss: 27.4698, MinusLogProbMetric: 27.4698, val_loss: 27.6435, val_MinusLogProbMetric: 27.6435

Epoch 207: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4698 - MinusLogProbMetric: 27.4698 - val_loss: 27.6435 - val_MinusLogProbMetric: 27.6435 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 208/1000
2023-09-12 18:01:28.532 
Epoch 208/1000 
	 loss: 27.4639, MinusLogProbMetric: 27.4639, val_loss: 27.6417, val_MinusLogProbMetric: 27.6417

Epoch 208: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4639 - MinusLogProbMetric: 27.4639 - val_loss: 27.6417 - val_MinusLogProbMetric: 27.6417 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 209/1000
2023-09-12 18:01:40.089 
Epoch 209/1000 
	 loss: 27.4625, MinusLogProbMetric: 27.4625, val_loss: 27.8284, val_MinusLogProbMetric: 27.8284

Epoch 209: val_loss did not improve from 27.58500
196/196 - 12s - loss: 27.4625 - MinusLogProbMetric: 27.4625 - val_loss: 27.8284 - val_MinusLogProbMetric: 27.8284 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-12 18:01:51.462 
Epoch 210/1000 
	 loss: 27.4666, MinusLogProbMetric: 27.4666, val_loss: 27.6243, val_MinusLogProbMetric: 27.6243

Epoch 210: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4666 - MinusLogProbMetric: 27.4666 - val_loss: 27.6243 - val_MinusLogProbMetric: 27.6243 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 211/1000
2023-09-12 18:02:02.853 
Epoch 211/1000 
	 loss: 27.4646, MinusLogProbMetric: 27.4646, val_loss: 27.6659, val_MinusLogProbMetric: 27.6659

Epoch 211: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4646 - MinusLogProbMetric: 27.4646 - val_loss: 27.6659 - val_MinusLogProbMetric: 27.6659 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 212/1000
2023-09-12 18:02:13.638 
Epoch 212/1000 
	 loss: 27.4659, MinusLogProbMetric: 27.4659, val_loss: 27.6650, val_MinusLogProbMetric: 27.6650

Epoch 212: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4659 - MinusLogProbMetric: 27.4659 - val_loss: 27.6650 - val_MinusLogProbMetric: 27.6650 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 213/1000
2023-09-12 18:02:24.979 
Epoch 213/1000 
	 loss: 27.4648, MinusLogProbMetric: 27.4648, val_loss: 27.6465, val_MinusLogProbMetric: 27.6465

Epoch 213: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4648 - MinusLogProbMetric: 27.4648 - val_loss: 27.6465 - val_MinusLogProbMetric: 27.6465 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 214/1000
2023-09-12 18:02:35.432 
Epoch 214/1000 
	 loss: 27.4634, MinusLogProbMetric: 27.4634, val_loss: 27.6271, val_MinusLogProbMetric: 27.6271

Epoch 214: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4634 - MinusLogProbMetric: 27.4634 - val_loss: 27.6271 - val_MinusLogProbMetric: 27.6271 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 215/1000
2023-09-12 18:02:46.628 
Epoch 215/1000 
	 loss: 27.4621, MinusLogProbMetric: 27.4621, val_loss: 27.6365, val_MinusLogProbMetric: 27.6365

Epoch 215: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4621 - MinusLogProbMetric: 27.4621 - val_loss: 27.6365 - val_MinusLogProbMetric: 27.6365 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 216/1000
2023-09-12 18:02:57.816 
Epoch 216/1000 
	 loss: 27.4666, MinusLogProbMetric: 27.4666, val_loss: 27.7105, val_MinusLogProbMetric: 27.7105

Epoch 216: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4666 - MinusLogProbMetric: 27.4666 - val_loss: 27.7105 - val_MinusLogProbMetric: 27.7105 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 217/1000
2023-09-12 18:03:08.281 
Epoch 217/1000 
	 loss: 27.4633, MinusLogProbMetric: 27.4633, val_loss: 27.6127, val_MinusLogProbMetric: 27.6127

Epoch 217: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4633 - MinusLogProbMetric: 27.4633 - val_loss: 27.6127 - val_MinusLogProbMetric: 27.6127 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 218/1000
2023-09-12 18:03:19.672 
Epoch 218/1000 
	 loss: 27.4615, MinusLogProbMetric: 27.4615, val_loss: 27.6104, val_MinusLogProbMetric: 27.6104

Epoch 218: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4615 - MinusLogProbMetric: 27.4615 - val_loss: 27.6104 - val_MinusLogProbMetric: 27.6104 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 219/1000
2023-09-12 18:03:31.041 
Epoch 219/1000 
	 loss: 27.4570, MinusLogProbMetric: 27.4570, val_loss: 27.6426, val_MinusLogProbMetric: 27.6426

Epoch 219: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4570 - MinusLogProbMetric: 27.4570 - val_loss: 27.6426 - val_MinusLogProbMetric: 27.6426 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 220/1000
2023-09-12 18:03:42.493 
Epoch 220/1000 
	 loss: 27.4603, MinusLogProbMetric: 27.4603, val_loss: 27.6224, val_MinusLogProbMetric: 27.6224

Epoch 220: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4603 - MinusLogProbMetric: 27.4603 - val_loss: 27.6224 - val_MinusLogProbMetric: 27.6224 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 221/1000
2023-09-12 18:03:53.747 
Epoch 221/1000 
	 loss: 27.4551, MinusLogProbMetric: 27.4551, val_loss: 27.6209, val_MinusLogProbMetric: 27.6209

Epoch 221: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4551 - MinusLogProbMetric: 27.4551 - val_loss: 27.6209 - val_MinusLogProbMetric: 27.6209 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 222/1000
2023-09-12 18:04:05.069 
Epoch 222/1000 
	 loss: 27.4540, MinusLogProbMetric: 27.4540, val_loss: 27.6122, val_MinusLogProbMetric: 27.6122

Epoch 222: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4540 - MinusLogProbMetric: 27.4540 - val_loss: 27.6122 - val_MinusLogProbMetric: 27.6122 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 223/1000
2023-09-12 18:04:14.959 
Epoch 223/1000 
	 loss: 27.4608, MinusLogProbMetric: 27.4608, val_loss: 27.6351, val_MinusLogProbMetric: 27.6351

Epoch 223: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4608 - MinusLogProbMetric: 27.4608 - val_loss: 27.6351 - val_MinusLogProbMetric: 27.6351 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 224/1000
2023-09-12 18:04:26.395 
Epoch 224/1000 
	 loss: 27.4572, MinusLogProbMetric: 27.4572, val_loss: 27.6768, val_MinusLogProbMetric: 27.6768

Epoch 224: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4572 - MinusLogProbMetric: 27.4572 - val_loss: 27.6768 - val_MinusLogProbMetric: 27.6768 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 225/1000
2023-09-12 18:04:37.616 
Epoch 225/1000 
	 loss: 27.4603, MinusLogProbMetric: 27.4603, val_loss: 27.5929, val_MinusLogProbMetric: 27.5929

Epoch 225: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4603 - MinusLogProbMetric: 27.4603 - val_loss: 27.5929 - val_MinusLogProbMetric: 27.5929 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 226/1000
2023-09-12 18:04:47.830 
Epoch 226/1000 
	 loss: 27.4488, MinusLogProbMetric: 27.4488, val_loss: 27.6374, val_MinusLogProbMetric: 27.6374

Epoch 226: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4488 - MinusLogProbMetric: 27.4488 - val_loss: 27.6374 - val_MinusLogProbMetric: 27.6374 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 227/1000
2023-09-12 18:04:58.458 
Epoch 227/1000 
	 loss: 27.4549, MinusLogProbMetric: 27.4549, val_loss: 27.6816, val_MinusLogProbMetric: 27.6816

Epoch 227: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4549 - MinusLogProbMetric: 27.4549 - val_loss: 27.6816 - val_MinusLogProbMetric: 27.6816 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 228/1000
2023-09-12 18:05:09.768 
Epoch 228/1000 
	 loss: 27.4461, MinusLogProbMetric: 27.4461, val_loss: 27.6620, val_MinusLogProbMetric: 27.6620

Epoch 228: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4461 - MinusLogProbMetric: 27.4461 - val_loss: 27.6620 - val_MinusLogProbMetric: 27.6620 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 229/1000
2023-09-12 18:05:21.100 
Epoch 229/1000 
	 loss: 27.4596, MinusLogProbMetric: 27.4596, val_loss: 27.6366, val_MinusLogProbMetric: 27.6366

Epoch 229: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4596 - MinusLogProbMetric: 27.4596 - val_loss: 27.6366 - val_MinusLogProbMetric: 27.6366 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 230/1000
2023-09-12 18:05:31.918 
Epoch 230/1000 
	 loss: 27.4556, MinusLogProbMetric: 27.4556, val_loss: 27.5933, val_MinusLogProbMetric: 27.5933

Epoch 230: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4556 - MinusLogProbMetric: 27.4556 - val_loss: 27.5933 - val_MinusLogProbMetric: 27.5933 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 231/1000
2023-09-12 18:05:41.611 
Epoch 231/1000 
	 loss: 27.4462, MinusLogProbMetric: 27.4462, val_loss: 27.6290, val_MinusLogProbMetric: 27.6290

Epoch 231: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4462 - MinusLogProbMetric: 27.4462 - val_loss: 27.6290 - val_MinusLogProbMetric: 27.6290 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 232/1000
2023-09-12 18:05:52.854 
Epoch 232/1000 
	 loss: 27.4509, MinusLogProbMetric: 27.4509, val_loss: 27.6295, val_MinusLogProbMetric: 27.6295

Epoch 232: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4509 - MinusLogProbMetric: 27.4509 - val_loss: 27.6295 - val_MinusLogProbMetric: 27.6295 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 233/1000
2023-09-12 18:06:04.223 
Epoch 233/1000 
	 loss: 27.4551, MinusLogProbMetric: 27.4551, val_loss: 27.6312, val_MinusLogProbMetric: 27.6312

Epoch 233: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4551 - MinusLogProbMetric: 27.4551 - val_loss: 27.6312 - val_MinusLogProbMetric: 27.6312 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 234/1000
2023-09-12 18:06:15.228 
Epoch 234/1000 
	 loss: 27.4503, MinusLogProbMetric: 27.4503, val_loss: 27.6191, val_MinusLogProbMetric: 27.6191

Epoch 234: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4503 - MinusLogProbMetric: 27.4503 - val_loss: 27.6191 - val_MinusLogProbMetric: 27.6191 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 235/1000
2023-09-12 18:06:25.369 
Epoch 235/1000 
	 loss: 27.4443, MinusLogProbMetric: 27.4443, val_loss: 27.6238, val_MinusLogProbMetric: 27.6238

Epoch 235: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4443 - MinusLogProbMetric: 27.4443 - val_loss: 27.6238 - val_MinusLogProbMetric: 27.6238 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 236/1000
2023-09-12 18:06:35.883 
Epoch 236/1000 
	 loss: 27.4507, MinusLogProbMetric: 27.4507, val_loss: 27.6395, val_MinusLogProbMetric: 27.6395

Epoch 236: val_loss did not improve from 27.58500
196/196 - 11s - loss: 27.4507 - MinusLogProbMetric: 27.4507 - val_loss: 27.6395 - val_MinusLogProbMetric: 27.6395 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 237/1000
2023-09-12 18:06:45.537 
Epoch 237/1000 
	 loss: 27.4502, MinusLogProbMetric: 27.4502, val_loss: 27.6177, val_MinusLogProbMetric: 27.6177

Epoch 237: val_loss did not improve from 27.58500
196/196 - 10s - loss: 27.4502 - MinusLogProbMetric: 27.4502 - val_loss: 27.6177 - val_MinusLogProbMetric: 27.6177 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 238/1000
2023-09-12 18:06:55.110 
Epoch 238/1000 
	 loss: 27.3713, MinusLogProbMetric: 27.3713, val_loss: 27.5681, val_MinusLogProbMetric: 27.5681

Epoch 238: val_loss improved from 27.58500 to 27.56813, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 10s - loss: 27.3713 - MinusLogProbMetric: 27.3713 - val_loss: 27.5681 - val_MinusLogProbMetric: 27.5681 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 239/1000
2023-09-12 18:07:04.759 
Epoch 239/1000 
	 loss: 27.3703, MinusLogProbMetric: 27.3703, val_loss: 27.5598, val_MinusLogProbMetric: 27.5598

Epoch 239: val_loss improved from 27.56813 to 27.55980, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 10s - loss: 27.3703 - MinusLogProbMetric: 27.3703 - val_loss: 27.5598 - val_MinusLogProbMetric: 27.5598 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 240/1000
2023-09-12 18:07:15.290 
Epoch 240/1000 
	 loss: 27.3699, MinusLogProbMetric: 27.3699, val_loss: 27.5489, val_MinusLogProbMetric: 27.5489

Epoch 240: val_loss improved from 27.55980 to 27.54892, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.3699 - MinusLogProbMetric: 27.3699 - val_loss: 27.5489 - val_MinusLogProbMetric: 27.5489 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 241/1000
2023-09-12 18:07:26.130 
Epoch 241/1000 
	 loss: 27.3684, MinusLogProbMetric: 27.3684, val_loss: 27.5936, val_MinusLogProbMetric: 27.5936

Epoch 241: val_loss did not improve from 27.54892
196/196 - 11s - loss: 27.3684 - MinusLogProbMetric: 27.3684 - val_loss: 27.5936 - val_MinusLogProbMetric: 27.5936 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 242/1000
2023-09-12 18:07:36.136 
Epoch 242/1000 
	 loss: 27.3695, MinusLogProbMetric: 27.3695, val_loss: 27.5746, val_MinusLogProbMetric: 27.5746

Epoch 242: val_loss did not improve from 27.54892
196/196 - 10s - loss: 27.3695 - MinusLogProbMetric: 27.3695 - val_loss: 27.5746 - val_MinusLogProbMetric: 27.5746 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 243/1000
2023-09-12 18:07:46.461 
Epoch 243/1000 
	 loss: 27.3651, MinusLogProbMetric: 27.3651, val_loss: 27.5681, val_MinusLogProbMetric: 27.5681

Epoch 243: val_loss did not improve from 27.54892
196/196 - 10s - loss: 27.3651 - MinusLogProbMetric: 27.3651 - val_loss: 27.5681 - val_MinusLogProbMetric: 27.5681 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 244/1000
2023-09-12 18:07:56.579 
Epoch 244/1000 
	 loss: 27.3656, MinusLogProbMetric: 27.3656, val_loss: 27.5940, val_MinusLogProbMetric: 27.5940

Epoch 244: val_loss did not improve from 27.54892
196/196 - 10s - loss: 27.3656 - MinusLogProbMetric: 27.3656 - val_loss: 27.5940 - val_MinusLogProbMetric: 27.5940 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 245/1000
2023-09-12 18:08:08.124 
Epoch 245/1000 
	 loss: 27.3604, MinusLogProbMetric: 27.3604, val_loss: 27.5618, val_MinusLogProbMetric: 27.5618

Epoch 245: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3604 - MinusLogProbMetric: 27.3604 - val_loss: 27.5618 - val_MinusLogProbMetric: 27.5618 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 246/1000
2023-09-12 18:08:19.926 
Epoch 246/1000 
	 loss: 27.3651, MinusLogProbMetric: 27.3651, val_loss: 27.5596, val_MinusLogProbMetric: 27.5596

Epoch 246: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3651 - MinusLogProbMetric: 27.3651 - val_loss: 27.5596 - val_MinusLogProbMetric: 27.5596 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 247/1000
2023-09-12 18:08:31.748 
Epoch 247/1000 
	 loss: 27.3683, MinusLogProbMetric: 27.3683, val_loss: 27.5638, val_MinusLogProbMetric: 27.5638

Epoch 247: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3683 - MinusLogProbMetric: 27.3683 - val_loss: 27.5638 - val_MinusLogProbMetric: 27.5638 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-12 18:08:43.517 
Epoch 248/1000 
	 loss: 27.3674, MinusLogProbMetric: 27.3674, val_loss: 27.5636, val_MinusLogProbMetric: 27.5636

Epoch 248: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3674 - MinusLogProbMetric: 27.3674 - val_loss: 27.5636 - val_MinusLogProbMetric: 27.5636 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 249/1000
2023-09-12 18:08:55.204 
Epoch 249/1000 
	 loss: 27.3637, MinusLogProbMetric: 27.3637, val_loss: 27.5758, val_MinusLogProbMetric: 27.5758

Epoch 249: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3637 - MinusLogProbMetric: 27.3637 - val_loss: 27.5758 - val_MinusLogProbMetric: 27.5758 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 250/1000
2023-09-12 18:09:06.792 
Epoch 250/1000 
	 loss: 27.3644, MinusLogProbMetric: 27.3644, val_loss: 27.5570, val_MinusLogProbMetric: 27.5570

Epoch 250: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3644 - MinusLogProbMetric: 27.3644 - val_loss: 27.5570 - val_MinusLogProbMetric: 27.5570 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 251/1000
2023-09-12 18:09:18.597 
Epoch 251/1000 
	 loss: 27.3655, MinusLogProbMetric: 27.3655, val_loss: 27.5573, val_MinusLogProbMetric: 27.5573

Epoch 251: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3655 - MinusLogProbMetric: 27.3655 - val_loss: 27.5573 - val_MinusLogProbMetric: 27.5573 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 252/1000
2023-09-12 18:09:30.239 
Epoch 252/1000 
	 loss: 27.3627, MinusLogProbMetric: 27.3627, val_loss: 27.5570, val_MinusLogProbMetric: 27.5570

Epoch 252: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3627 - MinusLogProbMetric: 27.3627 - val_loss: 27.5570 - val_MinusLogProbMetric: 27.5570 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 253/1000
2023-09-12 18:09:41.996 
Epoch 253/1000 
	 loss: 27.3623, MinusLogProbMetric: 27.3623, val_loss: 27.5592, val_MinusLogProbMetric: 27.5592

Epoch 253: val_loss did not improve from 27.54892
196/196 - 12s - loss: 27.3623 - MinusLogProbMetric: 27.3623 - val_loss: 27.5592 - val_MinusLogProbMetric: 27.5592 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 254/1000
2023-09-12 18:09:53.662 
Epoch 254/1000 
	 loss: 27.3646, MinusLogProbMetric: 27.3646, val_loss: 27.5410, val_MinusLogProbMetric: 27.5410

Epoch 254: val_loss improved from 27.54892 to 27.54095, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.3646 - MinusLogProbMetric: 27.3646 - val_loss: 27.5410 - val_MinusLogProbMetric: 27.5410 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-12 18:10:05.631 
Epoch 255/1000 
	 loss: 27.3651, MinusLogProbMetric: 27.3651, val_loss: 27.5535, val_MinusLogProbMetric: 27.5535

Epoch 255: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3651 - MinusLogProbMetric: 27.3651 - val_loss: 27.5535 - val_MinusLogProbMetric: 27.5535 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 256/1000
2023-09-12 18:10:17.318 
Epoch 256/1000 
	 loss: 27.3614, MinusLogProbMetric: 27.3614, val_loss: 27.5615, val_MinusLogProbMetric: 27.5615

Epoch 256: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3614 - MinusLogProbMetric: 27.3614 - val_loss: 27.5615 - val_MinusLogProbMetric: 27.5615 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 257/1000
2023-09-12 18:10:29.005 
Epoch 257/1000 
	 loss: 27.3611, MinusLogProbMetric: 27.3611, val_loss: 27.5528, val_MinusLogProbMetric: 27.5528

Epoch 257: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3611 - MinusLogProbMetric: 27.3611 - val_loss: 27.5528 - val_MinusLogProbMetric: 27.5528 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-12 18:10:40.651 
Epoch 258/1000 
	 loss: 27.3585, MinusLogProbMetric: 27.3585, val_loss: 27.5650, val_MinusLogProbMetric: 27.5650

Epoch 258: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3585 - MinusLogProbMetric: 27.3585 - val_loss: 27.5650 - val_MinusLogProbMetric: 27.5650 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 259/1000
2023-09-12 18:10:52.127 
Epoch 259/1000 
	 loss: 27.3668, MinusLogProbMetric: 27.3668, val_loss: 27.5769, val_MinusLogProbMetric: 27.5769

Epoch 259: val_loss did not improve from 27.54095
196/196 - 11s - loss: 27.3668 - MinusLogProbMetric: 27.3668 - val_loss: 27.5769 - val_MinusLogProbMetric: 27.5769 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 260/1000
2023-09-12 18:11:03.767 
Epoch 260/1000 
	 loss: 27.3589, MinusLogProbMetric: 27.3589, val_loss: 27.5519, val_MinusLogProbMetric: 27.5519

Epoch 260: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3589 - MinusLogProbMetric: 27.3589 - val_loss: 27.5519 - val_MinusLogProbMetric: 27.5519 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 261/1000
2023-09-12 18:11:15.312 
Epoch 261/1000 
	 loss: 27.3612, MinusLogProbMetric: 27.3612, val_loss: 27.5608, val_MinusLogProbMetric: 27.5608

Epoch 261: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3612 - MinusLogProbMetric: 27.3612 - val_loss: 27.5608 - val_MinusLogProbMetric: 27.5608 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 262/1000
2023-09-12 18:11:26.914 
Epoch 262/1000 
	 loss: 27.3660, MinusLogProbMetric: 27.3660, val_loss: 27.5642, val_MinusLogProbMetric: 27.5642

Epoch 262: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3660 - MinusLogProbMetric: 27.3660 - val_loss: 27.5642 - val_MinusLogProbMetric: 27.5642 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 263/1000
2023-09-12 18:11:38.466 
Epoch 263/1000 
	 loss: 27.3632, MinusLogProbMetric: 27.3632, val_loss: 27.5621, val_MinusLogProbMetric: 27.5621

Epoch 263: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3632 - MinusLogProbMetric: 27.3632 - val_loss: 27.5621 - val_MinusLogProbMetric: 27.5621 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 264/1000
2023-09-12 18:11:50.099 
Epoch 264/1000 
	 loss: 27.3589, MinusLogProbMetric: 27.3589, val_loss: 27.5691, val_MinusLogProbMetric: 27.5691

Epoch 264: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3589 - MinusLogProbMetric: 27.3589 - val_loss: 27.5691 - val_MinusLogProbMetric: 27.5691 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 265/1000
2023-09-12 18:12:01.623 
Epoch 265/1000 
	 loss: 27.3603, MinusLogProbMetric: 27.3603, val_loss: 27.5522, val_MinusLogProbMetric: 27.5522

Epoch 265: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3603 - MinusLogProbMetric: 27.3603 - val_loss: 27.5522 - val_MinusLogProbMetric: 27.5522 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 266/1000
2023-09-12 18:12:13.272 
Epoch 266/1000 
	 loss: 27.3630, MinusLogProbMetric: 27.3630, val_loss: 27.5518, val_MinusLogProbMetric: 27.5518

Epoch 266: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3630 - MinusLogProbMetric: 27.3630 - val_loss: 27.5518 - val_MinusLogProbMetric: 27.5518 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 267/1000
2023-09-12 18:12:25.081 
Epoch 267/1000 
	 loss: 27.3620, MinusLogProbMetric: 27.3620, val_loss: 27.5546, val_MinusLogProbMetric: 27.5546

Epoch 267: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3620 - MinusLogProbMetric: 27.3620 - val_loss: 27.5546 - val_MinusLogProbMetric: 27.5546 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 268/1000
2023-09-12 18:12:36.748 
Epoch 268/1000 
	 loss: 27.3637, MinusLogProbMetric: 27.3637, val_loss: 27.5661, val_MinusLogProbMetric: 27.5661

Epoch 268: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3637 - MinusLogProbMetric: 27.3637 - val_loss: 27.5661 - val_MinusLogProbMetric: 27.5661 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 269/1000
2023-09-12 18:12:48.227 
Epoch 269/1000 
	 loss: 27.3607, MinusLogProbMetric: 27.3607, val_loss: 27.5591, val_MinusLogProbMetric: 27.5591

Epoch 269: val_loss did not improve from 27.54095
196/196 - 11s - loss: 27.3607 - MinusLogProbMetric: 27.3607 - val_loss: 27.5591 - val_MinusLogProbMetric: 27.5591 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 270/1000
2023-09-12 18:12:59.837 
Epoch 270/1000 
	 loss: 27.3593, MinusLogProbMetric: 27.3593, val_loss: 27.5703, val_MinusLogProbMetric: 27.5703

Epoch 270: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3593 - MinusLogProbMetric: 27.3593 - val_loss: 27.5703 - val_MinusLogProbMetric: 27.5703 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 271/1000
2023-09-12 18:13:11.593 
Epoch 271/1000 
	 loss: 27.3602, MinusLogProbMetric: 27.3602, val_loss: 27.5769, val_MinusLogProbMetric: 27.5769

Epoch 271: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3602 - MinusLogProbMetric: 27.3602 - val_loss: 27.5769 - val_MinusLogProbMetric: 27.5769 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 272/1000
2023-09-12 18:13:23.353 
Epoch 272/1000 
	 loss: 27.3580, MinusLogProbMetric: 27.3580, val_loss: 27.5660, val_MinusLogProbMetric: 27.5660

Epoch 272: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3580 - MinusLogProbMetric: 27.3580 - val_loss: 27.5660 - val_MinusLogProbMetric: 27.5660 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 273/1000
2023-09-12 18:13:35.252 
Epoch 273/1000 
	 loss: 27.3604, MinusLogProbMetric: 27.3604, val_loss: 27.5597, val_MinusLogProbMetric: 27.5597

Epoch 273: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3604 - MinusLogProbMetric: 27.3604 - val_loss: 27.5597 - val_MinusLogProbMetric: 27.5597 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 274/1000
2023-09-12 18:13:46.939 
Epoch 274/1000 
	 loss: 27.3606, MinusLogProbMetric: 27.3606, val_loss: 27.5739, val_MinusLogProbMetric: 27.5739

Epoch 274: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3606 - MinusLogProbMetric: 27.3606 - val_loss: 27.5739 - val_MinusLogProbMetric: 27.5739 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 275/1000
2023-09-12 18:13:58.643 
Epoch 275/1000 
	 loss: 27.3604, MinusLogProbMetric: 27.3604, val_loss: 27.5641, val_MinusLogProbMetric: 27.5641

Epoch 275: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3604 - MinusLogProbMetric: 27.3604 - val_loss: 27.5641 - val_MinusLogProbMetric: 27.5641 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 276/1000
2023-09-12 18:14:10.220 
Epoch 276/1000 
	 loss: 27.3586, MinusLogProbMetric: 27.3586, val_loss: 27.5712, val_MinusLogProbMetric: 27.5712

Epoch 276: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3586 - MinusLogProbMetric: 27.3586 - val_loss: 27.5712 - val_MinusLogProbMetric: 27.5712 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 277/1000
2023-09-12 18:14:21.864 
Epoch 277/1000 
	 loss: 27.3605, MinusLogProbMetric: 27.3605, val_loss: 27.5771, val_MinusLogProbMetric: 27.5771

Epoch 277: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3605 - MinusLogProbMetric: 27.3605 - val_loss: 27.5771 - val_MinusLogProbMetric: 27.5771 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 278/1000
2023-09-12 18:14:33.533 
Epoch 278/1000 
	 loss: 27.3599, MinusLogProbMetric: 27.3599, val_loss: 27.5765, val_MinusLogProbMetric: 27.5765

Epoch 278: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3599 - MinusLogProbMetric: 27.3599 - val_loss: 27.5765 - val_MinusLogProbMetric: 27.5765 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 279/1000
2023-09-12 18:14:45.294 
Epoch 279/1000 
	 loss: 27.3570, MinusLogProbMetric: 27.3570, val_loss: 27.5843, val_MinusLogProbMetric: 27.5843

Epoch 279: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3570 - MinusLogProbMetric: 27.3570 - val_loss: 27.5843 - val_MinusLogProbMetric: 27.5843 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 280/1000
2023-09-12 18:14:57.132 
Epoch 280/1000 
	 loss: 27.3554, MinusLogProbMetric: 27.3554, val_loss: 27.5773, val_MinusLogProbMetric: 27.5773

Epoch 280: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3554 - MinusLogProbMetric: 27.3554 - val_loss: 27.5773 - val_MinusLogProbMetric: 27.5773 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-12 18:15:08.764 
Epoch 281/1000 
	 loss: 27.3549, MinusLogProbMetric: 27.3549, val_loss: 27.5781, val_MinusLogProbMetric: 27.5781

Epoch 281: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3549 - MinusLogProbMetric: 27.3549 - val_loss: 27.5781 - val_MinusLogProbMetric: 27.5781 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 282/1000
2023-09-12 18:15:20.592 
Epoch 282/1000 
	 loss: 27.3570, MinusLogProbMetric: 27.3570, val_loss: 27.5571, val_MinusLogProbMetric: 27.5571

Epoch 282: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3570 - MinusLogProbMetric: 27.3570 - val_loss: 27.5571 - val_MinusLogProbMetric: 27.5571 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 283/1000
2023-09-12 18:15:31.984 
Epoch 283/1000 
	 loss: 27.3573, MinusLogProbMetric: 27.3573, val_loss: 27.5618, val_MinusLogProbMetric: 27.5618

Epoch 283: val_loss did not improve from 27.54095
196/196 - 11s - loss: 27.3573 - MinusLogProbMetric: 27.3573 - val_loss: 27.5618 - val_MinusLogProbMetric: 27.5618 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 284/1000
2023-09-12 18:15:43.412 
Epoch 284/1000 
	 loss: 27.3580, MinusLogProbMetric: 27.3580, val_loss: 27.5643, val_MinusLogProbMetric: 27.5643

Epoch 284: val_loss did not improve from 27.54095
196/196 - 11s - loss: 27.3580 - MinusLogProbMetric: 27.3580 - val_loss: 27.5643 - val_MinusLogProbMetric: 27.5643 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 285/1000
2023-09-12 18:15:55.206 
Epoch 285/1000 
	 loss: 27.3567, MinusLogProbMetric: 27.3567, val_loss: 27.5659, val_MinusLogProbMetric: 27.5659

Epoch 285: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3567 - MinusLogProbMetric: 27.3567 - val_loss: 27.5659 - val_MinusLogProbMetric: 27.5659 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 286/1000
2023-09-12 18:16:06.912 
Epoch 286/1000 
	 loss: 27.3537, MinusLogProbMetric: 27.3537, val_loss: 27.5809, val_MinusLogProbMetric: 27.5809

Epoch 286: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3537 - MinusLogProbMetric: 27.3537 - val_loss: 27.5809 - val_MinusLogProbMetric: 27.5809 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 287/1000
2023-09-12 18:16:17.352 
Epoch 287/1000 
	 loss: 27.3570, MinusLogProbMetric: 27.3570, val_loss: 27.5639, val_MinusLogProbMetric: 27.5639

Epoch 287: val_loss did not improve from 27.54095
196/196 - 10s - loss: 27.3570 - MinusLogProbMetric: 27.3570 - val_loss: 27.5639 - val_MinusLogProbMetric: 27.5639 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 288/1000
2023-09-12 18:16:29.110 
Epoch 288/1000 
	 loss: 27.3560, MinusLogProbMetric: 27.3560, val_loss: 27.5773, val_MinusLogProbMetric: 27.5773

Epoch 288: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3560 - MinusLogProbMetric: 27.3560 - val_loss: 27.5773 - val_MinusLogProbMetric: 27.5773 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 289/1000
2023-09-12 18:16:40.752 
Epoch 289/1000 
	 loss: 27.3570, MinusLogProbMetric: 27.3570, val_loss: 27.5679, val_MinusLogProbMetric: 27.5679

Epoch 289: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3570 - MinusLogProbMetric: 27.3570 - val_loss: 27.5679 - val_MinusLogProbMetric: 27.5679 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 290/1000
2023-09-12 18:16:52.436 
Epoch 290/1000 
	 loss: 27.3559, MinusLogProbMetric: 27.3559, val_loss: 27.5713, val_MinusLogProbMetric: 27.5713

Epoch 290: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3559 - MinusLogProbMetric: 27.3559 - val_loss: 27.5713 - val_MinusLogProbMetric: 27.5713 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 291/1000
2023-09-12 18:17:03.365 
Epoch 291/1000 
	 loss: 27.3524, MinusLogProbMetric: 27.3524, val_loss: 27.6019, val_MinusLogProbMetric: 27.6019

Epoch 291: val_loss did not improve from 27.54095
196/196 - 11s - loss: 27.3524 - MinusLogProbMetric: 27.3524 - val_loss: 27.6019 - val_MinusLogProbMetric: 27.6019 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 292/1000
2023-09-12 18:17:13.882 
Epoch 292/1000 
	 loss: 27.3565, MinusLogProbMetric: 27.3565, val_loss: 27.5671, val_MinusLogProbMetric: 27.5671

Epoch 292: val_loss did not improve from 27.54095
196/196 - 11s - loss: 27.3565 - MinusLogProbMetric: 27.3565 - val_loss: 27.5671 - val_MinusLogProbMetric: 27.5671 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 293/1000
2023-09-12 18:17:25.581 
Epoch 293/1000 
	 loss: 27.3490, MinusLogProbMetric: 27.3490, val_loss: 27.5661, val_MinusLogProbMetric: 27.5661

Epoch 293: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3490 - MinusLogProbMetric: 27.3490 - val_loss: 27.5661 - val_MinusLogProbMetric: 27.5661 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 294/1000
2023-09-12 18:17:37.214 
Epoch 294/1000 
	 loss: 27.3481, MinusLogProbMetric: 27.3481, val_loss: 27.5651, val_MinusLogProbMetric: 27.5651

Epoch 294: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3481 - MinusLogProbMetric: 27.3481 - val_loss: 27.5651 - val_MinusLogProbMetric: 27.5651 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 295/1000
2023-09-12 18:17:48.982 
Epoch 295/1000 
	 loss: 27.3529, MinusLogProbMetric: 27.3529, val_loss: 27.5697, val_MinusLogProbMetric: 27.5697

Epoch 295: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3529 - MinusLogProbMetric: 27.3529 - val_loss: 27.5697 - val_MinusLogProbMetric: 27.5697 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 296/1000
2023-09-12 18:18:00.650 
Epoch 296/1000 
	 loss: 27.3529, MinusLogProbMetric: 27.3529, val_loss: 27.6076, val_MinusLogProbMetric: 27.6076

Epoch 296: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3529 - MinusLogProbMetric: 27.3529 - val_loss: 27.6076 - val_MinusLogProbMetric: 27.6076 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 297/1000
2023-09-12 18:18:12.249 
Epoch 297/1000 
	 loss: 27.3599, MinusLogProbMetric: 27.3599, val_loss: 27.5750, val_MinusLogProbMetric: 27.5750

Epoch 297: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3599 - MinusLogProbMetric: 27.3599 - val_loss: 27.5750 - val_MinusLogProbMetric: 27.5750 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 298/1000
2023-09-12 18:18:23.862 
Epoch 298/1000 
	 loss: 27.3538, MinusLogProbMetric: 27.3538, val_loss: 27.5848, val_MinusLogProbMetric: 27.5848

Epoch 298: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3538 - MinusLogProbMetric: 27.3538 - val_loss: 27.5848 - val_MinusLogProbMetric: 27.5848 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 299/1000
2023-09-12 18:18:35.452 
Epoch 299/1000 
	 loss: 27.3525, MinusLogProbMetric: 27.3525, val_loss: 27.5637, val_MinusLogProbMetric: 27.5637

Epoch 299: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3525 - MinusLogProbMetric: 27.3525 - val_loss: 27.5637 - val_MinusLogProbMetric: 27.5637 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 300/1000
2023-09-12 18:18:47.002 
Epoch 300/1000 
	 loss: 27.3508, MinusLogProbMetric: 27.3508, val_loss: 27.5638, val_MinusLogProbMetric: 27.5638

Epoch 300: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3508 - MinusLogProbMetric: 27.3508 - val_loss: 27.5638 - val_MinusLogProbMetric: 27.5638 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 301/1000
2023-09-12 18:18:58.526 
Epoch 301/1000 
	 loss: 27.3531, MinusLogProbMetric: 27.3531, val_loss: 27.5643, val_MinusLogProbMetric: 27.5643

Epoch 301: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3531 - MinusLogProbMetric: 27.3531 - val_loss: 27.5643 - val_MinusLogProbMetric: 27.5643 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 302/1000
2023-09-12 18:19:10.366 
Epoch 302/1000 
	 loss: 27.3555, MinusLogProbMetric: 27.3555, val_loss: 27.5626, val_MinusLogProbMetric: 27.5626

Epoch 302: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3555 - MinusLogProbMetric: 27.3555 - val_loss: 27.5626 - val_MinusLogProbMetric: 27.5626 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 303/1000
2023-09-12 18:19:21.988 
Epoch 303/1000 
	 loss: 27.3523, MinusLogProbMetric: 27.3523, val_loss: 27.5708, val_MinusLogProbMetric: 27.5708

Epoch 303: val_loss did not improve from 27.54095
196/196 - 12s - loss: 27.3523 - MinusLogProbMetric: 27.3523 - val_loss: 27.5708 - val_MinusLogProbMetric: 27.5708 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 304/1000
2023-09-12 18:19:33.427 
Epoch 304/1000 
	 loss: 27.3512, MinusLogProbMetric: 27.3512, val_loss: 27.5782, val_MinusLogProbMetric: 27.5782

Epoch 304: val_loss did not improve from 27.54095
196/196 - 11s - loss: 27.3512 - MinusLogProbMetric: 27.3512 - val_loss: 27.5782 - val_MinusLogProbMetric: 27.5782 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 305/1000
2023-09-12 18:19:44.941 
Epoch 305/1000 
	 loss: 27.3176, MinusLogProbMetric: 27.3176, val_loss: 27.5352, val_MinusLogProbMetric: 27.5352

Epoch 305: val_loss improved from 27.54095 to 27.53521, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.3176 - MinusLogProbMetric: 27.3176 - val_loss: 27.5352 - val_MinusLogProbMetric: 27.5352 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 306/1000
2023-09-12 18:19:56.624 
Epoch 306/1000 
	 loss: 27.3156, MinusLogProbMetric: 27.3156, val_loss: 27.5317, val_MinusLogProbMetric: 27.5317

Epoch 306: val_loss improved from 27.53521 to 27.53169, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.3156 - MinusLogProbMetric: 27.3156 - val_loss: 27.5317 - val_MinusLogProbMetric: 27.5317 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 307/1000
2023-09-12 18:20:08.276 
Epoch 307/1000 
	 loss: 27.3129, MinusLogProbMetric: 27.3129, val_loss: 27.5438, val_MinusLogProbMetric: 27.5438

Epoch 307: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3129 - MinusLogProbMetric: 27.3129 - val_loss: 27.5438 - val_MinusLogProbMetric: 27.5438 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 308/1000
2023-09-12 18:20:19.817 
Epoch 308/1000 
	 loss: 27.3136, MinusLogProbMetric: 27.3136, val_loss: 27.5417, val_MinusLogProbMetric: 27.5417

Epoch 308: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3136 - MinusLogProbMetric: 27.3136 - val_loss: 27.5417 - val_MinusLogProbMetric: 27.5417 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 309/1000
2023-09-12 18:20:31.321 
Epoch 309/1000 
	 loss: 27.3128, MinusLogProbMetric: 27.3128, val_loss: 27.5365, val_MinusLogProbMetric: 27.5365

Epoch 309: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3128 - MinusLogProbMetric: 27.3128 - val_loss: 27.5365 - val_MinusLogProbMetric: 27.5365 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 310/1000
2023-09-12 18:20:42.929 
Epoch 310/1000 
	 loss: 27.3141, MinusLogProbMetric: 27.3141, val_loss: 27.5445, val_MinusLogProbMetric: 27.5445

Epoch 310: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3141 - MinusLogProbMetric: 27.3141 - val_loss: 27.5445 - val_MinusLogProbMetric: 27.5445 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 311/1000
2023-09-12 18:20:54.480 
Epoch 311/1000 
	 loss: 27.3152, MinusLogProbMetric: 27.3152, val_loss: 27.5396, val_MinusLogProbMetric: 27.5396

Epoch 311: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3152 - MinusLogProbMetric: 27.3152 - val_loss: 27.5396 - val_MinusLogProbMetric: 27.5396 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 312/1000
2023-09-12 18:21:06.015 
Epoch 312/1000 
	 loss: 27.3144, MinusLogProbMetric: 27.3144, val_loss: 27.5425, val_MinusLogProbMetric: 27.5425

Epoch 312: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3144 - MinusLogProbMetric: 27.3144 - val_loss: 27.5425 - val_MinusLogProbMetric: 27.5425 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 313/1000
2023-09-12 18:21:17.580 
Epoch 313/1000 
	 loss: 27.3147, MinusLogProbMetric: 27.3147, val_loss: 27.5415, val_MinusLogProbMetric: 27.5415

Epoch 313: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3147 - MinusLogProbMetric: 27.3147 - val_loss: 27.5415 - val_MinusLogProbMetric: 27.5415 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 314/1000
2023-09-12 18:21:29.285 
Epoch 314/1000 
	 loss: 27.3135, MinusLogProbMetric: 27.3135, val_loss: 27.5319, val_MinusLogProbMetric: 27.5319

Epoch 314: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3135 - MinusLogProbMetric: 27.3135 - val_loss: 27.5319 - val_MinusLogProbMetric: 27.5319 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 315/1000
2023-09-12 18:21:40.284 
Epoch 315/1000 
	 loss: 27.3164, MinusLogProbMetric: 27.3164, val_loss: 27.5431, val_MinusLogProbMetric: 27.5431

Epoch 315: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3164 - MinusLogProbMetric: 27.3164 - val_loss: 27.5431 - val_MinusLogProbMetric: 27.5431 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 316/1000
2023-09-12 18:21:50.839 
Epoch 316/1000 
	 loss: 27.3113, MinusLogProbMetric: 27.3113, val_loss: 27.5402, val_MinusLogProbMetric: 27.5402

Epoch 316: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3113 - MinusLogProbMetric: 27.3113 - val_loss: 27.5402 - val_MinusLogProbMetric: 27.5402 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 317/1000
2023-09-12 18:22:02.002 
Epoch 317/1000 
	 loss: 27.3129, MinusLogProbMetric: 27.3129, val_loss: 27.5357, val_MinusLogProbMetric: 27.5357

Epoch 317: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3129 - MinusLogProbMetric: 27.3129 - val_loss: 27.5357 - val_MinusLogProbMetric: 27.5357 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 318/1000
2023-09-12 18:22:13.363 
Epoch 318/1000 
	 loss: 27.3128, MinusLogProbMetric: 27.3128, val_loss: 27.5391, val_MinusLogProbMetric: 27.5391

Epoch 318: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3128 - MinusLogProbMetric: 27.3128 - val_loss: 27.5391 - val_MinusLogProbMetric: 27.5391 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 319/1000
2023-09-12 18:22:24.939 
Epoch 319/1000 
	 loss: 27.3141, MinusLogProbMetric: 27.3141, val_loss: 27.5448, val_MinusLogProbMetric: 27.5448

Epoch 319: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3141 - MinusLogProbMetric: 27.3141 - val_loss: 27.5448 - val_MinusLogProbMetric: 27.5448 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 320/1000
2023-09-12 18:22:36.520 
Epoch 320/1000 
	 loss: 27.3107, MinusLogProbMetric: 27.3107, val_loss: 27.5569, val_MinusLogProbMetric: 27.5569

Epoch 320: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3107 - MinusLogProbMetric: 27.3107 - val_loss: 27.5569 - val_MinusLogProbMetric: 27.5569 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 321/1000
2023-09-12 18:22:48.023 
Epoch 321/1000 
	 loss: 27.3133, MinusLogProbMetric: 27.3133, val_loss: 27.5408, val_MinusLogProbMetric: 27.5408

Epoch 321: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3133 - MinusLogProbMetric: 27.3133 - val_loss: 27.5408 - val_MinusLogProbMetric: 27.5408 - lr: 2.5000e-04 - 11s/epoch - 59ms/step
Epoch 322/1000
2023-09-12 18:22:59.266 
Epoch 322/1000 
	 loss: 27.3154, MinusLogProbMetric: 27.3154, val_loss: 27.5457, val_MinusLogProbMetric: 27.5457

Epoch 322: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3154 - MinusLogProbMetric: 27.3154 - val_loss: 27.5457 - val_MinusLogProbMetric: 27.5457 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 323/1000
2023-09-12 18:23:10.852 
Epoch 323/1000 
	 loss: 27.3108, MinusLogProbMetric: 27.3108, val_loss: 27.5395, val_MinusLogProbMetric: 27.5395

Epoch 323: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3108 - MinusLogProbMetric: 27.3108 - val_loss: 27.5395 - val_MinusLogProbMetric: 27.5395 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 324/1000
2023-09-12 18:23:21.630 
Epoch 324/1000 
	 loss: 27.3113, MinusLogProbMetric: 27.3113, val_loss: 27.5352, val_MinusLogProbMetric: 27.5352

Epoch 324: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3113 - MinusLogProbMetric: 27.3113 - val_loss: 27.5352 - val_MinusLogProbMetric: 27.5352 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 325/1000
2023-09-12 18:23:33.324 
Epoch 325/1000 
	 loss: 27.3098, MinusLogProbMetric: 27.3098, val_loss: 27.5466, val_MinusLogProbMetric: 27.5466

Epoch 325: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3098 - MinusLogProbMetric: 27.3098 - val_loss: 27.5466 - val_MinusLogProbMetric: 27.5466 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 326/1000
2023-09-12 18:23:45.033 
Epoch 326/1000 
	 loss: 27.3113, MinusLogProbMetric: 27.3113, val_loss: 27.5376, val_MinusLogProbMetric: 27.5376

Epoch 326: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3113 - MinusLogProbMetric: 27.3113 - val_loss: 27.5376 - val_MinusLogProbMetric: 27.5376 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 327/1000
2023-09-12 18:23:56.740 
Epoch 327/1000 
	 loss: 27.3099, MinusLogProbMetric: 27.3099, val_loss: 27.5515, val_MinusLogProbMetric: 27.5515

Epoch 327: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3099 - MinusLogProbMetric: 27.3099 - val_loss: 27.5515 - val_MinusLogProbMetric: 27.5515 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 328/1000
2023-09-12 18:24:06.667 
Epoch 328/1000 
	 loss: 27.3118, MinusLogProbMetric: 27.3118, val_loss: 27.5481, val_MinusLogProbMetric: 27.5481

Epoch 328: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3118 - MinusLogProbMetric: 27.3118 - val_loss: 27.5481 - val_MinusLogProbMetric: 27.5481 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 329/1000
2023-09-12 18:24:18.251 
Epoch 329/1000 
	 loss: 27.3111, MinusLogProbMetric: 27.3111, val_loss: 27.5381, val_MinusLogProbMetric: 27.5381

Epoch 329: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3111 - MinusLogProbMetric: 27.3111 - val_loss: 27.5381 - val_MinusLogProbMetric: 27.5381 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 330/1000
2023-09-12 18:24:28.812 
Epoch 330/1000 
	 loss: 27.3114, MinusLogProbMetric: 27.3114, val_loss: 27.5347, val_MinusLogProbMetric: 27.5347

Epoch 330: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3114 - MinusLogProbMetric: 27.3114 - val_loss: 27.5347 - val_MinusLogProbMetric: 27.5347 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 331/1000
2023-09-12 18:24:40.219 
Epoch 331/1000 
	 loss: 27.3120, MinusLogProbMetric: 27.3120, val_loss: 27.5403, val_MinusLogProbMetric: 27.5403

Epoch 331: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3120 - MinusLogProbMetric: 27.3120 - val_loss: 27.5403 - val_MinusLogProbMetric: 27.5403 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 332/1000
2023-09-12 18:24:51.683 
Epoch 332/1000 
	 loss: 27.3099, MinusLogProbMetric: 27.3099, val_loss: 27.5505, val_MinusLogProbMetric: 27.5505

Epoch 332: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3099 - MinusLogProbMetric: 27.3099 - val_loss: 27.5505 - val_MinusLogProbMetric: 27.5505 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 333/1000
2023-09-12 18:25:01.549 
Epoch 333/1000 
	 loss: 27.3135, MinusLogProbMetric: 27.3135, val_loss: 27.5536, val_MinusLogProbMetric: 27.5536

Epoch 333: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3135 - MinusLogProbMetric: 27.3135 - val_loss: 27.5536 - val_MinusLogProbMetric: 27.5536 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 334/1000
2023-09-12 18:25:11.408 
Epoch 334/1000 
	 loss: 27.3100, MinusLogProbMetric: 27.3100, val_loss: 27.5476, val_MinusLogProbMetric: 27.5476

Epoch 334: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3100 - MinusLogProbMetric: 27.3100 - val_loss: 27.5476 - val_MinusLogProbMetric: 27.5476 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 335/1000
2023-09-12 18:25:21.287 
Epoch 335/1000 
	 loss: 27.3104, MinusLogProbMetric: 27.3104, val_loss: 27.5454, val_MinusLogProbMetric: 27.5454

Epoch 335: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3104 - MinusLogProbMetric: 27.3104 - val_loss: 27.5454 - val_MinusLogProbMetric: 27.5454 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 336/1000
2023-09-12 18:25:31.084 
Epoch 336/1000 
	 loss: 27.3097, MinusLogProbMetric: 27.3097, val_loss: 27.5425, val_MinusLogProbMetric: 27.5425

Epoch 336: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3097 - MinusLogProbMetric: 27.3097 - val_loss: 27.5425 - val_MinusLogProbMetric: 27.5425 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 337/1000
2023-09-12 18:25:41.160 
Epoch 337/1000 
	 loss: 27.3107, MinusLogProbMetric: 27.3107, val_loss: 27.5338, val_MinusLogProbMetric: 27.5338

Epoch 337: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3107 - MinusLogProbMetric: 27.3107 - val_loss: 27.5338 - val_MinusLogProbMetric: 27.5338 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 338/1000
2023-09-12 18:25:52.761 
Epoch 338/1000 
	 loss: 27.3099, MinusLogProbMetric: 27.3099, val_loss: 27.5446, val_MinusLogProbMetric: 27.5446

Epoch 338: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3099 - MinusLogProbMetric: 27.3099 - val_loss: 27.5446 - val_MinusLogProbMetric: 27.5446 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 339/1000
2023-09-12 18:26:02.886 
Epoch 339/1000 
	 loss: 27.3090, MinusLogProbMetric: 27.3090, val_loss: 27.5614, val_MinusLogProbMetric: 27.5614

Epoch 339: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3090 - MinusLogProbMetric: 27.3090 - val_loss: 27.5614 - val_MinusLogProbMetric: 27.5614 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 340/1000
2023-09-12 18:26:14.554 
Epoch 340/1000 
	 loss: 27.3099, MinusLogProbMetric: 27.3099, val_loss: 27.5469, val_MinusLogProbMetric: 27.5469

Epoch 340: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3099 - MinusLogProbMetric: 27.3099 - val_loss: 27.5469 - val_MinusLogProbMetric: 27.5469 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 341/1000
2023-09-12 18:26:25.893 
Epoch 341/1000 
	 loss: 27.3083, MinusLogProbMetric: 27.3083, val_loss: 27.5447, val_MinusLogProbMetric: 27.5447

Epoch 341: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3083 - MinusLogProbMetric: 27.3083 - val_loss: 27.5447 - val_MinusLogProbMetric: 27.5447 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 342/1000
2023-09-12 18:26:37.042 
Epoch 342/1000 
	 loss: 27.3110, MinusLogProbMetric: 27.3110, val_loss: 27.5398, val_MinusLogProbMetric: 27.5398

Epoch 342: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3110 - MinusLogProbMetric: 27.3110 - val_loss: 27.5398 - val_MinusLogProbMetric: 27.5398 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 343/1000
2023-09-12 18:26:48.736 
Epoch 343/1000 
	 loss: 27.3083, MinusLogProbMetric: 27.3083, val_loss: 27.5342, val_MinusLogProbMetric: 27.5342

Epoch 343: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3083 - MinusLogProbMetric: 27.3083 - val_loss: 27.5342 - val_MinusLogProbMetric: 27.5342 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 344/1000
2023-09-12 18:27:00.325 
Epoch 344/1000 
	 loss: 27.3080, MinusLogProbMetric: 27.3080, val_loss: 27.5515, val_MinusLogProbMetric: 27.5515

Epoch 344: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3080 - MinusLogProbMetric: 27.3080 - val_loss: 27.5515 - val_MinusLogProbMetric: 27.5515 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 345/1000
2023-09-12 18:27:10.219 
Epoch 345/1000 
	 loss: 27.3083, MinusLogProbMetric: 27.3083, val_loss: 27.5340, val_MinusLogProbMetric: 27.5340

Epoch 345: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3083 - MinusLogProbMetric: 27.3083 - val_loss: 27.5340 - val_MinusLogProbMetric: 27.5340 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 346/1000
2023-09-12 18:27:21.481 
Epoch 346/1000 
	 loss: 27.3074, MinusLogProbMetric: 27.3074, val_loss: 27.5439, val_MinusLogProbMetric: 27.5439

Epoch 346: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3074 - MinusLogProbMetric: 27.3074 - val_loss: 27.5439 - val_MinusLogProbMetric: 27.5439 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 347/1000
2023-09-12 18:27:33.272 
Epoch 347/1000 
	 loss: 27.3067, MinusLogProbMetric: 27.3067, val_loss: 27.5398, val_MinusLogProbMetric: 27.5398

Epoch 347: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3067 - MinusLogProbMetric: 27.3067 - val_loss: 27.5398 - val_MinusLogProbMetric: 27.5398 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 348/1000
2023-09-12 18:27:44.668 
Epoch 348/1000 
	 loss: 27.3081, MinusLogProbMetric: 27.3081, val_loss: 27.5478, val_MinusLogProbMetric: 27.5478

Epoch 348: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3081 - MinusLogProbMetric: 27.3081 - val_loss: 27.5478 - val_MinusLogProbMetric: 27.5478 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 349/1000
2023-09-12 18:27:56.461 
Epoch 349/1000 
	 loss: 27.3084, MinusLogProbMetric: 27.3084, val_loss: 27.5469, val_MinusLogProbMetric: 27.5469

Epoch 349: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3084 - MinusLogProbMetric: 27.3084 - val_loss: 27.5469 - val_MinusLogProbMetric: 27.5469 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 350/1000
2023-09-12 18:28:07.414 
Epoch 350/1000 
	 loss: 27.3101, MinusLogProbMetric: 27.3101, val_loss: 27.5459, val_MinusLogProbMetric: 27.5459

Epoch 350: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3101 - MinusLogProbMetric: 27.3101 - val_loss: 27.5459 - val_MinusLogProbMetric: 27.5459 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 351/1000
2023-09-12 18:28:18.122 
Epoch 351/1000 
	 loss: 27.3091, MinusLogProbMetric: 27.3091, val_loss: 27.5473, val_MinusLogProbMetric: 27.5473

Epoch 351: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3091 - MinusLogProbMetric: 27.3091 - val_loss: 27.5473 - val_MinusLogProbMetric: 27.5473 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 352/1000
2023-09-12 18:28:29.636 
Epoch 352/1000 
	 loss: 27.3065, MinusLogProbMetric: 27.3065, val_loss: 27.5432, val_MinusLogProbMetric: 27.5432

Epoch 352: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3065 - MinusLogProbMetric: 27.3065 - val_loss: 27.5432 - val_MinusLogProbMetric: 27.5432 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 353/1000
2023-09-12 18:28:41.404 
Epoch 353/1000 
	 loss: 27.3083, MinusLogProbMetric: 27.3083, val_loss: 27.5470, val_MinusLogProbMetric: 27.5470

Epoch 353: val_loss did not improve from 27.53169
196/196 - 12s - loss: 27.3083 - MinusLogProbMetric: 27.3083 - val_loss: 27.5470 - val_MinusLogProbMetric: 27.5470 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 354/1000
2023-09-12 18:28:52.473 
Epoch 354/1000 
	 loss: 27.3077, MinusLogProbMetric: 27.3077, val_loss: 27.5459, val_MinusLogProbMetric: 27.5459

Epoch 354: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.3077 - MinusLogProbMetric: 27.3077 - val_loss: 27.5459 - val_MinusLogProbMetric: 27.5459 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 355/1000
2023-09-12 18:29:02.815 
Epoch 355/1000 
	 loss: 27.3054, MinusLogProbMetric: 27.3054, val_loss: 27.5375, val_MinusLogProbMetric: 27.5375

Epoch 355: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3054 - MinusLogProbMetric: 27.3054 - val_loss: 27.5375 - val_MinusLogProbMetric: 27.5375 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 356/1000
2023-09-12 18:29:13.161 
Epoch 356/1000 
	 loss: 27.3079, MinusLogProbMetric: 27.3079, val_loss: 27.5454, val_MinusLogProbMetric: 27.5454

Epoch 356: val_loss did not improve from 27.53169
196/196 - 10s - loss: 27.3079 - MinusLogProbMetric: 27.3079 - val_loss: 27.5454 - val_MinusLogProbMetric: 27.5454 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 357/1000
2023-09-12 18:29:24.131 
Epoch 357/1000 
	 loss: 27.2901, MinusLogProbMetric: 27.2901, val_loss: 27.5359, val_MinusLogProbMetric: 27.5359

Epoch 357: val_loss did not improve from 27.53169
196/196 - 11s - loss: 27.2901 - MinusLogProbMetric: 27.2901 - val_loss: 27.5359 - val_MinusLogProbMetric: 27.5359 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 358/1000
2023-09-12 18:29:35.387 
Epoch 358/1000 
	 loss: 27.2887, MinusLogProbMetric: 27.2887, val_loss: 27.5316, val_MinusLogProbMetric: 27.5316

Epoch 358: val_loss improved from 27.53169 to 27.53156, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.2887 - MinusLogProbMetric: 27.2887 - val_loss: 27.5316 - val_MinusLogProbMetric: 27.5316 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 359/1000
2023-09-12 18:29:46.153 
Epoch 359/1000 
	 loss: 27.2899, MinusLogProbMetric: 27.2899, val_loss: 27.5334, val_MinusLogProbMetric: 27.5334

Epoch 359: val_loss did not improve from 27.53156
196/196 - 11s - loss: 27.2899 - MinusLogProbMetric: 27.2899 - val_loss: 27.5334 - val_MinusLogProbMetric: 27.5334 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 360/1000
2023-09-12 18:29:56.621 
Epoch 360/1000 
	 loss: 27.2883, MinusLogProbMetric: 27.2883, val_loss: 27.5299, val_MinusLogProbMetric: 27.5299

Epoch 360: val_loss improved from 27.53156 to 27.52991, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 11s - loss: 27.2883 - MinusLogProbMetric: 27.2883 - val_loss: 27.5299 - val_MinusLogProbMetric: 27.5299 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 361/1000
2023-09-12 18:30:06.590 
Epoch 361/1000 
	 loss: 27.2891, MinusLogProbMetric: 27.2891, val_loss: 27.5344, val_MinusLogProbMetric: 27.5344

Epoch 361: val_loss did not improve from 27.52991
196/196 - 10s - loss: 27.2891 - MinusLogProbMetric: 27.2891 - val_loss: 27.5344 - val_MinusLogProbMetric: 27.5344 - lr: 1.2500e-04 - 10s/epoch - 50ms/step
Epoch 362/1000
2023-09-12 18:30:18.233 
Epoch 362/1000 
	 loss: 27.2880, MinusLogProbMetric: 27.2880, val_loss: 27.5314, val_MinusLogProbMetric: 27.5314

Epoch 362: val_loss did not improve from 27.52991
196/196 - 12s - loss: 27.2880 - MinusLogProbMetric: 27.2880 - val_loss: 27.5314 - val_MinusLogProbMetric: 27.5314 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 363/1000
2023-09-12 18:30:28.770 
Epoch 363/1000 
	 loss: 27.2881, MinusLogProbMetric: 27.2881, val_loss: 27.5364, val_MinusLogProbMetric: 27.5364

Epoch 363: val_loss did not improve from 27.52991
196/196 - 11s - loss: 27.2881 - MinusLogProbMetric: 27.2881 - val_loss: 27.5364 - val_MinusLogProbMetric: 27.5364 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 364/1000
2023-09-12 18:30:40.028 
Epoch 364/1000 
	 loss: 27.2891, MinusLogProbMetric: 27.2891, val_loss: 27.5315, val_MinusLogProbMetric: 27.5315

Epoch 364: val_loss did not improve from 27.52991
196/196 - 11s - loss: 27.2891 - MinusLogProbMetric: 27.2891 - val_loss: 27.5315 - val_MinusLogProbMetric: 27.5315 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 365/1000
2023-09-12 18:30:50.263 
Epoch 365/1000 
	 loss: 27.2883, MinusLogProbMetric: 27.2883, val_loss: 27.5290, val_MinusLogProbMetric: 27.5290

Epoch 365: val_loss improved from 27.52991 to 27.52905, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 10s - loss: 27.2883 - MinusLogProbMetric: 27.2883 - val_loss: 27.5290 - val_MinusLogProbMetric: 27.5290 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 366/1000
2023-09-12 18:31:00.667 
Epoch 366/1000 
	 loss: 27.2886, MinusLogProbMetric: 27.2886, val_loss: 27.5327, val_MinusLogProbMetric: 27.5327

Epoch 366: val_loss did not improve from 27.52905
196/196 - 10s - loss: 27.2886 - MinusLogProbMetric: 27.2886 - val_loss: 27.5327 - val_MinusLogProbMetric: 27.5327 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 367/1000
2023-09-12 18:31:11.595 
Epoch 367/1000 
	 loss: 27.2866, MinusLogProbMetric: 27.2866, val_loss: 27.5308, val_MinusLogProbMetric: 27.5308

Epoch 367: val_loss did not improve from 27.52905
196/196 - 11s - loss: 27.2866 - MinusLogProbMetric: 27.2866 - val_loss: 27.5308 - val_MinusLogProbMetric: 27.5308 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 368/1000
2023-09-12 18:31:22.478 
Epoch 368/1000 
	 loss: 27.2879, MinusLogProbMetric: 27.2879, val_loss: 27.5334, val_MinusLogProbMetric: 27.5334

Epoch 368: val_loss did not improve from 27.52905
196/196 - 11s - loss: 27.2879 - MinusLogProbMetric: 27.2879 - val_loss: 27.5334 - val_MinusLogProbMetric: 27.5334 - lr: 1.2500e-04 - 11s/epoch - 56ms/step
Epoch 369/1000
2023-09-12 18:31:32.892 
Epoch 369/1000 
	 loss: 27.2879, MinusLogProbMetric: 27.2879, val_loss: 27.5334, val_MinusLogProbMetric: 27.5334

Epoch 369: val_loss did not improve from 27.52905
196/196 - 10s - loss: 27.2879 - MinusLogProbMetric: 27.2879 - val_loss: 27.5334 - val_MinusLogProbMetric: 27.5334 - lr: 1.2500e-04 - 10s/epoch - 53ms/step
Epoch 370/1000
2023-09-12 18:31:43.478 
Epoch 370/1000 
	 loss: 27.2876, MinusLogProbMetric: 27.2876, val_loss: 27.5323, val_MinusLogProbMetric: 27.5323

Epoch 370: val_loss did not improve from 27.52905
196/196 - 11s - loss: 27.2876 - MinusLogProbMetric: 27.2876 - val_loss: 27.5323 - val_MinusLogProbMetric: 27.5323 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 371/1000
2023-09-12 18:31:55.160 
Epoch 371/1000 
	 loss: 27.2880, MinusLogProbMetric: 27.2880, val_loss: 27.5310, val_MinusLogProbMetric: 27.5310

Epoch 371: val_loss did not improve from 27.52905
196/196 - 12s - loss: 27.2880 - MinusLogProbMetric: 27.2880 - val_loss: 27.5310 - val_MinusLogProbMetric: 27.5310 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 372/1000
2023-09-12 18:32:06.724 
Epoch 372/1000 
	 loss: 27.2879, MinusLogProbMetric: 27.2879, val_loss: 27.5362, val_MinusLogProbMetric: 27.5362

Epoch 372: val_loss did not improve from 27.52905
196/196 - 12s - loss: 27.2879 - MinusLogProbMetric: 27.2879 - val_loss: 27.5362 - val_MinusLogProbMetric: 27.5362 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 373/1000
2023-09-12 18:32:17.482 
Epoch 373/1000 
	 loss: 27.2881, MinusLogProbMetric: 27.2881, val_loss: 27.5315, val_MinusLogProbMetric: 27.5315

Epoch 373: val_loss did not improve from 27.52905
196/196 - 11s - loss: 27.2881 - MinusLogProbMetric: 27.2881 - val_loss: 27.5315 - val_MinusLogProbMetric: 27.5315 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 374/1000
2023-09-12 18:32:27.702 
Epoch 374/1000 
	 loss: 27.2870, MinusLogProbMetric: 27.2870, val_loss: 27.5326, val_MinusLogProbMetric: 27.5326

Epoch 374: val_loss did not improve from 27.52905
196/196 - 10s - loss: 27.2870 - MinusLogProbMetric: 27.2870 - val_loss: 27.5326 - val_MinusLogProbMetric: 27.5326 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 375/1000
2023-09-12 18:32:39.427 
Epoch 375/1000 
	 loss: 27.2877, MinusLogProbMetric: 27.2877, val_loss: 27.5356, val_MinusLogProbMetric: 27.5356

Epoch 375: val_loss did not improve from 27.52905
196/196 - 12s - loss: 27.2877 - MinusLogProbMetric: 27.2877 - val_loss: 27.5356 - val_MinusLogProbMetric: 27.5356 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 376/1000
2023-09-12 18:32:51.137 
Epoch 376/1000 
	 loss: 27.2883, MinusLogProbMetric: 27.2883, val_loss: 27.5285, val_MinusLogProbMetric: 27.5285

Epoch 376: val_loss improved from 27.52905 to 27.52850, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.2883 - MinusLogProbMetric: 27.2883 - val_loss: 27.5285 - val_MinusLogProbMetric: 27.5285 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 377/1000
2023-09-12 18:33:03.114 
Epoch 377/1000 
	 loss: 27.2878, MinusLogProbMetric: 27.2878, val_loss: 27.5339, val_MinusLogProbMetric: 27.5339

Epoch 377: val_loss did not improve from 27.52850
196/196 - 12s - loss: 27.2878 - MinusLogProbMetric: 27.2878 - val_loss: 27.5339 - val_MinusLogProbMetric: 27.5339 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 378/1000
2023-09-12 18:33:14.847 
Epoch 378/1000 
	 loss: 27.2874, MinusLogProbMetric: 27.2874, val_loss: 27.5324, val_MinusLogProbMetric: 27.5324

Epoch 378: val_loss did not improve from 27.52850
196/196 - 12s - loss: 27.2874 - MinusLogProbMetric: 27.2874 - val_loss: 27.5324 - val_MinusLogProbMetric: 27.5324 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 379/1000
2023-09-12 18:33:26.578 
Epoch 379/1000 
	 loss: 27.2873, MinusLogProbMetric: 27.2873, val_loss: 27.5274, val_MinusLogProbMetric: 27.5274

Epoch 379: val_loss improved from 27.52850 to 27.52742, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_163/weights/best_weights.h5
196/196 - 12s - loss: 27.2873 - MinusLogProbMetric: 27.2873 - val_loss: 27.5274 - val_MinusLogProbMetric: 27.5274 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-12 18:33:38.460 
Epoch 380/1000 
	 loss: 27.2878, MinusLogProbMetric: 27.2878, val_loss: 27.5341, val_MinusLogProbMetric: 27.5341

Epoch 380: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2878 - MinusLogProbMetric: 27.2878 - val_loss: 27.5341 - val_MinusLogProbMetric: 27.5341 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 381/1000
2023-09-12 18:33:49.084 
Epoch 381/1000 
	 loss: 27.2868, MinusLogProbMetric: 27.2868, val_loss: 27.5335, val_MinusLogProbMetric: 27.5335

Epoch 381: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2868 - MinusLogProbMetric: 27.2868 - val_loss: 27.5335 - val_MinusLogProbMetric: 27.5335 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 382/1000
2023-09-12 18:34:00.309 
Epoch 382/1000 
	 loss: 27.2874, MinusLogProbMetric: 27.2874, val_loss: 27.5338, val_MinusLogProbMetric: 27.5338

Epoch 382: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2874 - MinusLogProbMetric: 27.2874 - val_loss: 27.5338 - val_MinusLogProbMetric: 27.5338 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 383/1000
2023-09-12 18:34:10.164 
Epoch 383/1000 
	 loss: 27.2875, MinusLogProbMetric: 27.2875, val_loss: 27.5350, val_MinusLogProbMetric: 27.5350

Epoch 383: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2875 - MinusLogProbMetric: 27.2875 - val_loss: 27.5350 - val_MinusLogProbMetric: 27.5350 - lr: 1.2500e-04 - 10s/epoch - 50ms/step
Epoch 384/1000
2023-09-12 18:34:20.686 
Epoch 384/1000 
	 loss: 27.2878, MinusLogProbMetric: 27.2878, val_loss: 27.5346, val_MinusLogProbMetric: 27.5346

Epoch 384: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2878 - MinusLogProbMetric: 27.2878 - val_loss: 27.5346 - val_MinusLogProbMetric: 27.5346 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 385/1000
2023-09-12 18:34:32.625 
Epoch 385/1000 
	 loss: 27.2870, MinusLogProbMetric: 27.2870, val_loss: 27.5294, val_MinusLogProbMetric: 27.5294

Epoch 385: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2870 - MinusLogProbMetric: 27.2870 - val_loss: 27.5294 - val_MinusLogProbMetric: 27.5294 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 386/1000
2023-09-12 18:34:43.764 
Epoch 386/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.5315, val_MinusLogProbMetric: 27.5315

Epoch 386: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.5315 - val_MinusLogProbMetric: 27.5315 - lr: 1.2500e-04 - 11s/epoch - 57ms/step
Epoch 387/1000
2023-09-12 18:34:55.273 
Epoch 387/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.5347, val_MinusLogProbMetric: 27.5347

Epoch 387: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.5347 - val_MinusLogProbMetric: 27.5347 - lr: 1.2500e-04 - 12s/epoch - 59ms/step
Epoch 388/1000
2023-09-12 18:35:07.212 
Epoch 388/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.5368, val_MinusLogProbMetric: 27.5368

Epoch 388: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.5368 - val_MinusLogProbMetric: 27.5368 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 389/1000
2023-09-12 18:35:18.900 
Epoch 389/1000 
	 loss: 27.2875, MinusLogProbMetric: 27.2875, val_loss: 27.5319, val_MinusLogProbMetric: 27.5319

Epoch 389: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2875 - MinusLogProbMetric: 27.2875 - val_loss: 27.5319 - val_MinusLogProbMetric: 27.5319 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 390/1000
2023-09-12 18:35:29.721 
Epoch 390/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.5423, val_MinusLogProbMetric: 27.5423

Epoch 390: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.5423 - val_MinusLogProbMetric: 27.5423 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 391/1000
2023-09-12 18:35:40.365 
Epoch 391/1000 
	 loss: 27.2867, MinusLogProbMetric: 27.2867, val_loss: 27.5348, val_MinusLogProbMetric: 27.5348

Epoch 391: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2867 - MinusLogProbMetric: 27.2867 - val_loss: 27.5348 - val_MinusLogProbMetric: 27.5348 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 392/1000
2023-09-12 18:35:50.889 
Epoch 392/1000 
	 loss: 27.2867, MinusLogProbMetric: 27.2867, val_loss: 27.5386, val_MinusLogProbMetric: 27.5386

Epoch 392: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2867 - MinusLogProbMetric: 27.2867 - val_loss: 27.5386 - val_MinusLogProbMetric: 27.5386 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 393/1000
2023-09-12 18:36:02.919 
Epoch 393/1000 
	 loss: 27.2866, MinusLogProbMetric: 27.2866, val_loss: 27.5364, val_MinusLogProbMetric: 27.5364

Epoch 393: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2866 - MinusLogProbMetric: 27.2866 - val_loss: 27.5364 - val_MinusLogProbMetric: 27.5364 - lr: 1.2500e-04 - 12s/epoch - 61ms/step
Epoch 394/1000
2023-09-12 18:36:12.707 
Epoch 394/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.5390, val_MinusLogProbMetric: 27.5390

Epoch 394: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.5390 - val_MinusLogProbMetric: 27.5390 - lr: 1.2500e-04 - 10s/epoch - 50ms/step
Epoch 395/1000
2023-09-12 18:36:22.707 
Epoch 395/1000 
	 loss: 27.2857, MinusLogProbMetric: 27.2857, val_loss: 27.5350, val_MinusLogProbMetric: 27.5350

Epoch 395: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2857 - MinusLogProbMetric: 27.2857 - val_loss: 27.5350 - val_MinusLogProbMetric: 27.5350 - lr: 1.2500e-04 - 10s/epoch - 51ms/step
Epoch 396/1000
2023-09-12 18:36:32.581 
Epoch 396/1000 
	 loss: 27.2857, MinusLogProbMetric: 27.2857, val_loss: 27.5352, val_MinusLogProbMetric: 27.5352

Epoch 396: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2857 - MinusLogProbMetric: 27.2857 - val_loss: 27.5352 - val_MinusLogProbMetric: 27.5352 - lr: 1.2500e-04 - 10s/epoch - 50ms/step
Epoch 397/1000
2023-09-12 18:36:42.170 
Epoch 397/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.5434, val_MinusLogProbMetric: 27.5434

Epoch 397: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.5434 - val_MinusLogProbMetric: 27.5434 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 398/1000
2023-09-12 18:36:51.740 
Epoch 398/1000 
	 loss: 27.2860, MinusLogProbMetric: 27.2860, val_loss: 27.5380, val_MinusLogProbMetric: 27.5380

Epoch 398: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2860 - MinusLogProbMetric: 27.2860 - val_loss: 27.5380 - val_MinusLogProbMetric: 27.5380 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 399/1000
2023-09-12 18:37:01.268 
Epoch 399/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.5385, val_MinusLogProbMetric: 27.5385

Epoch 399: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.5385 - val_MinusLogProbMetric: 27.5385 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 400/1000
2023-09-12 18:37:12.596 
Epoch 400/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.5352, val_MinusLogProbMetric: 27.5352

Epoch 400: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.5352 - val_MinusLogProbMetric: 27.5352 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 401/1000
2023-09-12 18:37:24.385 
Epoch 401/1000 
	 loss: 27.2854, MinusLogProbMetric: 27.2854, val_loss: 27.5331, val_MinusLogProbMetric: 27.5331

Epoch 401: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2854 - MinusLogProbMetric: 27.2854 - val_loss: 27.5331 - val_MinusLogProbMetric: 27.5331 - lr: 1.2500e-04 - 12s/epoch - 60ms/step
Epoch 402/1000
2023-09-12 18:37:34.996 
Epoch 402/1000 
	 loss: 27.2857, MinusLogProbMetric: 27.2857, val_loss: 27.5447, val_MinusLogProbMetric: 27.5447

Epoch 402: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2857 - MinusLogProbMetric: 27.2857 - val_loss: 27.5447 - val_MinusLogProbMetric: 27.5447 - lr: 1.2500e-04 - 11s/epoch - 54ms/step
Epoch 403/1000
2023-09-12 18:37:44.350 
Epoch 403/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.5371, val_MinusLogProbMetric: 27.5371

Epoch 403: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.5371 - val_MinusLogProbMetric: 27.5371 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 404/1000
2023-09-12 18:37:53.691 
Epoch 404/1000 
	 loss: 27.2857, MinusLogProbMetric: 27.2857, val_loss: 27.5309, val_MinusLogProbMetric: 27.5309

Epoch 404: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2857 - MinusLogProbMetric: 27.2857 - val_loss: 27.5309 - val_MinusLogProbMetric: 27.5309 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 405/1000
2023-09-12 18:38:03.391 
Epoch 405/1000 
	 loss: 27.2848, MinusLogProbMetric: 27.2848, val_loss: 27.5349, val_MinusLogProbMetric: 27.5349

Epoch 405: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2848 - MinusLogProbMetric: 27.2848 - val_loss: 27.5349 - val_MinusLogProbMetric: 27.5349 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 406/1000
2023-09-12 18:38:13.008 
Epoch 406/1000 
	 loss: 27.2860, MinusLogProbMetric: 27.2860, val_loss: 27.5347, val_MinusLogProbMetric: 27.5347

Epoch 406: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2860 - MinusLogProbMetric: 27.2860 - val_loss: 27.5347 - val_MinusLogProbMetric: 27.5347 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 407/1000
2023-09-12 18:38:22.355 
Epoch 407/1000 
	 loss: 27.2854, MinusLogProbMetric: 27.2854, val_loss: 27.5379, val_MinusLogProbMetric: 27.5379

Epoch 407: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2854 - MinusLogProbMetric: 27.2854 - val_loss: 27.5379 - val_MinusLogProbMetric: 27.5379 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 408/1000
2023-09-12 18:38:32.420 
Epoch 408/1000 
	 loss: 27.2853, MinusLogProbMetric: 27.2853, val_loss: 27.5398, val_MinusLogProbMetric: 27.5398

Epoch 408: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2853 - MinusLogProbMetric: 27.2853 - val_loss: 27.5398 - val_MinusLogProbMetric: 27.5398 - lr: 1.2500e-04 - 10s/epoch - 51ms/step
Epoch 409/1000
2023-09-12 18:38:43.157 
Epoch 409/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.5397, val_MinusLogProbMetric: 27.5397

Epoch 409: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.5397 - val_MinusLogProbMetric: 27.5397 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 410/1000
2023-09-12 18:38:52.489 
Epoch 410/1000 
	 loss: 27.2865, MinusLogProbMetric: 27.2865, val_loss: 27.5413, val_MinusLogProbMetric: 27.5413

Epoch 410: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2865 - MinusLogProbMetric: 27.2865 - val_loss: 27.5413 - val_MinusLogProbMetric: 27.5413 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 411/1000
2023-09-12 18:39:02.716 
Epoch 411/1000 
	 loss: 27.2851, MinusLogProbMetric: 27.2851, val_loss: 27.5346, val_MinusLogProbMetric: 27.5346

Epoch 411: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2851 - MinusLogProbMetric: 27.2851 - val_loss: 27.5346 - val_MinusLogProbMetric: 27.5346 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 412/1000
2023-09-12 18:39:14.049 
Epoch 412/1000 
	 loss: 27.2854, MinusLogProbMetric: 27.2854, val_loss: 27.5354, val_MinusLogProbMetric: 27.5354

Epoch 412: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2854 - MinusLogProbMetric: 27.2854 - val_loss: 27.5354 - val_MinusLogProbMetric: 27.5354 - lr: 1.2500e-04 - 11s/epoch - 58ms/step
Epoch 413/1000
2023-09-12 18:39:23.294 
Epoch 413/1000 
	 loss: 27.2859, MinusLogProbMetric: 27.2859, val_loss: 27.5356, val_MinusLogProbMetric: 27.5356

Epoch 413: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2859 - MinusLogProbMetric: 27.2859 - val_loss: 27.5356 - val_MinusLogProbMetric: 27.5356 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 414/1000
2023-09-12 18:39:32.947 
Epoch 414/1000 
	 loss: 27.2852, MinusLogProbMetric: 27.2852, val_loss: 27.5338, val_MinusLogProbMetric: 27.5338

Epoch 414: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2852 - MinusLogProbMetric: 27.2852 - val_loss: 27.5338 - val_MinusLogProbMetric: 27.5338 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 415/1000
2023-09-12 18:39:42.386 
Epoch 415/1000 
	 loss: 27.2844, MinusLogProbMetric: 27.2844, val_loss: 27.5380, val_MinusLogProbMetric: 27.5380

Epoch 415: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2844 - MinusLogProbMetric: 27.2844 - val_loss: 27.5380 - val_MinusLogProbMetric: 27.5380 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 416/1000
2023-09-12 18:39:52.013 
Epoch 416/1000 
	 loss: 27.2842, MinusLogProbMetric: 27.2842, val_loss: 27.5372, val_MinusLogProbMetric: 27.5372

Epoch 416: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2842 - MinusLogProbMetric: 27.2842 - val_loss: 27.5372 - val_MinusLogProbMetric: 27.5372 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 417/1000
2023-09-12 18:40:01.532 
Epoch 417/1000 
	 loss: 27.2844, MinusLogProbMetric: 27.2844, val_loss: 27.5365, val_MinusLogProbMetric: 27.5365

Epoch 417: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2844 - MinusLogProbMetric: 27.2844 - val_loss: 27.5365 - val_MinusLogProbMetric: 27.5365 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 418/1000
2023-09-12 18:40:10.777 
Epoch 418/1000 
	 loss: 27.2843, MinusLogProbMetric: 27.2843, val_loss: 27.5373, val_MinusLogProbMetric: 27.5373

Epoch 418: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2843 - MinusLogProbMetric: 27.2843 - val_loss: 27.5373 - val_MinusLogProbMetric: 27.5373 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 419/1000
2023-09-12 18:40:20.096 
Epoch 419/1000 
	 loss: 27.2841, MinusLogProbMetric: 27.2841, val_loss: 27.5371, val_MinusLogProbMetric: 27.5371

Epoch 419: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2841 - MinusLogProbMetric: 27.2841 - val_loss: 27.5371 - val_MinusLogProbMetric: 27.5371 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 420/1000
2023-09-12 18:40:29.411 
Epoch 420/1000 
	 loss: 27.2849, MinusLogProbMetric: 27.2849, val_loss: 27.5348, val_MinusLogProbMetric: 27.5348

Epoch 420: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2849 - MinusLogProbMetric: 27.2849 - val_loss: 27.5348 - val_MinusLogProbMetric: 27.5348 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 421/1000
2023-09-12 18:40:38.784 
Epoch 421/1000 
	 loss: 27.2853, MinusLogProbMetric: 27.2853, val_loss: 27.5438, val_MinusLogProbMetric: 27.5438

Epoch 421: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2853 - MinusLogProbMetric: 27.2853 - val_loss: 27.5438 - val_MinusLogProbMetric: 27.5438 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 422/1000
2023-09-12 18:40:48.035 
Epoch 422/1000 
	 loss: 27.2850, MinusLogProbMetric: 27.2850, val_loss: 27.5406, val_MinusLogProbMetric: 27.5406

Epoch 422: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2850 - MinusLogProbMetric: 27.2850 - val_loss: 27.5406 - val_MinusLogProbMetric: 27.5406 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 423/1000
2023-09-12 18:40:57.861 
Epoch 423/1000 
	 loss: 27.2850, MinusLogProbMetric: 27.2850, val_loss: 27.5357, val_MinusLogProbMetric: 27.5357

Epoch 423: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2850 - MinusLogProbMetric: 27.2850 - val_loss: 27.5357 - val_MinusLogProbMetric: 27.5357 - lr: 1.2500e-04 - 10s/epoch - 50ms/step
Epoch 424/1000
2023-09-12 18:41:07.084 
Epoch 424/1000 
	 loss: 27.2852, MinusLogProbMetric: 27.2852, val_loss: 27.5433, val_MinusLogProbMetric: 27.5433

Epoch 424: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2852 - MinusLogProbMetric: 27.2852 - val_loss: 27.5433 - val_MinusLogProbMetric: 27.5433 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 425/1000
2023-09-12 18:41:16.272 
Epoch 425/1000 
	 loss: 27.2836, MinusLogProbMetric: 27.2836, val_loss: 27.5343, val_MinusLogProbMetric: 27.5343

Epoch 425: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2836 - MinusLogProbMetric: 27.2836 - val_loss: 27.5343 - val_MinusLogProbMetric: 27.5343 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 426/1000
2023-09-12 18:41:25.345 
Epoch 426/1000 
	 loss: 27.2841, MinusLogProbMetric: 27.2841, val_loss: 27.5386, val_MinusLogProbMetric: 27.5386

Epoch 426: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2841 - MinusLogProbMetric: 27.2841 - val_loss: 27.5386 - val_MinusLogProbMetric: 27.5386 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 427/1000
2023-09-12 18:41:36.076 
Epoch 427/1000 
	 loss: 27.2837, MinusLogProbMetric: 27.2837, val_loss: 27.5381, val_MinusLogProbMetric: 27.5381

Epoch 427: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2837 - MinusLogProbMetric: 27.2837 - val_loss: 27.5381 - val_MinusLogProbMetric: 27.5381 - lr: 1.2500e-04 - 11s/epoch - 55ms/step
Epoch 428/1000
2023-09-12 18:41:45.331 
Epoch 428/1000 
	 loss: 27.2853, MinusLogProbMetric: 27.2853, val_loss: 27.5401, val_MinusLogProbMetric: 27.5401

Epoch 428: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2853 - MinusLogProbMetric: 27.2853 - val_loss: 27.5401 - val_MinusLogProbMetric: 27.5401 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 429/1000
2023-09-12 18:41:54.647 
Epoch 429/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.5365, val_MinusLogProbMetric: 27.5365

Epoch 429: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.5365 - val_MinusLogProbMetric: 27.5365 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 430/1000
2023-09-12 18:42:05.945 
Epoch 430/1000 
	 loss: 27.2755, MinusLogProbMetric: 27.2755, val_loss: 27.5307, val_MinusLogProbMetric: 27.5307

Epoch 430: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2755 - MinusLogProbMetric: 27.2755 - val_loss: 27.5307 - val_MinusLogProbMetric: 27.5307 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 431/1000
2023-09-12 18:42:16.278 
Epoch 431/1000 
	 loss: 27.2747, MinusLogProbMetric: 27.2747, val_loss: 27.5298, val_MinusLogProbMetric: 27.5298

Epoch 431: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2747 - MinusLogProbMetric: 27.2747 - val_loss: 27.5298 - val_MinusLogProbMetric: 27.5298 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 432/1000
2023-09-12 18:42:25.727 
Epoch 432/1000 
	 loss: 27.2742, MinusLogProbMetric: 27.2742, val_loss: 27.5294, val_MinusLogProbMetric: 27.5294

Epoch 432: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2742 - MinusLogProbMetric: 27.2742 - val_loss: 27.5294 - val_MinusLogProbMetric: 27.5294 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 433/1000
2023-09-12 18:42:36.080 
Epoch 433/1000 
	 loss: 27.2741, MinusLogProbMetric: 27.2741, val_loss: 27.5318, val_MinusLogProbMetric: 27.5318

Epoch 433: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2741 - MinusLogProbMetric: 27.2741 - val_loss: 27.5318 - val_MinusLogProbMetric: 27.5318 - lr: 6.2500e-05 - 10s/epoch - 53ms/step
Epoch 434/1000
2023-09-12 18:42:46.939 
Epoch 434/1000 
	 loss: 27.2749, MinusLogProbMetric: 27.2749, val_loss: 27.5312, val_MinusLogProbMetric: 27.5312

Epoch 434: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2749 - MinusLogProbMetric: 27.2749 - val_loss: 27.5312 - val_MinusLogProbMetric: 27.5312 - lr: 6.2500e-05 - 11s/epoch - 55ms/step
Epoch 435/1000
2023-09-12 18:42:56.028 
Epoch 435/1000 
	 loss: 27.2738, MinusLogProbMetric: 27.2738, val_loss: 27.5307, val_MinusLogProbMetric: 27.5307

Epoch 435: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2738 - MinusLogProbMetric: 27.2738 - val_loss: 27.5307 - val_MinusLogProbMetric: 27.5307 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 436/1000
2023-09-12 18:43:05.206 
Epoch 436/1000 
	 loss: 27.2736, MinusLogProbMetric: 27.2736, val_loss: 27.5330, val_MinusLogProbMetric: 27.5330

Epoch 436: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2736 - MinusLogProbMetric: 27.2736 - val_loss: 27.5330 - val_MinusLogProbMetric: 27.5330 - lr: 6.2500e-05 - 9s/epoch - 47ms/step
Epoch 437/1000
2023-09-12 18:43:14.686 
Epoch 437/1000 
	 loss: 27.2742, MinusLogProbMetric: 27.2742, val_loss: 27.5325, val_MinusLogProbMetric: 27.5325

Epoch 437: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2742 - MinusLogProbMetric: 27.2742 - val_loss: 27.5325 - val_MinusLogProbMetric: 27.5325 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 438/1000
2023-09-12 18:43:25.582 
Epoch 438/1000 
	 loss: 27.2739, MinusLogProbMetric: 27.2739, val_loss: 27.5294, val_MinusLogProbMetric: 27.5294

Epoch 438: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2739 - MinusLogProbMetric: 27.2739 - val_loss: 27.5294 - val_MinusLogProbMetric: 27.5294 - lr: 6.2500e-05 - 11s/epoch - 56ms/step
Epoch 439/1000
2023-09-12 18:43:36.779 
Epoch 439/1000 
	 loss: 27.2740, MinusLogProbMetric: 27.2740, val_loss: 27.5320, val_MinusLogProbMetric: 27.5320

Epoch 439: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2740 - MinusLogProbMetric: 27.2740 - val_loss: 27.5320 - val_MinusLogProbMetric: 27.5320 - lr: 6.2500e-05 - 11s/epoch - 57ms/step
Epoch 440/1000
2023-09-12 18:43:48.216 
Epoch 440/1000 
	 loss: 27.2743, MinusLogProbMetric: 27.2743, val_loss: 27.5310, val_MinusLogProbMetric: 27.5310

Epoch 440: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2743 - MinusLogProbMetric: 27.2743 - val_loss: 27.5310 - val_MinusLogProbMetric: 27.5310 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 441/1000
2023-09-12 18:43:57.608 
Epoch 441/1000 
	 loss: 27.2741, MinusLogProbMetric: 27.2741, val_loss: 27.5300, val_MinusLogProbMetric: 27.5300

Epoch 441: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2741 - MinusLogProbMetric: 27.2741 - val_loss: 27.5300 - val_MinusLogProbMetric: 27.5300 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 442/1000
2023-09-12 18:44:06.927 
Epoch 442/1000 
	 loss: 27.2739, MinusLogProbMetric: 27.2739, val_loss: 27.5318, val_MinusLogProbMetric: 27.5318

Epoch 442: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2739 - MinusLogProbMetric: 27.2739 - val_loss: 27.5318 - val_MinusLogProbMetric: 27.5318 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 443/1000
2023-09-12 18:44:16.192 
Epoch 443/1000 
	 loss: 27.2739, MinusLogProbMetric: 27.2739, val_loss: 27.5308, val_MinusLogProbMetric: 27.5308

Epoch 443: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2739 - MinusLogProbMetric: 27.2739 - val_loss: 27.5308 - val_MinusLogProbMetric: 27.5308 - lr: 6.2500e-05 - 9s/epoch - 47ms/step
Epoch 444/1000
2023-09-12 18:44:26.168 
Epoch 444/1000 
	 loss: 27.2742, MinusLogProbMetric: 27.2742, val_loss: 27.5322, val_MinusLogProbMetric: 27.5322

Epoch 444: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2742 - MinusLogProbMetric: 27.2742 - val_loss: 27.5322 - val_MinusLogProbMetric: 27.5322 - lr: 6.2500e-05 - 10s/epoch - 51ms/step
Epoch 445/1000
2023-09-12 18:44:36.745 
Epoch 445/1000 
	 loss: 27.2736, MinusLogProbMetric: 27.2736, val_loss: 27.5320, val_MinusLogProbMetric: 27.5320

Epoch 445: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2736 - MinusLogProbMetric: 27.2736 - val_loss: 27.5320 - val_MinusLogProbMetric: 27.5320 - lr: 6.2500e-05 - 11s/epoch - 54ms/step
Epoch 446/1000
2023-09-12 18:44:45.810 
Epoch 446/1000 
	 loss: 27.2741, MinusLogProbMetric: 27.2741, val_loss: 27.5306, val_MinusLogProbMetric: 27.5306

Epoch 446: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2741 - MinusLogProbMetric: 27.2741 - val_loss: 27.5306 - val_MinusLogProbMetric: 27.5306 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 447/1000
2023-09-12 18:44:54.913 
Epoch 447/1000 
	 loss: 27.2737, MinusLogProbMetric: 27.2737, val_loss: 27.5318, val_MinusLogProbMetric: 27.5318

Epoch 447: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2737 - MinusLogProbMetric: 27.2737 - val_loss: 27.5318 - val_MinusLogProbMetric: 27.5318 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 448/1000
2023-09-12 18:45:04.027 
Epoch 448/1000 
	 loss: 27.2737, MinusLogProbMetric: 27.2737, val_loss: 27.5345, val_MinusLogProbMetric: 27.5345

Epoch 448: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2737 - MinusLogProbMetric: 27.2737 - val_loss: 27.5345 - val_MinusLogProbMetric: 27.5345 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 449/1000
2023-09-12 18:45:14.040 
Epoch 449/1000 
	 loss: 27.2736, MinusLogProbMetric: 27.2736, val_loss: 27.5363, val_MinusLogProbMetric: 27.5363

Epoch 449: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2736 - MinusLogProbMetric: 27.2736 - val_loss: 27.5363 - val_MinusLogProbMetric: 27.5363 - lr: 6.2500e-05 - 10s/epoch - 51ms/step
Epoch 450/1000
2023-09-12 18:45:24.954 
Epoch 450/1000 
	 loss: 27.2742, MinusLogProbMetric: 27.2742, val_loss: 27.5298, val_MinusLogProbMetric: 27.5298

Epoch 450: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2742 - MinusLogProbMetric: 27.2742 - val_loss: 27.5298 - val_MinusLogProbMetric: 27.5298 - lr: 6.2500e-05 - 11s/epoch - 56ms/step
Epoch 451/1000
2023-09-12 18:45:36.742 
Epoch 451/1000 
	 loss: 27.2729, MinusLogProbMetric: 27.2729, val_loss: 27.5329, val_MinusLogProbMetric: 27.5329

Epoch 451: val_loss did not improve from 27.52742
196/196 - 12s - loss: 27.2729 - MinusLogProbMetric: 27.2729 - val_loss: 27.5329 - val_MinusLogProbMetric: 27.5329 - lr: 6.2500e-05 - 12s/epoch - 60ms/step
Epoch 452/1000
2023-09-12 18:45:48.022 
Epoch 452/1000 
	 loss: 27.2734, MinusLogProbMetric: 27.2734, val_loss: 27.5311, val_MinusLogProbMetric: 27.5311

Epoch 452: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2734 - MinusLogProbMetric: 27.2734 - val_loss: 27.5311 - val_MinusLogProbMetric: 27.5311 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 453/1000
2023-09-12 18:45:57.412 
Epoch 453/1000 
	 loss: 27.2739, MinusLogProbMetric: 27.2739, val_loss: 27.5347, val_MinusLogProbMetric: 27.5347

Epoch 453: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2739 - MinusLogProbMetric: 27.2739 - val_loss: 27.5347 - val_MinusLogProbMetric: 27.5347 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 454/1000
2023-09-12 18:46:06.930 
Epoch 454/1000 
	 loss: 27.2740, MinusLogProbMetric: 27.2740, val_loss: 27.5309, val_MinusLogProbMetric: 27.5309

Epoch 454: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2740 - MinusLogProbMetric: 27.2740 - val_loss: 27.5309 - val_MinusLogProbMetric: 27.5309 - lr: 6.2500e-05 - 10s/epoch - 49ms/step
Epoch 455/1000
2023-09-12 18:46:16.458 
Epoch 455/1000 
	 loss: 27.2742, MinusLogProbMetric: 27.2742, val_loss: 27.5344, val_MinusLogProbMetric: 27.5344

Epoch 455: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2742 - MinusLogProbMetric: 27.2742 - val_loss: 27.5344 - val_MinusLogProbMetric: 27.5344 - lr: 6.2500e-05 - 10s/epoch - 49ms/step
Epoch 456/1000
2023-09-12 18:46:25.944 
Epoch 456/1000 
	 loss: 27.2730, MinusLogProbMetric: 27.2730, val_loss: 27.5311, val_MinusLogProbMetric: 27.5311

Epoch 456: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2730 - MinusLogProbMetric: 27.2730 - val_loss: 27.5311 - val_MinusLogProbMetric: 27.5311 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 457/1000
2023-09-12 18:46:35.504 
Epoch 457/1000 
	 loss: 27.2732, MinusLogProbMetric: 27.2732, val_loss: 27.5330, val_MinusLogProbMetric: 27.5330

Epoch 457: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2732 - MinusLogProbMetric: 27.2732 - val_loss: 27.5330 - val_MinusLogProbMetric: 27.5330 - lr: 6.2500e-05 - 10s/epoch - 49ms/step
Epoch 458/1000
2023-09-12 18:46:44.911 
Epoch 458/1000 
	 loss: 27.2737, MinusLogProbMetric: 27.2737, val_loss: 27.5346, val_MinusLogProbMetric: 27.5346

Epoch 458: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2737 - MinusLogProbMetric: 27.2737 - val_loss: 27.5346 - val_MinusLogProbMetric: 27.5346 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 459/1000
2023-09-12 18:46:54.221 
Epoch 459/1000 
	 loss: 27.2731, MinusLogProbMetric: 27.2731, val_loss: 27.5373, val_MinusLogProbMetric: 27.5373

Epoch 459: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2731 - MinusLogProbMetric: 27.2731 - val_loss: 27.5373 - val_MinusLogProbMetric: 27.5373 - lr: 6.2500e-05 - 9s/epoch - 47ms/step
Epoch 460/1000
2023-09-12 18:47:03.623 
Epoch 460/1000 
	 loss: 27.2727, MinusLogProbMetric: 27.2727, val_loss: 27.5324, val_MinusLogProbMetric: 27.5324

Epoch 460: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2727 - MinusLogProbMetric: 27.2727 - val_loss: 27.5324 - val_MinusLogProbMetric: 27.5324 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 461/1000
2023-09-12 18:47:12.623 
Epoch 461/1000 
	 loss: 27.2739, MinusLogProbMetric: 27.2739, val_loss: 27.5346, val_MinusLogProbMetric: 27.5346

Epoch 461: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2739 - MinusLogProbMetric: 27.2739 - val_loss: 27.5346 - val_MinusLogProbMetric: 27.5346 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 462/1000
2023-09-12 18:47:21.820 
Epoch 462/1000 
	 loss: 27.2731, MinusLogProbMetric: 27.2731, val_loss: 27.5330, val_MinusLogProbMetric: 27.5330

Epoch 462: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2731 - MinusLogProbMetric: 27.2731 - val_loss: 27.5330 - val_MinusLogProbMetric: 27.5330 - lr: 6.2500e-05 - 9s/epoch - 47ms/step
Epoch 463/1000
2023-09-12 18:47:30.865 
Epoch 463/1000 
	 loss: 27.2732, MinusLogProbMetric: 27.2732, val_loss: 27.5348, val_MinusLogProbMetric: 27.5348

Epoch 463: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2732 - MinusLogProbMetric: 27.2732 - val_loss: 27.5348 - val_MinusLogProbMetric: 27.5348 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 464/1000
2023-09-12 18:47:39.808 
Epoch 464/1000 
	 loss: 27.2732, MinusLogProbMetric: 27.2732, val_loss: 27.5352, val_MinusLogProbMetric: 27.5352

Epoch 464: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2732 - MinusLogProbMetric: 27.2732 - val_loss: 27.5352 - val_MinusLogProbMetric: 27.5352 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 465/1000
2023-09-12 18:47:49.190 
Epoch 465/1000 
	 loss: 27.2733, MinusLogProbMetric: 27.2733, val_loss: 27.5312, val_MinusLogProbMetric: 27.5312

Epoch 465: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2733 - MinusLogProbMetric: 27.2733 - val_loss: 27.5312 - val_MinusLogProbMetric: 27.5312 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 466/1000
2023-09-12 18:48:00.540 
Epoch 466/1000 
	 loss: 27.2735, MinusLogProbMetric: 27.2735, val_loss: 27.5333, val_MinusLogProbMetric: 27.5333

Epoch 466: val_loss did not improve from 27.52742
196/196 - 11s - loss: 27.2735 - MinusLogProbMetric: 27.2735 - val_loss: 27.5333 - val_MinusLogProbMetric: 27.5333 - lr: 6.2500e-05 - 11s/epoch - 58ms/step
Epoch 467/1000
2023-09-12 18:48:10.040 
Epoch 467/1000 
	 loss: 27.2729, MinusLogProbMetric: 27.2729, val_loss: 27.5327, val_MinusLogProbMetric: 27.5327

Epoch 467: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2729 - MinusLogProbMetric: 27.2729 - val_loss: 27.5327 - val_MinusLogProbMetric: 27.5327 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 468/1000
2023-09-12 18:48:19.603 
Epoch 468/1000 
	 loss: 27.2732, MinusLogProbMetric: 27.2732, val_loss: 27.5331, val_MinusLogProbMetric: 27.5331

Epoch 468: val_loss did not improve from 27.52742
196/196 - 10s - loss: 27.2732 - MinusLogProbMetric: 27.2732 - val_loss: 27.5331 - val_MinusLogProbMetric: 27.5331 - lr: 6.2500e-05 - 10s/epoch - 49ms/step
Epoch 469/1000
2023-09-12 18:48:29.033 
Epoch 469/1000 
	 loss: 27.2729, MinusLogProbMetric: 27.2729, val_loss: 27.5322, val_MinusLogProbMetric: 27.5322

Epoch 469: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2729 - MinusLogProbMetric: 27.2729 - val_loss: 27.5322 - val_MinusLogProbMetric: 27.5322 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 470/1000
2023-09-12 18:48:38.407 
Epoch 470/1000 
	 loss: 27.2729, MinusLogProbMetric: 27.2729, val_loss: 27.5295, val_MinusLogProbMetric: 27.5295

Epoch 470: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2729 - MinusLogProbMetric: 27.2729 - val_loss: 27.5295 - val_MinusLogProbMetric: 27.5295 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 471/1000
2023-09-12 18:48:47.407 
Epoch 471/1000 
	 loss: 27.2728, MinusLogProbMetric: 27.2728, val_loss: 27.5324, val_MinusLogProbMetric: 27.5324

Epoch 471: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2728 - MinusLogProbMetric: 27.2728 - val_loss: 27.5324 - val_MinusLogProbMetric: 27.5324 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 472/1000
2023-09-12 18:48:56.542 
Epoch 472/1000 
	 loss: 27.2732, MinusLogProbMetric: 27.2732, val_loss: 27.5362, val_MinusLogProbMetric: 27.5362

Epoch 472: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2732 - MinusLogProbMetric: 27.2732 - val_loss: 27.5362 - val_MinusLogProbMetric: 27.5362 - lr: 6.2500e-05 - 9s/epoch - 47ms/step
Epoch 473/1000
2023-09-12 18:49:05.442 
Epoch 473/1000 
	 loss: 27.2732, MinusLogProbMetric: 27.2732, val_loss: 27.5333, val_MinusLogProbMetric: 27.5333

Epoch 473: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2732 - MinusLogProbMetric: 27.2732 - val_loss: 27.5333 - val_MinusLogProbMetric: 27.5333 - lr: 6.2500e-05 - 9s/epoch - 45ms/step
Epoch 474/1000
2023-09-12 18:49:14.789 
Epoch 474/1000 
	 loss: 27.2725, MinusLogProbMetric: 27.2725, val_loss: 27.5327, val_MinusLogProbMetric: 27.5327

Epoch 474: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2725 - MinusLogProbMetric: 27.2725 - val_loss: 27.5327 - val_MinusLogProbMetric: 27.5327 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 475/1000
2023-09-12 18:49:24.247 
Epoch 475/1000 
	 loss: 27.2725, MinusLogProbMetric: 27.2725, val_loss: 27.5332, val_MinusLogProbMetric: 27.5332

Epoch 475: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2725 - MinusLogProbMetric: 27.2725 - val_loss: 27.5332 - val_MinusLogProbMetric: 27.5332 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 476/1000
2023-09-12 18:49:33.647 
Epoch 476/1000 
	 loss: 27.2724, MinusLogProbMetric: 27.2724, val_loss: 27.5350, val_MinusLogProbMetric: 27.5350

Epoch 476: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2724 - MinusLogProbMetric: 27.2724 - val_loss: 27.5350 - val_MinusLogProbMetric: 27.5350 - lr: 6.2500e-05 - 9s/epoch - 48ms/step
Epoch 477/1000
2023-09-12 18:49:42.707 
Epoch 477/1000 
	 loss: 27.2725, MinusLogProbMetric: 27.2725, val_loss: 27.5323, val_MinusLogProbMetric: 27.5323

Epoch 477: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2725 - MinusLogProbMetric: 27.2725 - val_loss: 27.5323 - val_MinusLogProbMetric: 27.5323 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 478/1000
2023-09-12 18:49:51.731 
Epoch 478/1000 
	 loss: 27.2723, MinusLogProbMetric: 27.2723, val_loss: 27.5357, val_MinusLogProbMetric: 27.5357

Epoch 478: val_loss did not improve from 27.52742
196/196 - 9s - loss: 27.2723 - MinusLogProbMetric: 27.2723 - val_loss: 27.5357 - val_MinusLogProbMetric: 27.5357 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 479/1000
2023-09-12 18:50:00.644 
Epoch 479/1000 
	 loss: 27.2726, MinusLogProbMetric: 27.2726, val_loss: 27.5338, val_MinusLogProbMetric: 27.5338

Epoch 479: val_loss did not improve from 27.52742
Restoring model weights from the end of the best epoch: 379.
196/196 - 9s - loss: 27.2726 - MinusLogProbMetric: 27.2726 - val_loss: 27.5338 - val_MinusLogProbMetric: 27.5338 - lr: 6.2500e-05 - 9s/epoch - 46ms/step
Epoch 479: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 10.133238308946602 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.781413297983818 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.763313696021214 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.256293648038991 seconds.
WARNING:root:Too few points to create valid contours
Training succeeded with seed 0.
Model trained in 5175.62 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Metrics computed in 3362.00 s.
Plots done in 63.80 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 3425.80 s.
===========
Run 163/360 done in 8602.78 s.
===========

Directory ../../results/MsplineN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_167/ already exists.
Skipping it.
===========
Run 167/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

===========
Generating train data for run 174.
===========
Train data generated in 0.13 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_174/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_174/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.7541595 , 5.721841  , 7.5400248 , ..., 0.17855006, 7.5787845 ,
        1.3515668 ],
       [5.442636  , 8.331263  , 5.8727856 , ..., 1.0242728 , 8.106918  ,
        1.274803  ],
       [1.849359  , 3.4476702 , 6.8133354 , ..., 6.851224  , 0.8453402 ,
        3.4794679 ],
       ...,
       [2.3177798 , 4.2122316 , 7.105509  , ..., 7.2533946 , 0.7699296 ,
        1.7943734 ],
       [6.3632    , 2.8481505 , 6.2368546 , ..., 3.6055064 , 5.1009455 ,
        2.9910412 ],
       [7.1731195 , 2.729657  , 6.1427665 , ..., 3.274747  , 1.7997704 ,
        2.8153737 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_174/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_174
self.data_kwargs: {'seed': 440}
self.x_data: [[ 2.0547452   3.776408    6.9601746  ...  5.8637457  -0.4179731
   2.747595  ]
 [ 6.405085    2.999549    6.1033454  ...  2.8107233   3.0569289
   2.003619  ]
 [ 2.0047038   4.064143    6.2048492  ...  5.6568336   0.71395487
   2.6926432 ]
 ...
 [ 5.645455    7.0971727   6.202566   ...  0.61970913  6.238492
   1.3539525 ]
 [ 6.475603    3.1151166   6.2248073  ...  2.8990176   3.6724448
   2.289971  ]
 [ 2.2290072   4.101192    7.1413527  ...  6.717821   -2.0046902
   2.3999293 ]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model_23"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_70 (InputLayer)       [(None, 64)]              0         
                                                                 
 log_prob_layer_23 (LogProbL  (None,)                  1053056   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,053,056
Trainable params: 1,053,056
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_23/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_23'")
self.model: <keras.engine.functional.Functional object at 0x7fbbfaf56ec0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fbc14f50070>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fbc14f50070>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fbc14f50940>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fbc14f51600>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fbc14f51b70>, <keras.callbacks.ModelCheckpoint object at 0x7fbc14f51c30>, <keras.callbacks.EarlyStopping object at 0x7fbc14f51ea0>, <keras.callbacks.ReduceLROnPlateau object at 0x7fbc14f51ed0>, <keras.callbacks.TerminateOnNaN object at 0x7fbc14f51b10>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.7541595 , 5.721841  , 7.5400248 , ..., 0.17855006, 7.5787845 ,
        1.3515668 ],
       [5.442636  , 8.331263  , 5.8727856 , ..., 1.0242728 , 8.106918  ,
        1.274803  ],
       [1.849359  , 3.4476702 , 6.8133354 , ..., 6.851224  , 0.8453402 ,
        3.4794679 ],
       ...,
       [2.3177798 , 4.2122316 , 7.105509  , ..., 7.2533946 , 0.7699296 ,
        1.7943734 ],
       [6.3632    , 2.8481505 , 6.2368546 , ..., 3.6055064 , 5.1009455 ,
        2.9910412 ],
       [7.1731195 , 2.729657  , 6.1427665 , ..., 3.274747  , 1.7997704 ,
        2.8153737 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_174/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 174/360 with hyperparameters:
timestamp = 2023-09-12 19:47:07.381793
ndims = 64
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1053056
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 2.0547452   3.776408    6.9601746   1.2163222   8.644804    1.0450234
  9.756204    5.9333344   9.3759165   6.2056174   7.6663713   0.8787037
  2.7781603   1.7675867   3.9287794   0.8286338   3.6572614   4.846633
  0.68292063  6.317236    6.48625     3.843101    5.88724     2.0270782
  5.1297107   7.7579265   2.6054757   6.6726594   1.0543873   7.123391
  3.5526195   2.046467    5.620422   -0.869851    8.648443    0.02500496
  7.4141846   2.6777635   7.6790566   9.76465     2.481489    6.2672224
  5.7068043   4.504637    1.1161722   9.691578    4.0927534   8.503739
  6.9964066   3.1729455   8.086372    4.0078015   8.096493    5.813139
  8.181514    6.97417     7.246071    5.0315676  10.666024    6.2678714
  3.6855178   5.8637457  -0.4179731   2.747595  ]
Epoch 1/1000
2023-09-12 19:47:36.420 
Epoch 1/1000 
	 loss: 84.6629, MinusLogProbMetric: 84.6629, val_loss: 36.1069, val_MinusLogProbMetric: 36.1069

Epoch 1: val_loss improved from inf to 36.10693, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 29s - loss: 84.6629 - MinusLogProbMetric: 84.6629 - val_loss: 36.1069 - val_MinusLogProbMetric: 36.1069 - lr: 0.0010 - 29s/epoch - 148ms/step
Epoch 2/1000
2023-09-12 19:47:48.444 
Epoch 2/1000 
	 loss: 33.0884, MinusLogProbMetric: 33.0884, val_loss: 31.9902, val_MinusLogProbMetric: 31.9902

Epoch 2: val_loss improved from 36.10693 to 31.99020, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 33.0884 - MinusLogProbMetric: 33.0884 - val_loss: 31.9902 - val_MinusLogProbMetric: 31.9902 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 3/1000
2023-09-12 19:48:00.250 
Epoch 3/1000 
	 loss: 30.9023, MinusLogProbMetric: 30.9023, val_loss: 30.3992, val_MinusLogProbMetric: 30.3992

Epoch 3: val_loss improved from 31.99020 to 30.39923, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 30.9023 - MinusLogProbMetric: 30.9023 - val_loss: 30.3992 - val_MinusLogProbMetric: 30.3992 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 4/1000
2023-09-12 19:48:12.084 
Epoch 4/1000 
	 loss: 29.7488, MinusLogProbMetric: 29.7488, val_loss: 29.7163, val_MinusLogProbMetric: 29.7163

Epoch 4: val_loss improved from 30.39923 to 29.71631, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 29.7488 - MinusLogProbMetric: 29.7488 - val_loss: 29.7163 - val_MinusLogProbMetric: 29.7163 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 5/1000
2023-09-12 19:48:24.118 
Epoch 5/1000 
	 loss: 29.2891, MinusLogProbMetric: 29.2891, val_loss: 29.5211, val_MinusLogProbMetric: 29.5211

Epoch 5: val_loss improved from 29.71631 to 29.52107, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 29.2891 - MinusLogProbMetric: 29.2891 - val_loss: 29.5211 - val_MinusLogProbMetric: 29.5211 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 6/1000
2023-09-12 19:48:35.969 
Epoch 6/1000 
	 loss: 28.9559, MinusLogProbMetric: 28.9559, val_loss: 28.9156, val_MinusLogProbMetric: 28.9156

Epoch 6: val_loss improved from 29.52107 to 28.91561, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 28.9559 - MinusLogProbMetric: 28.9559 - val_loss: 28.9156 - val_MinusLogProbMetric: 28.9156 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 7/1000
2023-09-12 19:48:47.874 
Epoch 7/1000 
	 loss: 28.8021, MinusLogProbMetric: 28.8021, val_loss: 28.7571, val_MinusLogProbMetric: 28.7571

Epoch 7: val_loss improved from 28.91561 to 28.75708, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 28.8021 - MinusLogProbMetric: 28.8021 - val_loss: 28.7571 - val_MinusLogProbMetric: 28.7571 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 8/1000
2023-09-12 19:48:59.875 
Epoch 8/1000 
	 loss: 28.6609, MinusLogProbMetric: 28.6609, val_loss: 28.8055, val_MinusLogProbMetric: 28.8055

Epoch 8: val_loss did not improve from 28.75708
196/196 - 12s - loss: 28.6609 - MinusLogProbMetric: 28.6609 - val_loss: 28.8055 - val_MinusLogProbMetric: 28.8055 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 9/1000
2023-09-12 19:49:11.863 
Epoch 9/1000 
	 loss: 28.5225, MinusLogProbMetric: 28.5225, val_loss: 28.7772, val_MinusLogProbMetric: 28.7772

Epoch 9: val_loss did not improve from 28.75708
196/196 - 12s - loss: 28.5225 - MinusLogProbMetric: 28.5225 - val_loss: 28.7772 - val_MinusLogProbMetric: 28.7772 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-12 19:49:23.722 
Epoch 10/1000 
	 loss: 28.4488, MinusLogProbMetric: 28.4488, val_loss: 28.4378, val_MinusLogProbMetric: 28.4378

Epoch 10: val_loss improved from 28.75708 to 28.43779, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 28.4488 - MinusLogProbMetric: 28.4488 - val_loss: 28.4378 - val_MinusLogProbMetric: 28.4378 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 11/1000
2023-09-12 19:49:35.771 
Epoch 11/1000 
	 loss: 28.3986, MinusLogProbMetric: 28.3986, val_loss: 28.4784, val_MinusLogProbMetric: 28.4784

Epoch 11: val_loss did not improve from 28.43779
196/196 - 12s - loss: 28.3986 - MinusLogProbMetric: 28.3986 - val_loss: 28.4784 - val_MinusLogProbMetric: 28.4784 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 12/1000
2023-09-12 19:49:47.452 
Epoch 12/1000 
	 loss: 28.3355, MinusLogProbMetric: 28.3355, val_loss: 28.4987, val_MinusLogProbMetric: 28.4987

Epoch 12: val_loss did not improve from 28.43779
196/196 - 12s - loss: 28.3355 - MinusLogProbMetric: 28.3355 - val_loss: 28.4987 - val_MinusLogProbMetric: 28.4987 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-12 19:49:59.111 
Epoch 13/1000 
	 loss: 28.2898, MinusLogProbMetric: 28.2898, val_loss: 28.2893, val_MinusLogProbMetric: 28.2893

Epoch 13: val_loss improved from 28.43779 to 28.28926, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 28.2898 - MinusLogProbMetric: 28.2898 - val_loss: 28.2893 - val_MinusLogProbMetric: 28.2893 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 14/1000
2023-09-12 19:50:11.152 
Epoch 14/1000 
	 loss: 28.2074, MinusLogProbMetric: 28.2074, val_loss: 28.2947, val_MinusLogProbMetric: 28.2947

Epoch 14: val_loss did not improve from 28.28926
196/196 - 12s - loss: 28.2074 - MinusLogProbMetric: 28.2074 - val_loss: 28.2947 - val_MinusLogProbMetric: 28.2947 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 15/1000
2023-09-12 19:50:22.685 
Epoch 15/1000 
	 loss: 28.1840, MinusLogProbMetric: 28.1840, val_loss: 28.1248, val_MinusLogProbMetric: 28.1248

Epoch 15: val_loss improved from 28.28926 to 28.12482, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 28.1840 - MinusLogProbMetric: 28.1840 - val_loss: 28.1248 - val_MinusLogProbMetric: 28.1248 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-12 19:50:34.651 
Epoch 16/1000 
	 loss: 28.1000, MinusLogProbMetric: 28.1000, val_loss: 28.1332, val_MinusLogProbMetric: 28.1332

Epoch 16: val_loss did not improve from 28.12482
196/196 - 12s - loss: 28.1000 - MinusLogProbMetric: 28.1000 - val_loss: 28.1332 - val_MinusLogProbMetric: 28.1332 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-12 19:50:46.388 
Epoch 17/1000 
	 loss: 28.0981, MinusLogProbMetric: 28.0981, val_loss: 28.4089, val_MinusLogProbMetric: 28.4089

Epoch 17: val_loss did not improve from 28.12482
196/196 - 12s - loss: 28.0981 - MinusLogProbMetric: 28.0981 - val_loss: 28.4089 - val_MinusLogProbMetric: 28.4089 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 18/1000
2023-09-12 19:50:57.896 
Epoch 18/1000 
	 loss: 28.0532, MinusLogProbMetric: 28.0532, val_loss: 28.1789, val_MinusLogProbMetric: 28.1789

Epoch 18: val_loss did not improve from 28.12482
196/196 - 12s - loss: 28.0532 - MinusLogProbMetric: 28.0532 - val_loss: 28.1789 - val_MinusLogProbMetric: 28.1789 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 19/1000
2023-09-12 19:51:09.574 
Epoch 19/1000 
	 loss: 28.0358, MinusLogProbMetric: 28.0358, val_loss: 28.3032, val_MinusLogProbMetric: 28.3032

Epoch 19: val_loss did not improve from 28.12482
196/196 - 12s - loss: 28.0358 - MinusLogProbMetric: 28.0358 - val_loss: 28.3032 - val_MinusLogProbMetric: 28.3032 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 20/1000
2023-09-12 19:51:21.234 
Epoch 20/1000 
	 loss: 28.0130, MinusLogProbMetric: 28.0130, val_loss: 28.1744, val_MinusLogProbMetric: 28.1744

Epoch 20: val_loss did not improve from 28.12482
196/196 - 12s - loss: 28.0130 - MinusLogProbMetric: 28.0130 - val_loss: 28.1744 - val_MinusLogProbMetric: 28.1744 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 21/1000
2023-09-12 19:51:33.022 
Epoch 21/1000 
	 loss: 28.0011, MinusLogProbMetric: 28.0011, val_loss: 28.0561, val_MinusLogProbMetric: 28.0561

Epoch 21: val_loss improved from 28.12482 to 28.05606, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 28.0011 - MinusLogProbMetric: 28.0011 - val_loss: 28.0561 - val_MinusLogProbMetric: 28.0561 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 22/1000
2023-09-12 19:51:44.644 
Epoch 22/1000 
	 loss: 28.0091, MinusLogProbMetric: 28.0091, val_loss: 28.0839, val_MinusLogProbMetric: 28.0839

Epoch 22: val_loss did not improve from 28.05606
196/196 - 11s - loss: 28.0091 - MinusLogProbMetric: 28.0091 - val_loss: 28.0839 - val_MinusLogProbMetric: 28.0839 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 23/1000
2023-09-12 19:51:56.163 
Epoch 23/1000 
	 loss: 27.9213, MinusLogProbMetric: 27.9213, val_loss: 28.0106, val_MinusLogProbMetric: 28.0106

Epoch 23: val_loss improved from 28.05606 to 28.01065, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 27.9213 - MinusLogProbMetric: 27.9213 - val_loss: 28.0106 - val_MinusLogProbMetric: 28.0106 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 24/1000
2023-09-12 19:52:07.808 
Epoch 24/1000 
	 loss: 27.9417, MinusLogProbMetric: 27.9417, val_loss: 27.9333, val_MinusLogProbMetric: 27.9333

Epoch 24: val_loss improved from 28.01065 to 27.93330, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 27.9417 - MinusLogProbMetric: 27.9417 - val_loss: 27.9333 - val_MinusLogProbMetric: 27.9333 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 25/1000
2023-09-12 19:52:19.632 
Epoch 25/1000 
	 loss: 27.9325, MinusLogProbMetric: 27.9325, val_loss: 27.9205, val_MinusLogProbMetric: 27.9205

Epoch 25: val_loss improved from 27.93330 to 27.92045, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 27.9325 - MinusLogProbMetric: 27.9325 - val_loss: 27.9205 - val_MinusLogProbMetric: 27.9205 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-12 19:52:31.390 
Epoch 26/1000 
	 loss: 27.8650, MinusLogProbMetric: 27.8650, val_loss: 28.0846, val_MinusLogProbMetric: 28.0846

Epoch 26: val_loss did not improve from 27.92045
196/196 - 12s - loss: 27.8650 - MinusLogProbMetric: 27.8650 - val_loss: 28.0846 - val_MinusLogProbMetric: 28.0846 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 27/1000
2023-09-12 19:52:43.245 
Epoch 27/1000 
	 loss: 27.8749, MinusLogProbMetric: 27.8749, val_loss: 27.9267, val_MinusLogProbMetric: 27.9267

Epoch 27: val_loss did not improve from 27.92045
196/196 - 12s - loss: 27.8749 - MinusLogProbMetric: 27.8749 - val_loss: 27.9267 - val_MinusLogProbMetric: 27.9267 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-12 19:52:54.774 
Epoch 28/1000 
	 loss: 27.8780, MinusLogProbMetric: 27.8780, val_loss: 28.0894, val_MinusLogProbMetric: 28.0894

Epoch 28: val_loss did not improve from 27.92045
196/196 - 12s - loss: 27.8780 - MinusLogProbMetric: 27.8780 - val_loss: 28.0894 - val_MinusLogProbMetric: 28.0894 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 29/1000
2023-09-12 19:53:06.355 
Epoch 29/1000 
	 loss: 27.8173, MinusLogProbMetric: 27.8173, val_loss: 28.0184, val_MinusLogProbMetric: 28.0184

Epoch 29: val_loss did not improve from 27.92045
196/196 - 12s - loss: 27.8173 - MinusLogProbMetric: 27.8173 - val_loss: 28.0184 - val_MinusLogProbMetric: 28.0184 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 30/1000
2023-09-12 19:53:17.921 
Epoch 30/1000 
	 loss: 27.8164, MinusLogProbMetric: 27.8164, val_loss: 28.1664, val_MinusLogProbMetric: 28.1664

Epoch 30: val_loss did not improve from 27.92045
196/196 - 12s - loss: 27.8164 - MinusLogProbMetric: 27.8164 - val_loss: 28.1664 - val_MinusLogProbMetric: 28.1664 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 31/1000
2023-09-12 19:53:29.932 
Epoch 31/1000 
	 loss: 27.8570, MinusLogProbMetric: 27.8570, val_loss: 28.0920, val_MinusLogProbMetric: 28.0920

Epoch 31: val_loss did not improve from 27.92045
196/196 - 12s - loss: 27.8570 - MinusLogProbMetric: 27.8570 - val_loss: 28.0920 - val_MinusLogProbMetric: 28.0920 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 32/1000
2023-09-12 19:53:41.790 
Epoch 32/1000 
	 loss: 27.8005, MinusLogProbMetric: 27.8005, val_loss: 27.8444, val_MinusLogProbMetric: 27.8444

Epoch 32: val_loss improved from 27.92045 to 27.84438, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 27.8005 - MinusLogProbMetric: 27.8005 - val_loss: 27.8444 - val_MinusLogProbMetric: 27.8444 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 33/1000
2023-09-12 19:53:53.886 
Epoch 33/1000 
	 loss: 27.7754, MinusLogProbMetric: 27.7754, val_loss: 27.8913, val_MinusLogProbMetric: 27.8913

Epoch 33: val_loss did not improve from 27.84438
196/196 - 12s - loss: 27.7754 - MinusLogProbMetric: 27.7754 - val_loss: 27.8913 - val_MinusLogProbMetric: 27.8913 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 34/1000
2023-09-12 19:54:05.830 
Epoch 34/1000 
	 loss: 27.7971, MinusLogProbMetric: 27.7971, val_loss: 27.8721, val_MinusLogProbMetric: 27.8721

Epoch 34: val_loss did not improve from 27.84438
196/196 - 12s - loss: 27.7971 - MinusLogProbMetric: 27.7971 - val_loss: 27.8721 - val_MinusLogProbMetric: 27.8721 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 35/1000
2023-09-12 19:54:16.702 
Epoch 35/1000 
	 loss: 27.7945, MinusLogProbMetric: 27.7945, val_loss: 27.8914, val_MinusLogProbMetric: 27.8914

Epoch 35: val_loss did not improve from 27.84438
196/196 - 11s - loss: 27.7945 - MinusLogProbMetric: 27.7945 - val_loss: 27.8914 - val_MinusLogProbMetric: 27.8914 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 36/1000
2023-09-12 19:54:28.552 
Epoch 36/1000 
	 loss: 27.7585, MinusLogProbMetric: 27.7585, val_loss: 27.8673, val_MinusLogProbMetric: 27.8673

Epoch 36: val_loss did not improve from 27.84438
196/196 - 12s - loss: 27.7585 - MinusLogProbMetric: 27.7585 - val_loss: 27.8673 - val_MinusLogProbMetric: 27.8673 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 37/1000
2023-09-12 19:54:40.679 
Epoch 37/1000 
	 loss: 27.7339, MinusLogProbMetric: 27.7339, val_loss: 28.0367, val_MinusLogProbMetric: 28.0367

Epoch 37: val_loss did not improve from 27.84438
196/196 - 12s - loss: 27.7339 - MinusLogProbMetric: 27.7339 - val_loss: 28.0367 - val_MinusLogProbMetric: 28.0367 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 38/1000
2023-09-12 19:54:52.237 
Epoch 38/1000 
	 loss: 27.7459, MinusLogProbMetric: 27.7459, val_loss: 27.8022, val_MinusLogProbMetric: 27.8022

Epoch 38: val_loss improved from 27.84438 to 27.80224, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 27.7459 - MinusLogProbMetric: 27.7459 - val_loss: 27.8022 - val_MinusLogProbMetric: 27.8022 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 19:55:03.160 
Epoch 39/1000 
	 loss: 27.7433, MinusLogProbMetric: 27.7433, val_loss: 27.8682, val_MinusLogProbMetric: 27.8682

Epoch 39: val_loss did not improve from 27.80224
196/196 - 11s - loss: 27.7433 - MinusLogProbMetric: 27.7433 - val_loss: 27.8682 - val_MinusLogProbMetric: 27.8682 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 40/1000
2023-09-12 19:55:15.102 
Epoch 40/1000 
	 loss: 27.7166, MinusLogProbMetric: 27.7166, val_loss: 27.8682, val_MinusLogProbMetric: 27.8682

Epoch 40: val_loss did not improve from 27.80224
196/196 - 12s - loss: 27.7166 - MinusLogProbMetric: 27.7166 - val_loss: 27.8682 - val_MinusLogProbMetric: 27.8682 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 41/1000
2023-09-12 19:55:26.480 
Epoch 41/1000 
	 loss: 27.7078, MinusLogProbMetric: 27.7078, val_loss: 27.7635, val_MinusLogProbMetric: 27.7635

Epoch 41: val_loss improved from 27.80224 to 27.76355, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 11s - loss: 27.7078 - MinusLogProbMetric: 27.7078 - val_loss: 27.7635 - val_MinusLogProbMetric: 27.7635 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 42/1000
2023-09-12 19:55:38.167 
Epoch 42/1000 
	 loss: 27.6910, MinusLogProbMetric: 27.6910, val_loss: 27.7345, val_MinusLogProbMetric: 27.7345

Epoch 42: val_loss improved from 27.76355 to 27.73454, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 27.6910 - MinusLogProbMetric: 27.6910 - val_loss: 27.7345 - val_MinusLogProbMetric: 27.7345 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 43/1000
2023-09-12 19:55:50.354 
Epoch 43/1000 
	 loss: 27.7300, MinusLogProbMetric: 27.7300, val_loss: 27.8466, val_MinusLogProbMetric: 27.8466

Epoch 43: val_loss did not improve from 27.73454
196/196 - 12s - loss: 27.7300 - MinusLogProbMetric: 27.7300 - val_loss: 27.8466 - val_MinusLogProbMetric: 27.8466 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 44/1000
2023-09-12 19:56:02.411 
Epoch 44/1000 
	 loss: 27.7296, MinusLogProbMetric: 27.7296, val_loss: 27.8398, val_MinusLogProbMetric: 27.8398

Epoch 44: val_loss did not improve from 27.73454
196/196 - 12s - loss: 27.7296 - MinusLogProbMetric: 27.7296 - val_loss: 27.8398 - val_MinusLogProbMetric: 27.8398 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 45/1000
2023-09-12 19:56:14.488 
Epoch 45/1000 
	 loss: 27.6949, MinusLogProbMetric: 27.6949, val_loss: 28.1115, val_MinusLogProbMetric: 28.1115

Epoch 45: val_loss did not improve from 27.73454
196/196 - 12s - loss: 27.6949 - MinusLogProbMetric: 27.6949 - val_loss: 28.1115 - val_MinusLogProbMetric: 28.1115 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 46/1000
2023-09-12 19:56:26.661 
Epoch 46/1000 
	 loss: 27.6829, MinusLogProbMetric: 27.6829, val_loss: 27.8138, val_MinusLogProbMetric: 27.8138

Epoch 46: val_loss did not improve from 27.73454
196/196 - 12s - loss: 27.6829 - MinusLogProbMetric: 27.6829 - val_loss: 27.8138 - val_MinusLogProbMetric: 27.8138 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 47/1000
2023-09-12 19:56:38.646 
Epoch 47/1000 
	 loss: 27.6990, MinusLogProbMetric: 27.6990, val_loss: 27.7910, val_MinusLogProbMetric: 27.7910

Epoch 47: val_loss did not improve from 27.73454
196/196 - 12s - loss: 27.6990 - MinusLogProbMetric: 27.6990 - val_loss: 27.7910 - val_MinusLogProbMetric: 27.7910 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 48/1000
2023-09-12 19:56:49.448 
Epoch 48/1000 
	 loss: 27.6683, MinusLogProbMetric: 27.6683, val_loss: 27.7578, val_MinusLogProbMetric: 27.7578

Epoch 48: val_loss did not improve from 27.73454
196/196 - 11s - loss: 27.6683 - MinusLogProbMetric: 27.6683 - val_loss: 27.7578 - val_MinusLogProbMetric: 27.7578 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 49/1000
2023-09-12 19:57:00.827 
Epoch 49/1000 
	 loss: 27.6545, MinusLogProbMetric: 27.6545, val_loss: 28.0125, val_MinusLogProbMetric: 28.0125

Epoch 49: val_loss did not improve from 27.73454
196/196 - 11s - loss: 27.6545 - MinusLogProbMetric: 27.6545 - val_loss: 28.0125 - val_MinusLogProbMetric: 28.0125 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 50/1000
2023-09-12 19:57:12.802 
Epoch 50/1000 
	 loss: 27.6775, MinusLogProbMetric: 27.6775, val_loss: 27.7889, val_MinusLogProbMetric: 27.7889

Epoch 50: val_loss did not improve from 27.73454
196/196 - 12s - loss: 27.6775 - MinusLogProbMetric: 27.6775 - val_loss: 27.7889 - val_MinusLogProbMetric: 27.7889 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 51/1000
2023-09-12 19:57:22.238 
Epoch 51/1000 
	 loss: 27.6719, MinusLogProbMetric: 27.6719, val_loss: 27.7738, val_MinusLogProbMetric: 27.7738

Epoch 51: val_loss did not improve from 27.73454
196/196 - 9s - loss: 27.6719 - MinusLogProbMetric: 27.6719 - val_loss: 27.7738 - val_MinusLogProbMetric: 27.7738 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 52/1000
2023-09-12 19:57:32.126 
Epoch 52/1000 
	 loss: 27.6753, MinusLogProbMetric: 27.6753, val_loss: 27.7578, val_MinusLogProbMetric: 27.7578

Epoch 52: val_loss did not improve from 27.73454
196/196 - 10s - loss: 27.6753 - MinusLogProbMetric: 27.6753 - val_loss: 27.7578 - val_MinusLogProbMetric: 27.7578 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 53/1000
2023-09-12 19:57:41.974 
Epoch 53/1000 
	 loss: 27.6308, MinusLogProbMetric: 27.6308, val_loss: 28.0158, val_MinusLogProbMetric: 28.0158

Epoch 53: val_loss did not improve from 27.73454
196/196 - 10s - loss: 27.6308 - MinusLogProbMetric: 27.6308 - val_loss: 28.0158 - val_MinusLogProbMetric: 28.0158 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 54/1000
2023-09-12 19:57:51.321 
Epoch 54/1000 
	 loss: 27.6693, MinusLogProbMetric: 27.6693, val_loss: 27.8190, val_MinusLogProbMetric: 27.8190

Epoch 54: val_loss did not improve from 27.73454
196/196 - 9s - loss: 27.6693 - MinusLogProbMetric: 27.6693 - val_loss: 27.8190 - val_MinusLogProbMetric: 27.8190 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 55/1000
2023-09-12 19:58:01.212 
Epoch 55/1000 
	 loss: 27.6617, MinusLogProbMetric: 27.6617, val_loss: 27.7230, val_MinusLogProbMetric: 27.7230

Epoch 55: val_loss improved from 27.73454 to 27.72297, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 10s - loss: 27.6617 - MinusLogProbMetric: 27.6617 - val_loss: 27.7230 - val_MinusLogProbMetric: 27.7230 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 56/1000
2023-09-12 19:58:13.213 
Epoch 56/1000 
	 loss: 27.6401, MinusLogProbMetric: 27.6401, val_loss: 27.9094, val_MinusLogProbMetric: 27.9094

Epoch 56: val_loss did not improve from 27.72297
196/196 - 12s - loss: 27.6401 - MinusLogProbMetric: 27.6401 - val_loss: 27.9094 - val_MinusLogProbMetric: 27.9094 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 57/1000
2023-09-12 19:58:25.150 
Epoch 57/1000 
	 loss: 27.6487, MinusLogProbMetric: 27.6487, val_loss: 27.7347, val_MinusLogProbMetric: 27.7347

Epoch 57: val_loss did not improve from 27.72297
196/196 - 12s - loss: 27.6487 - MinusLogProbMetric: 27.6487 - val_loss: 27.7347 - val_MinusLogProbMetric: 27.7347 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 58/1000
2023-09-12 19:58:34.521 
Epoch 58/1000 
	 loss: 27.6257, MinusLogProbMetric: 27.6257, val_loss: 27.7597, val_MinusLogProbMetric: 27.7597

Epoch 58: val_loss did not improve from 27.72297
196/196 - 9s - loss: 27.6257 - MinusLogProbMetric: 27.6257 - val_loss: 27.7597 - val_MinusLogProbMetric: 27.7597 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 59/1000
2023-09-12 19:58:44.467 
Epoch 59/1000 
	 loss: 27.6190, MinusLogProbMetric: 27.6190, val_loss: 27.7018, val_MinusLogProbMetric: 27.7018

Epoch 59: val_loss improved from 27.72297 to 27.70183, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 10s - loss: 27.6190 - MinusLogProbMetric: 27.6190 - val_loss: 27.7018 - val_MinusLogProbMetric: 27.7018 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 60/1000
2023-09-12 19:58:56.556 
Epoch 60/1000 
	 loss: 27.6165, MinusLogProbMetric: 27.6165, val_loss: 27.7807, val_MinusLogProbMetric: 27.7807

Epoch 60: val_loss did not improve from 27.70183
196/196 - 12s - loss: 27.6165 - MinusLogProbMetric: 27.6165 - val_loss: 27.7807 - val_MinusLogProbMetric: 27.7807 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 61/1000
2023-09-12 19:59:07.846 
Epoch 61/1000 
	 loss: 27.6221, MinusLogProbMetric: 27.6221, val_loss: 27.6770, val_MinusLogProbMetric: 27.6770

Epoch 61: val_loss improved from 27.70183 to 27.67698, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 11s - loss: 27.6221 - MinusLogProbMetric: 27.6221 - val_loss: 27.6770 - val_MinusLogProbMetric: 27.6770 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 62/1000
2023-09-12 19:59:17.508 
Epoch 62/1000 
	 loss: 27.6096, MinusLogProbMetric: 27.6096, val_loss: 27.7766, val_MinusLogProbMetric: 27.7766

Epoch 62: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.6096 - MinusLogProbMetric: 27.6096 - val_loss: 27.7766 - val_MinusLogProbMetric: 27.7766 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 63/1000
2023-09-12 19:59:26.944 
Epoch 63/1000 
	 loss: 27.6201, MinusLogProbMetric: 27.6201, val_loss: 27.7526, val_MinusLogProbMetric: 27.7526

Epoch 63: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.6201 - MinusLogProbMetric: 27.6201 - val_loss: 27.7526 - val_MinusLogProbMetric: 27.7526 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 64/1000
2023-09-12 19:59:36.399 
Epoch 64/1000 
	 loss: 27.6230, MinusLogProbMetric: 27.6230, val_loss: 27.7774, val_MinusLogProbMetric: 27.7774

Epoch 64: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.6230 - MinusLogProbMetric: 27.6230 - val_loss: 27.7774 - val_MinusLogProbMetric: 27.7774 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 65/1000
2023-09-12 19:59:45.917 
Epoch 65/1000 
	 loss: 27.6134, MinusLogProbMetric: 27.6134, val_loss: 27.8588, val_MinusLogProbMetric: 27.8588

Epoch 65: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.6134 - MinusLogProbMetric: 27.6134 - val_loss: 27.8588 - val_MinusLogProbMetric: 27.8588 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 66/1000
2023-09-12 19:59:55.187 
Epoch 66/1000 
	 loss: 27.5970, MinusLogProbMetric: 27.5970, val_loss: 27.7562, val_MinusLogProbMetric: 27.7562

Epoch 66: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5970 - MinusLogProbMetric: 27.5970 - val_loss: 27.7562 - val_MinusLogProbMetric: 27.7562 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 67/1000
2023-09-12 20:00:05.324 
Epoch 67/1000 
	 loss: 27.5964, MinusLogProbMetric: 27.5964, val_loss: 27.6979, val_MinusLogProbMetric: 27.6979

Epoch 67: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.5964 - MinusLogProbMetric: 27.5964 - val_loss: 27.6979 - val_MinusLogProbMetric: 27.6979 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 68/1000
2023-09-12 20:00:16.842 
Epoch 68/1000 
	 loss: 27.6001, MinusLogProbMetric: 27.6001, val_loss: 27.6993, val_MinusLogProbMetric: 27.6993

Epoch 68: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.6001 - MinusLogProbMetric: 27.6001 - val_loss: 27.6993 - val_MinusLogProbMetric: 27.6993 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-12 20:00:26.701 
Epoch 69/1000 
	 loss: 27.6179, MinusLogProbMetric: 27.6179, val_loss: 27.7626, val_MinusLogProbMetric: 27.7626

Epoch 69: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.6179 - MinusLogProbMetric: 27.6179 - val_loss: 27.7626 - val_MinusLogProbMetric: 27.7626 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 70/1000
2023-09-12 20:00:36.353 
Epoch 70/1000 
	 loss: 27.5908, MinusLogProbMetric: 27.5908, val_loss: 27.8504, val_MinusLogProbMetric: 27.8504

Epoch 70: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.5908 - MinusLogProbMetric: 27.5908 - val_loss: 27.8504 - val_MinusLogProbMetric: 27.8504 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 71/1000
2023-09-12 20:00:46.386 
Epoch 71/1000 
	 loss: 27.5934, MinusLogProbMetric: 27.5934, val_loss: 27.7825, val_MinusLogProbMetric: 27.7825

Epoch 71: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.5934 - MinusLogProbMetric: 27.5934 - val_loss: 27.7825 - val_MinusLogProbMetric: 27.7825 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 72/1000
2023-09-12 20:00:55.635 
Epoch 72/1000 
	 loss: 27.5849, MinusLogProbMetric: 27.5849, val_loss: 27.8044, val_MinusLogProbMetric: 27.8044

Epoch 72: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5849 - MinusLogProbMetric: 27.5849 - val_loss: 27.8044 - val_MinusLogProbMetric: 27.8044 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 73/1000
2023-09-12 20:01:04.939 
Epoch 73/1000 
	 loss: 27.5799, MinusLogProbMetric: 27.5799, val_loss: 27.8712, val_MinusLogProbMetric: 27.8712

Epoch 73: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5799 - MinusLogProbMetric: 27.5799 - val_loss: 27.8712 - val_MinusLogProbMetric: 27.8712 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 74/1000
2023-09-12 20:01:14.134 
Epoch 74/1000 
	 loss: 27.5635, MinusLogProbMetric: 27.5635, val_loss: 27.6918, val_MinusLogProbMetric: 27.6918

Epoch 74: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5635 - MinusLogProbMetric: 27.5635 - val_loss: 27.6918 - val_MinusLogProbMetric: 27.6918 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 75/1000
2023-09-12 20:01:23.136 
Epoch 75/1000 
	 loss: 27.5593, MinusLogProbMetric: 27.5593, val_loss: 27.7401, val_MinusLogProbMetric: 27.7401

Epoch 75: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5593 - MinusLogProbMetric: 27.5593 - val_loss: 27.7401 - val_MinusLogProbMetric: 27.7401 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 76/1000
2023-09-12 20:01:32.351 
Epoch 76/1000 
	 loss: 27.5770, MinusLogProbMetric: 27.5770, val_loss: 27.8221, val_MinusLogProbMetric: 27.8221

Epoch 76: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5770 - MinusLogProbMetric: 27.5770 - val_loss: 27.8221 - val_MinusLogProbMetric: 27.8221 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 77/1000
2023-09-12 20:01:41.472 
Epoch 77/1000 
	 loss: 27.5643, MinusLogProbMetric: 27.5643, val_loss: 27.7218, val_MinusLogProbMetric: 27.7218

Epoch 77: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5643 - MinusLogProbMetric: 27.5643 - val_loss: 27.7218 - val_MinusLogProbMetric: 27.7218 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 78/1000
2023-09-12 20:01:52.952 
Epoch 78/1000 
	 loss: 27.5537, MinusLogProbMetric: 27.5537, val_loss: 27.7387, val_MinusLogProbMetric: 27.7387

Epoch 78: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5537 - MinusLogProbMetric: 27.5537 - val_loss: 27.7387 - val_MinusLogProbMetric: 27.7387 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 79/1000
2023-09-12 20:02:02.343 
Epoch 79/1000 
	 loss: 27.5516, MinusLogProbMetric: 27.5516, val_loss: 27.8347, val_MinusLogProbMetric: 27.8347

Epoch 79: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5516 - MinusLogProbMetric: 27.5516 - val_loss: 27.8347 - val_MinusLogProbMetric: 27.8347 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 80/1000
2023-09-12 20:02:13.157 
Epoch 80/1000 
	 loss: 27.5574, MinusLogProbMetric: 27.5574, val_loss: 27.8924, val_MinusLogProbMetric: 27.8924

Epoch 80: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5574 - MinusLogProbMetric: 27.5574 - val_loss: 27.8924 - val_MinusLogProbMetric: 27.8924 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 81/1000
2023-09-12 20:02:22.990 
Epoch 81/1000 
	 loss: 27.5686, MinusLogProbMetric: 27.5686, val_loss: 27.7628, val_MinusLogProbMetric: 27.7628

Epoch 81: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.5686 - MinusLogProbMetric: 27.5686 - val_loss: 27.7628 - val_MinusLogProbMetric: 27.7628 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 82/1000
2023-09-12 20:02:34.620 
Epoch 82/1000 
	 loss: 27.5680, MinusLogProbMetric: 27.5680, val_loss: 27.6915, val_MinusLogProbMetric: 27.6915

Epoch 82: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.5680 - MinusLogProbMetric: 27.5680 - val_loss: 27.6915 - val_MinusLogProbMetric: 27.6915 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 83/1000
2023-09-12 20:02:46.205 
Epoch 83/1000 
	 loss: 27.5574, MinusLogProbMetric: 27.5574, val_loss: 27.7079, val_MinusLogProbMetric: 27.7079

Epoch 83: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.5574 - MinusLogProbMetric: 27.5574 - val_loss: 27.7079 - val_MinusLogProbMetric: 27.7079 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 84/1000
2023-09-12 20:02:56.361 
Epoch 84/1000 
	 loss: 27.5586, MinusLogProbMetric: 27.5586, val_loss: 27.7781, val_MinusLogProbMetric: 27.7781

Epoch 84: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.5586 - MinusLogProbMetric: 27.5586 - val_loss: 27.7781 - val_MinusLogProbMetric: 27.7781 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 85/1000
2023-09-12 20:03:08.011 
Epoch 85/1000 
	 loss: 27.5506, MinusLogProbMetric: 27.5506, val_loss: 27.7108, val_MinusLogProbMetric: 27.7108

Epoch 85: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.5506 - MinusLogProbMetric: 27.5506 - val_loss: 27.7108 - val_MinusLogProbMetric: 27.7108 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-12 20:03:18.416 
Epoch 86/1000 
	 loss: 27.5324, MinusLogProbMetric: 27.5324, val_loss: 27.7927, val_MinusLogProbMetric: 27.7927

Epoch 86: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.5324 - MinusLogProbMetric: 27.5324 - val_loss: 27.7927 - val_MinusLogProbMetric: 27.7927 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 87/1000
2023-09-12 20:03:27.950 
Epoch 87/1000 
	 loss: 27.5420, MinusLogProbMetric: 27.5420, val_loss: 27.7180, val_MinusLogProbMetric: 27.7180

Epoch 87: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.5420 - MinusLogProbMetric: 27.5420 - val_loss: 27.7180 - val_MinusLogProbMetric: 27.7180 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 88/1000
2023-09-12 20:03:37.374 
Epoch 88/1000 
	 loss: 27.5449, MinusLogProbMetric: 27.5449, val_loss: 27.7128, val_MinusLogProbMetric: 27.7128

Epoch 88: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5449 - MinusLogProbMetric: 27.5449 - val_loss: 27.7128 - val_MinusLogProbMetric: 27.7128 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 89/1000
2023-09-12 20:03:49.216 
Epoch 89/1000 
	 loss: 27.5398, MinusLogProbMetric: 27.5398, val_loss: 27.7307, val_MinusLogProbMetric: 27.7307

Epoch 89: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.5398 - MinusLogProbMetric: 27.5398 - val_loss: 27.7307 - val_MinusLogProbMetric: 27.7307 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-12 20:03:59.784 
Epoch 90/1000 
	 loss: 27.5394, MinusLogProbMetric: 27.5394, val_loss: 27.9085, val_MinusLogProbMetric: 27.9085

Epoch 90: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5394 - MinusLogProbMetric: 27.5394 - val_loss: 27.9085 - val_MinusLogProbMetric: 27.9085 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 91/1000
2023-09-12 20:04:09.144 
Epoch 91/1000 
	 loss: 27.5437, MinusLogProbMetric: 27.5437, val_loss: 27.6992, val_MinusLogProbMetric: 27.6992

Epoch 91: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5437 - MinusLogProbMetric: 27.5437 - val_loss: 27.6992 - val_MinusLogProbMetric: 27.6992 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 92/1000
2023-09-12 20:04:20.193 
Epoch 92/1000 
	 loss: 27.5243, MinusLogProbMetric: 27.5243, val_loss: 27.7140, val_MinusLogProbMetric: 27.7140

Epoch 92: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5243 - MinusLogProbMetric: 27.5243 - val_loss: 27.7140 - val_MinusLogProbMetric: 27.7140 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 93/1000
2023-09-12 20:04:30.822 
Epoch 93/1000 
	 loss: 27.5374, MinusLogProbMetric: 27.5374, val_loss: 27.8228, val_MinusLogProbMetric: 27.8228

Epoch 93: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5374 - MinusLogProbMetric: 27.5374 - val_loss: 27.8228 - val_MinusLogProbMetric: 27.8228 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 94/1000
2023-09-12 20:04:40.101 
Epoch 94/1000 
	 loss: 27.5401, MinusLogProbMetric: 27.5401, val_loss: 27.7286, val_MinusLogProbMetric: 27.7286

Epoch 94: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5401 - MinusLogProbMetric: 27.5401 - val_loss: 27.7286 - val_MinusLogProbMetric: 27.7286 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 95/1000
2023-09-12 20:04:49.298 
Epoch 95/1000 
	 loss: 27.5188, MinusLogProbMetric: 27.5188, val_loss: 27.7162, val_MinusLogProbMetric: 27.7162

Epoch 95: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5188 - MinusLogProbMetric: 27.5188 - val_loss: 27.7162 - val_MinusLogProbMetric: 27.7162 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 96/1000
2023-09-12 20:05:00.293 
Epoch 96/1000 
	 loss: 27.5274, MinusLogProbMetric: 27.5274, val_loss: 27.8383, val_MinusLogProbMetric: 27.8383

Epoch 96: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5274 - MinusLogProbMetric: 27.5274 - val_loss: 27.8383 - val_MinusLogProbMetric: 27.8383 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 97/1000
2023-09-12 20:05:11.893 
Epoch 97/1000 
	 loss: 27.5125, MinusLogProbMetric: 27.5125, val_loss: 27.7279, val_MinusLogProbMetric: 27.7279

Epoch 97: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.5125 - MinusLogProbMetric: 27.5125 - val_loss: 27.7279 - val_MinusLogProbMetric: 27.7279 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 98/1000
2023-09-12 20:05:23.051 
Epoch 98/1000 
	 loss: 27.5106, MinusLogProbMetric: 27.5106, val_loss: 27.7734, val_MinusLogProbMetric: 27.7734

Epoch 98: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5106 - MinusLogProbMetric: 27.5106 - val_loss: 27.7734 - val_MinusLogProbMetric: 27.7734 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 99/1000
2023-09-12 20:05:32.130 
Epoch 99/1000 
	 loss: 27.5030, MinusLogProbMetric: 27.5030, val_loss: 27.7062, val_MinusLogProbMetric: 27.7062

Epoch 99: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5030 - MinusLogProbMetric: 27.5030 - val_loss: 27.7062 - val_MinusLogProbMetric: 27.7062 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 100/1000
2023-09-12 20:05:43.194 
Epoch 100/1000 
	 loss: 27.5024, MinusLogProbMetric: 27.5024, val_loss: 27.7310, val_MinusLogProbMetric: 27.7310

Epoch 100: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.5024 - MinusLogProbMetric: 27.5024 - val_loss: 27.7310 - val_MinusLogProbMetric: 27.7310 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 101/1000
2023-09-12 20:05:54.575 
Epoch 101/1000 
	 loss: 27.4937, MinusLogProbMetric: 27.4937, val_loss: 27.7481, val_MinusLogProbMetric: 27.7481

Epoch 101: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.4937 - MinusLogProbMetric: 27.4937 - val_loss: 27.7481 - val_MinusLogProbMetric: 27.7481 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 102/1000
2023-09-12 20:06:06.233 
Epoch 102/1000 
	 loss: 27.4978, MinusLogProbMetric: 27.4978, val_loss: 27.6880, val_MinusLogProbMetric: 27.6880

Epoch 102: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.4978 - MinusLogProbMetric: 27.4978 - val_loss: 27.6880 - val_MinusLogProbMetric: 27.6880 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 103/1000
2023-09-12 20:06:16.783 
Epoch 103/1000 
	 loss: 27.4960, MinusLogProbMetric: 27.4960, val_loss: 27.7809, val_MinusLogProbMetric: 27.7809

Epoch 103: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.4960 - MinusLogProbMetric: 27.4960 - val_loss: 27.7809 - val_MinusLogProbMetric: 27.7809 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 104/1000
2023-09-12 20:06:28.460 
Epoch 104/1000 
	 loss: 27.4849, MinusLogProbMetric: 27.4849, val_loss: 27.7380, val_MinusLogProbMetric: 27.7380

Epoch 104: val_loss did not improve from 27.67698
196/196 - 12s - loss: 27.4849 - MinusLogProbMetric: 27.4849 - val_loss: 27.7380 - val_MinusLogProbMetric: 27.7380 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 105/1000
2023-09-12 20:06:37.629 
Epoch 105/1000 
	 loss: 27.5148, MinusLogProbMetric: 27.5148, val_loss: 27.7855, val_MinusLogProbMetric: 27.7855

Epoch 105: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.5148 - MinusLogProbMetric: 27.5148 - val_loss: 27.7855 - val_MinusLogProbMetric: 27.7855 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 106/1000
2023-09-12 20:06:47.294 
Epoch 106/1000 
	 loss: 27.4975, MinusLogProbMetric: 27.4975, val_loss: 27.6985, val_MinusLogProbMetric: 27.6985

Epoch 106: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.4975 - MinusLogProbMetric: 27.4975 - val_loss: 27.6985 - val_MinusLogProbMetric: 27.6985 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 107/1000
2023-09-12 20:06:56.463 
Epoch 107/1000 
	 loss: 27.4936, MinusLogProbMetric: 27.4936, val_loss: 27.7603, val_MinusLogProbMetric: 27.7603

Epoch 107: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.4936 - MinusLogProbMetric: 27.4936 - val_loss: 27.7603 - val_MinusLogProbMetric: 27.7603 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 108/1000
2023-09-12 20:07:05.895 
Epoch 108/1000 
	 loss: 27.4953, MinusLogProbMetric: 27.4953, val_loss: 27.6955, val_MinusLogProbMetric: 27.6955

Epoch 108: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.4953 - MinusLogProbMetric: 27.4953 - val_loss: 27.6955 - val_MinusLogProbMetric: 27.6955 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 109/1000
2023-09-12 20:07:15.194 
Epoch 109/1000 
	 loss: 27.4739, MinusLogProbMetric: 27.4739, val_loss: 27.7684, val_MinusLogProbMetric: 27.7684

Epoch 109: val_loss did not improve from 27.67698
196/196 - 9s - loss: 27.4739 - MinusLogProbMetric: 27.4739 - val_loss: 27.7684 - val_MinusLogProbMetric: 27.7684 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 110/1000
2023-09-12 20:07:25.692 
Epoch 110/1000 
	 loss: 27.4954, MinusLogProbMetric: 27.4954, val_loss: 27.7589, val_MinusLogProbMetric: 27.7589

Epoch 110: val_loss did not improve from 27.67698
196/196 - 10s - loss: 27.4954 - MinusLogProbMetric: 27.4954 - val_loss: 27.7589 - val_MinusLogProbMetric: 27.7589 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 111/1000
2023-09-12 20:07:37.114 
Epoch 111/1000 
	 loss: 27.4825, MinusLogProbMetric: 27.4825, val_loss: 27.6896, val_MinusLogProbMetric: 27.6896

Epoch 111: val_loss did not improve from 27.67698
196/196 - 11s - loss: 27.4825 - MinusLogProbMetric: 27.4825 - val_loss: 27.6896 - val_MinusLogProbMetric: 27.6896 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 112/1000
2023-09-12 20:07:48.620 
Epoch 112/1000 
	 loss: 27.3613, MinusLogProbMetric: 27.3613, val_loss: 27.6033, val_MinusLogProbMetric: 27.6033

Epoch 112: val_loss improved from 27.67698 to 27.60327, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_174/weights/best_weights.h5
196/196 - 12s - loss: 27.3613 - MinusLogProbMetric: 27.3613 - val_loss: 27.6033 - val_MinusLogProbMetric: 27.6033 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 113/1000
2023-09-12 20:07:58.340 
Epoch 113/1000 
	 loss: 27.3603, MinusLogProbMetric: 27.3603, val_loss: 27.6368, val_MinusLogProbMetric: 27.6368

Epoch 113: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.3603 - MinusLogProbMetric: 27.3603 - val_loss: 27.6368 - val_MinusLogProbMetric: 27.6368 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 114/1000
2023-09-12 20:08:07.305 
Epoch 114/1000 
	 loss: 27.3546, MinusLogProbMetric: 27.3546, val_loss: 27.6209, val_MinusLogProbMetric: 27.6209

Epoch 114: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3546 - MinusLogProbMetric: 27.3546 - val_loss: 27.6209 - val_MinusLogProbMetric: 27.6209 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 115/1000
2023-09-12 20:08:16.229 
Epoch 115/1000 
	 loss: 27.3578, MinusLogProbMetric: 27.3578, val_loss: 27.6428, val_MinusLogProbMetric: 27.6428

Epoch 115: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3578 - MinusLogProbMetric: 27.3578 - val_loss: 27.6428 - val_MinusLogProbMetric: 27.6428 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 116/1000
2023-09-12 20:08:24.923 
Epoch 116/1000 
	 loss: 27.3553, MinusLogProbMetric: 27.3553, val_loss: 27.6282, val_MinusLogProbMetric: 27.6282

Epoch 116: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3553 - MinusLogProbMetric: 27.3553 - val_loss: 27.6282 - val_MinusLogProbMetric: 27.6282 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 117/1000
2023-09-12 20:08:33.210 
Epoch 117/1000 
	 loss: 27.3577, MinusLogProbMetric: 27.3577, val_loss: 27.6104, val_MinusLogProbMetric: 27.6104

Epoch 117: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3577 - MinusLogProbMetric: 27.3577 - val_loss: 27.6104 - val_MinusLogProbMetric: 27.6104 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 118/1000
2023-09-12 20:08:42.956 
Epoch 118/1000 
	 loss: 27.3513, MinusLogProbMetric: 27.3513, val_loss: 27.6230, val_MinusLogProbMetric: 27.6230

Epoch 118: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.3513 - MinusLogProbMetric: 27.3513 - val_loss: 27.6230 - val_MinusLogProbMetric: 27.6230 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 119/1000
2023-09-12 20:08:53.873 
Epoch 119/1000 
	 loss: 27.3561, MinusLogProbMetric: 27.3561, val_loss: 27.6061, val_MinusLogProbMetric: 27.6061

Epoch 119: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.3561 - MinusLogProbMetric: 27.3561 - val_loss: 27.6061 - val_MinusLogProbMetric: 27.6061 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 120/1000
2023-09-12 20:09:03.369 
Epoch 120/1000 
	 loss: 27.3490, MinusLogProbMetric: 27.3490, val_loss: 27.6407, val_MinusLogProbMetric: 27.6407

Epoch 120: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3490 - MinusLogProbMetric: 27.3490 - val_loss: 27.6407 - val_MinusLogProbMetric: 27.6407 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 121/1000
2023-09-12 20:09:11.820 
Epoch 121/1000 
	 loss: 27.3472, MinusLogProbMetric: 27.3472, val_loss: 27.6291, val_MinusLogProbMetric: 27.6291

Epoch 121: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3472 - MinusLogProbMetric: 27.3472 - val_loss: 27.6291 - val_MinusLogProbMetric: 27.6291 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 122/1000
2023-09-12 20:09:20.675 
Epoch 122/1000 
	 loss: 27.3510, MinusLogProbMetric: 27.3510, val_loss: 27.6396, val_MinusLogProbMetric: 27.6396

Epoch 122: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3510 - MinusLogProbMetric: 27.3510 - val_loss: 27.6396 - val_MinusLogProbMetric: 27.6396 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 123/1000
2023-09-12 20:09:30.888 
Epoch 123/1000 
	 loss: 27.3403, MinusLogProbMetric: 27.3403, val_loss: 27.6379, val_MinusLogProbMetric: 27.6379

Epoch 123: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.3403 - MinusLogProbMetric: 27.3403 - val_loss: 27.6379 - val_MinusLogProbMetric: 27.6379 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 124/1000
2023-09-12 20:09:41.907 
Epoch 124/1000 
	 loss: 27.3470, MinusLogProbMetric: 27.3470, val_loss: 27.6393, val_MinusLogProbMetric: 27.6393

Epoch 124: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.3470 - MinusLogProbMetric: 27.3470 - val_loss: 27.6393 - val_MinusLogProbMetric: 27.6393 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 125/1000
2023-09-12 20:09:50.695 
Epoch 125/1000 
	 loss: 27.3436, MinusLogProbMetric: 27.3436, val_loss: 27.6566, val_MinusLogProbMetric: 27.6566

Epoch 125: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3436 - MinusLogProbMetric: 27.3436 - val_loss: 27.6566 - val_MinusLogProbMetric: 27.6566 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 126/1000
2023-09-12 20:09:59.197 
Epoch 126/1000 
	 loss: 27.3424, MinusLogProbMetric: 27.3424, val_loss: 27.6211, val_MinusLogProbMetric: 27.6211

Epoch 126: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3424 - MinusLogProbMetric: 27.3424 - val_loss: 27.6211 - val_MinusLogProbMetric: 27.6211 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 127/1000
2023-09-12 20:10:07.841 
Epoch 127/1000 
	 loss: 27.3378, MinusLogProbMetric: 27.3378, val_loss: 27.6649, val_MinusLogProbMetric: 27.6649

Epoch 127: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3378 - MinusLogProbMetric: 27.3378 - val_loss: 27.6649 - val_MinusLogProbMetric: 27.6649 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 128/1000
2023-09-12 20:10:16.278 
Epoch 128/1000 
	 loss: 27.3409, MinusLogProbMetric: 27.3409, val_loss: 27.6227, val_MinusLogProbMetric: 27.6227

Epoch 128: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3409 - MinusLogProbMetric: 27.3409 - val_loss: 27.6227 - val_MinusLogProbMetric: 27.6227 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 129/1000
2023-09-12 20:10:24.407 
Epoch 129/1000 
	 loss: 27.3473, MinusLogProbMetric: 27.3473, val_loss: 27.6296, val_MinusLogProbMetric: 27.6296

Epoch 129: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3473 - MinusLogProbMetric: 27.3473 - val_loss: 27.6296 - val_MinusLogProbMetric: 27.6296 - lr: 5.0000e-04 - 8s/epoch - 41ms/step
Epoch 130/1000
2023-09-12 20:10:33.149 
Epoch 130/1000 
	 loss: 27.3370, MinusLogProbMetric: 27.3370, val_loss: 27.6429, val_MinusLogProbMetric: 27.6429

Epoch 130: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3370 - MinusLogProbMetric: 27.3370 - val_loss: 27.6429 - val_MinusLogProbMetric: 27.6429 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 131/1000
2023-09-12 20:10:41.619 
Epoch 131/1000 
	 loss: 27.3336, MinusLogProbMetric: 27.3336, val_loss: 27.6229, val_MinusLogProbMetric: 27.6229

Epoch 131: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3336 - MinusLogProbMetric: 27.3336 - val_loss: 27.6229 - val_MinusLogProbMetric: 27.6229 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 132/1000
2023-09-12 20:10:51.480 
Epoch 132/1000 
	 loss: 27.3344, MinusLogProbMetric: 27.3344, val_loss: 27.6207, val_MinusLogProbMetric: 27.6207

Epoch 132: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.3344 - MinusLogProbMetric: 27.3344 - val_loss: 27.6207 - val_MinusLogProbMetric: 27.6207 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 133/1000
2023-09-12 20:11:02.497 
Epoch 133/1000 
	 loss: 27.3326, MinusLogProbMetric: 27.3326, val_loss: 27.6569, val_MinusLogProbMetric: 27.6569

Epoch 133: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.3326 - MinusLogProbMetric: 27.3326 - val_loss: 27.6569 - val_MinusLogProbMetric: 27.6569 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 134/1000
2023-09-12 20:11:13.449 
Epoch 134/1000 
	 loss: 27.3356, MinusLogProbMetric: 27.3356, val_loss: 27.6649, val_MinusLogProbMetric: 27.6649

Epoch 134: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.3356 - MinusLogProbMetric: 27.3356 - val_loss: 27.6649 - val_MinusLogProbMetric: 27.6649 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 135/1000
2023-09-12 20:11:23.946 
Epoch 135/1000 
	 loss: 27.3337, MinusLogProbMetric: 27.3337, val_loss: 27.6511, val_MinusLogProbMetric: 27.6511

Epoch 135: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.3337 - MinusLogProbMetric: 27.3337 - val_loss: 27.6511 - val_MinusLogProbMetric: 27.6511 - lr: 5.0000e-04 - 10s/epoch - 54ms/step
Epoch 136/1000
2023-09-12 20:11:33.348 
Epoch 136/1000 
	 loss: 27.3351, MinusLogProbMetric: 27.3351, val_loss: 27.6632, val_MinusLogProbMetric: 27.6632

Epoch 136: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3351 - MinusLogProbMetric: 27.3351 - val_loss: 27.6632 - val_MinusLogProbMetric: 27.6632 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 137/1000
2023-09-12 20:11:41.882 
Epoch 137/1000 
	 loss: 27.3341, MinusLogProbMetric: 27.3341, val_loss: 27.6373, val_MinusLogProbMetric: 27.6373

Epoch 137: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3341 - MinusLogProbMetric: 27.3341 - val_loss: 27.6373 - val_MinusLogProbMetric: 27.6373 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 138/1000
2023-09-12 20:11:50.322 
Epoch 138/1000 
	 loss: 27.3266, MinusLogProbMetric: 27.3266, val_loss: 27.6422, val_MinusLogProbMetric: 27.6422

Epoch 138: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3266 - MinusLogProbMetric: 27.3266 - val_loss: 27.6422 - val_MinusLogProbMetric: 27.6422 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 139/1000
2023-09-12 20:11:59.755 
Epoch 139/1000 
	 loss: 27.3285, MinusLogProbMetric: 27.3285, val_loss: 27.6682, val_MinusLogProbMetric: 27.6682

Epoch 139: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3285 - MinusLogProbMetric: 27.3285 - val_loss: 27.6682 - val_MinusLogProbMetric: 27.6682 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 140/1000
2023-09-12 20:12:10.410 
Epoch 140/1000 
	 loss: 27.3295, MinusLogProbMetric: 27.3295, val_loss: 27.6634, val_MinusLogProbMetric: 27.6634

Epoch 140: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.3295 - MinusLogProbMetric: 27.3295 - val_loss: 27.6634 - val_MinusLogProbMetric: 27.6634 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 141/1000
2023-09-12 20:12:19.904 
Epoch 141/1000 
	 loss: 27.3251, MinusLogProbMetric: 27.3251, val_loss: 27.6490, val_MinusLogProbMetric: 27.6490

Epoch 141: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3251 - MinusLogProbMetric: 27.3251 - val_loss: 27.6490 - val_MinusLogProbMetric: 27.6490 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 142/1000
2023-09-12 20:12:28.370 
Epoch 142/1000 
	 loss: 27.3261, MinusLogProbMetric: 27.3261, val_loss: 27.6534, val_MinusLogProbMetric: 27.6534

Epoch 142: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3261 - MinusLogProbMetric: 27.3261 - val_loss: 27.6534 - val_MinusLogProbMetric: 27.6534 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 143/1000
2023-09-12 20:12:36.756 
Epoch 143/1000 
	 loss: 27.3263, MinusLogProbMetric: 27.3263, val_loss: 27.6707, val_MinusLogProbMetric: 27.6707

Epoch 143: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3263 - MinusLogProbMetric: 27.3263 - val_loss: 27.6707 - val_MinusLogProbMetric: 27.6707 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 144/1000
2023-09-12 20:12:45.335 
Epoch 144/1000 
	 loss: 27.3219, MinusLogProbMetric: 27.3219, val_loss: 27.6532, val_MinusLogProbMetric: 27.6532

Epoch 144: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3219 - MinusLogProbMetric: 27.3219 - val_loss: 27.6532 - val_MinusLogProbMetric: 27.6532 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 145/1000
2023-09-12 20:12:53.620 
Epoch 145/1000 
	 loss: 27.3180, MinusLogProbMetric: 27.3180, val_loss: 27.7142, val_MinusLogProbMetric: 27.7142

Epoch 145: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3180 - MinusLogProbMetric: 27.3180 - val_loss: 27.7142 - val_MinusLogProbMetric: 27.7142 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 146/1000
2023-09-12 20:13:03.122 
Epoch 146/1000 
	 loss: 27.3179, MinusLogProbMetric: 27.3179, val_loss: 27.6513, val_MinusLogProbMetric: 27.6513

Epoch 146: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3179 - MinusLogProbMetric: 27.3179 - val_loss: 27.6513 - val_MinusLogProbMetric: 27.6513 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 147/1000
2023-09-12 20:13:13.864 
Epoch 147/1000 
	 loss: 27.3148, MinusLogProbMetric: 27.3148, val_loss: 27.6371, val_MinusLogProbMetric: 27.6371

Epoch 147: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.3148 - MinusLogProbMetric: 27.3148 - val_loss: 27.6371 - val_MinusLogProbMetric: 27.6371 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 148/1000
2023-09-12 20:13:23.307 
Epoch 148/1000 
	 loss: 27.3111, MinusLogProbMetric: 27.3111, val_loss: 27.7471, val_MinusLogProbMetric: 27.7471

Epoch 148: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3111 - MinusLogProbMetric: 27.3111 - val_loss: 27.7471 - val_MinusLogProbMetric: 27.7471 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 149/1000
2023-09-12 20:13:32.209 
Epoch 149/1000 
	 loss: 27.3181, MinusLogProbMetric: 27.3181, val_loss: 27.6612, val_MinusLogProbMetric: 27.6612

Epoch 149: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3181 - MinusLogProbMetric: 27.3181 - val_loss: 27.6612 - val_MinusLogProbMetric: 27.6612 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 150/1000
2023-09-12 20:13:41.168 
Epoch 150/1000 
	 loss: 27.3121, MinusLogProbMetric: 27.3121, val_loss: 27.6706, val_MinusLogProbMetric: 27.6706

Epoch 150: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3121 - MinusLogProbMetric: 27.3121 - val_loss: 27.6706 - val_MinusLogProbMetric: 27.6706 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 151/1000
2023-09-12 20:13:49.578 
Epoch 151/1000 
	 loss: 27.3142, MinusLogProbMetric: 27.3142, val_loss: 27.6987, val_MinusLogProbMetric: 27.6987

Epoch 151: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3142 - MinusLogProbMetric: 27.3142 - val_loss: 27.6987 - val_MinusLogProbMetric: 27.6987 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 152/1000
2023-09-12 20:13:57.865 
Epoch 152/1000 
	 loss: 27.3216, MinusLogProbMetric: 27.3216, val_loss: 27.6964, val_MinusLogProbMetric: 27.6964

Epoch 152: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3216 - MinusLogProbMetric: 27.3216 - val_loss: 27.6964 - val_MinusLogProbMetric: 27.6964 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 153/1000
2023-09-12 20:14:06.710 
Epoch 153/1000 
	 loss: 27.3082, MinusLogProbMetric: 27.3082, val_loss: 27.6568, val_MinusLogProbMetric: 27.6568

Epoch 153: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3082 - MinusLogProbMetric: 27.3082 - val_loss: 27.6568 - val_MinusLogProbMetric: 27.6568 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 154/1000
2023-09-12 20:14:17.796 
Epoch 154/1000 
	 loss: 27.3066, MinusLogProbMetric: 27.3066, val_loss: 27.6868, val_MinusLogProbMetric: 27.6868

Epoch 154: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.3066 - MinusLogProbMetric: 27.3066 - val_loss: 27.6868 - val_MinusLogProbMetric: 27.6868 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 155/1000
2023-09-12 20:14:27.448 
Epoch 155/1000 
	 loss: 27.3107, MinusLogProbMetric: 27.3107, val_loss: 27.6755, val_MinusLogProbMetric: 27.6755

Epoch 155: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.3107 - MinusLogProbMetric: 27.3107 - val_loss: 27.6755 - val_MinusLogProbMetric: 27.6755 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 156/1000
2023-09-12 20:14:35.696 
Epoch 156/1000 
	 loss: 27.3112, MinusLogProbMetric: 27.3112, val_loss: 27.6910, val_MinusLogProbMetric: 27.6910

Epoch 156: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3112 - MinusLogProbMetric: 27.3112 - val_loss: 27.6910 - val_MinusLogProbMetric: 27.6910 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 157/1000
2023-09-12 20:14:44.020 
Epoch 157/1000 
	 loss: 27.3057, MinusLogProbMetric: 27.3057, val_loss: 27.6697, val_MinusLogProbMetric: 27.6697

Epoch 157: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3057 - MinusLogProbMetric: 27.3057 - val_loss: 27.6697 - val_MinusLogProbMetric: 27.6697 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 158/1000
2023-09-12 20:14:52.557 
Epoch 158/1000 
	 loss: 27.3101, MinusLogProbMetric: 27.3101, val_loss: 27.6845, val_MinusLogProbMetric: 27.6845

Epoch 158: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3101 - MinusLogProbMetric: 27.3101 - val_loss: 27.6845 - val_MinusLogProbMetric: 27.6845 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 159/1000
2023-09-12 20:15:00.861 
Epoch 159/1000 
	 loss: 27.3095, MinusLogProbMetric: 27.3095, val_loss: 27.6575, val_MinusLogProbMetric: 27.6575

Epoch 159: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3095 - MinusLogProbMetric: 27.3095 - val_loss: 27.6575 - val_MinusLogProbMetric: 27.6575 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 160/1000
2023-09-12 20:15:09.322 
Epoch 160/1000 
	 loss: 27.3042, MinusLogProbMetric: 27.3042, val_loss: 27.6712, val_MinusLogProbMetric: 27.6712

Epoch 160: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3042 - MinusLogProbMetric: 27.3042 - val_loss: 27.6712 - val_MinusLogProbMetric: 27.6712 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 161/1000
2023-09-12 20:15:17.908 
Epoch 161/1000 
	 loss: 27.3053, MinusLogProbMetric: 27.3053, val_loss: 27.7043, val_MinusLogProbMetric: 27.7043

Epoch 161: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.3053 - MinusLogProbMetric: 27.3053 - val_loss: 27.7043 - val_MinusLogProbMetric: 27.7043 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 162/1000
2023-09-12 20:15:26.133 
Epoch 162/1000 
	 loss: 27.3085, MinusLogProbMetric: 27.3085, val_loss: 27.6662, val_MinusLogProbMetric: 27.6662

Epoch 162: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.3085 - MinusLogProbMetric: 27.3085 - val_loss: 27.6662 - val_MinusLogProbMetric: 27.6662 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 163/1000
2023-09-12 20:15:34.769 
Epoch 163/1000 
	 loss: 27.2477, MinusLogProbMetric: 27.2477, val_loss: 27.6336, val_MinusLogProbMetric: 27.6336

Epoch 163: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2477 - MinusLogProbMetric: 27.2477 - val_loss: 27.6336 - val_MinusLogProbMetric: 27.6336 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 164/1000
2023-09-12 20:15:43.227 
Epoch 164/1000 
	 loss: 27.2401, MinusLogProbMetric: 27.2401, val_loss: 27.6533, val_MinusLogProbMetric: 27.6533

Epoch 164: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2401 - MinusLogProbMetric: 27.2401 - val_loss: 27.6533 - val_MinusLogProbMetric: 27.6533 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 165/1000
2023-09-12 20:15:51.602 
Epoch 165/1000 
	 loss: 27.2432, MinusLogProbMetric: 27.2432, val_loss: 27.6507, val_MinusLogProbMetric: 27.6507

Epoch 165: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2432 - MinusLogProbMetric: 27.2432 - val_loss: 27.6507 - val_MinusLogProbMetric: 27.6507 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 166/1000
2023-09-12 20:16:00.028 
Epoch 166/1000 
	 loss: 27.2447, MinusLogProbMetric: 27.2447, val_loss: 27.6402, val_MinusLogProbMetric: 27.6402

Epoch 166: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2447 - MinusLogProbMetric: 27.2447 - val_loss: 27.6402 - val_MinusLogProbMetric: 27.6402 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 167/1000
2023-09-12 20:16:08.663 
Epoch 167/1000 
	 loss: 27.2409, MinusLogProbMetric: 27.2409, val_loss: 27.6332, val_MinusLogProbMetric: 27.6332

Epoch 167: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2409 - MinusLogProbMetric: 27.2409 - val_loss: 27.6332 - val_MinusLogProbMetric: 27.6332 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 168/1000
2023-09-12 20:16:17.037 
Epoch 168/1000 
	 loss: 27.2400, MinusLogProbMetric: 27.2400, val_loss: 27.6575, val_MinusLogProbMetric: 27.6575

Epoch 168: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2400 - MinusLogProbMetric: 27.2400 - val_loss: 27.6575 - val_MinusLogProbMetric: 27.6575 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 169/1000
2023-09-12 20:16:25.414 
Epoch 169/1000 
	 loss: 27.2394, MinusLogProbMetric: 27.2394, val_loss: 27.6199, val_MinusLogProbMetric: 27.6199

Epoch 169: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2394 - MinusLogProbMetric: 27.2394 - val_loss: 27.6199 - val_MinusLogProbMetric: 27.6199 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 170/1000
2023-09-12 20:16:34.603 
Epoch 170/1000 
	 loss: 27.2405, MinusLogProbMetric: 27.2405, val_loss: 27.6366, val_MinusLogProbMetric: 27.6366

Epoch 170: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2405 - MinusLogProbMetric: 27.2405 - val_loss: 27.6366 - val_MinusLogProbMetric: 27.6366 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 171/1000
2023-09-12 20:16:45.259 
Epoch 171/1000 
	 loss: 27.2377, MinusLogProbMetric: 27.2377, val_loss: 27.6475, val_MinusLogProbMetric: 27.6475

Epoch 171: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.2377 - MinusLogProbMetric: 27.2377 - val_loss: 27.6475 - val_MinusLogProbMetric: 27.6475 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 172/1000
2023-09-12 20:16:54.205 
Epoch 172/1000 
	 loss: 27.2385, MinusLogProbMetric: 27.2385, val_loss: 27.6409, val_MinusLogProbMetric: 27.6409

Epoch 172: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2385 - MinusLogProbMetric: 27.2385 - val_loss: 27.6409 - val_MinusLogProbMetric: 27.6409 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 173/1000
2023-09-12 20:17:04.296 
Epoch 173/1000 
	 loss: 27.2356, MinusLogProbMetric: 27.2356, val_loss: 27.6497, val_MinusLogProbMetric: 27.6497

Epoch 173: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.2356 - MinusLogProbMetric: 27.2356 - val_loss: 27.6497 - val_MinusLogProbMetric: 27.6497 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 174/1000
2023-09-12 20:17:12.611 
Epoch 174/1000 
	 loss: 27.2338, MinusLogProbMetric: 27.2338, val_loss: 27.6506, val_MinusLogProbMetric: 27.6506

Epoch 174: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2338 - MinusLogProbMetric: 27.2338 - val_loss: 27.6506 - val_MinusLogProbMetric: 27.6506 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 175/1000
2023-09-12 20:17:21.991 
Epoch 175/1000 
	 loss: 27.2406, MinusLogProbMetric: 27.2406, val_loss: 27.6518, val_MinusLogProbMetric: 27.6518

Epoch 175: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2406 - MinusLogProbMetric: 27.2406 - val_loss: 27.6518 - val_MinusLogProbMetric: 27.6518 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 176/1000
2023-09-12 20:17:30.760 
Epoch 176/1000 
	 loss: 27.2356, MinusLogProbMetric: 27.2356, val_loss: 27.6461, val_MinusLogProbMetric: 27.6461

Epoch 176: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2356 - MinusLogProbMetric: 27.2356 - val_loss: 27.6461 - val_MinusLogProbMetric: 27.6461 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 177/1000
2023-09-12 20:17:39.120 
Epoch 177/1000 
	 loss: 27.2351, MinusLogProbMetric: 27.2351, val_loss: 27.6452, val_MinusLogProbMetric: 27.6452

Epoch 177: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2351 - MinusLogProbMetric: 27.2351 - val_loss: 27.6452 - val_MinusLogProbMetric: 27.6452 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 178/1000
2023-09-12 20:17:47.637 
Epoch 178/1000 
	 loss: 27.2329, MinusLogProbMetric: 27.2329, val_loss: 27.6421, val_MinusLogProbMetric: 27.6421

Epoch 178: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2329 - MinusLogProbMetric: 27.2329 - val_loss: 27.6421 - val_MinusLogProbMetric: 27.6421 - lr: 2.5000e-04 - 9s/epoch - 43ms/step
Epoch 179/1000
2023-09-12 20:17:55.796 
Epoch 179/1000 
	 loss: 27.2335, MinusLogProbMetric: 27.2335, val_loss: 27.6490, val_MinusLogProbMetric: 27.6490

Epoch 179: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2335 - MinusLogProbMetric: 27.2335 - val_loss: 27.6490 - val_MinusLogProbMetric: 27.6490 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 180/1000
2023-09-12 20:18:03.976 
Epoch 180/1000 
	 loss: 27.2324, MinusLogProbMetric: 27.2324, val_loss: 27.6408, val_MinusLogProbMetric: 27.6408

Epoch 180: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2324 - MinusLogProbMetric: 27.2324 - val_loss: 27.6408 - val_MinusLogProbMetric: 27.6408 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 181/1000
2023-09-12 20:18:12.589 
Epoch 181/1000 
	 loss: 27.2321, MinusLogProbMetric: 27.2321, val_loss: 27.6712, val_MinusLogProbMetric: 27.6712

Epoch 181: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2321 - MinusLogProbMetric: 27.2321 - val_loss: 27.6712 - val_MinusLogProbMetric: 27.6712 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 182/1000
2023-09-12 20:18:21.289 
Epoch 182/1000 
	 loss: 27.2311, MinusLogProbMetric: 27.2311, val_loss: 27.6372, val_MinusLogProbMetric: 27.6372

Epoch 182: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2311 - MinusLogProbMetric: 27.2311 - val_loss: 27.6372 - val_MinusLogProbMetric: 27.6372 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 183/1000
2023-09-12 20:18:29.604 
Epoch 183/1000 
	 loss: 27.2336, MinusLogProbMetric: 27.2336, val_loss: 27.6634, val_MinusLogProbMetric: 27.6634

Epoch 183: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2336 - MinusLogProbMetric: 27.2336 - val_loss: 27.6634 - val_MinusLogProbMetric: 27.6634 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 184/1000
2023-09-12 20:18:37.631 
Epoch 184/1000 
	 loss: 27.2339, MinusLogProbMetric: 27.2339, val_loss: 27.6432, val_MinusLogProbMetric: 27.6432

Epoch 184: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2339 - MinusLogProbMetric: 27.2339 - val_loss: 27.6432 - val_MinusLogProbMetric: 27.6432 - lr: 2.5000e-04 - 8s/epoch - 41ms/step
Epoch 185/1000
2023-09-12 20:18:46.780 
Epoch 185/1000 
	 loss: 27.2284, MinusLogProbMetric: 27.2284, val_loss: 27.6452, val_MinusLogProbMetric: 27.6452

Epoch 185: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2284 - MinusLogProbMetric: 27.2284 - val_loss: 27.6452 - val_MinusLogProbMetric: 27.6452 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 186/1000
2023-09-12 20:18:57.297 
Epoch 186/1000 
	 loss: 27.2282, MinusLogProbMetric: 27.2282, val_loss: 27.6528, val_MinusLogProbMetric: 27.6528

Epoch 186: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.2282 - MinusLogProbMetric: 27.2282 - val_loss: 27.6528 - val_MinusLogProbMetric: 27.6528 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 187/1000
2023-09-12 20:19:07.132 
Epoch 187/1000 
	 loss: 27.2321, MinusLogProbMetric: 27.2321, val_loss: 27.6714, val_MinusLogProbMetric: 27.6714

Epoch 187: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.2321 - MinusLogProbMetric: 27.2321 - val_loss: 27.6714 - val_MinusLogProbMetric: 27.6714 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 188/1000
2023-09-12 20:19:15.529 
Epoch 188/1000 
	 loss: 27.2258, MinusLogProbMetric: 27.2258, val_loss: 27.6560, val_MinusLogProbMetric: 27.6560

Epoch 188: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2258 - MinusLogProbMetric: 27.2258 - val_loss: 27.6560 - val_MinusLogProbMetric: 27.6560 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 189/1000
2023-09-12 20:19:23.779 
Epoch 189/1000 
	 loss: 27.2240, MinusLogProbMetric: 27.2240, val_loss: 27.6465, val_MinusLogProbMetric: 27.6465

Epoch 189: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2240 - MinusLogProbMetric: 27.2240 - val_loss: 27.6465 - val_MinusLogProbMetric: 27.6465 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 190/1000
2023-09-12 20:19:32.630 
Epoch 190/1000 
	 loss: 27.2265, MinusLogProbMetric: 27.2265, val_loss: 27.6669, val_MinusLogProbMetric: 27.6669

Epoch 190: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2265 - MinusLogProbMetric: 27.2265 - val_loss: 27.6669 - val_MinusLogProbMetric: 27.6669 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 191/1000
2023-09-12 20:19:43.339 
Epoch 191/1000 
	 loss: 27.2273, MinusLogProbMetric: 27.2273, val_loss: 27.6770, val_MinusLogProbMetric: 27.6770

Epoch 191: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.2273 - MinusLogProbMetric: 27.2273 - val_loss: 27.6770 - val_MinusLogProbMetric: 27.6770 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 192/1000
2023-09-12 20:19:51.695 
Epoch 192/1000 
	 loss: 27.2227, MinusLogProbMetric: 27.2227, val_loss: 27.6727, val_MinusLogProbMetric: 27.6727

Epoch 192: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2227 - MinusLogProbMetric: 27.2227 - val_loss: 27.6727 - val_MinusLogProbMetric: 27.6727 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 193/1000
2023-09-12 20:20:00.109 
Epoch 193/1000 
	 loss: 27.2259, MinusLogProbMetric: 27.2259, val_loss: 27.6649, val_MinusLogProbMetric: 27.6649

Epoch 193: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2259 - MinusLogProbMetric: 27.2259 - val_loss: 27.6649 - val_MinusLogProbMetric: 27.6649 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 194/1000
2023-09-12 20:20:08.425 
Epoch 194/1000 
	 loss: 27.2255, MinusLogProbMetric: 27.2255, val_loss: 27.6532, val_MinusLogProbMetric: 27.6532

Epoch 194: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2255 - MinusLogProbMetric: 27.2255 - val_loss: 27.6532 - val_MinusLogProbMetric: 27.6532 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 195/1000
2023-09-12 20:20:17.109 
Epoch 195/1000 
	 loss: 27.2252, MinusLogProbMetric: 27.2252, val_loss: 27.6614, val_MinusLogProbMetric: 27.6614

Epoch 195: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2252 - MinusLogProbMetric: 27.2252 - val_loss: 27.6614 - val_MinusLogProbMetric: 27.6614 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 196/1000
2023-09-12 20:20:26.377 
Epoch 196/1000 
	 loss: 27.2240, MinusLogProbMetric: 27.2240, val_loss: 27.6511, val_MinusLogProbMetric: 27.6511

Epoch 196: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2240 - MinusLogProbMetric: 27.2240 - val_loss: 27.6511 - val_MinusLogProbMetric: 27.6511 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 197/1000
2023-09-12 20:20:36.141 
Epoch 197/1000 
	 loss: 27.2204, MinusLogProbMetric: 27.2204, val_loss: 27.6657, val_MinusLogProbMetric: 27.6657

Epoch 197: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.2204 - MinusLogProbMetric: 27.2204 - val_loss: 27.6657 - val_MinusLogProbMetric: 27.6657 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 198/1000
2023-09-12 20:20:44.437 
Epoch 198/1000 
	 loss: 27.2178, MinusLogProbMetric: 27.2178, val_loss: 27.6848, val_MinusLogProbMetric: 27.6848

Epoch 198: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2178 - MinusLogProbMetric: 27.2178 - val_loss: 27.6848 - val_MinusLogProbMetric: 27.6848 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 199/1000
2023-09-12 20:20:52.715 
Epoch 199/1000 
	 loss: 27.2204, MinusLogProbMetric: 27.2204, val_loss: 27.6693, val_MinusLogProbMetric: 27.6693

Epoch 199: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2204 - MinusLogProbMetric: 27.2204 - val_loss: 27.6693 - val_MinusLogProbMetric: 27.6693 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 200/1000
2023-09-12 20:21:01.953 
Epoch 200/1000 
	 loss: 27.2180, MinusLogProbMetric: 27.2180, val_loss: 27.6693, val_MinusLogProbMetric: 27.6693

Epoch 200: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2180 - MinusLogProbMetric: 27.2180 - val_loss: 27.6693 - val_MinusLogProbMetric: 27.6693 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 201/1000
2023-09-12 20:21:11.840 
Epoch 201/1000 
	 loss: 27.2164, MinusLogProbMetric: 27.2164, val_loss: 27.6676, val_MinusLogProbMetric: 27.6676

Epoch 201: val_loss did not improve from 27.60327
196/196 - 10s - loss: 27.2164 - MinusLogProbMetric: 27.2164 - val_loss: 27.6676 - val_MinusLogProbMetric: 27.6676 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 202/1000
2023-09-12 20:21:21.287 
Epoch 202/1000 
	 loss: 27.2179, MinusLogProbMetric: 27.2179, val_loss: 27.6725, val_MinusLogProbMetric: 27.6725

Epoch 202: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2179 - MinusLogProbMetric: 27.2179 - val_loss: 27.6725 - val_MinusLogProbMetric: 27.6725 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 203/1000
2023-09-12 20:21:30.167 
Epoch 203/1000 
	 loss: 27.2198, MinusLogProbMetric: 27.2198, val_loss: 27.6610, val_MinusLogProbMetric: 27.6610

Epoch 203: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2198 - MinusLogProbMetric: 27.2198 - val_loss: 27.6610 - val_MinusLogProbMetric: 27.6610 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 204/1000
2023-09-12 20:21:39.494 
Epoch 204/1000 
	 loss: 27.2187, MinusLogProbMetric: 27.2187, val_loss: 27.6658, val_MinusLogProbMetric: 27.6658

Epoch 204: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2187 - MinusLogProbMetric: 27.2187 - val_loss: 27.6658 - val_MinusLogProbMetric: 27.6658 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 205/1000
2023-09-12 20:21:48.210 
Epoch 205/1000 
	 loss: 27.2155, MinusLogProbMetric: 27.2155, val_loss: 27.6579, val_MinusLogProbMetric: 27.6579

Epoch 205: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2155 - MinusLogProbMetric: 27.2155 - val_loss: 27.6579 - val_MinusLogProbMetric: 27.6579 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 206/1000
2023-09-12 20:21:57.170 
Epoch 206/1000 
	 loss: 27.2170, MinusLogProbMetric: 27.2170, val_loss: 27.6889, val_MinusLogProbMetric: 27.6889

Epoch 206: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2170 - MinusLogProbMetric: 27.2170 - val_loss: 27.6889 - val_MinusLogProbMetric: 27.6889 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 207/1000
2023-09-12 20:22:07.761 
Epoch 207/1000 
	 loss: 27.2146, MinusLogProbMetric: 27.2146, val_loss: 27.6738, val_MinusLogProbMetric: 27.6738

Epoch 207: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.2146 - MinusLogProbMetric: 27.2146 - val_loss: 27.6738 - val_MinusLogProbMetric: 27.6738 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 208/1000
2023-09-12 20:22:18.583 
Epoch 208/1000 
	 loss: 27.2128, MinusLogProbMetric: 27.2128, val_loss: 27.6702, val_MinusLogProbMetric: 27.6702

Epoch 208: val_loss did not improve from 27.60327
196/196 - 11s - loss: 27.2128 - MinusLogProbMetric: 27.2128 - val_loss: 27.6702 - val_MinusLogProbMetric: 27.6702 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 209/1000
2023-09-12 20:22:28.063 
Epoch 209/1000 
	 loss: 27.2153, MinusLogProbMetric: 27.2153, val_loss: 27.6607, val_MinusLogProbMetric: 27.6607

Epoch 209: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2153 - MinusLogProbMetric: 27.2153 - val_loss: 27.6607 - val_MinusLogProbMetric: 27.6607 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 210/1000
2023-09-12 20:22:36.643 
Epoch 210/1000 
	 loss: 27.2118, MinusLogProbMetric: 27.2118, val_loss: 27.6758, val_MinusLogProbMetric: 27.6758

Epoch 210: val_loss did not improve from 27.60327
196/196 - 9s - loss: 27.2118 - MinusLogProbMetric: 27.2118 - val_loss: 27.6758 - val_MinusLogProbMetric: 27.6758 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 211/1000
2023-09-12 20:22:45.023 
Epoch 211/1000 
	 loss: 27.2131, MinusLogProbMetric: 27.2131, val_loss: 27.6659, val_MinusLogProbMetric: 27.6659

Epoch 211: val_loss did not improve from 27.60327
196/196 - 8s - loss: 27.2131 - MinusLogProbMetric: 27.2131 - val_loss: 27.6659 - val_MinusLogProbMetric: 27.6659 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 212/1000
2023-09-12 20:22:53.596 
Epoch 212/1000 
	 loss: 27.2135, MinusLogProbMetric: 27.2135, val_loss: 27.6676, val_MinusLogProbMetric: 27.6676

Epoch 212: val_loss did not improve from 27.60327
Restoring model weights from the end of the best epoch: 112.
196/196 - 9s - loss: 27.2135 - MinusLogProbMetric: 27.2135 - val_loss: 27.6676 - val_MinusLogProbMetric: 27.6676 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 212: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 9.059982889913954 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.15024699899368 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.4767976100556552 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.1647999950218946 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 440.
Model trained in 2146.29 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 976 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Metrics computed in 4963.79 s.
Plots done in 60.74 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 5024.53 s.
===========
Run 174/360 done in 7171.71 s.
===========

Directory ../../results/MsplineN_new/run_175/ already exists.
Skipping it.
===========
Run 175/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_176/ already exists.
Skipping it.
===========
Run 176/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_177/ already exists.
Skipping it.
===========
Run 177/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_178/ already exists.
Skipping it.
===========
Run 178/360 already exists. Skipping it.
===========

===========
Generating train data for run 179.
===========
Train data generated in 0.13 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_179/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_179/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.4659383 ,  4.1334686 ,  8.6866865 , ...,  6.8463674 ,
         0.36138976,  1.4300231 ],
       [ 6.484008  ,  3.007975  ,  6.2337604 , ...,  3.739787  ,
         1.4793756 ,  3.0040233 ],
       [ 2.264184  ,  3.3112721 ,  8.797337  , ...,  5.9933467 ,
         0.6142512 ,  3.1057003 ],
       ...,
       [ 5.4343762 ,  7.4912486 ,  6.4172325 , ...,  0.04709697,
         4.887264  ,  1.4711498 ],
       [ 1.6543716 ,  3.8658652 ,  8.345405  , ...,  6.200018  ,
        -1.0324802 ,  3.065315  ],
       [ 6.127924  ,  2.7694616 ,  6.280568  , ...,  3.5089302 ,
         5.2330275 ,  2.417325  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_179/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_179
self.data_kwargs: {'seed': 520}
self.x_data: [[2.1731846  3.8937397  6.9821544  ... 5.669328   0.68163395 3.5624375 ]
 [6.7535415  2.6749182  6.1859965  ... 3.3760262  4.638645   2.336814  ]
 [6.1686287  2.7568936  6.2012696  ... 2.5904071  3.339636   2.9827425 ]
 ...
 [6.6194353  2.9398146  6.1845684  ... 3.0365293  3.5444417  1.3393478 ]
 [5.613061   6.348512   5.164087   ... 1.829057   7.7712007  1.4071141 ]
 [6.893006   3.0565336  6.057088   ... 2.613742   4.4370584  2.0332472 ]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_73 (InputLayer)       [(None, 64)]              0         
                                                                 
 log_prob_layer_24 (LogProbL  (None,)                  660608    
 ayer)                                                           
                                                                 
=================================================================
Total params: 660,608
Trainable params: 660,608
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_24/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_24'")
self.model: <keras.engine.functional.Functional object at 0x7fc3ba99f8b0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc621395e70>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc621395e70>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc621396740>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc6213971f0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc621397760>, <keras.callbacks.ModelCheckpoint object at 0x7fc621397820>, <keras.callbacks.EarlyStopping object at 0x7fc621397a90>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc621397ac0>, <keras.callbacks.TerminateOnNaN object at 0x7fc621397700>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 2.4659383 ,  4.1334686 ,  8.6866865 , ...,  6.8463674 ,
         0.36138976,  1.4300231 ],
       [ 6.484008  ,  3.007975  ,  6.2337604 , ...,  3.739787  ,
         1.4793756 ,  3.0040233 ],
       [ 2.264184  ,  3.3112721 ,  8.797337  , ...,  5.9933467 ,
         0.6142512 ,  3.1057003 ],
       ...,
       [ 5.4343762 ,  7.4912486 ,  6.4172325 , ...,  0.04709697,
         4.887264  ,  1.4711498 ],
       [ 1.6543716 ,  3.8658652 ,  8.345405  , ...,  6.200018  ,
        -1.0324802 ,  3.065315  ],
       [ 6.127924  ,  2.7694616 ,  6.280568  , ...,  3.5089302 ,
         5.2330275 ,  2.417325  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_179/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 179/360 with hyperparameters:
timestamp = 2023-09-12 21:46:39.095269
ndims = 64
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 128-128-128
trainable_parameters = 660608
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 2.1731846   3.8937397   6.9821544   1.4459838   8.670284    0.996012
  9.747296    5.3488703  10.829596    5.798153    7.4385934  -0.39963475
  2.887594    1.6816981   1.9483483   2.4950166   3.377345    6.4428034
  0.7434967  10.024268    5.9064217   3.9731474   5.977063    2.0677786
  5.421294    7.7411385   2.3877835   6.667169    1.0165741   6.879494
  2.333092    1.6771841   5.2052946  -0.01726444  8.224516   -0.06788193
  7.1896877   2.6926644   7.7422037   9.618431    2.508284    5.3540187
  8.24927     4.96435     2.6443048   8.933116    4.0272393   8.583376
  6.9591885   2.9305875   8.131322    3.9143033   8.096406    5.8134246
  9.931866    7.011071    7.2540216   5.1431737  10.5702715   6.340821
  4.2660613   5.669328    0.68163395  3.5624375 ]
Epoch 1/1000
2023-09-12 21:47:06.850 
Epoch 1/1000 
	 loss: 105.2441, MinusLogProbMetric: 105.2441, val_loss: 36.2627, val_MinusLogProbMetric: 36.2627

Epoch 1: val_loss improved from inf to 36.26275, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 28s - loss: 105.2441 - MinusLogProbMetric: 105.2441 - val_loss: 36.2627 - val_MinusLogProbMetric: 36.2627 - lr: 0.0010 - 28s/epoch - 142ms/step
Epoch 2/1000
2023-09-12 21:47:16.022 
Epoch 2/1000 
	 loss: 32.2199, MinusLogProbMetric: 32.2199, val_loss: 31.1649, val_MinusLogProbMetric: 31.1649

Epoch 2: val_loss improved from 36.26275 to 31.16490, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 32.2199 - MinusLogProbMetric: 32.2199 - val_loss: 31.1649 - val_MinusLogProbMetric: 31.1649 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 3/1000
2023-09-12 21:47:26.647 
Epoch 3/1000 
	 loss: 30.1974, MinusLogProbMetric: 30.1974, val_loss: 29.6561, val_MinusLogProbMetric: 29.6561

Epoch 3: val_loss improved from 31.16490 to 29.65607, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 30.1974 - MinusLogProbMetric: 30.1974 - val_loss: 29.6561 - val_MinusLogProbMetric: 29.6561 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 4/1000
2023-09-12 21:47:38.158 
Epoch 4/1000 
	 loss: 29.4689, MinusLogProbMetric: 29.4689, val_loss: 29.4868, val_MinusLogProbMetric: 29.4868

Epoch 4: val_loss improved from 29.65607 to 29.48683, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 29.4689 - MinusLogProbMetric: 29.4689 - val_loss: 29.4868 - val_MinusLogProbMetric: 29.4868 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 5/1000
2023-09-12 21:47:49.153 
Epoch 5/1000 
	 loss: 29.1418, MinusLogProbMetric: 29.1418, val_loss: 29.2193, val_MinusLogProbMetric: 29.2193

Epoch 5: val_loss improved from 29.48683 to 29.21928, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 29.1418 - MinusLogProbMetric: 29.1418 - val_loss: 29.2193 - val_MinusLogProbMetric: 29.2193 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 6/1000
2023-09-12 21:47:58.778 
Epoch 6/1000 
	 loss: 28.8610, MinusLogProbMetric: 28.8610, val_loss: 28.7963, val_MinusLogProbMetric: 28.7963

Epoch 6: val_loss improved from 29.21928 to 28.79632, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 28.8610 - MinusLogProbMetric: 28.8610 - val_loss: 28.7963 - val_MinusLogProbMetric: 28.7963 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 7/1000
2023-09-12 21:48:10.019 
Epoch 7/1000 
	 loss: 28.6878, MinusLogProbMetric: 28.6878, val_loss: 28.4561, val_MinusLogProbMetric: 28.4561

Epoch 7: val_loss improved from 28.79632 to 28.45605, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 28.6878 - MinusLogProbMetric: 28.6878 - val_loss: 28.4561 - val_MinusLogProbMetric: 28.4561 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 8/1000
2023-09-12 21:48:21.149 
Epoch 8/1000 
	 loss: 28.5754, MinusLogProbMetric: 28.5754, val_loss: 28.6720, val_MinusLogProbMetric: 28.6720

Epoch 8: val_loss did not improve from 28.45605
196/196 - 11s - loss: 28.5754 - MinusLogProbMetric: 28.5754 - val_loss: 28.6720 - val_MinusLogProbMetric: 28.6720 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 9/1000
2023-09-12 21:48:30.298 
Epoch 9/1000 
	 loss: 28.4223, MinusLogProbMetric: 28.4223, val_loss: 28.4240, val_MinusLogProbMetric: 28.4240

Epoch 9: val_loss improved from 28.45605 to 28.42403, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 28.4223 - MinusLogProbMetric: 28.4223 - val_loss: 28.4240 - val_MinusLogProbMetric: 28.4240 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 10/1000
2023-09-12 21:48:38.958 
Epoch 10/1000 
	 loss: 28.3499, MinusLogProbMetric: 28.3499, val_loss: 28.3838, val_MinusLogProbMetric: 28.3838

Epoch 10: val_loss improved from 28.42403 to 28.38375, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 28.3499 - MinusLogProbMetric: 28.3499 - val_loss: 28.3838 - val_MinusLogProbMetric: 28.3838 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 11/1000
2023-09-12 21:48:49.687 
Epoch 11/1000 
	 loss: 28.2754, MinusLogProbMetric: 28.2754, val_loss: 28.6040, val_MinusLogProbMetric: 28.6040

Epoch 11: val_loss did not improve from 28.38375
196/196 - 11s - loss: 28.2754 - MinusLogProbMetric: 28.2754 - val_loss: 28.6040 - val_MinusLogProbMetric: 28.6040 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 12/1000
2023-09-12 21:49:00.635 
Epoch 12/1000 
	 loss: 28.2232, MinusLogProbMetric: 28.2232, val_loss: 28.1194, val_MinusLogProbMetric: 28.1194

Epoch 12: val_loss improved from 28.38375 to 28.11945, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 28.2232 - MinusLogProbMetric: 28.2232 - val_loss: 28.1194 - val_MinusLogProbMetric: 28.1194 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 13/1000
2023-09-12 21:49:11.027 
Epoch 13/1000 
	 loss: 28.1692, MinusLogProbMetric: 28.1692, val_loss: 28.2120, val_MinusLogProbMetric: 28.2120

Epoch 13: val_loss did not improve from 28.11945
196/196 - 10s - loss: 28.1692 - MinusLogProbMetric: 28.1692 - val_loss: 28.2120 - val_MinusLogProbMetric: 28.2120 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 14/1000
2023-09-12 21:49:20.204 
Epoch 14/1000 
	 loss: 28.0982, MinusLogProbMetric: 28.0982, val_loss: 28.2384, val_MinusLogProbMetric: 28.2384

Epoch 14: val_loss did not improve from 28.11945
196/196 - 9s - loss: 28.0982 - MinusLogProbMetric: 28.0982 - val_loss: 28.2384 - val_MinusLogProbMetric: 28.2384 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 15/1000
2023-09-12 21:49:30.540 
Epoch 15/1000 
	 loss: 28.0417, MinusLogProbMetric: 28.0417, val_loss: 28.1787, val_MinusLogProbMetric: 28.1787

Epoch 15: val_loss did not improve from 28.11945
196/196 - 10s - loss: 28.0417 - MinusLogProbMetric: 28.0417 - val_loss: 28.1787 - val_MinusLogProbMetric: 28.1787 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 16/1000
2023-09-12 21:49:39.786 
Epoch 16/1000 
	 loss: 28.0601, MinusLogProbMetric: 28.0601, val_loss: 28.4761, val_MinusLogProbMetric: 28.4761

Epoch 16: val_loss did not improve from 28.11945
196/196 - 9s - loss: 28.0601 - MinusLogProbMetric: 28.0601 - val_loss: 28.4761 - val_MinusLogProbMetric: 28.4761 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 17/1000
2023-09-12 21:49:51.007 
Epoch 17/1000 
	 loss: 28.0377, MinusLogProbMetric: 28.0377, val_loss: 28.0227, val_MinusLogProbMetric: 28.0227

Epoch 17: val_loss improved from 28.11945 to 28.02270, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 28.0377 - MinusLogProbMetric: 28.0377 - val_loss: 28.0227 - val_MinusLogProbMetric: 28.0227 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 18/1000
2023-09-12 21:50:00.537 
Epoch 18/1000 
	 loss: 27.9587, MinusLogProbMetric: 27.9587, val_loss: 28.2337, val_MinusLogProbMetric: 28.2337

Epoch 18: val_loss did not improve from 28.02270
196/196 - 9s - loss: 27.9587 - MinusLogProbMetric: 27.9587 - val_loss: 28.2337 - val_MinusLogProbMetric: 28.2337 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 19/1000
2023-09-12 21:50:08.790 
Epoch 19/1000 
	 loss: 27.9610, MinusLogProbMetric: 27.9610, val_loss: 28.1460, val_MinusLogProbMetric: 28.1460

Epoch 19: val_loss did not improve from 28.02270
196/196 - 8s - loss: 27.9610 - MinusLogProbMetric: 27.9610 - val_loss: 28.1460 - val_MinusLogProbMetric: 28.1460 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 20/1000
2023-09-12 21:50:19.415 
Epoch 20/1000 
	 loss: 27.9260, MinusLogProbMetric: 27.9260, val_loss: 28.1919, val_MinusLogProbMetric: 28.1919

Epoch 20: val_loss did not improve from 28.02270
196/196 - 11s - loss: 27.9260 - MinusLogProbMetric: 27.9260 - val_loss: 28.1919 - val_MinusLogProbMetric: 28.1919 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 21/1000
2023-09-12 21:50:30.497 
Epoch 21/1000 
	 loss: 27.9322, MinusLogProbMetric: 27.9322, val_loss: 28.0417, val_MinusLogProbMetric: 28.0417

Epoch 21: val_loss did not improve from 28.02270
196/196 - 11s - loss: 27.9322 - MinusLogProbMetric: 27.9322 - val_loss: 28.0417 - val_MinusLogProbMetric: 28.0417 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 22/1000
2023-09-12 21:50:40.256 
Epoch 22/1000 
	 loss: 27.8834, MinusLogProbMetric: 27.8834, val_loss: 27.9714, val_MinusLogProbMetric: 27.9714

Epoch 22: val_loss improved from 28.02270 to 27.97145, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 27.8834 - MinusLogProbMetric: 27.8834 - val_loss: 27.9714 - val_MinusLogProbMetric: 27.9714 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 23/1000
2023-09-12 21:50:50.735 
Epoch 23/1000 
	 loss: 27.8809, MinusLogProbMetric: 27.8809, val_loss: 27.9858, val_MinusLogProbMetric: 27.9858

Epoch 23: val_loss did not improve from 27.97145
196/196 - 10s - loss: 27.8809 - MinusLogProbMetric: 27.8809 - val_loss: 27.9858 - val_MinusLogProbMetric: 27.9858 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 24/1000
2023-09-12 21:51:01.613 
Epoch 24/1000 
	 loss: 27.8469, MinusLogProbMetric: 27.8469, val_loss: 27.9950, val_MinusLogProbMetric: 27.9950

Epoch 24: val_loss did not improve from 27.97145
196/196 - 11s - loss: 27.8469 - MinusLogProbMetric: 27.8469 - val_loss: 27.9950 - val_MinusLogProbMetric: 27.9950 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 25/1000
2023-09-12 21:51:13.157 
Epoch 25/1000 
	 loss: 27.8682, MinusLogProbMetric: 27.8682, val_loss: 27.9739, val_MinusLogProbMetric: 27.9739

Epoch 25: val_loss did not improve from 27.97145
196/196 - 12s - loss: 27.8682 - MinusLogProbMetric: 27.8682 - val_loss: 27.9739 - val_MinusLogProbMetric: 27.9739 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 26/1000
2023-09-12 21:51:24.858 
Epoch 26/1000 
	 loss: 27.8367, MinusLogProbMetric: 27.8367, val_loss: 27.8687, val_MinusLogProbMetric: 27.8687

Epoch 26: val_loss improved from 27.97145 to 27.86870, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 12s - loss: 27.8367 - MinusLogProbMetric: 27.8367 - val_loss: 27.8687 - val_MinusLogProbMetric: 27.8687 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-12 21:51:36.430 
Epoch 27/1000 
	 loss: 27.7948, MinusLogProbMetric: 27.7948, val_loss: 28.0180, val_MinusLogProbMetric: 28.0180

Epoch 27: val_loss did not improve from 27.86870
196/196 - 11s - loss: 27.7948 - MinusLogProbMetric: 27.7948 - val_loss: 28.0180 - val_MinusLogProbMetric: 28.0180 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 28/1000
2023-09-12 21:51:47.890 
Epoch 28/1000 
	 loss: 27.8187, MinusLogProbMetric: 27.8187, val_loss: 27.9506, val_MinusLogProbMetric: 27.9506

Epoch 28: val_loss did not improve from 27.86870
196/196 - 11s - loss: 27.8187 - MinusLogProbMetric: 27.8187 - val_loss: 27.9506 - val_MinusLogProbMetric: 27.9506 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 29/1000
2023-09-12 21:51:58.531 
Epoch 29/1000 
	 loss: 27.8038, MinusLogProbMetric: 27.8038, val_loss: 27.9154, val_MinusLogProbMetric: 27.9154

Epoch 29: val_loss did not improve from 27.86870
196/196 - 11s - loss: 27.8038 - MinusLogProbMetric: 27.8038 - val_loss: 27.9154 - val_MinusLogProbMetric: 27.9154 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 30/1000
2023-09-12 21:52:08.734 
Epoch 30/1000 
	 loss: 27.7919, MinusLogProbMetric: 27.7919, val_loss: 27.9587, val_MinusLogProbMetric: 27.9587

Epoch 30: val_loss did not improve from 27.86870
196/196 - 10s - loss: 27.7919 - MinusLogProbMetric: 27.7919 - val_loss: 27.9587 - val_MinusLogProbMetric: 27.9587 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 31/1000
2023-09-12 21:52:20.769 
Epoch 31/1000 
	 loss: 27.7675, MinusLogProbMetric: 27.7675, val_loss: 27.9480, val_MinusLogProbMetric: 27.9480

Epoch 31: val_loss did not improve from 27.86870
196/196 - 12s - loss: 27.7675 - MinusLogProbMetric: 27.7675 - val_loss: 27.9480 - val_MinusLogProbMetric: 27.9480 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 32/1000
2023-09-12 21:52:31.004 
Epoch 32/1000 
	 loss: 27.7920, MinusLogProbMetric: 27.7920, val_loss: 27.9078, val_MinusLogProbMetric: 27.9078

Epoch 32: val_loss did not improve from 27.86870
196/196 - 10s - loss: 27.7920 - MinusLogProbMetric: 27.7920 - val_loss: 27.9078 - val_MinusLogProbMetric: 27.9078 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 33/1000
2023-09-12 21:52:41.109 
Epoch 33/1000 
	 loss: 27.7642, MinusLogProbMetric: 27.7642, val_loss: 27.9368, val_MinusLogProbMetric: 27.9368

Epoch 33: val_loss did not improve from 27.86870
196/196 - 10s - loss: 27.7642 - MinusLogProbMetric: 27.7642 - val_loss: 27.9368 - val_MinusLogProbMetric: 27.9368 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 34/1000
2023-09-12 21:52:52.593 
Epoch 34/1000 
	 loss: 27.7478, MinusLogProbMetric: 27.7478, val_loss: 27.8565, val_MinusLogProbMetric: 27.8565

Epoch 34: val_loss improved from 27.86870 to 27.85648, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 12s - loss: 27.7478 - MinusLogProbMetric: 27.7478 - val_loss: 27.8565 - val_MinusLogProbMetric: 27.8565 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 35/1000
2023-09-12 21:53:04.736 
Epoch 35/1000 
	 loss: 27.7542, MinusLogProbMetric: 27.7542, val_loss: 27.9053, val_MinusLogProbMetric: 27.9053

Epoch 35: val_loss did not improve from 27.85648
196/196 - 12s - loss: 27.7542 - MinusLogProbMetric: 27.7542 - val_loss: 27.9053 - val_MinusLogProbMetric: 27.9053 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 36/1000
2023-09-12 21:53:16.796 
Epoch 36/1000 
	 loss: 27.7112, MinusLogProbMetric: 27.7112, val_loss: 27.8156, val_MinusLogProbMetric: 27.8156

Epoch 36: val_loss improved from 27.85648 to 27.81557, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 12s - loss: 27.7112 - MinusLogProbMetric: 27.7112 - val_loss: 27.8156 - val_MinusLogProbMetric: 27.8156 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 37/1000
2023-09-12 21:53:28.795 
Epoch 37/1000 
	 loss: 27.7288, MinusLogProbMetric: 27.7288, val_loss: 27.8553, val_MinusLogProbMetric: 27.8553

Epoch 37: val_loss did not improve from 27.81557
196/196 - 12s - loss: 27.7288 - MinusLogProbMetric: 27.7288 - val_loss: 27.8553 - val_MinusLogProbMetric: 27.8553 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 38/1000
2023-09-12 21:53:40.639 
Epoch 38/1000 
	 loss: 27.7431, MinusLogProbMetric: 27.7431, val_loss: 27.8967, val_MinusLogProbMetric: 27.8967

Epoch 38: val_loss did not improve from 27.81557
196/196 - 12s - loss: 27.7431 - MinusLogProbMetric: 27.7431 - val_loss: 27.8967 - val_MinusLogProbMetric: 27.8967 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-12 21:53:52.860 
Epoch 39/1000 
	 loss: 27.7330, MinusLogProbMetric: 27.7330, val_loss: 27.7736, val_MinusLogProbMetric: 27.7736

Epoch 39: val_loss improved from 27.81557 to 27.77361, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 12s - loss: 27.7330 - MinusLogProbMetric: 27.7330 - val_loss: 27.7736 - val_MinusLogProbMetric: 27.7736 - lr: 0.0010 - 12s/epoch - 63ms/step
Epoch 40/1000
2023-09-12 21:54:05.401 
Epoch 40/1000 
	 loss: 27.7025, MinusLogProbMetric: 27.7025, val_loss: 27.7071, val_MinusLogProbMetric: 27.7071

Epoch 40: val_loss improved from 27.77361 to 27.70710, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 13s - loss: 27.7025 - MinusLogProbMetric: 27.7025 - val_loss: 27.7071 - val_MinusLogProbMetric: 27.7071 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 41/1000
2023-09-12 21:54:17.881 
Epoch 41/1000 
	 loss: 27.7346, MinusLogProbMetric: 27.7346, val_loss: 27.8017, val_MinusLogProbMetric: 27.8017

Epoch 41: val_loss did not improve from 27.70710
196/196 - 12s - loss: 27.7346 - MinusLogProbMetric: 27.7346 - val_loss: 27.8017 - val_MinusLogProbMetric: 27.8017 - lr: 0.0010 - 12s/epoch - 63ms/step
Epoch 42/1000
2023-09-12 21:54:30.464 
Epoch 42/1000 
	 loss: 27.7102, MinusLogProbMetric: 27.7102, val_loss: 27.8239, val_MinusLogProbMetric: 27.8239

Epoch 42: val_loss did not improve from 27.70710
196/196 - 13s - loss: 27.7102 - MinusLogProbMetric: 27.7102 - val_loss: 27.8239 - val_MinusLogProbMetric: 27.8239 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 43/1000
2023-09-12 21:54:42.709 
Epoch 43/1000 
	 loss: 27.7007, MinusLogProbMetric: 27.7007, val_loss: 27.8792, val_MinusLogProbMetric: 27.8792

Epoch 43: val_loss did not improve from 27.70710
196/196 - 12s - loss: 27.7007 - MinusLogProbMetric: 27.7007 - val_loss: 27.8792 - val_MinusLogProbMetric: 27.8792 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 44/1000
2023-09-12 21:54:54.931 
Epoch 44/1000 
	 loss: 27.7050, MinusLogProbMetric: 27.7050, val_loss: 27.8839, val_MinusLogProbMetric: 27.8839

Epoch 44: val_loss did not improve from 27.70710
196/196 - 12s - loss: 27.7050 - MinusLogProbMetric: 27.7050 - val_loss: 27.8839 - val_MinusLogProbMetric: 27.8839 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 45/1000
2023-09-12 21:55:06.304 
Epoch 45/1000 
	 loss: 27.6792, MinusLogProbMetric: 27.6792, val_loss: 27.8177, val_MinusLogProbMetric: 27.8177

Epoch 45: val_loss did not improve from 27.70710
196/196 - 11s - loss: 27.6792 - MinusLogProbMetric: 27.6792 - val_loss: 27.8177 - val_MinusLogProbMetric: 27.8177 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 46/1000
2023-09-12 21:55:17.879 
Epoch 46/1000 
	 loss: 27.6923, MinusLogProbMetric: 27.6923, val_loss: 27.7719, val_MinusLogProbMetric: 27.7719

Epoch 46: val_loss did not improve from 27.70710
196/196 - 12s - loss: 27.6923 - MinusLogProbMetric: 27.6923 - val_loss: 27.7719 - val_MinusLogProbMetric: 27.7719 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 47/1000
2023-09-12 21:55:29.019 
Epoch 47/1000 
	 loss: 27.6573, MinusLogProbMetric: 27.6573, val_loss: 27.7803, val_MinusLogProbMetric: 27.7803

Epoch 47: val_loss did not improve from 27.70710
196/196 - 11s - loss: 27.6573 - MinusLogProbMetric: 27.6573 - val_loss: 27.7803 - val_MinusLogProbMetric: 27.7803 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 48/1000
2023-09-12 21:55:40.440 
Epoch 48/1000 
	 loss: 27.6801, MinusLogProbMetric: 27.6801, val_loss: 27.9445, val_MinusLogProbMetric: 27.9445

Epoch 48: val_loss did not improve from 27.70710
196/196 - 11s - loss: 27.6801 - MinusLogProbMetric: 27.6801 - val_loss: 27.9445 - val_MinusLogProbMetric: 27.9445 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 49/1000
2023-09-12 21:55:52.021 
Epoch 49/1000 
	 loss: 27.6855, MinusLogProbMetric: 27.6855, val_loss: 27.7747, val_MinusLogProbMetric: 27.7747

Epoch 49: val_loss did not improve from 27.70710
196/196 - 12s - loss: 27.6855 - MinusLogProbMetric: 27.6855 - val_loss: 27.7747 - val_MinusLogProbMetric: 27.7747 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 50/1000
2023-09-12 21:56:03.015 
Epoch 50/1000 
	 loss: 27.6757, MinusLogProbMetric: 27.6757, val_loss: 27.7636, val_MinusLogProbMetric: 27.7636

Epoch 50: val_loss did not improve from 27.70710
196/196 - 11s - loss: 27.6757 - MinusLogProbMetric: 27.6757 - val_loss: 27.7636 - val_MinusLogProbMetric: 27.7636 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 51/1000
2023-09-12 21:56:12.898 
Epoch 51/1000 
	 loss: 27.6571, MinusLogProbMetric: 27.6571, val_loss: 27.7638, val_MinusLogProbMetric: 27.7638

Epoch 51: val_loss did not improve from 27.70710
196/196 - 10s - loss: 27.6571 - MinusLogProbMetric: 27.6571 - val_loss: 27.7638 - val_MinusLogProbMetric: 27.7638 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 52/1000
2023-09-12 21:56:24.445 
Epoch 52/1000 
	 loss: 27.6774, MinusLogProbMetric: 27.6774, val_loss: 27.6767, val_MinusLogProbMetric: 27.6767

Epoch 52: val_loss improved from 27.70710 to 27.67670, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 12s - loss: 27.6774 - MinusLogProbMetric: 27.6774 - val_loss: 27.6767 - val_MinusLogProbMetric: 27.6767 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 53/1000
2023-09-12 21:56:36.601 
Epoch 53/1000 
	 loss: 27.6455, MinusLogProbMetric: 27.6455, val_loss: 27.7228, val_MinusLogProbMetric: 27.7228

Epoch 53: val_loss did not improve from 27.67670
196/196 - 12s - loss: 27.6455 - MinusLogProbMetric: 27.6455 - val_loss: 27.7228 - val_MinusLogProbMetric: 27.7228 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 54/1000
2023-09-12 21:56:47.480 
Epoch 54/1000 
	 loss: 27.6427, MinusLogProbMetric: 27.6427, val_loss: 27.6633, val_MinusLogProbMetric: 27.6633

Epoch 54: val_loss improved from 27.67670 to 27.66332, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 27.6427 - MinusLogProbMetric: 27.6427 - val_loss: 27.6633 - val_MinusLogProbMetric: 27.6633 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 55/1000
2023-09-12 21:56:59.715 
Epoch 55/1000 
	 loss: 27.6482, MinusLogProbMetric: 27.6482, val_loss: 27.7769, val_MinusLogProbMetric: 27.7769

Epoch 55: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6482 - MinusLogProbMetric: 27.6482 - val_loss: 27.7769 - val_MinusLogProbMetric: 27.7769 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 56/1000
2023-09-12 21:57:11.824 
Epoch 56/1000 
	 loss: 27.6470, MinusLogProbMetric: 27.6470, val_loss: 27.8011, val_MinusLogProbMetric: 27.8011

Epoch 56: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6470 - MinusLogProbMetric: 27.6470 - val_loss: 27.8011 - val_MinusLogProbMetric: 27.8011 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 57/1000
2023-09-12 21:57:23.400 
Epoch 57/1000 
	 loss: 27.6302, MinusLogProbMetric: 27.6302, val_loss: 27.7813, val_MinusLogProbMetric: 27.7813

Epoch 57: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6302 - MinusLogProbMetric: 27.6302 - val_loss: 27.7813 - val_MinusLogProbMetric: 27.7813 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 58/1000
2023-09-12 21:57:34.048 
Epoch 58/1000 
	 loss: 27.6326, MinusLogProbMetric: 27.6326, val_loss: 27.7639, val_MinusLogProbMetric: 27.7639

Epoch 58: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.6326 - MinusLogProbMetric: 27.6326 - val_loss: 27.7639 - val_MinusLogProbMetric: 27.7639 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 59/1000
2023-09-12 21:57:46.032 
Epoch 59/1000 
	 loss: 27.6307, MinusLogProbMetric: 27.6307, val_loss: 27.8514, val_MinusLogProbMetric: 27.8514

Epoch 59: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6307 - MinusLogProbMetric: 27.6307 - val_loss: 27.8514 - val_MinusLogProbMetric: 27.8514 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 60/1000
2023-09-12 21:57:58.102 
Epoch 60/1000 
	 loss: 27.6091, MinusLogProbMetric: 27.6091, val_loss: 27.7041, val_MinusLogProbMetric: 27.7041

Epoch 60: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6091 - MinusLogProbMetric: 27.6091 - val_loss: 27.7041 - val_MinusLogProbMetric: 27.7041 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 61/1000
2023-09-12 21:58:09.031 
Epoch 61/1000 
	 loss: 27.6158, MinusLogProbMetric: 27.6158, val_loss: 27.8672, val_MinusLogProbMetric: 27.8672

Epoch 61: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.6158 - MinusLogProbMetric: 27.6158 - val_loss: 27.8672 - val_MinusLogProbMetric: 27.8672 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 62/1000
2023-09-12 21:58:21.019 
Epoch 62/1000 
	 loss: 27.6229, MinusLogProbMetric: 27.6229, val_loss: 27.6977, val_MinusLogProbMetric: 27.6977

Epoch 62: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6229 - MinusLogProbMetric: 27.6229 - val_loss: 27.6977 - val_MinusLogProbMetric: 27.6977 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 63/1000
2023-09-12 21:58:32.415 
Epoch 63/1000 
	 loss: 27.6455, MinusLogProbMetric: 27.6455, val_loss: 27.7185, val_MinusLogProbMetric: 27.7185

Epoch 63: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.6455 - MinusLogProbMetric: 27.6455 - val_loss: 27.7185 - val_MinusLogProbMetric: 27.7185 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 64/1000
2023-09-12 21:58:43.220 
Epoch 64/1000 
	 loss: 27.6173, MinusLogProbMetric: 27.6173, val_loss: 27.8434, val_MinusLogProbMetric: 27.8434

Epoch 64: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.6173 - MinusLogProbMetric: 27.6173 - val_loss: 27.8434 - val_MinusLogProbMetric: 27.8434 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 65/1000
2023-09-12 21:58:52.935 
Epoch 65/1000 
	 loss: 27.6126, MinusLogProbMetric: 27.6126, val_loss: 27.7646, val_MinusLogProbMetric: 27.7646

Epoch 65: val_loss did not improve from 27.66332
196/196 - 10s - loss: 27.6126 - MinusLogProbMetric: 27.6126 - val_loss: 27.7646 - val_MinusLogProbMetric: 27.7646 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 66/1000
2023-09-12 21:59:04.443 
Epoch 66/1000 
	 loss: 27.6110, MinusLogProbMetric: 27.6110, val_loss: 27.7196, val_MinusLogProbMetric: 27.7196

Epoch 66: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6110 - MinusLogProbMetric: 27.6110 - val_loss: 27.7196 - val_MinusLogProbMetric: 27.7196 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 67/1000
2023-09-12 21:59:16.432 
Epoch 67/1000 
	 loss: 27.6183, MinusLogProbMetric: 27.6183, val_loss: 27.8248, val_MinusLogProbMetric: 27.8248

Epoch 67: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6183 - MinusLogProbMetric: 27.6183 - val_loss: 27.8248 - val_MinusLogProbMetric: 27.8248 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 68/1000
2023-09-12 21:59:28.448 
Epoch 68/1000 
	 loss: 27.6104, MinusLogProbMetric: 27.6104, val_loss: 27.7735, val_MinusLogProbMetric: 27.7735

Epoch 68: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6104 - MinusLogProbMetric: 27.6104 - val_loss: 27.7735 - val_MinusLogProbMetric: 27.7735 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 69/1000
2023-09-12 21:59:39.182 
Epoch 69/1000 
	 loss: 27.6065, MinusLogProbMetric: 27.6065, val_loss: 27.7274, val_MinusLogProbMetric: 27.7274

Epoch 69: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.6065 - MinusLogProbMetric: 27.6065 - val_loss: 27.7274 - val_MinusLogProbMetric: 27.7274 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 70/1000
2023-09-12 21:59:51.225 
Epoch 70/1000 
	 loss: 27.5972, MinusLogProbMetric: 27.5972, val_loss: 27.7185, val_MinusLogProbMetric: 27.7185

Epoch 70: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5972 - MinusLogProbMetric: 27.5972 - val_loss: 27.7185 - val_MinusLogProbMetric: 27.7185 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 71/1000
2023-09-12 22:00:03.324 
Epoch 71/1000 
	 loss: 27.5935, MinusLogProbMetric: 27.5935, val_loss: 27.6802, val_MinusLogProbMetric: 27.6802

Epoch 71: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5935 - MinusLogProbMetric: 27.5935 - val_loss: 27.6802 - val_MinusLogProbMetric: 27.6802 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 72/1000
2023-09-12 22:00:15.322 
Epoch 72/1000 
	 loss: 27.5920, MinusLogProbMetric: 27.5920, val_loss: 27.6958, val_MinusLogProbMetric: 27.6958

Epoch 72: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5920 - MinusLogProbMetric: 27.5920 - val_loss: 27.6958 - val_MinusLogProbMetric: 27.6958 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 73/1000
2023-09-12 22:00:26.434 
Epoch 73/1000 
	 loss: 27.5866, MinusLogProbMetric: 27.5866, val_loss: 27.6954, val_MinusLogProbMetric: 27.6954

Epoch 73: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.5866 - MinusLogProbMetric: 27.5866 - val_loss: 27.6954 - val_MinusLogProbMetric: 27.6954 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 74/1000
2023-09-12 22:00:38.072 
Epoch 74/1000 
	 loss: 27.6026, MinusLogProbMetric: 27.6026, val_loss: 27.7404, val_MinusLogProbMetric: 27.7404

Epoch 74: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.6026 - MinusLogProbMetric: 27.6026 - val_loss: 27.7404 - val_MinusLogProbMetric: 27.7404 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 75/1000
2023-09-12 22:00:49.431 
Epoch 75/1000 
	 loss: 27.5785, MinusLogProbMetric: 27.5785, val_loss: 27.8312, val_MinusLogProbMetric: 27.8312

Epoch 75: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.5785 - MinusLogProbMetric: 27.5785 - val_loss: 27.8312 - val_MinusLogProbMetric: 27.8312 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 76/1000
2023-09-12 22:01:01.369 
Epoch 76/1000 
	 loss: 27.5851, MinusLogProbMetric: 27.5851, val_loss: 27.8296, val_MinusLogProbMetric: 27.8296

Epoch 76: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5851 - MinusLogProbMetric: 27.5851 - val_loss: 27.8296 - val_MinusLogProbMetric: 27.8296 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 77/1000
2023-09-12 22:01:12.877 
Epoch 77/1000 
	 loss: 27.5636, MinusLogProbMetric: 27.5636, val_loss: 27.7321, val_MinusLogProbMetric: 27.7321

Epoch 77: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5636 - MinusLogProbMetric: 27.5636 - val_loss: 27.7321 - val_MinusLogProbMetric: 27.7321 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 78/1000
2023-09-12 22:01:24.335 
Epoch 78/1000 
	 loss: 27.5727, MinusLogProbMetric: 27.5727, val_loss: 27.7412, val_MinusLogProbMetric: 27.7412

Epoch 78: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.5727 - MinusLogProbMetric: 27.5727 - val_loss: 27.7412 - val_MinusLogProbMetric: 27.7412 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 79/1000
2023-09-12 22:01:35.578 
Epoch 79/1000 
	 loss: 27.5720, MinusLogProbMetric: 27.5720, val_loss: 27.7379, val_MinusLogProbMetric: 27.7379

Epoch 79: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.5720 - MinusLogProbMetric: 27.5720 - val_loss: 27.7379 - val_MinusLogProbMetric: 27.7379 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 80/1000
2023-09-12 22:01:45.973 
Epoch 80/1000 
	 loss: 27.5786, MinusLogProbMetric: 27.5786, val_loss: 27.7276, val_MinusLogProbMetric: 27.7276

Epoch 80: val_loss did not improve from 27.66332
196/196 - 10s - loss: 27.5786 - MinusLogProbMetric: 27.5786 - val_loss: 27.7276 - val_MinusLogProbMetric: 27.7276 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 81/1000
2023-09-12 22:01:57.560 
Epoch 81/1000 
	 loss: 27.5745, MinusLogProbMetric: 27.5745, val_loss: 27.6720, val_MinusLogProbMetric: 27.6720

Epoch 81: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5745 - MinusLogProbMetric: 27.5745 - val_loss: 27.6720 - val_MinusLogProbMetric: 27.6720 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 82/1000
2023-09-12 22:02:09.624 
Epoch 82/1000 
	 loss: 27.5615, MinusLogProbMetric: 27.5615, val_loss: 27.7482, val_MinusLogProbMetric: 27.7482

Epoch 82: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5615 - MinusLogProbMetric: 27.5615 - val_loss: 27.7482 - val_MinusLogProbMetric: 27.7482 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 83/1000
2023-09-12 22:02:21.611 
Epoch 83/1000 
	 loss: 27.5811, MinusLogProbMetric: 27.5811, val_loss: 27.7267, val_MinusLogProbMetric: 27.7267

Epoch 83: val_loss did not improve from 27.66332
196/196 - 12s - loss: 27.5811 - MinusLogProbMetric: 27.5811 - val_loss: 27.7267 - val_MinusLogProbMetric: 27.7267 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 84/1000
2023-09-12 22:02:31.592 
Epoch 84/1000 
	 loss: 27.5853, MinusLogProbMetric: 27.5853, val_loss: 27.7236, val_MinusLogProbMetric: 27.7236

Epoch 84: val_loss did not improve from 27.66332
196/196 - 10s - loss: 27.5853 - MinusLogProbMetric: 27.5853 - val_loss: 27.7236 - val_MinusLogProbMetric: 27.7236 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 85/1000
2023-09-12 22:02:41.420 
Epoch 85/1000 
	 loss: 27.5791, MinusLogProbMetric: 27.5791, val_loss: 27.7959, val_MinusLogProbMetric: 27.7959

Epoch 85: val_loss did not improve from 27.66332
196/196 - 10s - loss: 27.5791 - MinusLogProbMetric: 27.5791 - val_loss: 27.7959 - val_MinusLogProbMetric: 27.7959 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 86/1000
2023-09-12 22:02:50.808 
Epoch 86/1000 
	 loss: 27.5792, MinusLogProbMetric: 27.5792, val_loss: 27.7438, val_MinusLogProbMetric: 27.7438

Epoch 86: val_loss did not improve from 27.66332
196/196 - 9s - loss: 27.5792 - MinusLogProbMetric: 27.5792 - val_loss: 27.7438 - val_MinusLogProbMetric: 27.7438 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 87/1000
2023-09-12 22:02:59.791 
Epoch 87/1000 
	 loss: 27.5721, MinusLogProbMetric: 27.5721, val_loss: 27.6706, val_MinusLogProbMetric: 27.6706

Epoch 87: val_loss did not improve from 27.66332
196/196 - 9s - loss: 27.5721 - MinusLogProbMetric: 27.5721 - val_loss: 27.6706 - val_MinusLogProbMetric: 27.6706 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 88/1000
2023-09-12 22:03:10.845 
Epoch 88/1000 
	 loss: 27.5446, MinusLogProbMetric: 27.5446, val_loss: 27.7059, val_MinusLogProbMetric: 27.7059

Epoch 88: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.5446 - MinusLogProbMetric: 27.5446 - val_loss: 27.7059 - val_MinusLogProbMetric: 27.7059 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 89/1000
2023-09-12 22:03:21.958 
Epoch 89/1000 
	 loss: 27.5589, MinusLogProbMetric: 27.5589, val_loss: 27.7831, val_MinusLogProbMetric: 27.7831

Epoch 89: val_loss did not improve from 27.66332
196/196 - 11s - loss: 27.5589 - MinusLogProbMetric: 27.5589 - val_loss: 27.7831 - val_MinusLogProbMetric: 27.7831 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 90/1000
2023-09-12 22:03:31.642 
Epoch 90/1000 
	 loss: 27.5663, MinusLogProbMetric: 27.5663, val_loss: 27.7139, val_MinusLogProbMetric: 27.7139

Epoch 90: val_loss did not improve from 27.66332
196/196 - 10s - loss: 27.5663 - MinusLogProbMetric: 27.5663 - val_loss: 27.7139 - val_MinusLogProbMetric: 27.7139 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 91/1000
2023-09-12 22:03:41.345 
Epoch 91/1000 
	 loss: 27.5565, MinusLogProbMetric: 27.5565, val_loss: 27.7112, val_MinusLogProbMetric: 27.7112

Epoch 91: val_loss did not improve from 27.66332
196/196 - 10s - loss: 27.5565 - MinusLogProbMetric: 27.5565 - val_loss: 27.7112 - val_MinusLogProbMetric: 27.7112 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 92/1000
2023-09-12 22:03:50.960 
Epoch 92/1000 
	 loss: 27.5460, MinusLogProbMetric: 27.5460, val_loss: 27.6526, val_MinusLogProbMetric: 27.6526

Epoch 92: val_loss improved from 27.66332 to 27.65257, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 27.5460 - MinusLogProbMetric: 27.5460 - val_loss: 27.6526 - val_MinusLogProbMetric: 27.6526 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 93/1000
2023-09-12 22:04:00.265 
Epoch 93/1000 
	 loss: 27.5408, MinusLogProbMetric: 27.5408, val_loss: 27.6763, val_MinusLogProbMetric: 27.6763

Epoch 93: val_loss did not improve from 27.65257
196/196 - 9s - loss: 27.5408 - MinusLogProbMetric: 27.5408 - val_loss: 27.6763 - val_MinusLogProbMetric: 27.6763 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 94/1000
2023-09-12 22:04:09.422 
Epoch 94/1000 
	 loss: 27.5476, MinusLogProbMetric: 27.5476, val_loss: 27.6872, val_MinusLogProbMetric: 27.6872

Epoch 94: val_loss did not improve from 27.65257
196/196 - 9s - loss: 27.5476 - MinusLogProbMetric: 27.5476 - val_loss: 27.6872 - val_MinusLogProbMetric: 27.6872 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 95/1000
2023-09-12 22:04:18.618 
Epoch 95/1000 
	 loss: 27.5486, MinusLogProbMetric: 27.5486, val_loss: 27.6623, val_MinusLogProbMetric: 27.6623

Epoch 95: val_loss did not improve from 27.65257
196/196 - 9s - loss: 27.5486 - MinusLogProbMetric: 27.5486 - val_loss: 27.6623 - val_MinusLogProbMetric: 27.6623 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 96/1000
2023-09-12 22:04:27.430 
Epoch 96/1000 
	 loss: 27.5553, MinusLogProbMetric: 27.5553, val_loss: 27.6520, val_MinusLogProbMetric: 27.6520

Epoch 96: val_loss improved from 27.65257 to 27.65196, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 27.5553 - MinusLogProbMetric: 27.5553 - val_loss: 27.6520 - val_MinusLogProbMetric: 27.6520 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 97/1000
2023-09-12 22:04:37.388 
Epoch 97/1000 
	 loss: 27.5581, MinusLogProbMetric: 27.5581, val_loss: 27.7053, val_MinusLogProbMetric: 27.7053

Epoch 97: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5581 - MinusLogProbMetric: 27.5581 - val_loss: 27.7053 - val_MinusLogProbMetric: 27.7053 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 98/1000
2023-09-12 22:04:47.947 
Epoch 98/1000 
	 loss: 27.5445, MinusLogProbMetric: 27.5445, val_loss: 27.6960, val_MinusLogProbMetric: 27.6960

Epoch 98: val_loss did not improve from 27.65196
196/196 - 11s - loss: 27.5445 - MinusLogProbMetric: 27.5445 - val_loss: 27.6960 - val_MinusLogProbMetric: 27.6960 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 99/1000
2023-09-12 22:04:58.343 
Epoch 99/1000 
	 loss: 27.5522, MinusLogProbMetric: 27.5522, val_loss: 27.6683, val_MinusLogProbMetric: 27.6683

Epoch 99: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5522 - MinusLogProbMetric: 27.5522 - val_loss: 27.6683 - val_MinusLogProbMetric: 27.6683 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 100/1000
2023-09-12 22:05:09.616 
Epoch 100/1000 
	 loss: 27.5438, MinusLogProbMetric: 27.5438, val_loss: 27.7358, val_MinusLogProbMetric: 27.7358

Epoch 100: val_loss did not improve from 27.65196
196/196 - 11s - loss: 27.5438 - MinusLogProbMetric: 27.5438 - val_loss: 27.7358 - val_MinusLogProbMetric: 27.7358 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 101/1000
2023-09-12 22:05:18.723 
Epoch 101/1000 
	 loss: 27.5412, MinusLogProbMetric: 27.5412, val_loss: 27.7543, val_MinusLogProbMetric: 27.7543

Epoch 101: val_loss did not improve from 27.65196
196/196 - 9s - loss: 27.5412 - MinusLogProbMetric: 27.5412 - val_loss: 27.7543 - val_MinusLogProbMetric: 27.7543 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 102/1000
2023-09-12 22:05:28.234 
Epoch 102/1000 
	 loss: 27.5494, MinusLogProbMetric: 27.5494, val_loss: 27.8295, val_MinusLogProbMetric: 27.8295

Epoch 102: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5494 - MinusLogProbMetric: 27.5494 - val_loss: 27.8295 - val_MinusLogProbMetric: 27.8295 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 103/1000
2023-09-12 22:05:37.743 
Epoch 103/1000 
	 loss: 27.5397, MinusLogProbMetric: 27.5397, val_loss: 27.6632, val_MinusLogProbMetric: 27.6632

Epoch 103: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5397 - MinusLogProbMetric: 27.5397 - val_loss: 27.6632 - val_MinusLogProbMetric: 27.6632 - lr: 0.0010 - 10s/epoch - 48ms/step
Epoch 104/1000
2023-09-12 22:05:46.981 
Epoch 104/1000 
	 loss: 27.5513, MinusLogProbMetric: 27.5513, val_loss: 27.7279, val_MinusLogProbMetric: 27.7279

Epoch 104: val_loss did not improve from 27.65196
196/196 - 9s - loss: 27.5513 - MinusLogProbMetric: 27.5513 - val_loss: 27.7279 - val_MinusLogProbMetric: 27.7279 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 105/1000
2023-09-12 22:05:57.341 
Epoch 105/1000 
	 loss: 27.5449, MinusLogProbMetric: 27.5449, val_loss: 27.7913, val_MinusLogProbMetric: 27.7913

Epoch 105: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5449 - MinusLogProbMetric: 27.5449 - val_loss: 27.7913 - val_MinusLogProbMetric: 27.7913 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 106/1000
2023-09-12 22:06:07.716 
Epoch 106/1000 
	 loss: 27.5319, MinusLogProbMetric: 27.5319, val_loss: 27.7623, val_MinusLogProbMetric: 27.7623

Epoch 106: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5319 - MinusLogProbMetric: 27.5319 - val_loss: 27.7623 - val_MinusLogProbMetric: 27.7623 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 107/1000
2023-09-12 22:06:18.215 
Epoch 107/1000 
	 loss: 27.5486, MinusLogProbMetric: 27.5486, val_loss: 27.7047, val_MinusLogProbMetric: 27.7047

Epoch 107: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5486 - MinusLogProbMetric: 27.5486 - val_loss: 27.7047 - val_MinusLogProbMetric: 27.7047 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 108/1000
2023-09-12 22:06:27.730 
Epoch 108/1000 
	 loss: 27.5331, MinusLogProbMetric: 27.5331, val_loss: 27.6719, val_MinusLogProbMetric: 27.6719

Epoch 108: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5331 - MinusLogProbMetric: 27.5331 - val_loss: 27.6719 - val_MinusLogProbMetric: 27.6719 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 109/1000
2023-09-12 22:06:37.456 
Epoch 109/1000 
	 loss: 27.5357, MinusLogProbMetric: 27.5357, val_loss: 27.6785, val_MinusLogProbMetric: 27.6785

Epoch 109: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5357 - MinusLogProbMetric: 27.5357 - val_loss: 27.6785 - val_MinusLogProbMetric: 27.6785 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 110/1000
2023-09-12 22:06:47.946 
Epoch 110/1000 
	 loss: 27.5248, MinusLogProbMetric: 27.5248, val_loss: 27.6944, val_MinusLogProbMetric: 27.6944

Epoch 110: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5248 - MinusLogProbMetric: 27.5248 - val_loss: 27.6944 - val_MinusLogProbMetric: 27.6944 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 111/1000
2023-09-12 22:06:58.249 
Epoch 111/1000 
	 loss: 27.5199, MinusLogProbMetric: 27.5199, val_loss: 27.7199, val_MinusLogProbMetric: 27.7199

Epoch 111: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5199 - MinusLogProbMetric: 27.5199 - val_loss: 27.7199 - val_MinusLogProbMetric: 27.7199 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 112/1000
2023-09-12 22:07:08.681 
Epoch 112/1000 
	 loss: 27.5217, MinusLogProbMetric: 27.5217, val_loss: 27.6800, val_MinusLogProbMetric: 27.6800

Epoch 112: val_loss did not improve from 27.65196
196/196 - 10s - loss: 27.5217 - MinusLogProbMetric: 27.5217 - val_loss: 27.6800 - val_MinusLogProbMetric: 27.6800 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 113/1000
2023-09-12 22:07:18.265 
Epoch 113/1000 
	 loss: 27.5223, MinusLogProbMetric: 27.5223, val_loss: 27.6481, val_MinusLogProbMetric: 27.6481

Epoch 113: val_loss improved from 27.65196 to 27.64805, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 27.5223 - MinusLogProbMetric: 27.5223 - val_loss: 27.6481 - val_MinusLogProbMetric: 27.6481 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 114/1000
2023-09-12 22:07:28.798 
Epoch 114/1000 
	 loss: 27.5199, MinusLogProbMetric: 27.5199, val_loss: 27.6923, val_MinusLogProbMetric: 27.6923

Epoch 114: val_loss did not improve from 27.64805
196/196 - 10s - loss: 27.5199 - MinusLogProbMetric: 27.5199 - val_loss: 27.6923 - val_MinusLogProbMetric: 27.6923 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 115/1000
2023-09-12 22:07:39.225 
Epoch 115/1000 
	 loss: 27.5325, MinusLogProbMetric: 27.5325, val_loss: 27.6883, val_MinusLogProbMetric: 27.6883

Epoch 115: val_loss did not improve from 27.64805
196/196 - 10s - loss: 27.5325 - MinusLogProbMetric: 27.5325 - val_loss: 27.6883 - val_MinusLogProbMetric: 27.6883 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 116/1000
2023-09-12 22:07:49.638 
Epoch 116/1000 
	 loss: 27.5291, MinusLogProbMetric: 27.5291, val_loss: 27.7652, val_MinusLogProbMetric: 27.7652

Epoch 116: val_loss did not improve from 27.64805
196/196 - 10s - loss: 27.5291 - MinusLogProbMetric: 27.5291 - val_loss: 27.7652 - val_MinusLogProbMetric: 27.7652 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 117/1000
2023-09-12 22:08:00.041 
Epoch 117/1000 
	 loss: 27.5320, MinusLogProbMetric: 27.5320, val_loss: 27.6868, val_MinusLogProbMetric: 27.6868

Epoch 117: val_loss did not improve from 27.64805
196/196 - 10s - loss: 27.5320 - MinusLogProbMetric: 27.5320 - val_loss: 27.6868 - val_MinusLogProbMetric: 27.6868 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 118/1000
2023-09-12 22:08:09.798 
Epoch 118/1000 
	 loss: 27.5213, MinusLogProbMetric: 27.5213, val_loss: 27.6221, val_MinusLogProbMetric: 27.6221

Epoch 118: val_loss improved from 27.64805 to 27.62210, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 27.5213 - MinusLogProbMetric: 27.5213 - val_loss: 27.6221 - val_MinusLogProbMetric: 27.6221 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 119/1000
2023-09-12 22:08:20.148 
Epoch 119/1000 
	 loss: 27.5162, MinusLogProbMetric: 27.5162, val_loss: 27.6513, val_MinusLogProbMetric: 27.6513

Epoch 119: val_loss did not improve from 27.62210
196/196 - 10s - loss: 27.5162 - MinusLogProbMetric: 27.5162 - val_loss: 27.6513 - val_MinusLogProbMetric: 27.6513 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 120/1000
2023-09-12 22:08:30.060 
Epoch 120/1000 
	 loss: 27.5112, MinusLogProbMetric: 27.5112, val_loss: 27.6736, val_MinusLogProbMetric: 27.6736

Epoch 120: val_loss did not improve from 27.62210
196/196 - 10s - loss: 27.5112 - MinusLogProbMetric: 27.5112 - val_loss: 27.6736 - val_MinusLogProbMetric: 27.6736 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 121/1000
2023-09-12 22:08:38.846 
Epoch 121/1000 
	 loss: 27.5200, MinusLogProbMetric: 27.5200, val_loss: 27.6937, val_MinusLogProbMetric: 27.6937

Epoch 121: val_loss did not improve from 27.62210
196/196 - 9s - loss: 27.5200 - MinusLogProbMetric: 27.5200 - val_loss: 27.6937 - val_MinusLogProbMetric: 27.6937 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 122/1000
2023-09-12 22:08:47.574 
Epoch 122/1000 
	 loss: 27.4962, MinusLogProbMetric: 27.4962, val_loss: 27.6454, val_MinusLogProbMetric: 27.6454

Epoch 122: val_loss did not improve from 27.62210
196/196 - 9s - loss: 27.4962 - MinusLogProbMetric: 27.4962 - val_loss: 27.6454 - val_MinusLogProbMetric: 27.6454 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 123/1000
2023-09-12 22:08:57.429 
Epoch 123/1000 
	 loss: 27.5034, MinusLogProbMetric: 27.5034, val_loss: 27.6036, val_MinusLogProbMetric: 27.6036

Epoch 123: val_loss improved from 27.62210 to 27.60365, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 27.5034 - MinusLogProbMetric: 27.5034 - val_loss: 27.6036 - val_MinusLogProbMetric: 27.6036 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 124/1000
2023-09-12 22:09:07.935 
Epoch 124/1000 
	 loss: 27.4953, MinusLogProbMetric: 27.4953, val_loss: 27.6821, val_MinusLogProbMetric: 27.6821

Epoch 124: val_loss did not improve from 27.60365
196/196 - 10s - loss: 27.4953 - MinusLogProbMetric: 27.4953 - val_loss: 27.6821 - val_MinusLogProbMetric: 27.6821 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 125/1000
2023-09-12 22:09:16.876 
Epoch 125/1000 
	 loss: 27.5154, MinusLogProbMetric: 27.5154, val_loss: 27.6721, val_MinusLogProbMetric: 27.6721

Epoch 125: val_loss did not improve from 27.60365
196/196 - 9s - loss: 27.5154 - MinusLogProbMetric: 27.5154 - val_loss: 27.6721 - val_MinusLogProbMetric: 27.6721 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 126/1000
2023-09-12 22:09:26.121 
Epoch 126/1000 
	 loss: 27.5151, MinusLogProbMetric: 27.5151, val_loss: 27.6281, val_MinusLogProbMetric: 27.6281

Epoch 126: val_loss did not improve from 27.60365
196/196 - 9s - loss: 27.5151 - MinusLogProbMetric: 27.5151 - val_loss: 27.6281 - val_MinusLogProbMetric: 27.6281 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 127/1000
2023-09-12 22:09:36.219 
Epoch 127/1000 
	 loss: 27.5101, MinusLogProbMetric: 27.5101, val_loss: 27.6696, val_MinusLogProbMetric: 27.6696

Epoch 127: val_loss did not improve from 27.60365
196/196 - 10s - loss: 27.5101 - MinusLogProbMetric: 27.5101 - val_loss: 27.6696 - val_MinusLogProbMetric: 27.6696 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 128/1000
2023-09-12 22:09:46.644 
Epoch 128/1000 
	 loss: 27.5106, MinusLogProbMetric: 27.5106, val_loss: 27.6581, val_MinusLogProbMetric: 27.6581

Epoch 128: val_loss did not improve from 27.60365
196/196 - 10s - loss: 27.5106 - MinusLogProbMetric: 27.5106 - val_loss: 27.6581 - val_MinusLogProbMetric: 27.6581 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 129/1000
2023-09-12 22:09:56.046 
Epoch 129/1000 
	 loss: 27.5115, MinusLogProbMetric: 27.5115, val_loss: 27.6804, val_MinusLogProbMetric: 27.6804

Epoch 129: val_loss did not improve from 27.60365
196/196 - 9s - loss: 27.5115 - MinusLogProbMetric: 27.5115 - val_loss: 27.6804 - val_MinusLogProbMetric: 27.6804 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 130/1000
2023-09-12 22:10:04.836 
Epoch 130/1000 
	 loss: 27.5160, MinusLogProbMetric: 27.5160, val_loss: 27.6478, val_MinusLogProbMetric: 27.6478

Epoch 130: val_loss did not improve from 27.60365
196/196 - 9s - loss: 27.5160 - MinusLogProbMetric: 27.5160 - val_loss: 27.6478 - val_MinusLogProbMetric: 27.6478 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 131/1000
2023-09-12 22:10:13.454 
Epoch 131/1000 
	 loss: 27.4886, MinusLogProbMetric: 27.4886, val_loss: 27.7068, val_MinusLogProbMetric: 27.7068

Epoch 131: val_loss did not improve from 27.60365
196/196 - 9s - loss: 27.4886 - MinusLogProbMetric: 27.4886 - val_loss: 27.7068 - val_MinusLogProbMetric: 27.7068 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 132/1000
2023-09-12 22:10:22.829 
Epoch 132/1000 
	 loss: 27.5051, MinusLogProbMetric: 27.5051, val_loss: 27.6612, val_MinusLogProbMetric: 27.6612

Epoch 132: val_loss did not improve from 27.60365
196/196 - 9s - loss: 27.5051 - MinusLogProbMetric: 27.5051 - val_loss: 27.6612 - val_MinusLogProbMetric: 27.6612 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 133/1000
2023-09-12 22:10:32.344 
Epoch 133/1000 
	 loss: 27.4982, MinusLogProbMetric: 27.4982, val_loss: 27.6937, val_MinusLogProbMetric: 27.6937

Epoch 133: val_loss did not improve from 27.60365
196/196 - 10s - loss: 27.4982 - MinusLogProbMetric: 27.4982 - val_loss: 27.6937 - val_MinusLogProbMetric: 27.6937 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 134/1000
2023-09-12 22:10:41.802 
Epoch 134/1000 
	 loss: 27.4927, MinusLogProbMetric: 27.4927, val_loss: 27.6632, val_MinusLogProbMetric: 27.6632

Epoch 134: val_loss did not improve from 27.60365
196/196 - 9s - loss: 27.4927 - MinusLogProbMetric: 27.4927 - val_loss: 27.6632 - val_MinusLogProbMetric: 27.6632 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 135/1000
2023-09-12 22:10:52.328 
Epoch 135/1000 
	 loss: 27.5047, MinusLogProbMetric: 27.5047, val_loss: 27.6705, val_MinusLogProbMetric: 27.6705

Epoch 135: val_loss did not improve from 27.60365
196/196 - 11s - loss: 27.5047 - MinusLogProbMetric: 27.5047 - val_loss: 27.6705 - val_MinusLogProbMetric: 27.6705 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 136/1000
2023-09-12 22:11:03.127 
Epoch 136/1000 
	 loss: 27.4955, MinusLogProbMetric: 27.4955, val_loss: 27.6304, val_MinusLogProbMetric: 27.6304

Epoch 136: val_loss did not improve from 27.60365
196/196 - 11s - loss: 27.4955 - MinusLogProbMetric: 27.4955 - val_loss: 27.6304 - val_MinusLogProbMetric: 27.6304 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 137/1000
2023-09-12 22:11:13.594 
Epoch 137/1000 
	 loss: 27.4936, MinusLogProbMetric: 27.4936, val_loss: 27.6498, val_MinusLogProbMetric: 27.6498

Epoch 137: val_loss did not improve from 27.60365
196/196 - 10s - loss: 27.4936 - MinusLogProbMetric: 27.4936 - val_loss: 27.6498 - val_MinusLogProbMetric: 27.6498 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 138/1000
2023-09-12 22:11:24.205 
Epoch 138/1000 
	 loss: 27.4956, MinusLogProbMetric: 27.4956, val_loss: 27.7916, val_MinusLogProbMetric: 27.7916

Epoch 138: val_loss did not improve from 27.60365
196/196 - 11s - loss: 27.4956 - MinusLogProbMetric: 27.4956 - val_loss: 27.7916 - val_MinusLogProbMetric: 27.7916 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 139/1000
2023-09-12 22:11:34.628 
Epoch 139/1000 
	 loss: 27.5007, MinusLogProbMetric: 27.5007, val_loss: 27.7213, val_MinusLogProbMetric: 27.7213

Epoch 139: val_loss did not improve from 27.60365
196/196 - 10s - loss: 27.5007 - MinusLogProbMetric: 27.5007 - val_loss: 27.7213 - val_MinusLogProbMetric: 27.7213 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 140/1000
2023-09-12 22:11:44.999 
Epoch 140/1000 
	 loss: 27.4860, MinusLogProbMetric: 27.4860, val_loss: 27.6023, val_MinusLogProbMetric: 27.6023

Epoch 140: val_loss improved from 27.60365 to 27.60226, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 27.4860 - MinusLogProbMetric: 27.4860 - val_loss: 27.6023 - val_MinusLogProbMetric: 27.6023 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 141/1000
2023-09-12 22:11:54.235 
Epoch 141/1000 
	 loss: 27.4785, MinusLogProbMetric: 27.4785, val_loss: 27.7445, val_MinusLogProbMetric: 27.7445

Epoch 141: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4785 - MinusLogProbMetric: 27.4785 - val_loss: 27.7445 - val_MinusLogProbMetric: 27.7445 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 142/1000
2023-09-12 22:12:03.535 
Epoch 142/1000 
	 loss: 27.4913, MinusLogProbMetric: 27.4913, val_loss: 27.7145, val_MinusLogProbMetric: 27.7145

Epoch 142: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4913 - MinusLogProbMetric: 27.4913 - val_loss: 27.7145 - val_MinusLogProbMetric: 27.7145 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 143/1000
2023-09-12 22:12:12.111 
Epoch 143/1000 
	 loss: 27.5027, MinusLogProbMetric: 27.5027, val_loss: 27.6680, val_MinusLogProbMetric: 27.6680

Epoch 143: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.5027 - MinusLogProbMetric: 27.5027 - val_loss: 27.6680 - val_MinusLogProbMetric: 27.6680 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 144/1000
2023-09-12 22:12:20.727 
Epoch 144/1000 
	 loss: 27.4793, MinusLogProbMetric: 27.4793, val_loss: 27.7098, val_MinusLogProbMetric: 27.7098

Epoch 144: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4793 - MinusLogProbMetric: 27.4793 - val_loss: 27.7098 - val_MinusLogProbMetric: 27.7098 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 145/1000
2023-09-12 22:12:29.587 
Epoch 145/1000 
	 loss: 27.4850, MinusLogProbMetric: 27.4850, val_loss: 27.6783, val_MinusLogProbMetric: 27.6783

Epoch 145: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4850 - MinusLogProbMetric: 27.4850 - val_loss: 27.6783 - val_MinusLogProbMetric: 27.6783 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 146/1000
2023-09-12 22:12:38.182 
Epoch 146/1000 
	 loss: 27.5056, MinusLogProbMetric: 27.5056, val_loss: 27.6663, val_MinusLogProbMetric: 27.6663

Epoch 146: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.5056 - MinusLogProbMetric: 27.5056 - val_loss: 27.6663 - val_MinusLogProbMetric: 27.6663 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 147/1000
2023-09-12 22:12:46.797 
Epoch 147/1000 
	 loss: 27.4873, MinusLogProbMetric: 27.4873, val_loss: 27.6760, val_MinusLogProbMetric: 27.6760

Epoch 147: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4873 - MinusLogProbMetric: 27.4873 - val_loss: 27.6760 - val_MinusLogProbMetric: 27.6760 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 148/1000
2023-09-12 22:12:55.250 
Epoch 148/1000 
	 loss: 27.4796, MinusLogProbMetric: 27.4796, val_loss: 27.6314, val_MinusLogProbMetric: 27.6314

Epoch 148: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.4796 - MinusLogProbMetric: 27.4796 - val_loss: 27.6314 - val_MinusLogProbMetric: 27.6314 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 149/1000
2023-09-12 22:13:03.813 
Epoch 149/1000 
	 loss: 27.4855, MinusLogProbMetric: 27.4855, val_loss: 27.6259, val_MinusLogProbMetric: 27.6259

Epoch 149: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4855 - MinusLogProbMetric: 27.4855 - val_loss: 27.6259 - val_MinusLogProbMetric: 27.6259 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 150/1000
2023-09-12 22:13:12.364 
Epoch 150/1000 
	 loss: 27.4782, MinusLogProbMetric: 27.4782, val_loss: 27.6531, val_MinusLogProbMetric: 27.6531

Epoch 150: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4782 - MinusLogProbMetric: 27.4782 - val_loss: 27.6531 - val_MinusLogProbMetric: 27.6531 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 151/1000
2023-09-12 22:13:22.161 
Epoch 151/1000 
	 loss: 27.4776, MinusLogProbMetric: 27.4776, val_loss: 27.7612, val_MinusLogProbMetric: 27.7612

Epoch 151: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4776 - MinusLogProbMetric: 27.4776 - val_loss: 27.7612 - val_MinusLogProbMetric: 27.7612 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 152/1000
2023-09-12 22:13:31.608 
Epoch 152/1000 
	 loss: 27.4803, MinusLogProbMetric: 27.4803, val_loss: 27.6984, val_MinusLogProbMetric: 27.6984

Epoch 152: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4803 - MinusLogProbMetric: 27.4803 - val_loss: 27.6984 - val_MinusLogProbMetric: 27.6984 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 153/1000
2023-09-12 22:13:40.007 
Epoch 153/1000 
	 loss: 27.4777, MinusLogProbMetric: 27.4777, val_loss: 27.7182, val_MinusLogProbMetric: 27.7182

Epoch 153: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.4777 - MinusLogProbMetric: 27.4777 - val_loss: 27.7182 - val_MinusLogProbMetric: 27.7182 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 154/1000
2023-09-12 22:13:48.742 
Epoch 154/1000 
	 loss: 27.4800, MinusLogProbMetric: 27.4800, val_loss: 27.6538, val_MinusLogProbMetric: 27.6538

Epoch 154: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4800 - MinusLogProbMetric: 27.4800 - val_loss: 27.6538 - val_MinusLogProbMetric: 27.6538 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 155/1000
2023-09-12 22:13:57.238 
Epoch 155/1000 
	 loss: 27.4716, MinusLogProbMetric: 27.4716, val_loss: 27.6653, val_MinusLogProbMetric: 27.6653

Epoch 155: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.4716 - MinusLogProbMetric: 27.4716 - val_loss: 27.6653 - val_MinusLogProbMetric: 27.6653 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 156/1000
2023-09-12 22:14:05.799 
Epoch 156/1000 
	 loss: 27.4876, MinusLogProbMetric: 27.4876, val_loss: 27.6175, val_MinusLogProbMetric: 27.6175

Epoch 156: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4876 - MinusLogProbMetric: 27.4876 - val_loss: 27.6175 - val_MinusLogProbMetric: 27.6175 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 157/1000
2023-09-12 22:14:15.257 
Epoch 157/1000 
	 loss: 27.4723, MinusLogProbMetric: 27.4723, val_loss: 27.7378, val_MinusLogProbMetric: 27.7378

Epoch 157: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4723 - MinusLogProbMetric: 27.4723 - val_loss: 27.7378 - val_MinusLogProbMetric: 27.7378 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 158/1000
2023-09-12 22:14:25.550 
Epoch 158/1000 
	 loss: 27.4812, MinusLogProbMetric: 27.4812, val_loss: 27.6726, val_MinusLogProbMetric: 27.6726

Epoch 158: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4812 - MinusLogProbMetric: 27.4812 - val_loss: 27.6726 - val_MinusLogProbMetric: 27.6726 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 159/1000
2023-09-12 22:14:35.743 
Epoch 159/1000 
	 loss: 27.4763, MinusLogProbMetric: 27.4763, val_loss: 27.6463, val_MinusLogProbMetric: 27.6463

Epoch 159: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4763 - MinusLogProbMetric: 27.4763 - val_loss: 27.6463 - val_MinusLogProbMetric: 27.6463 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 160/1000
2023-09-12 22:14:45.826 
Epoch 160/1000 
	 loss: 27.4759, MinusLogProbMetric: 27.4759, val_loss: 27.6733, val_MinusLogProbMetric: 27.6733

Epoch 160: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4759 - MinusLogProbMetric: 27.4759 - val_loss: 27.6733 - val_MinusLogProbMetric: 27.6733 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 161/1000
2023-09-12 22:14:56.283 
Epoch 161/1000 
	 loss: 27.4613, MinusLogProbMetric: 27.4613, val_loss: 27.6170, val_MinusLogProbMetric: 27.6170

Epoch 161: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4613 - MinusLogProbMetric: 27.4613 - val_loss: 27.6170 - val_MinusLogProbMetric: 27.6170 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 162/1000
2023-09-12 22:15:06.668 
Epoch 162/1000 
	 loss: 27.4678, MinusLogProbMetric: 27.4678, val_loss: 27.6960, val_MinusLogProbMetric: 27.6960

Epoch 162: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4678 - MinusLogProbMetric: 27.4678 - val_loss: 27.6960 - val_MinusLogProbMetric: 27.6960 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 163/1000
2023-09-12 22:15:15.936 
Epoch 163/1000 
	 loss: 27.4765, MinusLogProbMetric: 27.4765, val_loss: 27.6640, val_MinusLogProbMetric: 27.6640

Epoch 163: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4765 - MinusLogProbMetric: 27.4765 - val_loss: 27.6640 - val_MinusLogProbMetric: 27.6640 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 164/1000
2023-09-12 22:15:26.228 
Epoch 164/1000 
	 loss: 27.4638, MinusLogProbMetric: 27.4638, val_loss: 27.6597, val_MinusLogProbMetric: 27.6597

Epoch 164: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4638 - MinusLogProbMetric: 27.4638 - val_loss: 27.6597 - val_MinusLogProbMetric: 27.6597 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 165/1000
2023-09-12 22:15:35.615 
Epoch 165/1000 
	 loss: 27.4690, MinusLogProbMetric: 27.4690, val_loss: 27.6785, val_MinusLogProbMetric: 27.6785

Epoch 165: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4690 - MinusLogProbMetric: 27.4690 - val_loss: 27.6785 - val_MinusLogProbMetric: 27.6785 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 166/1000
2023-09-12 22:15:44.127 
Epoch 166/1000 
	 loss: 27.4674, MinusLogProbMetric: 27.4674, val_loss: 27.7065, val_MinusLogProbMetric: 27.7065

Epoch 166: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4674 - MinusLogProbMetric: 27.4674 - val_loss: 27.7065 - val_MinusLogProbMetric: 27.7065 - lr: 0.0010 - 9s/epoch - 43ms/step
Epoch 167/1000
2023-09-12 22:15:52.575 
Epoch 167/1000 
	 loss: 27.4710, MinusLogProbMetric: 27.4710, val_loss: 27.6636, val_MinusLogProbMetric: 27.6636

Epoch 167: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.4710 - MinusLogProbMetric: 27.4710 - val_loss: 27.6636 - val_MinusLogProbMetric: 27.6636 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 168/1000
2023-09-12 22:16:01.147 
Epoch 168/1000 
	 loss: 27.4606, MinusLogProbMetric: 27.4606, val_loss: 27.7068, val_MinusLogProbMetric: 27.7068

Epoch 168: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4606 - MinusLogProbMetric: 27.4606 - val_loss: 27.7068 - val_MinusLogProbMetric: 27.7068 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 169/1000
2023-09-12 22:16:09.592 
Epoch 169/1000 
	 loss: 27.4733, MinusLogProbMetric: 27.4733, val_loss: 27.6572, val_MinusLogProbMetric: 27.6572

Epoch 169: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.4733 - MinusLogProbMetric: 27.4733 - val_loss: 27.6572 - val_MinusLogProbMetric: 27.6572 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 170/1000
2023-09-12 22:16:18.190 
Epoch 170/1000 
	 loss: 27.4587, MinusLogProbMetric: 27.4587, val_loss: 27.6164, val_MinusLogProbMetric: 27.6164

Epoch 170: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4587 - MinusLogProbMetric: 27.4587 - val_loss: 27.6164 - val_MinusLogProbMetric: 27.6164 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 171/1000
2023-09-12 22:16:27.846 
Epoch 171/1000 
	 loss: 27.4777, MinusLogProbMetric: 27.4777, val_loss: 27.6271, val_MinusLogProbMetric: 27.6271

Epoch 171: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4777 - MinusLogProbMetric: 27.4777 - val_loss: 27.6271 - val_MinusLogProbMetric: 27.6271 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 172/1000
2023-09-12 22:16:36.449 
Epoch 172/1000 
	 loss: 27.4639, MinusLogProbMetric: 27.4639, val_loss: 27.6628, val_MinusLogProbMetric: 27.6628

Epoch 172: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4639 - MinusLogProbMetric: 27.4639 - val_loss: 27.6628 - val_MinusLogProbMetric: 27.6628 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 173/1000
2023-09-12 22:16:45.172 
Epoch 173/1000 
	 loss: 27.4635, MinusLogProbMetric: 27.4635, val_loss: 27.6282, val_MinusLogProbMetric: 27.6282

Epoch 173: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4635 - MinusLogProbMetric: 27.4635 - val_loss: 27.6282 - val_MinusLogProbMetric: 27.6282 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 174/1000
2023-09-12 22:16:53.743 
Epoch 174/1000 
	 loss: 27.4596, MinusLogProbMetric: 27.4596, val_loss: 27.6756, val_MinusLogProbMetric: 27.6756

Epoch 174: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4596 - MinusLogProbMetric: 27.4596 - val_loss: 27.6756 - val_MinusLogProbMetric: 27.6756 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 175/1000
2023-09-12 22:17:02.317 
Epoch 175/1000 
	 loss: 27.4593, MinusLogProbMetric: 27.4593, val_loss: 27.6359, val_MinusLogProbMetric: 27.6359

Epoch 175: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4593 - MinusLogProbMetric: 27.4593 - val_loss: 27.6359 - val_MinusLogProbMetric: 27.6359 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 176/1000
2023-09-12 22:17:12.175 
Epoch 176/1000 
	 loss: 27.4633, MinusLogProbMetric: 27.4633, val_loss: 27.7456, val_MinusLogProbMetric: 27.7456

Epoch 176: val_loss did not improve from 27.60226
196/196 - 10s - loss: 27.4633 - MinusLogProbMetric: 27.4633 - val_loss: 27.7456 - val_MinusLogProbMetric: 27.7456 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 177/1000
2023-09-12 22:17:20.664 
Epoch 177/1000 
	 loss: 27.4533, MinusLogProbMetric: 27.4533, val_loss: 27.6634, val_MinusLogProbMetric: 27.6634

Epoch 177: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.4533 - MinusLogProbMetric: 27.4533 - val_loss: 27.6634 - val_MinusLogProbMetric: 27.6634 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 178/1000
2023-09-12 22:17:29.190 
Epoch 178/1000 
	 loss: 27.4533, MinusLogProbMetric: 27.4533, val_loss: 27.6731, val_MinusLogProbMetric: 27.6731

Epoch 178: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4533 - MinusLogProbMetric: 27.4533 - val_loss: 27.6731 - val_MinusLogProbMetric: 27.6731 - lr: 0.0010 - 9s/epoch - 43ms/step
Epoch 179/1000
2023-09-12 22:17:37.757 
Epoch 179/1000 
	 loss: 27.4668, MinusLogProbMetric: 27.4668, val_loss: 27.6244, val_MinusLogProbMetric: 27.6244

Epoch 179: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4668 - MinusLogProbMetric: 27.4668 - val_loss: 27.6244 - val_MinusLogProbMetric: 27.6244 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 180/1000
2023-09-12 22:17:46.405 
Epoch 180/1000 
	 loss: 27.4414, MinusLogProbMetric: 27.4414, val_loss: 27.6186, val_MinusLogProbMetric: 27.6186

Epoch 180: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4414 - MinusLogProbMetric: 27.4414 - val_loss: 27.6186 - val_MinusLogProbMetric: 27.6186 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 181/1000
2023-09-12 22:17:54.851 
Epoch 181/1000 
	 loss: 27.4476, MinusLogProbMetric: 27.4476, val_loss: 27.6637, val_MinusLogProbMetric: 27.6637

Epoch 181: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.4476 - MinusLogProbMetric: 27.4476 - val_loss: 27.6637 - val_MinusLogProbMetric: 27.6637 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 182/1000
2023-09-12 22:18:03.365 
Epoch 182/1000 
	 loss: 27.4451, MinusLogProbMetric: 27.4451, val_loss: 27.6711, val_MinusLogProbMetric: 27.6711

Epoch 182: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4451 - MinusLogProbMetric: 27.4451 - val_loss: 27.6711 - val_MinusLogProbMetric: 27.6711 - lr: 0.0010 - 9s/epoch - 43ms/step
Epoch 183/1000
2023-09-12 22:18:12.506 
Epoch 183/1000 
	 loss: 27.4531, MinusLogProbMetric: 27.4531, val_loss: 27.6609, val_MinusLogProbMetric: 27.6609

Epoch 183: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4531 - MinusLogProbMetric: 27.4531 - val_loss: 27.6609 - val_MinusLogProbMetric: 27.6609 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 184/1000
2023-09-12 22:18:23.158 
Epoch 184/1000 
	 loss: 27.4522, MinusLogProbMetric: 27.4522, val_loss: 27.6431, val_MinusLogProbMetric: 27.6431

Epoch 184: val_loss did not improve from 27.60226
196/196 - 11s - loss: 27.4522 - MinusLogProbMetric: 27.4522 - val_loss: 27.6431 - val_MinusLogProbMetric: 27.6431 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 185/1000
2023-09-12 22:18:32.055 
Epoch 185/1000 
	 loss: 27.4421, MinusLogProbMetric: 27.4421, val_loss: 27.6533, val_MinusLogProbMetric: 27.6533

Epoch 185: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4421 - MinusLogProbMetric: 27.4421 - val_loss: 27.6533 - val_MinusLogProbMetric: 27.6533 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 186/1000
2023-09-12 22:18:40.614 
Epoch 186/1000 
	 loss: 27.4469, MinusLogProbMetric: 27.4469, val_loss: 27.6027, val_MinusLogProbMetric: 27.6027

Epoch 186: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4469 - MinusLogProbMetric: 27.4469 - val_loss: 27.6027 - val_MinusLogProbMetric: 27.6027 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 187/1000
2023-09-12 22:18:49.378 
Epoch 187/1000 
	 loss: 27.4412, MinusLogProbMetric: 27.4412, val_loss: 27.6410, val_MinusLogProbMetric: 27.6410

Epoch 187: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4412 - MinusLogProbMetric: 27.4412 - val_loss: 27.6410 - val_MinusLogProbMetric: 27.6410 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 188/1000
2023-09-12 22:18:57.966 
Epoch 188/1000 
	 loss: 27.4517, MinusLogProbMetric: 27.4517, val_loss: 27.6199, val_MinusLogProbMetric: 27.6199

Epoch 188: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4517 - MinusLogProbMetric: 27.4517 - val_loss: 27.6199 - val_MinusLogProbMetric: 27.6199 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 189/1000
2023-09-12 22:19:06.491 
Epoch 189/1000 
	 loss: 27.4442, MinusLogProbMetric: 27.4442, val_loss: 27.6637, val_MinusLogProbMetric: 27.6637

Epoch 189: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4442 - MinusLogProbMetric: 27.4442 - val_loss: 27.6637 - val_MinusLogProbMetric: 27.6637 - lr: 0.0010 - 9s/epoch - 43ms/step
Epoch 190/1000
2023-09-12 22:19:15.101 
Epoch 190/1000 
	 loss: 27.4564, MinusLogProbMetric: 27.4564, val_loss: 27.6569, val_MinusLogProbMetric: 27.6569

Epoch 190: val_loss did not improve from 27.60226
196/196 - 9s - loss: 27.4564 - MinusLogProbMetric: 27.4564 - val_loss: 27.6569 - val_MinusLogProbMetric: 27.6569 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 191/1000
2023-09-12 22:19:23.537 
Epoch 191/1000 
	 loss: 27.3711, MinusLogProbMetric: 27.3711, val_loss: 27.6059, val_MinusLogProbMetric: 27.6059

Epoch 191: val_loss did not improve from 27.60226
196/196 - 8s - loss: 27.3711 - MinusLogProbMetric: 27.3711 - val_loss: 27.6059 - val_MinusLogProbMetric: 27.6059 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 192/1000
2023-09-12 22:19:33.562 
Epoch 192/1000 
	 loss: 27.3639, MinusLogProbMetric: 27.3639, val_loss: 27.5599, val_MinusLogProbMetric: 27.5599

Epoch 192: val_loss improved from 27.60226 to 27.55995, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 10s - loss: 27.3639 - MinusLogProbMetric: 27.3639 - val_loss: 27.5599 - val_MinusLogProbMetric: 27.5599 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 193/1000
2023-09-12 22:19:44.268 
Epoch 193/1000 
	 loss: 27.3584, MinusLogProbMetric: 27.3584, val_loss: 27.5601, val_MinusLogProbMetric: 27.5601

Epoch 193: val_loss did not improve from 27.55995
196/196 - 11s - loss: 27.3584 - MinusLogProbMetric: 27.3584 - val_loss: 27.5601 - val_MinusLogProbMetric: 27.5601 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 194/1000
2023-09-12 22:19:53.780 
Epoch 194/1000 
	 loss: 27.3606, MinusLogProbMetric: 27.3606, val_loss: 27.5793, val_MinusLogProbMetric: 27.5793

Epoch 194: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3606 - MinusLogProbMetric: 27.3606 - val_loss: 27.5793 - val_MinusLogProbMetric: 27.5793 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 195/1000
2023-09-12 22:20:02.390 
Epoch 195/1000 
	 loss: 27.3579, MinusLogProbMetric: 27.3579, val_loss: 27.5750, val_MinusLogProbMetric: 27.5750

Epoch 195: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3579 - MinusLogProbMetric: 27.3579 - val_loss: 27.5750 - val_MinusLogProbMetric: 27.5750 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 196/1000
2023-09-12 22:20:10.874 
Epoch 196/1000 
	 loss: 27.3614, MinusLogProbMetric: 27.3614, val_loss: 27.5642, val_MinusLogProbMetric: 27.5642

Epoch 196: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3614 - MinusLogProbMetric: 27.3614 - val_loss: 27.5642 - val_MinusLogProbMetric: 27.5642 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 197/1000
2023-09-12 22:20:19.216 
Epoch 197/1000 
	 loss: 27.3590, MinusLogProbMetric: 27.3590, val_loss: 27.5844, val_MinusLogProbMetric: 27.5844

Epoch 197: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3590 - MinusLogProbMetric: 27.3590 - val_loss: 27.5844 - val_MinusLogProbMetric: 27.5844 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 198/1000
2023-09-12 22:20:28.607 
Epoch 198/1000 
	 loss: 27.3598, MinusLogProbMetric: 27.3598, val_loss: 27.5808, val_MinusLogProbMetric: 27.5808

Epoch 198: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3598 - MinusLogProbMetric: 27.3598 - val_loss: 27.5808 - val_MinusLogProbMetric: 27.5808 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 199/1000
2023-09-12 22:20:37.036 
Epoch 199/1000 
	 loss: 27.3621, MinusLogProbMetric: 27.3621, val_loss: 27.5912, val_MinusLogProbMetric: 27.5912

Epoch 199: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3621 - MinusLogProbMetric: 27.3621 - val_loss: 27.5912 - val_MinusLogProbMetric: 27.5912 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 200/1000
2023-09-12 22:20:46.748 
Epoch 200/1000 
	 loss: 27.3590, MinusLogProbMetric: 27.3590, val_loss: 27.5709, val_MinusLogProbMetric: 27.5709

Epoch 200: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3590 - MinusLogProbMetric: 27.3590 - val_loss: 27.5709 - val_MinusLogProbMetric: 27.5709 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 201/1000
2023-09-12 22:20:55.683 
Epoch 201/1000 
	 loss: 27.3579, MinusLogProbMetric: 27.3579, val_loss: 27.5871, val_MinusLogProbMetric: 27.5871

Epoch 201: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3579 - MinusLogProbMetric: 27.3579 - val_loss: 27.5871 - val_MinusLogProbMetric: 27.5871 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 202/1000
2023-09-12 22:21:04.333 
Epoch 202/1000 
	 loss: 27.3614, MinusLogProbMetric: 27.3614, val_loss: 27.5727, val_MinusLogProbMetric: 27.5727

Epoch 202: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3614 - MinusLogProbMetric: 27.3614 - val_loss: 27.5727 - val_MinusLogProbMetric: 27.5727 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 203/1000
2023-09-12 22:21:14.665 
Epoch 203/1000 
	 loss: 27.3622, MinusLogProbMetric: 27.3622, val_loss: 27.5605, val_MinusLogProbMetric: 27.5605

Epoch 203: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3622 - MinusLogProbMetric: 27.3622 - val_loss: 27.5605 - val_MinusLogProbMetric: 27.5605 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 204/1000
2023-09-12 22:21:23.356 
Epoch 204/1000 
	 loss: 27.3535, MinusLogProbMetric: 27.3535, val_loss: 27.5900, val_MinusLogProbMetric: 27.5900

Epoch 204: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3535 - MinusLogProbMetric: 27.3535 - val_loss: 27.5900 - val_MinusLogProbMetric: 27.5900 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 205/1000
2023-09-12 22:21:32.863 
Epoch 205/1000 
	 loss: 27.3568, MinusLogProbMetric: 27.3568, val_loss: 27.5703, val_MinusLogProbMetric: 27.5703

Epoch 205: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3568 - MinusLogProbMetric: 27.3568 - val_loss: 27.5703 - val_MinusLogProbMetric: 27.5703 - lr: 5.0000e-04 - 10s/epoch - 48ms/step
Epoch 206/1000
2023-09-12 22:21:41.772 
Epoch 206/1000 
	 loss: 27.3535, MinusLogProbMetric: 27.3535, val_loss: 27.5730, val_MinusLogProbMetric: 27.5730

Epoch 206: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3535 - MinusLogProbMetric: 27.3535 - val_loss: 27.5730 - val_MinusLogProbMetric: 27.5730 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 207/1000
2023-09-12 22:21:51.169 
Epoch 207/1000 
	 loss: 27.3565, MinusLogProbMetric: 27.3565, val_loss: 27.5906, val_MinusLogProbMetric: 27.5906

Epoch 207: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3565 - MinusLogProbMetric: 27.3565 - val_loss: 27.5906 - val_MinusLogProbMetric: 27.5906 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 208/1000
2023-09-12 22:21:59.616 
Epoch 208/1000 
	 loss: 27.3512, MinusLogProbMetric: 27.3512, val_loss: 27.5720, val_MinusLogProbMetric: 27.5720

Epoch 208: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3512 - MinusLogProbMetric: 27.3512 - val_loss: 27.5720 - val_MinusLogProbMetric: 27.5720 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 209/1000
2023-09-12 22:22:09.663 
Epoch 209/1000 
	 loss: 27.3574, MinusLogProbMetric: 27.3574, val_loss: 27.6258, val_MinusLogProbMetric: 27.6258

Epoch 209: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3574 - MinusLogProbMetric: 27.3574 - val_loss: 27.6258 - val_MinusLogProbMetric: 27.6258 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 210/1000
2023-09-12 22:22:18.365 
Epoch 210/1000 
	 loss: 27.3504, MinusLogProbMetric: 27.3504, val_loss: 27.5798, val_MinusLogProbMetric: 27.5798

Epoch 210: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3504 - MinusLogProbMetric: 27.3504 - val_loss: 27.5798 - val_MinusLogProbMetric: 27.5798 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 211/1000
2023-09-12 22:22:27.656 
Epoch 211/1000 
	 loss: 27.3591, MinusLogProbMetric: 27.3591, val_loss: 27.5740, val_MinusLogProbMetric: 27.5740

Epoch 211: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3591 - MinusLogProbMetric: 27.3591 - val_loss: 27.5740 - val_MinusLogProbMetric: 27.5740 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 212/1000
2023-09-12 22:22:37.198 
Epoch 212/1000 
	 loss: 27.3526, MinusLogProbMetric: 27.3526, val_loss: 27.5679, val_MinusLogProbMetric: 27.5679

Epoch 212: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3526 - MinusLogProbMetric: 27.3526 - val_loss: 27.5679 - val_MinusLogProbMetric: 27.5679 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 213/1000
2023-09-12 22:22:46.884 
Epoch 213/1000 
	 loss: 27.3543, MinusLogProbMetric: 27.3543, val_loss: 27.5914, val_MinusLogProbMetric: 27.5914

Epoch 213: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3543 - MinusLogProbMetric: 27.3543 - val_loss: 27.5914 - val_MinusLogProbMetric: 27.5914 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 214/1000
2023-09-12 22:22:56.908 
Epoch 214/1000 
	 loss: 27.3568, MinusLogProbMetric: 27.3568, val_loss: 27.5773, val_MinusLogProbMetric: 27.5773

Epoch 214: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3568 - MinusLogProbMetric: 27.3568 - val_loss: 27.5773 - val_MinusLogProbMetric: 27.5773 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 215/1000
2023-09-12 22:23:05.537 
Epoch 215/1000 
	 loss: 27.3524, MinusLogProbMetric: 27.3524, val_loss: 27.5968, val_MinusLogProbMetric: 27.5968

Epoch 215: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3524 - MinusLogProbMetric: 27.3524 - val_loss: 27.5968 - val_MinusLogProbMetric: 27.5968 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 216/1000
2023-09-12 22:23:14.387 
Epoch 216/1000 
	 loss: 27.3517, MinusLogProbMetric: 27.3517, val_loss: 27.5748, val_MinusLogProbMetric: 27.5748

Epoch 216: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3517 - MinusLogProbMetric: 27.3517 - val_loss: 27.5748 - val_MinusLogProbMetric: 27.5748 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 217/1000
2023-09-12 22:23:22.868 
Epoch 217/1000 
	 loss: 27.3539, MinusLogProbMetric: 27.3539, val_loss: 27.5894, val_MinusLogProbMetric: 27.5894

Epoch 217: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3539 - MinusLogProbMetric: 27.3539 - val_loss: 27.5894 - val_MinusLogProbMetric: 27.5894 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 218/1000
2023-09-12 22:23:31.568 
Epoch 218/1000 
	 loss: 27.3497, MinusLogProbMetric: 27.3497, val_loss: 27.5678, val_MinusLogProbMetric: 27.5678

Epoch 218: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3497 - MinusLogProbMetric: 27.3497 - val_loss: 27.5678 - val_MinusLogProbMetric: 27.5678 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 219/1000
2023-09-12 22:23:40.355 
Epoch 219/1000 
	 loss: 27.3501, MinusLogProbMetric: 27.3501, val_loss: 27.5777, val_MinusLogProbMetric: 27.5777

Epoch 219: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3501 - MinusLogProbMetric: 27.3501 - val_loss: 27.5777 - val_MinusLogProbMetric: 27.5777 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 220/1000
2023-09-12 22:23:48.709 
Epoch 220/1000 
	 loss: 27.3476, MinusLogProbMetric: 27.3476, val_loss: 27.5747, val_MinusLogProbMetric: 27.5747

Epoch 220: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3476 - MinusLogProbMetric: 27.3476 - val_loss: 27.5747 - val_MinusLogProbMetric: 27.5747 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 221/1000
2023-09-12 22:23:57.183 
Epoch 221/1000 
	 loss: 27.3541, MinusLogProbMetric: 27.3541, val_loss: 27.6011, val_MinusLogProbMetric: 27.6011

Epoch 221: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3541 - MinusLogProbMetric: 27.3541 - val_loss: 27.6011 - val_MinusLogProbMetric: 27.6011 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 222/1000
2023-09-12 22:24:05.856 
Epoch 222/1000 
	 loss: 27.3535, MinusLogProbMetric: 27.3535, val_loss: 27.5733, val_MinusLogProbMetric: 27.5733

Epoch 222: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3535 - MinusLogProbMetric: 27.3535 - val_loss: 27.5733 - val_MinusLogProbMetric: 27.5733 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 223/1000
2023-09-12 22:24:14.720 
Epoch 223/1000 
	 loss: 27.3505, MinusLogProbMetric: 27.3505, val_loss: 27.5686, val_MinusLogProbMetric: 27.5686

Epoch 223: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3505 - MinusLogProbMetric: 27.3505 - val_loss: 27.5686 - val_MinusLogProbMetric: 27.5686 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 224/1000
2023-09-12 22:24:23.298 
Epoch 224/1000 
	 loss: 27.3496, MinusLogProbMetric: 27.3496, val_loss: 27.5687, val_MinusLogProbMetric: 27.5687

Epoch 224: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3496 - MinusLogProbMetric: 27.3496 - val_loss: 27.5687 - val_MinusLogProbMetric: 27.5687 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 225/1000
2023-09-12 22:24:32.285 
Epoch 225/1000 
	 loss: 27.3451, MinusLogProbMetric: 27.3451, val_loss: 27.6113, val_MinusLogProbMetric: 27.6113

Epoch 225: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3451 - MinusLogProbMetric: 27.3451 - val_loss: 27.6113 - val_MinusLogProbMetric: 27.6113 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 226/1000
2023-09-12 22:24:41.564 
Epoch 226/1000 
	 loss: 27.3532, MinusLogProbMetric: 27.3532, val_loss: 27.5904, val_MinusLogProbMetric: 27.5904

Epoch 226: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3532 - MinusLogProbMetric: 27.3532 - val_loss: 27.5904 - val_MinusLogProbMetric: 27.5904 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 227/1000
2023-09-12 22:24:52.171 
Epoch 227/1000 
	 loss: 27.3498, MinusLogProbMetric: 27.3498, val_loss: 27.5798, val_MinusLogProbMetric: 27.5798

Epoch 227: val_loss did not improve from 27.55995
196/196 - 11s - loss: 27.3498 - MinusLogProbMetric: 27.3498 - val_loss: 27.5798 - val_MinusLogProbMetric: 27.5798 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 228/1000
2023-09-12 22:25:02.614 
Epoch 228/1000 
	 loss: 27.3507, MinusLogProbMetric: 27.3507, val_loss: 27.6016, val_MinusLogProbMetric: 27.6016

Epoch 228: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3507 - MinusLogProbMetric: 27.3507 - val_loss: 27.6016 - val_MinusLogProbMetric: 27.6016 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 229/1000
2023-09-12 22:25:11.787 
Epoch 229/1000 
	 loss: 27.3460, MinusLogProbMetric: 27.3460, val_loss: 27.5745, val_MinusLogProbMetric: 27.5745

Epoch 229: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3460 - MinusLogProbMetric: 27.3460 - val_loss: 27.5745 - val_MinusLogProbMetric: 27.5745 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 230/1000
2023-09-12 22:25:20.475 
Epoch 230/1000 
	 loss: 27.3475, MinusLogProbMetric: 27.3475, val_loss: 27.5854, val_MinusLogProbMetric: 27.5854

Epoch 230: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3475 - MinusLogProbMetric: 27.3475 - val_loss: 27.5854 - val_MinusLogProbMetric: 27.5854 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 231/1000
2023-09-12 22:25:28.929 
Epoch 231/1000 
	 loss: 27.3529, MinusLogProbMetric: 27.3529, val_loss: 27.5972, val_MinusLogProbMetric: 27.5972

Epoch 231: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3529 - MinusLogProbMetric: 27.3529 - val_loss: 27.5972 - val_MinusLogProbMetric: 27.5972 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 232/1000
2023-09-12 22:25:37.517 
Epoch 232/1000 
	 loss: 27.3474, MinusLogProbMetric: 27.3474, val_loss: 27.5661, val_MinusLogProbMetric: 27.5661

Epoch 232: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3474 - MinusLogProbMetric: 27.3474 - val_loss: 27.5661 - val_MinusLogProbMetric: 27.5661 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 233/1000
2023-09-12 22:25:47.393 
Epoch 233/1000 
	 loss: 27.3438, MinusLogProbMetric: 27.3438, val_loss: 27.6106, val_MinusLogProbMetric: 27.6106

Epoch 233: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3438 - MinusLogProbMetric: 27.3438 - val_loss: 27.6106 - val_MinusLogProbMetric: 27.6106 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 234/1000
2023-09-12 22:25:57.760 
Epoch 234/1000 
	 loss: 27.3515, MinusLogProbMetric: 27.3515, val_loss: 27.5734, val_MinusLogProbMetric: 27.5734

Epoch 234: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3515 - MinusLogProbMetric: 27.3515 - val_loss: 27.5734 - val_MinusLogProbMetric: 27.5734 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 235/1000
2023-09-12 22:26:07.980 
Epoch 235/1000 
	 loss: 27.3440, MinusLogProbMetric: 27.3440, val_loss: 27.5609, val_MinusLogProbMetric: 27.5609

Epoch 235: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3440 - MinusLogProbMetric: 27.3440 - val_loss: 27.5609 - val_MinusLogProbMetric: 27.5609 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 236/1000
2023-09-12 22:26:16.475 
Epoch 236/1000 
	 loss: 27.3481, MinusLogProbMetric: 27.3481, val_loss: 27.6063, val_MinusLogProbMetric: 27.6063

Epoch 236: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3481 - MinusLogProbMetric: 27.3481 - val_loss: 27.6063 - val_MinusLogProbMetric: 27.6063 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 237/1000
2023-09-12 22:26:24.807 
Epoch 237/1000 
	 loss: 27.3478, MinusLogProbMetric: 27.3478, val_loss: 27.5800, val_MinusLogProbMetric: 27.5800

Epoch 237: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3478 - MinusLogProbMetric: 27.3478 - val_loss: 27.5800 - val_MinusLogProbMetric: 27.5800 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 238/1000
2023-09-12 22:26:33.402 
Epoch 238/1000 
	 loss: 27.3472, MinusLogProbMetric: 27.3472, val_loss: 27.5770, val_MinusLogProbMetric: 27.5770

Epoch 238: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3472 - MinusLogProbMetric: 27.3472 - val_loss: 27.5770 - val_MinusLogProbMetric: 27.5770 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 239/1000
2023-09-12 22:26:42.659 
Epoch 239/1000 
	 loss: 27.3482, MinusLogProbMetric: 27.3482, val_loss: 27.5690, val_MinusLogProbMetric: 27.5690

Epoch 239: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3482 - MinusLogProbMetric: 27.3482 - val_loss: 27.5690 - val_MinusLogProbMetric: 27.5690 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 240/1000
2023-09-12 22:26:52.249 
Epoch 240/1000 
	 loss: 27.3442, MinusLogProbMetric: 27.3442, val_loss: 27.5838, val_MinusLogProbMetric: 27.5838

Epoch 240: val_loss did not improve from 27.55995
196/196 - 10s - loss: 27.3442 - MinusLogProbMetric: 27.3442 - val_loss: 27.5838 - val_MinusLogProbMetric: 27.5838 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 241/1000
2023-09-12 22:27:01.276 
Epoch 241/1000 
	 loss: 27.3499, MinusLogProbMetric: 27.3499, val_loss: 27.5973, val_MinusLogProbMetric: 27.5973

Epoch 241: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3499 - MinusLogProbMetric: 27.3499 - val_loss: 27.5973 - val_MinusLogProbMetric: 27.5973 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 242/1000
2023-09-12 22:27:09.608 
Epoch 242/1000 
	 loss: 27.3471, MinusLogProbMetric: 27.3471, val_loss: 27.5888, val_MinusLogProbMetric: 27.5888

Epoch 242: val_loss did not improve from 27.55995
196/196 - 8s - loss: 27.3471 - MinusLogProbMetric: 27.3471 - val_loss: 27.5888 - val_MinusLogProbMetric: 27.5888 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 243/1000
2023-09-12 22:27:18.153 
Epoch 243/1000 
	 loss: 27.3067, MinusLogProbMetric: 27.3067, val_loss: 27.5639, val_MinusLogProbMetric: 27.5639

Epoch 243: val_loss did not improve from 27.55995
196/196 - 9s - loss: 27.3067 - MinusLogProbMetric: 27.3067 - val_loss: 27.5639 - val_MinusLogProbMetric: 27.5639 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 244/1000
2023-09-12 22:27:26.626 
Epoch 244/1000 
	 loss: 27.3038, MinusLogProbMetric: 27.3038, val_loss: 27.5493, val_MinusLogProbMetric: 27.5493

Epoch 244: val_loss improved from 27.55995 to 27.54928, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 27.3038 - MinusLogProbMetric: 27.3038 - val_loss: 27.5493 - val_MinusLogProbMetric: 27.5493 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 245/1000
2023-09-12 22:27:35.239 
Epoch 245/1000 
	 loss: 27.3054, MinusLogProbMetric: 27.3054, val_loss: 27.5427, val_MinusLogProbMetric: 27.5427

Epoch 245: val_loss improved from 27.54928 to 27.54274, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 27.3054 - MinusLogProbMetric: 27.3054 - val_loss: 27.5427 - val_MinusLogProbMetric: 27.5427 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 246/1000
2023-09-12 22:27:43.957 
Epoch 246/1000 
	 loss: 27.3060, MinusLogProbMetric: 27.3060, val_loss: 27.5448, val_MinusLogProbMetric: 27.5448

Epoch 246: val_loss did not improve from 27.54274
196/196 - 9s - loss: 27.3060 - MinusLogProbMetric: 27.3060 - val_loss: 27.5448 - val_MinusLogProbMetric: 27.5448 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 247/1000
2023-09-12 22:27:52.508 
Epoch 247/1000 
	 loss: 27.3010, MinusLogProbMetric: 27.3010, val_loss: 27.5424, val_MinusLogProbMetric: 27.5424

Epoch 247: val_loss improved from 27.54274 to 27.54240, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 27.3010 - MinusLogProbMetric: 27.3010 - val_loss: 27.5424 - val_MinusLogProbMetric: 27.5424 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 248/1000
2023-09-12 22:28:01.306 
Epoch 248/1000 
	 loss: 27.3062, MinusLogProbMetric: 27.3062, val_loss: 27.5453, val_MinusLogProbMetric: 27.5453

Epoch 248: val_loss did not improve from 27.54240
196/196 - 9s - loss: 27.3062 - MinusLogProbMetric: 27.3062 - val_loss: 27.5453 - val_MinusLogProbMetric: 27.5453 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 249/1000
2023-09-12 22:28:09.885 
Epoch 249/1000 
	 loss: 27.3011, MinusLogProbMetric: 27.3011, val_loss: 27.5527, val_MinusLogProbMetric: 27.5527

Epoch 249: val_loss did not improve from 27.54240
196/196 - 9s - loss: 27.3011 - MinusLogProbMetric: 27.3011 - val_loss: 27.5527 - val_MinusLogProbMetric: 27.5527 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 250/1000
2023-09-12 22:28:18.383 
Epoch 250/1000 
	 loss: 27.3042, MinusLogProbMetric: 27.3042, val_loss: 27.5449, val_MinusLogProbMetric: 27.5449

Epoch 250: val_loss did not improve from 27.54240
196/196 - 8s - loss: 27.3042 - MinusLogProbMetric: 27.3042 - val_loss: 27.5449 - val_MinusLogProbMetric: 27.5449 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 251/1000
2023-09-12 22:28:27.105 
Epoch 251/1000 
	 loss: 27.3025, MinusLogProbMetric: 27.3025, val_loss: 27.5516, val_MinusLogProbMetric: 27.5516

Epoch 251: val_loss did not improve from 27.54240
196/196 - 9s - loss: 27.3025 - MinusLogProbMetric: 27.3025 - val_loss: 27.5516 - val_MinusLogProbMetric: 27.5516 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 252/1000
2023-09-12 22:28:35.762 
Epoch 252/1000 
	 loss: 27.3033, MinusLogProbMetric: 27.3033, val_loss: 27.5415, val_MinusLogProbMetric: 27.5415

Epoch 252: val_loss improved from 27.54240 to 27.54146, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 9s - loss: 27.3033 - MinusLogProbMetric: 27.3033 - val_loss: 27.5415 - val_MinusLogProbMetric: 27.5415 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 253/1000
2023-09-12 22:28:44.487 
Epoch 253/1000 
	 loss: 27.3038, MinusLogProbMetric: 27.3038, val_loss: 27.5487, val_MinusLogProbMetric: 27.5487

Epoch 253: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3038 - MinusLogProbMetric: 27.3038 - val_loss: 27.5487 - val_MinusLogProbMetric: 27.5487 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 254/1000
2023-09-12 22:28:53.664 
Epoch 254/1000 
	 loss: 27.3022, MinusLogProbMetric: 27.3022, val_loss: 27.5442, val_MinusLogProbMetric: 27.5442

Epoch 254: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3022 - MinusLogProbMetric: 27.3022 - val_loss: 27.5442 - val_MinusLogProbMetric: 27.5442 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 255/1000
2023-09-12 22:29:02.390 
Epoch 255/1000 
	 loss: 27.3025, MinusLogProbMetric: 27.3025, val_loss: 27.5460, val_MinusLogProbMetric: 27.5460

Epoch 255: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3025 - MinusLogProbMetric: 27.3025 - val_loss: 27.5460 - val_MinusLogProbMetric: 27.5460 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 256/1000
2023-09-12 22:29:10.754 
Epoch 256/1000 
	 loss: 27.3003, MinusLogProbMetric: 27.3003, val_loss: 27.5497, val_MinusLogProbMetric: 27.5497

Epoch 256: val_loss did not improve from 27.54146
196/196 - 8s - loss: 27.3003 - MinusLogProbMetric: 27.3003 - val_loss: 27.5497 - val_MinusLogProbMetric: 27.5497 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 257/1000
2023-09-12 22:29:19.317 
Epoch 257/1000 
	 loss: 27.3023, MinusLogProbMetric: 27.3023, val_loss: 27.5456, val_MinusLogProbMetric: 27.5456

Epoch 257: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3023 - MinusLogProbMetric: 27.3023 - val_loss: 27.5456 - val_MinusLogProbMetric: 27.5456 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 258/1000
2023-09-12 22:29:27.867 
Epoch 258/1000 
	 loss: 27.3054, MinusLogProbMetric: 27.3054, val_loss: 27.5468, val_MinusLogProbMetric: 27.5468

Epoch 258: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3054 - MinusLogProbMetric: 27.3054 - val_loss: 27.5468 - val_MinusLogProbMetric: 27.5468 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 259/1000
2023-09-12 22:29:36.470 
Epoch 259/1000 
	 loss: 27.3012, MinusLogProbMetric: 27.3012, val_loss: 27.5433, val_MinusLogProbMetric: 27.5433

Epoch 259: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3012 - MinusLogProbMetric: 27.3012 - val_loss: 27.5433 - val_MinusLogProbMetric: 27.5433 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 260/1000
2023-09-12 22:29:44.754 
Epoch 260/1000 
	 loss: 27.3044, MinusLogProbMetric: 27.3044, val_loss: 27.5490, val_MinusLogProbMetric: 27.5490

Epoch 260: val_loss did not improve from 27.54146
196/196 - 8s - loss: 27.3044 - MinusLogProbMetric: 27.3044 - val_loss: 27.5490 - val_MinusLogProbMetric: 27.5490 - lr: 2.5000e-04 - 8s/epoch - 42ms/step
Epoch 261/1000
2023-09-12 22:29:53.226 
Epoch 261/1000 
	 loss: 27.3019, MinusLogProbMetric: 27.3019, val_loss: 27.5514, val_MinusLogProbMetric: 27.5514

Epoch 261: val_loss did not improve from 27.54146
196/196 - 8s - loss: 27.3019 - MinusLogProbMetric: 27.3019 - val_loss: 27.5514 - val_MinusLogProbMetric: 27.5514 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 262/1000
2023-09-12 22:30:01.782 
Epoch 262/1000 
	 loss: 27.3033, MinusLogProbMetric: 27.3033, val_loss: 27.5625, val_MinusLogProbMetric: 27.5625

Epoch 262: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3033 - MinusLogProbMetric: 27.3033 - val_loss: 27.5625 - val_MinusLogProbMetric: 27.5625 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 263/1000
2023-09-12 22:30:10.395 
Epoch 263/1000 
	 loss: 27.3001, MinusLogProbMetric: 27.3001, val_loss: 27.5531, val_MinusLogProbMetric: 27.5531

Epoch 263: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3001 - MinusLogProbMetric: 27.3001 - val_loss: 27.5531 - val_MinusLogProbMetric: 27.5531 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 264/1000
2023-09-12 22:30:19.057 
Epoch 264/1000 
	 loss: 27.3007, MinusLogProbMetric: 27.3007, val_loss: 27.5497, val_MinusLogProbMetric: 27.5497

Epoch 264: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3007 - MinusLogProbMetric: 27.3007 - val_loss: 27.5497 - val_MinusLogProbMetric: 27.5497 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 265/1000
2023-09-12 22:30:27.528 
Epoch 265/1000 
	 loss: 27.3020, MinusLogProbMetric: 27.3020, val_loss: 27.5472, val_MinusLogProbMetric: 27.5472

Epoch 265: val_loss did not improve from 27.54146
196/196 - 8s - loss: 27.3020 - MinusLogProbMetric: 27.3020 - val_loss: 27.5472 - val_MinusLogProbMetric: 27.5472 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 266/1000
2023-09-12 22:30:36.389 
Epoch 266/1000 
	 loss: 27.2981, MinusLogProbMetric: 27.2981, val_loss: 27.5577, val_MinusLogProbMetric: 27.5577

Epoch 266: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.2981 - MinusLogProbMetric: 27.2981 - val_loss: 27.5577 - val_MinusLogProbMetric: 27.5577 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 267/1000
2023-09-12 22:30:46.279 
Epoch 267/1000 
	 loss: 27.3024, MinusLogProbMetric: 27.3024, val_loss: 27.5595, val_MinusLogProbMetric: 27.5595

Epoch 267: val_loss did not improve from 27.54146
196/196 - 10s - loss: 27.3024 - MinusLogProbMetric: 27.3024 - val_loss: 27.5595 - val_MinusLogProbMetric: 27.5595 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 268/1000
2023-09-12 22:30:55.839 
Epoch 268/1000 
	 loss: 27.2998, MinusLogProbMetric: 27.2998, val_loss: 27.5625, val_MinusLogProbMetric: 27.5625

Epoch 268: val_loss did not improve from 27.54146
196/196 - 10s - loss: 27.2998 - MinusLogProbMetric: 27.2998 - val_loss: 27.5625 - val_MinusLogProbMetric: 27.5625 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 269/1000
2023-09-12 22:31:05.305 
Epoch 269/1000 
	 loss: 27.3013, MinusLogProbMetric: 27.3013, val_loss: 27.5586, val_MinusLogProbMetric: 27.5586

Epoch 269: val_loss did not improve from 27.54146
196/196 - 9s - loss: 27.3013 - MinusLogProbMetric: 27.3013 - val_loss: 27.5586 - val_MinusLogProbMetric: 27.5586 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 270/1000
2023-09-12 22:31:15.770 
Epoch 270/1000 
	 loss: 27.3038, MinusLogProbMetric: 27.3038, val_loss: 27.5567, val_MinusLogProbMetric: 27.5567

Epoch 270: val_loss did not improve from 27.54146
196/196 - 10s - loss: 27.3038 - MinusLogProbMetric: 27.3038 - val_loss: 27.5567 - val_MinusLogProbMetric: 27.5567 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 271/1000
2023-09-12 22:31:26.227 
Epoch 271/1000 
	 loss: 27.2987, MinusLogProbMetric: 27.2987, val_loss: 27.5632, val_MinusLogProbMetric: 27.5632

Epoch 271: val_loss did not improve from 27.54146
196/196 - 10s - loss: 27.2987 - MinusLogProbMetric: 27.2987 - val_loss: 27.5632 - val_MinusLogProbMetric: 27.5632 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 272/1000
2023-09-12 22:31:36.629 
Epoch 272/1000 
	 loss: 27.2994, MinusLogProbMetric: 27.2994, val_loss: 27.5407, val_MinusLogProbMetric: 27.5407

Epoch 272: val_loss improved from 27.54146 to 27.54074, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_179/weights/best_weights.h5
196/196 - 11s - loss: 27.2994 - MinusLogProbMetric: 27.2994 - val_loss: 27.5407 - val_MinusLogProbMetric: 27.5407 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 273/1000
2023-09-12 22:31:46.805 
Epoch 273/1000 
	 loss: 27.3006, MinusLogProbMetric: 27.3006, val_loss: 27.5478, val_MinusLogProbMetric: 27.5478

Epoch 273: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.3006 - MinusLogProbMetric: 27.3006 - val_loss: 27.5478 - val_MinusLogProbMetric: 27.5478 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 274/1000
2023-09-12 22:31:57.190 
Epoch 274/1000 
	 loss: 27.3000, MinusLogProbMetric: 27.3000, val_loss: 27.5590, val_MinusLogProbMetric: 27.5590

Epoch 274: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.3000 - MinusLogProbMetric: 27.3000 - val_loss: 27.5590 - val_MinusLogProbMetric: 27.5590 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 275/1000
2023-09-12 22:32:06.448 
Epoch 275/1000 
	 loss: 27.2986, MinusLogProbMetric: 27.2986, val_loss: 27.5611, val_MinusLogProbMetric: 27.5611

Epoch 275: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2986 - MinusLogProbMetric: 27.2986 - val_loss: 27.5611 - val_MinusLogProbMetric: 27.5611 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 276/1000
2023-09-12 22:32:14.851 
Epoch 276/1000 
	 loss: 27.2996, MinusLogProbMetric: 27.2996, val_loss: 27.5523, val_MinusLogProbMetric: 27.5523

Epoch 276: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2996 - MinusLogProbMetric: 27.2996 - val_loss: 27.5523 - val_MinusLogProbMetric: 27.5523 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 277/1000
2023-09-12 22:32:23.434 
Epoch 277/1000 
	 loss: 27.2984, MinusLogProbMetric: 27.2984, val_loss: 27.5491, val_MinusLogProbMetric: 27.5491

Epoch 277: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2984 - MinusLogProbMetric: 27.2984 - val_loss: 27.5491 - val_MinusLogProbMetric: 27.5491 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 278/1000
2023-09-12 22:32:32.743 
Epoch 278/1000 
	 loss: 27.3010, MinusLogProbMetric: 27.3010, val_loss: 27.5523, val_MinusLogProbMetric: 27.5523

Epoch 278: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.3010 - MinusLogProbMetric: 27.3010 - val_loss: 27.5523 - val_MinusLogProbMetric: 27.5523 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 279/1000
2023-09-12 22:32:43.372 
Epoch 279/1000 
	 loss: 27.2985, MinusLogProbMetric: 27.2985, val_loss: 27.5434, val_MinusLogProbMetric: 27.5434

Epoch 279: val_loss did not improve from 27.54074
196/196 - 11s - loss: 27.2985 - MinusLogProbMetric: 27.2985 - val_loss: 27.5434 - val_MinusLogProbMetric: 27.5434 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 280/1000
2023-09-12 22:32:52.053 
Epoch 280/1000 
	 loss: 27.2994, MinusLogProbMetric: 27.2994, val_loss: 27.5455, val_MinusLogProbMetric: 27.5455

Epoch 280: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2994 - MinusLogProbMetric: 27.2994 - val_loss: 27.5455 - val_MinusLogProbMetric: 27.5455 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 281/1000
2023-09-12 22:33:01.536 
Epoch 281/1000 
	 loss: 27.2970, MinusLogProbMetric: 27.2970, val_loss: 27.5741, val_MinusLogProbMetric: 27.5741

Epoch 281: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2970 - MinusLogProbMetric: 27.2970 - val_loss: 27.5741 - val_MinusLogProbMetric: 27.5741 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 282/1000
2023-09-12 22:33:10.042 
Epoch 282/1000 
	 loss: 27.2981, MinusLogProbMetric: 27.2981, val_loss: 27.5569, val_MinusLogProbMetric: 27.5569

Epoch 282: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2981 - MinusLogProbMetric: 27.2981 - val_loss: 27.5569 - val_MinusLogProbMetric: 27.5569 - lr: 2.5000e-04 - 9s/epoch - 43ms/step
Epoch 283/1000
2023-09-12 22:33:19.585 
Epoch 283/1000 
	 loss: 27.2979, MinusLogProbMetric: 27.2979, val_loss: 27.5644, val_MinusLogProbMetric: 27.5644

Epoch 283: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2979 - MinusLogProbMetric: 27.2979 - val_loss: 27.5644 - val_MinusLogProbMetric: 27.5644 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 284/1000
2023-09-12 22:33:28.924 
Epoch 284/1000 
	 loss: 27.2971, MinusLogProbMetric: 27.2971, val_loss: 27.5655, val_MinusLogProbMetric: 27.5655

Epoch 284: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2971 - MinusLogProbMetric: 27.2971 - val_loss: 27.5655 - val_MinusLogProbMetric: 27.5655 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 285/1000
2023-09-12 22:33:37.528 
Epoch 285/1000 
	 loss: 27.2999, MinusLogProbMetric: 27.2999, val_loss: 27.5516, val_MinusLogProbMetric: 27.5516

Epoch 285: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2999 - MinusLogProbMetric: 27.2999 - val_loss: 27.5516 - val_MinusLogProbMetric: 27.5516 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 286/1000
2023-09-12 22:33:47.376 
Epoch 286/1000 
	 loss: 27.2970, MinusLogProbMetric: 27.2970, val_loss: 27.5571, val_MinusLogProbMetric: 27.5571

Epoch 286: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2970 - MinusLogProbMetric: 27.2970 - val_loss: 27.5571 - val_MinusLogProbMetric: 27.5571 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 287/1000
2023-09-12 22:33:56.736 
Epoch 287/1000 
	 loss: 27.2976, MinusLogProbMetric: 27.2976, val_loss: 27.5552, val_MinusLogProbMetric: 27.5552

Epoch 287: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2976 - MinusLogProbMetric: 27.2976 - val_loss: 27.5552 - val_MinusLogProbMetric: 27.5552 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 288/1000
2023-09-12 22:34:05.605 
Epoch 288/1000 
	 loss: 27.2993, MinusLogProbMetric: 27.2993, val_loss: 27.5529, val_MinusLogProbMetric: 27.5529

Epoch 288: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2993 - MinusLogProbMetric: 27.2993 - val_loss: 27.5529 - val_MinusLogProbMetric: 27.5529 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 289/1000
2023-09-12 22:34:14.084 
Epoch 289/1000 
	 loss: 27.2968, MinusLogProbMetric: 27.2968, val_loss: 27.5646, val_MinusLogProbMetric: 27.5646

Epoch 289: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2968 - MinusLogProbMetric: 27.2968 - val_loss: 27.5646 - val_MinusLogProbMetric: 27.5646 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 290/1000
2023-09-12 22:34:22.632 
Epoch 290/1000 
	 loss: 27.2966, MinusLogProbMetric: 27.2966, val_loss: 27.5537, val_MinusLogProbMetric: 27.5537

Epoch 290: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2966 - MinusLogProbMetric: 27.2966 - val_loss: 27.5537 - val_MinusLogProbMetric: 27.5537 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 291/1000
2023-09-12 22:34:31.334 
Epoch 291/1000 
	 loss: 27.3000, MinusLogProbMetric: 27.3000, val_loss: 27.5539, val_MinusLogProbMetric: 27.5539

Epoch 291: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.3000 - MinusLogProbMetric: 27.3000 - val_loss: 27.5539 - val_MinusLogProbMetric: 27.5539 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 292/1000
2023-09-12 22:34:40.049 
Epoch 292/1000 
	 loss: 27.2979, MinusLogProbMetric: 27.2979, val_loss: 27.5512, val_MinusLogProbMetric: 27.5512

Epoch 292: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2979 - MinusLogProbMetric: 27.2979 - val_loss: 27.5512 - val_MinusLogProbMetric: 27.5512 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 293/1000
2023-09-12 22:34:49.336 
Epoch 293/1000 
	 loss: 27.2977, MinusLogProbMetric: 27.2977, val_loss: 27.5596, val_MinusLogProbMetric: 27.5596

Epoch 293: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2977 - MinusLogProbMetric: 27.2977 - val_loss: 27.5596 - val_MinusLogProbMetric: 27.5596 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 294/1000
2023-09-12 22:34:58.192 
Epoch 294/1000 
	 loss: 27.2966, MinusLogProbMetric: 27.2966, val_loss: 27.5580, val_MinusLogProbMetric: 27.5580

Epoch 294: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2966 - MinusLogProbMetric: 27.2966 - val_loss: 27.5580 - val_MinusLogProbMetric: 27.5580 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 295/1000
2023-09-12 22:35:07.769 
Epoch 295/1000 
	 loss: 27.2981, MinusLogProbMetric: 27.2981, val_loss: 27.5598, val_MinusLogProbMetric: 27.5598

Epoch 295: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2981 - MinusLogProbMetric: 27.2981 - val_loss: 27.5598 - val_MinusLogProbMetric: 27.5598 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 296/1000
2023-09-12 22:35:16.156 
Epoch 296/1000 
	 loss: 27.2961, MinusLogProbMetric: 27.2961, val_loss: 27.5556, val_MinusLogProbMetric: 27.5556

Epoch 296: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2961 - MinusLogProbMetric: 27.2961 - val_loss: 27.5556 - val_MinusLogProbMetric: 27.5556 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 297/1000
2023-09-12 22:35:25.036 
Epoch 297/1000 
	 loss: 27.2958, MinusLogProbMetric: 27.2958, val_loss: 27.5583, val_MinusLogProbMetric: 27.5583

Epoch 297: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2958 - MinusLogProbMetric: 27.2958 - val_loss: 27.5583 - val_MinusLogProbMetric: 27.5583 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 298/1000
2023-09-12 22:35:33.534 
Epoch 298/1000 
	 loss: 27.2961, MinusLogProbMetric: 27.2961, val_loss: 27.5498, val_MinusLogProbMetric: 27.5498

Epoch 298: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2961 - MinusLogProbMetric: 27.2961 - val_loss: 27.5498 - val_MinusLogProbMetric: 27.5498 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 299/1000
2023-09-12 22:35:43.037 
Epoch 299/1000 
	 loss: 27.2938, MinusLogProbMetric: 27.2938, val_loss: 27.5644, val_MinusLogProbMetric: 27.5644

Epoch 299: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2938 - MinusLogProbMetric: 27.2938 - val_loss: 27.5644 - val_MinusLogProbMetric: 27.5644 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 300/1000
2023-09-12 22:35:52.521 
Epoch 300/1000 
	 loss: 27.2967, MinusLogProbMetric: 27.2967, val_loss: 27.5592, val_MinusLogProbMetric: 27.5592

Epoch 300: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2967 - MinusLogProbMetric: 27.2967 - val_loss: 27.5592 - val_MinusLogProbMetric: 27.5592 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 301/1000
2023-09-12 22:36:00.988 
Epoch 301/1000 
	 loss: 27.2949, MinusLogProbMetric: 27.2949, val_loss: 27.5543, val_MinusLogProbMetric: 27.5543

Epoch 301: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2949 - MinusLogProbMetric: 27.2949 - val_loss: 27.5543 - val_MinusLogProbMetric: 27.5543 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 302/1000
2023-09-12 22:36:10.911 
Epoch 302/1000 
	 loss: 27.2990, MinusLogProbMetric: 27.2990, val_loss: 27.5659, val_MinusLogProbMetric: 27.5659

Epoch 302: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2990 - MinusLogProbMetric: 27.2990 - val_loss: 27.5659 - val_MinusLogProbMetric: 27.5659 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 303/1000
2023-09-12 22:36:19.821 
Epoch 303/1000 
	 loss: 27.2951, MinusLogProbMetric: 27.2951, val_loss: 27.5750, val_MinusLogProbMetric: 27.5750

Epoch 303: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2951 - MinusLogProbMetric: 27.2951 - val_loss: 27.5750 - val_MinusLogProbMetric: 27.5750 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 304/1000
2023-09-12 22:36:28.990 
Epoch 304/1000 
	 loss: 27.2983, MinusLogProbMetric: 27.2983, val_loss: 27.5568, val_MinusLogProbMetric: 27.5568

Epoch 304: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2983 - MinusLogProbMetric: 27.2983 - val_loss: 27.5568 - val_MinusLogProbMetric: 27.5568 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 305/1000
2023-09-12 22:36:37.496 
Epoch 305/1000 
	 loss: 27.2947, MinusLogProbMetric: 27.2947, val_loss: 27.5527, val_MinusLogProbMetric: 27.5527

Epoch 305: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2947 - MinusLogProbMetric: 27.2947 - val_loss: 27.5527 - val_MinusLogProbMetric: 27.5527 - lr: 2.5000e-04 - 8s/epoch - 43ms/step
Epoch 306/1000
2023-09-12 22:36:46.206 
Epoch 306/1000 
	 loss: 27.2942, MinusLogProbMetric: 27.2942, val_loss: 27.5663, val_MinusLogProbMetric: 27.5663

Epoch 306: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2942 - MinusLogProbMetric: 27.2942 - val_loss: 27.5663 - val_MinusLogProbMetric: 27.5663 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 307/1000
2023-09-12 22:36:54.832 
Epoch 307/1000 
	 loss: 27.2946, MinusLogProbMetric: 27.2946, val_loss: 27.5654, val_MinusLogProbMetric: 27.5654

Epoch 307: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2946 - MinusLogProbMetric: 27.2946 - val_loss: 27.5654 - val_MinusLogProbMetric: 27.5654 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 308/1000
2023-09-12 22:37:03.664 
Epoch 308/1000 
	 loss: 27.2957, MinusLogProbMetric: 27.2957, val_loss: 27.5575, val_MinusLogProbMetric: 27.5575

Epoch 308: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2957 - MinusLogProbMetric: 27.2957 - val_loss: 27.5575 - val_MinusLogProbMetric: 27.5575 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 309/1000
2023-09-12 22:37:13.214 
Epoch 309/1000 
	 loss: 27.2966, MinusLogProbMetric: 27.2966, val_loss: 27.5598, val_MinusLogProbMetric: 27.5598

Epoch 309: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2966 - MinusLogProbMetric: 27.2966 - val_loss: 27.5598 - val_MinusLogProbMetric: 27.5598 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 310/1000
2023-09-12 22:37:23.237 
Epoch 310/1000 
	 loss: 27.2940, MinusLogProbMetric: 27.2940, val_loss: 27.5529, val_MinusLogProbMetric: 27.5529

Epoch 310: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2940 - MinusLogProbMetric: 27.2940 - val_loss: 27.5529 - val_MinusLogProbMetric: 27.5529 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 311/1000
2023-09-12 22:37:33.625 
Epoch 311/1000 
	 loss: 27.2939, MinusLogProbMetric: 27.2939, val_loss: 27.5586, val_MinusLogProbMetric: 27.5586

Epoch 311: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2939 - MinusLogProbMetric: 27.2939 - val_loss: 27.5586 - val_MinusLogProbMetric: 27.5586 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 312/1000
2023-09-12 22:37:43.839 
Epoch 312/1000 
	 loss: 27.2987, MinusLogProbMetric: 27.2987, val_loss: 27.5643, val_MinusLogProbMetric: 27.5643

Epoch 312: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2987 - MinusLogProbMetric: 27.2987 - val_loss: 27.5643 - val_MinusLogProbMetric: 27.5643 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 313/1000
2023-09-12 22:37:54.319 
Epoch 313/1000 
	 loss: 27.2948, MinusLogProbMetric: 27.2948, val_loss: 27.5572, val_MinusLogProbMetric: 27.5572

Epoch 313: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2948 - MinusLogProbMetric: 27.2948 - val_loss: 27.5572 - val_MinusLogProbMetric: 27.5572 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 314/1000
2023-09-12 22:38:04.534 
Epoch 314/1000 
	 loss: 27.2938, MinusLogProbMetric: 27.2938, val_loss: 27.5573, val_MinusLogProbMetric: 27.5573

Epoch 314: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2938 - MinusLogProbMetric: 27.2938 - val_loss: 27.5573 - val_MinusLogProbMetric: 27.5573 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 315/1000
2023-09-12 22:38:14.885 
Epoch 315/1000 
	 loss: 27.2925, MinusLogProbMetric: 27.2925, val_loss: 27.5559, val_MinusLogProbMetric: 27.5559

Epoch 315: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2925 - MinusLogProbMetric: 27.2925 - val_loss: 27.5559 - val_MinusLogProbMetric: 27.5559 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 316/1000
2023-09-12 22:38:24.512 
Epoch 316/1000 
	 loss: 27.2946, MinusLogProbMetric: 27.2946, val_loss: 27.5638, val_MinusLogProbMetric: 27.5638

Epoch 316: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2946 - MinusLogProbMetric: 27.2946 - val_loss: 27.5638 - val_MinusLogProbMetric: 27.5638 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 317/1000
2023-09-12 22:38:33.380 
Epoch 317/1000 
	 loss: 27.2964, MinusLogProbMetric: 27.2964, val_loss: 27.5556, val_MinusLogProbMetric: 27.5556

Epoch 317: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2964 - MinusLogProbMetric: 27.2964 - val_loss: 27.5556 - val_MinusLogProbMetric: 27.5556 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 318/1000
2023-09-12 22:38:41.967 
Epoch 318/1000 
	 loss: 27.2939, MinusLogProbMetric: 27.2939, val_loss: 27.5650, val_MinusLogProbMetric: 27.5650

Epoch 318: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2939 - MinusLogProbMetric: 27.2939 - val_loss: 27.5650 - val_MinusLogProbMetric: 27.5650 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 319/1000
2023-09-12 22:38:52.078 
Epoch 319/1000 
	 loss: 27.2912, MinusLogProbMetric: 27.2912, val_loss: 27.5709, val_MinusLogProbMetric: 27.5709

Epoch 319: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2912 - MinusLogProbMetric: 27.2912 - val_loss: 27.5709 - val_MinusLogProbMetric: 27.5709 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 320/1000
2023-09-12 22:39:02.430 
Epoch 320/1000 
	 loss: 27.2930, MinusLogProbMetric: 27.2930, val_loss: 27.5636, val_MinusLogProbMetric: 27.5636

Epoch 320: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2930 - MinusLogProbMetric: 27.2930 - val_loss: 27.5636 - val_MinusLogProbMetric: 27.5636 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 321/1000
2023-09-12 22:39:11.461 
Epoch 321/1000 
	 loss: 27.2931, MinusLogProbMetric: 27.2931, val_loss: 27.5620, val_MinusLogProbMetric: 27.5620

Epoch 321: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2931 - MinusLogProbMetric: 27.2931 - val_loss: 27.5620 - val_MinusLogProbMetric: 27.5620 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 322/1000
2023-09-12 22:39:20.080 
Epoch 322/1000 
	 loss: 27.2928, MinusLogProbMetric: 27.2928, val_loss: 27.5659, val_MinusLogProbMetric: 27.5659

Epoch 322: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2928 - MinusLogProbMetric: 27.2928 - val_loss: 27.5659 - val_MinusLogProbMetric: 27.5659 - lr: 2.5000e-04 - 9s/epoch - 44ms/step
Epoch 323/1000
2023-09-12 22:39:30.316 
Epoch 323/1000 
	 loss: 27.2746, MinusLogProbMetric: 27.2746, val_loss: 27.5418, val_MinusLogProbMetric: 27.5418

Epoch 323: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2746 - MinusLogProbMetric: 27.2746 - val_loss: 27.5418 - val_MinusLogProbMetric: 27.5418 - lr: 1.2500e-04 - 10s/epoch - 52ms/step
Epoch 324/1000
2023-09-12 22:39:39.959 
Epoch 324/1000 
	 loss: 27.2712, MinusLogProbMetric: 27.2712, val_loss: 27.5469, val_MinusLogProbMetric: 27.5469

Epoch 324: val_loss did not improve from 27.54074
196/196 - 10s - loss: 27.2712 - MinusLogProbMetric: 27.2712 - val_loss: 27.5469 - val_MinusLogProbMetric: 27.5469 - lr: 1.2500e-04 - 10s/epoch - 49ms/step
Epoch 325/1000
2023-09-12 22:39:48.583 
Epoch 325/1000 
	 loss: 27.2719, MinusLogProbMetric: 27.2719, val_loss: 27.5434, val_MinusLogProbMetric: 27.5434

Epoch 325: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2719 - MinusLogProbMetric: 27.2719 - val_loss: 27.5434 - val_MinusLogProbMetric: 27.5434 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 326/1000
2023-09-12 22:39:57.193 
Epoch 326/1000 
	 loss: 27.2713, MinusLogProbMetric: 27.2713, val_loss: 27.5427, val_MinusLogProbMetric: 27.5427

Epoch 326: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2713 - MinusLogProbMetric: 27.2713 - val_loss: 27.5427 - val_MinusLogProbMetric: 27.5427 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 327/1000
2023-09-12 22:40:05.962 
Epoch 327/1000 
	 loss: 27.2710, MinusLogProbMetric: 27.2710, val_loss: 27.5446, val_MinusLogProbMetric: 27.5446

Epoch 327: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2710 - MinusLogProbMetric: 27.2710 - val_loss: 27.5446 - val_MinusLogProbMetric: 27.5446 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 328/1000
2023-09-12 22:40:14.601 
Epoch 328/1000 
	 loss: 27.2735, MinusLogProbMetric: 27.2735, val_loss: 27.5467, val_MinusLogProbMetric: 27.5467

Epoch 328: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2735 - MinusLogProbMetric: 27.2735 - val_loss: 27.5467 - val_MinusLogProbMetric: 27.5467 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 329/1000
2023-09-12 22:40:23.355 
Epoch 329/1000 
	 loss: 27.2700, MinusLogProbMetric: 27.2700, val_loss: 27.5500, val_MinusLogProbMetric: 27.5500

Epoch 329: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2700 - MinusLogProbMetric: 27.2700 - val_loss: 27.5500 - val_MinusLogProbMetric: 27.5500 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 330/1000
2023-09-12 22:40:31.773 
Epoch 330/1000 
	 loss: 27.2714, MinusLogProbMetric: 27.2714, val_loss: 27.5472, val_MinusLogProbMetric: 27.5472

Epoch 330: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2714 - MinusLogProbMetric: 27.2714 - val_loss: 27.5472 - val_MinusLogProbMetric: 27.5472 - lr: 1.2500e-04 - 8s/epoch - 43ms/step
Epoch 331/1000
2023-09-12 22:40:40.354 
Epoch 331/1000 
	 loss: 27.2711, MinusLogProbMetric: 27.2711, val_loss: 27.5473, val_MinusLogProbMetric: 27.5473

Epoch 331: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2711 - MinusLogProbMetric: 27.2711 - val_loss: 27.5473 - val_MinusLogProbMetric: 27.5473 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 332/1000
2023-09-12 22:40:48.922 
Epoch 332/1000 
	 loss: 27.2713, MinusLogProbMetric: 27.2713, val_loss: 27.5450, val_MinusLogProbMetric: 27.5450

Epoch 332: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2713 - MinusLogProbMetric: 27.2713 - val_loss: 27.5450 - val_MinusLogProbMetric: 27.5450 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 333/1000
2023-09-12 22:40:57.336 
Epoch 333/1000 
	 loss: 27.2710, MinusLogProbMetric: 27.2710, val_loss: 27.5496, val_MinusLogProbMetric: 27.5496

Epoch 333: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2710 - MinusLogProbMetric: 27.2710 - val_loss: 27.5496 - val_MinusLogProbMetric: 27.5496 - lr: 1.2500e-04 - 8s/epoch - 43ms/step
Epoch 334/1000
2023-09-12 22:41:05.890 
Epoch 334/1000 
	 loss: 27.2710, MinusLogProbMetric: 27.2710, val_loss: 27.5440, val_MinusLogProbMetric: 27.5440

Epoch 334: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2710 - MinusLogProbMetric: 27.2710 - val_loss: 27.5440 - val_MinusLogProbMetric: 27.5440 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 335/1000
2023-09-12 22:41:14.404 
Epoch 335/1000 
	 loss: 27.2716, MinusLogProbMetric: 27.2716, val_loss: 27.5470, val_MinusLogProbMetric: 27.5470

Epoch 335: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2716 - MinusLogProbMetric: 27.2716 - val_loss: 27.5470 - val_MinusLogProbMetric: 27.5470 - lr: 1.2500e-04 - 9s/epoch - 43ms/step
Epoch 336/1000
2023-09-12 22:41:23.151 
Epoch 336/1000 
	 loss: 27.2710, MinusLogProbMetric: 27.2710, val_loss: 27.5477, val_MinusLogProbMetric: 27.5477

Epoch 336: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2710 - MinusLogProbMetric: 27.2710 - val_loss: 27.5477 - val_MinusLogProbMetric: 27.5477 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 337/1000
2023-09-12 22:41:31.342 
Epoch 337/1000 
	 loss: 27.2703, MinusLogProbMetric: 27.2703, val_loss: 27.5447, val_MinusLogProbMetric: 27.5447

Epoch 337: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2703 - MinusLogProbMetric: 27.2703 - val_loss: 27.5447 - val_MinusLogProbMetric: 27.5447 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 338/1000
2023-09-12 22:41:39.206 
Epoch 338/1000 
	 loss: 27.2709, MinusLogProbMetric: 27.2709, val_loss: 27.5475, val_MinusLogProbMetric: 27.5475

Epoch 338: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2709 - MinusLogProbMetric: 27.2709 - val_loss: 27.5475 - val_MinusLogProbMetric: 27.5475 - lr: 1.2500e-04 - 8s/epoch - 40ms/step
Epoch 339/1000
2023-09-12 22:41:47.887 
Epoch 339/1000 
	 loss: 27.2705, MinusLogProbMetric: 27.2705, val_loss: 27.5475, val_MinusLogProbMetric: 27.5475

Epoch 339: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2705 - MinusLogProbMetric: 27.2705 - val_loss: 27.5475 - val_MinusLogProbMetric: 27.5475 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 340/1000
2023-09-12 22:41:57.071 
Epoch 340/1000 
	 loss: 27.2708, MinusLogProbMetric: 27.2708, val_loss: 27.5511, val_MinusLogProbMetric: 27.5511

Epoch 340: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2708 - MinusLogProbMetric: 27.2708 - val_loss: 27.5511 - val_MinusLogProbMetric: 27.5511 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 341/1000
2023-09-12 22:42:06.530 
Epoch 341/1000 
	 loss: 27.2711, MinusLogProbMetric: 27.2711, val_loss: 27.5425, val_MinusLogProbMetric: 27.5425

Epoch 341: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2711 - MinusLogProbMetric: 27.2711 - val_loss: 27.5425 - val_MinusLogProbMetric: 27.5425 - lr: 1.2500e-04 - 9s/epoch - 48ms/step
Epoch 342/1000
2023-09-12 22:42:15.315 
Epoch 342/1000 
	 loss: 27.2708, MinusLogProbMetric: 27.2708, val_loss: 27.5481, val_MinusLogProbMetric: 27.5481

Epoch 342: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2708 - MinusLogProbMetric: 27.2708 - val_loss: 27.5481 - val_MinusLogProbMetric: 27.5481 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 343/1000
2023-09-12 22:42:24.315 
Epoch 343/1000 
	 loss: 27.2707, MinusLogProbMetric: 27.2707, val_loss: 27.5480, val_MinusLogProbMetric: 27.5480

Epoch 343: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2707 - MinusLogProbMetric: 27.2707 - val_loss: 27.5480 - val_MinusLogProbMetric: 27.5480 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 344/1000
2023-09-12 22:42:32.625 
Epoch 344/1000 
	 loss: 27.2697, MinusLogProbMetric: 27.2697, val_loss: 27.5560, val_MinusLogProbMetric: 27.5560

Epoch 344: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2697 - MinusLogProbMetric: 27.2697 - val_loss: 27.5560 - val_MinusLogProbMetric: 27.5560 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 345/1000
2023-09-12 22:42:40.332 
Epoch 345/1000 
	 loss: 27.2707, MinusLogProbMetric: 27.2707, val_loss: 27.5518, val_MinusLogProbMetric: 27.5518

Epoch 345: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2707 - MinusLogProbMetric: 27.2707 - val_loss: 27.5518 - val_MinusLogProbMetric: 27.5518 - lr: 1.2500e-04 - 8s/epoch - 39ms/step
Epoch 346/1000
2023-09-12 22:42:48.076 
Epoch 346/1000 
	 loss: 27.2711, MinusLogProbMetric: 27.2711, val_loss: 27.5451, val_MinusLogProbMetric: 27.5451

Epoch 346: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2711 - MinusLogProbMetric: 27.2711 - val_loss: 27.5451 - val_MinusLogProbMetric: 27.5451 - lr: 1.2500e-04 - 8s/epoch - 40ms/step
Epoch 347/1000
2023-09-12 22:42:55.842 
Epoch 347/1000 
	 loss: 27.2700, MinusLogProbMetric: 27.2700, val_loss: 27.5507, val_MinusLogProbMetric: 27.5507

Epoch 347: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2700 - MinusLogProbMetric: 27.2700 - val_loss: 27.5507 - val_MinusLogProbMetric: 27.5507 - lr: 1.2500e-04 - 8s/epoch - 40ms/step
Epoch 348/1000
2023-09-12 22:43:03.908 
Epoch 348/1000 
	 loss: 27.2714, MinusLogProbMetric: 27.2714, val_loss: 27.5490, val_MinusLogProbMetric: 27.5490

Epoch 348: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2714 - MinusLogProbMetric: 27.2714 - val_loss: 27.5490 - val_MinusLogProbMetric: 27.5490 - lr: 1.2500e-04 - 8s/epoch - 41ms/step
Epoch 349/1000
2023-09-12 22:43:12.511 
Epoch 349/1000 
	 loss: 27.2707, MinusLogProbMetric: 27.2707, val_loss: 27.5481, val_MinusLogProbMetric: 27.5481

Epoch 349: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2707 - MinusLogProbMetric: 27.2707 - val_loss: 27.5481 - val_MinusLogProbMetric: 27.5481 - lr: 1.2500e-04 - 9s/epoch - 44ms/step
Epoch 350/1000
2023-09-12 22:43:20.390 
Epoch 350/1000 
	 loss: 27.2708, MinusLogProbMetric: 27.2708, val_loss: 27.5496, val_MinusLogProbMetric: 27.5496

Epoch 350: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2708 - MinusLogProbMetric: 27.2708 - val_loss: 27.5496 - val_MinusLogProbMetric: 27.5496 - lr: 1.2500e-04 - 8s/epoch - 40ms/step
Epoch 351/1000
2023-09-12 22:43:28.793 
Epoch 351/1000 
	 loss: 27.2712, MinusLogProbMetric: 27.2712, val_loss: 27.5482, val_MinusLogProbMetric: 27.5482

Epoch 351: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2712 - MinusLogProbMetric: 27.2712 - val_loss: 27.5482 - val_MinusLogProbMetric: 27.5482 - lr: 1.2500e-04 - 8s/epoch - 43ms/step
Epoch 352/1000
2023-09-12 22:43:37.613 
Epoch 352/1000 
	 loss: 27.2707, MinusLogProbMetric: 27.2707, val_loss: 27.5499, val_MinusLogProbMetric: 27.5499

Epoch 352: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2707 - MinusLogProbMetric: 27.2707 - val_loss: 27.5499 - val_MinusLogProbMetric: 27.5499 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 353/1000
2023-09-12 22:43:46.471 
Epoch 353/1000 
	 loss: 27.2690, MinusLogProbMetric: 27.2690, val_loss: 27.5525, val_MinusLogProbMetric: 27.5525

Epoch 353: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2690 - MinusLogProbMetric: 27.2690 - val_loss: 27.5525 - val_MinusLogProbMetric: 27.5525 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 354/1000
2023-09-12 22:43:54.870 
Epoch 354/1000 
	 loss: 27.2698, MinusLogProbMetric: 27.2698, val_loss: 27.5500, val_MinusLogProbMetric: 27.5500

Epoch 354: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2698 - MinusLogProbMetric: 27.2698 - val_loss: 27.5500 - val_MinusLogProbMetric: 27.5500 - lr: 1.2500e-04 - 8s/epoch - 43ms/step
Epoch 355/1000
2023-09-12 22:44:03.680 
Epoch 355/1000 
	 loss: 27.2701, MinusLogProbMetric: 27.2701, val_loss: 27.5500, val_MinusLogProbMetric: 27.5500

Epoch 355: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2701 - MinusLogProbMetric: 27.2701 - val_loss: 27.5500 - val_MinusLogProbMetric: 27.5500 - lr: 1.2500e-04 - 9s/epoch - 45ms/step
Epoch 356/1000
2023-09-12 22:44:12.831 
Epoch 356/1000 
	 loss: 27.2711, MinusLogProbMetric: 27.2711, val_loss: 27.5520, val_MinusLogProbMetric: 27.5520

Epoch 356: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2711 - MinusLogProbMetric: 27.2711 - val_loss: 27.5520 - val_MinusLogProbMetric: 27.5520 - lr: 1.2500e-04 - 9s/epoch - 47ms/step
Epoch 357/1000
2023-09-12 22:44:21.944 
Epoch 357/1000 
	 loss: 27.2686, MinusLogProbMetric: 27.2686, val_loss: 27.5514, val_MinusLogProbMetric: 27.5514

Epoch 357: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2686 - MinusLogProbMetric: 27.2686 - val_loss: 27.5514 - val_MinusLogProbMetric: 27.5514 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 358/1000
2023-09-12 22:44:30.881 
Epoch 358/1000 
	 loss: 27.2693, MinusLogProbMetric: 27.2693, val_loss: 27.5474, val_MinusLogProbMetric: 27.5474

Epoch 358: val_loss did not improve from 27.54074
196/196 - 9s - loss: 27.2693 - MinusLogProbMetric: 27.2693 - val_loss: 27.5474 - val_MinusLogProbMetric: 27.5474 - lr: 1.2500e-04 - 9s/epoch - 46ms/step
Epoch 359/1000
2023-09-12 22:44:39.158 
Epoch 359/1000 
	 loss: 27.2687, MinusLogProbMetric: 27.2687, val_loss: 27.5499, val_MinusLogProbMetric: 27.5499

Epoch 359: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2687 - MinusLogProbMetric: 27.2687 - val_loss: 27.5499 - val_MinusLogProbMetric: 27.5499 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 360/1000
2023-09-12 22:44:47.364 
Epoch 360/1000 
	 loss: 27.2682, MinusLogProbMetric: 27.2682, val_loss: 27.5545, val_MinusLogProbMetric: 27.5545

Epoch 360: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2682 - MinusLogProbMetric: 27.2682 - val_loss: 27.5545 - val_MinusLogProbMetric: 27.5545 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 361/1000
2023-09-12 22:44:55.419 
Epoch 361/1000 
	 loss: 27.2686, MinusLogProbMetric: 27.2686, val_loss: 27.5543, val_MinusLogProbMetric: 27.5543

Epoch 361: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2686 - MinusLogProbMetric: 27.2686 - val_loss: 27.5543 - val_MinusLogProbMetric: 27.5543 - lr: 1.2500e-04 - 8s/epoch - 41ms/step
Epoch 362/1000
2023-09-12 22:45:03.555 
Epoch 362/1000 
	 loss: 27.2701, MinusLogProbMetric: 27.2701, val_loss: 27.5494, val_MinusLogProbMetric: 27.5494

Epoch 362: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2701 - MinusLogProbMetric: 27.2701 - val_loss: 27.5494 - val_MinusLogProbMetric: 27.5494 - lr: 1.2500e-04 - 8s/epoch - 41ms/step
Epoch 363/1000
2023-09-12 22:45:11.837 
Epoch 363/1000 
	 loss: 27.2711, MinusLogProbMetric: 27.2711, val_loss: 27.5512, val_MinusLogProbMetric: 27.5512

Epoch 363: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2711 - MinusLogProbMetric: 27.2711 - val_loss: 27.5512 - val_MinusLogProbMetric: 27.5512 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 364/1000
2023-09-12 22:45:19.928 
Epoch 364/1000 
	 loss: 27.2699, MinusLogProbMetric: 27.2699, val_loss: 27.5521, val_MinusLogProbMetric: 27.5521

Epoch 364: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2699 - MinusLogProbMetric: 27.2699 - val_loss: 27.5521 - val_MinusLogProbMetric: 27.5521 - lr: 1.2500e-04 - 8s/epoch - 41ms/step
Epoch 365/1000
2023-09-12 22:45:28.095 
Epoch 365/1000 
	 loss: 27.2696, MinusLogProbMetric: 27.2696, val_loss: 27.5499, val_MinusLogProbMetric: 27.5499

Epoch 365: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2696 - MinusLogProbMetric: 27.2696 - val_loss: 27.5499 - val_MinusLogProbMetric: 27.5499 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 366/1000
2023-09-12 22:45:36.421 
Epoch 366/1000 
	 loss: 27.2692, MinusLogProbMetric: 27.2692, val_loss: 27.5477, val_MinusLogProbMetric: 27.5477

Epoch 366: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2692 - MinusLogProbMetric: 27.2692 - val_loss: 27.5477 - val_MinusLogProbMetric: 27.5477 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 367/1000
2023-09-12 22:45:44.640 
Epoch 367/1000 
	 loss: 27.2672, MinusLogProbMetric: 27.2672, val_loss: 27.5534, val_MinusLogProbMetric: 27.5534

Epoch 367: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2672 - MinusLogProbMetric: 27.2672 - val_loss: 27.5534 - val_MinusLogProbMetric: 27.5534 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 368/1000
2023-09-12 22:45:53.001 
Epoch 368/1000 
	 loss: 27.2696, MinusLogProbMetric: 27.2696, val_loss: 27.5628, val_MinusLogProbMetric: 27.5628

Epoch 368: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2696 - MinusLogProbMetric: 27.2696 - val_loss: 27.5628 - val_MinusLogProbMetric: 27.5628 - lr: 1.2500e-04 - 8s/epoch - 43ms/step
Epoch 369/1000
2023-09-12 22:46:01.144 
Epoch 369/1000 
	 loss: 27.2678, MinusLogProbMetric: 27.2678, val_loss: 27.5545, val_MinusLogProbMetric: 27.5545

Epoch 369: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2678 - MinusLogProbMetric: 27.2678 - val_loss: 27.5545 - val_MinusLogProbMetric: 27.5545 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 370/1000
2023-09-12 22:46:09.345 
Epoch 370/1000 
	 loss: 27.2693, MinusLogProbMetric: 27.2693, val_loss: 27.5613, val_MinusLogProbMetric: 27.5613

Epoch 370: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2693 - MinusLogProbMetric: 27.2693 - val_loss: 27.5613 - val_MinusLogProbMetric: 27.5613 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 371/1000
2023-09-12 22:46:17.687 
Epoch 371/1000 
	 loss: 27.2697, MinusLogProbMetric: 27.2697, val_loss: 27.5502, val_MinusLogProbMetric: 27.5502

Epoch 371: val_loss did not improve from 27.54074
196/196 - 8s - loss: 27.2697 - MinusLogProbMetric: 27.2697 - val_loss: 27.5502 - val_MinusLogProbMetric: 27.5502 - lr: 1.2500e-04 - 8s/epoch - 43ms/step
Epoch 372/1000
2023-09-12 22:46:25.946 
Epoch 372/1000 
	 loss: 27.2687, MinusLogProbMetric: 27.2687, val_loss: 27.5485, val_MinusLogProbMetric: 27.5485

Epoch 372: val_loss did not improve from 27.54074
Restoring model weights from the end of the best epoch: 272.
196/196 - 8s - loss: 27.2687 - MinusLogProbMetric: 27.2687 - val_loss: 27.5485 - val_MinusLogProbMetric: 27.5485 - lr: 1.2500e-04 - 8s/epoch - 42ms/step
Epoch 372: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 9.390336957992986 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.594963323906995 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.69651912804693 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.135602611931972 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 520.
Model trained in 3586.92 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Metrics computed in 3285.62 s.
Plots done in 73.91 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 3359.53 s.
===========
Run 179/360 done in 6947.32 s.
===========

Directory ../../results/MsplineN_new/run_180/ already exists.
Skipping it.
===========
Run 180/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_181/ already exists.
Skipping it.
===========
Run 181/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_182/ already exists.
Skipping it.
===========
Run 182/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_183/ already exists.
Skipping it.
===========
Run 183/360 already exists. Skipping it.
===========

===========
Generating train data for run 184.
===========
Train data generated in 0.14 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_184/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 541}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_184/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.672276  , 7.747077  , 5.353606  , ..., 1.9898596 , 6.4533057 ,
        1.3801477 ],
       [6.831665  , 2.8270175 , 6.123529  , ..., 3.7326455 , 4.034952  ,
        1.2204404 ],
       [6.945523  , 3.0432987 , 6.2105227 , ..., 3.0559149 , 4.230059  ,
        2.415763  ],
       ...,
       [5.3746367 , 7.366772  , 6.0980034 , ..., 1.4703689 , 7.145194  ,
        1.4068515 ],
       [1.7761964 , 3.7400303 , 9.268795  , ..., 5.5180016 , 0.19900042,
        4.052124  ],
       [5.3399296 , 8.263746  , 6.06707   , ..., 1.0115646 , 6.354734  ,
        1.5268791 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_184/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_184
self.data_kwargs: {'seed': 541}
self.x_data: [[7.2128525 3.0379212 6.2367196 ... 3.0671625 3.9712758 2.9062366]
 [6.9294653 2.776415  6.1588674 ... 3.1774852 3.3745446 1.8558645]
 [5.9664783 2.8420978 6.1059666 ... 2.842883  4.150837  2.5282533]
 ...
 [1.7772449 4.049644  7.7634    ... 5.1831775 1.4676232 2.7587254]
 [5.071257  6.457654  5.797537  ... 1.1522104 7.100011  1.4003892]
 [5.5332866 8.634485  5.3762307 ... 1.4035112 6.4775186 1.2732773]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model_25"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_76 (InputLayer)       [(None, 64)]              0         
                                                                 
 log_prob_layer_25 (LogProbL  (None,)                  1447808   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,447,808
Trainable params: 1,447,808
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_25/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_25'")
self.model: <keras.engine.functional.Functional object at 0x7fc618e60dc0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc623e52bc0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc623e52bc0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc623e53490>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc622778190>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc622778700>, <keras.callbacks.ModelCheckpoint object at 0x7fc6227787c0>, <keras.callbacks.EarlyStopping object at 0x7fc622778a30>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc622778a60>, <keras.callbacks.TerminateOnNaN object at 0x7fc6227786a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[5.672276  , 7.747077  , 5.353606  , ..., 1.9898596 , 6.4533057 ,
        1.3801477 ],
       [6.831665  , 2.8270175 , 6.123529  , ..., 3.7326455 , 4.034952  ,
        1.2204404 ],
       [6.945523  , 3.0432987 , 6.2105227 , ..., 3.0559149 , 4.230059  ,
        2.415763  ],
       ...,
       [5.3746367 , 7.366772  , 6.0980034 , ..., 1.4703689 , 7.145194  ,
        1.4068515 ],
       [1.7761964 , 3.7400303 , 9.268795  , ..., 5.5180016 , 0.19900042,
        4.052124  ],
       [5.3399296 , 8.263746  , 6.06707   , ..., 1.0115646 , 6.354734  ,
        1.5268791 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_184/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 184/360 with hyperparameters:
timestamp = 2023-09-12 23:42:26.848401
ndims = 64
seed_train = 541
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1447808
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 7.2128525   3.0379212   6.2367196   4.3304725   1.1500694   2.2690165
  5.1556735   5.938522    5.8135405   6.610918    6.7030854   3.1799724
  8.919708    2.7416692   3.9000368   9.134979    8.039232    8.02363
  1.5622978   9.261075    6.5763392  10.023463    0.6410362   8.711104
  0.19289434  6.151961    1.8393004   7.966868    8.919258    6.2695036
  4.6195264   0.72402155  6.516158    4.5063744   6.651485    8.823901
 10.0223675   8.378911    0.25785983  3.0188398   7.1746483   2.8368304
  5.7315655   1.0176957   2.865625    0.34789518  8.293505    2.1613307
  3.3841972   9.323753    7.32612    -0.01674449  0.4303813   7.508686
  5.7885385   2.6548457   8.486073    6.1425443   5.8022866   6.5669823
  7.4040923   3.0671625   3.9712758   2.9062366 ]
Epoch 1/1000
2023-09-12 23:42:59.256 
Epoch 1/1000 
	 loss: 87.9098, MinusLogProbMetric: 87.9098, val_loss: 33.9614, val_MinusLogProbMetric: 33.9614

Epoch 1: val_loss improved from inf to 33.96144, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 32s - loss: 87.9098 - MinusLogProbMetric: 87.9098 - val_loss: 33.9614 - val_MinusLogProbMetric: 33.9614 - lr: 0.0010 - 32s/epoch - 165ms/step
Epoch 2/1000
2023-09-12 23:43:08.529 
Epoch 2/1000 
	 loss: 31.8575, MinusLogProbMetric: 31.8575, val_loss: 30.8701, val_MinusLogProbMetric: 30.8701

Epoch 2: val_loss improved from 33.96144 to 30.87013, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 31.8575 - MinusLogProbMetric: 31.8575 - val_loss: 30.8701 - val_MinusLogProbMetric: 30.8701 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 3/1000
2023-09-12 23:43:20.049 
Epoch 3/1000 
	 loss: 30.2830, MinusLogProbMetric: 30.2830, val_loss: 29.8504, val_MinusLogProbMetric: 29.8504

Epoch 3: val_loss improved from 30.87013 to 29.85036, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 12s - loss: 30.2830 - MinusLogProbMetric: 30.2830 - val_loss: 29.8504 - val_MinusLogProbMetric: 29.8504 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 4/1000
2023-09-12 23:43:29.967 
Epoch 4/1000 
	 loss: 29.5645, MinusLogProbMetric: 29.5645, val_loss: 29.3413, val_MinusLogProbMetric: 29.3413

Epoch 4: val_loss improved from 29.85036 to 29.34130, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 10s - loss: 29.5645 - MinusLogProbMetric: 29.5645 - val_loss: 29.3413 - val_MinusLogProbMetric: 29.3413 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 5/1000
2023-09-12 23:43:39.412 
Epoch 5/1000 
	 loss: 29.2655, MinusLogProbMetric: 29.2655, val_loss: 29.0959, val_MinusLogProbMetric: 29.0959

Epoch 5: val_loss improved from 29.34130 to 29.09594, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 29.2655 - MinusLogProbMetric: 29.2655 - val_loss: 29.0959 - val_MinusLogProbMetric: 29.0959 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 6/1000
2023-09-12 23:43:48.535 
Epoch 6/1000 
	 loss: 28.9238, MinusLogProbMetric: 28.9238, val_loss: 29.0866, val_MinusLogProbMetric: 29.0866

Epoch 6: val_loss improved from 29.09594 to 29.08664, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 28.9238 - MinusLogProbMetric: 28.9238 - val_loss: 29.0866 - val_MinusLogProbMetric: 29.0866 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 7/1000
2023-09-12 23:43:57.486 
Epoch 7/1000 
	 loss: 28.7555, MinusLogProbMetric: 28.7555, val_loss: 29.3030, val_MinusLogProbMetric: 29.3030

Epoch 7: val_loss did not improve from 29.08664
196/196 - 9s - loss: 28.7555 - MinusLogProbMetric: 28.7555 - val_loss: 29.3030 - val_MinusLogProbMetric: 29.3030 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 8/1000
2023-09-12 23:44:08.052 
Epoch 8/1000 
	 loss: 28.6551, MinusLogProbMetric: 28.6551, val_loss: 28.5675, val_MinusLogProbMetric: 28.5675

Epoch 8: val_loss improved from 29.08664 to 28.56748, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 11s - loss: 28.6551 - MinusLogProbMetric: 28.6551 - val_loss: 28.5675 - val_MinusLogProbMetric: 28.5675 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 9/1000
2023-09-12 23:44:19.762 
Epoch 9/1000 
	 loss: 28.5135, MinusLogProbMetric: 28.5135, val_loss: 28.9347, val_MinusLogProbMetric: 28.9347

Epoch 9: val_loss did not improve from 28.56748
196/196 - 12s - loss: 28.5135 - MinusLogProbMetric: 28.5135 - val_loss: 28.9347 - val_MinusLogProbMetric: 28.9347 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 10/1000
2023-09-12 23:44:29.108 
Epoch 10/1000 
	 loss: 28.4536, MinusLogProbMetric: 28.4536, val_loss: 28.5702, val_MinusLogProbMetric: 28.5702

Epoch 10: val_loss did not improve from 28.56748
196/196 - 9s - loss: 28.4536 - MinusLogProbMetric: 28.4536 - val_loss: 28.5702 - val_MinusLogProbMetric: 28.5702 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 11/1000
2023-09-12 23:44:38.990 
Epoch 11/1000 
	 loss: 28.3896, MinusLogProbMetric: 28.3896, val_loss: 28.6642, val_MinusLogProbMetric: 28.6642

Epoch 11: val_loss did not improve from 28.56748
196/196 - 10s - loss: 28.3896 - MinusLogProbMetric: 28.3896 - val_loss: 28.6642 - val_MinusLogProbMetric: 28.6642 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 12/1000
2023-09-12 23:44:50.676 
Epoch 12/1000 
	 loss: 28.3161, MinusLogProbMetric: 28.3161, val_loss: 28.0706, val_MinusLogProbMetric: 28.0706

Epoch 12: val_loss improved from 28.56748 to 28.07059, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 12s - loss: 28.3161 - MinusLogProbMetric: 28.3161 - val_loss: 28.0706 - val_MinusLogProbMetric: 28.0706 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 13/1000
2023-09-12 23:45:00.230 
Epoch 13/1000 
	 loss: 28.2907, MinusLogProbMetric: 28.2907, val_loss: 28.1964, val_MinusLogProbMetric: 28.1964

Epoch 13: val_loss did not improve from 28.07059
196/196 - 9s - loss: 28.2907 - MinusLogProbMetric: 28.2907 - val_loss: 28.1964 - val_MinusLogProbMetric: 28.1964 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 14/1000
2023-09-12 23:45:09.451 
Epoch 14/1000 
	 loss: 28.1682, MinusLogProbMetric: 28.1682, val_loss: 28.1687, val_MinusLogProbMetric: 28.1687

Epoch 14: val_loss did not improve from 28.07059
196/196 - 9s - loss: 28.1682 - MinusLogProbMetric: 28.1682 - val_loss: 28.1687 - val_MinusLogProbMetric: 28.1687 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 15/1000
2023-09-12 23:45:18.633 
Epoch 15/1000 
	 loss: 28.1600, MinusLogProbMetric: 28.1600, val_loss: 28.3841, val_MinusLogProbMetric: 28.3841

Epoch 15: val_loss did not improve from 28.07059
196/196 - 9s - loss: 28.1600 - MinusLogProbMetric: 28.1600 - val_loss: 28.3841 - val_MinusLogProbMetric: 28.3841 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 16/1000
2023-09-12 23:45:27.553 
Epoch 16/1000 
	 loss: 28.1564, MinusLogProbMetric: 28.1564, val_loss: 28.1840, val_MinusLogProbMetric: 28.1840

Epoch 16: val_loss did not improve from 28.07059
196/196 - 9s - loss: 28.1564 - MinusLogProbMetric: 28.1564 - val_loss: 28.1840 - val_MinusLogProbMetric: 28.1840 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 17/1000
2023-09-12 23:45:36.955 
Epoch 17/1000 
	 loss: 28.1061, MinusLogProbMetric: 28.1061, val_loss: 28.1083, val_MinusLogProbMetric: 28.1083

Epoch 17: val_loss did not improve from 28.07059
196/196 - 9s - loss: 28.1061 - MinusLogProbMetric: 28.1061 - val_loss: 28.1083 - val_MinusLogProbMetric: 28.1083 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 18/1000
2023-09-12 23:45:45.875 
Epoch 18/1000 
	 loss: 28.1198, MinusLogProbMetric: 28.1198, val_loss: 28.2193, val_MinusLogProbMetric: 28.2193

Epoch 18: val_loss did not improve from 28.07059
196/196 - 9s - loss: 28.1198 - MinusLogProbMetric: 28.1198 - val_loss: 28.2193 - val_MinusLogProbMetric: 28.2193 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 19/1000
2023-09-12 23:45:54.827 
Epoch 19/1000 
	 loss: 28.0511, MinusLogProbMetric: 28.0511, val_loss: 28.1386, val_MinusLogProbMetric: 28.1386

Epoch 19: val_loss did not improve from 28.07059
196/196 - 9s - loss: 28.0511 - MinusLogProbMetric: 28.0511 - val_loss: 28.1386 - val_MinusLogProbMetric: 28.1386 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 20/1000
2023-09-12 23:46:03.767 
Epoch 20/1000 
	 loss: 28.0312, MinusLogProbMetric: 28.0312, val_loss: 27.9982, val_MinusLogProbMetric: 27.9982

Epoch 20: val_loss improved from 28.07059 to 27.99815, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 28.0312 - MinusLogProbMetric: 28.0312 - val_loss: 27.9982 - val_MinusLogProbMetric: 27.9982 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 21/1000
2023-09-12 23:46:12.957 
Epoch 21/1000 
	 loss: 27.9945, MinusLogProbMetric: 27.9945, val_loss: 28.0409, val_MinusLogProbMetric: 28.0409

Epoch 21: val_loss did not improve from 27.99815
196/196 - 9s - loss: 27.9945 - MinusLogProbMetric: 27.9945 - val_loss: 28.0409 - val_MinusLogProbMetric: 28.0409 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 22/1000
2023-09-12 23:46:21.920 
Epoch 22/1000 
	 loss: 27.9795, MinusLogProbMetric: 27.9795, val_loss: 28.2752, val_MinusLogProbMetric: 28.2752

Epoch 22: val_loss did not improve from 27.99815
196/196 - 9s - loss: 27.9795 - MinusLogProbMetric: 27.9795 - val_loss: 28.2752 - val_MinusLogProbMetric: 28.2752 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 23/1000
2023-09-12 23:46:30.900 
Epoch 23/1000 
	 loss: 27.9986, MinusLogProbMetric: 27.9986, val_loss: 27.9258, val_MinusLogProbMetric: 27.9258

Epoch 23: val_loss improved from 27.99815 to 27.92583, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 27.9986 - MinusLogProbMetric: 27.9986 - val_loss: 27.9258 - val_MinusLogProbMetric: 27.9258 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 24/1000
2023-09-12 23:46:39.817 
Epoch 24/1000 
	 loss: 27.9451, MinusLogProbMetric: 27.9451, val_loss: 27.9502, val_MinusLogProbMetric: 27.9502

Epoch 24: val_loss did not improve from 27.92583
196/196 - 9s - loss: 27.9451 - MinusLogProbMetric: 27.9451 - val_loss: 27.9502 - val_MinusLogProbMetric: 27.9502 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 25/1000
2023-09-12 23:46:48.697 
Epoch 25/1000 
	 loss: 27.9367, MinusLogProbMetric: 27.9367, val_loss: 28.0629, val_MinusLogProbMetric: 28.0629

Epoch 25: val_loss did not improve from 27.92583
196/196 - 9s - loss: 27.9367 - MinusLogProbMetric: 27.9367 - val_loss: 28.0629 - val_MinusLogProbMetric: 28.0629 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 26/1000
2023-09-12 23:46:57.589 
Epoch 26/1000 
	 loss: 27.9139, MinusLogProbMetric: 27.9139, val_loss: 27.8304, val_MinusLogProbMetric: 27.8304

Epoch 26: val_loss improved from 27.92583 to 27.83041, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 27.9139 - MinusLogProbMetric: 27.9139 - val_loss: 27.8304 - val_MinusLogProbMetric: 27.8304 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 27/1000
2023-09-12 23:47:06.522 
Epoch 27/1000 
	 loss: 27.8800, MinusLogProbMetric: 27.8800, val_loss: 28.0226, val_MinusLogProbMetric: 28.0226

Epoch 27: val_loss did not improve from 27.83041
196/196 - 9s - loss: 27.8800 - MinusLogProbMetric: 27.8800 - val_loss: 28.0226 - val_MinusLogProbMetric: 28.0226 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 28/1000
2023-09-12 23:47:15.451 
Epoch 28/1000 
	 loss: 27.8982, MinusLogProbMetric: 27.8982, val_loss: 28.1091, val_MinusLogProbMetric: 28.1091

Epoch 28: val_loss did not improve from 27.83041
196/196 - 9s - loss: 27.8982 - MinusLogProbMetric: 27.8982 - val_loss: 28.1091 - val_MinusLogProbMetric: 28.1091 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 29/1000
2023-09-12 23:47:24.225 
Epoch 29/1000 
	 loss: 27.8744, MinusLogProbMetric: 27.8744, val_loss: 28.1140, val_MinusLogProbMetric: 28.1140

Epoch 29: val_loss did not improve from 27.83041
196/196 - 9s - loss: 27.8744 - MinusLogProbMetric: 27.8744 - val_loss: 28.1140 - val_MinusLogProbMetric: 28.1140 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 30/1000
2023-09-12 23:47:33.127 
Epoch 30/1000 
	 loss: 27.8605, MinusLogProbMetric: 27.8605, val_loss: 27.9032, val_MinusLogProbMetric: 27.9032

Epoch 30: val_loss did not improve from 27.83041
196/196 - 9s - loss: 27.8605 - MinusLogProbMetric: 27.8605 - val_loss: 27.9032 - val_MinusLogProbMetric: 27.9032 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 31/1000
2023-09-12 23:47:42.365 
Epoch 31/1000 
	 loss: 27.8175, MinusLogProbMetric: 27.8175, val_loss: 27.9454, val_MinusLogProbMetric: 27.9454

Epoch 31: val_loss did not improve from 27.83041
196/196 - 9s - loss: 27.8175 - MinusLogProbMetric: 27.8175 - val_loss: 27.9454 - val_MinusLogProbMetric: 27.9454 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 32/1000
2023-09-12 23:47:51.551 
Epoch 32/1000 
	 loss: 27.8352, MinusLogProbMetric: 27.8352, val_loss: 27.9244, val_MinusLogProbMetric: 27.9244

Epoch 32: val_loss did not improve from 27.83041
196/196 - 9s - loss: 27.8352 - MinusLogProbMetric: 27.8352 - val_loss: 27.9244 - val_MinusLogProbMetric: 27.9244 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 33/1000
2023-09-12 23:48:00.547 
Epoch 33/1000 
	 loss: 27.7968, MinusLogProbMetric: 27.7968, val_loss: 27.7776, val_MinusLogProbMetric: 27.7776

Epoch 33: val_loss improved from 27.83041 to 27.77764, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 27.7968 - MinusLogProbMetric: 27.7968 - val_loss: 27.7776 - val_MinusLogProbMetric: 27.7776 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 34/1000
2023-09-12 23:48:10.138 
Epoch 34/1000 
	 loss: 27.8028, MinusLogProbMetric: 27.8028, val_loss: 27.9817, val_MinusLogProbMetric: 27.9817

Epoch 34: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.8028 - MinusLogProbMetric: 27.8028 - val_loss: 27.9817 - val_MinusLogProbMetric: 27.9817 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 35/1000
2023-09-12 23:48:21.609 
Epoch 35/1000 
	 loss: 27.8220, MinusLogProbMetric: 27.8220, val_loss: 27.9011, val_MinusLogProbMetric: 27.9011

Epoch 35: val_loss did not improve from 27.77764
196/196 - 11s - loss: 27.8220 - MinusLogProbMetric: 27.8220 - val_loss: 27.9011 - val_MinusLogProbMetric: 27.9011 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 36/1000
2023-09-12 23:48:33.069 
Epoch 36/1000 
	 loss: 27.7890, MinusLogProbMetric: 27.7890, val_loss: 27.8298, val_MinusLogProbMetric: 27.8298

Epoch 36: val_loss did not improve from 27.77764
196/196 - 11s - loss: 27.7890 - MinusLogProbMetric: 27.7890 - val_loss: 27.8298 - val_MinusLogProbMetric: 27.8298 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 37/1000
2023-09-12 23:48:42.415 
Epoch 37/1000 
	 loss: 27.7982, MinusLogProbMetric: 27.7982, val_loss: 28.0125, val_MinusLogProbMetric: 28.0125

Epoch 37: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.7982 - MinusLogProbMetric: 27.7982 - val_loss: 28.0125 - val_MinusLogProbMetric: 28.0125 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 38/1000
2023-09-12 23:48:51.795 
Epoch 38/1000 
	 loss: 27.7919, MinusLogProbMetric: 27.7919, val_loss: 27.8553, val_MinusLogProbMetric: 27.8553

Epoch 38: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.7919 - MinusLogProbMetric: 27.7919 - val_loss: 27.8553 - val_MinusLogProbMetric: 27.8553 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 39/1000
2023-09-12 23:49:01.103 
Epoch 39/1000 
	 loss: 27.7410, MinusLogProbMetric: 27.7410, val_loss: 27.9492, val_MinusLogProbMetric: 27.9492

Epoch 39: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.7410 - MinusLogProbMetric: 27.7410 - val_loss: 27.9492 - val_MinusLogProbMetric: 27.9492 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 40/1000
2023-09-12 23:49:10.372 
Epoch 40/1000 
	 loss: 27.7649, MinusLogProbMetric: 27.7649, val_loss: 27.8103, val_MinusLogProbMetric: 27.8103

Epoch 40: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.7649 - MinusLogProbMetric: 27.7649 - val_loss: 27.8103 - val_MinusLogProbMetric: 27.8103 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 41/1000
2023-09-12 23:49:19.616 
Epoch 41/1000 
	 loss: 27.7631, MinusLogProbMetric: 27.7631, val_loss: 27.8133, val_MinusLogProbMetric: 27.8133

Epoch 41: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.7631 - MinusLogProbMetric: 27.7631 - val_loss: 27.8133 - val_MinusLogProbMetric: 27.8133 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 42/1000
2023-09-12 23:49:28.760 
Epoch 42/1000 
	 loss: 27.7531, MinusLogProbMetric: 27.7531, val_loss: 27.8436, val_MinusLogProbMetric: 27.8436

Epoch 42: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.7531 - MinusLogProbMetric: 27.7531 - val_loss: 27.8436 - val_MinusLogProbMetric: 27.8436 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 43/1000
2023-09-12 23:49:37.991 
Epoch 43/1000 
	 loss: 27.7448, MinusLogProbMetric: 27.7448, val_loss: 27.7890, val_MinusLogProbMetric: 27.7890

Epoch 43: val_loss did not improve from 27.77764
196/196 - 9s - loss: 27.7448 - MinusLogProbMetric: 27.7448 - val_loss: 27.7890 - val_MinusLogProbMetric: 27.7890 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 44/1000
2023-09-12 23:49:47.631 
Epoch 44/1000 
	 loss: 27.7361, MinusLogProbMetric: 27.7361, val_loss: 27.7370, val_MinusLogProbMetric: 27.7370

Epoch 44: val_loss improved from 27.77764 to 27.73696, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 10s - loss: 27.7361 - MinusLogProbMetric: 27.7361 - val_loss: 27.7370 - val_MinusLogProbMetric: 27.7370 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 45/1000
2023-09-12 23:49:57.986 
Epoch 45/1000 
	 loss: 27.7141, MinusLogProbMetric: 27.7141, val_loss: 27.7848, val_MinusLogProbMetric: 27.7848

Epoch 45: val_loss did not improve from 27.73696
196/196 - 10s - loss: 27.7141 - MinusLogProbMetric: 27.7141 - val_loss: 27.7848 - val_MinusLogProbMetric: 27.7848 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 46/1000
2023-09-12 23:50:08.346 
Epoch 46/1000 
	 loss: 27.7207, MinusLogProbMetric: 27.7207, val_loss: 27.8752, val_MinusLogProbMetric: 27.8752

Epoch 46: val_loss did not improve from 27.73696
196/196 - 10s - loss: 27.7207 - MinusLogProbMetric: 27.7207 - val_loss: 27.8752 - val_MinusLogProbMetric: 27.8752 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 47/1000
2023-09-12 23:50:17.570 
Epoch 47/1000 
	 loss: 27.7396, MinusLogProbMetric: 27.7396, val_loss: 27.8166, val_MinusLogProbMetric: 27.8166

Epoch 47: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.7396 - MinusLogProbMetric: 27.7396 - val_loss: 27.8166 - val_MinusLogProbMetric: 27.8166 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 48/1000
2023-09-12 23:50:26.856 
Epoch 48/1000 
	 loss: 27.7053, MinusLogProbMetric: 27.7053, val_loss: 27.8354, val_MinusLogProbMetric: 27.8354

Epoch 48: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.7053 - MinusLogProbMetric: 27.7053 - val_loss: 27.8354 - val_MinusLogProbMetric: 27.8354 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 49/1000
2023-09-12 23:50:36.064 
Epoch 49/1000 
	 loss: 27.7178, MinusLogProbMetric: 27.7178, val_loss: 27.8065, val_MinusLogProbMetric: 27.8065

Epoch 49: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.7178 - MinusLogProbMetric: 27.7178 - val_loss: 27.8065 - val_MinusLogProbMetric: 27.8065 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 50/1000
2023-09-12 23:50:45.359 
Epoch 50/1000 
	 loss: 27.6954, MinusLogProbMetric: 27.6954, val_loss: 27.9582, val_MinusLogProbMetric: 27.9582

Epoch 50: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.6954 - MinusLogProbMetric: 27.6954 - val_loss: 27.9582 - val_MinusLogProbMetric: 27.9582 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 51/1000
2023-09-12 23:50:55.785 
Epoch 51/1000 
	 loss: 27.6890, MinusLogProbMetric: 27.6890, val_loss: 27.8560, val_MinusLogProbMetric: 27.8560

Epoch 51: val_loss did not improve from 27.73696
196/196 - 10s - loss: 27.6890 - MinusLogProbMetric: 27.6890 - val_loss: 27.8560 - val_MinusLogProbMetric: 27.8560 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 52/1000
2023-09-12 23:51:07.443 
Epoch 52/1000 
	 loss: 27.7022, MinusLogProbMetric: 27.7022, val_loss: 27.7801, val_MinusLogProbMetric: 27.7801

Epoch 52: val_loss did not improve from 27.73696
196/196 - 12s - loss: 27.7022 - MinusLogProbMetric: 27.7022 - val_loss: 27.7801 - val_MinusLogProbMetric: 27.7801 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 53/1000
2023-09-12 23:51:19.125 
Epoch 53/1000 
	 loss: 27.6801, MinusLogProbMetric: 27.6801, val_loss: 27.8285, val_MinusLogProbMetric: 27.8285

Epoch 53: val_loss did not improve from 27.73696
196/196 - 12s - loss: 27.6801 - MinusLogProbMetric: 27.6801 - val_loss: 27.8285 - val_MinusLogProbMetric: 27.8285 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-12 23:51:28.962 
Epoch 54/1000 
	 loss: 27.6871, MinusLogProbMetric: 27.6871, val_loss: 27.9471, val_MinusLogProbMetric: 27.9471

Epoch 54: val_loss did not improve from 27.73696
196/196 - 10s - loss: 27.6871 - MinusLogProbMetric: 27.6871 - val_loss: 27.9471 - val_MinusLogProbMetric: 27.9471 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 55/1000
2023-09-12 23:51:38.055 
Epoch 55/1000 
	 loss: 27.6714, MinusLogProbMetric: 27.6714, val_loss: 27.8397, val_MinusLogProbMetric: 27.8397

Epoch 55: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.6714 - MinusLogProbMetric: 27.6714 - val_loss: 27.8397 - val_MinusLogProbMetric: 27.8397 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 56/1000
2023-09-12 23:51:49.294 
Epoch 56/1000 
	 loss: 27.6751, MinusLogProbMetric: 27.6751, val_loss: 27.8468, val_MinusLogProbMetric: 27.8468

Epoch 56: val_loss did not improve from 27.73696
196/196 - 11s - loss: 27.6751 - MinusLogProbMetric: 27.6751 - val_loss: 27.8468 - val_MinusLogProbMetric: 27.8468 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 57/1000
2023-09-12 23:52:00.813 
Epoch 57/1000 
	 loss: 27.6599, MinusLogProbMetric: 27.6599, val_loss: 27.8641, val_MinusLogProbMetric: 27.8641

Epoch 57: val_loss did not improve from 27.73696
196/196 - 12s - loss: 27.6599 - MinusLogProbMetric: 27.6599 - val_loss: 27.8641 - val_MinusLogProbMetric: 27.8641 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 58/1000
2023-09-12 23:52:12.357 
Epoch 58/1000 
	 loss: 27.6465, MinusLogProbMetric: 27.6465, val_loss: 27.7773, val_MinusLogProbMetric: 27.7773

Epoch 58: val_loss did not improve from 27.73696
196/196 - 12s - loss: 27.6465 - MinusLogProbMetric: 27.6465 - val_loss: 27.7773 - val_MinusLogProbMetric: 27.7773 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 59/1000
2023-09-12 23:52:24.074 
Epoch 59/1000 
	 loss: 27.6775, MinusLogProbMetric: 27.6775, val_loss: 27.8088, val_MinusLogProbMetric: 27.8088

Epoch 59: val_loss did not improve from 27.73696
196/196 - 12s - loss: 27.6775 - MinusLogProbMetric: 27.6775 - val_loss: 27.8088 - val_MinusLogProbMetric: 27.8088 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-12 23:52:35.377 
Epoch 60/1000 
	 loss: 27.6500, MinusLogProbMetric: 27.6500, val_loss: 27.7383, val_MinusLogProbMetric: 27.7383

Epoch 60: val_loss did not improve from 27.73696
196/196 - 11s - loss: 27.6500 - MinusLogProbMetric: 27.6500 - val_loss: 27.7383 - val_MinusLogProbMetric: 27.7383 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 61/1000
2023-09-12 23:52:44.638 
Epoch 61/1000 
	 loss: 27.6497, MinusLogProbMetric: 27.6497, val_loss: 27.7956, val_MinusLogProbMetric: 27.7956

Epoch 61: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.6497 - MinusLogProbMetric: 27.6497 - val_loss: 27.7956 - val_MinusLogProbMetric: 27.7956 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 62/1000
2023-09-12 23:52:53.954 
Epoch 62/1000 
	 loss: 27.6601, MinusLogProbMetric: 27.6601, val_loss: 27.8132, val_MinusLogProbMetric: 27.8132

Epoch 62: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.6601 - MinusLogProbMetric: 27.6601 - val_loss: 27.8132 - val_MinusLogProbMetric: 27.8132 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 63/1000
2023-09-12 23:53:03.239 
Epoch 63/1000 
	 loss: 27.6507, MinusLogProbMetric: 27.6507, val_loss: 27.7594, val_MinusLogProbMetric: 27.7594

Epoch 63: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.6507 - MinusLogProbMetric: 27.6507 - val_loss: 27.7594 - val_MinusLogProbMetric: 27.7594 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 64/1000
2023-09-12 23:53:12.668 
Epoch 64/1000 
	 loss: 27.6779, MinusLogProbMetric: 27.6779, val_loss: 27.8436, val_MinusLogProbMetric: 27.8436

Epoch 64: val_loss did not improve from 27.73696
196/196 - 9s - loss: 27.6779 - MinusLogProbMetric: 27.6779 - val_loss: 27.8436 - val_MinusLogProbMetric: 27.8436 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 65/1000
2023-09-12 23:53:23.343 
Epoch 65/1000 
	 loss: 27.6289, MinusLogProbMetric: 27.6289, val_loss: 27.7331, val_MinusLogProbMetric: 27.7331

Epoch 65: val_loss improved from 27.73696 to 27.73309, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 11s - loss: 27.6289 - MinusLogProbMetric: 27.6289 - val_loss: 27.7331 - val_MinusLogProbMetric: 27.7331 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 66/1000
2023-09-12 23:53:32.990 
Epoch 66/1000 
	 loss: 27.6084, MinusLogProbMetric: 27.6084, val_loss: 27.7674, val_MinusLogProbMetric: 27.7674

Epoch 66: val_loss did not improve from 27.73309
196/196 - 10s - loss: 27.6084 - MinusLogProbMetric: 27.6084 - val_loss: 27.7674 - val_MinusLogProbMetric: 27.7674 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 67/1000
2023-09-12 23:53:44.585 
Epoch 67/1000 
	 loss: 27.6566, MinusLogProbMetric: 27.6566, val_loss: 27.8352, val_MinusLogProbMetric: 27.8352

Epoch 67: val_loss did not improve from 27.73309
196/196 - 12s - loss: 27.6566 - MinusLogProbMetric: 27.6566 - val_loss: 27.8352 - val_MinusLogProbMetric: 27.8352 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 68/1000
2023-09-12 23:53:53.869 
Epoch 68/1000 
	 loss: 27.6279, MinusLogProbMetric: 27.6279, val_loss: 28.0525, val_MinusLogProbMetric: 28.0525

Epoch 68: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.6279 - MinusLogProbMetric: 27.6279 - val_loss: 28.0525 - val_MinusLogProbMetric: 28.0525 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 69/1000
2023-09-12 23:54:02.937 
Epoch 69/1000 
	 loss: 27.6203, MinusLogProbMetric: 27.6203, val_loss: 27.8294, val_MinusLogProbMetric: 27.8294

Epoch 69: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.6203 - MinusLogProbMetric: 27.6203 - val_loss: 27.8294 - val_MinusLogProbMetric: 27.8294 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 70/1000
2023-09-12 23:54:11.754 
Epoch 70/1000 
	 loss: 27.6037, MinusLogProbMetric: 27.6037, val_loss: 27.8888, val_MinusLogProbMetric: 27.8888

Epoch 70: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.6037 - MinusLogProbMetric: 27.6037 - val_loss: 27.8888 - val_MinusLogProbMetric: 27.8888 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 71/1000
2023-09-12 23:54:20.621 
Epoch 71/1000 
	 loss: 27.6247, MinusLogProbMetric: 27.6247, val_loss: 27.8308, val_MinusLogProbMetric: 27.8308

Epoch 71: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.6247 - MinusLogProbMetric: 27.6247 - val_loss: 27.8308 - val_MinusLogProbMetric: 27.8308 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 72/1000
2023-09-12 23:54:29.625 
Epoch 72/1000 
	 loss: 27.6150, MinusLogProbMetric: 27.6150, val_loss: 27.7700, val_MinusLogProbMetric: 27.7700

Epoch 72: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.6150 - MinusLogProbMetric: 27.6150 - val_loss: 27.7700 - val_MinusLogProbMetric: 27.7700 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 73/1000
2023-09-12 23:54:38.587 
Epoch 73/1000 
	 loss: 27.5890, MinusLogProbMetric: 27.5890, val_loss: 27.8481, val_MinusLogProbMetric: 27.8481

Epoch 73: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.5890 - MinusLogProbMetric: 27.5890 - val_loss: 27.8481 - val_MinusLogProbMetric: 27.8481 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 74/1000
2023-09-12 23:54:47.701 
Epoch 74/1000 
	 loss: 27.5921, MinusLogProbMetric: 27.5921, val_loss: 27.8075, val_MinusLogProbMetric: 27.8075

Epoch 74: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.5921 - MinusLogProbMetric: 27.5921 - val_loss: 27.8075 - val_MinusLogProbMetric: 27.8075 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 75/1000
2023-09-12 23:54:56.853 
Epoch 75/1000 
	 loss: 27.5933, MinusLogProbMetric: 27.5933, val_loss: 27.7879, val_MinusLogProbMetric: 27.7879

Epoch 75: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.5933 - MinusLogProbMetric: 27.5933 - val_loss: 27.7879 - val_MinusLogProbMetric: 27.7879 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 76/1000
2023-09-12 23:55:06.822 
Epoch 76/1000 
	 loss: 27.5898, MinusLogProbMetric: 27.5898, val_loss: 27.9632, val_MinusLogProbMetric: 27.9632

Epoch 76: val_loss did not improve from 27.73309
196/196 - 10s - loss: 27.5898 - MinusLogProbMetric: 27.5898 - val_loss: 27.9632 - val_MinusLogProbMetric: 27.9632 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 77/1000
2023-09-12 23:55:17.577 
Epoch 77/1000 
	 loss: 27.6087, MinusLogProbMetric: 27.6087, val_loss: 27.8909, val_MinusLogProbMetric: 27.8909

Epoch 77: val_loss did not improve from 27.73309
196/196 - 11s - loss: 27.6087 - MinusLogProbMetric: 27.6087 - val_loss: 27.8909 - val_MinusLogProbMetric: 27.8909 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 78/1000
2023-09-12 23:55:28.191 
Epoch 78/1000 
	 loss: 27.5795, MinusLogProbMetric: 27.5795, val_loss: 27.8003, val_MinusLogProbMetric: 27.8003

Epoch 78: val_loss did not improve from 27.73309
196/196 - 11s - loss: 27.5795 - MinusLogProbMetric: 27.5795 - val_loss: 27.8003 - val_MinusLogProbMetric: 27.8003 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 79/1000
2023-09-12 23:55:37.375 
Epoch 79/1000 
	 loss: 27.5706, MinusLogProbMetric: 27.5706, val_loss: 27.7360, val_MinusLogProbMetric: 27.7360

Epoch 79: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.5706 - MinusLogProbMetric: 27.5706 - val_loss: 27.7360 - val_MinusLogProbMetric: 27.7360 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 80/1000
2023-09-12 23:55:46.830 
Epoch 80/1000 
	 loss: 27.5816, MinusLogProbMetric: 27.5816, val_loss: 27.7856, val_MinusLogProbMetric: 27.7856

Epoch 80: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.5816 - MinusLogProbMetric: 27.5816 - val_loss: 27.7856 - val_MinusLogProbMetric: 27.7856 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 81/1000
2023-09-12 23:55:56.196 
Epoch 81/1000 
	 loss: 27.5799, MinusLogProbMetric: 27.5799, val_loss: 27.7369, val_MinusLogProbMetric: 27.7369

Epoch 81: val_loss did not improve from 27.73309
196/196 - 9s - loss: 27.5799 - MinusLogProbMetric: 27.5799 - val_loss: 27.7369 - val_MinusLogProbMetric: 27.7369 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 82/1000
2023-09-12 23:56:05.210 
Epoch 82/1000 
	 loss: 27.5693, MinusLogProbMetric: 27.5693, val_loss: 27.7207, val_MinusLogProbMetric: 27.7207

Epoch 82: val_loss improved from 27.73309 to 27.72067, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 27.5693 - MinusLogProbMetric: 27.5693 - val_loss: 27.7207 - val_MinusLogProbMetric: 27.7207 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 83/1000
2023-09-12 23:56:14.341 
Epoch 83/1000 
	 loss: 27.5587, MinusLogProbMetric: 27.5587, val_loss: 27.8098, val_MinusLogProbMetric: 27.8098

Epoch 83: val_loss did not improve from 27.72067
196/196 - 9s - loss: 27.5587 - MinusLogProbMetric: 27.5587 - val_loss: 27.8098 - val_MinusLogProbMetric: 27.8098 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 84/1000
2023-09-12 23:56:23.520 
Epoch 84/1000 
	 loss: 27.5479, MinusLogProbMetric: 27.5479, val_loss: 27.7169, val_MinusLogProbMetric: 27.7169

Epoch 84: val_loss improved from 27.72067 to 27.71689, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 9s - loss: 27.5479 - MinusLogProbMetric: 27.5479 - val_loss: 27.7169 - val_MinusLogProbMetric: 27.7169 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 85/1000
2023-09-12 23:56:32.646 
Epoch 85/1000 
	 loss: 27.5558, MinusLogProbMetric: 27.5558, val_loss: 27.7239, val_MinusLogProbMetric: 27.7239

Epoch 85: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5558 - MinusLogProbMetric: 27.5558 - val_loss: 27.7239 - val_MinusLogProbMetric: 27.7239 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 86/1000
2023-09-12 23:56:41.584 
Epoch 86/1000 
	 loss: 27.5530, MinusLogProbMetric: 27.5530, val_loss: 27.8643, val_MinusLogProbMetric: 27.8643

Epoch 86: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5530 - MinusLogProbMetric: 27.5530 - val_loss: 27.8643 - val_MinusLogProbMetric: 27.8643 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 87/1000
2023-09-12 23:56:51.142 
Epoch 87/1000 
	 loss: 27.5361, MinusLogProbMetric: 27.5361, val_loss: 27.7527, val_MinusLogProbMetric: 27.7527

Epoch 87: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.5361 - MinusLogProbMetric: 27.5361 - val_loss: 27.7527 - val_MinusLogProbMetric: 27.7527 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 88/1000
2023-09-12 23:57:00.947 
Epoch 88/1000 
	 loss: 27.5436, MinusLogProbMetric: 27.5436, val_loss: 27.8203, val_MinusLogProbMetric: 27.8203

Epoch 88: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.5436 - MinusLogProbMetric: 27.5436 - val_loss: 27.8203 - val_MinusLogProbMetric: 27.8203 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 89/1000
2023-09-12 23:57:11.960 
Epoch 89/1000 
	 loss: 27.5538, MinusLogProbMetric: 27.5538, val_loss: 27.8301, val_MinusLogProbMetric: 27.8301

Epoch 89: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.5538 - MinusLogProbMetric: 27.5538 - val_loss: 27.8301 - val_MinusLogProbMetric: 27.8301 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 90/1000
2023-09-12 23:57:21.219 
Epoch 90/1000 
	 loss: 27.5335, MinusLogProbMetric: 27.5335, val_loss: 27.7559, val_MinusLogProbMetric: 27.7559

Epoch 90: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5335 - MinusLogProbMetric: 27.5335 - val_loss: 27.7559 - val_MinusLogProbMetric: 27.7559 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 91/1000
2023-09-12 23:57:30.226 
Epoch 91/1000 
	 loss: 27.5517, MinusLogProbMetric: 27.5517, val_loss: 27.8360, val_MinusLogProbMetric: 27.8360

Epoch 91: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5517 - MinusLogProbMetric: 27.5517 - val_loss: 27.8360 - val_MinusLogProbMetric: 27.8360 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 92/1000
2023-09-12 23:57:41.024 
Epoch 92/1000 
	 loss: 27.5440, MinusLogProbMetric: 27.5440, val_loss: 27.7196, val_MinusLogProbMetric: 27.7196

Epoch 92: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.5440 - MinusLogProbMetric: 27.5440 - val_loss: 27.7196 - val_MinusLogProbMetric: 27.7196 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 93/1000
2023-09-12 23:57:52.397 
Epoch 93/1000 
	 loss: 27.5200, MinusLogProbMetric: 27.5200, val_loss: 27.7770, val_MinusLogProbMetric: 27.7770

Epoch 93: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.5200 - MinusLogProbMetric: 27.5200 - val_loss: 27.7770 - val_MinusLogProbMetric: 27.7770 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 94/1000
2023-09-12 23:58:01.758 
Epoch 94/1000 
	 loss: 27.5425, MinusLogProbMetric: 27.5425, val_loss: 27.7581, val_MinusLogProbMetric: 27.7581

Epoch 94: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5425 - MinusLogProbMetric: 27.5425 - val_loss: 27.7581 - val_MinusLogProbMetric: 27.7581 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 95/1000
2023-09-12 23:58:11.241 
Epoch 95/1000 
	 loss: 27.5091, MinusLogProbMetric: 27.5091, val_loss: 27.9172, val_MinusLogProbMetric: 27.9172

Epoch 95: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5091 - MinusLogProbMetric: 27.5091 - val_loss: 27.9172 - val_MinusLogProbMetric: 27.9172 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 96/1000
2023-09-12 23:58:21.336 
Epoch 96/1000 
	 loss: 27.5150, MinusLogProbMetric: 27.5150, val_loss: 27.7894, val_MinusLogProbMetric: 27.7894

Epoch 96: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.5150 - MinusLogProbMetric: 27.5150 - val_loss: 27.7894 - val_MinusLogProbMetric: 27.7894 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 97/1000
2023-09-12 23:58:30.535 
Epoch 97/1000 
	 loss: 27.5152, MinusLogProbMetric: 27.5152, val_loss: 27.7840, val_MinusLogProbMetric: 27.7840

Epoch 97: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5152 - MinusLogProbMetric: 27.5152 - val_loss: 27.7840 - val_MinusLogProbMetric: 27.7840 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 98/1000
2023-09-12 23:58:40.059 
Epoch 98/1000 
	 loss: 27.5240, MinusLogProbMetric: 27.5240, val_loss: 27.7662, val_MinusLogProbMetric: 27.7662

Epoch 98: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.5240 - MinusLogProbMetric: 27.5240 - val_loss: 27.7662 - val_MinusLogProbMetric: 27.7662 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 99/1000
2023-09-12 23:58:49.113 
Epoch 99/1000 
	 loss: 27.5124, MinusLogProbMetric: 27.5124, val_loss: 27.7519, val_MinusLogProbMetric: 27.7519

Epoch 99: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5124 - MinusLogProbMetric: 27.5124 - val_loss: 27.7519 - val_MinusLogProbMetric: 27.7519 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 100/1000
2023-09-12 23:58:58.014 
Epoch 100/1000 
	 loss: 27.5122, MinusLogProbMetric: 27.5122, val_loss: 28.0459, val_MinusLogProbMetric: 28.0459

Epoch 100: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5122 - MinusLogProbMetric: 27.5122 - val_loss: 28.0459 - val_MinusLogProbMetric: 28.0459 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 101/1000
2023-09-12 23:59:07.049 
Epoch 101/1000 
	 loss: 27.5171, MinusLogProbMetric: 27.5171, val_loss: 27.9033, val_MinusLogProbMetric: 27.9033

Epoch 101: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5171 - MinusLogProbMetric: 27.5171 - val_loss: 27.9033 - val_MinusLogProbMetric: 27.9033 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 102/1000
2023-09-12 23:59:16.035 
Epoch 102/1000 
	 loss: 27.5134, MinusLogProbMetric: 27.5134, val_loss: 27.7422, val_MinusLogProbMetric: 27.7422

Epoch 102: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.5134 - MinusLogProbMetric: 27.5134 - val_loss: 27.7422 - val_MinusLogProbMetric: 27.7422 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 103/1000
2023-09-12 23:59:25.443 
Epoch 103/1000 
	 loss: 27.4920, MinusLogProbMetric: 27.4920, val_loss: 27.7724, val_MinusLogProbMetric: 27.7724

Epoch 103: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4920 - MinusLogProbMetric: 27.4920 - val_loss: 27.7724 - val_MinusLogProbMetric: 27.7724 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 104/1000
2023-09-12 23:59:34.925 
Epoch 104/1000 
	 loss: 27.4833, MinusLogProbMetric: 27.4833, val_loss: 27.8129, val_MinusLogProbMetric: 27.8129

Epoch 104: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4833 - MinusLogProbMetric: 27.4833 - val_loss: 27.8129 - val_MinusLogProbMetric: 27.8129 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 105/1000
2023-09-12 23:59:45.880 
Epoch 105/1000 
	 loss: 27.4951, MinusLogProbMetric: 27.4951, val_loss: 27.8181, val_MinusLogProbMetric: 27.8181

Epoch 105: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4951 - MinusLogProbMetric: 27.4951 - val_loss: 27.8181 - val_MinusLogProbMetric: 27.8181 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 106/1000
2023-09-12 23:59:56.164 
Epoch 106/1000 
	 loss: 27.4889, MinusLogProbMetric: 27.4889, val_loss: 27.8175, val_MinusLogProbMetric: 27.8175

Epoch 106: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.4889 - MinusLogProbMetric: 27.4889 - val_loss: 27.8175 - val_MinusLogProbMetric: 27.8175 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 107/1000
2023-09-13 00:00:05.357 
Epoch 107/1000 
	 loss: 27.4894, MinusLogProbMetric: 27.4894, val_loss: 27.8093, val_MinusLogProbMetric: 27.8093

Epoch 107: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4894 - MinusLogProbMetric: 27.4894 - val_loss: 27.8093 - val_MinusLogProbMetric: 27.8093 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 108/1000
2023-09-13 00:00:14.182 
Epoch 108/1000 
	 loss: 27.4836, MinusLogProbMetric: 27.4836, val_loss: 27.8035, val_MinusLogProbMetric: 27.8035

Epoch 108: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4836 - MinusLogProbMetric: 27.4836 - val_loss: 27.8035 - val_MinusLogProbMetric: 27.8035 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 109/1000
2023-09-13 00:00:24.491 
Epoch 109/1000 
	 loss: 27.4899, MinusLogProbMetric: 27.4899, val_loss: 27.7415, val_MinusLogProbMetric: 27.7415

Epoch 109: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.4899 - MinusLogProbMetric: 27.4899 - val_loss: 27.7415 - val_MinusLogProbMetric: 27.7415 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 110/1000
2023-09-13 00:00:35.356 
Epoch 110/1000 
	 loss: 27.4831, MinusLogProbMetric: 27.4831, val_loss: 27.8222, val_MinusLogProbMetric: 27.8222

Epoch 110: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4831 - MinusLogProbMetric: 27.4831 - val_loss: 27.8222 - val_MinusLogProbMetric: 27.8222 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 111/1000
2023-09-13 00:00:47.076 
Epoch 111/1000 
	 loss: 27.4729, MinusLogProbMetric: 27.4729, val_loss: 27.8172, val_MinusLogProbMetric: 27.8172

Epoch 111: val_loss did not improve from 27.71689
196/196 - 12s - loss: 27.4729 - MinusLogProbMetric: 27.4729 - val_loss: 27.8172 - val_MinusLogProbMetric: 27.8172 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-13 00:00:57.145 
Epoch 112/1000 
	 loss: 27.4736, MinusLogProbMetric: 27.4736, val_loss: 27.8054, val_MinusLogProbMetric: 27.8054

Epoch 112: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.4736 - MinusLogProbMetric: 27.4736 - val_loss: 27.8054 - val_MinusLogProbMetric: 27.8054 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 113/1000
2023-09-13 00:01:06.141 
Epoch 113/1000 
	 loss: 27.4714, MinusLogProbMetric: 27.4714, val_loss: 27.7605, val_MinusLogProbMetric: 27.7605

Epoch 113: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4714 - MinusLogProbMetric: 27.4714 - val_loss: 27.7605 - val_MinusLogProbMetric: 27.7605 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 114/1000
2023-09-13 00:01:15.262 
Epoch 114/1000 
	 loss: 27.4661, MinusLogProbMetric: 27.4661, val_loss: 27.7761, val_MinusLogProbMetric: 27.7761

Epoch 114: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4661 - MinusLogProbMetric: 27.4661 - val_loss: 27.7761 - val_MinusLogProbMetric: 27.7761 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 115/1000
2023-09-13 00:01:25.973 
Epoch 115/1000 
	 loss: 27.4729, MinusLogProbMetric: 27.4729, val_loss: 27.8495, val_MinusLogProbMetric: 27.8495

Epoch 115: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4729 - MinusLogProbMetric: 27.4729 - val_loss: 27.8495 - val_MinusLogProbMetric: 27.8495 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 116/1000
2023-09-13 00:01:36.663 
Epoch 116/1000 
	 loss: 27.4561, MinusLogProbMetric: 27.4561, val_loss: 27.7757, val_MinusLogProbMetric: 27.7757

Epoch 116: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4561 - MinusLogProbMetric: 27.4561 - val_loss: 27.7757 - val_MinusLogProbMetric: 27.7757 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 117/1000
2023-09-13 00:01:48.334 
Epoch 117/1000 
	 loss: 27.4422, MinusLogProbMetric: 27.4422, val_loss: 27.8822, val_MinusLogProbMetric: 27.8822

Epoch 117: val_loss did not improve from 27.71689
196/196 - 12s - loss: 27.4422 - MinusLogProbMetric: 27.4422 - val_loss: 27.8822 - val_MinusLogProbMetric: 27.8822 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 118/1000
2023-09-13 00:01:59.816 
Epoch 118/1000 
	 loss: 27.4780, MinusLogProbMetric: 27.4780, val_loss: 27.7996, val_MinusLogProbMetric: 27.7996

Epoch 118: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4780 - MinusLogProbMetric: 27.4780 - val_loss: 27.7996 - val_MinusLogProbMetric: 27.7996 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 119/1000
2023-09-13 00:02:09.992 
Epoch 119/1000 
	 loss: 27.4445, MinusLogProbMetric: 27.4445, val_loss: 27.8774, val_MinusLogProbMetric: 27.8774

Epoch 119: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.4445 - MinusLogProbMetric: 27.4445 - val_loss: 27.8774 - val_MinusLogProbMetric: 27.8774 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 120/1000
2023-09-13 00:02:19.067 
Epoch 120/1000 
	 loss: 27.4548, MinusLogProbMetric: 27.4548, val_loss: 27.7711, val_MinusLogProbMetric: 27.7711

Epoch 120: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4548 - MinusLogProbMetric: 27.4548 - val_loss: 27.7711 - val_MinusLogProbMetric: 27.7711 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 121/1000
2023-09-13 00:02:29.609 
Epoch 121/1000 
	 loss: 27.4350, MinusLogProbMetric: 27.4350, val_loss: 27.8197, val_MinusLogProbMetric: 27.8197

Epoch 121: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4350 - MinusLogProbMetric: 27.4350 - val_loss: 27.8197 - val_MinusLogProbMetric: 27.8197 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 122/1000
2023-09-13 00:02:39.287 
Epoch 122/1000 
	 loss: 27.4411, MinusLogProbMetric: 27.4411, val_loss: 27.7858, val_MinusLogProbMetric: 27.7858

Epoch 122: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.4411 - MinusLogProbMetric: 27.4411 - val_loss: 27.7858 - val_MinusLogProbMetric: 27.7858 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 123/1000
2023-09-13 00:02:48.432 
Epoch 123/1000 
	 loss: 27.4381, MinusLogProbMetric: 27.4381, val_loss: 27.7340, val_MinusLogProbMetric: 27.7340

Epoch 123: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4381 - MinusLogProbMetric: 27.4381 - val_loss: 27.7340 - val_MinusLogProbMetric: 27.7340 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 124/1000
2023-09-13 00:02:59.077 
Epoch 124/1000 
	 loss: 27.4462, MinusLogProbMetric: 27.4462, val_loss: 27.8535, val_MinusLogProbMetric: 27.8535

Epoch 124: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4462 - MinusLogProbMetric: 27.4462 - val_loss: 27.8535 - val_MinusLogProbMetric: 27.8535 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 125/1000
2023-09-13 00:03:10.533 
Epoch 125/1000 
	 loss: 27.4284, MinusLogProbMetric: 27.4284, val_loss: 27.7628, val_MinusLogProbMetric: 27.7628

Epoch 125: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4284 - MinusLogProbMetric: 27.4284 - val_loss: 27.7628 - val_MinusLogProbMetric: 27.7628 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 126/1000
2023-09-13 00:03:19.570 
Epoch 126/1000 
	 loss: 27.4388, MinusLogProbMetric: 27.4388, val_loss: 27.7886, val_MinusLogProbMetric: 27.7886

Epoch 126: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4388 - MinusLogProbMetric: 27.4388 - val_loss: 27.7886 - val_MinusLogProbMetric: 27.7886 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 127/1000
2023-09-13 00:03:28.679 
Epoch 127/1000 
	 loss: 27.4190, MinusLogProbMetric: 27.4190, val_loss: 27.7959, val_MinusLogProbMetric: 27.7959

Epoch 127: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4190 - MinusLogProbMetric: 27.4190 - val_loss: 27.7959 - val_MinusLogProbMetric: 27.7959 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 128/1000
2023-09-13 00:03:37.954 
Epoch 128/1000 
	 loss: 27.4395, MinusLogProbMetric: 27.4395, val_loss: 27.8264, val_MinusLogProbMetric: 27.8264

Epoch 128: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4395 - MinusLogProbMetric: 27.4395 - val_loss: 27.8264 - val_MinusLogProbMetric: 27.8264 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 129/1000
2023-09-13 00:03:49.491 
Epoch 129/1000 
	 loss: 27.4205, MinusLogProbMetric: 27.4205, val_loss: 27.7796, val_MinusLogProbMetric: 27.7796

Epoch 129: val_loss did not improve from 27.71689
196/196 - 12s - loss: 27.4205 - MinusLogProbMetric: 27.4205 - val_loss: 27.7796 - val_MinusLogProbMetric: 27.7796 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 130/1000
2023-09-13 00:04:00.459 
Epoch 130/1000 
	 loss: 27.4204, MinusLogProbMetric: 27.4204, val_loss: 27.8424, val_MinusLogProbMetric: 27.8424

Epoch 130: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4204 - MinusLogProbMetric: 27.4204 - val_loss: 27.8424 - val_MinusLogProbMetric: 27.8424 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 131/1000
2023-09-13 00:04:09.403 
Epoch 131/1000 
	 loss: 27.4196, MinusLogProbMetric: 27.4196, val_loss: 27.7897, val_MinusLogProbMetric: 27.7897

Epoch 131: val_loss did not improve from 27.71689
196/196 - 9s - loss: 27.4196 - MinusLogProbMetric: 27.4196 - val_loss: 27.7897 - val_MinusLogProbMetric: 27.7897 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 132/1000
2023-09-13 00:04:19.998 
Epoch 132/1000 
	 loss: 27.4108, MinusLogProbMetric: 27.4108, val_loss: 27.7482, val_MinusLogProbMetric: 27.7482

Epoch 132: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4108 - MinusLogProbMetric: 27.4108 - val_loss: 27.7482 - val_MinusLogProbMetric: 27.7482 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 133/1000
2023-09-13 00:04:29.897 
Epoch 133/1000 
	 loss: 27.4060, MinusLogProbMetric: 27.4060, val_loss: 27.8732, val_MinusLogProbMetric: 27.8732

Epoch 133: val_loss did not improve from 27.71689
196/196 - 10s - loss: 27.4060 - MinusLogProbMetric: 27.4060 - val_loss: 27.8732 - val_MinusLogProbMetric: 27.8732 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 134/1000
2023-09-13 00:04:41.253 
Epoch 134/1000 
	 loss: 27.4188, MinusLogProbMetric: 27.4188, val_loss: 27.8085, val_MinusLogProbMetric: 27.8085

Epoch 134: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.4188 - MinusLogProbMetric: 27.4188 - val_loss: 27.8085 - val_MinusLogProbMetric: 27.8085 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 135/1000
2023-09-13 00:04:51.773 
Epoch 135/1000 
	 loss: 27.2860, MinusLogProbMetric: 27.2860, val_loss: 27.7201, val_MinusLogProbMetric: 27.7201

Epoch 135: val_loss did not improve from 27.71689
196/196 - 11s - loss: 27.2860 - MinusLogProbMetric: 27.2860 - val_loss: 27.7201 - val_MinusLogProbMetric: 27.7201 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 136/1000
2023-09-13 00:05:01.709 
Epoch 136/1000 
	 loss: 27.2885, MinusLogProbMetric: 27.2885, val_loss: 27.7119, val_MinusLogProbMetric: 27.7119

Epoch 136: val_loss improved from 27.71689 to 27.71192, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_184/weights/best_weights.h5
196/196 - 10s - loss: 27.2885 - MinusLogProbMetric: 27.2885 - val_loss: 27.7119 - val_MinusLogProbMetric: 27.7119 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 137/1000
2023-09-13 00:05:11.105 
Epoch 137/1000 
	 loss: 27.2862, MinusLogProbMetric: 27.2862, val_loss: 27.7183, val_MinusLogProbMetric: 27.7183

Epoch 137: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2862 - MinusLogProbMetric: 27.2862 - val_loss: 27.7183 - val_MinusLogProbMetric: 27.7183 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 138/1000
2023-09-13 00:05:22.182 
Epoch 138/1000 
	 loss: 27.2879, MinusLogProbMetric: 27.2879, val_loss: 27.7810, val_MinusLogProbMetric: 27.7810

Epoch 138: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2879 - MinusLogProbMetric: 27.2879 - val_loss: 27.7810 - val_MinusLogProbMetric: 27.7810 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 139/1000
2023-09-13 00:05:31.118 
Epoch 139/1000 
	 loss: 27.2864, MinusLogProbMetric: 27.2864, val_loss: 27.7655, val_MinusLogProbMetric: 27.7655

Epoch 139: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2864 - MinusLogProbMetric: 27.2864 - val_loss: 27.7655 - val_MinusLogProbMetric: 27.7655 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 140/1000
2023-09-13 00:05:40.283 
Epoch 140/1000 
	 loss: 27.2876, MinusLogProbMetric: 27.2876, val_loss: 27.7322, val_MinusLogProbMetric: 27.7322

Epoch 140: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2876 - MinusLogProbMetric: 27.2876 - val_loss: 27.7322 - val_MinusLogProbMetric: 27.7322 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 141/1000
2023-09-13 00:05:51.526 
Epoch 141/1000 
	 loss: 27.2855, MinusLogProbMetric: 27.2855, val_loss: 27.7222, val_MinusLogProbMetric: 27.7222

Epoch 141: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2855 - MinusLogProbMetric: 27.2855 - val_loss: 27.7222 - val_MinusLogProbMetric: 27.7222 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 142/1000
2023-09-13 00:06:03.136 
Epoch 142/1000 
	 loss: 27.2762, MinusLogProbMetric: 27.2762, val_loss: 27.7209, val_MinusLogProbMetric: 27.7209

Epoch 142: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.2762 - MinusLogProbMetric: 27.2762 - val_loss: 27.7209 - val_MinusLogProbMetric: 27.7209 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 143/1000
2023-09-13 00:06:12.921 
Epoch 143/1000 
	 loss: 27.2806, MinusLogProbMetric: 27.2806, val_loss: 27.7623, val_MinusLogProbMetric: 27.7623

Epoch 143: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.2806 - MinusLogProbMetric: 27.2806 - val_loss: 27.7623 - val_MinusLogProbMetric: 27.7623 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 144/1000
2023-09-13 00:06:23.186 
Epoch 144/1000 
	 loss: 27.2738, MinusLogProbMetric: 27.2738, val_loss: 27.7581, val_MinusLogProbMetric: 27.7581

Epoch 144: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.2738 - MinusLogProbMetric: 27.2738 - val_loss: 27.7581 - val_MinusLogProbMetric: 27.7581 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 145/1000
2023-09-13 00:06:34.097 
Epoch 145/1000 
	 loss: 27.2713, MinusLogProbMetric: 27.2713, val_loss: 27.7456, val_MinusLogProbMetric: 27.7456

Epoch 145: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2713 - MinusLogProbMetric: 27.2713 - val_loss: 27.7456 - val_MinusLogProbMetric: 27.7456 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 146/1000
2023-09-13 00:06:45.846 
Epoch 146/1000 
	 loss: 27.2760, MinusLogProbMetric: 27.2760, val_loss: 27.7458, val_MinusLogProbMetric: 27.7458

Epoch 146: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.2760 - MinusLogProbMetric: 27.2760 - val_loss: 27.7458 - val_MinusLogProbMetric: 27.7458 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 147/1000
2023-09-13 00:06:56.350 
Epoch 147/1000 
	 loss: 27.2699, MinusLogProbMetric: 27.2699, val_loss: 27.7369, val_MinusLogProbMetric: 27.7369

Epoch 147: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2699 - MinusLogProbMetric: 27.2699 - val_loss: 27.7369 - val_MinusLogProbMetric: 27.7369 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 148/1000
2023-09-13 00:07:05.847 
Epoch 148/1000 
	 loss: 27.2721, MinusLogProbMetric: 27.2721, val_loss: 27.7663, val_MinusLogProbMetric: 27.7663

Epoch 148: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2721 - MinusLogProbMetric: 27.2721 - val_loss: 27.7663 - val_MinusLogProbMetric: 27.7663 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 149/1000
2023-09-13 00:07:14.857 
Epoch 149/1000 
	 loss: 27.2741, MinusLogProbMetric: 27.2741, val_loss: 27.7339, val_MinusLogProbMetric: 27.7339

Epoch 149: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2741 - MinusLogProbMetric: 27.2741 - val_loss: 27.7339 - val_MinusLogProbMetric: 27.7339 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 150/1000
2023-09-13 00:07:24.242 
Epoch 150/1000 
	 loss: 27.2696, MinusLogProbMetric: 27.2696, val_loss: 27.7605, val_MinusLogProbMetric: 27.7605

Epoch 150: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2696 - MinusLogProbMetric: 27.2696 - val_loss: 27.7605 - val_MinusLogProbMetric: 27.7605 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 151/1000
2023-09-13 00:07:33.227 
Epoch 151/1000 
	 loss: 27.2659, MinusLogProbMetric: 27.2659, val_loss: 27.7503, val_MinusLogProbMetric: 27.7503

Epoch 151: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2659 - MinusLogProbMetric: 27.2659 - val_loss: 27.7503 - val_MinusLogProbMetric: 27.7503 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 152/1000
2023-09-13 00:07:43.217 
Epoch 152/1000 
	 loss: 27.2640, MinusLogProbMetric: 27.2640, val_loss: 27.7473, val_MinusLogProbMetric: 27.7473

Epoch 152: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.2640 - MinusLogProbMetric: 27.2640 - val_loss: 27.7473 - val_MinusLogProbMetric: 27.7473 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 153/1000
2023-09-13 00:07:54.460 
Epoch 153/1000 
	 loss: 27.2539, MinusLogProbMetric: 27.2539, val_loss: 27.7928, val_MinusLogProbMetric: 27.7928

Epoch 153: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2539 - MinusLogProbMetric: 27.2539 - val_loss: 27.7928 - val_MinusLogProbMetric: 27.7928 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 154/1000
2023-09-13 00:08:04.750 
Epoch 154/1000 
	 loss: 27.2573, MinusLogProbMetric: 27.2573, val_loss: 27.7557, val_MinusLogProbMetric: 27.7557

Epoch 154: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.2573 - MinusLogProbMetric: 27.2573 - val_loss: 27.7557 - val_MinusLogProbMetric: 27.7557 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 155/1000
2023-09-13 00:08:16.062 
Epoch 155/1000 
	 loss: 27.2607, MinusLogProbMetric: 27.2607, val_loss: 27.7738, val_MinusLogProbMetric: 27.7738

Epoch 155: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2607 - MinusLogProbMetric: 27.2607 - val_loss: 27.7738 - val_MinusLogProbMetric: 27.7738 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 156/1000
2023-09-13 00:08:25.120 
Epoch 156/1000 
	 loss: 27.2633, MinusLogProbMetric: 27.2633, val_loss: 27.7673, val_MinusLogProbMetric: 27.7673

Epoch 156: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2633 - MinusLogProbMetric: 27.2633 - val_loss: 27.7673 - val_MinusLogProbMetric: 27.7673 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 157/1000
2023-09-13 00:08:34.061 
Epoch 157/1000 
	 loss: 27.2592, MinusLogProbMetric: 27.2592, val_loss: 27.7646, val_MinusLogProbMetric: 27.7646

Epoch 157: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2592 - MinusLogProbMetric: 27.2592 - val_loss: 27.7646 - val_MinusLogProbMetric: 27.7646 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 158/1000
2023-09-13 00:08:43.114 
Epoch 158/1000 
	 loss: 27.2614, MinusLogProbMetric: 27.2614, val_loss: 27.7730, val_MinusLogProbMetric: 27.7730

Epoch 158: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2614 - MinusLogProbMetric: 27.2614 - val_loss: 27.7730 - val_MinusLogProbMetric: 27.7730 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 159/1000
2023-09-13 00:08:52.093 
Epoch 159/1000 
	 loss: 27.2534, MinusLogProbMetric: 27.2534, val_loss: 27.8042, val_MinusLogProbMetric: 27.8042

Epoch 159: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2534 - MinusLogProbMetric: 27.2534 - val_loss: 27.8042 - val_MinusLogProbMetric: 27.8042 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 160/1000
2023-09-13 00:09:01.081 
Epoch 160/1000 
	 loss: 27.2492, MinusLogProbMetric: 27.2492, val_loss: 27.7420, val_MinusLogProbMetric: 27.7420

Epoch 160: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2492 - MinusLogProbMetric: 27.2492 - val_loss: 27.7420 - val_MinusLogProbMetric: 27.7420 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 161/1000
2023-09-13 00:09:12.141 
Epoch 161/1000 
	 loss: 27.2475, MinusLogProbMetric: 27.2475, val_loss: 27.7600, val_MinusLogProbMetric: 27.7600

Epoch 161: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2475 - MinusLogProbMetric: 27.2475 - val_loss: 27.7600 - val_MinusLogProbMetric: 27.7600 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 162/1000
2023-09-13 00:09:23.897 
Epoch 162/1000 
	 loss: 27.2555, MinusLogProbMetric: 27.2555, val_loss: 27.7522, val_MinusLogProbMetric: 27.7522

Epoch 162: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.2555 - MinusLogProbMetric: 27.2555 - val_loss: 27.7522 - val_MinusLogProbMetric: 27.7522 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 163/1000
2023-09-13 00:09:33.254 
Epoch 163/1000 
	 loss: 27.2446, MinusLogProbMetric: 27.2446, val_loss: 27.7834, val_MinusLogProbMetric: 27.7834

Epoch 163: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2446 - MinusLogProbMetric: 27.2446 - val_loss: 27.7834 - val_MinusLogProbMetric: 27.7834 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 164/1000
2023-09-13 00:09:42.394 
Epoch 164/1000 
	 loss: 27.2507, MinusLogProbMetric: 27.2507, val_loss: 27.7830, val_MinusLogProbMetric: 27.7830

Epoch 164: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2507 - MinusLogProbMetric: 27.2507 - val_loss: 27.7830 - val_MinusLogProbMetric: 27.7830 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 165/1000
2023-09-13 00:09:51.489 
Epoch 165/1000 
	 loss: 27.2443, MinusLogProbMetric: 27.2443, val_loss: 27.8000, val_MinusLogProbMetric: 27.8000

Epoch 165: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2443 - MinusLogProbMetric: 27.2443 - val_loss: 27.8000 - val_MinusLogProbMetric: 27.8000 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 166/1000
2023-09-13 00:10:00.547 
Epoch 166/1000 
	 loss: 27.2458, MinusLogProbMetric: 27.2458, val_loss: 27.7734, val_MinusLogProbMetric: 27.7734

Epoch 166: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2458 - MinusLogProbMetric: 27.2458 - val_loss: 27.7734 - val_MinusLogProbMetric: 27.7734 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 167/1000
2023-09-13 00:10:09.356 
Epoch 167/1000 
	 loss: 27.2382, MinusLogProbMetric: 27.2382, val_loss: 27.8030, val_MinusLogProbMetric: 27.8030

Epoch 167: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2382 - MinusLogProbMetric: 27.2382 - val_loss: 27.8030 - val_MinusLogProbMetric: 27.8030 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 168/1000
2023-09-13 00:10:18.295 
Epoch 168/1000 
	 loss: 27.2430, MinusLogProbMetric: 27.2430, val_loss: 27.7784, val_MinusLogProbMetric: 27.7784

Epoch 168: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2430 - MinusLogProbMetric: 27.2430 - val_loss: 27.7784 - val_MinusLogProbMetric: 27.7784 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 169/1000
2023-09-13 00:10:27.336 
Epoch 169/1000 
	 loss: 27.2404, MinusLogProbMetric: 27.2404, val_loss: 27.7812, val_MinusLogProbMetric: 27.7812

Epoch 169: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2404 - MinusLogProbMetric: 27.2404 - val_loss: 27.7812 - val_MinusLogProbMetric: 27.7812 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 170/1000
2023-09-13 00:10:36.528 
Epoch 170/1000 
	 loss: 27.2397, MinusLogProbMetric: 27.2397, val_loss: 27.7597, val_MinusLogProbMetric: 27.7597

Epoch 170: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2397 - MinusLogProbMetric: 27.2397 - val_loss: 27.7597 - val_MinusLogProbMetric: 27.7597 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 171/1000
2023-09-13 00:10:47.684 
Epoch 171/1000 
	 loss: 27.2373, MinusLogProbMetric: 27.2373, val_loss: 27.7983, val_MinusLogProbMetric: 27.7983

Epoch 171: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2373 - MinusLogProbMetric: 27.2373 - val_loss: 27.7983 - val_MinusLogProbMetric: 27.7983 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 172/1000
2023-09-13 00:10:58.347 
Epoch 172/1000 
	 loss: 27.2376, MinusLogProbMetric: 27.2376, val_loss: 27.8028, val_MinusLogProbMetric: 27.8028

Epoch 172: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2376 - MinusLogProbMetric: 27.2376 - val_loss: 27.8028 - val_MinusLogProbMetric: 27.8028 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 173/1000
2023-09-13 00:11:08.036 
Epoch 173/1000 
	 loss: 27.2396, MinusLogProbMetric: 27.2396, val_loss: 27.7856, val_MinusLogProbMetric: 27.7856

Epoch 173: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.2396 - MinusLogProbMetric: 27.2396 - val_loss: 27.7856 - val_MinusLogProbMetric: 27.7856 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 174/1000
2023-09-13 00:11:17.133 
Epoch 174/1000 
	 loss: 27.2351, MinusLogProbMetric: 27.2351, val_loss: 27.8173, val_MinusLogProbMetric: 27.8173

Epoch 174: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2351 - MinusLogProbMetric: 27.2351 - val_loss: 27.8173 - val_MinusLogProbMetric: 27.8173 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 175/1000
2023-09-13 00:11:26.105 
Epoch 175/1000 
	 loss: 27.2330, MinusLogProbMetric: 27.2330, val_loss: 27.7729, val_MinusLogProbMetric: 27.7729

Epoch 175: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2330 - MinusLogProbMetric: 27.2330 - val_loss: 27.7729 - val_MinusLogProbMetric: 27.7729 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 176/1000
2023-09-13 00:11:35.289 
Epoch 176/1000 
	 loss: 27.2321, MinusLogProbMetric: 27.2321, val_loss: 27.7733, val_MinusLogProbMetric: 27.7733

Epoch 176: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2321 - MinusLogProbMetric: 27.2321 - val_loss: 27.7733 - val_MinusLogProbMetric: 27.7733 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 177/1000
2023-09-13 00:11:44.499 
Epoch 177/1000 
	 loss: 27.2304, MinusLogProbMetric: 27.2304, val_loss: 27.8060, val_MinusLogProbMetric: 27.8060

Epoch 177: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2304 - MinusLogProbMetric: 27.2304 - val_loss: 27.8060 - val_MinusLogProbMetric: 27.8060 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 178/1000
2023-09-13 00:11:53.673 
Epoch 178/1000 
	 loss: 27.2239, MinusLogProbMetric: 27.2239, val_loss: 27.8108, val_MinusLogProbMetric: 27.8108

Epoch 178: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2239 - MinusLogProbMetric: 27.2239 - val_loss: 27.8108 - val_MinusLogProbMetric: 27.8108 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 179/1000
2023-09-13 00:12:05.216 
Epoch 179/1000 
	 loss: 27.2247, MinusLogProbMetric: 27.2247, val_loss: 27.7769, val_MinusLogProbMetric: 27.7769

Epoch 179: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.2247 - MinusLogProbMetric: 27.2247 - val_loss: 27.7769 - val_MinusLogProbMetric: 27.7769 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 180/1000
2023-09-13 00:12:16.129 
Epoch 180/1000 
	 loss: 27.2233, MinusLogProbMetric: 27.2233, val_loss: 27.8038, val_MinusLogProbMetric: 27.8038

Epoch 180: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.2233 - MinusLogProbMetric: 27.2233 - val_loss: 27.8038 - val_MinusLogProbMetric: 27.8038 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 181/1000
2023-09-13 00:12:25.442 
Epoch 181/1000 
	 loss: 27.2332, MinusLogProbMetric: 27.2332, val_loss: 27.8189, val_MinusLogProbMetric: 27.8189

Epoch 181: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2332 - MinusLogProbMetric: 27.2332 - val_loss: 27.8189 - val_MinusLogProbMetric: 27.8189 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 182/1000
2023-09-13 00:12:34.361 
Epoch 182/1000 
	 loss: 27.2267, MinusLogProbMetric: 27.2267, val_loss: 27.8137, val_MinusLogProbMetric: 27.8137

Epoch 182: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2267 - MinusLogProbMetric: 27.2267 - val_loss: 27.8137 - val_MinusLogProbMetric: 27.8137 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 183/1000
2023-09-13 00:12:43.118 
Epoch 183/1000 
	 loss: 27.2252, MinusLogProbMetric: 27.2252, val_loss: 27.7955, val_MinusLogProbMetric: 27.7955

Epoch 183: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2252 - MinusLogProbMetric: 27.2252 - val_loss: 27.7955 - val_MinusLogProbMetric: 27.7955 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 184/1000
2023-09-13 00:12:52.245 
Epoch 184/1000 
	 loss: 27.2217, MinusLogProbMetric: 27.2217, val_loss: 27.7905, val_MinusLogProbMetric: 27.7905

Epoch 184: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2217 - MinusLogProbMetric: 27.2217 - val_loss: 27.7905 - val_MinusLogProbMetric: 27.7905 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 185/1000
2023-09-13 00:13:02.428 
Epoch 185/1000 
	 loss: 27.2199, MinusLogProbMetric: 27.2199, val_loss: 27.8245, val_MinusLogProbMetric: 27.8245

Epoch 185: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.2199 - MinusLogProbMetric: 27.2199 - val_loss: 27.8245 - val_MinusLogProbMetric: 27.8245 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 186/1000
2023-09-13 00:13:11.355 
Epoch 186/1000 
	 loss: 27.2176, MinusLogProbMetric: 27.2176, val_loss: 27.7924, val_MinusLogProbMetric: 27.7924

Epoch 186: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.2176 - MinusLogProbMetric: 27.2176 - val_loss: 27.7924 - val_MinusLogProbMetric: 27.7924 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 187/1000
2023-09-13 00:13:20.594 
Epoch 187/1000 
	 loss: 27.1612, MinusLogProbMetric: 27.1612, val_loss: 27.7863, val_MinusLogProbMetric: 27.7863

Epoch 187: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1612 - MinusLogProbMetric: 27.1612 - val_loss: 27.7863 - val_MinusLogProbMetric: 27.7863 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 188/1000
2023-09-13 00:13:31.498 
Epoch 188/1000 
	 loss: 27.1555, MinusLogProbMetric: 27.1555, val_loss: 27.7863, val_MinusLogProbMetric: 27.7863

Epoch 188: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1555 - MinusLogProbMetric: 27.1555 - val_loss: 27.7863 - val_MinusLogProbMetric: 27.7863 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 189/1000
2023-09-13 00:13:43.261 
Epoch 189/1000 
	 loss: 27.1571, MinusLogProbMetric: 27.1571, val_loss: 27.7949, val_MinusLogProbMetric: 27.7949

Epoch 189: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1571 - MinusLogProbMetric: 27.1571 - val_loss: 27.7949 - val_MinusLogProbMetric: 27.7949 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 190/1000
2023-09-13 00:13:54.972 
Epoch 190/1000 
	 loss: 27.1544, MinusLogProbMetric: 27.1544, val_loss: 27.7774, val_MinusLogProbMetric: 27.7774

Epoch 190: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1544 - MinusLogProbMetric: 27.1544 - val_loss: 27.7774 - val_MinusLogProbMetric: 27.7774 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-13 00:14:04.602 
Epoch 191/1000 
	 loss: 27.1540, MinusLogProbMetric: 27.1540, val_loss: 27.7728, val_MinusLogProbMetric: 27.7728

Epoch 191: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.1540 - MinusLogProbMetric: 27.1540 - val_loss: 27.7728 - val_MinusLogProbMetric: 27.7728 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 192/1000
2023-09-13 00:14:13.789 
Epoch 192/1000 
	 loss: 27.1526, MinusLogProbMetric: 27.1526, val_loss: 27.7846, val_MinusLogProbMetric: 27.7846

Epoch 192: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1526 - MinusLogProbMetric: 27.1526 - val_loss: 27.7846 - val_MinusLogProbMetric: 27.7846 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 193/1000
2023-09-13 00:14:24.552 
Epoch 193/1000 
	 loss: 27.1535, MinusLogProbMetric: 27.1535, val_loss: 27.7908, val_MinusLogProbMetric: 27.7908

Epoch 193: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1535 - MinusLogProbMetric: 27.1535 - val_loss: 27.7908 - val_MinusLogProbMetric: 27.7908 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 194/1000
2023-09-13 00:14:33.674 
Epoch 194/1000 
	 loss: 27.1484, MinusLogProbMetric: 27.1484, val_loss: 27.7927, val_MinusLogProbMetric: 27.7927

Epoch 194: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1484 - MinusLogProbMetric: 27.1484 - val_loss: 27.7927 - val_MinusLogProbMetric: 27.7927 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 195/1000
2023-09-13 00:14:42.656 
Epoch 195/1000 
	 loss: 27.1500, MinusLogProbMetric: 27.1500, val_loss: 27.7942, val_MinusLogProbMetric: 27.7942

Epoch 195: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1500 - MinusLogProbMetric: 27.1500 - val_loss: 27.7942 - val_MinusLogProbMetric: 27.7942 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 196/1000
2023-09-13 00:14:51.948 
Epoch 196/1000 
	 loss: 27.1511, MinusLogProbMetric: 27.1511, val_loss: 27.8081, val_MinusLogProbMetric: 27.8081

Epoch 196: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1511 - MinusLogProbMetric: 27.1511 - val_loss: 27.8081 - val_MinusLogProbMetric: 27.8081 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 197/1000
2023-09-13 00:15:00.989 
Epoch 197/1000 
	 loss: 27.1483, MinusLogProbMetric: 27.1483, val_loss: 27.7914, val_MinusLogProbMetric: 27.7914

Epoch 197: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1483 - MinusLogProbMetric: 27.1483 - val_loss: 27.7914 - val_MinusLogProbMetric: 27.7914 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 198/1000
2023-09-13 00:15:09.978 
Epoch 198/1000 
	 loss: 27.1476, MinusLogProbMetric: 27.1476, val_loss: 27.8043, val_MinusLogProbMetric: 27.8043

Epoch 198: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1476 - MinusLogProbMetric: 27.1476 - val_loss: 27.8043 - val_MinusLogProbMetric: 27.8043 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 199/1000
2023-09-13 00:15:18.972 
Epoch 199/1000 
	 loss: 27.1510, MinusLogProbMetric: 27.1510, val_loss: 27.7996, val_MinusLogProbMetric: 27.7996

Epoch 199: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1510 - MinusLogProbMetric: 27.1510 - val_loss: 27.7996 - val_MinusLogProbMetric: 27.7996 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 200/1000
2023-09-13 00:15:28.285 
Epoch 200/1000 
	 loss: 27.1458, MinusLogProbMetric: 27.1458, val_loss: 27.8058, val_MinusLogProbMetric: 27.8058

Epoch 200: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1458 - MinusLogProbMetric: 27.1458 - val_loss: 27.8058 - val_MinusLogProbMetric: 27.8058 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 201/1000
2023-09-13 00:15:38.172 
Epoch 201/1000 
	 loss: 27.1455, MinusLogProbMetric: 27.1455, val_loss: 27.8074, val_MinusLogProbMetric: 27.8074

Epoch 201: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.1455 - MinusLogProbMetric: 27.1455 - val_loss: 27.8074 - val_MinusLogProbMetric: 27.8074 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 202/1000
2023-09-13 00:15:48.150 
Epoch 202/1000 
	 loss: 27.1452, MinusLogProbMetric: 27.1452, val_loss: 27.7995, val_MinusLogProbMetric: 27.7995

Epoch 202: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.1452 - MinusLogProbMetric: 27.1452 - val_loss: 27.7995 - val_MinusLogProbMetric: 27.7995 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 203/1000
2023-09-13 00:15:57.079 
Epoch 203/1000 
	 loss: 27.1441, MinusLogProbMetric: 27.1441, val_loss: 27.8016, val_MinusLogProbMetric: 27.8016

Epoch 203: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1441 - MinusLogProbMetric: 27.1441 - val_loss: 27.8016 - val_MinusLogProbMetric: 27.8016 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 204/1000
2023-09-13 00:16:08.340 
Epoch 204/1000 
	 loss: 27.1444, MinusLogProbMetric: 27.1444, val_loss: 27.8030, val_MinusLogProbMetric: 27.8030

Epoch 204: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1444 - MinusLogProbMetric: 27.1444 - val_loss: 27.8030 - val_MinusLogProbMetric: 27.8030 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 205/1000
2023-09-13 00:16:18.512 
Epoch 205/1000 
	 loss: 27.1423, MinusLogProbMetric: 27.1423, val_loss: 27.8242, val_MinusLogProbMetric: 27.8242

Epoch 205: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.1423 - MinusLogProbMetric: 27.1423 - val_loss: 27.8242 - val_MinusLogProbMetric: 27.8242 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 206/1000
2023-09-13 00:16:27.517 
Epoch 206/1000 
	 loss: 27.1451, MinusLogProbMetric: 27.1451, val_loss: 27.8268, val_MinusLogProbMetric: 27.8268

Epoch 206: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1451 - MinusLogProbMetric: 27.1451 - val_loss: 27.8268 - val_MinusLogProbMetric: 27.8268 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 207/1000
2023-09-13 00:16:36.346 
Epoch 207/1000 
	 loss: 27.1393, MinusLogProbMetric: 27.1393, val_loss: 27.8167, val_MinusLogProbMetric: 27.8167

Epoch 207: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1393 - MinusLogProbMetric: 27.1393 - val_loss: 27.8167 - val_MinusLogProbMetric: 27.8167 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 208/1000
2023-09-13 00:16:46.434 
Epoch 208/1000 
	 loss: 27.1394, MinusLogProbMetric: 27.1394, val_loss: 27.7934, val_MinusLogProbMetric: 27.7934

Epoch 208: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.1394 - MinusLogProbMetric: 27.1394 - val_loss: 27.7934 - val_MinusLogProbMetric: 27.7934 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 209/1000
2023-09-13 00:16:58.077 
Epoch 209/1000 
	 loss: 27.1392, MinusLogProbMetric: 27.1392, val_loss: 27.8090, val_MinusLogProbMetric: 27.8090

Epoch 209: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1392 - MinusLogProbMetric: 27.1392 - val_loss: 27.8090 - val_MinusLogProbMetric: 27.8090 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-13 00:17:07.351 
Epoch 210/1000 
	 loss: 27.1381, MinusLogProbMetric: 27.1381, val_loss: 27.8090, val_MinusLogProbMetric: 27.8090

Epoch 210: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1381 - MinusLogProbMetric: 27.1381 - val_loss: 27.8090 - val_MinusLogProbMetric: 27.8090 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 211/1000
2023-09-13 00:17:16.574 
Epoch 211/1000 
	 loss: 27.1358, MinusLogProbMetric: 27.1358, val_loss: 27.8014, val_MinusLogProbMetric: 27.8014

Epoch 211: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1358 - MinusLogProbMetric: 27.1358 - val_loss: 27.8014 - val_MinusLogProbMetric: 27.8014 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 212/1000
2023-09-13 00:17:25.653 
Epoch 212/1000 
	 loss: 27.1393, MinusLogProbMetric: 27.1393, val_loss: 27.8268, val_MinusLogProbMetric: 27.8268

Epoch 212: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1393 - MinusLogProbMetric: 27.1393 - val_loss: 27.8268 - val_MinusLogProbMetric: 27.8268 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 213/1000
2023-09-13 00:17:34.610 
Epoch 213/1000 
	 loss: 27.1393, MinusLogProbMetric: 27.1393, val_loss: 27.8404, val_MinusLogProbMetric: 27.8404

Epoch 213: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1393 - MinusLogProbMetric: 27.1393 - val_loss: 27.8404 - val_MinusLogProbMetric: 27.8404 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 214/1000
2023-09-13 00:17:43.422 
Epoch 214/1000 
	 loss: 27.1372, MinusLogProbMetric: 27.1372, val_loss: 27.8185, val_MinusLogProbMetric: 27.8185

Epoch 214: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1372 - MinusLogProbMetric: 27.1372 - val_loss: 27.8185 - val_MinusLogProbMetric: 27.8185 - lr: 2.5000e-04 - 9s/epoch - 45ms/step
Epoch 215/1000
2023-09-13 00:17:53.396 
Epoch 215/1000 
	 loss: 27.1346, MinusLogProbMetric: 27.1346, val_loss: 27.8149, val_MinusLogProbMetric: 27.8149

Epoch 215: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.1346 - MinusLogProbMetric: 27.1346 - val_loss: 27.8149 - val_MinusLogProbMetric: 27.8149 - lr: 2.5000e-04 - 10s/epoch - 51ms/step
Epoch 216/1000
2023-09-13 00:18:02.607 
Epoch 216/1000 
	 loss: 27.1313, MinusLogProbMetric: 27.1313, val_loss: 27.8302, val_MinusLogProbMetric: 27.8302

Epoch 216: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1313 - MinusLogProbMetric: 27.1313 - val_loss: 27.8302 - val_MinusLogProbMetric: 27.8302 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 217/1000
2023-09-13 00:18:11.718 
Epoch 217/1000 
	 loss: 27.1360, MinusLogProbMetric: 27.1360, val_loss: 27.8494, val_MinusLogProbMetric: 27.8494

Epoch 217: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1360 - MinusLogProbMetric: 27.1360 - val_loss: 27.8494 - val_MinusLogProbMetric: 27.8494 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 218/1000
2023-09-13 00:18:20.934 
Epoch 218/1000 
	 loss: 27.1345, MinusLogProbMetric: 27.1345, val_loss: 27.8101, val_MinusLogProbMetric: 27.8101

Epoch 218: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1345 - MinusLogProbMetric: 27.1345 - val_loss: 27.8101 - val_MinusLogProbMetric: 27.8101 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 219/1000
2023-09-13 00:18:30.368 
Epoch 219/1000 
	 loss: 27.1346, MinusLogProbMetric: 27.1346, val_loss: 27.8207, val_MinusLogProbMetric: 27.8207

Epoch 219: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1346 - MinusLogProbMetric: 27.1346 - val_loss: 27.8207 - val_MinusLogProbMetric: 27.8207 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 220/1000
2023-09-13 00:18:42.083 
Epoch 220/1000 
	 loss: 27.1325, MinusLogProbMetric: 27.1325, val_loss: 27.8266, val_MinusLogProbMetric: 27.8266

Epoch 220: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1325 - MinusLogProbMetric: 27.1325 - val_loss: 27.8266 - val_MinusLogProbMetric: 27.8266 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 221/1000
2023-09-13 00:18:53.229 
Epoch 221/1000 
	 loss: 27.1336, MinusLogProbMetric: 27.1336, val_loss: 27.8288, val_MinusLogProbMetric: 27.8288

Epoch 221: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1336 - MinusLogProbMetric: 27.1336 - val_loss: 27.8288 - val_MinusLogProbMetric: 27.8288 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 222/1000
2023-09-13 00:19:03.902 
Epoch 222/1000 
	 loss: 27.1325, MinusLogProbMetric: 27.1325, val_loss: 27.8398, val_MinusLogProbMetric: 27.8398

Epoch 222: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1325 - MinusLogProbMetric: 27.1325 - val_loss: 27.8398 - val_MinusLogProbMetric: 27.8398 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 223/1000
2023-09-13 00:19:14.953 
Epoch 223/1000 
	 loss: 27.1309, MinusLogProbMetric: 27.1309, val_loss: 27.8335, val_MinusLogProbMetric: 27.8335

Epoch 223: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1309 - MinusLogProbMetric: 27.1309 - val_loss: 27.8335 - val_MinusLogProbMetric: 27.8335 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 224/1000
2023-09-13 00:19:25.665 
Epoch 224/1000 
	 loss: 27.1297, MinusLogProbMetric: 27.1297, val_loss: 27.8241, val_MinusLogProbMetric: 27.8241

Epoch 224: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1297 - MinusLogProbMetric: 27.1297 - val_loss: 27.8241 - val_MinusLogProbMetric: 27.8241 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 225/1000
2023-09-13 00:19:36.187 
Epoch 225/1000 
	 loss: 27.1286, MinusLogProbMetric: 27.1286, val_loss: 27.8382, val_MinusLogProbMetric: 27.8382

Epoch 225: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1286 - MinusLogProbMetric: 27.1286 - val_loss: 27.8382 - val_MinusLogProbMetric: 27.8382 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 226/1000
2023-09-13 00:19:45.588 
Epoch 226/1000 
	 loss: 27.1278, MinusLogProbMetric: 27.1278, val_loss: 27.8537, val_MinusLogProbMetric: 27.8537

Epoch 226: val_loss did not improve from 27.71192
196/196 - 9s - loss: 27.1278 - MinusLogProbMetric: 27.1278 - val_loss: 27.8537 - val_MinusLogProbMetric: 27.8537 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 227/1000
2023-09-13 00:19:55.355 
Epoch 227/1000 
	 loss: 27.1262, MinusLogProbMetric: 27.1262, val_loss: 27.8390, val_MinusLogProbMetric: 27.8390

Epoch 227: val_loss did not improve from 27.71192
196/196 - 10s - loss: 27.1262 - MinusLogProbMetric: 27.1262 - val_loss: 27.8390 - val_MinusLogProbMetric: 27.8390 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 228/1000
2023-09-13 00:20:07.276 
Epoch 228/1000 
	 loss: 27.1261, MinusLogProbMetric: 27.1261, val_loss: 27.8354, val_MinusLogProbMetric: 27.8354

Epoch 228: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1261 - MinusLogProbMetric: 27.1261 - val_loss: 27.8354 - val_MinusLogProbMetric: 27.8354 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 229/1000
2023-09-13 00:20:19.192 
Epoch 229/1000 
	 loss: 27.1251, MinusLogProbMetric: 27.1251, val_loss: 27.8484, val_MinusLogProbMetric: 27.8484

Epoch 229: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1251 - MinusLogProbMetric: 27.1251 - val_loss: 27.8484 - val_MinusLogProbMetric: 27.8484 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 230/1000
2023-09-13 00:20:31.075 
Epoch 230/1000 
	 loss: 27.1241, MinusLogProbMetric: 27.1241, val_loss: 27.8401, val_MinusLogProbMetric: 27.8401

Epoch 230: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1241 - MinusLogProbMetric: 27.1241 - val_loss: 27.8401 - val_MinusLogProbMetric: 27.8401 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 231/1000
2023-09-13 00:20:42.919 
Epoch 231/1000 
	 loss: 27.1231, MinusLogProbMetric: 27.1231, val_loss: 27.8294, val_MinusLogProbMetric: 27.8294

Epoch 231: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1231 - MinusLogProbMetric: 27.1231 - val_loss: 27.8294 - val_MinusLogProbMetric: 27.8294 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 232/1000
2023-09-13 00:20:54.787 
Epoch 232/1000 
	 loss: 27.1235, MinusLogProbMetric: 27.1235, val_loss: 27.8562, val_MinusLogProbMetric: 27.8562

Epoch 232: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1235 - MinusLogProbMetric: 27.1235 - val_loss: 27.8562 - val_MinusLogProbMetric: 27.8562 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 233/1000
2023-09-13 00:21:06.629 
Epoch 233/1000 
	 loss: 27.1258, MinusLogProbMetric: 27.1258, val_loss: 27.8601, val_MinusLogProbMetric: 27.8601

Epoch 233: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1258 - MinusLogProbMetric: 27.1258 - val_loss: 27.8601 - val_MinusLogProbMetric: 27.8601 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 234/1000
2023-09-13 00:21:18.337 
Epoch 234/1000 
	 loss: 27.1227, MinusLogProbMetric: 27.1227, val_loss: 27.8539, val_MinusLogProbMetric: 27.8539

Epoch 234: val_loss did not improve from 27.71192
196/196 - 12s - loss: 27.1227 - MinusLogProbMetric: 27.1227 - val_loss: 27.8539 - val_MinusLogProbMetric: 27.8539 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-13 00:21:29.479 
Epoch 235/1000 
	 loss: 27.1225, MinusLogProbMetric: 27.1225, val_loss: 27.8609, val_MinusLogProbMetric: 27.8609

Epoch 235: val_loss did not improve from 27.71192
196/196 - 11s - loss: 27.1225 - MinusLogProbMetric: 27.1225 - val_loss: 27.8609 - val_MinusLogProbMetric: 27.8609 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 236/1000
2023-09-13 00:21:39.123 
Epoch 236/1000 
	 loss: 27.1227, MinusLogProbMetric: 27.1227, val_loss: 27.8610, val_MinusLogProbMetric: 27.8610

Epoch 236: val_loss did not improve from 27.71192
Restoring model weights from the end of the best epoch: 136.
196/196 - 10s - loss: 27.1227 - MinusLogProbMetric: 27.1227 - val_loss: 27.8610 - val_MinusLogProbMetric: 27.8610 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 236: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 9.72695541405119 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 4.84355264599435 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.857259324984625 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.5595832550898194 seconds.
WARNING:root:Too few points to create valid contours
Training succeeded with seed 541.
Model trained in 2352.35 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Metrics computed in 3049.15 s.
Plots done in 64.83 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 3113.98 s.
===========
Run 184/360 done in 5467.63 s.
===========

Directory ../../results/MsplineN_new/run_185/ already exists.
Skipping it.
===========
Run 185/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_186/ already exists.
Skipping it.
===========
Run 186/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_187/ already exists.
Skipping it.
===========
Run 187/360 already exists. Skipping it.
===========

===========
Generating train data for run 188.
===========
Train data generated in 0.13 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 64)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_188/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 721}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_188/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.958336 ,  3.6590893,  8.676455 , ...,  5.9946833,  2.2094154,
         2.624469 ],
       [ 1.2393765,  3.8911932,  8.905665 , ...,  5.783149 ,  1.3067368,
         2.3810356],
       [ 6.815516 ,  2.883391 ,  6.09811  , ...,  2.679101 ,  5.190114 ,
         1.7287396],
       ...,
       [ 5.1098504,  8.570955 ,  5.486371 , ...,  2.6942174,  5.2584124,
         1.4402856],
       [ 1.5225409,  2.876459 ,  6.062782 , ...,  5.341303 , -0.5483551,
         3.446848 ],
       [ 5.6395645,  6.8262954,  6.6988196, ...,  1.2809412,  5.949959 ,
         1.4368113]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[64], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_188/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_188
self.data_kwargs: {'seed': 721}
self.x_data: [[ 5.475364    7.6366067   6.593081   ...  0.8530688   8.875271
   1.2600539 ]
 [ 6.624233    2.860935    6.2971916  ...  2.665269    4.2119365
   3.0900779 ]
 [ 6.4123483   2.9544969   6.2372165  ...  3.7006004   4.897939
   1.9067069 ]
 ...
 [ 5.291359    8.643322    5.9392395  ...  0.5393052   7.1813807
   1.3439621 ]
 [ 5.5789056   6.2932816   6.272862   ... -0.29475307  6.0157323
   1.3976022 ]
 [ 1.6532166   2.3152595  10.214214   ...  6.271919   -0.05406091
   3.9072165 ]]
self.y_data: []
self.ndims: 64
Model defined.
Model: "model_26"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_79 (InputLayer)       [(None, 64)]              0         
                                                                 
 log_prob_layer_26 (LogProbL  (None,)                  1447808   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,447,808
Trainable params: 1,447,808
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_26/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_26'")
self.model: <keras.engine.functional.Functional object at 0x7fc584bed4e0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fbc164edde0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fbc164edde0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fbc164ee6b0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fbc164ef370>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fbc164ef8e0>, <keras.callbacks.ModelCheckpoint object at 0x7fbc164ef9a0>, <keras.callbacks.EarlyStopping object at 0x7fbc164efc10>, <keras.callbacks.ReduceLROnPlateau object at 0x7fbc164efc40>, <keras.callbacks.TerminateOnNaN object at 0x7fbc164ef880>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 0.958336 ,  3.6590893,  8.676455 , ...,  5.9946833,  2.2094154,
         2.624469 ],
       [ 1.2393765,  3.8911932,  8.905665 , ...,  5.783149 ,  1.3067368,
         2.3810356],
       [ 6.815516 ,  2.883391 ,  6.09811  , ...,  2.679101 ,  5.190114 ,
         1.7287396],
       ...,
       [ 5.1098504,  8.570955 ,  5.486371 , ...,  2.6942174,  5.2584124,
         1.4402856],
       [ 1.5225409,  2.876459 ,  6.062782 , ...,  5.341303 , -0.5483551,
         3.446848 ],
       [ 5.6395645,  6.8262954,  6.6988196, ...,  1.2809412,  5.949959 ,
         1.4368113]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_188/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 188/360 with hyperparameters:
timestamp = 2023-09-13 01:13:34.222819
ndims = 64
seed_train = 721
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1447808
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.475364    7.6366067   6.593081    5.2213635   4.3851104   6.547967
  4.392531    8.637874    9.379391    3.0568433   8.712279    4.9198484
  5.701744    9.309082    0.31514573  1.1504446  -0.4705431   8.813661
  9.537466    8.269614    8.780608    7.8593726   4.6449614   7.4048796
  1.683444    6.839795    1.5740938   9.839       4.622554    3.4715672
  2.0572462   7.526533    4.5307302   5.4113736   0.1867744   5.891015
  4.975408    5.49995     9.17347     6.8054004   3.9538507   4.336993
  6.759812    0.17014661  6.225843    6.527422    2.054394    1.277253
  3.0545924   3.5868065   4.708149    4.201944    9.617644    1.0881705
  1.922195    1.5136921   6.466659    1.6895405   4.5659165   2.2596717
  1.6085154   0.8530688   8.875271    1.2600539 ]
Epoch 1/1000
2023-09-13 01:14:01.502 
Epoch 1/1000 
	 loss: 89.0998, MinusLogProbMetric: 89.0998, val_loss: 34.4062, val_MinusLogProbMetric: 34.4062

Epoch 1: val_loss improved from inf to 34.40625, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 27s - loss: 89.0998 - MinusLogProbMetric: 89.0998 - val_loss: 34.4062 - val_MinusLogProbMetric: 34.4062 - lr: 0.0010 - 27s/epoch - 139ms/step
Epoch 2/1000
2023-09-13 01:14:10.784 
Epoch 2/1000 
	 loss: 31.9974, MinusLogProbMetric: 31.9974, val_loss: 30.5816, val_MinusLogProbMetric: 30.5816

Epoch 2: val_loss improved from 34.40625 to 30.58160, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 9s - loss: 31.9974 - MinusLogProbMetric: 31.9974 - val_loss: 30.5816 - val_MinusLogProbMetric: 30.5816 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 3/1000
2023-09-13 01:14:21.615 
Epoch 3/1000 
	 loss: 30.2199, MinusLogProbMetric: 30.2199, val_loss: 29.3410, val_MinusLogProbMetric: 29.3410

Epoch 3: val_loss improved from 30.58160 to 29.34104, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 11s - loss: 30.2199 - MinusLogProbMetric: 30.2199 - val_loss: 29.3410 - val_MinusLogProbMetric: 29.3410 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 4/1000
2023-09-13 01:14:33.416 
Epoch 4/1000 
	 loss: 29.4764, MinusLogProbMetric: 29.4764, val_loss: 29.4006, val_MinusLogProbMetric: 29.4006

Epoch 4: val_loss did not improve from 29.34104
196/196 - 12s - loss: 29.4764 - MinusLogProbMetric: 29.4764 - val_loss: 29.4006 - val_MinusLogProbMetric: 29.4006 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 5/1000
2023-09-13 01:14:45.028 
Epoch 5/1000 
	 loss: 29.1559, MinusLogProbMetric: 29.1559, val_loss: 28.5741, val_MinusLogProbMetric: 28.5741

Epoch 5: val_loss improved from 29.34104 to 28.57414, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 12s - loss: 29.1559 - MinusLogProbMetric: 29.1559 - val_loss: 28.5741 - val_MinusLogProbMetric: 28.5741 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 6/1000
2023-09-13 01:14:56.053 
Epoch 6/1000 
	 loss: 29.0477, MinusLogProbMetric: 29.0477, val_loss: 28.6826, val_MinusLogProbMetric: 28.6826

Epoch 6: val_loss did not improve from 28.57414
196/196 - 11s - loss: 29.0477 - MinusLogProbMetric: 29.0477 - val_loss: 28.6826 - val_MinusLogProbMetric: 28.6826 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 7/1000
2023-09-13 01:15:06.272 
Epoch 7/1000 
	 loss: 28.7185, MinusLogProbMetric: 28.7185, val_loss: 28.5349, val_MinusLogProbMetric: 28.5349

Epoch 7: val_loss improved from 28.57414 to 28.53489, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 10s - loss: 28.7185 - MinusLogProbMetric: 28.7185 - val_loss: 28.5349 - val_MinusLogProbMetric: 28.5349 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 8/1000
2023-09-13 01:15:18.216 
Epoch 8/1000 
	 loss: 28.6075, MinusLogProbMetric: 28.6075, val_loss: 28.5612, val_MinusLogProbMetric: 28.5612

Epoch 8: val_loss did not improve from 28.53489
196/196 - 12s - loss: 28.6075 - MinusLogProbMetric: 28.6075 - val_loss: 28.5612 - val_MinusLogProbMetric: 28.5612 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 9/1000
2023-09-13 01:15:30.055 
Epoch 9/1000 
	 loss: 28.4408, MinusLogProbMetric: 28.4408, val_loss: 28.3725, val_MinusLogProbMetric: 28.3725

Epoch 9: val_loss improved from 28.53489 to 28.37248, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 12s - loss: 28.4408 - MinusLogProbMetric: 28.4408 - val_loss: 28.3725 - val_MinusLogProbMetric: 28.3725 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-13 01:15:40.399 
Epoch 10/1000 
	 loss: 28.4432, MinusLogProbMetric: 28.4432, val_loss: 28.4725, val_MinusLogProbMetric: 28.4725

Epoch 10: val_loss did not improve from 28.37248
196/196 - 10s - loss: 28.4432 - MinusLogProbMetric: 28.4432 - val_loss: 28.4725 - val_MinusLogProbMetric: 28.4725 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 11/1000
2023-09-13 01:15:50.118 
Epoch 11/1000 
	 loss: 28.3667, MinusLogProbMetric: 28.3667, val_loss: 28.4891, val_MinusLogProbMetric: 28.4891

Epoch 11: val_loss did not improve from 28.37248
196/196 - 10s - loss: 28.3667 - MinusLogProbMetric: 28.3667 - val_loss: 28.4891 - val_MinusLogProbMetric: 28.4891 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 12/1000
2023-09-13 01:16:01.231 
Epoch 12/1000 
	 loss: 28.2318, MinusLogProbMetric: 28.2318, val_loss: 28.5227, val_MinusLogProbMetric: 28.5227

Epoch 12: val_loss did not improve from 28.37248
196/196 - 11s - loss: 28.2318 - MinusLogProbMetric: 28.2318 - val_loss: 28.5227 - val_MinusLogProbMetric: 28.5227 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 13/1000
2023-09-13 01:16:10.935 
Epoch 13/1000 
	 loss: 28.2080, MinusLogProbMetric: 28.2080, val_loss: 28.1632, val_MinusLogProbMetric: 28.1632

Epoch 13: val_loss improved from 28.37248 to 28.16325, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 10s - loss: 28.2080 - MinusLogProbMetric: 28.2080 - val_loss: 28.1632 - val_MinusLogProbMetric: 28.1632 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 14/1000
2023-09-13 01:16:22.421 
Epoch 14/1000 
	 loss: 28.1135, MinusLogProbMetric: 28.1135, val_loss: 28.2214, val_MinusLogProbMetric: 28.2214

Epoch 14: val_loss did not improve from 28.16325
196/196 - 11s - loss: 28.1135 - MinusLogProbMetric: 28.1135 - val_loss: 28.2214 - val_MinusLogProbMetric: 28.2214 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 15/1000
2023-09-13 01:16:33.652 
Epoch 15/1000 
	 loss: 28.1331, MinusLogProbMetric: 28.1331, val_loss: 28.2098, val_MinusLogProbMetric: 28.2098

Epoch 15: val_loss did not improve from 28.16325
196/196 - 11s - loss: 28.1331 - MinusLogProbMetric: 28.1331 - val_loss: 28.2098 - val_MinusLogProbMetric: 28.2098 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 16/1000
2023-09-13 01:16:43.810 
Epoch 16/1000 
	 loss: 28.0602, MinusLogProbMetric: 28.0602, val_loss: 28.1448, val_MinusLogProbMetric: 28.1448

Epoch 16: val_loss improved from 28.16325 to 28.14476, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 10s - loss: 28.0602 - MinusLogProbMetric: 28.0602 - val_loss: 28.1448 - val_MinusLogProbMetric: 28.1448 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 17/1000
2023-09-13 01:16:53.647 
Epoch 17/1000 
	 loss: 28.0510, MinusLogProbMetric: 28.0510, val_loss: 28.2053, val_MinusLogProbMetric: 28.2053

Epoch 17: val_loss did not improve from 28.14476
196/196 - 10s - loss: 28.0510 - MinusLogProbMetric: 28.0510 - val_loss: 28.2053 - val_MinusLogProbMetric: 28.2053 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 18/1000
2023-09-13 01:17:02.827 
Epoch 18/1000 
	 loss: 28.0373, MinusLogProbMetric: 28.0373, val_loss: 28.0887, val_MinusLogProbMetric: 28.0887

Epoch 18: val_loss improved from 28.14476 to 28.08867, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 9s - loss: 28.0373 - MinusLogProbMetric: 28.0373 - val_loss: 28.0887 - val_MinusLogProbMetric: 28.0887 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 19/1000
2023-09-13 01:17:11.914 
Epoch 19/1000 
	 loss: 27.9856, MinusLogProbMetric: 27.9856, val_loss: 28.0295, val_MinusLogProbMetric: 28.0295

Epoch 19: val_loss improved from 28.08867 to 28.02953, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 9s - loss: 27.9856 - MinusLogProbMetric: 27.9856 - val_loss: 28.0295 - val_MinusLogProbMetric: 28.0295 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 20/1000
2023-09-13 01:17:21.020 
Epoch 20/1000 
	 loss: 27.9673, MinusLogProbMetric: 27.9673, val_loss: 27.9317, val_MinusLogProbMetric: 27.9317

Epoch 20: val_loss improved from 28.02953 to 27.93165, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 9s - loss: 27.9673 - MinusLogProbMetric: 27.9673 - val_loss: 27.9317 - val_MinusLogProbMetric: 27.9317 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 21/1000
2023-09-13 01:17:30.237 
Epoch 21/1000 
	 loss: 27.9856, MinusLogProbMetric: 27.9856, val_loss: 28.0142, val_MinusLogProbMetric: 28.0142

Epoch 21: val_loss did not improve from 27.93165
196/196 - 9s - loss: 27.9856 - MinusLogProbMetric: 27.9856 - val_loss: 28.0142 - val_MinusLogProbMetric: 28.0142 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 22/1000
2023-09-13 01:17:39.156 
Epoch 22/1000 
	 loss: 27.8973, MinusLogProbMetric: 27.8973, val_loss: 27.9593, val_MinusLogProbMetric: 27.9593

Epoch 22: val_loss did not improve from 27.93165
196/196 - 9s - loss: 27.8973 - MinusLogProbMetric: 27.8973 - val_loss: 27.9593 - val_MinusLogProbMetric: 27.9593 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 23/1000
2023-09-13 01:17:48.364 
Epoch 23/1000 
	 loss: 27.9066, MinusLogProbMetric: 27.9066, val_loss: 28.0356, val_MinusLogProbMetric: 28.0356

Epoch 23: val_loss did not improve from 27.93165
196/196 - 9s - loss: 27.9066 - MinusLogProbMetric: 27.9066 - val_loss: 28.0356 - val_MinusLogProbMetric: 28.0356 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 24/1000
2023-09-13 01:17:57.534 
Epoch 24/1000 
	 loss: 27.9441, MinusLogProbMetric: 27.9441, val_loss: 27.9140, val_MinusLogProbMetric: 27.9140

Epoch 24: val_loss improved from 27.93165 to 27.91401, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 9s - loss: 27.9441 - MinusLogProbMetric: 27.9441 - val_loss: 27.9140 - val_MinusLogProbMetric: 27.9140 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 25/1000
2023-09-13 01:18:07.034 
Epoch 25/1000 
	 loss: 27.8984, MinusLogProbMetric: 27.8984, val_loss: 27.9341, val_MinusLogProbMetric: 27.9341

Epoch 25: val_loss did not improve from 27.91401
196/196 - 9s - loss: 27.8984 - MinusLogProbMetric: 27.8984 - val_loss: 27.9341 - val_MinusLogProbMetric: 27.9341 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 26/1000
2023-09-13 01:18:16.935 
Epoch 26/1000 
	 loss: 27.8452, MinusLogProbMetric: 27.8452, val_loss: 28.0383, val_MinusLogProbMetric: 28.0383

Epoch 26: val_loss did not improve from 27.91401
196/196 - 10s - loss: 27.8452 - MinusLogProbMetric: 27.8452 - val_loss: 28.0383 - val_MinusLogProbMetric: 28.0383 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 27/1000
2023-09-13 01:18:26.595 
Epoch 27/1000 
	 loss: 27.8397, MinusLogProbMetric: 27.8397, val_loss: 28.0050, val_MinusLogProbMetric: 28.0050

Epoch 27: val_loss did not improve from 27.91401
196/196 - 10s - loss: 27.8397 - MinusLogProbMetric: 27.8397 - val_loss: 28.0050 - val_MinusLogProbMetric: 28.0050 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 28/1000
2023-09-13 01:18:36.965 
Epoch 28/1000 
	 loss: 27.8495, MinusLogProbMetric: 27.8495, val_loss: 27.8898, val_MinusLogProbMetric: 27.8898

Epoch 28: val_loss improved from 27.91401 to 27.88977, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 11s - loss: 27.8495 - MinusLogProbMetric: 27.8495 - val_loss: 27.8898 - val_MinusLogProbMetric: 27.8898 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 29/1000
2023-09-13 01:18:48.009 
Epoch 29/1000 
	 loss: 27.8297, MinusLogProbMetric: 27.8297, val_loss: 27.8661, val_MinusLogProbMetric: 27.8661

Epoch 29: val_loss improved from 27.88977 to 27.86609, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 11s - loss: 27.8297 - MinusLogProbMetric: 27.8297 - val_loss: 27.8661 - val_MinusLogProbMetric: 27.8661 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 30/1000
2023-09-13 01:18:59.044 
Epoch 30/1000 
	 loss: 27.8104, MinusLogProbMetric: 27.8104, val_loss: 27.8283, val_MinusLogProbMetric: 27.8283

Epoch 30: val_loss improved from 27.86609 to 27.82830, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 11s - loss: 27.8104 - MinusLogProbMetric: 27.8104 - val_loss: 27.8283 - val_MinusLogProbMetric: 27.8283 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 31/1000
2023-09-13 01:19:08.839 
Epoch 31/1000 
	 loss: 27.8020, MinusLogProbMetric: 27.8020, val_loss: 27.8341, val_MinusLogProbMetric: 27.8341

Epoch 31: val_loss did not improve from 27.82830
196/196 - 10s - loss: 27.8020 - MinusLogProbMetric: 27.8020 - val_loss: 27.8341 - val_MinusLogProbMetric: 27.8341 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 32/1000
2023-09-13 01:19:17.266 
Epoch 32/1000 
	 loss: 27.7979, MinusLogProbMetric: 27.7979, val_loss: 27.8556, val_MinusLogProbMetric: 27.8556

Epoch 32: val_loss did not improve from 27.82830
196/196 - 8s - loss: 27.7979 - MinusLogProbMetric: 27.7979 - val_loss: 27.8556 - val_MinusLogProbMetric: 27.8556 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 33/1000
2023-09-13 01:19:25.674 
Epoch 33/1000 
	 loss: 27.7903, MinusLogProbMetric: 27.7903, val_loss: 28.0047, val_MinusLogProbMetric: 28.0047

Epoch 33: val_loss did not improve from 27.82830
196/196 - 8s - loss: 27.7903 - MinusLogProbMetric: 27.7903 - val_loss: 28.0047 - val_MinusLogProbMetric: 28.0047 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 34/1000
2023-09-13 01:19:33.977 
Epoch 34/1000 
	 loss: 27.7818, MinusLogProbMetric: 27.7818, val_loss: 27.9090, val_MinusLogProbMetric: 27.9090

Epoch 34: val_loss did not improve from 27.82830
196/196 - 8s - loss: 27.7818 - MinusLogProbMetric: 27.7818 - val_loss: 27.9090 - val_MinusLogProbMetric: 27.9090 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 35/1000
2023-09-13 01:19:42.336 
Epoch 35/1000 
	 loss: 27.7715, MinusLogProbMetric: 27.7715, val_loss: 27.8170, val_MinusLogProbMetric: 27.8170

Epoch 35: val_loss improved from 27.82830 to 27.81703, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 8s - loss: 27.7715 - MinusLogProbMetric: 27.7715 - val_loss: 27.8170 - val_MinusLogProbMetric: 27.8170 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 36/1000
2023-09-13 01:19:51.311 
Epoch 36/1000 
	 loss: 27.7654, MinusLogProbMetric: 27.7654, val_loss: 27.9521, val_MinusLogProbMetric: 27.9521

Epoch 36: val_loss did not improve from 27.81703
196/196 - 9s - loss: 27.7654 - MinusLogProbMetric: 27.7654 - val_loss: 27.9521 - val_MinusLogProbMetric: 27.9521 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 37/1000
2023-09-13 01:20:01.489 
Epoch 37/1000 
	 loss: 27.7456, MinusLogProbMetric: 27.7456, val_loss: 27.8622, val_MinusLogProbMetric: 27.8622

Epoch 37: val_loss did not improve from 27.81703
196/196 - 10s - loss: 27.7456 - MinusLogProbMetric: 27.7456 - val_loss: 27.8622 - val_MinusLogProbMetric: 27.8622 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 38/1000
2023-09-13 01:20:12.079 
Epoch 38/1000 
	 loss: 27.7460, MinusLogProbMetric: 27.7460, val_loss: 27.8256, val_MinusLogProbMetric: 27.8256

Epoch 38: val_loss did not improve from 27.81703
196/196 - 11s - loss: 27.7460 - MinusLogProbMetric: 27.7460 - val_loss: 27.8256 - val_MinusLogProbMetric: 27.8256 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 39/1000
2023-09-13 01:20:21.787 
Epoch 39/1000 
	 loss: 27.7367, MinusLogProbMetric: 27.7367, val_loss: 27.7589, val_MinusLogProbMetric: 27.7589

Epoch 39: val_loss improved from 27.81703 to 27.75891, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 10s - loss: 27.7367 - MinusLogProbMetric: 27.7367 - val_loss: 27.7589 - val_MinusLogProbMetric: 27.7589 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 40/1000
2023-09-13 01:20:30.980 
Epoch 40/1000 
	 loss: 27.7204, MinusLogProbMetric: 27.7204, val_loss: 27.7817, val_MinusLogProbMetric: 27.7817

Epoch 40: val_loss did not improve from 27.75891
196/196 - 9s - loss: 27.7204 - MinusLogProbMetric: 27.7204 - val_loss: 27.7817 - val_MinusLogProbMetric: 27.7817 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 41/1000
2023-09-13 01:20:40.093 
Epoch 41/1000 
	 loss: 27.7295, MinusLogProbMetric: 27.7295, val_loss: 28.1252, val_MinusLogProbMetric: 28.1252

Epoch 41: val_loss did not improve from 27.75891
196/196 - 9s - loss: 27.7295 - MinusLogProbMetric: 27.7295 - val_loss: 28.1252 - val_MinusLogProbMetric: 28.1252 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 42/1000
2023-09-13 01:20:48.496 
Epoch 42/1000 
	 loss: 27.7137, MinusLogProbMetric: 27.7137, val_loss: 27.9209, val_MinusLogProbMetric: 27.9209

Epoch 42: val_loss did not improve from 27.75891
196/196 - 8s - loss: 27.7137 - MinusLogProbMetric: 27.7137 - val_loss: 27.9209 - val_MinusLogProbMetric: 27.9209 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 43/1000
2023-09-13 01:20:57.005 
Epoch 43/1000 
	 loss: 27.7066, MinusLogProbMetric: 27.7066, val_loss: 27.7392, val_MinusLogProbMetric: 27.7392

Epoch 43: val_loss improved from 27.75891 to 27.73919, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 9s - loss: 27.7066 - MinusLogProbMetric: 27.7066 - val_loss: 27.7392 - val_MinusLogProbMetric: 27.7392 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 44/1000
2023-09-13 01:21:05.633 
Epoch 44/1000 
	 loss: 27.7129, MinusLogProbMetric: 27.7129, val_loss: 28.0448, val_MinusLogProbMetric: 28.0448

Epoch 44: val_loss did not improve from 27.73919
196/196 - 8s - loss: 27.7129 - MinusLogProbMetric: 27.7129 - val_loss: 28.0448 - val_MinusLogProbMetric: 28.0448 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 45/1000
2023-09-13 01:21:14.216 
Epoch 45/1000 
	 loss: 27.6811, MinusLogProbMetric: 27.6811, val_loss: 27.7929, val_MinusLogProbMetric: 27.7929

Epoch 45: val_loss did not improve from 27.73919
196/196 - 9s - loss: 27.6811 - MinusLogProbMetric: 27.6811 - val_loss: 27.7929 - val_MinusLogProbMetric: 27.7929 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 46/1000
2023-09-13 01:21:23.364 
Epoch 46/1000 
	 loss: 27.7144, MinusLogProbMetric: 27.7144, val_loss: 27.9582, val_MinusLogProbMetric: 27.9582

Epoch 46: val_loss did not improve from 27.73919
196/196 - 9s - loss: 27.7144 - MinusLogProbMetric: 27.7144 - val_loss: 27.9582 - val_MinusLogProbMetric: 27.9582 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 47/1000
2023-09-13 01:21:32.990 
Epoch 47/1000 
	 loss: 27.6746, MinusLogProbMetric: 27.6746, val_loss: 27.7898, val_MinusLogProbMetric: 27.7898

Epoch 47: val_loss did not improve from 27.73919
196/196 - 10s - loss: 27.6746 - MinusLogProbMetric: 27.6746 - val_loss: 27.7898 - val_MinusLogProbMetric: 27.7898 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 48/1000
2023-09-13 01:21:43.368 
Epoch 48/1000 
	 loss: 27.6998, MinusLogProbMetric: 27.6998, val_loss: 27.7562, val_MinusLogProbMetric: 27.7562

Epoch 48: val_loss did not improve from 27.73919
196/196 - 10s - loss: 27.6998 - MinusLogProbMetric: 27.6998 - val_loss: 27.7562 - val_MinusLogProbMetric: 27.7562 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 49/1000
2023-09-13 01:21:52.861 
Epoch 49/1000 
	 loss: 27.6811, MinusLogProbMetric: 27.6811, val_loss: 27.8826, val_MinusLogProbMetric: 27.8826

Epoch 49: val_loss did not improve from 27.73919
196/196 - 9s - loss: 27.6811 - MinusLogProbMetric: 27.6811 - val_loss: 27.8826 - val_MinusLogProbMetric: 27.8826 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 50/1000
2023-09-13 01:22:01.602 
Epoch 50/1000 
	 loss: 27.6732, MinusLogProbMetric: 27.6732, val_loss: 27.8401, val_MinusLogProbMetric: 27.8401

Epoch 50: val_loss did not improve from 27.73919
196/196 - 9s - loss: 27.6732 - MinusLogProbMetric: 27.6732 - val_loss: 27.8401 - val_MinusLogProbMetric: 27.8401 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 51/1000
2023-09-13 01:22:10.635 
Epoch 51/1000 
	 loss: 27.6471, MinusLogProbMetric: 27.6471, val_loss: 27.7801, val_MinusLogProbMetric: 27.7801

Epoch 51: val_loss did not improve from 27.73919
196/196 - 9s - loss: 27.6471 - MinusLogProbMetric: 27.6471 - val_loss: 27.7801 - val_MinusLogProbMetric: 27.7801 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 52/1000
2023-09-13 01:22:18.988 
Epoch 52/1000 
	 loss: 27.6594, MinusLogProbMetric: 27.6594, val_loss: 27.7922, val_MinusLogProbMetric: 27.7922

Epoch 52: val_loss did not improve from 27.73919
196/196 - 8s - loss: 27.6594 - MinusLogProbMetric: 27.6594 - val_loss: 27.7922 - val_MinusLogProbMetric: 27.7922 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 53/1000
2023-09-13 01:22:27.232 
Epoch 53/1000 
	 loss: 27.6628, MinusLogProbMetric: 27.6628, val_loss: 27.7125, val_MinusLogProbMetric: 27.7125

Epoch 53: val_loss improved from 27.73919 to 27.71247, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 8s - loss: 27.6628 - MinusLogProbMetric: 27.6628 - val_loss: 27.7125 - val_MinusLogProbMetric: 27.7125 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 54/1000
2023-09-13 01:22:36.061 
Epoch 54/1000 
	 loss: 27.6298, MinusLogProbMetric: 27.6298, val_loss: 27.8401, val_MinusLogProbMetric: 27.8401

Epoch 54: val_loss did not improve from 27.71247
196/196 - 9s - loss: 27.6298 - MinusLogProbMetric: 27.6298 - val_loss: 27.8401 - val_MinusLogProbMetric: 27.8401 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 55/1000
2023-09-13 01:22:45.728 
Epoch 55/1000 
	 loss: 27.6312, MinusLogProbMetric: 27.6312, val_loss: 27.8421, val_MinusLogProbMetric: 27.8421

Epoch 55: val_loss did not improve from 27.71247
196/196 - 10s - loss: 27.6312 - MinusLogProbMetric: 27.6312 - val_loss: 27.8421 - val_MinusLogProbMetric: 27.8421 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 56/1000
2023-09-13 01:22:56.029 
Epoch 56/1000 
	 loss: 27.6469, MinusLogProbMetric: 27.6469, val_loss: 27.8049, val_MinusLogProbMetric: 27.8049

Epoch 56: val_loss did not improve from 27.71247
196/196 - 10s - loss: 27.6469 - MinusLogProbMetric: 27.6469 - val_loss: 27.8049 - val_MinusLogProbMetric: 27.8049 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 57/1000
2023-09-13 01:23:04.853 
Epoch 57/1000 
	 loss: 27.6313, MinusLogProbMetric: 27.6313, val_loss: 27.8161, val_MinusLogProbMetric: 27.8161

Epoch 57: val_loss did not improve from 27.71247
196/196 - 9s - loss: 27.6313 - MinusLogProbMetric: 27.6313 - val_loss: 27.8161 - val_MinusLogProbMetric: 27.8161 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 58/1000
2023-09-13 01:23:13.100 
Epoch 58/1000 
	 loss: 27.6319, MinusLogProbMetric: 27.6319, val_loss: 27.7756, val_MinusLogProbMetric: 27.7756

Epoch 58: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6319 - MinusLogProbMetric: 27.6319 - val_loss: 27.7756 - val_MinusLogProbMetric: 27.7756 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 59/1000
2023-09-13 01:23:21.816 
Epoch 59/1000 
	 loss: 27.6231, MinusLogProbMetric: 27.6231, val_loss: 27.8606, val_MinusLogProbMetric: 27.8606

Epoch 59: val_loss did not improve from 27.71247
196/196 - 9s - loss: 27.6231 - MinusLogProbMetric: 27.6231 - val_loss: 27.8606 - val_MinusLogProbMetric: 27.8606 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 60/1000
2023-09-13 01:23:29.955 
Epoch 60/1000 
	 loss: 27.6203, MinusLogProbMetric: 27.6203, val_loss: 27.8058, val_MinusLogProbMetric: 27.8058

Epoch 60: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6203 - MinusLogProbMetric: 27.6203 - val_loss: 27.8058 - val_MinusLogProbMetric: 27.8058 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 61/1000
2023-09-13 01:23:38.215 
Epoch 61/1000 
	 loss: 27.6328, MinusLogProbMetric: 27.6328, val_loss: 27.8098, val_MinusLogProbMetric: 27.8098

Epoch 61: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6328 - MinusLogProbMetric: 27.6328 - val_loss: 27.8098 - val_MinusLogProbMetric: 27.8098 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 62/1000
2023-09-13 01:23:46.542 
Epoch 62/1000 
	 loss: 27.6174, MinusLogProbMetric: 27.6174, val_loss: 27.7759, val_MinusLogProbMetric: 27.7759

Epoch 62: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6174 - MinusLogProbMetric: 27.6174 - val_loss: 27.7759 - val_MinusLogProbMetric: 27.7759 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 63/1000
2023-09-13 01:23:54.792 
Epoch 63/1000 
	 loss: 27.6198, MinusLogProbMetric: 27.6198, val_loss: 27.7201, val_MinusLogProbMetric: 27.7201

Epoch 63: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6198 - MinusLogProbMetric: 27.6198 - val_loss: 27.7201 - val_MinusLogProbMetric: 27.7201 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 64/1000
2023-09-13 01:24:03.131 
Epoch 64/1000 
	 loss: 27.6195, MinusLogProbMetric: 27.6195, val_loss: 27.7531, val_MinusLogProbMetric: 27.7531

Epoch 64: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6195 - MinusLogProbMetric: 27.6195 - val_loss: 27.7531 - val_MinusLogProbMetric: 27.7531 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 65/1000
2023-09-13 01:24:11.545 
Epoch 65/1000 
	 loss: 27.6104, MinusLogProbMetric: 27.6104, val_loss: 27.8089, val_MinusLogProbMetric: 27.8089

Epoch 65: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6104 - MinusLogProbMetric: 27.6104 - val_loss: 27.8089 - val_MinusLogProbMetric: 27.8089 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 66/1000
2023-09-13 01:24:19.849 
Epoch 66/1000 
	 loss: 27.5845, MinusLogProbMetric: 27.5845, val_loss: 27.7637, val_MinusLogProbMetric: 27.7637

Epoch 66: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.5845 - MinusLogProbMetric: 27.5845 - val_loss: 27.7637 - val_MinusLogProbMetric: 27.7637 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 67/1000
2023-09-13 01:24:28.278 
Epoch 67/1000 
	 loss: 27.6051, MinusLogProbMetric: 27.6051, val_loss: 27.7145, val_MinusLogProbMetric: 27.7145

Epoch 67: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.6051 - MinusLogProbMetric: 27.6051 - val_loss: 27.7145 - val_MinusLogProbMetric: 27.7145 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 68/1000
2023-09-13 01:24:38.047 
Epoch 68/1000 
	 loss: 27.5847, MinusLogProbMetric: 27.5847, val_loss: 27.7932, val_MinusLogProbMetric: 27.7932

Epoch 68: val_loss did not improve from 27.71247
196/196 - 10s - loss: 27.5847 - MinusLogProbMetric: 27.5847 - val_loss: 27.7932 - val_MinusLogProbMetric: 27.7932 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 69/1000
2023-09-13 01:24:46.281 
Epoch 69/1000 
	 loss: 27.5898, MinusLogProbMetric: 27.5898, val_loss: 27.8128, val_MinusLogProbMetric: 27.8128

Epoch 69: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.5898 - MinusLogProbMetric: 27.5898 - val_loss: 27.8128 - val_MinusLogProbMetric: 27.8128 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 70/1000
2023-09-13 01:24:54.489 
Epoch 70/1000 
	 loss: 27.5979, MinusLogProbMetric: 27.5979, val_loss: 27.7830, val_MinusLogProbMetric: 27.7830

Epoch 70: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.5979 - MinusLogProbMetric: 27.5979 - val_loss: 27.7830 - val_MinusLogProbMetric: 27.7830 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 71/1000
2023-09-13 01:25:02.830 
Epoch 71/1000 
	 loss: 27.5793, MinusLogProbMetric: 27.5793, val_loss: 27.7826, val_MinusLogProbMetric: 27.7826

Epoch 71: val_loss did not improve from 27.71247
196/196 - 8s - loss: 27.5793 - MinusLogProbMetric: 27.5793 - val_loss: 27.7826 - val_MinusLogProbMetric: 27.7826 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 72/1000
2023-09-13 01:25:11.827 
Epoch 72/1000 
	 loss: 27.5697, MinusLogProbMetric: 27.5697, val_loss: 27.7377, val_MinusLogProbMetric: 27.7377

Epoch 72: val_loss did not improve from 27.71247
196/196 - 9s - loss: 27.5697 - MinusLogProbMetric: 27.5697 - val_loss: 27.7377 - val_MinusLogProbMetric: 27.7377 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 73/1000
2023-09-13 01:25:22.265 
Epoch 73/1000 
	 loss: 27.5797, MinusLogProbMetric: 27.5797, val_loss: 27.8242, val_MinusLogProbMetric: 27.8242

Epoch 73: val_loss did not improve from 27.71247
196/196 - 10s - loss: 27.5797 - MinusLogProbMetric: 27.5797 - val_loss: 27.8242 - val_MinusLogProbMetric: 27.8242 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 74/1000
2023-09-13 01:25:32.579 
Epoch 74/1000 
	 loss: 27.5732, MinusLogProbMetric: 27.5732, val_loss: 27.7025, val_MinusLogProbMetric: 27.7025

Epoch 74: val_loss improved from 27.71247 to 27.70254, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 10s - loss: 27.5732 - MinusLogProbMetric: 27.5732 - val_loss: 27.7025 - val_MinusLogProbMetric: 27.7025 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 75/1000
2023-09-13 01:25:42.723 
Epoch 75/1000 
	 loss: 27.5573, MinusLogProbMetric: 27.5573, val_loss: 27.7647, val_MinusLogProbMetric: 27.7647

Epoch 75: val_loss did not improve from 27.70254
196/196 - 10s - loss: 27.5573 - MinusLogProbMetric: 27.5573 - val_loss: 27.7647 - val_MinusLogProbMetric: 27.7647 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 76/1000
2023-09-13 01:25:52.034 
Epoch 76/1000 
	 loss: 27.5431, MinusLogProbMetric: 27.5431, val_loss: 27.7237, val_MinusLogProbMetric: 27.7237

Epoch 76: val_loss did not improve from 27.70254
196/196 - 9s - loss: 27.5431 - MinusLogProbMetric: 27.5431 - val_loss: 27.7237 - val_MinusLogProbMetric: 27.7237 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 77/1000
2023-09-13 01:26:00.237 
Epoch 77/1000 
	 loss: 27.5705, MinusLogProbMetric: 27.5705, val_loss: 27.7171, val_MinusLogProbMetric: 27.7171

Epoch 77: val_loss did not improve from 27.70254
196/196 - 8s - loss: 27.5705 - MinusLogProbMetric: 27.5705 - val_loss: 27.7171 - val_MinusLogProbMetric: 27.7171 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 78/1000
2023-09-13 01:26:08.424 
Epoch 78/1000 
	 loss: 27.5453, MinusLogProbMetric: 27.5453, val_loss: 27.6974, val_MinusLogProbMetric: 27.6974

Epoch 78: val_loss improved from 27.70254 to 27.69744, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 8s - loss: 27.5453 - MinusLogProbMetric: 27.5453 - val_loss: 27.6974 - val_MinusLogProbMetric: 27.6974 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 79/1000
2023-09-13 01:26:17.006 
Epoch 79/1000 
	 loss: 27.5557, MinusLogProbMetric: 27.5557, val_loss: 27.8947, val_MinusLogProbMetric: 27.8947

Epoch 79: val_loss did not improve from 27.69744
196/196 - 8s - loss: 27.5557 - MinusLogProbMetric: 27.5557 - val_loss: 27.8947 - val_MinusLogProbMetric: 27.8947 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 80/1000
2023-09-13 01:26:25.409 
Epoch 80/1000 
	 loss: 27.5592, MinusLogProbMetric: 27.5592, val_loss: 27.7576, val_MinusLogProbMetric: 27.7576

Epoch 80: val_loss did not improve from 27.69744
196/196 - 8s - loss: 27.5592 - MinusLogProbMetric: 27.5592 - val_loss: 27.7576 - val_MinusLogProbMetric: 27.7576 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 81/1000
2023-09-13 01:26:33.690 
Epoch 81/1000 
	 loss: 27.5422, MinusLogProbMetric: 27.5422, val_loss: 27.9044, val_MinusLogProbMetric: 27.9044

Epoch 81: val_loss did not improve from 27.69744
196/196 - 8s - loss: 27.5422 - MinusLogProbMetric: 27.5422 - val_loss: 27.9044 - val_MinusLogProbMetric: 27.9044 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 82/1000
2023-09-13 01:26:41.989 
Epoch 82/1000 
	 loss: 27.5319, MinusLogProbMetric: 27.5319, val_loss: 27.7795, val_MinusLogProbMetric: 27.7795

Epoch 82: val_loss did not improve from 27.69744
196/196 - 8s - loss: 27.5319 - MinusLogProbMetric: 27.5319 - val_loss: 27.7795 - val_MinusLogProbMetric: 27.7795 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 83/1000
2023-09-13 01:26:50.103 
Epoch 83/1000 
	 loss: 27.5274, MinusLogProbMetric: 27.5274, val_loss: 27.7778, val_MinusLogProbMetric: 27.7778

Epoch 83: val_loss did not improve from 27.69744
196/196 - 8s - loss: 27.5274 - MinusLogProbMetric: 27.5274 - val_loss: 27.7778 - val_MinusLogProbMetric: 27.7778 - lr: 0.0010 - 8s/epoch - 41ms/step
Epoch 84/1000
2023-09-13 01:26:58.802 
Epoch 84/1000 
	 loss: 27.5339, MinusLogProbMetric: 27.5339, val_loss: 27.8489, val_MinusLogProbMetric: 27.8489

Epoch 84: val_loss did not improve from 27.69744
196/196 - 9s - loss: 27.5339 - MinusLogProbMetric: 27.5339 - val_loss: 27.8489 - val_MinusLogProbMetric: 27.8489 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 85/1000
2023-09-13 01:27:09.155 
Epoch 85/1000 
	 loss: 27.5419, MinusLogProbMetric: 27.5419, val_loss: 27.7927, val_MinusLogProbMetric: 27.7927

Epoch 85: val_loss did not improve from 27.69744
196/196 - 10s - loss: 27.5419 - MinusLogProbMetric: 27.5419 - val_loss: 27.7927 - val_MinusLogProbMetric: 27.7927 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 86/1000
2023-09-13 01:27:19.539 
Epoch 86/1000 
	 loss: 27.5313, MinusLogProbMetric: 27.5313, val_loss: 27.8910, val_MinusLogProbMetric: 27.8910

Epoch 86: val_loss did not improve from 27.69744
196/196 - 10s - loss: 27.5313 - MinusLogProbMetric: 27.5313 - val_loss: 27.8910 - val_MinusLogProbMetric: 27.8910 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 87/1000
2023-09-13 01:27:29.693 
Epoch 87/1000 
	 loss: 27.5317, MinusLogProbMetric: 27.5317, val_loss: 28.1808, val_MinusLogProbMetric: 28.1808

Epoch 87: val_loss did not improve from 27.69744
196/196 - 10s - loss: 27.5317 - MinusLogProbMetric: 27.5317 - val_loss: 28.1808 - val_MinusLogProbMetric: 28.1808 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 88/1000
2023-09-13 01:27:40.082 
Epoch 88/1000 
	 loss: 27.5100, MinusLogProbMetric: 27.5100, val_loss: 27.8009, val_MinusLogProbMetric: 27.8009

Epoch 88: val_loss did not improve from 27.69744
196/196 - 10s - loss: 27.5100 - MinusLogProbMetric: 27.5100 - val_loss: 27.8009 - val_MinusLogProbMetric: 27.8009 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 89/1000
2023-09-13 01:27:50.439 
Epoch 89/1000 
	 loss: 27.5104, MinusLogProbMetric: 27.5104, val_loss: 27.7015, val_MinusLogProbMetric: 27.7015

Epoch 89: val_loss did not improve from 27.69744
196/196 - 10s - loss: 27.5104 - MinusLogProbMetric: 27.5104 - val_loss: 27.7015 - val_MinusLogProbMetric: 27.7015 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 90/1000
2023-09-13 01:28:00.647 
Epoch 90/1000 
	 loss: 27.5026, MinusLogProbMetric: 27.5026, val_loss: 27.7715, val_MinusLogProbMetric: 27.7715

Epoch 90: val_loss did not improve from 27.69744
196/196 - 10s - loss: 27.5026 - MinusLogProbMetric: 27.5026 - val_loss: 27.7715 - val_MinusLogProbMetric: 27.7715 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 91/1000
2023-09-13 01:28:11.097 
Epoch 91/1000 
	 loss: 27.5034, MinusLogProbMetric: 27.5034, val_loss: 27.7887, val_MinusLogProbMetric: 27.7887

Epoch 91: val_loss did not improve from 27.69744
196/196 - 10s - loss: 27.5034 - MinusLogProbMetric: 27.5034 - val_loss: 27.7887 - val_MinusLogProbMetric: 27.7887 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 92/1000
2023-09-13 01:28:19.477 
Epoch 92/1000 
	 loss: 27.5144, MinusLogProbMetric: 27.5144, val_loss: 27.6815, val_MinusLogProbMetric: 27.6815

Epoch 92: val_loss improved from 27.69744 to 27.68149, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_188/weights/best_weights.h5
196/196 - 9s - loss: 27.5144 - MinusLogProbMetric: 27.5144 - val_loss: 27.6815 - val_MinusLogProbMetric: 27.6815 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 93/1000
2023-09-13 01:28:28.656 
Epoch 93/1000 
	 loss: 27.5053, MinusLogProbMetric: 27.5053, val_loss: 27.7969, val_MinusLogProbMetric: 27.7969

Epoch 93: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.5053 - MinusLogProbMetric: 27.5053 - val_loss: 27.7969 - val_MinusLogProbMetric: 27.7969 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 94/1000
2023-09-13 01:28:38.971 
Epoch 94/1000 
	 loss: 27.4998, MinusLogProbMetric: 27.4998, val_loss: 27.7432, val_MinusLogProbMetric: 27.7432

Epoch 94: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4998 - MinusLogProbMetric: 27.4998 - val_loss: 27.7432 - val_MinusLogProbMetric: 27.7432 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 95/1000
2023-09-13 01:28:49.231 
Epoch 95/1000 
	 loss: 27.4984, MinusLogProbMetric: 27.4984, val_loss: 27.7452, val_MinusLogProbMetric: 27.7452

Epoch 95: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4984 - MinusLogProbMetric: 27.4984 - val_loss: 27.7452 - val_MinusLogProbMetric: 27.7452 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 96/1000
2023-09-13 01:28:58.958 
Epoch 96/1000 
	 loss: 27.5114, MinusLogProbMetric: 27.5114, val_loss: 27.7114, val_MinusLogProbMetric: 27.7114

Epoch 96: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.5114 - MinusLogProbMetric: 27.5114 - val_loss: 27.7114 - val_MinusLogProbMetric: 27.7114 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 97/1000
2023-09-13 01:29:07.715 
Epoch 97/1000 
	 loss: 27.4819, MinusLogProbMetric: 27.4819, val_loss: 27.8055, val_MinusLogProbMetric: 27.8055

Epoch 97: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.4819 - MinusLogProbMetric: 27.4819 - val_loss: 27.8055 - val_MinusLogProbMetric: 27.8055 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 98/1000
2023-09-13 01:29:17.999 
Epoch 98/1000 
	 loss: 27.5012, MinusLogProbMetric: 27.5012, val_loss: 27.7896, val_MinusLogProbMetric: 27.7896

Epoch 98: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.5012 - MinusLogProbMetric: 27.5012 - val_loss: 27.7896 - val_MinusLogProbMetric: 27.7896 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 99/1000
2023-09-13 01:29:27.800 
Epoch 99/1000 
	 loss: 27.4677, MinusLogProbMetric: 27.4677, val_loss: 27.8197, val_MinusLogProbMetric: 27.8197

Epoch 99: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4677 - MinusLogProbMetric: 27.4677 - val_loss: 27.8197 - val_MinusLogProbMetric: 27.8197 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 100/1000
2023-09-13 01:29:36.215 
Epoch 100/1000 
	 loss: 27.4781, MinusLogProbMetric: 27.4781, val_loss: 27.8061, val_MinusLogProbMetric: 27.8061

Epoch 100: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4781 - MinusLogProbMetric: 27.4781 - val_loss: 27.8061 - val_MinusLogProbMetric: 27.8061 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 101/1000
2023-09-13 01:29:44.826 
Epoch 101/1000 
	 loss: 27.4775, MinusLogProbMetric: 27.4775, val_loss: 27.7810, val_MinusLogProbMetric: 27.7810

Epoch 101: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.4775 - MinusLogProbMetric: 27.4775 - val_loss: 27.7810 - val_MinusLogProbMetric: 27.7810 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 102/1000
2023-09-13 01:29:53.019 
Epoch 102/1000 
	 loss: 27.4638, MinusLogProbMetric: 27.4638, val_loss: 27.7518, val_MinusLogProbMetric: 27.7518

Epoch 102: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4638 - MinusLogProbMetric: 27.4638 - val_loss: 27.7518 - val_MinusLogProbMetric: 27.7518 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 103/1000
2023-09-13 01:30:01.323 
Epoch 103/1000 
	 loss: 27.4641, MinusLogProbMetric: 27.4641, val_loss: 27.7726, val_MinusLogProbMetric: 27.7726

Epoch 103: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4641 - MinusLogProbMetric: 27.4641 - val_loss: 27.7726 - val_MinusLogProbMetric: 27.7726 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 104/1000
2023-09-13 01:30:09.649 
Epoch 104/1000 
	 loss: 27.4635, MinusLogProbMetric: 27.4635, val_loss: 27.7524, val_MinusLogProbMetric: 27.7524

Epoch 104: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4635 - MinusLogProbMetric: 27.4635 - val_loss: 27.7524 - val_MinusLogProbMetric: 27.7524 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 105/1000
2023-09-13 01:30:17.939 
Epoch 105/1000 
	 loss: 27.4620, MinusLogProbMetric: 27.4620, val_loss: 27.7363, val_MinusLogProbMetric: 27.7363

Epoch 105: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4620 - MinusLogProbMetric: 27.4620 - val_loss: 27.7363 - val_MinusLogProbMetric: 27.7363 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 106/1000
2023-09-13 01:30:26.405 
Epoch 106/1000 
	 loss: 27.4682, MinusLogProbMetric: 27.4682, val_loss: 27.7785, val_MinusLogProbMetric: 27.7785

Epoch 106: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4682 - MinusLogProbMetric: 27.4682 - val_loss: 27.7785 - val_MinusLogProbMetric: 27.7785 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 107/1000
2023-09-13 01:30:34.862 
Epoch 107/1000 
	 loss: 27.4484, MinusLogProbMetric: 27.4484, val_loss: 27.8166, val_MinusLogProbMetric: 27.8166

Epoch 107: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4484 - MinusLogProbMetric: 27.4484 - val_loss: 27.8166 - val_MinusLogProbMetric: 27.8166 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 108/1000
2023-09-13 01:30:43.355 
Epoch 108/1000 
	 loss: 27.4437, MinusLogProbMetric: 27.4437, val_loss: 27.8423, val_MinusLogProbMetric: 27.8423

Epoch 108: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4437 - MinusLogProbMetric: 27.4437 - val_loss: 27.8423 - val_MinusLogProbMetric: 27.8423 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 109/1000
2023-09-13 01:30:53.592 
Epoch 109/1000 
	 loss: 27.4504, MinusLogProbMetric: 27.4504, val_loss: 27.7890, val_MinusLogProbMetric: 27.7890

Epoch 109: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4504 - MinusLogProbMetric: 27.4504 - val_loss: 27.7890 - val_MinusLogProbMetric: 27.7890 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 110/1000
2023-09-13 01:31:02.663 
Epoch 110/1000 
	 loss: 27.4381, MinusLogProbMetric: 27.4381, val_loss: 27.8077, val_MinusLogProbMetric: 27.8077

Epoch 110: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.4381 - MinusLogProbMetric: 27.4381 - val_loss: 27.8077 - val_MinusLogProbMetric: 27.8077 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 111/1000
2023-09-13 01:31:11.001 
Epoch 111/1000 
	 loss: 27.4460, MinusLogProbMetric: 27.4460, val_loss: 27.7815, val_MinusLogProbMetric: 27.7815

Epoch 111: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4460 - MinusLogProbMetric: 27.4460 - val_loss: 27.7815 - val_MinusLogProbMetric: 27.7815 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 112/1000
2023-09-13 01:31:19.498 
Epoch 112/1000 
	 loss: 27.4432, MinusLogProbMetric: 27.4432, val_loss: 27.7278, val_MinusLogProbMetric: 27.7278

Epoch 112: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4432 - MinusLogProbMetric: 27.4432 - val_loss: 27.7278 - val_MinusLogProbMetric: 27.7278 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 113/1000
2023-09-13 01:31:29.029 
Epoch 113/1000 
	 loss: 27.4415, MinusLogProbMetric: 27.4415, val_loss: 27.7905, val_MinusLogProbMetric: 27.7905

Epoch 113: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4415 - MinusLogProbMetric: 27.4415 - val_loss: 27.7905 - val_MinusLogProbMetric: 27.7905 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 114/1000
2023-09-13 01:31:39.513 
Epoch 114/1000 
	 loss: 27.4355, MinusLogProbMetric: 27.4355, val_loss: 27.8506, val_MinusLogProbMetric: 27.8506

Epoch 114: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4355 - MinusLogProbMetric: 27.4355 - val_loss: 27.8506 - val_MinusLogProbMetric: 27.8506 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 115/1000
2023-09-13 01:31:49.841 
Epoch 115/1000 
	 loss: 27.4276, MinusLogProbMetric: 27.4276, val_loss: 27.7387, val_MinusLogProbMetric: 27.7387

Epoch 115: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4276 - MinusLogProbMetric: 27.4276 - val_loss: 27.7387 - val_MinusLogProbMetric: 27.7387 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 116/1000
2023-09-13 01:32:00.370 
Epoch 116/1000 
	 loss: 27.4218, MinusLogProbMetric: 27.4218, val_loss: 27.8979, val_MinusLogProbMetric: 27.8979

Epoch 116: val_loss did not improve from 27.68149
196/196 - 11s - loss: 27.4218 - MinusLogProbMetric: 27.4218 - val_loss: 27.8979 - val_MinusLogProbMetric: 27.8979 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 117/1000
2023-09-13 01:32:10.783 
Epoch 117/1000 
	 loss: 27.4187, MinusLogProbMetric: 27.4187, val_loss: 27.7980, val_MinusLogProbMetric: 27.7980

Epoch 117: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4187 - MinusLogProbMetric: 27.4187 - val_loss: 27.7980 - val_MinusLogProbMetric: 27.7980 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 118/1000
2023-09-13 01:32:19.238 
Epoch 118/1000 
	 loss: 27.4316, MinusLogProbMetric: 27.4316, val_loss: 27.8024, val_MinusLogProbMetric: 27.8024

Epoch 118: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4316 - MinusLogProbMetric: 27.4316 - val_loss: 27.8024 - val_MinusLogProbMetric: 27.8024 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 119/1000
2023-09-13 01:32:28.038 
Epoch 119/1000 
	 loss: 27.4034, MinusLogProbMetric: 27.4034, val_loss: 27.7944, val_MinusLogProbMetric: 27.7944

Epoch 119: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.4034 - MinusLogProbMetric: 27.4034 - val_loss: 27.7944 - val_MinusLogProbMetric: 27.7944 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 120/1000
2023-09-13 01:32:38.289 
Epoch 120/1000 
	 loss: 27.4150, MinusLogProbMetric: 27.4150, val_loss: 27.8685, val_MinusLogProbMetric: 27.8685

Epoch 120: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.4150 - MinusLogProbMetric: 27.4150 - val_loss: 27.8685 - val_MinusLogProbMetric: 27.8685 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 121/1000
2023-09-13 01:32:46.888 
Epoch 121/1000 
	 loss: 27.4202, MinusLogProbMetric: 27.4202, val_loss: 27.8604, val_MinusLogProbMetric: 27.8604

Epoch 121: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.4202 - MinusLogProbMetric: 27.4202 - val_loss: 27.8604 - val_MinusLogProbMetric: 27.8604 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 122/1000
2023-09-13 01:32:55.178 
Epoch 122/1000 
	 loss: 27.4174, MinusLogProbMetric: 27.4174, val_loss: 27.8051, val_MinusLogProbMetric: 27.8051

Epoch 122: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4174 - MinusLogProbMetric: 27.4174 - val_loss: 27.8051 - val_MinusLogProbMetric: 27.8051 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 123/1000
2023-09-13 01:33:03.439 
Epoch 123/1000 
	 loss: 27.3966, MinusLogProbMetric: 27.3966, val_loss: 27.8776, val_MinusLogProbMetric: 27.8776

Epoch 123: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.3966 - MinusLogProbMetric: 27.3966 - val_loss: 27.8776 - val_MinusLogProbMetric: 27.8776 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 124/1000
2023-09-13 01:33:11.903 
Epoch 124/1000 
	 loss: 27.4098, MinusLogProbMetric: 27.4098, val_loss: 27.7378, val_MinusLogProbMetric: 27.7378

Epoch 124: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.4098 - MinusLogProbMetric: 27.4098 - val_loss: 27.7378 - val_MinusLogProbMetric: 27.7378 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 125/1000
2023-09-13 01:33:20.054 
Epoch 125/1000 
	 loss: 27.3875, MinusLogProbMetric: 27.3875, val_loss: 27.7506, val_MinusLogProbMetric: 27.7506

Epoch 125: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.3875 - MinusLogProbMetric: 27.3875 - val_loss: 27.7506 - val_MinusLogProbMetric: 27.7506 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 126/1000
2023-09-13 01:33:28.611 
Epoch 126/1000 
	 loss: 27.3860, MinusLogProbMetric: 27.3860, val_loss: 27.7620, val_MinusLogProbMetric: 27.7620

Epoch 126: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.3860 - MinusLogProbMetric: 27.3860 - val_loss: 27.7620 - val_MinusLogProbMetric: 27.7620 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 127/1000
2023-09-13 01:33:37.485 
Epoch 127/1000 
	 loss: 27.3878, MinusLogProbMetric: 27.3878, val_loss: 27.7780, val_MinusLogProbMetric: 27.7780

Epoch 127: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.3878 - MinusLogProbMetric: 27.3878 - val_loss: 27.7780 - val_MinusLogProbMetric: 27.7780 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 128/1000
2023-09-13 01:33:47.544 
Epoch 128/1000 
	 loss: 27.3939, MinusLogProbMetric: 27.3939, val_loss: 27.8496, val_MinusLogProbMetric: 27.8496

Epoch 128: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3939 - MinusLogProbMetric: 27.3939 - val_loss: 27.8496 - val_MinusLogProbMetric: 27.8496 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 129/1000
2023-09-13 01:33:58.066 
Epoch 129/1000 
	 loss: 27.3865, MinusLogProbMetric: 27.3865, val_loss: 27.8915, val_MinusLogProbMetric: 27.8915

Epoch 129: val_loss did not improve from 27.68149
196/196 - 11s - loss: 27.3865 - MinusLogProbMetric: 27.3865 - val_loss: 27.8915 - val_MinusLogProbMetric: 27.8915 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 130/1000
2023-09-13 01:34:08.383 
Epoch 130/1000 
	 loss: 27.3832, MinusLogProbMetric: 27.3832, val_loss: 27.8257, val_MinusLogProbMetric: 27.8257

Epoch 130: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3832 - MinusLogProbMetric: 27.3832 - val_loss: 27.8257 - val_MinusLogProbMetric: 27.8257 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 131/1000
2023-09-13 01:34:17.088 
Epoch 131/1000 
	 loss: 27.3832, MinusLogProbMetric: 27.3832, val_loss: 27.8580, val_MinusLogProbMetric: 27.8580

Epoch 131: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.3832 - MinusLogProbMetric: 27.3832 - val_loss: 27.8580 - val_MinusLogProbMetric: 27.8580 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 132/1000
2023-09-13 01:34:26.025 
Epoch 132/1000 
	 loss: 27.3811, MinusLogProbMetric: 27.3811, val_loss: 27.8480, val_MinusLogProbMetric: 27.8480

Epoch 132: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.3811 - MinusLogProbMetric: 27.3811 - val_loss: 27.8480 - val_MinusLogProbMetric: 27.8480 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 133/1000
2023-09-13 01:34:35.945 
Epoch 133/1000 
	 loss: 27.3861, MinusLogProbMetric: 27.3861, val_loss: 27.8170, val_MinusLogProbMetric: 27.8170

Epoch 133: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3861 - MinusLogProbMetric: 27.3861 - val_loss: 27.8170 - val_MinusLogProbMetric: 27.8170 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 134/1000
2023-09-13 01:34:44.212 
Epoch 134/1000 
	 loss: 27.3717, MinusLogProbMetric: 27.3717, val_loss: 27.8451, val_MinusLogProbMetric: 27.8451

Epoch 134: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.3717 - MinusLogProbMetric: 27.3717 - val_loss: 27.8451 - val_MinusLogProbMetric: 27.8451 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 135/1000
2023-09-13 01:34:52.641 
Epoch 135/1000 
	 loss: 27.3694, MinusLogProbMetric: 27.3694, val_loss: 27.8477, val_MinusLogProbMetric: 27.8477

Epoch 135: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.3694 - MinusLogProbMetric: 27.3694 - val_loss: 27.8477 - val_MinusLogProbMetric: 27.8477 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 136/1000
2023-09-13 01:35:01.775 
Epoch 136/1000 
	 loss: 27.3835, MinusLogProbMetric: 27.3835, val_loss: 27.8492, val_MinusLogProbMetric: 27.8492

Epoch 136: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.3835 - MinusLogProbMetric: 27.3835 - val_loss: 27.8492 - val_MinusLogProbMetric: 27.8492 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 137/1000
2023-09-13 01:35:12.034 
Epoch 137/1000 
	 loss: 27.3734, MinusLogProbMetric: 27.3734, val_loss: 27.8684, val_MinusLogProbMetric: 27.8684

Epoch 137: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3734 - MinusLogProbMetric: 27.3734 - val_loss: 27.8684 - val_MinusLogProbMetric: 27.8684 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 138/1000
2023-09-13 01:35:22.221 
Epoch 138/1000 
	 loss: 27.3701, MinusLogProbMetric: 27.3701, val_loss: 27.8358, val_MinusLogProbMetric: 27.8358

Epoch 138: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3701 - MinusLogProbMetric: 27.3701 - val_loss: 27.8358 - val_MinusLogProbMetric: 27.8358 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 139/1000
2023-09-13 01:35:32.367 
Epoch 139/1000 
	 loss: 27.3572, MinusLogProbMetric: 27.3572, val_loss: 27.8046, val_MinusLogProbMetric: 27.8046

Epoch 139: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3572 - MinusLogProbMetric: 27.3572 - val_loss: 27.8046 - val_MinusLogProbMetric: 27.8046 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 140/1000
2023-09-13 01:35:42.616 
Epoch 140/1000 
	 loss: 27.3684, MinusLogProbMetric: 27.3684, val_loss: 27.7889, val_MinusLogProbMetric: 27.7889

Epoch 140: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3684 - MinusLogProbMetric: 27.3684 - val_loss: 27.7889 - val_MinusLogProbMetric: 27.7889 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 141/1000
2023-09-13 01:35:52.831 
Epoch 141/1000 
	 loss: 27.3696, MinusLogProbMetric: 27.3696, val_loss: 27.8247, val_MinusLogProbMetric: 27.8247

Epoch 141: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3696 - MinusLogProbMetric: 27.3696 - val_loss: 27.8247 - val_MinusLogProbMetric: 27.8247 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 142/1000
2023-09-13 01:36:03.180 
Epoch 142/1000 
	 loss: 27.3613, MinusLogProbMetric: 27.3613, val_loss: 27.8216, val_MinusLogProbMetric: 27.8216

Epoch 142: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.3613 - MinusLogProbMetric: 27.3613 - val_loss: 27.8216 - val_MinusLogProbMetric: 27.8216 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 143/1000
2023-09-13 01:36:12.135 
Epoch 143/1000 
	 loss: 27.2378, MinusLogProbMetric: 27.2378, val_loss: 27.7062, val_MinusLogProbMetric: 27.7062

Epoch 143: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.2378 - MinusLogProbMetric: 27.2378 - val_loss: 27.7062 - val_MinusLogProbMetric: 27.7062 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 144/1000
2023-09-13 01:36:20.388 
Epoch 144/1000 
	 loss: 27.2298, MinusLogProbMetric: 27.2298, val_loss: 27.7585, val_MinusLogProbMetric: 27.7585

Epoch 144: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2298 - MinusLogProbMetric: 27.2298 - val_loss: 27.7585 - val_MinusLogProbMetric: 27.7585 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 145/1000
2023-09-13 01:36:28.782 
Epoch 145/1000 
	 loss: 27.2304, MinusLogProbMetric: 27.2304, val_loss: 27.7363, val_MinusLogProbMetric: 27.7363

Epoch 145: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2304 - MinusLogProbMetric: 27.2304 - val_loss: 27.7363 - val_MinusLogProbMetric: 27.7363 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 146/1000
2023-09-13 01:36:38.632 
Epoch 146/1000 
	 loss: 27.2264, MinusLogProbMetric: 27.2264, val_loss: 27.7150, val_MinusLogProbMetric: 27.7150

Epoch 146: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.2264 - MinusLogProbMetric: 27.2264 - val_loss: 27.7150 - val_MinusLogProbMetric: 27.7150 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 147/1000
2023-09-13 01:36:48.855 
Epoch 147/1000 
	 loss: 27.2301, MinusLogProbMetric: 27.2301, val_loss: 27.7133, val_MinusLogProbMetric: 27.7133

Epoch 147: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.2301 - MinusLogProbMetric: 27.2301 - val_loss: 27.7133 - val_MinusLogProbMetric: 27.7133 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 148/1000
2023-09-13 01:36:59.132 
Epoch 148/1000 
	 loss: 27.2258, MinusLogProbMetric: 27.2258, val_loss: 27.7255, val_MinusLogProbMetric: 27.7255

Epoch 148: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.2258 - MinusLogProbMetric: 27.2258 - val_loss: 27.7255 - val_MinusLogProbMetric: 27.7255 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 149/1000
2023-09-13 01:37:09.433 
Epoch 149/1000 
	 loss: 27.2231, MinusLogProbMetric: 27.2231, val_loss: 27.7254, val_MinusLogProbMetric: 27.7254

Epoch 149: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.2231 - MinusLogProbMetric: 27.2231 - val_loss: 27.7254 - val_MinusLogProbMetric: 27.7254 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 150/1000
2023-09-13 01:37:18.537 
Epoch 150/1000 
	 loss: 27.2220, MinusLogProbMetric: 27.2220, val_loss: 27.7329, val_MinusLogProbMetric: 27.7329

Epoch 150: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.2220 - MinusLogProbMetric: 27.2220 - val_loss: 27.7329 - val_MinusLogProbMetric: 27.7329 - lr: 5.0000e-04 - 9s/epoch - 46ms/step
Epoch 151/1000
2023-09-13 01:37:26.805 
Epoch 151/1000 
	 loss: 27.2200, MinusLogProbMetric: 27.2200, val_loss: 27.7476, val_MinusLogProbMetric: 27.7476

Epoch 151: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2200 - MinusLogProbMetric: 27.2200 - val_loss: 27.7476 - val_MinusLogProbMetric: 27.7476 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 152/1000
2023-09-13 01:37:35.084 
Epoch 152/1000 
	 loss: 27.2236, MinusLogProbMetric: 27.2236, val_loss: 27.7396, val_MinusLogProbMetric: 27.7396

Epoch 152: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2236 - MinusLogProbMetric: 27.2236 - val_loss: 27.7396 - val_MinusLogProbMetric: 27.7396 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 153/1000
2023-09-13 01:37:43.289 
Epoch 153/1000 
	 loss: 27.2166, MinusLogProbMetric: 27.2166, val_loss: 27.7456, val_MinusLogProbMetric: 27.7456

Epoch 153: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2166 - MinusLogProbMetric: 27.2166 - val_loss: 27.7456 - val_MinusLogProbMetric: 27.7456 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 154/1000
2023-09-13 01:37:51.840 
Epoch 154/1000 
	 loss: 27.2101, MinusLogProbMetric: 27.2101, val_loss: 27.7562, val_MinusLogProbMetric: 27.7562

Epoch 154: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.2101 - MinusLogProbMetric: 27.2101 - val_loss: 27.7562 - val_MinusLogProbMetric: 27.7562 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 155/1000
2023-09-13 01:38:00.076 
Epoch 155/1000 
	 loss: 27.2111, MinusLogProbMetric: 27.2111, val_loss: 27.7529, val_MinusLogProbMetric: 27.7529

Epoch 155: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2111 - MinusLogProbMetric: 27.2111 - val_loss: 27.7529 - val_MinusLogProbMetric: 27.7529 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 156/1000
2023-09-13 01:38:08.172 
Epoch 156/1000 
	 loss: 27.2141, MinusLogProbMetric: 27.2141, val_loss: 27.7616, val_MinusLogProbMetric: 27.7616

Epoch 156: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2141 - MinusLogProbMetric: 27.2141 - val_loss: 27.7616 - val_MinusLogProbMetric: 27.7616 - lr: 5.0000e-04 - 8s/epoch - 41ms/step
Epoch 157/1000
2023-09-13 01:38:17.469 
Epoch 157/1000 
	 loss: 27.2089, MinusLogProbMetric: 27.2089, val_loss: 27.7462, val_MinusLogProbMetric: 27.7462

Epoch 157: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.2089 - MinusLogProbMetric: 27.2089 - val_loss: 27.7462 - val_MinusLogProbMetric: 27.7462 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 158/1000
2023-09-13 01:38:27.977 
Epoch 158/1000 
	 loss: 27.2117, MinusLogProbMetric: 27.2117, val_loss: 27.7788, val_MinusLogProbMetric: 27.7788

Epoch 158: val_loss did not improve from 27.68149
196/196 - 11s - loss: 27.2117 - MinusLogProbMetric: 27.2117 - val_loss: 27.7788 - val_MinusLogProbMetric: 27.7788 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 159/1000
2023-09-13 01:38:36.548 
Epoch 159/1000 
	 loss: 27.2083, MinusLogProbMetric: 27.2083, val_loss: 27.7464, val_MinusLogProbMetric: 27.7464

Epoch 159: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.2083 - MinusLogProbMetric: 27.2083 - val_loss: 27.7464 - val_MinusLogProbMetric: 27.7464 - lr: 5.0000e-04 - 9s/epoch - 44ms/step
Epoch 160/1000
2023-09-13 01:38:44.924 
Epoch 160/1000 
	 loss: 27.2028, MinusLogProbMetric: 27.2028, val_loss: 27.7591, val_MinusLogProbMetric: 27.7591

Epoch 160: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2028 - MinusLogProbMetric: 27.2028 - val_loss: 27.7591 - val_MinusLogProbMetric: 27.7591 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 161/1000
2023-09-13 01:38:53.244 
Epoch 161/1000 
	 loss: 27.2023, MinusLogProbMetric: 27.2023, val_loss: 27.7570, val_MinusLogProbMetric: 27.7570

Epoch 161: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2023 - MinusLogProbMetric: 27.2023 - val_loss: 27.7570 - val_MinusLogProbMetric: 27.7570 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 162/1000
2023-09-13 01:39:01.583 
Epoch 162/1000 
	 loss: 27.2057, MinusLogProbMetric: 27.2057, val_loss: 27.7550, val_MinusLogProbMetric: 27.7550

Epoch 162: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2057 - MinusLogProbMetric: 27.2057 - val_loss: 27.7550 - val_MinusLogProbMetric: 27.7550 - lr: 5.0000e-04 - 8s/epoch - 43ms/step
Epoch 163/1000
2023-09-13 01:39:09.906 
Epoch 163/1000 
	 loss: 27.1975, MinusLogProbMetric: 27.1975, val_loss: 27.7370, val_MinusLogProbMetric: 27.7370

Epoch 163: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1975 - MinusLogProbMetric: 27.1975 - val_loss: 27.7370 - val_MinusLogProbMetric: 27.7370 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 164/1000
2023-09-13 01:39:18.098 
Epoch 164/1000 
	 loss: 27.2019, MinusLogProbMetric: 27.2019, val_loss: 27.7541, val_MinusLogProbMetric: 27.7541

Epoch 164: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.2019 - MinusLogProbMetric: 27.2019 - val_loss: 27.7541 - val_MinusLogProbMetric: 27.7541 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 165/1000
2023-09-13 01:39:27.387 
Epoch 165/1000 
	 loss: 27.1949, MinusLogProbMetric: 27.1949, val_loss: 27.7798, val_MinusLogProbMetric: 27.7798

Epoch 165: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.1949 - MinusLogProbMetric: 27.1949 - val_loss: 27.7798 - val_MinusLogProbMetric: 27.7798 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 166/1000
2023-09-13 01:39:37.760 
Epoch 166/1000 
	 loss: 27.1921, MinusLogProbMetric: 27.1921, val_loss: 27.7580, val_MinusLogProbMetric: 27.7580

Epoch 166: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1921 - MinusLogProbMetric: 27.1921 - val_loss: 27.7580 - val_MinusLogProbMetric: 27.7580 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 167/1000
2023-09-13 01:39:48.172 
Epoch 167/1000 
	 loss: 27.1924, MinusLogProbMetric: 27.1924, val_loss: 27.7782, val_MinusLogProbMetric: 27.7782

Epoch 167: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1924 - MinusLogProbMetric: 27.1924 - val_loss: 27.7782 - val_MinusLogProbMetric: 27.7782 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 168/1000
2023-09-13 01:39:58.503 
Epoch 168/1000 
	 loss: 27.1908, MinusLogProbMetric: 27.1908, val_loss: 27.7801, val_MinusLogProbMetric: 27.7801

Epoch 168: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1908 - MinusLogProbMetric: 27.1908 - val_loss: 27.7801 - val_MinusLogProbMetric: 27.7801 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 169/1000
2023-09-13 01:40:08.571 
Epoch 169/1000 
	 loss: 27.1931, MinusLogProbMetric: 27.1931, val_loss: 27.7574, val_MinusLogProbMetric: 27.7574

Epoch 169: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1931 - MinusLogProbMetric: 27.1931 - val_loss: 27.7574 - val_MinusLogProbMetric: 27.7574 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 170/1000
2023-09-13 01:40:16.800 
Epoch 170/1000 
	 loss: 27.1874, MinusLogProbMetric: 27.1874, val_loss: 27.8006, val_MinusLogProbMetric: 27.8006

Epoch 170: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1874 - MinusLogProbMetric: 27.1874 - val_loss: 27.8006 - val_MinusLogProbMetric: 27.8006 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 171/1000
2023-09-13 01:40:25.688 
Epoch 171/1000 
	 loss: 27.1920, MinusLogProbMetric: 27.1920, val_loss: 27.7481, val_MinusLogProbMetric: 27.7481

Epoch 171: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.1920 - MinusLogProbMetric: 27.1920 - val_loss: 27.7481 - val_MinusLogProbMetric: 27.7481 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 172/1000
2023-09-13 01:40:35.089 
Epoch 172/1000 
	 loss: 27.1917, MinusLogProbMetric: 27.1917, val_loss: 27.7886, val_MinusLogProbMetric: 27.7886

Epoch 172: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.1917 - MinusLogProbMetric: 27.1917 - val_loss: 27.7886 - val_MinusLogProbMetric: 27.7886 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 173/1000
2023-09-13 01:40:43.908 
Epoch 173/1000 
	 loss: 27.1892, MinusLogProbMetric: 27.1892, val_loss: 27.8050, val_MinusLogProbMetric: 27.8050

Epoch 173: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.1892 - MinusLogProbMetric: 27.1892 - val_loss: 27.8050 - val_MinusLogProbMetric: 27.8050 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 174/1000
2023-09-13 01:40:52.219 
Epoch 174/1000 
	 loss: 27.1920, MinusLogProbMetric: 27.1920, val_loss: 27.8122, val_MinusLogProbMetric: 27.8122

Epoch 174: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1920 - MinusLogProbMetric: 27.1920 - val_loss: 27.8122 - val_MinusLogProbMetric: 27.8122 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 175/1000
2023-09-13 01:41:00.478 
Epoch 175/1000 
	 loss: 27.1829, MinusLogProbMetric: 27.1829, val_loss: 27.7711, val_MinusLogProbMetric: 27.7711

Epoch 175: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1829 - MinusLogProbMetric: 27.1829 - val_loss: 27.7711 - val_MinusLogProbMetric: 27.7711 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 176/1000
2023-09-13 01:41:08.798 
Epoch 176/1000 
	 loss: 27.1820, MinusLogProbMetric: 27.1820, val_loss: 27.8117, val_MinusLogProbMetric: 27.8117

Epoch 176: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1820 - MinusLogProbMetric: 27.1820 - val_loss: 27.8117 - val_MinusLogProbMetric: 27.8117 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 177/1000
2023-09-13 01:41:16.971 
Epoch 177/1000 
	 loss: 27.1782, MinusLogProbMetric: 27.1782, val_loss: 27.7992, val_MinusLogProbMetric: 27.7992

Epoch 177: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1782 - MinusLogProbMetric: 27.1782 - val_loss: 27.7992 - val_MinusLogProbMetric: 27.7992 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 178/1000
2023-09-13 01:41:25.694 
Epoch 178/1000 
	 loss: 27.1770, MinusLogProbMetric: 27.1770, val_loss: 27.7754, val_MinusLogProbMetric: 27.7754

Epoch 178: val_loss did not improve from 27.68149
196/196 - 9s - loss: 27.1770 - MinusLogProbMetric: 27.1770 - val_loss: 27.7754 - val_MinusLogProbMetric: 27.7754 - lr: 5.0000e-04 - 9s/epoch - 45ms/step
Epoch 179/1000
2023-09-13 01:41:35.848 
Epoch 179/1000 
	 loss: 27.1782, MinusLogProbMetric: 27.1782, val_loss: 27.7825, val_MinusLogProbMetric: 27.7825

Epoch 179: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1782 - MinusLogProbMetric: 27.1782 - val_loss: 27.7825 - val_MinusLogProbMetric: 27.7825 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 180/1000
2023-09-13 01:41:46.000 
Epoch 180/1000 
	 loss: 27.1765, MinusLogProbMetric: 27.1765, val_loss: 27.7787, val_MinusLogProbMetric: 27.7787

Epoch 180: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1765 - MinusLogProbMetric: 27.1765 - val_loss: 27.7787 - val_MinusLogProbMetric: 27.7787 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 181/1000
2023-09-13 01:41:56.205 
Epoch 181/1000 
	 loss: 27.1721, MinusLogProbMetric: 27.1721, val_loss: 27.7925, val_MinusLogProbMetric: 27.7925

Epoch 181: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1721 - MinusLogProbMetric: 27.1721 - val_loss: 27.7925 - val_MinusLogProbMetric: 27.7925 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 182/1000
2023-09-13 01:42:06.022 
Epoch 182/1000 
	 loss: 27.1769, MinusLogProbMetric: 27.1769, val_loss: 27.7985, val_MinusLogProbMetric: 27.7985

Epoch 182: val_loss did not improve from 27.68149
196/196 - 10s - loss: 27.1769 - MinusLogProbMetric: 27.1769 - val_loss: 27.7985 - val_MinusLogProbMetric: 27.7985 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 183/1000
2023-09-13 01:42:14.332 
Epoch 183/1000 
	 loss: 27.1736, MinusLogProbMetric: 27.1736, val_loss: 27.8015, val_MinusLogProbMetric: 27.8015

Epoch 183: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1736 - MinusLogProbMetric: 27.1736 - val_loss: 27.8015 - val_MinusLogProbMetric: 27.8015 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 184/1000
2023-09-13 01:42:22.637 
Epoch 184/1000 
	 loss: 27.1708, MinusLogProbMetric: 27.1708, val_loss: 27.7943, val_MinusLogProbMetric: 27.7943

Epoch 184: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1708 - MinusLogProbMetric: 27.1708 - val_loss: 27.7943 - val_MinusLogProbMetric: 27.7943 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 185/1000
2023-09-13 01:42:30.859 
Epoch 185/1000 
	 loss: 27.1713, MinusLogProbMetric: 27.1713, val_loss: 27.7989, val_MinusLogProbMetric: 27.7989

Epoch 185: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1713 - MinusLogProbMetric: 27.1713 - val_loss: 27.7989 - val_MinusLogProbMetric: 27.7989 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 186/1000
2023-09-13 01:42:39.146 
Epoch 186/1000 
	 loss: 27.1699, MinusLogProbMetric: 27.1699, val_loss: 27.7827, val_MinusLogProbMetric: 27.7827

Epoch 186: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1699 - MinusLogProbMetric: 27.1699 - val_loss: 27.7827 - val_MinusLogProbMetric: 27.7827 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 187/1000
2023-09-13 01:42:47.377 
Epoch 187/1000 
	 loss: 27.1725, MinusLogProbMetric: 27.1725, val_loss: 27.8254, val_MinusLogProbMetric: 27.8254

Epoch 187: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1725 - MinusLogProbMetric: 27.1725 - val_loss: 27.8254 - val_MinusLogProbMetric: 27.8254 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 188/1000
2023-09-13 01:42:55.694 
Epoch 188/1000 
	 loss: 27.1625, MinusLogProbMetric: 27.1625, val_loss: 27.7900, val_MinusLogProbMetric: 27.7900

Epoch 188: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1625 - MinusLogProbMetric: 27.1625 - val_loss: 27.7900 - val_MinusLogProbMetric: 27.7900 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 189/1000
2023-09-13 01:43:03.985 
Epoch 189/1000 
	 loss: 27.1660, MinusLogProbMetric: 27.1660, val_loss: 27.7988, val_MinusLogProbMetric: 27.7988

Epoch 189: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1660 - MinusLogProbMetric: 27.1660 - val_loss: 27.7988 - val_MinusLogProbMetric: 27.7988 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 190/1000
2023-09-13 01:43:12.304 
Epoch 190/1000 
	 loss: 27.1694, MinusLogProbMetric: 27.1694, val_loss: 27.8048, val_MinusLogProbMetric: 27.8048

Epoch 190: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1694 - MinusLogProbMetric: 27.1694 - val_loss: 27.8048 - val_MinusLogProbMetric: 27.8048 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 191/1000
2023-09-13 01:43:20.531 
Epoch 191/1000 
	 loss: 27.1608, MinusLogProbMetric: 27.1608, val_loss: 27.8197, val_MinusLogProbMetric: 27.8197

Epoch 191: val_loss did not improve from 27.68149
196/196 - 8s - loss: 27.1608 - MinusLogProbMetric: 27.1608 - val_loss: 27.8197 - val_MinusLogProbMetric: 27.8197 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 192/1000
2023-09-13 01:43:28.768 
Epoch 192/1000 
	 loss: 27.1606, MinusLogProbMetric: 27.1606, val_loss: 27.8387, val_MinusLogProbMetric: 27.8387

Epoch 192: val_loss did not improve from 27.68149
Restoring model weights from the end of the best epoch: 92.
196/196 - 8s - loss: 27.1606 - MinusLogProbMetric: 27.1606 - val_loss: 27.8387 - val_MinusLogProbMetric: 27.8387 - lr: 5.0000e-04 - 8s/epoch - 42ms/step
Epoch 192: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 10.255144599010237 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 3.839716308983043 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1.7053802829468623 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.2850194780621678 seconds.
WARNING:root:Too few points to create valid contours
Training succeeded with seed 721.
Model trained in 1794.61 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 976 and retrying.
Warning: Batch size too large. Halving batch size to 488 and retrying.
Warning: Batch size too large. Halving batch size to 244 and retrying.
Warning: Batch size too large. Halving batch size to 122 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Metrics computed in 23861.18 s.
Plots done in 77.26 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 23938.44 s.
===========
Run 188/360 done in 25734.10 s.
===========

Directory ../../results/MsplineN_new/run_189/ already exists.
Skipping it.
===========
Run 189/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_190/ already exists.
Skipping it.
===========
Run 190/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_191/ already exists.
Skipping it.
===========
Run 191/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_192/ already exists.
Skipping it.
===========
Run 192/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_193/ already exists.
Skipping it.
===========
Run 193/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_194/ already exists.
Skipping it.
===========
Run 194/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_195/ already exists.
Skipping it.
===========
Run 195/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_196/ already exists.
Skipping it.
===========
Run 196/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_197/ already exists.
Skipping it.
===========
Run 197/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_198/ already exists.
Skipping it.
===========
Run 198/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_199/ already exists.
Skipping it.
===========
Run 199/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_200/ already exists.
Skipping it.
===========
Run 200/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_201/ already exists.
Skipping it.
===========
Run 201/360 already exists. Skipping it.
===========

===========
Generating train data for run 202.
===========
Train data generated in 0.18 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 100)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_202/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 0}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_202/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.1117342 ,  6.724983  ,  4.738387  , ...,  9.18981   ,
         9.966645  ,  9.417953  ],
       [ 3.070945  ,  7.03914   ,  3.3850236 , ...,  8.421514  ,
         9.388257  , 10.0439825 ],
       [ 3.3494005 ,  6.6208525 ,  4.071571  , ...,  8.689273  ,
         9.733164  , 10.183063  ],
       ...,
       [ 5.8936186 ,  7.0103445 ,  5.6668954 , ...,  0.10688139,
         8.324543  ,  0.35676813],
       [ 5.1697054 ,  6.843064  ,  5.9020343 , ...,  0.7361994 ,
         8.296032  , -0.01713873],
       [ 6.558123  ,  7.169092  ,  6.083838  , ...,  0.36036867,
         8.29056   , -0.10401164]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_202/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_202
self.data_kwargs: {'seed': 0}
self.x_data: [[3.1988616e+00 6.4596548e+00 3.4971681e+00 ... 8.4548540e+00
  9.9900160e+00 9.2984438e+00]
 [7.2895646e+00 2.2435577e+00 7.1758137e+00 ... 1.8451822e+00
  6.6551912e-01 4.2349429e+00]
 [4.5507236e+00 8.1209593e+00 6.0352001e+00 ... 4.3117601e-01
  8.2851753e+00 2.7205688e-01]
 ...
 [6.4571786e+00 3.3359065e+00 7.2818942e+00 ... 2.8372436e+00
  1.6785768e-01 3.7896473e+00]
 [7.0386562e+00 1.5919313e+00 7.3295102e+00 ... 3.2355165e+00
  9.2371702e-03 4.3022585e+00]
 [3.2339067e+00 7.1636057e+00 3.9843028e+00 ... 8.2155190e+00
  9.6683483e+00 8.1347198e+00]]
self.y_data: []
self.ndims: 100
Model defined.
Model: "model_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_82 (InputLayer)       [(None, 100)]             0         
                                                                 
 log_prob_layer_27 (LogProbL  (None,)                  1497080   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,497,080
Trainable params: 1,497,080
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_27/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_27'")
self.model: <keras.engine.functional.Functional object at 0x7fbc118028f0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fbbd508c940>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fbbd508c940>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fbbd508d210>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fbbd508ded0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fbbd508e440>, <keras.callbacks.ModelCheckpoint object at 0x7fbbd508e500>, <keras.callbacks.EarlyStopping object at 0x7fbbd508e770>, <keras.callbacks.ReduceLROnPlateau object at 0x7fbbd508e7a0>, <keras.callbacks.TerminateOnNaN object at 0x7fbbd508e3e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.1117342 ,  6.724983  ,  4.738387  , ...,  9.18981   ,
         9.966645  ,  9.417953  ],
       [ 3.070945  ,  7.03914   ,  3.3850236 , ...,  8.421514  ,
         9.388257  , 10.0439825 ],
       [ 3.3494005 ,  6.6208525 ,  4.071571  , ...,  8.689273  ,
         9.733164  , 10.183063  ],
       ...,
       [ 5.8936186 ,  7.0103445 ,  5.6668954 , ...,  0.10688139,
         8.324543  ,  0.35676813],
       [ 5.1697054 ,  6.843064  ,  5.9020343 , ...,  0.7361994 ,
         8.296032  , -0.01713873],
       [ 6.558123  ,  7.169092  ,  6.083838  , ...,  0.36036867,
         8.29056   , -0.10401164]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_202/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 202/360 with hyperparameters:
timestamp = 2023-09-13 08:22:28.470567
ndims = 100
seed_train = 0
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1497080
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 3.1988616   6.459655    3.497168    2.5258198   0.5146842   0.01144499
  8.660946    4.4687414   5.3369775   9.222479    9.825627    2.0164165
  5.8595243   2.7608967   0.01777877  7.9863286   3.0862474   4.038523
  4.8480043   8.324652    6.3692403   8.858448    2.7943842   8.503383
  1.8646172   9.545225    7.280446    3.16205     9.42947     7.2309823
  2.5119016   2.2208848   5.641275    0.15324405  1.8451912   3.9893744
  3.7616286   4.3864183   1.6560541   7.271039    8.639502    0.42183757
  5.939365    1.6088052   6.496237    3.9659636   5.826187    2.751687
  2.041491    5.154163    4.2846527   9.414735    8.1881895   6.119909
  9.289563    1.0227115   5.5518694   5.898068    8.84132     3.1552873
  2.987031    1.1560615   0.7653631  10.124298    5.9141235   7.6628203
  3.1531022   6.0366597   1.2124346   4.589357    9.863814    8.792568
  3.4425902   9.722224    1.758931    9.752882    9.420302    8.509628
  5.7721124   9.332831    3.1424959   7.715396    7.1740627   0.08349583
  3.1046915   1.3896693   9.787189    4.757281    4.951331    4.9443026
  1.1299293   2.0995584   9.307955    1.7638296   4.8817134   0.51830494
  1.3658354   8.454854    9.990016    9.298444  ]
Epoch 1/1000
2023-09-13 08:22:58.728 
Epoch 1/1000 
	 loss: 130.7804, MinusLogProbMetric: 130.7804, val_loss: 52.3946, val_MinusLogProbMetric: 52.3946

Epoch 1: val_loss improved from inf to 52.39459, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 30s - loss: 130.7804 - MinusLogProbMetric: 130.7804 - val_loss: 52.3946 - val_MinusLogProbMetric: 52.3946 - lr: 0.0010 - 30s/epoch - 155ms/step
Epoch 2/1000
2023-09-13 08:23:10.697 
Epoch 2/1000 
	 loss: 48.7594, MinusLogProbMetric: 48.7594, val_loss: 47.6035, val_MinusLogProbMetric: 47.6035

Epoch 2: val_loss improved from 52.39459 to 47.60353, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 12s - loss: 48.7594 - MinusLogProbMetric: 48.7594 - val_loss: 47.6035 - val_MinusLogProbMetric: 47.6035 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 3/1000
2023-09-13 08:23:22.406 
Epoch 3/1000 
	 loss: 45.6985, MinusLogProbMetric: 45.6985, val_loss: 45.2146, val_MinusLogProbMetric: 45.2146

Epoch 3: val_loss improved from 47.60353 to 45.21455, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 12s - loss: 45.6985 - MinusLogProbMetric: 45.6985 - val_loss: 45.2146 - val_MinusLogProbMetric: 45.2146 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 4/1000
2023-09-13 08:23:34.041 
Epoch 4/1000 
	 loss: 44.3783, MinusLogProbMetric: 44.3783, val_loss: 44.1606, val_MinusLogProbMetric: 44.1606

Epoch 4: val_loss improved from 45.21455 to 44.16056, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 12s - loss: 44.3783 - MinusLogProbMetric: 44.3783 - val_loss: 44.1606 - val_MinusLogProbMetric: 44.1606 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 5/1000
2023-09-13 08:23:45.475 
Epoch 5/1000 
	 loss: 44.0642, MinusLogProbMetric: 44.0642, val_loss: 43.2688, val_MinusLogProbMetric: 43.2688

Epoch 5: val_loss improved from 44.16056 to 43.26885, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 11s - loss: 44.0642 - MinusLogProbMetric: 44.0642 - val_loss: 43.2688 - val_MinusLogProbMetric: 43.2688 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 6/1000
2023-09-13 08:23:56.556 
Epoch 6/1000 
	 loss: 43.4263, MinusLogProbMetric: 43.4263, val_loss: 44.5413, val_MinusLogProbMetric: 44.5413

Epoch 6: val_loss did not improve from 43.26885
196/196 - 11s - loss: 43.4263 - MinusLogProbMetric: 43.4263 - val_loss: 44.5413 - val_MinusLogProbMetric: 44.5413 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 7/1000
2023-09-13 08:24:07.691 
Epoch 7/1000 
	 loss: 43.3142, MinusLogProbMetric: 43.3142, val_loss: 43.2753, val_MinusLogProbMetric: 43.2753

Epoch 7: val_loss did not improve from 43.26885
196/196 - 11s - loss: 43.3142 - MinusLogProbMetric: 43.3142 - val_loss: 43.2753 - val_MinusLogProbMetric: 43.2753 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 8/1000
2023-09-13 08:24:19.080 
Epoch 8/1000 
	 loss: 42.6076, MinusLogProbMetric: 42.6076, val_loss: 44.0396, val_MinusLogProbMetric: 44.0396

Epoch 8: val_loss did not improve from 43.26885
196/196 - 11s - loss: 42.6076 - MinusLogProbMetric: 42.6076 - val_loss: 44.0396 - val_MinusLogProbMetric: 44.0396 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 9/1000
2023-09-13 08:24:30.426 
Epoch 9/1000 
	 loss: 42.3406, MinusLogProbMetric: 42.3406, val_loss: 42.1713, val_MinusLogProbMetric: 42.1713

Epoch 9: val_loss improved from 43.26885 to 42.17130, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 11s - loss: 42.3406 - MinusLogProbMetric: 42.3406 - val_loss: 42.1713 - val_MinusLogProbMetric: 42.1713 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 10/1000
2023-09-13 08:24:41.027 
Epoch 10/1000 
	 loss: 42.3324, MinusLogProbMetric: 42.3324, val_loss: 43.2809, val_MinusLogProbMetric: 43.2809

Epoch 10: val_loss did not improve from 42.17130
196/196 - 10s - loss: 42.3324 - MinusLogProbMetric: 42.3324 - val_loss: 43.2809 - val_MinusLogProbMetric: 43.2809 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 11/1000
2023-09-13 08:24:49.683 
Epoch 11/1000 
	 loss: 42.1158, MinusLogProbMetric: 42.1158, val_loss: 41.4606, val_MinusLogProbMetric: 41.4606

Epoch 11: val_loss improved from 42.17130 to 41.46061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 9s - loss: 42.1158 - MinusLogProbMetric: 42.1158 - val_loss: 41.4606 - val_MinusLogProbMetric: 41.4606 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 12/1000
2023-09-13 08:24:58.303 
Epoch 12/1000 
	 loss: 41.9315, MinusLogProbMetric: 41.9315, val_loss: 41.8371, val_MinusLogProbMetric: 41.8371

Epoch 12: val_loss did not improve from 41.46061
196/196 - 9s - loss: 41.9315 - MinusLogProbMetric: 41.9315 - val_loss: 41.8371 - val_MinusLogProbMetric: 41.8371 - lr: 0.0010 - 9s/epoch - 43ms/step
Epoch 13/1000
2023-09-13 08:25:06.536 
Epoch 13/1000 
	 loss: 41.8441, MinusLogProbMetric: 41.8441, val_loss: 41.4911, val_MinusLogProbMetric: 41.4911

Epoch 13: val_loss did not improve from 41.46061
196/196 - 8s - loss: 41.8441 - MinusLogProbMetric: 41.8441 - val_loss: 41.4911 - val_MinusLogProbMetric: 41.4911 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 14/1000
2023-09-13 08:25:14.920 
Epoch 14/1000 
	 loss: 41.8381, MinusLogProbMetric: 41.8381, val_loss: 41.3300, val_MinusLogProbMetric: 41.3300

Epoch 14: val_loss improved from 41.46061 to 41.33004, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 9s - loss: 41.8381 - MinusLogProbMetric: 41.8381 - val_loss: 41.3300 - val_MinusLogProbMetric: 41.3300 - lr: 0.0010 - 9s/epoch - 43ms/step
Epoch 15/1000
2023-09-13 08:25:23.304 
Epoch 15/1000 
	 loss: 41.6192, MinusLogProbMetric: 41.6192, val_loss: 43.1512, val_MinusLogProbMetric: 43.1512

Epoch 15: val_loss did not improve from 41.33004
196/196 - 8s - loss: 41.6192 - MinusLogProbMetric: 41.6192 - val_loss: 43.1512 - val_MinusLogProbMetric: 43.1512 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 16/1000
2023-09-13 08:25:31.632 
Epoch 16/1000 
	 loss: 41.8251, MinusLogProbMetric: 41.8251, val_loss: 41.5078, val_MinusLogProbMetric: 41.5078

Epoch 16: val_loss did not improve from 41.33004
196/196 - 8s - loss: 41.8251 - MinusLogProbMetric: 41.8251 - val_loss: 41.5078 - val_MinusLogProbMetric: 41.5078 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 17/1000
2023-09-13 08:25:39.917 
Epoch 17/1000 
	 loss: 41.4868, MinusLogProbMetric: 41.4868, val_loss: 41.3886, val_MinusLogProbMetric: 41.3886

Epoch 17: val_loss did not improve from 41.33004
196/196 - 8s - loss: 41.4868 - MinusLogProbMetric: 41.4868 - val_loss: 41.3886 - val_MinusLogProbMetric: 41.3886 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 18/1000
2023-09-13 08:25:48.165 
Epoch 18/1000 
	 loss: 41.3664, MinusLogProbMetric: 41.3664, val_loss: 41.3181, val_MinusLogProbMetric: 41.3181

Epoch 18: val_loss improved from 41.33004 to 41.31810, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 8s - loss: 41.3664 - MinusLogProbMetric: 41.3664 - val_loss: 41.3181 - val_MinusLogProbMetric: 41.3181 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 19/1000
2023-09-13 08:25:56.636 
Epoch 19/1000 
	 loss: 41.4682, MinusLogProbMetric: 41.4682, val_loss: 41.3013, val_MinusLogProbMetric: 41.3013

Epoch 19: val_loss improved from 41.31810 to 41.30129, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 8s - loss: 41.4682 - MinusLogProbMetric: 41.4682 - val_loss: 41.3013 - val_MinusLogProbMetric: 41.3013 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 20/1000
2023-09-13 08:26:05.708 
Epoch 20/1000 
	 loss: 41.1261, MinusLogProbMetric: 41.1261, val_loss: 41.1888, val_MinusLogProbMetric: 41.1888

Epoch 20: val_loss improved from 41.30129 to 41.18877, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 9s - loss: 41.1261 - MinusLogProbMetric: 41.1261 - val_loss: 41.1888 - val_MinusLogProbMetric: 41.1888 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 21/1000
2023-09-13 08:26:14.182 
Epoch 21/1000 
	 loss: 41.2192, MinusLogProbMetric: 41.2192, val_loss: 41.3813, val_MinusLogProbMetric: 41.3813

Epoch 21: val_loss did not improve from 41.18877
196/196 - 8s - loss: 41.2192 - MinusLogProbMetric: 41.2192 - val_loss: 41.3813 - val_MinusLogProbMetric: 41.3813 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 22/1000
2023-09-13 08:26:22.711 
Epoch 22/1000 
	 loss: 41.5673, MinusLogProbMetric: 41.5673, val_loss: 40.9185, val_MinusLogProbMetric: 40.9185

Epoch 22: val_loss improved from 41.18877 to 40.91847, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 9s - loss: 41.5673 - MinusLogProbMetric: 41.5673 - val_loss: 40.9185 - val_MinusLogProbMetric: 40.9185 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 23/1000
2023-09-13 08:26:31.300 
Epoch 23/1000 
	 loss: 41.2463, MinusLogProbMetric: 41.2463, val_loss: 41.4368, val_MinusLogProbMetric: 41.4368

Epoch 23: val_loss did not improve from 40.91847
196/196 - 8s - loss: 41.2463 - MinusLogProbMetric: 41.2463 - val_loss: 41.4368 - val_MinusLogProbMetric: 41.4368 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 24/1000
2023-09-13 08:26:40.883 
Epoch 24/1000 
	 loss: 41.0994, MinusLogProbMetric: 41.0994, val_loss: 40.9678, val_MinusLogProbMetric: 40.9678

Epoch 24: val_loss did not improve from 40.91847
196/196 - 10s - loss: 41.0994 - MinusLogProbMetric: 41.0994 - val_loss: 40.9678 - val_MinusLogProbMetric: 40.9678 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 25/1000
2023-09-13 08:26:51.776 
Epoch 25/1000 
	 loss: 41.0320, MinusLogProbMetric: 41.0320, val_loss: 41.2310, val_MinusLogProbMetric: 41.2310

Epoch 25: val_loss did not improve from 40.91847
196/196 - 11s - loss: 41.0320 - MinusLogProbMetric: 41.0320 - val_loss: 41.2310 - val_MinusLogProbMetric: 41.2310 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 26/1000
2023-09-13 08:27:00.705 
Epoch 26/1000 
	 loss: 40.9538, MinusLogProbMetric: 40.9538, val_loss: 40.9885, val_MinusLogProbMetric: 40.9885

Epoch 26: val_loss did not improve from 40.91847
196/196 - 9s - loss: 40.9538 - MinusLogProbMetric: 40.9538 - val_loss: 40.9885 - val_MinusLogProbMetric: 40.9885 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 27/1000
2023-09-13 08:27:09.134 
Epoch 27/1000 
	 loss: 41.0055, MinusLogProbMetric: 41.0055, val_loss: 41.4079, val_MinusLogProbMetric: 41.4079

Epoch 27: val_loss did not improve from 40.91847
196/196 - 8s - loss: 41.0055 - MinusLogProbMetric: 41.0055 - val_loss: 41.4079 - val_MinusLogProbMetric: 41.4079 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 28/1000
2023-09-13 08:27:17.485 
Epoch 28/1000 
	 loss: 40.9283, MinusLogProbMetric: 40.9283, val_loss: 41.0561, val_MinusLogProbMetric: 41.0561

Epoch 28: val_loss did not improve from 40.91847
196/196 - 8s - loss: 40.9283 - MinusLogProbMetric: 40.9283 - val_loss: 41.0561 - val_MinusLogProbMetric: 41.0561 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 29/1000
2023-09-13 08:27:25.754 
Epoch 29/1000 
	 loss: 40.7520, MinusLogProbMetric: 40.7520, val_loss: 40.7140, val_MinusLogProbMetric: 40.7140

Epoch 29: val_loss improved from 40.91847 to 40.71404, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 8s - loss: 40.7520 - MinusLogProbMetric: 40.7520 - val_loss: 40.7140 - val_MinusLogProbMetric: 40.7140 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 30/1000
2023-09-13 08:27:34.171 
Epoch 30/1000 
	 loss: 40.8477, MinusLogProbMetric: 40.8477, val_loss: 41.2852, val_MinusLogProbMetric: 41.2852

Epoch 30: val_loss did not improve from 40.71404
196/196 - 8s - loss: 40.8477 - MinusLogProbMetric: 40.8477 - val_loss: 41.2852 - val_MinusLogProbMetric: 41.2852 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 31/1000
2023-09-13 08:27:42.397 
Epoch 31/1000 
	 loss: 40.7576, MinusLogProbMetric: 40.7576, val_loss: 41.0640, val_MinusLogProbMetric: 41.0640

Epoch 31: val_loss did not improve from 40.71404
196/196 - 8s - loss: 40.7576 - MinusLogProbMetric: 40.7576 - val_loss: 41.0640 - val_MinusLogProbMetric: 41.0640 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 32/1000
2023-09-13 08:27:50.528 
Epoch 32/1000 
	 loss: 40.6952, MinusLogProbMetric: 40.6952, val_loss: 40.9235, val_MinusLogProbMetric: 40.9235

Epoch 32: val_loss did not improve from 40.71404
196/196 - 8s - loss: 40.6952 - MinusLogProbMetric: 40.6952 - val_loss: 40.9235 - val_MinusLogProbMetric: 40.9235 - lr: 0.0010 - 8s/epoch - 41ms/step
Epoch 33/1000
2023-09-13 08:27:59.026 
Epoch 33/1000 
	 loss: 40.6968, MinusLogProbMetric: 40.6968, val_loss: 41.6464, val_MinusLogProbMetric: 41.6464

Epoch 33: val_loss did not improve from 40.71404
196/196 - 8s - loss: 40.6968 - MinusLogProbMetric: 40.6968 - val_loss: 41.6464 - val_MinusLogProbMetric: 41.6464 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 34/1000
2023-09-13 08:28:07.329 
Epoch 34/1000 
	 loss: 40.6512, MinusLogProbMetric: 40.6512, val_loss: 41.0670, val_MinusLogProbMetric: 41.0670

Epoch 34: val_loss did not improve from 40.71404
196/196 - 8s - loss: 40.6512 - MinusLogProbMetric: 40.6512 - val_loss: 41.0670 - val_MinusLogProbMetric: 41.0670 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 35/1000
2023-09-13 08:28:15.904 
Epoch 35/1000 
	 loss: 40.6790, MinusLogProbMetric: 40.6790, val_loss: 41.0746, val_MinusLogProbMetric: 41.0746

Epoch 35: val_loss did not improve from 40.71404
196/196 - 9s - loss: 40.6790 - MinusLogProbMetric: 40.6790 - val_loss: 41.0746 - val_MinusLogProbMetric: 41.0746 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 36/1000
2023-09-13 08:28:24.249 
Epoch 36/1000 
	 loss: 40.7603, MinusLogProbMetric: 40.7603, val_loss: 41.4440, val_MinusLogProbMetric: 41.4440

Epoch 36: val_loss did not improve from 40.71404
196/196 - 8s - loss: 40.7603 - MinusLogProbMetric: 40.7603 - val_loss: 41.4440 - val_MinusLogProbMetric: 41.4440 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 37/1000
2023-09-13 08:28:32.607 
Epoch 37/1000 
	 loss: 40.6504, MinusLogProbMetric: 40.6504, val_loss: 40.8943, val_MinusLogProbMetric: 40.8943

Epoch 37: val_loss did not improve from 40.71404
196/196 - 8s - loss: 40.6504 - MinusLogProbMetric: 40.6504 - val_loss: 40.8943 - val_MinusLogProbMetric: 40.8943 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 38/1000
2023-09-13 08:28:41.210 
Epoch 38/1000 
	 loss: 40.6239, MinusLogProbMetric: 40.6239, val_loss: 40.7740, val_MinusLogProbMetric: 40.7740

Epoch 38: val_loss did not improve from 40.71404
196/196 - 9s - loss: 40.6239 - MinusLogProbMetric: 40.6239 - val_loss: 40.7740 - val_MinusLogProbMetric: 40.7740 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 39/1000
2023-09-13 08:28:49.713 
Epoch 39/1000 
	 loss: 40.6127, MinusLogProbMetric: 40.6127, val_loss: 40.5058, val_MinusLogProbMetric: 40.5058

Epoch 39: val_loss improved from 40.71404 to 40.50583, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 9s - loss: 40.6127 - MinusLogProbMetric: 40.6127 - val_loss: 40.5058 - val_MinusLogProbMetric: 40.5058 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 40/1000
2023-09-13 08:28:58.128 
Epoch 40/1000 
	 loss: 40.6550, MinusLogProbMetric: 40.6550, val_loss: 41.0824, val_MinusLogProbMetric: 41.0824

Epoch 40: val_loss did not improve from 40.50583
196/196 - 8s - loss: 40.6550 - MinusLogProbMetric: 40.6550 - val_loss: 41.0824 - val_MinusLogProbMetric: 41.0824 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 41/1000
2023-09-13 08:29:06.351 
Epoch 41/1000 
	 loss: 40.5202, MinusLogProbMetric: 40.5202, val_loss: 40.8300, val_MinusLogProbMetric: 40.8300

Epoch 41: val_loss did not improve from 40.50583
196/196 - 8s - loss: 40.5202 - MinusLogProbMetric: 40.5202 - val_loss: 40.8300 - val_MinusLogProbMetric: 40.8300 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 42/1000
2023-09-13 08:29:14.647 
Epoch 42/1000 
	 loss: 40.5922, MinusLogProbMetric: 40.5922, val_loss: 41.0854, val_MinusLogProbMetric: 41.0854

Epoch 42: val_loss did not improve from 40.50583
196/196 - 8s - loss: 40.5922 - MinusLogProbMetric: 40.5922 - val_loss: 41.0854 - val_MinusLogProbMetric: 41.0854 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 43/1000
2023-09-13 08:29:22.968 
Epoch 43/1000 
	 loss: 40.5279, MinusLogProbMetric: 40.5279, val_loss: 40.7178, val_MinusLogProbMetric: 40.7178

Epoch 43: val_loss did not improve from 40.50583
196/196 - 8s - loss: 40.5279 - MinusLogProbMetric: 40.5279 - val_loss: 40.7178 - val_MinusLogProbMetric: 40.7178 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 44/1000
2023-09-13 08:29:31.175 
Epoch 44/1000 
	 loss: 40.5230, MinusLogProbMetric: 40.5230, val_loss: 41.0174, val_MinusLogProbMetric: 41.0174

Epoch 44: val_loss did not improve from 40.50583
196/196 - 8s - loss: 40.5230 - MinusLogProbMetric: 40.5230 - val_loss: 41.0174 - val_MinusLogProbMetric: 41.0174 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 45/1000
2023-09-13 08:29:39.524 
Epoch 45/1000 
	 loss: 40.5100, MinusLogProbMetric: 40.5100, val_loss: 40.7445, val_MinusLogProbMetric: 40.7445

Epoch 45: val_loss did not improve from 40.50583
196/196 - 8s - loss: 40.5100 - MinusLogProbMetric: 40.5100 - val_loss: 40.7445 - val_MinusLogProbMetric: 40.7445 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 46/1000
2023-09-13 08:29:48.881 
Epoch 46/1000 
	 loss: 40.4737, MinusLogProbMetric: 40.4737, val_loss: 41.1486, val_MinusLogProbMetric: 41.1486

Epoch 46: val_loss did not improve from 40.50583
196/196 - 9s - loss: 40.4737 - MinusLogProbMetric: 40.4737 - val_loss: 41.1486 - val_MinusLogProbMetric: 41.1486 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 47/1000
2023-09-13 08:29:59.423 
Epoch 47/1000 
	 loss: 40.4823, MinusLogProbMetric: 40.4823, val_loss: 40.5961, val_MinusLogProbMetric: 40.5961

Epoch 47: val_loss did not improve from 40.50583
196/196 - 11s - loss: 40.4823 - MinusLogProbMetric: 40.4823 - val_loss: 40.5961 - val_MinusLogProbMetric: 40.5961 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 48/1000
2023-09-13 08:30:11.033 
Epoch 48/1000 
	 loss: 40.5240, MinusLogProbMetric: 40.5240, val_loss: 40.6128, val_MinusLogProbMetric: 40.6128

Epoch 48: val_loss did not improve from 40.50583
196/196 - 12s - loss: 40.5240 - MinusLogProbMetric: 40.5240 - val_loss: 40.6128 - val_MinusLogProbMetric: 40.6128 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 49/1000
2023-09-13 08:30:20.795 
Epoch 49/1000 
	 loss: 40.4352, MinusLogProbMetric: 40.4352, val_loss: 40.5411, val_MinusLogProbMetric: 40.5411

Epoch 49: val_loss did not improve from 40.50583
196/196 - 10s - loss: 40.4352 - MinusLogProbMetric: 40.4352 - val_loss: 40.5411 - val_MinusLogProbMetric: 40.5411 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 50/1000
2023-09-13 08:30:31.399 
Epoch 50/1000 
	 loss: 40.4414, MinusLogProbMetric: 40.4414, val_loss: 40.5941, val_MinusLogProbMetric: 40.5941

Epoch 50: val_loss did not improve from 40.50583
196/196 - 11s - loss: 40.4414 - MinusLogProbMetric: 40.4414 - val_loss: 40.5941 - val_MinusLogProbMetric: 40.5941 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 51/1000
2023-09-13 08:30:42.245 
Epoch 51/1000 
	 loss: 40.4159, MinusLogProbMetric: 40.4159, val_loss: 40.5409, val_MinusLogProbMetric: 40.5409

Epoch 51: val_loss did not improve from 40.50583
196/196 - 11s - loss: 40.4159 - MinusLogProbMetric: 40.4159 - val_loss: 40.5409 - val_MinusLogProbMetric: 40.5409 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 52/1000
2023-09-13 08:30:53.817 
Epoch 52/1000 
	 loss: 40.4099, MinusLogProbMetric: 40.4099, val_loss: 41.2347, val_MinusLogProbMetric: 41.2347

Epoch 52: val_loss did not improve from 40.50583
196/196 - 12s - loss: 40.4099 - MinusLogProbMetric: 40.4099 - val_loss: 41.2347 - val_MinusLogProbMetric: 41.2347 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 53/1000
2023-09-13 08:31:04.043 
Epoch 53/1000 
	 loss: 40.4107, MinusLogProbMetric: 40.4107, val_loss: 40.4296, val_MinusLogProbMetric: 40.4296

Epoch 53: val_loss improved from 40.50583 to 40.42961, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 10s - loss: 40.4107 - MinusLogProbMetric: 40.4107 - val_loss: 40.4296 - val_MinusLogProbMetric: 40.4296 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 54/1000
2023-09-13 08:31:15.372 
Epoch 54/1000 
	 loss: 40.3968, MinusLogProbMetric: 40.3968, val_loss: 40.4669, val_MinusLogProbMetric: 40.4669

Epoch 54: val_loss did not improve from 40.42961
196/196 - 11s - loss: 40.3968 - MinusLogProbMetric: 40.3968 - val_loss: 40.4669 - val_MinusLogProbMetric: 40.4669 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 55/1000
2023-09-13 08:31:25.428 
Epoch 55/1000 
	 loss: 40.3876, MinusLogProbMetric: 40.3876, val_loss: 40.5935, val_MinusLogProbMetric: 40.5935

Epoch 55: val_loss did not improve from 40.42961
196/196 - 10s - loss: 40.3876 - MinusLogProbMetric: 40.3876 - val_loss: 40.5935 - val_MinusLogProbMetric: 40.5935 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 56/1000
2023-09-13 08:31:34.256 
Epoch 56/1000 
	 loss: 40.4179, MinusLogProbMetric: 40.4179, val_loss: 40.4004, val_MinusLogProbMetric: 40.4004

Epoch 56: val_loss improved from 40.42961 to 40.40038, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 9s - loss: 40.4179 - MinusLogProbMetric: 40.4179 - val_loss: 40.4004 - val_MinusLogProbMetric: 40.4004 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 57/1000
2023-09-13 08:31:43.944 
Epoch 57/1000 
	 loss: 40.3464, MinusLogProbMetric: 40.3464, val_loss: 40.5070, val_MinusLogProbMetric: 40.5070

Epoch 57: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.3464 - MinusLogProbMetric: 40.3464 - val_loss: 40.5070 - val_MinusLogProbMetric: 40.5070 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 58/1000
2023-09-13 08:31:54.759 
Epoch 58/1000 
	 loss: 40.3741, MinusLogProbMetric: 40.3741, val_loss: 40.5028, val_MinusLogProbMetric: 40.5028

Epoch 58: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.3741 - MinusLogProbMetric: 40.3741 - val_loss: 40.5028 - val_MinusLogProbMetric: 40.5028 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 59/1000
2023-09-13 08:32:05.147 
Epoch 59/1000 
	 loss: 40.3183, MinusLogProbMetric: 40.3183, val_loss: 40.8765, val_MinusLogProbMetric: 40.8765

Epoch 59: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.3183 - MinusLogProbMetric: 40.3183 - val_loss: 40.8765 - val_MinusLogProbMetric: 40.8765 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 60/1000
2023-09-13 08:32:15.722 
Epoch 60/1000 
	 loss: 40.3878, MinusLogProbMetric: 40.3878, val_loss: 40.4859, val_MinusLogProbMetric: 40.4859

Epoch 60: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.3878 - MinusLogProbMetric: 40.3878 - val_loss: 40.4859 - val_MinusLogProbMetric: 40.4859 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 61/1000
2023-09-13 08:32:26.137 
Epoch 61/1000 
	 loss: 40.3265, MinusLogProbMetric: 40.3265, val_loss: 40.6557, val_MinusLogProbMetric: 40.6557

Epoch 61: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.3265 - MinusLogProbMetric: 40.3265 - val_loss: 40.6557 - val_MinusLogProbMetric: 40.6557 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 62/1000
2023-09-13 08:32:36.772 
Epoch 62/1000 
	 loss: 40.3706, MinusLogProbMetric: 40.3706, val_loss: 40.5045, val_MinusLogProbMetric: 40.5045

Epoch 62: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.3706 - MinusLogProbMetric: 40.3706 - val_loss: 40.5045 - val_MinusLogProbMetric: 40.5045 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 63/1000
2023-09-13 08:32:47.386 
Epoch 63/1000 
	 loss: 40.3242, MinusLogProbMetric: 40.3242, val_loss: 40.4032, val_MinusLogProbMetric: 40.4032

Epoch 63: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.3242 - MinusLogProbMetric: 40.3242 - val_loss: 40.4032 - val_MinusLogProbMetric: 40.4032 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 64/1000
2023-09-13 08:32:57.403 
Epoch 64/1000 
	 loss: 40.3083, MinusLogProbMetric: 40.3083, val_loss: 40.6452, val_MinusLogProbMetric: 40.6452

Epoch 64: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.3083 - MinusLogProbMetric: 40.3083 - val_loss: 40.6452 - val_MinusLogProbMetric: 40.6452 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 65/1000
2023-09-13 08:33:05.957 
Epoch 65/1000 
	 loss: 40.3519, MinusLogProbMetric: 40.3519, val_loss: 40.4505, val_MinusLogProbMetric: 40.4505

Epoch 65: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.3519 - MinusLogProbMetric: 40.3519 - val_loss: 40.4505 - val_MinusLogProbMetric: 40.4505 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 66/1000
2023-09-13 08:33:14.525 
Epoch 66/1000 
	 loss: 40.3064, MinusLogProbMetric: 40.3064, val_loss: 40.5364, val_MinusLogProbMetric: 40.5364

Epoch 66: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.3064 - MinusLogProbMetric: 40.3064 - val_loss: 40.5364 - val_MinusLogProbMetric: 40.5364 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 67/1000
2023-09-13 08:33:23.085 
Epoch 67/1000 
	 loss: 40.2876, MinusLogProbMetric: 40.2876, val_loss: 41.1568, val_MinusLogProbMetric: 41.1568

Epoch 67: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.2876 - MinusLogProbMetric: 40.2876 - val_loss: 41.1568 - val_MinusLogProbMetric: 41.1568 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 68/1000
2023-09-13 08:33:31.641 
Epoch 68/1000 
	 loss: 40.3126, MinusLogProbMetric: 40.3126, val_loss: 40.5358, val_MinusLogProbMetric: 40.5358

Epoch 68: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.3126 - MinusLogProbMetric: 40.3126 - val_loss: 40.5358 - val_MinusLogProbMetric: 40.5358 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 69/1000
2023-09-13 08:33:40.347 
Epoch 69/1000 
	 loss: 40.2768, MinusLogProbMetric: 40.2768, val_loss: 40.4121, val_MinusLogProbMetric: 40.4121

Epoch 69: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.2768 - MinusLogProbMetric: 40.2768 - val_loss: 40.4121 - val_MinusLogProbMetric: 40.4121 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 70/1000
2023-09-13 08:33:48.860 
Epoch 70/1000 
	 loss: 40.2752, MinusLogProbMetric: 40.2752, val_loss: 40.6088, val_MinusLogProbMetric: 40.6088

Epoch 70: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.2752 - MinusLogProbMetric: 40.2752 - val_loss: 40.6088 - val_MinusLogProbMetric: 40.6088 - lr: 0.0010 - 9s/epoch - 43ms/step
Epoch 71/1000
2023-09-13 08:33:57.357 
Epoch 71/1000 
	 loss: 40.2723, MinusLogProbMetric: 40.2723, val_loss: 40.4209, val_MinusLogProbMetric: 40.4209

Epoch 71: val_loss did not improve from 40.40038
196/196 - 8s - loss: 40.2723 - MinusLogProbMetric: 40.2723 - val_loss: 40.4209 - val_MinusLogProbMetric: 40.4209 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 72/1000
2023-09-13 08:34:05.969 
Epoch 72/1000 
	 loss: 40.2530, MinusLogProbMetric: 40.2530, val_loss: 40.9135, val_MinusLogProbMetric: 40.9135

Epoch 72: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.2530 - MinusLogProbMetric: 40.2530 - val_loss: 40.9135 - val_MinusLogProbMetric: 40.9135 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 73/1000
2023-09-13 08:34:20.442 
Epoch 73/1000 
	 loss: 40.2512, MinusLogProbMetric: 40.2512, val_loss: 40.5511, val_MinusLogProbMetric: 40.5511

Epoch 73: val_loss did not improve from 40.40038
196/196 - 14s - loss: 40.2512 - MinusLogProbMetric: 40.2512 - val_loss: 40.5511 - val_MinusLogProbMetric: 40.5511 - lr: 0.0010 - 14s/epoch - 74ms/step
Epoch 74/1000
2023-09-13 08:34:31.530 
Epoch 74/1000 
	 loss: 40.2352, MinusLogProbMetric: 40.2352, val_loss: 40.5009, val_MinusLogProbMetric: 40.5009

Epoch 74: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.2352 - MinusLogProbMetric: 40.2352 - val_loss: 40.5009 - val_MinusLogProbMetric: 40.5009 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 75/1000
2023-09-13 08:34:41.496 
Epoch 75/1000 
	 loss: 40.2335, MinusLogProbMetric: 40.2335, val_loss: 40.5429, val_MinusLogProbMetric: 40.5429

Epoch 75: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.2335 - MinusLogProbMetric: 40.2335 - val_loss: 40.5429 - val_MinusLogProbMetric: 40.5429 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 76/1000
2023-09-13 08:34:51.299 
Epoch 76/1000 
	 loss: 40.2727, MinusLogProbMetric: 40.2727, val_loss: 40.5373, val_MinusLogProbMetric: 40.5373

Epoch 76: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.2727 - MinusLogProbMetric: 40.2727 - val_loss: 40.5373 - val_MinusLogProbMetric: 40.5373 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 77/1000
2023-09-13 08:35:01.315 
Epoch 77/1000 
	 loss: 40.1905, MinusLogProbMetric: 40.1905, val_loss: 40.8484, val_MinusLogProbMetric: 40.8484

Epoch 77: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.1905 - MinusLogProbMetric: 40.1905 - val_loss: 40.8484 - val_MinusLogProbMetric: 40.8484 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 78/1000
2023-09-13 08:35:09.954 
Epoch 78/1000 
	 loss: 40.2604, MinusLogProbMetric: 40.2604, val_loss: 40.6085, val_MinusLogProbMetric: 40.6085

Epoch 78: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.2604 - MinusLogProbMetric: 40.2604 - val_loss: 40.6085 - val_MinusLogProbMetric: 40.6085 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 79/1000
2023-09-13 08:35:19.943 
Epoch 79/1000 
	 loss: 40.2116, MinusLogProbMetric: 40.2116, val_loss: 40.4860, val_MinusLogProbMetric: 40.4860

Epoch 79: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.2116 - MinusLogProbMetric: 40.2116 - val_loss: 40.4860 - val_MinusLogProbMetric: 40.4860 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 80/1000
2023-09-13 08:35:31.172 
Epoch 80/1000 
	 loss: 40.2502, MinusLogProbMetric: 40.2502, val_loss: 40.4694, val_MinusLogProbMetric: 40.4694

Epoch 80: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.2502 - MinusLogProbMetric: 40.2502 - val_loss: 40.4694 - val_MinusLogProbMetric: 40.4694 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 81/1000
2023-09-13 08:35:42.095 
Epoch 81/1000 
	 loss: 40.1981, MinusLogProbMetric: 40.1981, val_loss: 40.5262, val_MinusLogProbMetric: 40.5262

Epoch 81: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.1981 - MinusLogProbMetric: 40.1981 - val_loss: 40.5262 - val_MinusLogProbMetric: 40.5262 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 82/1000
2023-09-13 08:35:53.224 
Epoch 82/1000 
	 loss: 40.2115, MinusLogProbMetric: 40.2115, val_loss: 40.5187, val_MinusLogProbMetric: 40.5187

Epoch 82: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.2115 - MinusLogProbMetric: 40.2115 - val_loss: 40.5187 - val_MinusLogProbMetric: 40.5187 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 83/1000
2023-09-13 08:36:03.233 
Epoch 83/1000 
	 loss: 40.2048, MinusLogProbMetric: 40.2048, val_loss: 40.5461, val_MinusLogProbMetric: 40.5461

Epoch 83: val_loss did not improve from 40.40038
196/196 - 10s - loss: 40.2048 - MinusLogProbMetric: 40.2048 - val_loss: 40.5461 - val_MinusLogProbMetric: 40.5461 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 84/1000
2023-09-13 08:36:12.708 
Epoch 84/1000 
	 loss: 40.1792, MinusLogProbMetric: 40.1792, val_loss: 40.6718, val_MinusLogProbMetric: 40.6718

Epoch 84: val_loss did not improve from 40.40038
196/196 - 9s - loss: 40.1792 - MinusLogProbMetric: 40.1792 - val_loss: 40.6718 - val_MinusLogProbMetric: 40.6718 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 85/1000
2023-09-13 08:36:23.755 
Epoch 85/1000 
	 loss: 40.2118, MinusLogProbMetric: 40.2118, val_loss: 40.4051, val_MinusLogProbMetric: 40.4051

Epoch 85: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.2118 - MinusLogProbMetric: 40.2118 - val_loss: 40.4051 - val_MinusLogProbMetric: 40.4051 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 86/1000
2023-09-13 08:36:34.946 
Epoch 86/1000 
	 loss: 40.1572, MinusLogProbMetric: 40.1572, val_loss: 40.5146, val_MinusLogProbMetric: 40.5146

Epoch 86: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.1572 - MinusLogProbMetric: 40.1572 - val_loss: 40.5146 - val_MinusLogProbMetric: 40.5146 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 87/1000
2023-09-13 08:36:46.446 
Epoch 87/1000 
	 loss: 40.2023, MinusLogProbMetric: 40.2023, val_loss: 40.5255, val_MinusLogProbMetric: 40.5255

Epoch 87: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.2023 - MinusLogProbMetric: 40.2023 - val_loss: 40.5255 - val_MinusLogProbMetric: 40.5255 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 88/1000
2023-09-13 08:36:57.794 
Epoch 88/1000 
	 loss: 40.1347, MinusLogProbMetric: 40.1347, val_loss: 40.5476, val_MinusLogProbMetric: 40.5476

Epoch 88: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.1347 - MinusLogProbMetric: 40.1347 - val_loss: 40.5476 - val_MinusLogProbMetric: 40.5476 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 89/1000
2023-09-13 08:37:09.218 
Epoch 89/1000 
	 loss: 40.1640, MinusLogProbMetric: 40.1640, val_loss: 40.4756, val_MinusLogProbMetric: 40.4756

Epoch 89: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.1640 - MinusLogProbMetric: 40.1640 - val_loss: 40.4756 - val_MinusLogProbMetric: 40.4756 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 90/1000
2023-09-13 08:37:20.532 
Epoch 90/1000 
	 loss: 40.1554, MinusLogProbMetric: 40.1554, val_loss: 40.4673, val_MinusLogProbMetric: 40.4673

Epoch 90: val_loss did not improve from 40.40038
196/196 - 11s - loss: 40.1554 - MinusLogProbMetric: 40.1554 - val_loss: 40.4673 - val_MinusLogProbMetric: 40.4673 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 91/1000
2023-09-13 08:37:32.017 
Epoch 91/1000 
	 loss: 40.1370, MinusLogProbMetric: 40.1370, val_loss: 40.3963, val_MinusLogProbMetric: 40.3963

Epoch 91: val_loss improved from 40.40038 to 40.39633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 12s - loss: 40.1370 - MinusLogProbMetric: 40.1370 - val_loss: 40.3963 - val_MinusLogProbMetric: 40.3963 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 92/1000
2023-09-13 08:37:42.752 
Epoch 92/1000 
	 loss: 40.1646, MinusLogProbMetric: 40.1646, val_loss: 40.3231, val_MinusLogProbMetric: 40.3231

Epoch 92: val_loss improved from 40.39633 to 40.32308, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 11s - loss: 40.1646 - MinusLogProbMetric: 40.1646 - val_loss: 40.3231 - val_MinusLogProbMetric: 40.3231 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 93/1000
2023-09-13 08:37:51.987 
Epoch 93/1000 
	 loss: 40.1640, MinusLogProbMetric: 40.1640, val_loss: 40.4341, val_MinusLogProbMetric: 40.4341

Epoch 93: val_loss did not improve from 40.32308
196/196 - 9s - loss: 40.1640 - MinusLogProbMetric: 40.1640 - val_loss: 40.4341 - val_MinusLogProbMetric: 40.4341 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 94/1000
2023-09-13 08:38:02.013 
Epoch 94/1000 
	 loss: 40.1629, MinusLogProbMetric: 40.1629, val_loss: 40.5061, val_MinusLogProbMetric: 40.5061

Epoch 94: val_loss did not improve from 40.32308
196/196 - 10s - loss: 40.1629 - MinusLogProbMetric: 40.1629 - val_loss: 40.5061 - val_MinusLogProbMetric: 40.5061 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 95/1000
2023-09-13 08:38:13.721 
Epoch 95/1000 
	 loss: 40.1404, MinusLogProbMetric: 40.1404, val_loss: 40.5126, val_MinusLogProbMetric: 40.5126

Epoch 95: val_loss did not improve from 40.32308
196/196 - 12s - loss: 40.1404 - MinusLogProbMetric: 40.1404 - val_loss: 40.5126 - val_MinusLogProbMetric: 40.5126 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-13 08:38:24.898 
Epoch 96/1000 
	 loss: 40.1202, MinusLogProbMetric: 40.1202, val_loss: 40.4536, val_MinusLogProbMetric: 40.4536

Epoch 96: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.1202 - MinusLogProbMetric: 40.1202 - val_loss: 40.4536 - val_MinusLogProbMetric: 40.4536 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 97/1000
2023-09-13 08:38:36.402 
Epoch 97/1000 
	 loss: 40.1100, MinusLogProbMetric: 40.1100, val_loss: 40.3556, val_MinusLogProbMetric: 40.3556

Epoch 97: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.1100 - MinusLogProbMetric: 40.1100 - val_loss: 40.3556 - val_MinusLogProbMetric: 40.3556 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 98/1000
2023-09-13 08:38:47.824 
Epoch 98/1000 
	 loss: 40.1413, MinusLogProbMetric: 40.1413, val_loss: 40.3620, val_MinusLogProbMetric: 40.3620

Epoch 98: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.1413 - MinusLogProbMetric: 40.1413 - val_loss: 40.3620 - val_MinusLogProbMetric: 40.3620 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 99/1000
2023-09-13 08:38:59.444 
Epoch 99/1000 
	 loss: 40.1247, MinusLogProbMetric: 40.1247, val_loss: 40.4517, val_MinusLogProbMetric: 40.4517

Epoch 99: val_loss did not improve from 40.32308
196/196 - 12s - loss: 40.1247 - MinusLogProbMetric: 40.1247 - val_loss: 40.4517 - val_MinusLogProbMetric: 40.4517 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 100/1000
2023-09-13 08:39:11.392 
Epoch 100/1000 
	 loss: 40.1144, MinusLogProbMetric: 40.1144, val_loss: 40.3620, val_MinusLogProbMetric: 40.3620

Epoch 100: val_loss did not improve from 40.32308
196/196 - 12s - loss: 40.1144 - MinusLogProbMetric: 40.1144 - val_loss: 40.3620 - val_MinusLogProbMetric: 40.3620 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 101/1000
2023-09-13 08:39:22.541 
Epoch 101/1000 
	 loss: 40.1165, MinusLogProbMetric: 40.1165, val_loss: 40.4296, val_MinusLogProbMetric: 40.4296

Epoch 101: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.1165 - MinusLogProbMetric: 40.1165 - val_loss: 40.4296 - val_MinusLogProbMetric: 40.4296 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 102/1000
2023-09-13 08:39:31.539 
Epoch 102/1000 
	 loss: 40.1381, MinusLogProbMetric: 40.1381, val_loss: 40.4667, val_MinusLogProbMetric: 40.4667

Epoch 102: val_loss did not improve from 40.32308
196/196 - 9s - loss: 40.1381 - MinusLogProbMetric: 40.1381 - val_loss: 40.4667 - val_MinusLogProbMetric: 40.4667 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 103/1000
2023-09-13 08:39:39.868 
Epoch 103/1000 
	 loss: 40.0990, MinusLogProbMetric: 40.0990, val_loss: 40.8639, val_MinusLogProbMetric: 40.8639

Epoch 103: val_loss did not improve from 40.32308
196/196 - 8s - loss: 40.0990 - MinusLogProbMetric: 40.0990 - val_loss: 40.8639 - val_MinusLogProbMetric: 40.8639 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 104/1000
2023-09-13 08:39:48.196 
Epoch 104/1000 
	 loss: 40.1108, MinusLogProbMetric: 40.1108, val_loss: 40.3821, val_MinusLogProbMetric: 40.3821

Epoch 104: val_loss did not improve from 40.32308
196/196 - 8s - loss: 40.1108 - MinusLogProbMetric: 40.1108 - val_loss: 40.3821 - val_MinusLogProbMetric: 40.3821 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 105/1000
2023-09-13 08:39:57.576 
Epoch 105/1000 
	 loss: 40.0970, MinusLogProbMetric: 40.0970, val_loss: 40.5011, val_MinusLogProbMetric: 40.5011

Epoch 105: val_loss did not improve from 40.32308
196/196 - 9s - loss: 40.0970 - MinusLogProbMetric: 40.0970 - val_loss: 40.5011 - val_MinusLogProbMetric: 40.5011 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 106/1000
2023-09-13 08:40:07.209 
Epoch 106/1000 
	 loss: 40.0858, MinusLogProbMetric: 40.0858, val_loss: 40.5193, val_MinusLogProbMetric: 40.5193

Epoch 106: val_loss did not improve from 40.32308
196/196 - 10s - loss: 40.0858 - MinusLogProbMetric: 40.0858 - val_loss: 40.5193 - val_MinusLogProbMetric: 40.5193 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 107/1000
2023-09-13 08:40:17.807 
Epoch 107/1000 
	 loss: 40.1203, MinusLogProbMetric: 40.1203, val_loss: 40.4590, val_MinusLogProbMetric: 40.4590

Epoch 107: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.1203 - MinusLogProbMetric: 40.1203 - val_loss: 40.4590 - val_MinusLogProbMetric: 40.4590 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 108/1000
2023-09-13 08:40:29.165 
Epoch 108/1000 
	 loss: 40.0811, MinusLogProbMetric: 40.0811, val_loss: 40.4281, val_MinusLogProbMetric: 40.4281

Epoch 108: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0811 - MinusLogProbMetric: 40.0811 - val_loss: 40.4281 - val_MinusLogProbMetric: 40.4281 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 109/1000
2023-09-13 08:40:40.193 
Epoch 109/1000 
	 loss: 40.0780, MinusLogProbMetric: 40.0780, val_loss: 40.4306, val_MinusLogProbMetric: 40.4306

Epoch 109: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0780 - MinusLogProbMetric: 40.0780 - val_loss: 40.4306 - val_MinusLogProbMetric: 40.4306 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 110/1000
2023-09-13 08:40:51.230 
Epoch 110/1000 
	 loss: 40.0577, MinusLogProbMetric: 40.0577, val_loss: 40.4490, val_MinusLogProbMetric: 40.4490

Epoch 110: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0577 - MinusLogProbMetric: 40.0577 - val_loss: 40.4490 - val_MinusLogProbMetric: 40.4490 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 111/1000
2023-09-13 08:41:02.083 
Epoch 111/1000 
	 loss: 40.0575, MinusLogProbMetric: 40.0575, val_loss: 40.5751, val_MinusLogProbMetric: 40.5751

Epoch 111: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0575 - MinusLogProbMetric: 40.0575 - val_loss: 40.5751 - val_MinusLogProbMetric: 40.5751 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 112/1000
2023-09-13 08:41:12.877 
Epoch 112/1000 
	 loss: 40.0782, MinusLogProbMetric: 40.0782, val_loss: 41.2066, val_MinusLogProbMetric: 41.2066

Epoch 112: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0782 - MinusLogProbMetric: 40.0782 - val_loss: 41.2066 - val_MinusLogProbMetric: 41.2066 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 113/1000
2023-09-13 08:41:23.765 
Epoch 113/1000 
	 loss: 40.0726, MinusLogProbMetric: 40.0726, val_loss: 40.4139, val_MinusLogProbMetric: 40.4139

Epoch 113: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0726 - MinusLogProbMetric: 40.0726 - val_loss: 40.4139 - val_MinusLogProbMetric: 40.4139 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 114/1000
2023-09-13 08:41:34.555 
Epoch 114/1000 
	 loss: 40.0397, MinusLogProbMetric: 40.0397, val_loss: 40.4933, val_MinusLogProbMetric: 40.4933

Epoch 114: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0397 - MinusLogProbMetric: 40.0397 - val_loss: 40.4933 - val_MinusLogProbMetric: 40.4933 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 115/1000
2023-09-13 08:41:45.496 
Epoch 115/1000 
	 loss: 40.0543, MinusLogProbMetric: 40.0543, val_loss: 40.4414, val_MinusLogProbMetric: 40.4414

Epoch 115: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0543 - MinusLogProbMetric: 40.0543 - val_loss: 40.4414 - val_MinusLogProbMetric: 40.4414 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 116/1000
2023-09-13 08:41:56.175 
Epoch 116/1000 
	 loss: 40.0447, MinusLogProbMetric: 40.0447, val_loss: 40.4054, val_MinusLogProbMetric: 40.4054

Epoch 116: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0447 - MinusLogProbMetric: 40.0447 - val_loss: 40.4054 - val_MinusLogProbMetric: 40.4054 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 117/1000
2023-09-13 08:42:07.275 
Epoch 117/1000 
	 loss: 40.0520, MinusLogProbMetric: 40.0520, val_loss: 40.4307, val_MinusLogProbMetric: 40.4307

Epoch 117: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0520 - MinusLogProbMetric: 40.0520 - val_loss: 40.4307 - val_MinusLogProbMetric: 40.4307 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 118/1000
2023-09-13 08:42:18.147 
Epoch 118/1000 
	 loss: 40.0316, MinusLogProbMetric: 40.0316, val_loss: 40.5071, val_MinusLogProbMetric: 40.5071

Epoch 118: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0316 - MinusLogProbMetric: 40.0316 - val_loss: 40.5071 - val_MinusLogProbMetric: 40.5071 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 119/1000
2023-09-13 08:42:28.931 
Epoch 119/1000 
	 loss: 40.0361, MinusLogProbMetric: 40.0361, val_loss: 40.4957, val_MinusLogProbMetric: 40.4957

Epoch 119: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0361 - MinusLogProbMetric: 40.0361 - val_loss: 40.4957 - val_MinusLogProbMetric: 40.4957 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 120/1000
2023-09-13 08:42:39.828 
Epoch 120/1000 
	 loss: 40.0356, MinusLogProbMetric: 40.0356, val_loss: 40.4242, val_MinusLogProbMetric: 40.4242

Epoch 120: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0356 - MinusLogProbMetric: 40.0356 - val_loss: 40.4242 - val_MinusLogProbMetric: 40.4242 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 121/1000
2023-09-13 08:42:50.395 
Epoch 121/1000 
	 loss: 40.0248, MinusLogProbMetric: 40.0248, val_loss: 40.4926, val_MinusLogProbMetric: 40.4926

Epoch 121: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0248 - MinusLogProbMetric: 40.0248 - val_loss: 40.4926 - val_MinusLogProbMetric: 40.4926 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 122/1000
2023-09-13 08:43:00.484 
Epoch 122/1000 
	 loss: 40.0076, MinusLogProbMetric: 40.0076, val_loss: 40.5285, val_MinusLogProbMetric: 40.5285

Epoch 122: val_loss did not improve from 40.32308
196/196 - 10s - loss: 40.0076 - MinusLogProbMetric: 40.0076 - val_loss: 40.5285 - val_MinusLogProbMetric: 40.5285 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 123/1000
2023-09-13 08:43:11.334 
Epoch 123/1000 
	 loss: 40.0419, MinusLogProbMetric: 40.0419, val_loss: 40.3998, val_MinusLogProbMetric: 40.3998

Epoch 123: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0419 - MinusLogProbMetric: 40.0419 - val_loss: 40.3998 - val_MinusLogProbMetric: 40.3998 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 124/1000
2023-09-13 08:43:22.215 
Epoch 124/1000 
	 loss: 40.0439, MinusLogProbMetric: 40.0439, val_loss: 40.5123, val_MinusLogProbMetric: 40.5123

Epoch 124: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0439 - MinusLogProbMetric: 40.0439 - val_loss: 40.5123 - val_MinusLogProbMetric: 40.5123 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 125/1000
2023-09-13 08:43:33.105 
Epoch 125/1000 
	 loss: 40.0222, MinusLogProbMetric: 40.0222, val_loss: 40.4757, val_MinusLogProbMetric: 40.4757

Epoch 125: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0222 - MinusLogProbMetric: 40.0222 - val_loss: 40.4757 - val_MinusLogProbMetric: 40.4757 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 126/1000
2023-09-13 08:43:44.383 
Epoch 126/1000 
	 loss: 39.9790, MinusLogProbMetric: 39.9790, val_loss: 40.4771, val_MinusLogProbMetric: 40.4771

Epoch 126: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9790 - MinusLogProbMetric: 39.9790 - val_loss: 40.4771 - val_MinusLogProbMetric: 40.4771 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 127/1000
2023-09-13 08:43:55.425 
Epoch 127/1000 
	 loss: 40.0252, MinusLogProbMetric: 40.0252, val_loss: 40.4096, val_MinusLogProbMetric: 40.4096

Epoch 127: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0252 - MinusLogProbMetric: 40.0252 - val_loss: 40.4096 - val_MinusLogProbMetric: 40.4096 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 128/1000
2023-09-13 08:44:06.330 
Epoch 128/1000 
	 loss: 39.9659, MinusLogProbMetric: 39.9659, val_loss: 40.4210, val_MinusLogProbMetric: 40.4210

Epoch 128: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9659 - MinusLogProbMetric: 39.9659 - val_loss: 40.4210 - val_MinusLogProbMetric: 40.4210 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 129/1000
2023-09-13 08:44:17.191 
Epoch 129/1000 
	 loss: 39.9946, MinusLogProbMetric: 39.9946, val_loss: 40.5836, val_MinusLogProbMetric: 40.5836

Epoch 129: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9946 - MinusLogProbMetric: 39.9946 - val_loss: 40.5836 - val_MinusLogProbMetric: 40.5836 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 130/1000
2023-09-13 08:44:27.573 
Epoch 130/1000 
	 loss: 40.0159, MinusLogProbMetric: 40.0159, val_loss: 40.7212, val_MinusLogProbMetric: 40.7212

Epoch 130: val_loss did not improve from 40.32308
196/196 - 10s - loss: 40.0159 - MinusLogProbMetric: 40.0159 - val_loss: 40.7212 - val_MinusLogProbMetric: 40.7212 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 131/1000
2023-09-13 08:44:38.371 
Epoch 131/1000 
	 loss: 39.9953, MinusLogProbMetric: 39.9953, val_loss: 40.6367, val_MinusLogProbMetric: 40.6367

Epoch 131: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9953 - MinusLogProbMetric: 39.9953 - val_loss: 40.6367 - val_MinusLogProbMetric: 40.6367 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 132/1000
2023-09-13 08:44:49.383 
Epoch 132/1000 
	 loss: 40.0017, MinusLogProbMetric: 40.0017, val_loss: 40.4554, val_MinusLogProbMetric: 40.4554

Epoch 132: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0017 - MinusLogProbMetric: 40.0017 - val_loss: 40.4554 - val_MinusLogProbMetric: 40.4554 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 133/1000
2023-09-13 08:45:00.200 
Epoch 133/1000 
	 loss: 40.0000, MinusLogProbMetric: 40.0000, val_loss: 40.3722, val_MinusLogProbMetric: 40.3722

Epoch 133: val_loss did not improve from 40.32308
196/196 - 11s - loss: 40.0000 - MinusLogProbMetric: 40.0000 - val_loss: 40.3722 - val_MinusLogProbMetric: 40.3722 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 134/1000
2023-09-13 08:45:10.699 
Epoch 134/1000 
	 loss: 39.9718, MinusLogProbMetric: 39.9718, val_loss: 40.4676, val_MinusLogProbMetric: 40.4676

Epoch 134: val_loss did not improve from 40.32308
196/196 - 10s - loss: 39.9718 - MinusLogProbMetric: 39.9718 - val_loss: 40.4676 - val_MinusLogProbMetric: 40.4676 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 135/1000
2023-09-13 08:45:21.551 
Epoch 135/1000 
	 loss: 39.9876, MinusLogProbMetric: 39.9876, val_loss: 40.3722, val_MinusLogProbMetric: 40.3722

Epoch 135: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9876 - MinusLogProbMetric: 39.9876 - val_loss: 40.3722 - val_MinusLogProbMetric: 40.3722 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 136/1000
2023-09-13 08:45:32.635 
Epoch 136/1000 
	 loss: 39.9704, MinusLogProbMetric: 39.9704, val_loss: 40.5611, val_MinusLogProbMetric: 40.5611

Epoch 136: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9704 - MinusLogProbMetric: 39.9704 - val_loss: 40.5611 - val_MinusLogProbMetric: 40.5611 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 137/1000
2023-09-13 08:45:43.796 
Epoch 137/1000 
	 loss: 39.9728, MinusLogProbMetric: 39.9728, val_loss: 40.4796, val_MinusLogProbMetric: 40.4796

Epoch 137: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9728 - MinusLogProbMetric: 39.9728 - val_loss: 40.4796 - val_MinusLogProbMetric: 40.4796 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 138/1000
2023-09-13 08:45:54.409 
Epoch 138/1000 
	 loss: 39.9782, MinusLogProbMetric: 39.9782, val_loss: 40.4456, val_MinusLogProbMetric: 40.4456

Epoch 138: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9782 - MinusLogProbMetric: 39.9782 - val_loss: 40.4456 - val_MinusLogProbMetric: 40.4456 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 139/1000
2023-09-13 08:46:05.129 
Epoch 139/1000 
	 loss: 39.9789, MinusLogProbMetric: 39.9789, val_loss: 40.4317, val_MinusLogProbMetric: 40.4317

Epoch 139: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9789 - MinusLogProbMetric: 39.9789 - val_loss: 40.4317 - val_MinusLogProbMetric: 40.4317 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 140/1000
2023-09-13 08:46:16.140 
Epoch 140/1000 
	 loss: 39.9712, MinusLogProbMetric: 39.9712, val_loss: 40.3755, val_MinusLogProbMetric: 40.3755

Epoch 140: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9712 - MinusLogProbMetric: 39.9712 - val_loss: 40.3755 - val_MinusLogProbMetric: 40.3755 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 141/1000
2023-09-13 08:46:26.749 
Epoch 141/1000 
	 loss: 39.9549, MinusLogProbMetric: 39.9549, val_loss: 40.4585, val_MinusLogProbMetric: 40.4585

Epoch 141: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9549 - MinusLogProbMetric: 39.9549 - val_loss: 40.4585 - val_MinusLogProbMetric: 40.4585 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 142/1000
2023-09-13 08:46:37.681 
Epoch 142/1000 
	 loss: 39.9386, MinusLogProbMetric: 39.9386, val_loss: 40.5074, val_MinusLogProbMetric: 40.5074

Epoch 142: val_loss did not improve from 40.32308
196/196 - 11s - loss: 39.9386 - MinusLogProbMetric: 39.9386 - val_loss: 40.5074 - val_MinusLogProbMetric: 40.5074 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 143/1000
2023-09-13 08:46:48.992 
Epoch 143/1000 
	 loss: 39.7593, MinusLogProbMetric: 39.7593, val_loss: 40.3217, val_MinusLogProbMetric: 40.3217

Epoch 143: val_loss improved from 40.32308 to 40.32168, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 11s - loss: 39.7593 - MinusLogProbMetric: 39.7593 - val_loss: 40.3217 - val_MinusLogProbMetric: 40.3217 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 144/1000
2023-09-13 08:47:00.712 
Epoch 144/1000 
	 loss: 39.7484, MinusLogProbMetric: 39.7484, val_loss: 40.2864, val_MinusLogProbMetric: 40.2864

Epoch 144: val_loss improved from 40.32168 to 40.28637, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 12s - loss: 39.7484 - MinusLogProbMetric: 39.7484 - val_loss: 40.2864 - val_MinusLogProbMetric: 40.2864 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 145/1000
2023-09-13 08:47:11.947 
Epoch 145/1000 
	 loss: 39.7550, MinusLogProbMetric: 39.7550, val_loss: 40.3156, val_MinusLogProbMetric: 40.3156

Epoch 145: val_loss did not improve from 40.28637
196/196 - 11s - loss: 39.7550 - MinusLogProbMetric: 39.7550 - val_loss: 40.3156 - val_MinusLogProbMetric: 40.3156 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 146/1000
2023-09-13 08:47:23.260 
Epoch 146/1000 
	 loss: 39.7419, MinusLogProbMetric: 39.7419, val_loss: 40.3137, val_MinusLogProbMetric: 40.3137

Epoch 146: val_loss did not improve from 40.28637
196/196 - 11s - loss: 39.7419 - MinusLogProbMetric: 39.7419 - val_loss: 40.3137 - val_MinusLogProbMetric: 40.3137 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-13 08:47:34.453 
Epoch 147/1000 
	 loss: 39.7524, MinusLogProbMetric: 39.7524, val_loss: 40.3067, val_MinusLogProbMetric: 40.3067

Epoch 147: val_loss did not improve from 40.28637
196/196 - 11s - loss: 39.7524 - MinusLogProbMetric: 39.7524 - val_loss: 40.3067 - val_MinusLogProbMetric: 40.3067 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 148/1000
2023-09-13 08:47:45.434 
Epoch 148/1000 
	 loss: 39.7393, MinusLogProbMetric: 39.7393, val_loss: 40.2923, val_MinusLogProbMetric: 40.2923

Epoch 148: val_loss did not improve from 40.28637
196/196 - 11s - loss: 39.7393 - MinusLogProbMetric: 39.7393 - val_loss: 40.2923 - val_MinusLogProbMetric: 40.2923 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 149/1000
2023-09-13 08:47:56.623 
Epoch 149/1000 
	 loss: 39.7583, MinusLogProbMetric: 39.7583, val_loss: 40.2724, val_MinusLogProbMetric: 40.2724

Epoch 149: val_loss improved from 40.28637 to 40.27237, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_202/weights/best_weights.h5
196/196 - 11s - loss: 39.7583 - MinusLogProbMetric: 39.7583 - val_loss: 40.2724 - val_MinusLogProbMetric: 40.2724 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 150/1000
2023-09-13 08:48:07.721 
Epoch 150/1000 
	 loss: 39.7504, MinusLogProbMetric: 39.7504, val_loss: 40.2976, val_MinusLogProbMetric: 40.2976

Epoch 150: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7504 - MinusLogProbMetric: 39.7504 - val_loss: 40.2976 - val_MinusLogProbMetric: 40.2976 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 151/1000
2023-09-13 08:48:18.964 
Epoch 151/1000 
	 loss: 39.7365, MinusLogProbMetric: 39.7365, val_loss: 40.3604, val_MinusLogProbMetric: 40.3604

Epoch 151: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7365 - MinusLogProbMetric: 39.7365 - val_loss: 40.3604 - val_MinusLogProbMetric: 40.3604 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 152/1000
2023-09-13 08:48:30.350 
Epoch 152/1000 
	 loss: 39.7468, MinusLogProbMetric: 39.7468, val_loss: 40.3419, val_MinusLogProbMetric: 40.3419

Epoch 152: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7468 - MinusLogProbMetric: 39.7468 - val_loss: 40.3419 - val_MinusLogProbMetric: 40.3419 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 153/1000
2023-09-13 08:48:41.839 
Epoch 153/1000 
	 loss: 39.7479, MinusLogProbMetric: 39.7479, val_loss: 40.3249, val_MinusLogProbMetric: 40.3249

Epoch 153: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7479 - MinusLogProbMetric: 39.7479 - val_loss: 40.3249 - val_MinusLogProbMetric: 40.3249 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 154/1000
2023-09-13 08:48:53.081 
Epoch 154/1000 
	 loss: 39.7300, MinusLogProbMetric: 39.7300, val_loss: 40.3669, val_MinusLogProbMetric: 40.3669

Epoch 154: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7300 - MinusLogProbMetric: 39.7300 - val_loss: 40.3669 - val_MinusLogProbMetric: 40.3669 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 155/1000
2023-09-13 08:49:03.626 
Epoch 155/1000 
	 loss: 39.7311, MinusLogProbMetric: 39.7311, val_loss: 40.3485, val_MinusLogProbMetric: 40.3485

Epoch 155: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7311 - MinusLogProbMetric: 39.7311 - val_loss: 40.3485 - val_MinusLogProbMetric: 40.3485 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 156/1000
2023-09-13 08:49:14.346 
Epoch 156/1000 
	 loss: 39.7361, MinusLogProbMetric: 39.7361, val_loss: 40.3338, val_MinusLogProbMetric: 40.3338

Epoch 156: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7361 - MinusLogProbMetric: 39.7361 - val_loss: 40.3338 - val_MinusLogProbMetric: 40.3338 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 157/1000
2023-09-13 08:49:24.975 
Epoch 157/1000 
	 loss: 39.7296, MinusLogProbMetric: 39.7296, val_loss: 40.3065, val_MinusLogProbMetric: 40.3065

Epoch 157: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7296 - MinusLogProbMetric: 39.7296 - val_loss: 40.3065 - val_MinusLogProbMetric: 40.3065 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 158/1000
2023-09-13 08:49:36.175 
Epoch 158/1000 
	 loss: 39.7335, MinusLogProbMetric: 39.7335, val_loss: 40.3494, val_MinusLogProbMetric: 40.3494

Epoch 158: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7335 - MinusLogProbMetric: 39.7335 - val_loss: 40.3494 - val_MinusLogProbMetric: 40.3494 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 159/1000
2023-09-13 08:49:46.910 
Epoch 159/1000 
	 loss: 39.7197, MinusLogProbMetric: 39.7197, val_loss: 40.3833, val_MinusLogProbMetric: 40.3833

Epoch 159: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7197 - MinusLogProbMetric: 39.7197 - val_loss: 40.3833 - val_MinusLogProbMetric: 40.3833 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 160/1000
2023-09-13 08:49:58.323 
Epoch 160/1000 
	 loss: 39.7194, MinusLogProbMetric: 39.7194, val_loss: 40.3080, val_MinusLogProbMetric: 40.3080

Epoch 160: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7194 - MinusLogProbMetric: 39.7194 - val_loss: 40.3080 - val_MinusLogProbMetric: 40.3080 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 161/1000
2023-09-13 08:50:09.531 
Epoch 161/1000 
	 loss: 39.7238, MinusLogProbMetric: 39.7238, val_loss: 40.3316, val_MinusLogProbMetric: 40.3316

Epoch 161: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7238 - MinusLogProbMetric: 39.7238 - val_loss: 40.3316 - val_MinusLogProbMetric: 40.3316 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 162/1000
2023-09-13 08:50:20.749 
Epoch 162/1000 
	 loss: 39.7222, MinusLogProbMetric: 39.7222, val_loss: 40.3377, val_MinusLogProbMetric: 40.3377

Epoch 162: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7222 - MinusLogProbMetric: 39.7222 - val_loss: 40.3377 - val_MinusLogProbMetric: 40.3377 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 163/1000
2023-09-13 08:50:31.951 
Epoch 163/1000 
	 loss: 39.7202, MinusLogProbMetric: 39.7202, val_loss: 40.3836, val_MinusLogProbMetric: 40.3836

Epoch 163: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7202 - MinusLogProbMetric: 39.7202 - val_loss: 40.3836 - val_MinusLogProbMetric: 40.3836 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 164/1000
2023-09-13 08:50:43.075 
Epoch 164/1000 
	 loss: 39.7215, MinusLogProbMetric: 39.7215, val_loss: 40.3291, val_MinusLogProbMetric: 40.3291

Epoch 164: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7215 - MinusLogProbMetric: 39.7215 - val_loss: 40.3291 - val_MinusLogProbMetric: 40.3291 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 165/1000
2023-09-13 08:50:54.520 
Epoch 165/1000 
	 loss: 39.7200, MinusLogProbMetric: 39.7200, val_loss: 40.3955, val_MinusLogProbMetric: 40.3955

Epoch 165: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7200 - MinusLogProbMetric: 39.7200 - val_loss: 40.3955 - val_MinusLogProbMetric: 40.3955 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 166/1000
2023-09-13 08:51:05.719 
Epoch 166/1000 
	 loss: 39.7245, MinusLogProbMetric: 39.7245, val_loss: 40.4060, val_MinusLogProbMetric: 40.4060

Epoch 166: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7245 - MinusLogProbMetric: 39.7245 - val_loss: 40.4060 - val_MinusLogProbMetric: 40.4060 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 167/1000
2023-09-13 08:51:16.536 
Epoch 167/1000 
	 loss: 39.7177, MinusLogProbMetric: 39.7177, val_loss: 40.3375, val_MinusLogProbMetric: 40.3375

Epoch 167: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7177 - MinusLogProbMetric: 39.7177 - val_loss: 40.3375 - val_MinusLogProbMetric: 40.3375 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 168/1000
2023-09-13 08:51:27.673 
Epoch 168/1000 
	 loss: 39.7109, MinusLogProbMetric: 39.7109, val_loss: 40.3503, val_MinusLogProbMetric: 40.3503

Epoch 168: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7109 - MinusLogProbMetric: 39.7109 - val_loss: 40.3503 - val_MinusLogProbMetric: 40.3503 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 169/1000
2023-09-13 08:51:38.793 
Epoch 169/1000 
	 loss: 39.7118, MinusLogProbMetric: 39.7118, val_loss: 40.3239, val_MinusLogProbMetric: 40.3239

Epoch 169: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7118 - MinusLogProbMetric: 39.7118 - val_loss: 40.3239 - val_MinusLogProbMetric: 40.3239 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 170/1000
2023-09-13 08:51:50.167 
Epoch 170/1000 
	 loss: 39.7178, MinusLogProbMetric: 39.7178, val_loss: 40.3185, val_MinusLogProbMetric: 40.3185

Epoch 170: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7178 - MinusLogProbMetric: 39.7178 - val_loss: 40.3185 - val_MinusLogProbMetric: 40.3185 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 171/1000
2023-09-13 08:52:01.305 
Epoch 171/1000 
	 loss: 39.7108, MinusLogProbMetric: 39.7108, val_loss: 40.3425, val_MinusLogProbMetric: 40.3425

Epoch 171: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7108 - MinusLogProbMetric: 39.7108 - val_loss: 40.3425 - val_MinusLogProbMetric: 40.3425 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 172/1000
2023-09-13 08:52:12.284 
Epoch 172/1000 
	 loss: 39.7009, MinusLogProbMetric: 39.7009, val_loss: 40.3415, val_MinusLogProbMetric: 40.3415

Epoch 172: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7009 - MinusLogProbMetric: 39.7009 - val_loss: 40.3415 - val_MinusLogProbMetric: 40.3415 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 173/1000
2023-09-13 08:52:23.372 
Epoch 173/1000 
	 loss: 39.7132, MinusLogProbMetric: 39.7132, val_loss: 40.3701, val_MinusLogProbMetric: 40.3701

Epoch 173: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7132 - MinusLogProbMetric: 39.7132 - val_loss: 40.3701 - val_MinusLogProbMetric: 40.3701 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 174/1000
2023-09-13 08:52:34.113 
Epoch 174/1000 
	 loss: 39.7104, MinusLogProbMetric: 39.7104, val_loss: 40.3561, val_MinusLogProbMetric: 40.3561

Epoch 174: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7104 - MinusLogProbMetric: 39.7104 - val_loss: 40.3561 - val_MinusLogProbMetric: 40.3561 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 175/1000
2023-09-13 08:52:45.209 
Epoch 175/1000 
	 loss: 39.7091, MinusLogProbMetric: 39.7091, val_loss: 40.3573, val_MinusLogProbMetric: 40.3573

Epoch 175: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7091 - MinusLogProbMetric: 39.7091 - val_loss: 40.3573 - val_MinusLogProbMetric: 40.3573 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 176/1000
2023-09-13 08:52:56.227 
Epoch 176/1000 
	 loss: 39.6984, MinusLogProbMetric: 39.6984, val_loss: 40.3532, val_MinusLogProbMetric: 40.3532

Epoch 176: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6984 - MinusLogProbMetric: 39.6984 - val_loss: 40.3532 - val_MinusLogProbMetric: 40.3532 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 177/1000
2023-09-13 08:53:07.512 
Epoch 177/1000 
	 loss: 39.7018, MinusLogProbMetric: 39.7018, val_loss: 40.4153, val_MinusLogProbMetric: 40.4153

Epoch 177: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7018 - MinusLogProbMetric: 39.7018 - val_loss: 40.4153 - val_MinusLogProbMetric: 40.4153 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 178/1000
2023-09-13 08:53:18.641 
Epoch 178/1000 
	 loss: 39.6896, MinusLogProbMetric: 39.6896, val_loss: 40.3976, val_MinusLogProbMetric: 40.3976

Epoch 178: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6896 - MinusLogProbMetric: 39.6896 - val_loss: 40.3976 - val_MinusLogProbMetric: 40.3976 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 179/1000
2023-09-13 08:53:29.999 
Epoch 179/1000 
	 loss: 39.7043, MinusLogProbMetric: 39.7043, val_loss: 40.3844, val_MinusLogProbMetric: 40.3844

Epoch 179: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7043 - MinusLogProbMetric: 39.7043 - val_loss: 40.3844 - val_MinusLogProbMetric: 40.3844 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 180/1000
2023-09-13 08:53:41.304 
Epoch 180/1000 
	 loss: 39.7032, MinusLogProbMetric: 39.7032, val_loss: 40.3328, val_MinusLogProbMetric: 40.3328

Epoch 180: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7032 - MinusLogProbMetric: 39.7032 - val_loss: 40.3328 - val_MinusLogProbMetric: 40.3328 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 181/1000
2023-09-13 08:53:52.324 
Epoch 181/1000 
	 loss: 39.6980, MinusLogProbMetric: 39.6980, val_loss: 40.3833, val_MinusLogProbMetric: 40.3833

Epoch 181: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6980 - MinusLogProbMetric: 39.6980 - val_loss: 40.3833 - val_MinusLogProbMetric: 40.3833 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 182/1000
2023-09-13 08:54:03.386 
Epoch 182/1000 
	 loss: 39.7045, MinusLogProbMetric: 39.7045, val_loss: 40.3403, val_MinusLogProbMetric: 40.3403

Epoch 182: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7045 - MinusLogProbMetric: 39.7045 - val_loss: 40.3403 - val_MinusLogProbMetric: 40.3403 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 183/1000
2023-09-13 08:54:14.421 
Epoch 183/1000 
	 loss: 39.6896, MinusLogProbMetric: 39.6896, val_loss: 40.3462, val_MinusLogProbMetric: 40.3462

Epoch 183: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6896 - MinusLogProbMetric: 39.6896 - val_loss: 40.3462 - val_MinusLogProbMetric: 40.3462 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 184/1000
2023-09-13 08:54:25.404 
Epoch 184/1000 
	 loss: 39.6928, MinusLogProbMetric: 39.6928, val_loss: 40.3617, val_MinusLogProbMetric: 40.3617

Epoch 184: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6928 - MinusLogProbMetric: 39.6928 - val_loss: 40.3617 - val_MinusLogProbMetric: 40.3617 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 185/1000
2023-09-13 08:54:36.465 
Epoch 185/1000 
	 loss: 39.6962, MinusLogProbMetric: 39.6962, val_loss: 40.3420, val_MinusLogProbMetric: 40.3420

Epoch 185: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6962 - MinusLogProbMetric: 39.6962 - val_loss: 40.3420 - val_MinusLogProbMetric: 40.3420 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 186/1000
2023-09-13 08:54:47.390 
Epoch 186/1000 
	 loss: 39.6922, MinusLogProbMetric: 39.6922, val_loss: 40.4052, val_MinusLogProbMetric: 40.4052

Epoch 186: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6922 - MinusLogProbMetric: 39.6922 - val_loss: 40.4052 - val_MinusLogProbMetric: 40.4052 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 187/1000
2023-09-13 08:54:58.449 
Epoch 187/1000 
	 loss: 39.6895, MinusLogProbMetric: 39.6895, val_loss: 40.3795, val_MinusLogProbMetric: 40.3795

Epoch 187: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6895 - MinusLogProbMetric: 39.6895 - val_loss: 40.3795 - val_MinusLogProbMetric: 40.3795 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 188/1000
2023-09-13 08:55:09.492 
Epoch 188/1000 
	 loss: 39.6956, MinusLogProbMetric: 39.6956, val_loss: 40.3460, val_MinusLogProbMetric: 40.3460

Epoch 188: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6956 - MinusLogProbMetric: 39.6956 - val_loss: 40.3460 - val_MinusLogProbMetric: 40.3460 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 189/1000
2023-09-13 08:55:20.002 
Epoch 189/1000 
	 loss: 39.6910, MinusLogProbMetric: 39.6910, val_loss: 40.3927, val_MinusLogProbMetric: 40.3927

Epoch 189: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6910 - MinusLogProbMetric: 39.6910 - val_loss: 40.3927 - val_MinusLogProbMetric: 40.3927 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 190/1000
2023-09-13 08:55:30.879 
Epoch 190/1000 
	 loss: 39.7000, MinusLogProbMetric: 39.7000, val_loss: 40.3872, val_MinusLogProbMetric: 40.3872

Epoch 190: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.7000 - MinusLogProbMetric: 39.7000 - val_loss: 40.3872 - val_MinusLogProbMetric: 40.3872 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 191/1000
2023-09-13 08:55:41.967 
Epoch 191/1000 
	 loss: 39.6876, MinusLogProbMetric: 39.6876, val_loss: 40.3487, val_MinusLogProbMetric: 40.3487

Epoch 191: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6876 - MinusLogProbMetric: 39.6876 - val_loss: 40.3487 - val_MinusLogProbMetric: 40.3487 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 192/1000
2023-09-13 08:55:53.018 
Epoch 192/1000 
	 loss: 39.6838, MinusLogProbMetric: 39.6838, val_loss: 40.3409, val_MinusLogProbMetric: 40.3409

Epoch 192: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6838 - MinusLogProbMetric: 39.6838 - val_loss: 40.3409 - val_MinusLogProbMetric: 40.3409 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 193/1000
2023-09-13 08:56:04.287 
Epoch 193/1000 
	 loss: 39.6797, MinusLogProbMetric: 39.6797, val_loss: 40.4009, val_MinusLogProbMetric: 40.4009

Epoch 193: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6797 - MinusLogProbMetric: 39.6797 - val_loss: 40.4009 - val_MinusLogProbMetric: 40.4009 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 194/1000
2023-09-13 08:56:15.127 
Epoch 194/1000 
	 loss: 39.6817, MinusLogProbMetric: 39.6817, val_loss: 40.3989, val_MinusLogProbMetric: 40.3989

Epoch 194: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6817 - MinusLogProbMetric: 39.6817 - val_loss: 40.3989 - val_MinusLogProbMetric: 40.3989 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 195/1000
2023-09-13 08:56:26.093 
Epoch 195/1000 
	 loss: 39.6755, MinusLogProbMetric: 39.6755, val_loss: 40.4173, val_MinusLogProbMetric: 40.4173

Epoch 195: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6755 - MinusLogProbMetric: 39.6755 - val_loss: 40.4173 - val_MinusLogProbMetric: 40.4173 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 196/1000
2023-09-13 08:56:37.467 
Epoch 196/1000 
	 loss: 39.6839, MinusLogProbMetric: 39.6839, val_loss: 40.3763, val_MinusLogProbMetric: 40.3763

Epoch 196: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6839 - MinusLogProbMetric: 39.6839 - val_loss: 40.3763 - val_MinusLogProbMetric: 40.3763 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 197/1000
2023-09-13 08:56:48.593 
Epoch 197/1000 
	 loss: 39.6731, MinusLogProbMetric: 39.6731, val_loss: 40.3590, val_MinusLogProbMetric: 40.3590

Epoch 197: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6731 - MinusLogProbMetric: 39.6731 - val_loss: 40.3590 - val_MinusLogProbMetric: 40.3590 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 198/1000
2023-09-13 08:56:59.862 
Epoch 198/1000 
	 loss: 39.6712, MinusLogProbMetric: 39.6712, val_loss: 40.3685, val_MinusLogProbMetric: 40.3685

Epoch 198: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6712 - MinusLogProbMetric: 39.6712 - val_loss: 40.3685 - val_MinusLogProbMetric: 40.3685 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 199/1000
2023-09-13 08:57:11.278 
Epoch 199/1000 
	 loss: 39.6722, MinusLogProbMetric: 39.6722, val_loss: 40.3917, val_MinusLogProbMetric: 40.3917

Epoch 199: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.6722 - MinusLogProbMetric: 39.6722 - val_loss: 40.3917 - val_MinusLogProbMetric: 40.3917 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 200/1000
2023-09-13 08:57:22.192 
Epoch 200/1000 
	 loss: 39.5895, MinusLogProbMetric: 39.5895, val_loss: 40.3215, val_MinusLogProbMetric: 40.3215

Epoch 200: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5895 - MinusLogProbMetric: 39.5895 - val_loss: 40.3215 - val_MinusLogProbMetric: 40.3215 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 201/1000
2023-09-13 08:57:33.057 
Epoch 201/1000 
	 loss: 39.5787, MinusLogProbMetric: 39.5787, val_loss: 40.3121, val_MinusLogProbMetric: 40.3121

Epoch 201: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5787 - MinusLogProbMetric: 39.5787 - val_loss: 40.3121 - val_MinusLogProbMetric: 40.3121 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 202/1000
2023-09-13 08:57:43.982 
Epoch 202/1000 
	 loss: 39.5777, MinusLogProbMetric: 39.5777, val_loss: 40.3178, val_MinusLogProbMetric: 40.3178

Epoch 202: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5777 - MinusLogProbMetric: 39.5777 - val_loss: 40.3178 - val_MinusLogProbMetric: 40.3178 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 203/1000
2023-09-13 08:57:55.036 
Epoch 203/1000 
	 loss: 39.5762, MinusLogProbMetric: 39.5762, val_loss: 40.3210, val_MinusLogProbMetric: 40.3210

Epoch 203: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5762 - MinusLogProbMetric: 39.5762 - val_loss: 40.3210 - val_MinusLogProbMetric: 40.3210 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 204/1000
2023-09-13 08:58:06.043 
Epoch 204/1000 
	 loss: 39.5785, MinusLogProbMetric: 39.5785, val_loss: 40.3384, val_MinusLogProbMetric: 40.3384

Epoch 204: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5785 - MinusLogProbMetric: 39.5785 - val_loss: 40.3384 - val_MinusLogProbMetric: 40.3384 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 205/1000
2023-09-13 08:58:16.809 
Epoch 205/1000 
	 loss: 39.5772, MinusLogProbMetric: 39.5772, val_loss: 40.3298, val_MinusLogProbMetric: 40.3298

Epoch 205: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5772 - MinusLogProbMetric: 39.5772 - val_loss: 40.3298 - val_MinusLogProbMetric: 40.3298 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 206/1000
2023-09-13 08:58:27.201 
Epoch 206/1000 
	 loss: 39.5768, MinusLogProbMetric: 39.5768, val_loss: 40.3355, val_MinusLogProbMetric: 40.3355

Epoch 206: val_loss did not improve from 40.27237
196/196 - 10s - loss: 39.5768 - MinusLogProbMetric: 39.5768 - val_loss: 40.3355 - val_MinusLogProbMetric: 40.3355 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 207/1000
2023-09-13 08:58:38.356 
Epoch 207/1000 
	 loss: 39.5804, MinusLogProbMetric: 39.5804, val_loss: 40.3183, val_MinusLogProbMetric: 40.3183

Epoch 207: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5804 - MinusLogProbMetric: 39.5804 - val_loss: 40.3183 - val_MinusLogProbMetric: 40.3183 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 208/1000
2023-09-13 08:58:49.419 
Epoch 208/1000 
	 loss: 39.5729, MinusLogProbMetric: 39.5729, val_loss: 40.3250, val_MinusLogProbMetric: 40.3250

Epoch 208: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5729 - MinusLogProbMetric: 39.5729 - val_loss: 40.3250 - val_MinusLogProbMetric: 40.3250 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 209/1000
2023-09-13 08:59:00.159 
Epoch 209/1000 
	 loss: 39.5758, MinusLogProbMetric: 39.5758, val_loss: 40.3424, val_MinusLogProbMetric: 40.3424

Epoch 209: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5758 - MinusLogProbMetric: 39.5758 - val_loss: 40.3424 - val_MinusLogProbMetric: 40.3424 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 210/1000
2023-09-13 08:59:10.352 
Epoch 210/1000 
	 loss: 39.5759, MinusLogProbMetric: 39.5759, val_loss: 40.3522, val_MinusLogProbMetric: 40.3522

Epoch 210: val_loss did not improve from 40.27237
196/196 - 10s - loss: 39.5759 - MinusLogProbMetric: 39.5759 - val_loss: 40.3522 - val_MinusLogProbMetric: 40.3522 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 211/1000
2023-09-13 08:59:21.550 
Epoch 211/1000 
	 loss: 39.5770, MinusLogProbMetric: 39.5770, val_loss: 40.3436, val_MinusLogProbMetric: 40.3436

Epoch 211: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5770 - MinusLogProbMetric: 39.5770 - val_loss: 40.3436 - val_MinusLogProbMetric: 40.3436 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 212/1000
2023-09-13 08:59:32.513 
Epoch 212/1000 
	 loss: 39.5711, MinusLogProbMetric: 39.5711, val_loss: 40.3565, val_MinusLogProbMetric: 40.3565

Epoch 212: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5711 - MinusLogProbMetric: 39.5711 - val_loss: 40.3565 - val_MinusLogProbMetric: 40.3565 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 213/1000
2023-09-13 08:59:43.771 
Epoch 213/1000 
	 loss: 39.5731, MinusLogProbMetric: 39.5731, val_loss: 40.3232, val_MinusLogProbMetric: 40.3232

Epoch 213: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5731 - MinusLogProbMetric: 39.5731 - val_loss: 40.3232 - val_MinusLogProbMetric: 40.3232 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 214/1000
2023-09-13 08:59:54.702 
Epoch 214/1000 
	 loss: 39.5704, MinusLogProbMetric: 39.5704, val_loss: 40.3512, val_MinusLogProbMetric: 40.3512

Epoch 214: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5704 - MinusLogProbMetric: 39.5704 - val_loss: 40.3512 - val_MinusLogProbMetric: 40.3512 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 215/1000
2023-09-13 09:00:05.630 
Epoch 215/1000 
	 loss: 39.5680, MinusLogProbMetric: 39.5680, val_loss: 40.3409, val_MinusLogProbMetric: 40.3409

Epoch 215: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5680 - MinusLogProbMetric: 39.5680 - val_loss: 40.3409 - val_MinusLogProbMetric: 40.3409 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 216/1000
2023-09-13 09:00:16.775 
Epoch 216/1000 
	 loss: 39.5677, MinusLogProbMetric: 39.5677, val_loss: 40.3659, val_MinusLogProbMetric: 40.3659

Epoch 216: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5677 - MinusLogProbMetric: 39.5677 - val_loss: 40.3659 - val_MinusLogProbMetric: 40.3659 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 217/1000
2023-09-13 09:00:27.654 
Epoch 217/1000 
	 loss: 39.5674, MinusLogProbMetric: 39.5674, val_loss: 40.3634, val_MinusLogProbMetric: 40.3634

Epoch 217: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5674 - MinusLogProbMetric: 39.5674 - val_loss: 40.3634 - val_MinusLogProbMetric: 40.3634 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 218/1000
2023-09-13 09:00:38.591 
Epoch 218/1000 
	 loss: 39.5712, MinusLogProbMetric: 39.5712, val_loss: 40.3452, val_MinusLogProbMetric: 40.3452

Epoch 218: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5712 - MinusLogProbMetric: 39.5712 - val_loss: 40.3452 - val_MinusLogProbMetric: 40.3452 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 219/1000
2023-09-13 09:00:48.914 
Epoch 219/1000 
	 loss: 39.5707, MinusLogProbMetric: 39.5707, val_loss: 40.3545, val_MinusLogProbMetric: 40.3545

Epoch 219: val_loss did not improve from 40.27237
196/196 - 10s - loss: 39.5707 - MinusLogProbMetric: 39.5707 - val_loss: 40.3545 - val_MinusLogProbMetric: 40.3545 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 220/1000
2023-09-13 09:00:59.928 
Epoch 220/1000 
	 loss: 39.5723, MinusLogProbMetric: 39.5723, val_loss: 40.3628, val_MinusLogProbMetric: 40.3628

Epoch 220: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5723 - MinusLogProbMetric: 39.5723 - val_loss: 40.3628 - val_MinusLogProbMetric: 40.3628 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 221/1000
2023-09-13 09:01:10.936 
Epoch 221/1000 
	 loss: 39.5666, MinusLogProbMetric: 39.5666, val_loss: 40.3421, val_MinusLogProbMetric: 40.3421

Epoch 221: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5666 - MinusLogProbMetric: 39.5666 - val_loss: 40.3421 - val_MinusLogProbMetric: 40.3421 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 222/1000
2023-09-13 09:01:21.890 
Epoch 222/1000 
	 loss: 39.5673, MinusLogProbMetric: 39.5673, val_loss: 40.3502, val_MinusLogProbMetric: 40.3502

Epoch 222: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5673 - MinusLogProbMetric: 39.5673 - val_loss: 40.3502 - val_MinusLogProbMetric: 40.3502 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 223/1000
2023-09-13 09:01:32.886 
Epoch 223/1000 
	 loss: 39.5631, MinusLogProbMetric: 39.5631, val_loss: 40.3574, val_MinusLogProbMetric: 40.3574

Epoch 223: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5631 - MinusLogProbMetric: 39.5631 - val_loss: 40.3574 - val_MinusLogProbMetric: 40.3574 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 224/1000
2023-09-13 09:01:44.267 
Epoch 224/1000 
	 loss: 39.5613, MinusLogProbMetric: 39.5613, val_loss: 40.3468, val_MinusLogProbMetric: 40.3468

Epoch 224: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5613 - MinusLogProbMetric: 39.5613 - val_loss: 40.3468 - val_MinusLogProbMetric: 40.3468 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 225/1000
2023-09-13 09:01:55.266 
Epoch 225/1000 
	 loss: 39.5638, MinusLogProbMetric: 39.5638, val_loss: 40.3725, val_MinusLogProbMetric: 40.3725

Epoch 225: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5638 - MinusLogProbMetric: 39.5638 - val_loss: 40.3725 - val_MinusLogProbMetric: 40.3725 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 226/1000
2023-09-13 09:02:05.918 
Epoch 226/1000 
	 loss: 39.5642, MinusLogProbMetric: 39.5642, val_loss: 40.3460, val_MinusLogProbMetric: 40.3460

Epoch 226: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5642 - MinusLogProbMetric: 39.5642 - val_loss: 40.3460 - val_MinusLogProbMetric: 40.3460 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 227/1000
2023-09-13 09:02:17.071 
Epoch 227/1000 
	 loss: 39.5561, MinusLogProbMetric: 39.5561, val_loss: 40.3741, val_MinusLogProbMetric: 40.3741

Epoch 227: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5561 - MinusLogProbMetric: 39.5561 - val_loss: 40.3741 - val_MinusLogProbMetric: 40.3741 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 228/1000
2023-09-13 09:02:27.860 
Epoch 228/1000 
	 loss: 39.5615, MinusLogProbMetric: 39.5615, val_loss: 40.3672, val_MinusLogProbMetric: 40.3672

Epoch 228: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5615 - MinusLogProbMetric: 39.5615 - val_loss: 40.3672 - val_MinusLogProbMetric: 40.3672 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 229/1000
2023-09-13 09:02:39.130 
Epoch 229/1000 
	 loss: 39.5623, MinusLogProbMetric: 39.5623, val_loss: 40.3520, val_MinusLogProbMetric: 40.3520

Epoch 229: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5623 - MinusLogProbMetric: 39.5623 - val_loss: 40.3520 - val_MinusLogProbMetric: 40.3520 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 230/1000
2023-09-13 09:02:49.885 
Epoch 230/1000 
	 loss: 39.5620, MinusLogProbMetric: 39.5620, val_loss: 40.4505, val_MinusLogProbMetric: 40.4505

Epoch 230: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5620 - MinusLogProbMetric: 39.5620 - val_loss: 40.4505 - val_MinusLogProbMetric: 40.4505 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 231/1000
2023-09-13 09:03:01.184 
Epoch 231/1000 
	 loss: 39.5584, MinusLogProbMetric: 39.5584, val_loss: 40.3535, val_MinusLogProbMetric: 40.3535

Epoch 231: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5584 - MinusLogProbMetric: 39.5584 - val_loss: 40.3535 - val_MinusLogProbMetric: 40.3535 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 232/1000
2023-09-13 09:03:12.589 
Epoch 232/1000 
	 loss: 39.5601, MinusLogProbMetric: 39.5601, val_loss: 40.3684, val_MinusLogProbMetric: 40.3684

Epoch 232: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5601 - MinusLogProbMetric: 39.5601 - val_loss: 40.3684 - val_MinusLogProbMetric: 40.3684 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 233/1000
2023-09-13 09:03:24.534 
Epoch 233/1000 
	 loss: 39.5529, MinusLogProbMetric: 39.5529, val_loss: 40.3588, val_MinusLogProbMetric: 40.3588

Epoch 233: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5529 - MinusLogProbMetric: 39.5529 - val_loss: 40.3588 - val_MinusLogProbMetric: 40.3588 - lr: 2.5000e-04 - 12s/epoch - 61ms/step
Epoch 234/1000
2023-09-13 09:03:36.653 
Epoch 234/1000 
	 loss: 39.5527, MinusLogProbMetric: 39.5527, val_loss: 40.3692, val_MinusLogProbMetric: 40.3692

Epoch 234: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5527 - MinusLogProbMetric: 39.5527 - val_loss: 40.3692 - val_MinusLogProbMetric: 40.3692 - lr: 2.5000e-04 - 12s/epoch - 62ms/step
Epoch 235/1000
2023-09-13 09:03:48.460 
Epoch 235/1000 
	 loss: 39.5570, MinusLogProbMetric: 39.5570, val_loss: 40.3804, val_MinusLogProbMetric: 40.3804

Epoch 235: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5570 - MinusLogProbMetric: 39.5570 - val_loss: 40.3804 - val_MinusLogProbMetric: 40.3804 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 236/1000
2023-09-13 09:04:00.615 
Epoch 236/1000 
	 loss: 39.5583, MinusLogProbMetric: 39.5583, val_loss: 40.4016, val_MinusLogProbMetric: 40.4016

Epoch 236: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5583 - MinusLogProbMetric: 39.5583 - val_loss: 40.4016 - val_MinusLogProbMetric: 40.4016 - lr: 2.5000e-04 - 12s/epoch - 62ms/step
Epoch 237/1000
2023-09-13 09:04:12.455 
Epoch 237/1000 
	 loss: 39.5541, MinusLogProbMetric: 39.5541, val_loss: 40.3736, val_MinusLogProbMetric: 40.3736

Epoch 237: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5541 - MinusLogProbMetric: 39.5541 - val_loss: 40.3736 - val_MinusLogProbMetric: 40.3736 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 238/1000
2023-09-13 09:04:24.133 
Epoch 238/1000 
	 loss: 39.5532, MinusLogProbMetric: 39.5532, val_loss: 40.3972, val_MinusLogProbMetric: 40.3972

Epoch 238: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5532 - MinusLogProbMetric: 39.5532 - val_loss: 40.3972 - val_MinusLogProbMetric: 40.3972 - lr: 2.5000e-04 - 12s/epoch - 60ms/step
Epoch 239/1000
2023-09-13 09:04:35.725 
Epoch 239/1000 
	 loss: 39.5543, MinusLogProbMetric: 39.5543, val_loss: 40.3702, val_MinusLogProbMetric: 40.3702

Epoch 239: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5543 - MinusLogProbMetric: 39.5543 - val_loss: 40.3702 - val_MinusLogProbMetric: 40.3702 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 240/1000
2023-09-13 09:04:46.851 
Epoch 240/1000 
	 loss: 39.5512, MinusLogProbMetric: 39.5512, val_loss: 40.3823, val_MinusLogProbMetric: 40.3823

Epoch 240: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5512 - MinusLogProbMetric: 39.5512 - val_loss: 40.3823 - val_MinusLogProbMetric: 40.3823 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 241/1000
2023-09-13 09:04:58.039 
Epoch 241/1000 
	 loss: 39.5511, MinusLogProbMetric: 39.5511, val_loss: 40.3862, val_MinusLogProbMetric: 40.3862

Epoch 241: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5511 - MinusLogProbMetric: 39.5511 - val_loss: 40.3862 - val_MinusLogProbMetric: 40.3862 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 242/1000
2023-09-13 09:05:09.682 
Epoch 242/1000 
	 loss: 39.5499, MinusLogProbMetric: 39.5499, val_loss: 40.3823, val_MinusLogProbMetric: 40.3823

Epoch 242: val_loss did not improve from 40.27237
196/196 - 12s - loss: 39.5499 - MinusLogProbMetric: 39.5499 - val_loss: 40.3823 - val_MinusLogProbMetric: 40.3823 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 243/1000
2023-09-13 09:05:21.063 
Epoch 243/1000 
	 loss: 39.5595, MinusLogProbMetric: 39.5595, val_loss: 40.3621, val_MinusLogProbMetric: 40.3621

Epoch 243: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5595 - MinusLogProbMetric: 39.5595 - val_loss: 40.3621 - val_MinusLogProbMetric: 40.3621 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 244/1000
2023-09-13 09:05:31.628 
Epoch 244/1000 
	 loss: 39.5464, MinusLogProbMetric: 39.5464, val_loss: 40.3812, val_MinusLogProbMetric: 40.3812

Epoch 244: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5464 - MinusLogProbMetric: 39.5464 - val_loss: 40.3812 - val_MinusLogProbMetric: 40.3812 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 245/1000
2023-09-13 09:05:41.963 
Epoch 245/1000 
	 loss: 39.5477, MinusLogProbMetric: 39.5477, val_loss: 40.3891, val_MinusLogProbMetric: 40.3891

Epoch 245: val_loss did not improve from 40.27237
196/196 - 10s - loss: 39.5477 - MinusLogProbMetric: 39.5477 - val_loss: 40.3891 - val_MinusLogProbMetric: 40.3891 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 246/1000
2023-09-13 09:05:53.334 
Epoch 246/1000 
	 loss: 39.5510, MinusLogProbMetric: 39.5510, val_loss: 40.3727, val_MinusLogProbMetric: 40.3727

Epoch 246: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5510 - MinusLogProbMetric: 39.5510 - val_loss: 40.3727 - val_MinusLogProbMetric: 40.3727 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 247/1000
2023-09-13 09:06:03.793 
Epoch 247/1000 
	 loss: 39.5461, MinusLogProbMetric: 39.5461, val_loss: 40.3919, val_MinusLogProbMetric: 40.3919

Epoch 247: val_loss did not improve from 40.27237
196/196 - 10s - loss: 39.5461 - MinusLogProbMetric: 39.5461 - val_loss: 40.3919 - val_MinusLogProbMetric: 40.3919 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 248/1000
2023-09-13 09:06:14.685 
Epoch 248/1000 
	 loss: 39.5482, MinusLogProbMetric: 39.5482, val_loss: 40.3782, val_MinusLogProbMetric: 40.3782

Epoch 248: val_loss did not improve from 40.27237
196/196 - 11s - loss: 39.5482 - MinusLogProbMetric: 39.5482 - val_loss: 40.3782 - val_MinusLogProbMetric: 40.3782 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 249/1000
2023-09-13 09:06:25.001 
Epoch 249/1000 
	 loss: 39.5455, MinusLogProbMetric: 39.5455, val_loss: 40.3785, val_MinusLogProbMetric: 40.3785

Epoch 249: val_loss did not improve from 40.27237
Restoring model weights from the end of the best epoch: 149.
196/196 - 10s - loss: 39.5455 - MinusLogProbMetric: 39.5455 - val_loss: 40.3785 - val_MinusLogProbMetric: 40.3785 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 249: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 11.018064590985887 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.8355135780293494 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.0051684950012714 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2.3013152370695025 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 0.
Model trained in 2636.60 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 976 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 976 and retrying.
Metrics computed in 9631.95 s.
Plots done in 88.31 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 9720.26 s.
===========
Run 202/360 done in 12357.97 s.
===========

Directory ../../results/MsplineN_new/run_203/ already exists.
Skipping it.
===========
Run 203/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_204/ already exists.
Skipping it.
===========
Run 204/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_205/ already exists.
Skipping it.
===========
Run 205/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_206/ already exists.
Skipping it.
===========
Run 206/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_207/ already exists.
Skipping it.
===========
Run 207/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_208/ already exists.
Skipping it.
===========
Run 208/360 already exists. Skipping it.
===========

Directory ../../results/MsplineN_new/run_209/ already exists.
Skipping it.
===========
Run 209/360 already exists. Skipping it.
===========

===========
Generating train data for run 210.
===========
Train data generated in 0.22 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 100)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_210/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_210/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.2146864 ,  6.631287  ,  3.8488867 , ...,  8.701448  ,
         9.995869  ,  8.467634  ],
       [ 2.8034534 ,  6.2523446 ,  6.587882  , ...,  0.2610864 ,
         8.289457  ,  0.40014002],
       [ 3.1083388 ,  6.904127  ,  3.8563085 , ...,  9.2451105 ,
         9.438324  ,  9.252335  ],
       ...,
       [ 3.2707572 ,  7.137167  ,  4.15955   , ...,  8.417309  ,
         9.719597  ,  9.971758  ],
       [ 2.9350822 ,  7.2153897 ,  4.6962466 , ...,  8.324518  ,
         9.470934  , 10.1611395 ],
       [ 2.8749945 ,  7.372215  ,  3.7357469 , ...,  8.341062  ,
         9.43408   ,  9.775034  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_210/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_210
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.377221    7.127741    6.2438807  ...  0.41386062  8.333076
  -0.20018621]
 [ 6.990193    3.6036158   7.2023716  ...  2.5000641   0.24059269
   4.0499587 ]
 [ 4.625933    7.1490397   5.677378   ... -0.07451734  8.288161
   0.11478856]
 ...
 [ 3.0931716   6.40883     3.5263834  ...  9.596216   10.054146
   9.589475  ]
 [ 3.3032775   7.705798    4.4765306  ...  9.215089    9.65445
   9.671152  ]
 [ 5.3625393   6.8024626   6.3470583  ...  0.19077146  8.306975
   0.49249855]]
self.y_data: []
self.ndims: 100
Model defined.
Model: "model_28"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_85 (InputLayer)       [(None, 100)]             0         
                                                                 
 log_prob_layer_28 (LogProbL  (None,)                  1497080   
 ayer)                                                           
                                                                 
=================================================================
Total params: 1,497,080
Trainable params: 1,497,080
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_28/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_28'")
self.model: <keras.engine.functional.Functional object at 0x7fbc3bd82590>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc5382eba90>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc5382eba90>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc5382eac20>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc5382e8190>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc6ec316bc0>, <keras.callbacks.ModelCheckpoint object at 0x7fcd56722da0>, <keras.callbacks.EarlyStopping object at 0x7fcd56a47f40>, <keras.callbacks.ReduceLROnPlateau object at 0x7fcd56723eb0>, <keras.callbacks.TerminateOnNaN object at 0x7fcd56a45570>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.2146864 ,  6.631287  ,  3.8488867 , ...,  8.701448  ,
         9.995869  ,  8.467634  ],
       [ 2.8034534 ,  6.2523446 ,  6.587882  , ...,  0.2610864 ,
         8.289457  ,  0.40014002],
       [ 3.1083388 ,  6.904127  ,  3.8563085 , ...,  9.2451105 ,
         9.438324  ,  9.252335  ],
       ...,
       [ 3.2707572 ,  7.137167  ,  4.15955   , ...,  8.417309  ,
         9.719597  ,  9.971758  ],
       [ 2.9350822 ,  7.2153897 ,  4.6962466 , ...,  8.324518  ,
         9.470934  , 10.1611395 ],
       [ 2.8749945 ,  7.372215  ,  3.7357469 , ...,  8.341062  ,
         9.43408   ,  9.775034  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_210/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 210/360 with hyperparameters:
timestamp = 2023-09-13 11:48:26.547795
ndims = 100
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 8
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 1497080
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.377221    7.127741    6.2438807   5.435673    4.0165205   6.219049
  4.1100683   8.8912945   8.92213     3.839687    7.2213755   5.307855
  5.647077    9.321208    0.88903034  1.1936541   0.02009015  8.125818
  8.583153    9.655658    9.708242    8.047664    4.635592    7.956708
  0.69603527  6.3117905   0.84046364  9.506726    5.873458    3.812477
  2.5029004   8.513819    4.5791717   5.4547668   0.38966614  5.245923
  6.1506085   6.674606    9.7018795   6.636814    3.3463945   4.644469
  7.275876    0.607445    7.351542    6.6946445   2.4746628   1.2882023
  3.4071944   5.330654    6.1714883   4.4290667   9.648411   -0.15112126
  2.9771137   0.42422986  6.6482043   2.43198     4.204295    4.4230494
  1.6423705   1.2461631   7.064476    1.7268543   3.0895011   4.317311
  8.377744    1.4959692   8.227504    0.34852362  9.020381    4.5677514
 10.634903    5.1945934   7.095311    0.5202157   2.788597    1.1506679
  2.1603026   0.45417947  3.3186061   4.6653333  -0.767903    7.405855
  6.0683556   0.04347444  4.8182964   1.1355917   6.122411    9.17348
  3.1331472   6.9240985   1.4263403   7.782923    2.9285986   1.2252684
  6.0443587   0.41386062  8.333076   -0.20018621]
Epoch 1/1000
2023-09-13 11:48:57.576 
Epoch 1/1000 
	 loss: 128.3045, MinusLogProbMetric: 128.3045, val_loss: 52.7805, val_MinusLogProbMetric: 52.7805

Epoch 1: val_loss improved from inf to 52.78048, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 31s - loss: 128.3045 - MinusLogProbMetric: 128.3045 - val_loss: 52.7805 - val_MinusLogProbMetric: 52.7805 - lr: 0.0010 - 31s/epoch - 159ms/step
Epoch 2/1000
2023-09-13 11:49:07.955 
Epoch 2/1000 
	 loss: 49.5696, MinusLogProbMetric: 49.5696, val_loss: 47.6665, val_MinusLogProbMetric: 47.6665

Epoch 2: val_loss improved from 52.78048 to 47.66645, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 10s - loss: 49.5696 - MinusLogProbMetric: 49.5696 - val_loss: 47.6665 - val_MinusLogProbMetric: 47.6665 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 3/1000
2023-09-13 11:49:17.860 
Epoch 3/1000 
	 loss: 46.3790, MinusLogProbMetric: 46.3790, val_loss: 45.4246, val_MinusLogProbMetric: 45.4246

Epoch 3: val_loss improved from 47.66645 to 45.42464, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 10s - loss: 46.3790 - MinusLogProbMetric: 46.3790 - val_loss: 45.4246 - val_MinusLogProbMetric: 45.4246 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 4/1000
2023-09-13 11:49:28.812 
Epoch 4/1000 
	 loss: 45.0708, MinusLogProbMetric: 45.0708, val_loss: 44.1166, val_MinusLogProbMetric: 44.1166

Epoch 4: val_loss improved from 45.42464 to 44.11660, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 11s - loss: 45.0708 - MinusLogProbMetric: 45.0708 - val_loss: 44.1166 - val_MinusLogProbMetric: 44.1166 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 5/1000
2023-09-13 11:49:38.628 
Epoch 5/1000 
	 loss: 44.7234, MinusLogProbMetric: 44.7234, val_loss: 45.1677, val_MinusLogProbMetric: 45.1677

Epoch 5: val_loss did not improve from 44.11660
196/196 - 10s - loss: 44.7234 - MinusLogProbMetric: 44.7234 - val_loss: 45.1677 - val_MinusLogProbMetric: 45.1677 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 6/1000
2023-09-13 11:49:47.831 
Epoch 6/1000 
	 loss: 43.7267, MinusLogProbMetric: 43.7267, val_loss: 43.9136, val_MinusLogProbMetric: 43.9136

Epoch 6: val_loss improved from 44.11660 to 43.91356, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 9s - loss: 43.7267 - MinusLogProbMetric: 43.7267 - val_loss: 43.9136 - val_MinusLogProbMetric: 43.9136 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 7/1000
2023-09-13 11:49:57.965 
Epoch 7/1000 
	 loss: 43.1183, MinusLogProbMetric: 43.1183, val_loss: 42.9142, val_MinusLogProbMetric: 42.9142

Epoch 7: val_loss improved from 43.91356 to 42.91417, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 10s - loss: 43.1183 - MinusLogProbMetric: 43.1183 - val_loss: 42.9142 - val_MinusLogProbMetric: 42.9142 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 8/1000
2023-09-13 11:50:09.533 
Epoch 8/1000 
	 loss: 42.9395, MinusLogProbMetric: 42.9395, val_loss: 42.3953, val_MinusLogProbMetric: 42.3953

Epoch 8: val_loss improved from 42.91417 to 42.39530, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 12s - loss: 42.9395 - MinusLogProbMetric: 42.9395 - val_loss: 42.3953 - val_MinusLogProbMetric: 42.3953 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 9/1000
2023-09-13 11:50:20.284 
Epoch 9/1000 
	 loss: 42.5884, MinusLogProbMetric: 42.5884, val_loss: 42.0585, val_MinusLogProbMetric: 42.0585

Epoch 9: val_loss improved from 42.39530 to 42.05851, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 11s - loss: 42.5884 - MinusLogProbMetric: 42.5884 - val_loss: 42.0585 - val_MinusLogProbMetric: 42.0585 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 10/1000
2023-09-13 11:50:31.428 
Epoch 10/1000 
	 loss: 42.2616, MinusLogProbMetric: 42.2616, val_loss: 42.8333, val_MinusLogProbMetric: 42.8333

Epoch 10: val_loss did not improve from 42.05851
196/196 - 11s - loss: 42.2616 - MinusLogProbMetric: 42.2616 - val_loss: 42.8333 - val_MinusLogProbMetric: 42.8333 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 11/1000
2023-09-13 11:50:43.466 
Epoch 11/1000 
	 loss: 42.0926, MinusLogProbMetric: 42.0926, val_loss: 42.2321, val_MinusLogProbMetric: 42.2321

Epoch 11: val_loss did not improve from 42.05851
196/196 - 12s - loss: 42.0926 - MinusLogProbMetric: 42.0926 - val_loss: 42.2321 - val_MinusLogProbMetric: 42.2321 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 12/1000
2023-09-13 11:50:52.700 
Epoch 12/1000 
	 loss: 42.1910, MinusLogProbMetric: 42.1910, val_loss: 41.4291, val_MinusLogProbMetric: 41.4291

Epoch 12: val_loss improved from 42.05851 to 41.42910, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 9s - loss: 42.1910 - MinusLogProbMetric: 42.1910 - val_loss: 41.4291 - val_MinusLogProbMetric: 41.4291 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 13/1000
2023-09-13 11:51:01.595 
Epoch 13/1000 
	 loss: 41.7510, MinusLogProbMetric: 41.7510, val_loss: 41.7570, val_MinusLogProbMetric: 41.7570

Epoch 13: val_loss did not improve from 41.42910
196/196 - 9s - loss: 41.7510 - MinusLogProbMetric: 41.7510 - val_loss: 41.7570 - val_MinusLogProbMetric: 41.7570 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 14/1000
2023-09-13 11:51:11.021 
Epoch 14/1000 
	 loss: 41.6532, MinusLogProbMetric: 41.6532, val_loss: 43.4295, val_MinusLogProbMetric: 43.4295

Epoch 14: val_loss did not improve from 41.42910
196/196 - 9s - loss: 41.6532 - MinusLogProbMetric: 41.6532 - val_loss: 43.4295 - val_MinusLogProbMetric: 43.4295 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 15/1000
2023-09-13 11:51:21.918 
Epoch 15/1000 
	 loss: 41.5987, MinusLogProbMetric: 41.5987, val_loss: 41.1056, val_MinusLogProbMetric: 41.1056

Epoch 15: val_loss improved from 41.42910 to 41.10561, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 11s - loss: 41.5987 - MinusLogProbMetric: 41.5987 - val_loss: 41.1056 - val_MinusLogProbMetric: 41.1056 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 16/1000
2023-09-13 11:51:33.865 
Epoch 16/1000 
	 loss: 41.6591, MinusLogProbMetric: 41.6591, val_loss: 41.6286, val_MinusLogProbMetric: 41.6286

Epoch 16: val_loss did not improve from 41.10561
196/196 - 12s - loss: 41.6591 - MinusLogProbMetric: 41.6591 - val_loss: 41.6286 - val_MinusLogProbMetric: 41.6286 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 17/1000
2023-09-13 11:51:45.479 
Epoch 17/1000 
	 loss: 41.3994, MinusLogProbMetric: 41.3994, val_loss: 41.3070, val_MinusLogProbMetric: 41.3070

Epoch 17: val_loss did not improve from 41.10561
196/196 - 12s - loss: 41.3994 - MinusLogProbMetric: 41.3994 - val_loss: 41.3070 - val_MinusLogProbMetric: 41.3070 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 18/1000
2023-09-13 11:51:56.898 
Epoch 18/1000 
	 loss: 41.2852, MinusLogProbMetric: 41.2852, val_loss: 41.1026, val_MinusLogProbMetric: 41.1026

Epoch 18: val_loss improved from 41.10561 to 41.10257, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 12s - loss: 41.2852 - MinusLogProbMetric: 41.2852 - val_loss: 41.1026 - val_MinusLogProbMetric: 41.1026 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 19/1000
2023-09-13 11:52:08.465 
Epoch 19/1000 
	 loss: 41.2691, MinusLogProbMetric: 41.2691, val_loss: 41.2089, val_MinusLogProbMetric: 41.2089

Epoch 19: val_loss did not improve from 41.10257
196/196 - 11s - loss: 41.2691 - MinusLogProbMetric: 41.2691 - val_loss: 41.2089 - val_MinusLogProbMetric: 41.2089 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 20/1000
2023-09-13 11:52:19.466 
Epoch 20/1000 
	 loss: 41.1185, MinusLogProbMetric: 41.1185, val_loss: 40.9015, val_MinusLogProbMetric: 40.9015

Epoch 20: val_loss improved from 41.10257 to 40.90152, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 11s - loss: 41.1185 - MinusLogProbMetric: 41.1185 - val_loss: 40.9015 - val_MinusLogProbMetric: 40.9015 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 21/1000
2023-09-13 11:52:29.734 
Epoch 21/1000 
	 loss: 41.0066, MinusLogProbMetric: 41.0066, val_loss: 42.2356, val_MinusLogProbMetric: 42.2356

Epoch 21: val_loss did not improve from 40.90152
196/196 - 10s - loss: 41.0066 - MinusLogProbMetric: 41.0066 - val_loss: 42.2356 - val_MinusLogProbMetric: 42.2356 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 22/1000
2023-09-13 11:52:40.334 
Epoch 22/1000 
	 loss: 40.9455, MinusLogProbMetric: 40.9455, val_loss: 41.1722, val_MinusLogProbMetric: 41.1722

Epoch 22: val_loss did not improve from 40.90152
196/196 - 11s - loss: 40.9455 - MinusLogProbMetric: 40.9455 - val_loss: 41.1722 - val_MinusLogProbMetric: 41.1722 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 23/1000
2023-09-13 11:52:50.919 
Epoch 23/1000 
	 loss: 41.0175, MinusLogProbMetric: 41.0175, val_loss: 41.0199, val_MinusLogProbMetric: 41.0199

Epoch 23: val_loss did not improve from 40.90152
196/196 - 11s - loss: 41.0175 - MinusLogProbMetric: 41.0175 - val_loss: 41.0199 - val_MinusLogProbMetric: 41.0199 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 24/1000
2023-09-13 11:52:59.509 
Epoch 24/1000 
	 loss: 40.9167, MinusLogProbMetric: 40.9167, val_loss: 41.2538, val_MinusLogProbMetric: 41.2538

Epoch 24: val_loss did not improve from 40.90152
196/196 - 9s - loss: 40.9167 - MinusLogProbMetric: 40.9167 - val_loss: 41.2538 - val_MinusLogProbMetric: 41.2538 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 25/1000
2023-09-13 11:53:07.825 
Epoch 25/1000 
	 loss: 40.9195, MinusLogProbMetric: 40.9195, val_loss: 41.6340, val_MinusLogProbMetric: 41.6340

Epoch 25: val_loss did not improve from 40.90152
196/196 - 8s - loss: 40.9195 - MinusLogProbMetric: 40.9195 - val_loss: 41.6340 - val_MinusLogProbMetric: 41.6340 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 26/1000
2023-09-13 11:53:16.210 
Epoch 26/1000 
	 loss: 40.7822, MinusLogProbMetric: 40.7822, val_loss: 41.0323, val_MinusLogProbMetric: 41.0323

Epoch 26: val_loss did not improve from 40.90152
196/196 - 8s - loss: 40.7822 - MinusLogProbMetric: 40.7822 - val_loss: 41.0323 - val_MinusLogProbMetric: 41.0323 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 27/1000
2023-09-13 11:53:26.356 
Epoch 27/1000 
	 loss: 40.7484, MinusLogProbMetric: 40.7484, val_loss: 40.7791, val_MinusLogProbMetric: 40.7791

Epoch 27: val_loss improved from 40.90152 to 40.77909, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 10s - loss: 40.7484 - MinusLogProbMetric: 40.7484 - val_loss: 40.7791 - val_MinusLogProbMetric: 40.7791 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 28/1000
2023-09-13 11:53:38.247 
Epoch 28/1000 
	 loss: 40.8593, MinusLogProbMetric: 40.8593, val_loss: 40.8417, val_MinusLogProbMetric: 40.8417

Epoch 28: val_loss did not improve from 40.77909
196/196 - 12s - loss: 40.8593 - MinusLogProbMetric: 40.8593 - val_loss: 40.8417 - val_MinusLogProbMetric: 40.8417 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 29/1000
2023-09-13 11:53:47.740 
Epoch 29/1000 
	 loss: 40.7779, MinusLogProbMetric: 40.7779, val_loss: 40.8167, val_MinusLogProbMetric: 40.8167

Epoch 29: val_loss did not improve from 40.77909
196/196 - 9s - loss: 40.7779 - MinusLogProbMetric: 40.7779 - val_loss: 40.8167 - val_MinusLogProbMetric: 40.8167 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 30/1000
2023-09-13 11:53:57.334 
Epoch 30/1000 
	 loss: 40.6937, MinusLogProbMetric: 40.6937, val_loss: 40.7368, val_MinusLogProbMetric: 40.7368

Epoch 30: val_loss improved from 40.77909 to 40.73678, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 10s - loss: 40.6937 - MinusLogProbMetric: 40.6937 - val_loss: 40.7368 - val_MinusLogProbMetric: 40.7368 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 31/1000
2023-09-13 11:54:08.182 
Epoch 31/1000 
	 loss: 40.6325, MinusLogProbMetric: 40.6325, val_loss: 40.9881, val_MinusLogProbMetric: 40.9881

Epoch 31: val_loss did not improve from 40.73678
196/196 - 11s - loss: 40.6325 - MinusLogProbMetric: 40.6325 - val_loss: 40.9881 - val_MinusLogProbMetric: 40.9881 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 32/1000
2023-09-13 11:54:20.239 
Epoch 32/1000 
	 loss: 40.6600, MinusLogProbMetric: 40.6600, val_loss: 40.6719, val_MinusLogProbMetric: 40.6719

Epoch 32: val_loss improved from 40.73678 to 40.67186, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 12s - loss: 40.6600 - MinusLogProbMetric: 40.6600 - val_loss: 40.6719 - val_MinusLogProbMetric: 40.6719 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 33/1000
2023-09-13 11:54:32.378 
Epoch 33/1000 
	 loss: 40.7014, MinusLogProbMetric: 40.7014, val_loss: 41.2942, val_MinusLogProbMetric: 41.2942

Epoch 33: val_loss did not improve from 40.67186
196/196 - 12s - loss: 40.7014 - MinusLogProbMetric: 40.7014 - val_loss: 41.2942 - val_MinusLogProbMetric: 41.2942 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 34/1000
2023-09-13 11:54:44.362 
Epoch 34/1000 
	 loss: 40.5865, MinusLogProbMetric: 40.5865, val_loss: 40.4893, val_MinusLogProbMetric: 40.4893

Epoch 34: val_loss improved from 40.67186 to 40.48931, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 12s - loss: 40.5865 - MinusLogProbMetric: 40.5865 - val_loss: 40.4893 - val_MinusLogProbMetric: 40.4893 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 35/1000
2023-09-13 11:54:56.347 
Epoch 35/1000 
	 loss: 40.5458, MinusLogProbMetric: 40.5458, val_loss: 40.5675, val_MinusLogProbMetric: 40.5675

Epoch 35: val_loss did not improve from 40.48931
196/196 - 12s - loss: 40.5458 - MinusLogProbMetric: 40.5458 - val_loss: 40.5675 - val_MinusLogProbMetric: 40.5675 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 36/1000
2023-09-13 11:55:08.353 
Epoch 36/1000 
	 loss: 40.5302, MinusLogProbMetric: 40.5302, val_loss: 41.0820, val_MinusLogProbMetric: 41.0820

Epoch 36: val_loss did not improve from 40.48931
196/196 - 12s - loss: 40.5302 - MinusLogProbMetric: 40.5302 - val_loss: 41.0820 - val_MinusLogProbMetric: 41.0820 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 37/1000
2023-09-13 11:55:20.325 
Epoch 37/1000 
	 loss: 40.5771, MinusLogProbMetric: 40.5771, val_loss: 40.4349, val_MinusLogProbMetric: 40.4349

Epoch 37: val_loss improved from 40.48931 to 40.43494, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 12s - loss: 40.5771 - MinusLogProbMetric: 40.5771 - val_loss: 40.4349 - val_MinusLogProbMetric: 40.4349 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 38/1000
2023-09-13 11:55:32.230 
Epoch 38/1000 
	 loss: 40.5225, MinusLogProbMetric: 40.5225, val_loss: 41.0062, val_MinusLogProbMetric: 41.0062

Epoch 38: val_loss did not improve from 40.43494
196/196 - 12s - loss: 40.5225 - MinusLogProbMetric: 40.5225 - val_loss: 41.0062 - val_MinusLogProbMetric: 41.0062 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 39/1000
2023-09-13 11:55:44.256 
Epoch 39/1000 
	 loss: 40.5302, MinusLogProbMetric: 40.5302, val_loss: 40.5482, val_MinusLogProbMetric: 40.5482

Epoch 39: val_loss did not improve from 40.43494
196/196 - 12s - loss: 40.5302 - MinusLogProbMetric: 40.5302 - val_loss: 40.5482 - val_MinusLogProbMetric: 40.5482 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 40/1000
2023-09-13 11:55:56.135 
Epoch 40/1000 
	 loss: 40.4830, MinusLogProbMetric: 40.4830, val_loss: 40.8524, val_MinusLogProbMetric: 40.8524

Epoch 40: val_loss did not improve from 40.43494
196/196 - 12s - loss: 40.4830 - MinusLogProbMetric: 40.4830 - val_loss: 40.8524 - val_MinusLogProbMetric: 40.8524 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 41/1000
2023-09-13 11:56:07.962 
Epoch 41/1000 
	 loss: 40.4592, MinusLogProbMetric: 40.4592, val_loss: 41.1135, val_MinusLogProbMetric: 41.1135

Epoch 41: val_loss did not improve from 40.43494
196/196 - 12s - loss: 40.4592 - MinusLogProbMetric: 40.4592 - val_loss: 41.1135 - val_MinusLogProbMetric: 41.1135 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 42/1000
2023-09-13 11:56:17.675 
Epoch 42/1000 
	 loss: 40.4935, MinusLogProbMetric: 40.4935, val_loss: 40.5815, val_MinusLogProbMetric: 40.5815

Epoch 42: val_loss did not improve from 40.43494
196/196 - 10s - loss: 40.4935 - MinusLogProbMetric: 40.4935 - val_loss: 40.5815 - val_MinusLogProbMetric: 40.5815 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 43/1000
2023-09-13 11:56:26.295 
Epoch 43/1000 
	 loss: 40.4851, MinusLogProbMetric: 40.4851, val_loss: 40.4778, val_MinusLogProbMetric: 40.4778

Epoch 43: val_loss did not improve from 40.43494
196/196 - 9s - loss: 40.4851 - MinusLogProbMetric: 40.4851 - val_loss: 40.4778 - val_MinusLogProbMetric: 40.4778 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 44/1000
2023-09-13 11:56:35.382 
Epoch 44/1000 
	 loss: 40.4316, MinusLogProbMetric: 40.4316, val_loss: 40.3943, val_MinusLogProbMetric: 40.3943

Epoch 44: val_loss improved from 40.43494 to 40.39428, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 9s - loss: 40.4316 - MinusLogProbMetric: 40.4316 - val_loss: 40.3943 - val_MinusLogProbMetric: 40.3943 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 45/1000
2023-09-13 11:56:45.054 
Epoch 45/1000 
	 loss: 40.4711, MinusLogProbMetric: 40.4711, val_loss: 40.7556, val_MinusLogProbMetric: 40.7556

Epoch 45: val_loss did not improve from 40.39428
196/196 - 10s - loss: 40.4711 - MinusLogProbMetric: 40.4711 - val_loss: 40.7556 - val_MinusLogProbMetric: 40.7556 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 46/1000
2023-09-13 11:56:54.190 
Epoch 46/1000 
	 loss: 40.4700, MinusLogProbMetric: 40.4700, val_loss: 40.8055, val_MinusLogProbMetric: 40.8055

Epoch 46: val_loss did not improve from 40.39428
196/196 - 9s - loss: 40.4700 - MinusLogProbMetric: 40.4700 - val_loss: 40.8055 - val_MinusLogProbMetric: 40.8055 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 47/1000
2023-09-13 11:57:05.620 
Epoch 47/1000 
	 loss: 40.4011, MinusLogProbMetric: 40.4011, val_loss: 40.5763, val_MinusLogProbMetric: 40.5763

Epoch 47: val_loss did not improve from 40.39428
196/196 - 11s - loss: 40.4011 - MinusLogProbMetric: 40.4011 - val_loss: 40.5763 - val_MinusLogProbMetric: 40.5763 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 48/1000
2023-09-13 11:57:17.278 
Epoch 48/1000 
	 loss: 40.4181, MinusLogProbMetric: 40.4181, val_loss: 40.7277, val_MinusLogProbMetric: 40.7277

Epoch 48: val_loss did not improve from 40.39428
196/196 - 12s - loss: 40.4181 - MinusLogProbMetric: 40.4181 - val_loss: 40.7277 - val_MinusLogProbMetric: 40.7277 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 49/1000
2023-09-13 11:57:27.839 
Epoch 49/1000 
	 loss: 40.4196, MinusLogProbMetric: 40.4196, val_loss: 41.0443, val_MinusLogProbMetric: 41.0443

Epoch 49: val_loss did not improve from 40.39428
196/196 - 11s - loss: 40.4196 - MinusLogProbMetric: 40.4196 - val_loss: 41.0443 - val_MinusLogProbMetric: 41.0443 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 50/1000
2023-09-13 11:57:37.475 
Epoch 50/1000 
	 loss: 40.3742, MinusLogProbMetric: 40.3742, val_loss: 40.6257, val_MinusLogProbMetric: 40.6257

Epoch 50: val_loss did not improve from 40.39428
196/196 - 10s - loss: 40.3742 - MinusLogProbMetric: 40.3742 - val_loss: 40.6257 - val_MinusLogProbMetric: 40.6257 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 51/1000
2023-09-13 11:57:48.324 
Epoch 51/1000 
	 loss: 40.3718, MinusLogProbMetric: 40.3718, val_loss: 40.4738, val_MinusLogProbMetric: 40.4738

Epoch 51: val_loss did not improve from 40.39428
196/196 - 11s - loss: 40.3718 - MinusLogProbMetric: 40.3718 - val_loss: 40.4738 - val_MinusLogProbMetric: 40.4738 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 52/1000
2023-09-13 11:57:59.247 
Epoch 52/1000 
	 loss: 40.3394, MinusLogProbMetric: 40.3394, val_loss: 40.7821, val_MinusLogProbMetric: 40.7821

Epoch 52: val_loss did not improve from 40.39428
196/196 - 11s - loss: 40.3394 - MinusLogProbMetric: 40.3394 - val_loss: 40.7821 - val_MinusLogProbMetric: 40.7821 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 53/1000
2023-09-13 11:58:11.373 
Epoch 53/1000 
	 loss: 40.3489, MinusLogProbMetric: 40.3489, val_loss: 40.8318, val_MinusLogProbMetric: 40.8318

Epoch 53: val_loss did not improve from 40.39428
196/196 - 12s - loss: 40.3489 - MinusLogProbMetric: 40.3489 - val_loss: 40.8318 - val_MinusLogProbMetric: 40.8318 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 54/1000
2023-09-13 11:58:24.152 
Epoch 54/1000 
	 loss: 40.3463, MinusLogProbMetric: 40.3463, val_loss: 40.6291, val_MinusLogProbMetric: 40.6291

Epoch 54: val_loss did not improve from 40.39428
196/196 - 13s - loss: 40.3463 - MinusLogProbMetric: 40.3463 - val_loss: 40.6291 - val_MinusLogProbMetric: 40.6291 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 55/1000
2023-09-13 11:58:36.605 
Epoch 55/1000 
	 loss: 40.3484, MinusLogProbMetric: 40.3484, val_loss: 40.4888, val_MinusLogProbMetric: 40.4888

Epoch 55: val_loss did not improve from 40.39428
196/196 - 12s - loss: 40.3484 - MinusLogProbMetric: 40.3484 - val_loss: 40.4888 - val_MinusLogProbMetric: 40.4888 - lr: 0.0010 - 12s/epoch - 64ms/step
Epoch 56/1000
2023-09-13 11:58:47.882 
Epoch 56/1000 
	 loss: 40.3116, MinusLogProbMetric: 40.3116, val_loss: 40.5979, val_MinusLogProbMetric: 40.5979

Epoch 56: val_loss did not improve from 40.39428
196/196 - 11s - loss: 40.3116 - MinusLogProbMetric: 40.3116 - val_loss: 40.5979 - val_MinusLogProbMetric: 40.5979 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 57/1000
2023-09-13 11:58:59.792 
Epoch 57/1000 
	 loss: 40.3372, MinusLogProbMetric: 40.3372, val_loss: 40.8904, val_MinusLogProbMetric: 40.8904

Epoch 57: val_loss did not improve from 40.39428
196/196 - 12s - loss: 40.3372 - MinusLogProbMetric: 40.3372 - val_loss: 40.8904 - val_MinusLogProbMetric: 40.8904 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 58/1000
2023-09-13 11:59:12.151 
Epoch 58/1000 
	 loss: 40.3142, MinusLogProbMetric: 40.3142, val_loss: 40.3111, val_MinusLogProbMetric: 40.3111

Epoch 58: val_loss improved from 40.39428 to 40.31114, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 13s - loss: 40.3142 - MinusLogProbMetric: 40.3142 - val_loss: 40.3111 - val_MinusLogProbMetric: 40.3111 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 59/1000
2023-09-13 11:59:24.159 
Epoch 59/1000 
	 loss: 40.3106, MinusLogProbMetric: 40.3106, val_loss: 40.5624, val_MinusLogProbMetric: 40.5624

Epoch 59: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.3106 - MinusLogProbMetric: 40.3106 - val_loss: 40.5624 - val_MinusLogProbMetric: 40.5624 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 60/1000
2023-09-13 11:59:36.220 
Epoch 60/1000 
	 loss: 40.3038, MinusLogProbMetric: 40.3038, val_loss: 40.4937, val_MinusLogProbMetric: 40.4937

Epoch 60: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.3038 - MinusLogProbMetric: 40.3038 - val_loss: 40.4937 - val_MinusLogProbMetric: 40.4937 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 61/1000
2023-09-13 11:59:48.126 
Epoch 61/1000 
	 loss: 40.2514, MinusLogProbMetric: 40.2514, val_loss: 40.5284, val_MinusLogProbMetric: 40.5284

Epoch 61: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.2514 - MinusLogProbMetric: 40.2514 - val_loss: 40.5284 - val_MinusLogProbMetric: 40.5284 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 62/1000
2023-09-13 12:00:00.256 
Epoch 62/1000 
	 loss: 40.3158, MinusLogProbMetric: 40.3158, val_loss: 40.5014, val_MinusLogProbMetric: 40.5014

Epoch 62: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.3158 - MinusLogProbMetric: 40.3158 - val_loss: 40.5014 - val_MinusLogProbMetric: 40.5014 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 63/1000
2023-09-13 12:00:11.570 
Epoch 63/1000 
	 loss: 40.2806, MinusLogProbMetric: 40.2806, val_loss: 40.5956, val_MinusLogProbMetric: 40.5956

Epoch 63: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.2806 - MinusLogProbMetric: 40.2806 - val_loss: 40.5956 - val_MinusLogProbMetric: 40.5956 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 64/1000
2023-09-13 12:00:23.623 
Epoch 64/1000 
	 loss: 40.2959, MinusLogProbMetric: 40.2959, val_loss: 40.4307, val_MinusLogProbMetric: 40.4307

Epoch 64: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.2959 - MinusLogProbMetric: 40.2959 - val_loss: 40.4307 - val_MinusLogProbMetric: 40.4307 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 65/1000
2023-09-13 12:00:35.158 
Epoch 65/1000 
	 loss: 40.2195, MinusLogProbMetric: 40.2195, val_loss: 40.5752, val_MinusLogProbMetric: 40.5752

Epoch 65: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.2195 - MinusLogProbMetric: 40.2195 - val_loss: 40.5752 - val_MinusLogProbMetric: 40.5752 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 66/1000
2023-09-13 12:00:45.793 
Epoch 66/1000 
	 loss: 40.2151, MinusLogProbMetric: 40.2151, val_loss: 40.4711, val_MinusLogProbMetric: 40.4711

Epoch 66: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.2151 - MinusLogProbMetric: 40.2151 - val_loss: 40.4711 - val_MinusLogProbMetric: 40.4711 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 67/1000
2023-09-13 12:00:55.417 
Epoch 67/1000 
	 loss: 40.2629, MinusLogProbMetric: 40.2629, val_loss: 40.4306, val_MinusLogProbMetric: 40.4306

Epoch 67: val_loss did not improve from 40.31114
196/196 - 10s - loss: 40.2629 - MinusLogProbMetric: 40.2629 - val_loss: 40.4306 - val_MinusLogProbMetric: 40.4306 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 68/1000
2023-09-13 12:01:05.524 
Epoch 68/1000 
	 loss: 40.2149, MinusLogProbMetric: 40.2149, val_loss: 40.4378, val_MinusLogProbMetric: 40.4378

Epoch 68: val_loss did not improve from 40.31114
196/196 - 10s - loss: 40.2149 - MinusLogProbMetric: 40.2149 - val_loss: 40.4378 - val_MinusLogProbMetric: 40.4378 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 69/1000
2023-09-13 12:01:16.538 
Epoch 69/1000 
	 loss: 40.2531, MinusLogProbMetric: 40.2531, val_loss: 40.3415, val_MinusLogProbMetric: 40.3415

Epoch 69: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.2531 - MinusLogProbMetric: 40.2531 - val_loss: 40.3415 - val_MinusLogProbMetric: 40.3415 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 70/1000
2023-09-13 12:01:27.926 
Epoch 70/1000 
	 loss: 40.1821, MinusLogProbMetric: 40.1821, val_loss: 40.4602, val_MinusLogProbMetric: 40.4602

Epoch 70: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1821 - MinusLogProbMetric: 40.1821 - val_loss: 40.4602 - val_MinusLogProbMetric: 40.4602 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 71/1000
2023-09-13 12:01:37.785 
Epoch 71/1000 
	 loss: 40.2369, MinusLogProbMetric: 40.2369, val_loss: 40.7043, val_MinusLogProbMetric: 40.7043

Epoch 71: val_loss did not improve from 40.31114
196/196 - 10s - loss: 40.2369 - MinusLogProbMetric: 40.2369 - val_loss: 40.7043 - val_MinusLogProbMetric: 40.7043 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 72/1000
2023-09-13 12:01:47.904 
Epoch 72/1000 
	 loss: 40.2031, MinusLogProbMetric: 40.2031, val_loss: 40.5729, val_MinusLogProbMetric: 40.5729

Epoch 72: val_loss did not improve from 40.31114
196/196 - 10s - loss: 40.2031 - MinusLogProbMetric: 40.2031 - val_loss: 40.5729 - val_MinusLogProbMetric: 40.5729 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 73/1000
2023-09-13 12:01:58.909 
Epoch 73/1000 
	 loss: 40.1625, MinusLogProbMetric: 40.1625, val_loss: 40.4017, val_MinusLogProbMetric: 40.4017

Epoch 73: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1625 - MinusLogProbMetric: 40.1625 - val_loss: 40.4017 - val_MinusLogProbMetric: 40.4017 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 74/1000
2023-09-13 12:02:10.588 
Epoch 74/1000 
	 loss: 40.1951, MinusLogProbMetric: 40.1951, val_loss: 40.4616, val_MinusLogProbMetric: 40.4616

Epoch 74: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.1951 - MinusLogProbMetric: 40.1951 - val_loss: 40.4616 - val_MinusLogProbMetric: 40.4616 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 75/1000
2023-09-13 12:02:22.514 
Epoch 75/1000 
	 loss: 40.1503, MinusLogProbMetric: 40.1503, val_loss: 40.4284, val_MinusLogProbMetric: 40.4284

Epoch 75: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.1503 - MinusLogProbMetric: 40.1503 - val_loss: 40.4284 - val_MinusLogProbMetric: 40.4284 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 76/1000
2023-09-13 12:02:34.646 
Epoch 76/1000 
	 loss: 40.1898, MinusLogProbMetric: 40.1898, val_loss: 40.4237, val_MinusLogProbMetric: 40.4237

Epoch 76: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.1898 - MinusLogProbMetric: 40.1898 - val_loss: 40.4237 - val_MinusLogProbMetric: 40.4237 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 77/1000
2023-09-13 12:02:46.415 
Epoch 77/1000 
	 loss: 40.1714, MinusLogProbMetric: 40.1714, val_loss: 40.7336, val_MinusLogProbMetric: 40.7336

Epoch 77: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.1714 - MinusLogProbMetric: 40.1714 - val_loss: 40.7336 - val_MinusLogProbMetric: 40.7336 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-13 12:02:57.324 
Epoch 78/1000 
	 loss: 40.1936, MinusLogProbMetric: 40.1936, val_loss: 40.5653, val_MinusLogProbMetric: 40.5653

Epoch 78: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1936 - MinusLogProbMetric: 40.1936 - val_loss: 40.5653 - val_MinusLogProbMetric: 40.5653 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 79/1000
2023-09-13 12:03:09.283 
Epoch 79/1000 
	 loss: 40.1427, MinusLogProbMetric: 40.1427, val_loss: 40.6240, val_MinusLogProbMetric: 40.6240

Epoch 79: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.1427 - MinusLogProbMetric: 40.1427 - val_loss: 40.6240 - val_MinusLogProbMetric: 40.6240 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 80/1000
2023-09-13 12:03:21.002 
Epoch 80/1000 
	 loss: 40.1739, MinusLogProbMetric: 40.1739, val_loss: 40.4039, val_MinusLogProbMetric: 40.4039

Epoch 80: val_loss did not improve from 40.31114
196/196 - 12s - loss: 40.1739 - MinusLogProbMetric: 40.1739 - val_loss: 40.4039 - val_MinusLogProbMetric: 40.4039 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 81/1000
2023-09-13 12:03:32.497 
Epoch 81/1000 
	 loss: 40.1561, MinusLogProbMetric: 40.1561, val_loss: 40.7776, val_MinusLogProbMetric: 40.7776

Epoch 81: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1561 - MinusLogProbMetric: 40.1561 - val_loss: 40.7776 - val_MinusLogProbMetric: 40.7776 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 82/1000
2023-09-13 12:03:43.034 
Epoch 82/1000 
	 loss: 40.1332, MinusLogProbMetric: 40.1332, val_loss: 40.5410, val_MinusLogProbMetric: 40.5410

Epoch 82: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1332 - MinusLogProbMetric: 40.1332 - val_loss: 40.5410 - val_MinusLogProbMetric: 40.5410 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 83/1000
2023-09-13 12:03:53.182 
Epoch 83/1000 
	 loss: 40.1442, MinusLogProbMetric: 40.1442, val_loss: 40.4112, val_MinusLogProbMetric: 40.4112

Epoch 83: val_loss did not improve from 40.31114
196/196 - 10s - loss: 40.1442 - MinusLogProbMetric: 40.1442 - val_loss: 40.4112 - val_MinusLogProbMetric: 40.4112 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 84/1000
2023-09-13 12:04:03.979 
Epoch 84/1000 
	 loss: 40.1512, MinusLogProbMetric: 40.1512, val_loss: 40.5693, val_MinusLogProbMetric: 40.5693

Epoch 84: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1512 - MinusLogProbMetric: 40.1512 - val_loss: 40.5693 - val_MinusLogProbMetric: 40.5693 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 85/1000
2023-09-13 12:04:14.871 
Epoch 85/1000 
	 loss: 40.1314, MinusLogProbMetric: 40.1314, val_loss: 40.4652, val_MinusLogProbMetric: 40.4652

Epoch 85: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1314 - MinusLogProbMetric: 40.1314 - val_loss: 40.4652 - val_MinusLogProbMetric: 40.4652 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 86/1000
2023-09-13 12:04:24.877 
Epoch 86/1000 
	 loss: 40.1201, MinusLogProbMetric: 40.1201, val_loss: 40.3803, val_MinusLogProbMetric: 40.3803

Epoch 86: val_loss did not improve from 40.31114
196/196 - 10s - loss: 40.1201 - MinusLogProbMetric: 40.1201 - val_loss: 40.3803 - val_MinusLogProbMetric: 40.3803 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 87/1000
2023-09-13 12:04:35.819 
Epoch 87/1000 
	 loss: 40.1347, MinusLogProbMetric: 40.1347, val_loss: 40.5246, val_MinusLogProbMetric: 40.5246

Epoch 87: val_loss did not improve from 40.31114
196/196 - 11s - loss: 40.1347 - MinusLogProbMetric: 40.1347 - val_loss: 40.5246 - val_MinusLogProbMetric: 40.5246 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 88/1000
2023-09-13 12:04:46.860 
Epoch 88/1000 
	 loss: 40.1032, MinusLogProbMetric: 40.1032, val_loss: 40.2920, val_MinusLogProbMetric: 40.2920

Epoch 88: val_loss improved from 40.31114 to 40.29205, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 11s - loss: 40.1032 - MinusLogProbMetric: 40.1032 - val_loss: 40.2920 - val_MinusLogProbMetric: 40.2920 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 89/1000
2023-09-13 12:04:58.114 
Epoch 89/1000 
	 loss: 40.1474, MinusLogProbMetric: 40.1474, val_loss: 40.4548, val_MinusLogProbMetric: 40.4548

Epoch 89: val_loss did not improve from 40.29205
196/196 - 11s - loss: 40.1474 - MinusLogProbMetric: 40.1474 - val_loss: 40.4548 - val_MinusLogProbMetric: 40.4548 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 90/1000
2023-09-13 12:05:09.236 
Epoch 90/1000 
	 loss: 40.1088, MinusLogProbMetric: 40.1088, val_loss: 40.3517, val_MinusLogProbMetric: 40.3517

Epoch 90: val_loss did not improve from 40.29205
196/196 - 11s - loss: 40.1088 - MinusLogProbMetric: 40.1088 - val_loss: 40.3517 - val_MinusLogProbMetric: 40.3517 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 91/1000
2023-09-13 12:05:19.884 
Epoch 91/1000 
	 loss: 40.0991, MinusLogProbMetric: 40.0991, val_loss: 40.4800, val_MinusLogProbMetric: 40.4800

Epoch 91: val_loss did not improve from 40.29205
196/196 - 11s - loss: 40.0991 - MinusLogProbMetric: 40.0991 - val_loss: 40.4800 - val_MinusLogProbMetric: 40.4800 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 92/1000
2023-09-13 12:05:31.631 
Epoch 92/1000 
	 loss: 40.1005, MinusLogProbMetric: 40.1005, val_loss: 40.4638, val_MinusLogProbMetric: 40.4638

Epoch 92: val_loss did not improve from 40.29205
196/196 - 12s - loss: 40.1005 - MinusLogProbMetric: 40.1005 - val_loss: 40.4638 - val_MinusLogProbMetric: 40.4638 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 93/1000
2023-09-13 12:05:43.542 
Epoch 93/1000 
	 loss: 40.0936, MinusLogProbMetric: 40.0936, val_loss: 40.4282, val_MinusLogProbMetric: 40.4282

Epoch 93: val_loss did not improve from 40.29205
196/196 - 12s - loss: 40.0936 - MinusLogProbMetric: 40.0936 - val_loss: 40.4282 - val_MinusLogProbMetric: 40.4282 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 94/1000
2023-09-13 12:05:55.495 
Epoch 94/1000 
	 loss: 40.0984, MinusLogProbMetric: 40.0984, val_loss: 40.4718, val_MinusLogProbMetric: 40.4718

Epoch 94: val_loss did not improve from 40.29205
196/196 - 12s - loss: 40.0984 - MinusLogProbMetric: 40.0984 - val_loss: 40.4718 - val_MinusLogProbMetric: 40.4718 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 95/1000
2023-09-13 12:06:07.209 
Epoch 95/1000 
	 loss: 40.0899, MinusLogProbMetric: 40.0899, val_loss: 40.3304, val_MinusLogProbMetric: 40.3304

Epoch 95: val_loss did not improve from 40.29205
196/196 - 12s - loss: 40.0899 - MinusLogProbMetric: 40.0899 - val_loss: 40.3304 - val_MinusLogProbMetric: 40.3304 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 96/1000
2023-09-13 12:06:18.448 
Epoch 96/1000 
	 loss: 40.0836, MinusLogProbMetric: 40.0836, val_loss: 40.7480, val_MinusLogProbMetric: 40.7480

Epoch 96: val_loss did not improve from 40.29205
196/196 - 11s - loss: 40.0836 - MinusLogProbMetric: 40.0836 - val_loss: 40.7480 - val_MinusLogProbMetric: 40.7480 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 97/1000
2023-09-13 12:06:27.779 
Epoch 97/1000 
	 loss: 40.1019, MinusLogProbMetric: 40.1019, val_loss: 40.3315, val_MinusLogProbMetric: 40.3315

Epoch 97: val_loss did not improve from 40.29205
196/196 - 9s - loss: 40.1019 - MinusLogProbMetric: 40.1019 - val_loss: 40.3315 - val_MinusLogProbMetric: 40.3315 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 98/1000
2023-09-13 12:06:36.709 
Epoch 98/1000 
	 loss: 40.0669, MinusLogProbMetric: 40.0669, val_loss: 40.2887, val_MinusLogProbMetric: 40.2887

Epoch 98: val_loss improved from 40.29205 to 40.28867, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 9s - loss: 40.0669 - MinusLogProbMetric: 40.0669 - val_loss: 40.2887 - val_MinusLogProbMetric: 40.2887 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 99/1000
2023-09-13 12:06:45.636 
Epoch 99/1000 
	 loss: 40.0512, MinusLogProbMetric: 40.0512, val_loss: 40.4232, val_MinusLogProbMetric: 40.4232

Epoch 99: val_loss did not improve from 40.28867
196/196 - 9s - loss: 40.0512 - MinusLogProbMetric: 40.0512 - val_loss: 40.4232 - val_MinusLogProbMetric: 40.4232 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 100/1000
2023-09-13 12:06:54.497 
Epoch 100/1000 
	 loss: 40.0492, MinusLogProbMetric: 40.0492, val_loss: 40.4772, val_MinusLogProbMetric: 40.4772

Epoch 100: val_loss did not improve from 40.28867
196/196 - 9s - loss: 40.0492 - MinusLogProbMetric: 40.0492 - val_loss: 40.4772 - val_MinusLogProbMetric: 40.4772 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 101/1000
2023-09-13 12:07:03.364 
Epoch 101/1000 
	 loss: 40.0602, MinusLogProbMetric: 40.0602, val_loss: 40.4326, val_MinusLogProbMetric: 40.4326

Epoch 101: val_loss did not improve from 40.28867
196/196 - 9s - loss: 40.0602 - MinusLogProbMetric: 40.0602 - val_loss: 40.4326 - val_MinusLogProbMetric: 40.4326 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 102/1000
2023-09-13 12:07:12.565 
Epoch 102/1000 
	 loss: 40.0773, MinusLogProbMetric: 40.0773, val_loss: 40.5385, val_MinusLogProbMetric: 40.5385

Epoch 102: val_loss did not improve from 40.28867
196/196 - 9s - loss: 40.0773 - MinusLogProbMetric: 40.0773 - val_loss: 40.5385 - val_MinusLogProbMetric: 40.5385 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 103/1000
2023-09-13 12:07:22.227 
Epoch 103/1000 
	 loss: 40.0504, MinusLogProbMetric: 40.0504, val_loss: 40.6652, val_MinusLogProbMetric: 40.6652

Epoch 103: val_loss did not improve from 40.28867
196/196 - 10s - loss: 40.0504 - MinusLogProbMetric: 40.0504 - val_loss: 40.6652 - val_MinusLogProbMetric: 40.6652 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 104/1000
2023-09-13 12:07:32.552 
Epoch 104/1000 
	 loss: 40.0466, MinusLogProbMetric: 40.0466, val_loss: 40.4195, val_MinusLogProbMetric: 40.4195

Epoch 104: val_loss did not improve from 40.28867
196/196 - 10s - loss: 40.0466 - MinusLogProbMetric: 40.0466 - val_loss: 40.4195 - val_MinusLogProbMetric: 40.4195 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 105/1000
2023-09-13 12:07:43.334 
Epoch 105/1000 
	 loss: 40.0286, MinusLogProbMetric: 40.0286, val_loss: 40.3430, val_MinusLogProbMetric: 40.3430

Epoch 105: val_loss did not improve from 40.28867
196/196 - 11s - loss: 40.0286 - MinusLogProbMetric: 40.0286 - val_loss: 40.3430 - val_MinusLogProbMetric: 40.3430 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 106/1000
2023-09-13 12:07:55.017 
Epoch 106/1000 
	 loss: 40.0316, MinusLogProbMetric: 40.0316, val_loss: 40.4155, val_MinusLogProbMetric: 40.4155

Epoch 106: val_loss did not improve from 40.28867
196/196 - 12s - loss: 40.0316 - MinusLogProbMetric: 40.0316 - val_loss: 40.4155 - val_MinusLogProbMetric: 40.4155 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 107/1000
2023-09-13 12:08:06.468 
Epoch 107/1000 
	 loss: 40.0173, MinusLogProbMetric: 40.0173, val_loss: 40.4904, val_MinusLogProbMetric: 40.4904

Epoch 107: val_loss did not improve from 40.28867
196/196 - 11s - loss: 40.0173 - MinusLogProbMetric: 40.0173 - val_loss: 40.4904 - val_MinusLogProbMetric: 40.4904 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 108/1000
2023-09-13 12:08:16.979 
Epoch 108/1000 
	 loss: 40.0501, MinusLogProbMetric: 40.0501, val_loss: 40.3743, val_MinusLogProbMetric: 40.3743

Epoch 108: val_loss did not improve from 40.28867
196/196 - 11s - loss: 40.0501 - MinusLogProbMetric: 40.0501 - val_loss: 40.3743 - val_MinusLogProbMetric: 40.3743 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 109/1000
2023-09-13 12:08:28.593 
Epoch 109/1000 
	 loss: 40.0558, MinusLogProbMetric: 40.0558, val_loss: 40.3646, val_MinusLogProbMetric: 40.3646

Epoch 109: val_loss did not improve from 40.28867
196/196 - 12s - loss: 40.0558 - MinusLogProbMetric: 40.0558 - val_loss: 40.3646 - val_MinusLogProbMetric: 40.3646 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 110/1000
2023-09-13 12:08:40.113 
Epoch 110/1000 
	 loss: 40.0074, MinusLogProbMetric: 40.0074, val_loss: 40.4351, val_MinusLogProbMetric: 40.4351

Epoch 110: val_loss did not improve from 40.28867
196/196 - 12s - loss: 40.0074 - MinusLogProbMetric: 40.0074 - val_loss: 40.4351 - val_MinusLogProbMetric: 40.4351 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 111/1000
2023-09-13 12:08:51.785 
Epoch 111/1000 
	 loss: 40.0120, MinusLogProbMetric: 40.0120, val_loss: 40.5271, val_MinusLogProbMetric: 40.5271

Epoch 111: val_loss did not improve from 40.28867
196/196 - 12s - loss: 40.0120 - MinusLogProbMetric: 40.0120 - val_loss: 40.5271 - val_MinusLogProbMetric: 40.5271 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-13 12:09:03.367 
Epoch 112/1000 
	 loss: 40.0204, MinusLogProbMetric: 40.0204, val_loss: 40.4217, val_MinusLogProbMetric: 40.4217

Epoch 112: val_loss did not improve from 40.28867
196/196 - 12s - loss: 40.0204 - MinusLogProbMetric: 40.0204 - val_loss: 40.4217 - val_MinusLogProbMetric: 40.4217 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 113/1000
2023-09-13 12:09:14.913 
Epoch 113/1000 
	 loss: 39.9859, MinusLogProbMetric: 39.9859, val_loss: 40.5292, val_MinusLogProbMetric: 40.5292

Epoch 113: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9859 - MinusLogProbMetric: 39.9859 - val_loss: 40.5292 - val_MinusLogProbMetric: 40.5292 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 114/1000
2023-09-13 12:09:26.528 
Epoch 114/1000 
	 loss: 39.9832, MinusLogProbMetric: 39.9832, val_loss: 40.5396, val_MinusLogProbMetric: 40.5396

Epoch 114: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9832 - MinusLogProbMetric: 39.9832 - val_loss: 40.5396 - val_MinusLogProbMetric: 40.5396 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 115/1000
2023-09-13 12:09:37.336 
Epoch 115/1000 
	 loss: 40.0058, MinusLogProbMetric: 40.0058, val_loss: 40.4423, val_MinusLogProbMetric: 40.4423

Epoch 115: val_loss did not improve from 40.28867
196/196 - 11s - loss: 40.0058 - MinusLogProbMetric: 40.0058 - val_loss: 40.4423 - val_MinusLogProbMetric: 40.4423 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 116/1000
2023-09-13 12:09:46.077 
Epoch 116/1000 
	 loss: 39.9884, MinusLogProbMetric: 39.9884, val_loss: 40.3694, val_MinusLogProbMetric: 40.3694

Epoch 116: val_loss did not improve from 40.28867
196/196 - 9s - loss: 39.9884 - MinusLogProbMetric: 39.9884 - val_loss: 40.3694 - val_MinusLogProbMetric: 40.3694 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 117/1000
2023-09-13 12:09:56.689 
Epoch 117/1000 
	 loss: 40.0185, MinusLogProbMetric: 40.0185, val_loss: 40.3789, val_MinusLogProbMetric: 40.3789

Epoch 117: val_loss did not improve from 40.28867
196/196 - 11s - loss: 40.0185 - MinusLogProbMetric: 40.0185 - val_loss: 40.3789 - val_MinusLogProbMetric: 40.3789 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 118/1000
2023-09-13 12:10:08.386 
Epoch 118/1000 
	 loss: 39.9714, MinusLogProbMetric: 39.9714, val_loss: 40.4005, val_MinusLogProbMetric: 40.4005

Epoch 118: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9714 - MinusLogProbMetric: 39.9714 - val_loss: 40.4005 - val_MinusLogProbMetric: 40.4005 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 119/1000
2023-09-13 12:10:18.603 
Epoch 119/1000 
	 loss: 39.9961, MinusLogProbMetric: 39.9961, val_loss: 40.3258, val_MinusLogProbMetric: 40.3258

Epoch 119: val_loss did not improve from 40.28867
196/196 - 10s - loss: 39.9961 - MinusLogProbMetric: 39.9961 - val_loss: 40.3258 - val_MinusLogProbMetric: 40.3258 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 120/1000
2023-09-13 12:10:27.530 
Epoch 120/1000 
	 loss: 39.9946, MinusLogProbMetric: 39.9946, val_loss: 40.3734, val_MinusLogProbMetric: 40.3734

Epoch 120: val_loss did not improve from 40.28867
196/196 - 9s - loss: 39.9946 - MinusLogProbMetric: 39.9946 - val_loss: 40.3734 - val_MinusLogProbMetric: 40.3734 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 121/1000
2023-09-13 12:10:37.522 
Epoch 121/1000 
	 loss: 39.9957, MinusLogProbMetric: 39.9957, val_loss: 40.4744, val_MinusLogProbMetric: 40.4744

Epoch 121: val_loss did not improve from 40.28867
196/196 - 10s - loss: 39.9957 - MinusLogProbMetric: 39.9957 - val_loss: 40.4744 - val_MinusLogProbMetric: 40.4744 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 122/1000
2023-09-13 12:10:49.067 
Epoch 122/1000 
	 loss: 39.9813, MinusLogProbMetric: 39.9813, val_loss: 40.3172, val_MinusLogProbMetric: 40.3172

Epoch 122: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9813 - MinusLogProbMetric: 39.9813 - val_loss: 40.3172 - val_MinusLogProbMetric: 40.3172 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 123/1000
2023-09-13 12:11:00.415 
Epoch 123/1000 
	 loss: 39.9775, MinusLogProbMetric: 39.9775, val_loss: 40.4433, val_MinusLogProbMetric: 40.4433

Epoch 123: val_loss did not improve from 40.28867
196/196 - 11s - loss: 39.9775 - MinusLogProbMetric: 39.9775 - val_loss: 40.4433 - val_MinusLogProbMetric: 40.4433 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 124/1000
2023-09-13 12:11:12.141 
Epoch 124/1000 
	 loss: 39.9515, MinusLogProbMetric: 39.9515, val_loss: 40.3552, val_MinusLogProbMetric: 40.3552

Epoch 124: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9515 - MinusLogProbMetric: 39.9515 - val_loss: 40.3552 - val_MinusLogProbMetric: 40.3552 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-13 12:11:23.889 
Epoch 125/1000 
	 loss: 39.9649, MinusLogProbMetric: 39.9649, val_loss: 40.4639, val_MinusLogProbMetric: 40.4639

Epoch 125: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9649 - MinusLogProbMetric: 39.9649 - val_loss: 40.4639 - val_MinusLogProbMetric: 40.4639 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 126/1000
2023-09-13 12:11:35.660 
Epoch 126/1000 
	 loss: 39.9705, MinusLogProbMetric: 39.9705, val_loss: 40.4541, val_MinusLogProbMetric: 40.4541

Epoch 126: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9705 - MinusLogProbMetric: 39.9705 - val_loss: 40.4541 - val_MinusLogProbMetric: 40.4541 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 127/1000
2023-09-13 12:11:45.909 
Epoch 127/1000 
	 loss: 39.9580, MinusLogProbMetric: 39.9580, val_loss: 40.4024, val_MinusLogProbMetric: 40.4024

Epoch 127: val_loss did not improve from 40.28867
196/196 - 10s - loss: 39.9580 - MinusLogProbMetric: 39.9580 - val_loss: 40.4024 - val_MinusLogProbMetric: 40.4024 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 128/1000
2023-09-13 12:11:55.033 
Epoch 128/1000 
	 loss: 39.9338, MinusLogProbMetric: 39.9338, val_loss: 40.3923, val_MinusLogProbMetric: 40.3923

Epoch 128: val_loss did not improve from 40.28867
196/196 - 9s - loss: 39.9338 - MinusLogProbMetric: 39.9338 - val_loss: 40.3923 - val_MinusLogProbMetric: 40.3923 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 129/1000
2023-09-13 12:12:05.404 
Epoch 129/1000 
	 loss: 39.9604, MinusLogProbMetric: 39.9604, val_loss: 40.3473, val_MinusLogProbMetric: 40.3473

Epoch 129: val_loss did not improve from 40.28867
196/196 - 10s - loss: 39.9604 - MinusLogProbMetric: 39.9604 - val_loss: 40.3473 - val_MinusLogProbMetric: 40.3473 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 130/1000
2023-09-13 12:12:16.709 
Epoch 130/1000 
	 loss: 39.9609, MinusLogProbMetric: 39.9609, val_loss: 40.3437, val_MinusLogProbMetric: 40.3437

Epoch 130: val_loss did not improve from 40.28867
196/196 - 11s - loss: 39.9609 - MinusLogProbMetric: 39.9609 - val_loss: 40.3437 - val_MinusLogProbMetric: 40.3437 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 131/1000
2023-09-13 12:12:28.744 
Epoch 131/1000 
	 loss: 39.9501, MinusLogProbMetric: 39.9501, val_loss: 40.5364, val_MinusLogProbMetric: 40.5364

Epoch 131: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9501 - MinusLogProbMetric: 39.9501 - val_loss: 40.5364 - val_MinusLogProbMetric: 40.5364 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 132/1000
2023-09-13 12:12:40.621 
Epoch 132/1000 
	 loss: 39.9476, MinusLogProbMetric: 39.9476, val_loss: 40.4312, val_MinusLogProbMetric: 40.4312

Epoch 132: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9476 - MinusLogProbMetric: 39.9476 - val_loss: 40.4312 - val_MinusLogProbMetric: 40.4312 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 133/1000
2023-09-13 12:12:51.830 
Epoch 133/1000 
	 loss: 39.9351, MinusLogProbMetric: 39.9351, val_loss: 40.3703, val_MinusLogProbMetric: 40.3703

Epoch 133: val_loss did not improve from 40.28867
196/196 - 11s - loss: 39.9351 - MinusLogProbMetric: 39.9351 - val_loss: 40.3703 - val_MinusLogProbMetric: 40.3703 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 134/1000
2023-09-13 12:13:03.792 
Epoch 134/1000 
	 loss: 39.9370, MinusLogProbMetric: 39.9370, val_loss: 40.4095, val_MinusLogProbMetric: 40.4095

Epoch 134: val_loss did not improve from 40.28867
196/196 - 12s - loss: 39.9370 - MinusLogProbMetric: 39.9370 - val_loss: 40.4095 - val_MinusLogProbMetric: 40.4095 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 135/1000
2023-09-13 12:13:14.072 
Epoch 135/1000 
	 loss: 39.9499, MinusLogProbMetric: 39.9499, val_loss: 40.3140, val_MinusLogProbMetric: 40.3140

Epoch 135: val_loss did not improve from 40.28867
196/196 - 10s - loss: 39.9499 - MinusLogProbMetric: 39.9499 - val_loss: 40.3140 - val_MinusLogProbMetric: 40.3140 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 136/1000
2023-09-13 12:13:24.924 
Epoch 136/1000 
	 loss: 39.9475, MinusLogProbMetric: 39.9475, val_loss: 40.2793, val_MinusLogProbMetric: 40.2793

Epoch 136: val_loss improved from 40.28867 to 40.27925, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_210/weights/best_weights.h5
196/196 - 11s - loss: 39.9475 - MinusLogProbMetric: 39.9475 - val_loss: 40.2793 - val_MinusLogProbMetric: 40.2793 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 137/1000
2023-09-13 12:13:36.559 
Epoch 137/1000 
	 loss: 39.9053, MinusLogProbMetric: 39.9053, val_loss: 40.3767, val_MinusLogProbMetric: 40.3767

Epoch 137: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9053 - MinusLogProbMetric: 39.9053 - val_loss: 40.3767 - val_MinusLogProbMetric: 40.3767 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 138/1000
2023-09-13 12:13:47.378 
Epoch 138/1000 
	 loss: 39.9105, MinusLogProbMetric: 39.9105, val_loss: 40.4222, val_MinusLogProbMetric: 40.4222

Epoch 138: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9105 - MinusLogProbMetric: 39.9105 - val_loss: 40.4222 - val_MinusLogProbMetric: 40.4222 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 139/1000
2023-09-13 12:13:57.618 
Epoch 139/1000 
	 loss: 39.9160, MinusLogProbMetric: 39.9160, val_loss: 40.3397, val_MinusLogProbMetric: 40.3397

Epoch 139: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.9160 - MinusLogProbMetric: 39.9160 - val_loss: 40.3397 - val_MinusLogProbMetric: 40.3397 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 140/1000
2023-09-13 12:14:09.092 
Epoch 140/1000 
	 loss: 39.9429, MinusLogProbMetric: 39.9429, val_loss: 40.3469, val_MinusLogProbMetric: 40.3469

Epoch 140: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9429 - MinusLogProbMetric: 39.9429 - val_loss: 40.3469 - val_MinusLogProbMetric: 40.3469 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 141/1000
2023-09-13 12:14:20.536 
Epoch 141/1000 
	 loss: 39.9109, MinusLogProbMetric: 39.9109, val_loss: 40.3632, val_MinusLogProbMetric: 40.3632

Epoch 141: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9109 - MinusLogProbMetric: 39.9109 - val_loss: 40.3632 - val_MinusLogProbMetric: 40.3632 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 142/1000
2023-09-13 12:14:31.184 
Epoch 142/1000 
	 loss: 39.9149, MinusLogProbMetric: 39.9149, val_loss: 40.4933, val_MinusLogProbMetric: 40.4933

Epoch 142: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9149 - MinusLogProbMetric: 39.9149 - val_loss: 40.4933 - val_MinusLogProbMetric: 40.4933 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 143/1000
2023-09-13 12:14:41.820 
Epoch 143/1000 
	 loss: 39.9245, MinusLogProbMetric: 39.9245, val_loss: 40.3230, val_MinusLogProbMetric: 40.3230

Epoch 143: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9245 - MinusLogProbMetric: 39.9245 - val_loss: 40.3230 - val_MinusLogProbMetric: 40.3230 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 144/1000
2023-09-13 12:14:52.432 
Epoch 144/1000 
	 loss: 39.9011, MinusLogProbMetric: 39.9011, val_loss: 40.3899, val_MinusLogProbMetric: 40.3899

Epoch 144: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9011 - MinusLogProbMetric: 39.9011 - val_loss: 40.3899 - val_MinusLogProbMetric: 40.3899 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 145/1000
2023-09-13 12:15:02.551 
Epoch 145/1000 
	 loss: 39.8967, MinusLogProbMetric: 39.8967, val_loss: 40.2808, val_MinusLogProbMetric: 40.2808

Epoch 145: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.8967 - MinusLogProbMetric: 39.8967 - val_loss: 40.2808 - val_MinusLogProbMetric: 40.2808 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 146/1000
2023-09-13 12:15:12.832 
Epoch 146/1000 
	 loss: 39.9129, MinusLogProbMetric: 39.9129, val_loss: 40.5061, val_MinusLogProbMetric: 40.5061

Epoch 146: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.9129 - MinusLogProbMetric: 39.9129 - val_loss: 40.5061 - val_MinusLogProbMetric: 40.5061 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 147/1000
2023-09-13 12:15:24.178 
Epoch 147/1000 
	 loss: 39.9023, MinusLogProbMetric: 39.9023, val_loss: 40.4568, val_MinusLogProbMetric: 40.4568

Epoch 147: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9023 - MinusLogProbMetric: 39.9023 - val_loss: 40.4568 - val_MinusLogProbMetric: 40.4568 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 148/1000
2023-09-13 12:15:34.854 
Epoch 148/1000 
	 loss: 39.9160, MinusLogProbMetric: 39.9160, val_loss: 40.4106, val_MinusLogProbMetric: 40.4106

Epoch 148: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.9160 - MinusLogProbMetric: 39.9160 - val_loss: 40.4106 - val_MinusLogProbMetric: 40.4106 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 149/1000
2023-09-13 12:15:44.596 
Epoch 149/1000 
	 loss: 39.8844, MinusLogProbMetric: 39.8844, val_loss: 40.4108, val_MinusLogProbMetric: 40.4108

Epoch 149: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.8844 - MinusLogProbMetric: 39.8844 - val_loss: 40.4108 - val_MinusLogProbMetric: 40.4108 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 150/1000
2023-09-13 12:15:54.253 
Epoch 150/1000 
	 loss: 39.9009, MinusLogProbMetric: 39.9009, val_loss: 40.3744, val_MinusLogProbMetric: 40.3744

Epoch 150: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.9009 - MinusLogProbMetric: 39.9009 - val_loss: 40.3744 - val_MinusLogProbMetric: 40.3744 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 151/1000
2023-09-13 12:16:03.579 
Epoch 151/1000 
	 loss: 39.8713, MinusLogProbMetric: 39.8713, val_loss: 40.3760, val_MinusLogProbMetric: 40.3760

Epoch 151: val_loss did not improve from 40.27925
196/196 - 9s - loss: 39.8713 - MinusLogProbMetric: 39.8713 - val_loss: 40.3760 - val_MinusLogProbMetric: 40.3760 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 152/1000
2023-09-13 12:16:12.590 
Epoch 152/1000 
	 loss: 39.8820, MinusLogProbMetric: 39.8820, val_loss: 40.3512, val_MinusLogProbMetric: 40.3512

Epoch 152: val_loss did not improve from 40.27925
196/196 - 9s - loss: 39.8820 - MinusLogProbMetric: 39.8820 - val_loss: 40.3512 - val_MinusLogProbMetric: 40.3512 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 153/1000
2023-09-13 12:16:21.683 
Epoch 153/1000 
	 loss: 39.8821, MinusLogProbMetric: 39.8821, val_loss: 40.5905, val_MinusLogProbMetric: 40.5905

Epoch 153: val_loss did not improve from 40.27925
196/196 - 9s - loss: 39.8821 - MinusLogProbMetric: 39.8821 - val_loss: 40.5905 - val_MinusLogProbMetric: 40.5905 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 154/1000
2023-09-13 12:16:31.030 
Epoch 154/1000 
	 loss: 39.8674, MinusLogProbMetric: 39.8674, val_loss: 40.4732, val_MinusLogProbMetric: 40.4732

Epoch 154: val_loss did not improve from 40.27925
196/196 - 9s - loss: 39.8674 - MinusLogProbMetric: 39.8674 - val_loss: 40.4732 - val_MinusLogProbMetric: 40.4732 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 155/1000
2023-09-13 12:16:40.335 
Epoch 155/1000 
	 loss: 39.8903, MinusLogProbMetric: 39.8903, val_loss: 40.2953, val_MinusLogProbMetric: 40.2953

Epoch 155: val_loss did not improve from 40.27925
196/196 - 9s - loss: 39.8903 - MinusLogProbMetric: 39.8903 - val_loss: 40.2953 - val_MinusLogProbMetric: 40.2953 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 156/1000
2023-09-13 12:16:49.699 
Epoch 156/1000 
	 loss: 39.8562, MinusLogProbMetric: 39.8562, val_loss: 40.6082, val_MinusLogProbMetric: 40.6082

Epoch 156: val_loss did not improve from 40.27925
196/196 - 9s - loss: 39.8562 - MinusLogProbMetric: 39.8562 - val_loss: 40.6082 - val_MinusLogProbMetric: 40.6082 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 157/1000
2023-09-13 12:16:59.339 
Epoch 157/1000 
	 loss: 39.8636, MinusLogProbMetric: 39.8636, val_loss: 40.3938, val_MinusLogProbMetric: 40.3938

Epoch 157: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.8636 - MinusLogProbMetric: 39.8636 - val_loss: 40.3938 - val_MinusLogProbMetric: 40.3938 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 158/1000
2023-09-13 12:17:09.364 
Epoch 158/1000 
	 loss: 39.8782, MinusLogProbMetric: 39.8782, val_loss: 40.5604, val_MinusLogProbMetric: 40.5604

Epoch 158: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.8782 - MinusLogProbMetric: 39.8782 - val_loss: 40.5604 - val_MinusLogProbMetric: 40.5604 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 159/1000
2023-09-13 12:17:21.212 
Epoch 159/1000 
	 loss: 39.8593, MinusLogProbMetric: 39.8593, val_loss: 40.4147, val_MinusLogProbMetric: 40.4147

Epoch 159: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8593 - MinusLogProbMetric: 39.8593 - val_loss: 40.4147 - val_MinusLogProbMetric: 40.4147 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 160/1000
2023-09-13 12:17:33.273 
Epoch 160/1000 
	 loss: 39.8644, MinusLogProbMetric: 39.8644, val_loss: 40.5145, val_MinusLogProbMetric: 40.5145

Epoch 160: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8644 - MinusLogProbMetric: 39.8644 - val_loss: 40.5145 - val_MinusLogProbMetric: 40.5145 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 161/1000
2023-09-13 12:17:44.040 
Epoch 161/1000 
	 loss: 39.8968, MinusLogProbMetric: 39.8968, val_loss: 40.6041, val_MinusLogProbMetric: 40.6041

Epoch 161: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8968 - MinusLogProbMetric: 39.8968 - val_loss: 40.6041 - val_MinusLogProbMetric: 40.6041 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 162/1000
2023-09-13 12:17:55.738 
Epoch 162/1000 
	 loss: 39.8470, MinusLogProbMetric: 39.8470, val_loss: 40.3820, val_MinusLogProbMetric: 40.3820

Epoch 162: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8470 - MinusLogProbMetric: 39.8470 - val_loss: 40.3820 - val_MinusLogProbMetric: 40.3820 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 163/1000
2023-09-13 12:18:07.463 
Epoch 163/1000 
	 loss: 39.8597, MinusLogProbMetric: 39.8597, val_loss: 40.5057, val_MinusLogProbMetric: 40.5057

Epoch 163: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8597 - MinusLogProbMetric: 39.8597 - val_loss: 40.5057 - val_MinusLogProbMetric: 40.5057 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 164/1000
2023-09-13 12:18:19.246 
Epoch 164/1000 
	 loss: 39.8618, MinusLogProbMetric: 39.8618, val_loss: 40.4465, val_MinusLogProbMetric: 40.4465

Epoch 164: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8618 - MinusLogProbMetric: 39.8618 - val_loss: 40.4465 - val_MinusLogProbMetric: 40.4465 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 165/1000
2023-09-13 12:18:31.373 
Epoch 165/1000 
	 loss: 39.8518, MinusLogProbMetric: 39.8518, val_loss: 40.3892, val_MinusLogProbMetric: 40.3892

Epoch 165: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8518 - MinusLogProbMetric: 39.8518 - val_loss: 40.3892 - val_MinusLogProbMetric: 40.3892 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 166/1000
2023-09-13 12:18:42.971 
Epoch 166/1000 
	 loss: 39.8450, MinusLogProbMetric: 39.8450, val_loss: 40.4616, val_MinusLogProbMetric: 40.4616

Epoch 166: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8450 - MinusLogProbMetric: 39.8450 - val_loss: 40.4616 - val_MinusLogProbMetric: 40.4616 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-13 12:18:54.173 
Epoch 167/1000 
	 loss: 39.8118, MinusLogProbMetric: 39.8118, val_loss: 40.3847, val_MinusLogProbMetric: 40.3847

Epoch 167: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8118 - MinusLogProbMetric: 39.8118 - val_loss: 40.3847 - val_MinusLogProbMetric: 40.3847 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 168/1000
2023-09-13 12:19:05.599 
Epoch 168/1000 
	 loss: 39.8319, MinusLogProbMetric: 39.8319, val_loss: 40.3635, val_MinusLogProbMetric: 40.3635

Epoch 168: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8319 - MinusLogProbMetric: 39.8319 - val_loss: 40.3635 - val_MinusLogProbMetric: 40.3635 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 169/1000
2023-09-13 12:19:16.687 
Epoch 169/1000 
	 loss: 39.8167, MinusLogProbMetric: 39.8167, val_loss: 40.3358, val_MinusLogProbMetric: 40.3358

Epoch 169: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8167 - MinusLogProbMetric: 39.8167 - val_loss: 40.3358 - val_MinusLogProbMetric: 40.3358 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 170/1000
2023-09-13 12:19:28.080 
Epoch 170/1000 
	 loss: 39.8296, MinusLogProbMetric: 39.8296, val_loss: 40.3359, val_MinusLogProbMetric: 40.3359

Epoch 170: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8296 - MinusLogProbMetric: 39.8296 - val_loss: 40.3359 - val_MinusLogProbMetric: 40.3359 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 171/1000
2023-09-13 12:19:39.653 
Epoch 171/1000 
	 loss: 39.8086, MinusLogProbMetric: 39.8086, val_loss: 40.3806, val_MinusLogProbMetric: 40.3806

Epoch 171: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8086 - MinusLogProbMetric: 39.8086 - val_loss: 40.3806 - val_MinusLogProbMetric: 40.3806 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 172/1000
2023-09-13 12:19:51.151 
Epoch 172/1000 
	 loss: 39.7998, MinusLogProbMetric: 39.7998, val_loss: 40.4427, val_MinusLogProbMetric: 40.4427

Epoch 172: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.7998 - MinusLogProbMetric: 39.7998 - val_loss: 40.4427 - val_MinusLogProbMetric: 40.4427 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 173/1000
2023-09-13 12:20:01.139 
Epoch 173/1000 
	 loss: 39.8066, MinusLogProbMetric: 39.8066, val_loss: 40.6034, val_MinusLogProbMetric: 40.6034

Epoch 173: val_loss did not improve from 40.27925
196/196 - 10s - loss: 39.8066 - MinusLogProbMetric: 39.8066 - val_loss: 40.6034 - val_MinusLogProbMetric: 40.6034 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 174/1000
2023-09-13 12:20:12.117 
Epoch 174/1000 
	 loss: 39.8109, MinusLogProbMetric: 39.8109, val_loss: 40.4906, val_MinusLogProbMetric: 40.4906

Epoch 174: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8109 - MinusLogProbMetric: 39.8109 - val_loss: 40.4906 - val_MinusLogProbMetric: 40.4906 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 175/1000
2023-09-13 12:20:23.435 
Epoch 175/1000 
	 loss: 39.8025, MinusLogProbMetric: 39.8025, val_loss: 40.4793, val_MinusLogProbMetric: 40.4793

Epoch 175: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8025 - MinusLogProbMetric: 39.8025 - val_loss: 40.4793 - val_MinusLogProbMetric: 40.4793 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 176/1000
2023-09-13 12:20:35.441 
Epoch 176/1000 
	 loss: 39.8215, MinusLogProbMetric: 39.8215, val_loss: 40.4770, val_MinusLogProbMetric: 40.4770

Epoch 176: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8215 - MinusLogProbMetric: 39.8215 - val_loss: 40.4770 - val_MinusLogProbMetric: 40.4770 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 177/1000
2023-09-13 12:20:46.043 
Epoch 177/1000 
	 loss: 39.8074, MinusLogProbMetric: 39.8074, val_loss: 40.3806, val_MinusLogProbMetric: 40.3806

Epoch 177: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8074 - MinusLogProbMetric: 39.8074 - val_loss: 40.3806 - val_MinusLogProbMetric: 40.3806 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 178/1000
2023-09-13 12:20:58.097 
Epoch 178/1000 
	 loss: 39.8284, MinusLogProbMetric: 39.8284, val_loss: 40.5957, val_MinusLogProbMetric: 40.5957

Epoch 178: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8284 - MinusLogProbMetric: 39.8284 - val_loss: 40.5957 - val_MinusLogProbMetric: 40.5957 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 179/1000
2023-09-13 12:21:08.886 
Epoch 179/1000 
	 loss: 39.7930, MinusLogProbMetric: 39.7930, val_loss: 40.4366, val_MinusLogProbMetric: 40.4366

Epoch 179: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.7930 - MinusLogProbMetric: 39.7930 - val_loss: 40.4366 - val_MinusLogProbMetric: 40.4366 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 180/1000
2023-09-13 12:21:20.027 
Epoch 180/1000 
	 loss: 39.8166, MinusLogProbMetric: 39.8166, val_loss: 40.4619, val_MinusLogProbMetric: 40.4619

Epoch 180: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.8166 - MinusLogProbMetric: 39.8166 - val_loss: 40.4619 - val_MinusLogProbMetric: 40.4619 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 181/1000
2023-09-13 12:21:31.852 
Epoch 181/1000 
	 loss: 39.7953, MinusLogProbMetric: 39.7953, val_loss: 40.3549, val_MinusLogProbMetric: 40.3549

Epoch 181: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.7953 - MinusLogProbMetric: 39.7953 - val_loss: 40.3549 - val_MinusLogProbMetric: 40.3549 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 182/1000
2023-09-13 12:21:43.321 
Epoch 182/1000 
	 loss: 39.7858, MinusLogProbMetric: 39.7858, val_loss: 40.3681, val_MinusLogProbMetric: 40.3681

Epoch 182: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.7858 - MinusLogProbMetric: 39.7858 - val_loss: 40.3681 - val_MinusLogProbMetric: 40.3681 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 183/1000
2023-09-13 12:21:54.815 
Epoch 183/1000 
	 loss: 39.7904, MinusLogProbMetric: 39.7904, val_loss: 40.4396, val_MinusLogProbMetric: 40.4396

Epoch 183: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.7904 - MinusLogProbMetric: 39.7904 - val_loss: 40.4396 - val_MinusLogProbMetric: 40.4396 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 184/1000
2023-09-13 12:22:06.353 
Epoch 184/1000 
	 loss: 39.7720, MinusLogProbMetric: 39.7720, val_loss: 40.4328, val_MinusLogProbMetric: 40.4328

Epoch 184: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.7720 - MinusLogProbMetric: 39.7720 - val_loss: 40.4328 - val_MinusLogProbMetric: 40.4328 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 185/1000
2023-09-13 12:22:18.041 
Epoch 185/1000 
	 loss: 39.8010, MinusLogProbMetric: 39.8010, val_loss: 40.6325, val_MinusLogProbMetric: 40.6325

Epoch 185: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.8010 - MinusLogProbMetric: 39.8010 - val_loss: 40.6325 - val_MinusLogProbMetric: 40.6325 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 186/1000
2023-09-13 12:22:29.896 
Epoch 186/1000 
	 loss: 39.7921, MinusLogProbMetric: 39.7921, val_loss: 40.4376, val_MinusLogProbMetric: 40.4376

Epoch 186: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.7921 - MinusLogProbMetric: 39.7921 - val_loss: 40.4376 - val_MinusLogProbMetric: 40.4376 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 187/1000
2023-09-13 12:22:41.726 
Epoch 187/1000 
	 loss: 39.6164, MinusLogProbMetric: 39.6164, val_loss: 40.3354, val_MinusLogProbMetric: 40.3354

Epoch 187: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.6164 - MinusLogProbMetric: 39.6164 - val_loss: 40.3354 - val_MinusLogProbMetric: 40.3354 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 188/1000
2023-09-13 12:22:53.857 
Epoch 188/1000 
	 loss: 39.5930, MinusLogProbMetric: 39.5930, val_loss: 40.2969, val_MinusLogProbMetric: 40.2969

Epoch 188: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5930 - MinusLogProbMetric: 39.5930 - val_loss: 40.2969 - val_MinusLogProbMetric: 40.2969 - lr: 5.0000e-04 - 12s/epoch - 62ms/step
Epoch 189/1000
2023-09-13 12:23:05.801 
Epoch 189/1000 
	 loss: 39.5941, MinusLogProbMetric: 39.5941, val_loss: 40.2855, val_MinusLogProbMetric: 40.2855

Epoch 189: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5941 - MinusLogProbMetric: 39.5941 - val_loss: 40.2855 - val_MinusLogProbMetric: 40.2855 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 190/1000
2023-09-13 12:23:17.513 
Epoch 190/1000 
	 loss: 39.5856, MinusLogProbMetric: 39.5856, val_loss: 40.3111, val_MinusLogProbMetric: 40.3111

Epoch 190: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5856 - MinusLogProbMetric: 39.5856 - val_loss: 40.3111 - val_MinusLogProbMetric: 40.3111 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-13 12:23:28.187 
Epoch 191/1000 
	 loss: 39.5915, MinusLogProbMetric: 39.5915, val_loss: 40.3247, val_MinusLogProbMetric: 40.3247

Epoch 191: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5915 - MinusLogProbMetric: 39.5915 - val_loss: 40.3247 - val_MinusLogProbMetric: 40.3247 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 192/1000
2023-09-13 12:23:39.184 
Epoch 192/1000 
	 loss: 39.5955, MinusLogProbMetric: 39.5955, val_loss: 40.3675, val_MinusLogProbMetric: 40.3675

Epoch 192: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5955 - MinusLogProbMetric: 39.5955 - val_loss: 40.3675 - val_MinusLogProbMetric: 40.3675 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 193/1000
2023-09-13 12:23:50.055 
Epoch 193/1000 
	 loss: 39.5885, MinusLogProbMetric: 39.5885, val_loss: 40.3048, val_MinusLogProbMetric: 40.3048

Epoch 193: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5885 - MinusLogProbMetric: 39.5885 - val_loss: 40.3048 - val_MinusLogProbMetric: 40.3048 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 194/1000
2023-09-13 12:24:01.731 
Epoch 194/1000 
	 loss: 39.5958, MinusLogProbMetric: 39.5958, val_loss: 40.3413, val_MinusLogProbMetric: 40.3413

Epoch 194: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5958 - MinusLogProbMetric: 39.5958 - val_loss: 40.3413 - val_MinusLogProbMetric: 40.3413 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 195/1000
2023-09-13 12:24:13.183 
Epoch 195/1000 
	 loss: 39.5853, MinusLogProbMetric: 39.5853, val_loss: 40.3478, val_MinusLogProbMetric: 40.3478

Epoch 195: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5853 - MinusLogProbMetric: 39.5853 - val_loss: 40.3478 - val_MinusLogProbMetric: 40.3478 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 196/1000
2023-09-13 12:24:24.830 
Epoch 196/1000 
	 loss: 39.5821, MinusLogProbMetric: 39.5821, val_loss: 40.3376, val_MinusLogProbMetric: 40.3376

Epoch 196: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5821 - MinusLogProbMetric: 39.5821 - val_loss: 40.3376 - val_MinusLogProbMetric: 40.3376 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 197/1000
2023-09-13 12:24:36.629 
Epoch 197/1000 
	 loss: 39.5859, MinusLogProbMetric: 39.5859, val_loss: 40.3230, val_MinusLogProbMetric: 40.3230

Epoch 197: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5859 - MinusLogProbMetric: 39.5859 - val_loss: 40.3230 - val_MinusLogProbMetric: 40.3230 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-13 12:24:48.403 
Epoch 198/1000 
	 loss: 39.5817, MinusLogProbMetric: 39.5817, val_loss: 40.3696, val_MinusLogProbMetric: 40.3696

Epoch 198: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5817 - MinusLogProbMetric: 39.5817 - val_loss: 40.3696 - val_MinusLogProbMetric: 40.3696 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 199/1000
2023-09-13 12:24:59.708 
Epoch 199/1000 
	 loss: 39.5774, MinusLogProbMetric: 39.5774, val_loss: 40.3464, val_MinusLogProbMetric: 40.3464

Epoch 199: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5774 - MinusLogProbMetric: 39.5774 - val_loss: 40.3464 - val_MinusLogProbMetric: 40.3464 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 200/1000
2023-09-13 12:25:11.227 
Epoch 200/1000 
	 loss: 39.5748, MinusLogProbMetric: 39.5748, val_loss: 40.3161, val_MinusLogProbMetric: 40.3161

Epoch 200: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5748 - MinusLogProbMetric: 39.5748 - val_loss: 40.3161 - val_MinusLogProbMetric: 40.3161 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 201/1000
2023-09-13 12:25:23.205 
Epoch 201/1000 
	 loss: 39.5730, MinusLogProbMetric: 39.5730, val_loss: 40.3791, val_MinusLogProbMetric: 40.3791

Epoch 201: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5730 - MinusLogProbMetric: 39.5730 - val_loss: 40.3791 - val_MinusLogProbMetric: 40.3791 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 202/1000
2023-09-13 12:25:34.351 
Epoch 202/1000 
	 loss: 39.5819, MinusLogProbMetric: 39.5819, val_loss: 40.3596, val_MinusLogProbMetric: 40.3596

Epoch 202: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5819 - MinusLogProbMetric: 39.5819 - val_loss: 40.3596 - val_MinusLogProbMetric: 40.3596 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 203/1000
2023-09-13 12:25:45.713 
Epoch 203/1000 
	 loss: 39.5812, MinusLogProbMetric: 39.5812, val_loss: 40.3736, val_MinusLogProbMetric: 40.3736

Epoch 203: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5812 - MinusLogProbMetric: 39.5812 - val_loss: 40.3736 - val_MinusLogProbMetric: 40.3736 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 204/1000
2023-09-13 12:25:57.575 
Epoch 204/1000 
	 loss: 39.5732, MinusLogProbMetric: 39.5732, val_loss: 40.3680, val_MinusLogProbMetric: 40.3680

Epoch 204: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5732 - MinusLogProbMetric: 39.5732 - val_loss: 40.3680 - val_MinusLogProbMetric: 40.3680 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 205/1000
2023-09-13 12:26:09.009 
Epoch 205/1000 
	 loss: 39.5792, MinusLogProbMetric: 39.5792, val_loss: 40.3519, val_MinusLogProbMetric: 40.3519

Epoch 205: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5792 - MinusLogProbMetric: 39.5792 - val_loss: 40.3519 - val_MinusLogProbMetric: 40.3519 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-13 12:26:20.093 
Epoch 206/1000 
	 loss: 39.5719, MinusLogProbMetric: 39.5719, val_loss: 40.3295, val_MinusLogProbMetric: 40.3295

Epoch 206: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5719 - MinusLogProbMetric: 39.5719 - val_loss: 40.3295 - val_MinusLogProbMetric: 40.3295 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 207/1000
2023-09-13 12:26:31.917 
Epoch 207/1000 
	 loss: 39.5746, MinusLogProbMetric: 39.5746, val_loss: 40.3437, val_MinusLogProbMetric: 40.3437

Epoch 207: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5746 - MinusLogProbMetric: 39.5746 - val_loss: 40.3437 - val_MinusLogProbMetric: 40.3437 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 208/1000
2023-09-13 12:26:42.567 
Epoch 208/1000 
	 loss: 39.5656, MinusLogProbMetric: 39.5656, val_loss: 40.3393, val_MinusLogProbMetric: 40.3393

Epoch 208: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5656 - MinusLogProbMetric: 39.5656 - val_loss: 40.3393 - val_MinusLogProbMetric: 40.3393 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 209/1000
2023-09-13 12:26:54.083 
Epoch 209/1000 
	 loss: 39.5617, MinusLogProbMetric: 39.5617, val_loss: 40.3533, val_MinusLogProbMetric: 40.3533

Epoch 209: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5617 - MinusLogProbMetric: 39.5617 - val_loss: 40.3533 - val_MinusLogProbMetric: 40.3533 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 210/1000
2023-09-13 12:27:05.739 
Epoch 210/1000 
	 loss: 39.5622, MinusLogProbMetric: 39.5622, val_loss: 40.3331, val_MinusLogProbMetric: 40.3331

Epoch 210: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5622 - MinusLogProbMetric: 39.5622 - val_loss: 40.3331 - val_MinusLogProbMetric: 40.3331 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 211/1000
2023-09-13 12:27:17.100 
Epoch 211/1000 
	 loss: 39.5648, MinusLogProbMetric: 39.5648, val_loss: 40.4523, val_MinusLogProbMetric: 40.4523

Epoch 211: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5648 - MinusLogProbMetric: 39.5648 - val_loss: 40.4523 - val_MinusLogProbMetric: 40.4523 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 212/1000
2023-09-13 12:27:28.841 
Epoch 212/1000 
	 loss: 39.5647, MinusLogProbMetric: 39.5647, val_loss: 40.3888, val_MinusLogProbMetric: 40.3888

Epoch 212: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5647 - MinusLogProbMetric: 39.5647 - val_loss: 40.3888 - val_MinusLogProbMetric: 40.3888 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 213/1000
2023-09-13 12:27:39.645 
Epoch 213/1000 
	 loss: 39.5606, MinusLogProbMetric: 39.5606, val_loss: 40.4191, val_MinusLogProbMetric: 40.4191

Epoch 213: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5606 - MinusLogProbMetric: 39.5606 - val_loss: 40.4191 - val_MinusLogProbMetric: 40.4191 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 214/1000
2023-09-13 12:27:51.228 
Epoch 214/1000 
	 loss: 39.5761, MinusLogProbMetric: 39.5761, val_loss: 40.3197, val_MinusLogProbMetric: 40.3197

Epoch 214: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5761 - MinusLogProbMetric: 39.5761 - val_loss: 40.3197 - val_MinusLogProbMetric: 40.3197 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 215/1000
2023-09-13 12:28:02.542 
Epoch 215/1000 
	 loss: 39.5614, MinusLogProbMetric: 39.5614, val_loss: 40.3898, val_MinusLogProbMetric: 40.3898

Epoch 215: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5614 - MinusLogProbMetric: 39.5614 - val_loss: 40.3898 - val_MinusLogProbMetric: 40.3898 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 216/1000
2023-09-13 12:28:13.101 
Epoch 216/1000 
	 loss: 39.5662, MinusLogProbMetric: 39.5662, val_loss: 40.4069, val_MinusLogProbMetric: 40.4069

Epoch 216: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5662 - MinusLogProbMetric: 39.5662 - val_loss: 40.4069 - val_MinusLogProbMetric: 40.4069 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 217/1000
2023-09-13 12:28:24.354 
Epoch 217/1000 
	 loss: 39.5515, MinusLogProbMetric: 39.5515, val_loss: 40.3664, val_MinusLogProbMetric: 40.3664

Epoch 217: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5515 - MinusLogProbMetric: 39.5515 - val_loss: 40.3664 - val_MinusLogProbMetric: 40.3664 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 218/1000
2023-09-13 12:28:36.184 
Epoch 218/1000 
	 loss: 39.5508, MinusLogProbMetric: 39.5508, val_loss: 40.3343, val_MinusLogProbMetric: 40.3343

Epoch 218: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5508 - MinusLogProbMetric: 39.5508 - val_loss: 40.3343 - val_MinusLogProbMetric: 40.3343 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 219/1000
2023-09-13 12:28:47.875 
Epoch 219/1000 
	 loss: 39.5457, MinusLogProbMetric: 39.5457, val_loss: 40.3675, val_MinusLogProbMetric: 40.3675

Epoch 219: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5457 - MinusLogProbMetric: 39.5457 - val_loss: 40.3675 - val_MinusLogProbMetric: 40.3675 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 220/1000
2023-09-13 12:28:58.754 
Epoch 220/1000 
	 loss: 39.5559, MinusLogProbMetric: 39.5559, val_loss: 40.3818, val_MinusLogProbMetric: 40.3818

Epoch 220: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5559 - MinusLogProbMetric: 39.5559 - val_loss: 40.3818 - val_MinusLogProbMetric: 40.3818 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 221/1000
2023-09-13 12:29:09.742 
Epoch 221/1000 
	 loss: 39.5479, MinusLogProbMetric: 39.5479, val_loss: 40.3563, val_MinusLogProbMetric: 40.3563

Epoch 221: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5479 - MinusLogProbMetric: 39.5479 - val_loss: 40.3563 - val_MinusLogProbMetric: 40.3563 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 222/1000
2023-09-13 12:29:20.326 
Epoch 222/1000 
	 loss: 39.5490, MinusLogProbMetric: 39.5490, val_loss: 40.3751, val_MinusLogProbMetric: 40.3751

Epoch 222: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5490 - MinusLogProbMetric: 39.5490 - val_loss: 40.3751 - val_MinusLogProbMetric: 40.3751 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 223/1000
2023-09-13 12:29:31.772 
Epoch 223/1000 
	 loss: 39.5486, MinusLogProbMetric: 39.5486, val_loss: 40.5182, val_MinusLogProbMetric: 40.5182

Epoch 223: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5486 - MinusLogProbMetric: 39.5486 - val_loss: 40.5182 - val_MinusLogProbMetric: 40.5182 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 224/1000
2023-09-13 12:29:41.108 
Epoch 224/1000 
	 loss: 39.5423, MinusLogProbMetric: 39.5423, val_loss: 40.3867, val_MinusLogProbMetric: 40.3867

Epoch 224: val_loss did not improve from 40.27925
196/196 - 9s - loss: 39.5423 - MinusLogProbMetric: 39.5423 - val_loss: 40.3867 - val_MinusLogProbMetric: 40.3867 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 225/1000
2023-09-13 12:29:52.513 
Epoch 225/1000 
	 loss: 39.5492, MinusLogProbMetric: 39.5492, val_loss: 40.4215, val_MinusLogProbMetric: 40.4215

Epoch 225: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5492 - MinusLogProbMetric: 39.5492 - val_loss: 40.4215 - val_MinusLogProbMetric: 40.4215 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 226/1000
2023-09-13 12:30:04.176 
Epoch 226/1000 
	 loss: 39.5432, MinusLogProbMetric: 39.5432, val_loss: 40.3382, val_MinusLogProbMetric: 40.3382

Epoch 226: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5432 - MinusLogProbMetric: 39.5432 - val_loss: 40.3382 - val_MinusLogProbMetric: 40.3382 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 227/1000
2023-09-13 12:30:16.134 
Epoch 227/1000 
	 loss: 39.5445, MinusLogProbMetric: 39.5445, val_loss: 40.4208, val_MinusLogProbMetric: 40.4208

Epoch 227: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5445 - MinusLogProbMetric: 39.5445 - val_loss: 40.4208 - val_MinusLogProbMetric: 40.4208 - lr: 5.0000e-04 - 12s/epoch - 61ms/step
Epoch 228/1000
2023-09-13 12:30:27.784 
Epoch 228/1000 
	 loss: 39.5538, MinusLogProbMetric: 39.5538, val_loss: 40.3597, val_MinusLogProbMetric: 40.3597

Epoch 228: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5538 - MinusLogProbMetric: 39.5538 - val_loss: 40.3597 - val_MinusLogProbMetric: 40.3597 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 229/1000
2023-09-13 12:30:38.995 
Epoch 229/1000 
	 loss: 39.5427, MinusLogProbMetric: 39.5427, val_loss: 40.4249, val_MinusLogProbMetric: 40.4249

Epoch 229: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5427 - MinusLogProbMetric: 39.5427 - val_loss: 40.4249 - val_MinusLogProbMetric: 40.4249 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 230/1000
2023-09-13 12:30:50.213 
Epoch 230/1000 
	 loss: 39.5399, MinusLogProbMetric: 39.5399, val_loss: 40.3844, val_MinusLogProbMetric: 40.3844

Epoch 230: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5399 - MinusLogProbMetric: 39.5399 - val_loss: 40.3844 - val_MinusLogProbMetric: 40.3844 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 231/1000
2023-09-13 12:31:01.138 
Epoch 231/1000 
	 loss: 39.5403, MinusLogProbMetric: 39.5403, val_loss: 40.3811, val_MinusLogProbMetric: 40.3811

Epoch 231: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5403 - MinusLogProbMetric: 39.5403 - val_loss: 40.3811 - val_MinusLogProbMetric: 40.3811 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 232/1000
2023-09-13 12:31:12.498 
Epoch 232/1000 
	 loss: 39.5462, MinusLogProbMetric: 39.5462, val_loss: 40.4599, val_MinusLogProbMetric: 40.4599

Epoch 232: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5462 - MinusLogProbMetric: 39.5462 - val_loss: 40.4599 - val_MinusLogProbMetric: 40.4599 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 233/1000
2023-09-13 12:31:23.746 
Epoch 233/1000 
	 loss: 39.5320, MinusLogProbMetric: 39.5320, val_loss: 40.4168, val_MinusLogProbMetric: 40.4168

Epoch 233: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5320 - MinusLogProbMetric: 39.5320 - val_loss: 40.4168 - val_MinusLogProbMetric: 40.4168 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 234/1000
2023-09-13 12:31:35.532 
Epoch 234/1000 
	 loss: 39.5397, MinusLogProbMetric: 39.5397, val_loss: 40.4372, val_MinusLogProbMetric: 40.4372

Epoch 234: val_loss did not improve from 40.27925
196/196 - 12s - loss: 39.5397 - MinusLogProbMetric: 39.5397 - val_loss: 40.4372 - val_MinusLogProbMetric: 40.4372 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 235/1000
2023-09-13 12:31:46.943 
Epoch 235/1000 
	 loss: 39.5407, MinusLogProbMetric: 39.5407, val_loss: 40.3660, val_MinusLogProbMetric: 40.3660

Epoch 235: val_loss did not improve from 40.27925
196/196 - 11s - loss: 39.5407 - MinusLogProbMetric: 39.5407 - val_loss: 40.3660 - val_MinusLogProbMetric: 40.3660 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 236/1000
2023-09-13 12:31:57.205 
Epoch 236/1000 
	 loss: 39.5409, MinusLogProbMetric: 39.5409, val_loss: 40.3970, val_MinusLogProbMetric: 40.3970

Epoch 236: val_loss did not improve from 40.27925
Restoring model weights from the end of the best epoch: 136.
196/196 - 10s - loss: 39.5409 - MinusLogProbMetric: 39.5409 - val_loss: 40.3970 - val_MinusLogProbMetric: 40.3970 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 236: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 13.675566972000524 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
KS tests calculation completed in 5.65072864596732 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2.7089231619611382 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3.105045332806185 seconds.
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
WARNING:root:Too few points to create valid contours
Training succeeded with seed 377.
Model trained in 2610.75 s.

===========
Computing predictions
===========

Computing metrics...
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 976 and retrying.
Warning: Batch size too large. Halving batch size to 500000 and retrying.
Warning: Batch size too large. Halving batch size to 250000 and retrying.
Warning: Batch size too large. Halving batch size to 125000 and retrying.
Warning: Batch size too large. Halving batch size to 62500 and retrying.
Warning: Batch size too large. Halving batch size to 31250 and retrying.
Warning: Batch size too large. Halving batch size to 15625 and retrying.
Warning: Batch size too large. Halving batch size to 7812 and retrying.
Warning: Batch size too large. Halving batch size to 3906 and retrying.
Warning: Batch size too large. Halving batch size to 1953 and retrying.
Warning: Batch size too large. Halving batch size to 976 and retrying.
Metrics computed in 11469.89 s.
Plots done in 94.63 s.
results.txt saved
results.json saved
Results log saved
Model predictions computed in 11564.52 s.
===========
Run 210/360 done in 14176.50 s.
===========

Directory ../../results/MsplineN_new/run_211/ already exists.
Skipping it.
===========
Run 211/360 already exists. Skipping it.
===========

===========
Generating train data for run 212.
===========
Train data generated in 0.20 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 100)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MsplineN_new/run_212/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_212/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.2146864 ,  6.631287  ,  3.8488867 , ...,  8.701448  ,
         9.995869  ,  8.467634  ],
       [ 2.8034534 ,  6.2523446 ,  6.587882  , ...,  0.2610864 ,
         8.289457  ,  0.40014002],
       [ 3.1083388 ,  6.904127  ,  3.8563085 , ...,  9.2451105 ,
         9.438324  ,  9.252335  ],
       ...,
       [ 3.2707572 ,  7.137167  ,  4.15955   , ...,  8.417309  ,
         9.719597  ,  9.971758  ],
       [ 2.9350822 ,  7.2153897 ,  4.6962466 , ...,  8.324518  ,
         9.470934  , 10.1611395 ],
       [ 2.8749945 ,  7.372215  ,  3.7357469 , ...,  8.341062  ,
         9.43408   ,  9.775034  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_MAFspline_of_permute_of_MAFspline", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal", batch_shape=[], event_shape=[100], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_212/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MsplineN_new/run_212
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.377221    7.127741    6.2438807  ...  0.41386062  8.333076
  -0.20018621]
 [ 6.990193    3.6036158   7.2023716  ...  2.5000641   0.24059269
   4.0499587 ]
 [ 4.625933    7.1490397   5.677378   ... -0.07451734  8.288161
   0.11478856]
 ...
 [ 3.0931716   6.40883     3.5263834  ...  9.596216   10.054146
   9.589475  ]
 [ 3.3032775   7.705798    4.4765306  ...  9.215089    9.65445
   9.671152  ]
 [ 5.3625393   6.8024626   6.3470583  ...  0.19077146  8.306975
   0.49249855]]
self.y_data: []
self.ndims: 100
Model defined.
Model: "model_29"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_88 (InputLayer)       [(None, 100)]             0         
                                                                 
 log_prob_layer_29 (LogProbL  (None,)                  2113880   
 ayer)                                                           
                                                                 
=================================================================
Total params: 2,113,880
Trainable params: 2,113,880
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_29/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_29'")
self.model: <keras.engine.functional.Functional object at 0x7fbc12482950>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7fc586a9b2b0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7fc586a9b2b0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7fc586ac0130>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7fc586ac0880>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7fc586ac0df0>, <keras.callbacks.ModelCheckpoint object at 0x7fc586ac0eb0>, <keras.callbacks.EarlyStopping object at 0x7fc586ac1120>, <keras.callbacks.ReduceLROnPlateau object at 0x7fc586ac1150>, <keras.callbacks.TerminateOnNaN object at 0x7fc586ac0d90>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 3.2146864 ,  6.631287  ,  3.8488867 , ...,  8.701448  ,
         9.995869  ,  8.467634  ],
       [ 2.8034534 ,  6.2523446 ,  6.587882  , ...,  0.2610864 ,
         8.289457  ,  0.40014002],
       [ 3.1083388 ,  6.904127  ,  3.8563085 , ...,  9.2451105 ,
         9.438324  ,  9.252335  ],
       ...,
       [ 3.2707572 ,  7.137167  ,  4.15955   , ...,  8.417309  ,
         9.719597  ,  9.971758  ],
       [ 2.9350822 ,  7.2153897 ,  4.6962466 , ...,  8.324518  ,
         9.470934  , 10.1611395 ],
       [ 2.8749945 ,  7.372215  ,  3.7357469 , ...,  8.341062  ,
         9.43408   ,  9.775034  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MsplineN_new/run_212/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 212/360 with hyperparameters:
timestamp = 2023-09-13 15:44:43.147445
ndims = 100
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MsplineN
nbijectors = 2
spline_knots = 12
range_min = -16
hidden_layers = 256-256-256
trainable_parameters = 2113880
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.377221    7.127741    6.2438807   5.435673    4.0165205   6.219049
  4.1100683   8.8912945   8.92213     3.839687    7.2213755   5.307855
  5.647077    9.321208    0.88903034  1.1936541   0.02009015  8.125818
  8.583153    9.655658    9.708242    8.047664    4.635592    7.956708
  0.69603527  6.3117905   0.84046364  9.506726    5.873458    3.812477
  2.5029004   8.513819    4.5791717   5.4547668   0.38966614  5.245923
  6.1506085   6.674606    9.7018795   6.636814    3.3463945   4.644469
  7.275876    0.607445    7.351542    6.6946445   2.4746628   1.2882023
  3.4071944   5.330654    6.1714883   4.4290667   9.648411   -0.15112126
  2.9771137   0.42422986  6.6482043   2.43198     4.204295    4.4230494
  1.6423705   1.2461631   7.064476    1.7268543   3.0895011   4.317311
  8.377744    1.4959692   8.227504    0.34852362  9.020381    4.5677514
 10.634903    5.1945934   7.095311    0.5202157   2.788597    1.1506679
  2.1603026   0.45417947  3.3186061   4.6653333  -0.767903    7.405855
  6.0683556   0.04347444  4.8182964   1.1355917   6.122411    9.17348
  3.1331472   6.9240985   1.4263403   7.782923    2.9285986   1.2252684
  6.0443587   0.41386062  8.333076   -0.20018621]
Epoch 1/1000
2023-09-13 15:45:27.790 
Epoch 1/1000 
	 loss: 130.1994, MinusLogProbMetric: 130.1994, val_loss: 52.4266, val_MinusLogProbMetric: 52.4266

Epoch 1: val_loss improved from inf to 52.42658, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 45s - loss: 130.1994 - MinusLogProbMetric: 130.1994 - val_loss: 52.4266 - val_MinusLogProbMetric: 52.4266 - lr: 0.0010 - 45s/epoch - 228ms/step
Epoch 2/1000
2023-09-13 15:45:39.405 
Epoch 2/1000 
	 loss: 49.2816, MinusLogProbMetric: 49.2816, val_loss: 46.9456, val_MinusLogProbMetric: 46.9456

Epoch 2: val_loss improved from 52.42658 to 46.94564, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 49.2816 - MinusLogProbMetric: 49.2816 - val_loss: 46.9456 - val_MinusLogProbMetric: 46.9456 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 3/1000
2023-09-13 15:45:51.729 
Epoch 3/1000 
	 loss: 46.0136, MinusLogProbMetric: 46.0136, val_loss: 45.2835, val_MinusLogProbMetric: 45.2835

Epoch 3: val_loss improved from 46.94564 to 45.28351, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 46.0136 - MinusLogProbMetric: 46.0136 - val_loss: 45.2835 - val_MinusLogProbMetric: 45.2835 - lr: 0.0010 - 12s/epoch - 63ms/step
Epoch 4/1000
2023-09-13 15:46:04.050 
Epoch 4/1000 
	 loss: 44.4710, MinusLogProbMetric: 44.4710, val_loss: 45.3815, val_MinusLogProbMetric: 45.3815

Epoch 4: val_loss did not improve from 45.28351
196/196 - 12s - loss: 44.4710 - MinusLogProbMetric: 44.4710 - val_loss: 45.3815 - val_MinusLogProbMetric: 45.3815 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 5/1000
2023-09-13 15:46:14.644 
Epoch 5/1000 
	 loss: 43.7863, MinusLogProbMetric: 43.7863, val_loss: 43.2214, val_MinusLogProbMetric: 43.2214

Epoch 5: val_loss improved from 45.28351 to 43.22144, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 43.7863 - MinusLogProbMetric: 43.7863 - val_loss: 43.2214 - val_MinusLogProbMetric: 43.2214 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 6/1000
2023-09-13 15:46:26.163 
Epoch 6/1000 
	 loss: 43.1808, MinusLogProbMetric: 43.1808, val_loss: 42.8011, val_MinusLogProbMetric: 42.8011

Epoch 6: val_loss improved from 43.22144 to 42.80107, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 43.1808 - MinusLogProbMetric: 43.1808 - val_loss: 42.8011 - val_MinusLogProbMetric: 42.8011 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 7/1000
2023-09-13 15:46:37.660 
Epoch 7/1000 
	 loss: 42.8453, MinusLogProbMetric: 42.8453, val_loss: 43.1366, val_MinusLogProbMetric: 43.1366

Epoch 7: val_loss did not improve from 42.80107
196/196 - 11s - loss: 42.8453 - MinusLogProbMetric: 42.8453 - val_loss: 43.1366 - val_MinusLogProbMetric: 43.1366 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 8/1000
2023-09-13 15:46:47.561 
Epoch 8/1000 
	 loss: 42.8309, MinusLogProbMetric: 42.8309, val_loss: 43.7689, val_MinusLogProbMetric: 43.7689

Epoch 8: val_loss did not improve from 42.80107
196/196 - 10s - loss: 42.8309 - MinusLogProbMetric: 42.8309 - val_loss: 43.7689 - val_MinusLogProbMetric: 43.7689 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 9/1000
2023-09-13 15:46:59.281 
Epoch 9/1000 
	 loss: 42.4438, MinusLogProbMetric: 42.4438, val_loss: 42.6916, val_MinusLogProbMetric: 42.6916

Epoch 9: val_loss improved from 42.80107 to 42.69164, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 42.4438 - MinusLogProbMetric: 42.4438 - val_loss: 42.6916 - val_MinusLogProbMetric: 42.6916 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-13 15:47:11.401 
Epoch 10/1000 
	 loss: 42.2803, MinusLogProbMetric: 42.2803, val_loss: 43.2684, val_MinusLogProbMetric: 43.2684

Epoch 10: val_loss did not improve from 42.69164
196/196 - 12s - loss: 42.2803 - MinusLogProbMetric: 42.2803 - val_loss: 43.2684 - val_MinusLogProbMetric: 43.2684 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 11/1000
2023-09-13 15:47:22.591 
Epoch 11/1000 
	 loss: 41.9742, MinusLogProbMetric: 41.9742, val_loss: 41.7138, val_MinusLogProbMetric: 41.7138

Epoch 11: val_loss improved from 42.69164 to 41.71376, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 41.9742 - MinusLogProbMetric: 41.9742 - val_loss: 41.7138 - val_MinusLogProbMetric: 41.7138 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 12/1000
2023-09-13 15:47:34.779 
Epoch 12/1000 
	 loss: 41.6537, MinusLogProbMetric: 41.6537, val_loss: 41.4373, val_MinusLogProbMetric: 41.4373

Epoch 12: val_loss improved from 41.71376 to 41.43728, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 41.6537 - MinusLogProbMetric: 41.6537 - val_loss: 41.4373 - val_MinusLogProbMetric: 41.4373 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 13/1000
2023-09-13 15:47:46.908 
Epoch 13/1000 
	 loss: 41.8943, MinusLogProbMetric: 41.8943, val_loss: 41.8440, val_MinusLogProbMetric: 41.8440

Epoch 13: val_loss did not improve from 41.43728
196/196 - 12s - loss: 41.8943 - MinusLogProbMetric: 41.8943 - val_loss: 41.8440 - val_MinusLogProbMetric: 41.8440 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 14/1000
2023-09-13 15:47:58.613 
Epoch 14/1000 
	 loss: 41.7417, MinusLogProbMetric: 41.7417, val_loss: 41.4839, val_MinusLogProbMetric: 41.4839

Epoch 14: val_loss did not improve from 41.43728
196/196 - 12s - loss: 41.7417 - MinusLogProbMetric: 41.7417 - val_loss: 41.4839 - val_MinusLogProbMetric: 41.4839 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 15/1000
2023-09-13 15:48:10.438 
Epoch 15/1000 
	 loss: 41.6679, MinusLogProbMetric: 41.6679, val_loss: 41.8235, val_MinusLogProbMetric: 41.8235

Epoch 15: val_loss did not improve from 41.43728
196/196 - 12s - loss: 41.6679 - MinusLogProbMetric: 41.6679 - val_loss: 41.8235 - val_MinusLogProbMetric: 41.8235 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 16/1000
2023-09-13 15:48:20.699 
Epoch 16/1000 
	 loss: 41.4213, MinusLogProbMetric: 41.4213, val_loss: 42.0592, val_MinusLogProbMetric: 42.0592

Epoch 16: val_loss did not improve from 41.43728
196/196 - 10s - loss: 41.4213 - MinusLogProbMetric: 41.4213 - val_loss: 42.0592 - val_MinusLogProbMetric: 42.0592 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 17/1000
2023-09-13 15:48:31.906 
Epoch 17/1000 
	 loss: 41.3978, MinusLogProbMetric: 41.3978, val_loss: 41.5377, val_MinusLogProbMetric: 41.5377

Epoch 17: val_loss did not improve from 41.43728
196/196 - 11s - loss: 41.3978 - MinusLogProbMetric: 41.3978 - val_loss: 41.5377 - val_MinusLogProbMetric: 41.5377 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 18/1000
2023-09-13 15:48:43.383 
Epoch 18/1000 
	 loss: 41.4070, MinusLogProbMetric: 41.4070, val_loss: 41.1720, val_MinusLogProbMetric: 41.1720

Epoch 18: val_loss improved from 41.43728 to 41.17197, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 41.4070 - MinusLogProbMetric: 41.4070 - val_loss: 41.1720 - val_MinusLogProbMetric: 41.1720 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 19/1000
2023-09-13 15:48:54.716 
Epoch 19/1000 
	 loss: 41.1523, MinusLogProbMetric: 41.1523, val_loss: 41.0128, val_MinusLogProbMetric: 41.0128

Epoch 19: val_loss improved from 41.17197 to 41.01284, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 41.1523 - MinusLogProbMetric: 41.1523 - val_loss: 41.0128 - val_MinusLogProbMetric: 41.0128 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 20/1000
2023-09-13 15:49:04.591 
Epoch 20/1000 
	 loss: 41.1904, MinusLogProbMetric: 41.1904, val_loss: 41.1694, val_MinusLogProbMetric: 41.1694

Epoch 20: val_loss did not improve from 41.01284
196/196 - 10s - loss: 41.1904 - MinusLogProbMetric: 41.1904 - val_loss: 41.1694 - val_MinusLogProbMetric: 41.1694 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 21/1000
2023-09-13 15:49:16.220 
Epoch 21/1000 
	 loss: 41.0352, MinusLogProbMetric: 41.0352, val_loss: 40.9701, val_MinusLogProbMetric: 40.9701

Epoch 21: val_loss improved from 41.01284 to 40.97010, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 41.0352 - MinusLogProbMetric: 41.0352 - val_loss: 40.9701 - val_MinusLogProbMetric: 40.9701 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 22/1000
2023-09-13 15:49:27.053 
Epoch 22/1000 
	 loss: 40.8977, MinusLogProbMetric: 40.8977, val_loss: 41.8687, val_MinusLogProbMetric: 41.8687

Epoch 22: val_loss did not improve from 40.97010
196/196 - 11s - loss: 40.8977 - MinusLogProbMetric: 40.8977 - val_loss: 41.8687 - val_MinusLogProbMetric: 41.8687 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 23/1000
2023-09-13 15:49:38.584 
Epoch 23/1000 
	 loss: 40.9628, MinusLogProbMetric: 40.9628, val_loss: 40.8171, val_MinusLogProbMetric: 40.8171

Epoch 23: val_loss improved from 40.97010 to 40.81713, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.9628 - MinusLogProbMetric: 40.9628 - val_loss: 40.8171 - val_MinusLogProbMetric: 40.8171 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 24/1000
2023-09-13 15:49:50.102 
Epoch 24/1000 
	 loss: 40.9290, MinusLogProbMetric: 40.9290, val_loss: 41.0147, val_MinusLogProbMetric: 41.0147

Epoch 24: val_loss did not improve from 40.81713
196/196 - 11s - loss: 40.9290 - MinusLogProbMetric: 40.9290 - val_loss: 41.0147 - val_MinusLogProbMetric: 41.0147 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 25/1000
2023-09-13 15:50:01.816 
Epoch 25/1000 
	 loss: 40.8341, MinusLogProbMetric: 40.8341, val_loss: 41.3021, val_MinusLogProbMetric: 41.3021

Epoch 25: val_loss did not improve from 40.81713
196/196 - 12s - loss: 40.8341 - MinusLogProbMetric: 40.8341 - val_loss: 41.3021 - val_MinusLogProbMetric: 41.3021 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 26/1000
2023-09-13 15:50:13.538 
Epoch 26/1000 
	 loss: 40.8359, MinusLogProbMetric: 40.8359, val_loss: 40.7240, val_MinusLogProbMetric: 40.7240

Epoch 26: val_loss improved from 40.81713 to 40.72399, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.8359 - MinusLogProbMetric: 40.8359 - val_loss: 40.7240 - val_MinusLogProbMetric: 40.7240 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 27/1000
2023-09-13 15:50:24.042 
Epoch 27/1000 
	 loss: 40.7998, MinusLogProbMetric: 40.7998, val_loss: 40.9085, val_MinusLogProbMetric: 40.9085

Epoch 27: val_loss did not improve from 40.72399
196/196 - 10s - loss: 40.7998 - MinusLogProbMetric: 40.7998 - val_loss: 40.9085 - val_MinusLogProbMetric: 40.9085 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 28/1000
2023-09-13 15:50:34.032 
Epoch 28/1000 
	 loss: 40.6980, MinusLogProbMetric: 40.6980, val_loss: 41.0262, val_MinusLogProbMetric: 41.0262

Epoch 28: val_loss did not improve from 40.72399
196/196 - 10s - loss: 40.6980 - MinusLogProbMetric: 40.6980 - val_loss: 41.0262 - val_MinusLogProbMetric: 41.0262 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 29/1000
2023-09-13 15:50:43.926 
Epoch 29/1000 
	 loss: 40.6545, MinusLogProbMetric: 40.6545, val_loss: 40.6699, val_MinusLogProbMetric: 40.6699

Epoch 29: val_loss improved from 40.72399 to 40.66990, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 10s - loss: 40.6545 - MinusLogProbMetric: 40.6545 - val_loss: 40.6699 - val_MinusLogProbMetric: 40.6699 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 30/1000
2023-09-13 15:50:55.865 
Epoch 30/1000 
	 loss: 40.6779, MinusLogProbMetric: 40.6779, val_loss: 40.6377, val_MinusLogProbMetric: 40.6377

Epoch 30: val_loss improved from 40.66990 to 40.63769, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.6779 - MinusLogProbMetric: 40.6779 - val_loss: 40.6377 - val_MinusLogProbMetric: 40.6377 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 31/1000
2023-09-13 15:51:07.920 
Epoch 31/1000 
	 loss: 40.7521, MinusLogProbMetric: 40.7521, val_loss: 40.8846, val_MinusLogProbMetric: 40.8846

Epoch 31: val_loss did not improve from 40.63769
196/196 - 12s - loss: 40.7521 - MinusLogProbMetric: 40.7521 - val_loss: 40.8846 - val_MinusLogProbMetric: 40.8846 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 32/1000
2023-09-13 15:51:19.001 
Epoch 32/1000 
	 loss: 40.6654, MinusLogProbMetric: 40.6654, val_loss: 40.6047, val_MinusLogProbMetric: 40.6047

Epoch 32: val_loss improved from 40.63769 to 40.60473, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 40.6654 - MinusLogProbMetric: 40.6654 - val_loss: 40.6047 - val_MinusLogProbMetric: 40.6047 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 33/1000
2023-09-13 15:51:29.708 
Epoch 33/1000 
	 loss: 40.5969, MinusLogProbMetric: 40.5969, val_loss: 40.5323, val_MinusLogProbMetric: 40.5323

Epoch 33: val_loss improved from 40.60473 to 40.53231, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 40.5969 - MinusLogProbMetric: 40.5969 - val_loss: 40.5323 - val_MinusLogProbMetric: 40.5323 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 34/1000
2023-09-13 15:51:39.550 
Epoch 34/1000 
	 loss: 40.6013, MinusLogProbMetric: 40.6013, val_loss: 40.6785, val_MinusLogProbMetric: 40.6785

Epoch 34: val_loss did not improve from 40.53231
196/196 - 10s - loss: 40.6013 - MinusLogProbMetric: 40.6013 - val_loss: 40.6785 - val_MinusLogProbMetric: 40.6785 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 35/1000
2023-09-13 15:51:50.856 
Epoch 35/1000 
	 loss: 40.5425, MinusLogProbMetric: 40.5425, val_loss: 40.9188, val_MinusLogProbMetric: 40.9188

Epoch 35: val_loss did not improve from 40.53231
196/196 - 11s - loss: 40.5425 - MinusLogProbMetric: 40.5425 - val_loss: 40.9188 - val_MinusLogProbMetric: 40.9188 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 36/1000
2023-09-13 15:52:02.741 
Epoch 36/1000 
	 loss: 40.5578, MinusLogProbMetric: 40.5578, val_loss: 40.5171, val_MinusLogProbMetric: 40.5171

Epoch 36: val_loss improved from 40.53231 to 40.51713, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.5578 - MinusLogProbMetric: 40.5578 - val_loss: 40.5171 - val_MinusLogProbMetric: 40.5171 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 37/1000
2023-09-13 15:52:12.388 
Epoch 37/1000 
	 loss: 40.5797, MinusLogProbMetric: 40.5797, val_loss: 40.6929, val_MinusLogProbMetric: 40.6929

Epoch 37: val_loss did not improve from 40.51713
196/196 - 9s - loss: 40.5797 - MinusLogProbMetric: 40.5797 - val_loss: 40.6929 - val_MinusLogProbMetric: 40.6929 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 38/1000
2023-09-13 15:52:21.775 
Epoch 38/1000 
	 loss: 40.5017, MinusLogProbMetric: 40.5017, val_loss: 40.5837, val_MinusLogProbMetric: 40.5837

Epoch 38: val_loss did not improve from 40.51713
196/196 - 9s - loss: 40.5017 - MinusLogProbMetric: 40.5017 - val_loss: 40.5837 - val_MinusLogProbMetric: 40.5837 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 39/1000
2023-09-13 15:52:31.139 
Epoch 39/1000 
	 loss: 40.4908, MinusLogProbMetric: 40.4908, val_loss: 41.2403, val_MinusLogProbMetric: 41.2403

Epoch 39: val_loss did not improve from 40.51713
196/196 - 9s - loss: 40.4908 - MinusLogProbMetric: 40.4908 - val_loss: 41.2403 - val_MinusLogProbMetric: 41.2403 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 40/1000
2023-09-13 15:52:40.676 
Epoch 40/1000 
	 loss: 40.4988, MinusLogProbMetric: 40.4988, val_loss: 40.5718, val_MinusLogProbMetric: 40.5718

Epoch 40: val_loss did not improve from 40.51713
196/196 - 10s - loss: 40.4988 - MinusLogProbMetric: 40.4988 - val_loss: 40.5718 - val_MinusLogProbMetric: 40.5718 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 41/1000
2023-09-13 15:52:50.136 
Epoch 41/1000 
	 loss: 40.4288, MinusLogProbMetric: 40.4288, val_loss: 40.6484, val_MinusLogProbMetric: 40.6484

Epoch 41: val_loss did not improve from 40.51713
196/196 - 9s - loss: 40.4288 - MinusLogProbMetric: 40.4288 - val_loss: 40.6484 - val_MinusLogProbMetric: 40.6484 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 42/1000
2023-09-13 15:52:59.661 
Epoch 42/1000 
	 loss: 40.4459, MinusLogProbMetric: 40.4459, val_loss: 40.7854, val_MinusLogProbMetric: 40.7854

Epoch 42: val_loss did not improve from 40.51713
196/196 - 10s - loss: 40.4459 - MinusLogProbMetric: 40.4459 - val_loss: 40.7854 - val_MinusLogProbMetric: 40.7854 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 43/1000
2023-09-13 15:53:09.287 
Epoch 43/1000 
	 loss: 40.4319, MinusLogProbMetric: 40.4319, val_loss: 40.4604, val_MinusLogProbMetric: 40.4604

Epoch 43: val_loss improved from 40.51713 to 40.46041, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 10s - loss: 40.4319 - MinusLogProbMetric: 40.4319 - val_loss: 40.4604 - val_MinusLogProbMetric: 40.4604 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 44/1000
2023-09-13 15:53:18.733 
Epoch 44/1000 
	 loss: 40.4471, MinusLogProbMetric: 40.4471, val_loss: 40.6513, val_MinusLogProbMetric: 40.6513

Epoch 44: val_loss did not improve from 40.46041
196/196 - 9s - loss: 40.4471 - MinusLogProbMetric: 40.4471 - val_loss: 40.6513 - val_MinusLogProbMetric: 40.6513 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 45/1000
2023-09-13 15:53:29.475 
Epoch 45/1000 
	 loss: 40.3763, MinusLogProbMetric: 40.3763, val_loss: 40.5636, val_MinusLogProbMetric: 40.5636

Epoch 45: val_loss did not improve from 40.46041
196/196 - 11s - loss: 40.3763 - MinusLogProbMetric: 40.3763 - val_loss: 40.5636 - val_MinusLogProbMetric: 40.5636 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 46/1000
2023-09-13 15:53:41.635 
Epoch 46/1000 
	 loss: 40.3678, MinusLogProbMetric: 40.3678, val_loss: 40.9100, val_MinusLogProbMetric: 40.9100

Epoch 46: val_loss did not improve from 40.46041
196/196 - 12s - loss: 40.3678 - MinusLogProbMetric: 40.3678 - val_loss: 40.9100 - val_MinusLogProbMetric: 40.9100 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 47/1000
2023-09-13 15:53:52.333 
Epoch 47/1000 
	 loss: 40.3924, MinusLogProbMetric: 40.3924, val_loss: 40.6133, val_MinusLogProbMetric: 40.6133

Epoch 47: val_loss did not improve from 40.46041
196/196 - 11s - loss: 40.3924 - MinusLogProbMetric: 40.3924 - val_loss: 40.6133 - val_MinusLogProbMetric: 40.6133 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 48/1000
2023-09-13 15:54:02.343 
Epoch 48/1000 
	 loss: 40.3974, MinusLogProbMetric: 40.3974, val_loss: 40.4104, val_MinusLogProbMetric: 40.4104

Epoch 48: val_loss improved from 40.46041 to 40.41037, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 10s - loss: 40.3974 - MinusLogProbMetric: 40.3974 - val_loss: 40.4104 - val_MinusLogProbMetric: 40.4104 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 49/1000
2023-09-13 15:54:14.206 
Epoch 49/1000 
	 loss: 40.3961, MinusLogProbMetric: 40.3961, val_loss: 41.0226, val_MinusLogProbMetric: 41.0226

Epoch 49: val_loss did not improve from 40.41037
196/196 - 12s - loss: 40.3961 - MinusLogProbMetric: 40.3961 - val_loss: 41.0226 - val_MinusLogProbMetric: 41.0226 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 50/1000
2023-09-13 15:54:25.213 
Epoch 50/1000 
	 loss: 40.3502, MinusLogProbMetric: 40.3502, val_loss: 40.4521, val_MinusLogProbMetric: 40.4521

Epoch 50: val_loss did not improve from 40.41037
196/196 - 11s - loss: 40.3502 - MinusLogProbMetric: 40.3502 - val_loss: 40.4521 - val_MinusLogProbMetric: 40.4521 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 51/1000
2023-09-13 15:54:34.939 
Epoch 51/1000 
	 loss: 40.3367, MinusLogProbMetric: 40.3367, val_loss: 40.6153, val_MinusLogProbMetric: 40.6153

Epoch 51: val_loss did not improve from 40.41037
196/196 - 10s - loss: 40.3367 - MinusLogProbMetric: 40.3367 - val_loss: 40.6153 - val_MinusLogProbMetric: 40.6153 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 52/1000
2023-09-13 15:54:44.546 
Epoch 52/1000 
	 loss: 40.3184, MinusLogProbMetric: 40.3184, val_loss: 40.4577, val_MinusLogProbMetric: 40.4577

Epoch 52: val_loss did not improve from 40.41037
196/196 - 10s - loss: 40.3184 - MinusLogProbMetric: 40.3184 - val_loss: 40.4577 - val_MinusLogProbMetric: 40.4577 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 53/1000
2023-09-13 15:54:54.120 
Epoch 53/1000 
	 loss: 40.3320, MinusLogProbMetric: 40.3320, val_loss: 40.6823, val_MinusLogProbMetric: 40.6823

Epoch 53: val_loss did not improve from 40.41037
196/196 - 10s - loss: 40.3320 - MinusLogProbMetric: 40.3320 - val_loss: 40.6823 - val_MinusLogProbMetric: 40.6823 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 54/1000
2023-09-13 15:55:04.105 
Epoch 54/1000 
	 loss: 40.2842, MinusLogProbMetric: 40.2842, val_loss: 40.4915, val_MinusLogProbMetric: 40.4915

Epoch 54: val_loss did not improve from 40.41037
196/196 - 10s - loss: 40.2842 - MinusLogProbMetric: 40.2842 - val_loss: 40.4915 - val_MinusLogProbMetric: 40.4915 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 55/1000
2023-09-13 15:55:15.845 
Epoch 55/1000 
	 loss: 40.3064, MinusLogProbMetric: 40.3064, val_loss: 40.4496, val_MinusLogProbMetric: 40.4496

Epoch 55: val_loss did not improve from 40.41037
196/196 - 12s - loss: 40.3064 - MinusLogProbMetric: 40.3064 - val_loss: 40.4496 - val_MinusLogProbMetric: 40.4496 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 56/1000
2023-09-13 15:55:27.470 
Epoch 56/1000 
	 loss: 40.2944, MinusLogProbMetric: 40.2944, val_loss: 40.5992, val_MinusLogProbMetric: 40.5992

Epoch 56: val_loss did not improve from 40.41037
196/196 - 12s - loss: 40.2944 - MinusLogProbMetric: 40.2944 - val_loss: 40.5992 - val_MinusLogProbMetric: 40.5992 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 57/1000
2023-09-13 15:55:38.123 
Epoch 57/1000 
	 loss: 40.2654, MinusLogProbMetric: 40.2654, val_loss: 40.5582, val_MinusLogProbMetric: 40.5582

Epoch 57: val_loss did not improve from 40.41037
196/196 - 11s - loss: 40.2654 - MinusLogProbMetric: 40.2654 - val_loss: 40.5582 - val_MinusLogProbMetric: 40.5582 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 58/1000
2023-09-13 15:55:47.699 
Epoch 58/1000 
	 loss: 40.2627, MinusLogProbMetric: 40.2627, val_loss: 40.4016, val_MinusLogProbMetric: 40.4016

Epoch 58: val_loss improved from 40.41037 to 40.40160, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 10s - loss: 40.2627 - MinusLogProbMetric: 40.2627 - val_loss: 40.4016 - val_MinusLogProbMetric: 40.4016 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 59/1000
2023-09-13 15:55:57.198 
Epoch 59/1000 
	 loss: 40.2792, MinusLogProbMetric: 40.2792, val_loss: 40.6262, val_MinusLogProbMetric: 40.6262

Epoch 59: val_loss did not improve from 40.40160
196/196 - 9s - loss: 40.2792 - MinusLogProbMetric: 40.2792 - val_loss: 40.6262 - val_MinusLogProbMetric: 40.6262 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 60/1000
2023-09-13 15:56:08.436 
Epoch 60/1000 
	 loss: 40.2301, MinusLogProbMetric: 40.2301, val_loss: 40.3794, val_MinusLogProbMetric: 40.3794

Epoch 60: val_loss improved from 40.40160 to 40.37938, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 40.2301 - MinusLogProbMetric: 40.2301 - val_loss: 40.3794 - val_MinusLogProbMetric: 40.3794 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 61/1000
2023-09-13 15:56:20.376 
Epoch 61/1000 
	 loss: 40.2224, MinusLogProbMetric: 40.2224, val_loss: 40.6058, val_MinusLogProbMetric: 40.6058

Epoch 61: val_loss did not improve from 40.37938
196/196 - 12s - loss: 40.2224 - MinusLogProbMetric: 40.2224 - val_loss: 40.6058 - val_MinusLogProbMetric: 40.6058 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 62/1000
2023-09-13 15:56:32.047 
Epoch 62/1000 
	 loss: 40.2447, MinusLogProbMetric: 40.2447, val_loss: 40.3673, val_MinusLogProbMetric: 40.3673

Epoch 62: val_loss improved from 40.37938 to 40.36729, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.2447 - MinusLogProbMetric: 40.2447 - val_loss: 40.3673 - val_MinusLogProbMetric: 40.3673 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 63/1000
2023-09-13 15:56:43.965 
Epoch 63/1000 
	 loss: 40.2563, MinusLogProbMetric: 40.2563, val_loss: 40.4741, val_MinusLogProbMetric: 40.4741

Epoch 63: val_loss did not improve from 40.36729
196/196 - 12s - loss: 40.2563 - MinusLogProbMetric: 40.2563 - val_loss: 40.4741 - val_MinusLogProbMetric: 40.4741 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 64/1000
2023-09-13 15:56:55.908 
Epoch 64/1000 
	 loss: 40.2293, MinusLogProbMetric: 40.2293, val_loss: 40.6264, val_MinusLogProbMetric: 40.6264

Epoch 64: val_loss did not improve from 40.36729
196/196 - 12s - loss: 40.2293 - MinusLogProbMetric: 40.2293 - val_loss: 40.6264 - val_MinusLogProbMetric: 40.6264 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 65/1000
2023-09-13 15:57:08.006 
Epoch 65/1000 
	 loss: 40.2143, MinusLogProbMetric: 40.2143, val_loss: 40.4277, val_MinusLogProbMetric: 40.4277

Epoch 65: val_loss did not improve from 40.36729
196/196 - 12s - loss: 40.2143 - MinusLogProbMetric: 40.2143 - val_loss: 40.4277 - val_MinusLogProbMetric: 40.4277 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 66/1000
2023-09-13 15:57:17.880 
Epoch 66/1000 
	 loss: 40.1799, MinusLogProbMetric: 40.1799, val_loss: 40.4410, val_MinusLogProbMetric: 40.4410

Epoch 66: val_loss did not improve from 40.36729
196/196 - 10s - loss: 40.1799 - MinusLogProbMetric: 40.1799 - val_loss: 40.4410 - val_MinusLogProbMetric: 40.4410 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 67/1000
2023-09-13 15:57:27.409 
Epoch 67/1000 
	 loss: 40.1682, MinusLogProbMetric: 40.1682, val_loss: 40.4820, val_MinusLogProbMetric: 40.4820

Epoch 67: val_loss did not improve from 40.36729
196/196 - 10s - loss: 40.1682 - MinusLogProbMetric: 40.1682 - val_loss: 40.4820 - val_MinusLogProbMetric: 40.4820 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 68/1000
2023-09-13 15:57:39.039 
Epoch 68/1000 
	 loss: 40.2125, MinusLogProbMetric: 40.2125, val_loss: 40.5728, val_MinusLogProbMetric: 40.5728

Epoch 68: val_loss did not improve from 40.36729
196/196 - 12s - loss: 40.2125 - MinusLogProbMetric: 40.2125 - val_loss: 40.5728 - val_MinusLogProbMetric: 40.5728 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-13 15:57:50.551 
Epoch 69/1000 
	 loss: 40.2362, MinusLogProbMetric: 40.2362, val_loss: 40.3578, val_MinusLogProbMetric: 40.3578

Epoch 69: val_loss improved from 40.36729 to 40.35784, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.2362 - MinusLogProbMetric: 40.2362 - val_loss: 40.3578 - val_MinusLogProbMetric: 40.3578 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 70/1000
2023-09-13 15:58:02.478 
Epoch 70/1000 
	 loss: 40.1641, MinusLogProbMetric: 40.1641, val_loss: 40.4388, val_MinusLogProbMetric: 40.4388

Epoch 70: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1641 - MinusLogProbMetric: 40.1641 - val_loss: 40.4388 - val_MinusLogProbMetric: 40.4388 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 71/1000
2023-09-13 15:58:13.518 
Epoch 71/1000 
	 loss: 40.1706, MinusLogProbMetric: 40.1706, val_loss: 40.6955, val_MinusLogProbMetric: 40.6955

Epoch 71: val_loss did not improve from 40.35784
196/196 - 11s - loss: 40.1706 - MinusLogProbMetric: 40.1706 - val_loss: 40.6955 - val_MinusLogProbMetric: 40.6955 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 72/1000
2023-09-13 15:58:23.437 
Epoch 72/1000 
	 loss: 40.1673, MinusLogProbMetric: 40.1673, val_loss: 40.4106, val_MinusLogProbMetric: 40.4106

Epoch 72: val_loss did not improve from 40.35784
196/196 - 10s - loss: 40.1673 - MinusLogProbMetric: 40.1673 - val_loss: 40.4106 - val_MinusLogProbMetric: 40.4106 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 73/1000
2023-09-13 15:58:35.395 
Epoch 73/1000 
	 loss: 40.1403, MinusLogProbMetric: 40.1403, val_loss: 40.3961, val_MinusLogProbMetric: 40.3961

Epoch 73: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1403 - MinusLogProbMetric: 40.1403 - val_loss: 40.3961 - val_MinusLogProbMetric: 40.3961 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 74/1000
2023-09-13 15:58:46.569 
Epoch 74/1000 
	 loss: 40.1425, MinusLogProbMetric: 40.1425, val_loss: 40.5585, val_MinusLogProbMetric: 40.5585

Epoch 74: val_loss did not improve from 40.35784
196/196 - 11s - loss: 40.1425 - MinusLogProbMetric: 40.1425 - val_loss: 40.5585 - val_MinusLogProbMetric: 40.5585 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 75/1000
2023-09-13 15:58:56.626 
Epoch 75/1000 
	 loss: 40.1821, MinusLogProbMetric: 40.1821, val_loss: 40.4506, val_MinusLogProbMetric: 40.4506

Epoch 75: val_loss did not improve from 40.35784
196/196 - 10s - loss: 40.1821 - MinusLogProbMetric: 40.1821 - val_loss: 40.4506 - val_MinusLogProbMetric: 40.4506 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 76/1000
2023-09-13 15:59:08.451 
Epoch 76/1000 
	 loss: 40.1328, MinusLogProbMetric: 40.1328, val_loss: 40.5190, val_MinusLogProbMetric: 40.5190

Epoch 76: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1328 - MinusLogProbMetric: 40.1328 - val_loss: 40.5190 - val_MinusLogProbMetric: 40.5190 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 77/1000
2023-09-13 15:59:20.203 
Epoch 77/1000 
	 loss: 40.1245, MinusLogProbMetric: 40.1245, val_loss: 40.7781, val_MinusLogProbMetric: 40.7781

Epoch 77: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1245 - MinusLogProbMetric: 40.1245 - val_loss: 40.7781 - val_MinusLogProbMetric: 40.7781 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 78/1000
2023-09-13 15:59:32.096 
Epoch 78/1000 
	 loss: 40.1525, MinusLogProbMetric: 40.1525, val_loss: 40.5119, val_MinusLogProbMetric: 40.5119

Epoch 78: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1525 - MinusLogProbMetric: 40.1525 - val_loss: 40.5119 - val_MinusLogProbMetric: 40.5119 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 79/1000
2023-09-13 15:59:43.536 
Epoch 79/1000 
	 loss: 40.0996, MinusLogProbMetric: 40.0996, val_loss: 40.3666, val_MinusLogProbMetric: 40.3666

Epoch 79: val_loss did not improve from 40.35784
196/196 - 11s - loss: 40.0996 - MinusLogProbMetric: 40.0996 - val_loss: 40.3666 - val_MinusLogProbMetric: 40.3666 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 80/1000
2023-09-13 15:59:55.157 
Epoch 80/1000 
	 loss: 40.1113, MinusLogProbMetric: 40.1113, val_loss: 40.4438, val_MinusLogProbMetric: 40.4438

Epoch 80: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1113 - MinusLogProbMetric: 40.1113 - val_loss: 40.4438 - val_MinusLogProbMetric: 40.4438 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 81/1000
2023-09-13 16:00:06.853 
Epoch 81/1000 
	 loss: 40.1178, MinusLogProbMetric: 40.1178, val_loss: 40.6776, val_MinusLogProbMetric: 40.6776

Epoch 81: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1178 - MinusLogProbMetric: 40.1178 - val_loss: 40.6776 - val_MinusLogProbMetric: 40.6776 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 82/1000
2023-09-13 16:00:18.670 
Epoch 82/1000 
	 loss: 40.0899, MinusLogProbMetric: 40.0899, val_loss: 40.4133, val_MinusLogProbMetric: 40.4133

Epoch 82: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.0899 - MinusLogProbMetric: 40.0899 - val_loss: 40.4133 - val_MinusLogProbMetric: 40.4133 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 83/1000
2023-09-13 16:00:30.345 
Epoch 83/1000 
	 loss: 40.0921, MinusLogProbMetric: 40.0921, val_loss: 40.5032, val_MinusLogProbMetric: 40.5032

Epoch 83: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.0921 - MinusLogProbMetric: 40.0921 - val_loss: 40.5032 - val_MinusLogProbMetric: 40.5032 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 84/1000
2023-09-13 16:00:42.238 
Epoch 84/1000 
	 loss: 40.1120, MinusLogProbMetric: 40.1120, val_loss: 40.4434, val_MinusLogProbMetric: 40.4434

Epoch 84: val_loss did not improve from 40.35784
196/196 - 12s - loss: 40.1120 - MinusLogProbMetric: 40.1120 - val_loss: 40.4434 - val_MinusLogProbMetric: 40.4434 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 85/1000
2023-09-13 16:00:53.657 
Epoch 85/1000 
	 loss: 40.0855, MinusLogProbMetric: 40.0855, val_loss: 40.3242, val_MinusLogProbMetric: 40.3242

Epoch 85: val_loss improved from 40.35784 to 40.32423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.0855 - MinusLogProbMetric: 40.0855 - val_loss: 40.3242 - val_MinusLogProbMetric: 40.3242 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 86/1000
2023-09-13 16:01:04.875 
Epoch 86/1000 
	 loss: 40.0933, MinusLogProbMetric: 40.0933, val_loss: 40.4858, val_MinusLogProbMetric: 40.4858

Epoch 86: val_loss did not improve from 40.32423
196/196 - 11s - loss: 40.0933 - MinusLogProbMetric: 40.0933 - val_loss: 40.4858 - val_MinusLogProbMetric: 40.4858 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 87/1000
2023-09-13 16:01:16.317 
Epoch 87/1000 
	 loss: 40.0805, MinusLogProbMetric: 40.0805, val_loss: 40.3220, val_MinusLogProbMetric: 40.3220

Epoch 87: val_loss improved from 40.32423 to 40.32201, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 12s - loss: 40.0805 - MinusLogProbMetric: 40.0805 - val_loss: 40.3220 - val_MinusLogProbMetric: 40.3220 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-13 16:01:28.083 
Epoch 88/1000 
	 loss: 40.0560, MinusLogProbMetric: 40.0560, val_loss: 40.3337, val_MinusLogProbMetric: 40.3337

Epoch 88: val_loss did not improve from 40.32201
196/196 - 12s - loss: 40.0560 - MinusLogProbMetric: 40.0560 - val_loss: 40.3337 - val_MinusLogProbMetric: 40.3337 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 89/1000
2023-09-13 16:01:39.778 
Epoch 89/1000 
	 loss: 40.0652, MinusLogProbMetric: 40.0652, val_loss: 40.3627, val_MinusLogProbMetric: 40.3627

Epoch 89: val_loss did not improve from 40.32201
196/196 - 12s - loss: 40.0652 - MinusLogProbMetric: 40.0652 - val_loss: 40.3627 - val_MinusLogProbMetric: 40.3627 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 90/1000
2023-09-13 16:01:51.612 
Epoch 90/1000 
	 loss: 40.0674, MinusLogProbMetric: 40.0674, val_loss: 40.3819, val_MinusLogProbMetric: 40.3819

Epoch 90: val_loss did not improve from 40.32201
196/196 - 12s - loss: 40.0674 - MinusLogProbMetric: 40.0674 - val_loss: 40.3819 - val_MinusLogProbMetric: 40.3819 - lr: 0.0010 - 12s/epoch - 60ms/step
Epoch 91/1000
2023-09-13 16:02:03.746 
Epoch 91/1000 
	 loss: 40.0575, MinusLogProbMetric: 40.0575, val_loss: 40.4013, val_MinusLogProbMetric: 40.4013

Epoch 91: val_loss did not improve from 40.32201
196/196 - 12s - loss: 40.0575 - MinusLogProbMetric: 40.0575 - val_loss: 40.4013 - val_MinusLogProbMetric: 40.4013 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 92/1000
2023-09-13 16:02:15.706 
Epoch 92/1000 
	 loss: 40.0630, MinusLogProbMetric: 40.0630, val_loss: 40.4356, val_MinusLogProbMetric: 40.4356

Epoch 92: val_loss did not improve from 40.32201
196/196 - 12s - loss: 40.0630 - MinusLogProbMetric: 40.0630 - val_loss: 40.4356 - val_MinusLogProbMetric: 40.4356 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 93/1000
2023-09-13 16:02:26.312 
Epoch 93/1000 
	 loss: 40.0440, MinusLogProbMetric: 40.0440, val_loss: 40.5567, val_MinusLogProbMetric: 40.5567

Epoch 93: val_loss did not improve from 40.32201
196/196 - 11s - loss: 40.0440 - MinusLogProbMetric: 40.0440 - val_loss: 40.5567 - val_MinusLogProbMetric: 40.5567 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 94/1000
2023-09-13 16:02:37.604 
Epoch 94/1000 
	 loss: 40.0486, MinusLogProbMetric: 40.0486, val_loss: 40.2997, val_MinusLogProbMetric: 40.2997

Epoch 94: val_loss improved from 40.32201 to 40.29971, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 40.0486 - MinusLogProbMetric: 40.0486 - val_loss: 40.2997 - val_MinusLogProbMetric: 40.2997 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 95/1000
2023-09-13 16:02:48.191 
Epoch 95/1000 
	 loss: 40.0493, MinusLogProbMetric: 40.0493, val_loss: 40.4243, val_MinusLogProbMetric: 40.4243

Epoch 95: val_loss did not improve from 40.29971
196/196 - 10s - loss: 40.0493 - MinusLogProbMetric: 40.0493 - val_loss: 40.4243 - val_MinusLogProbMetric: 40.4243 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 96/1000
2023-09-13 16:02:58.244 
Epoch 96/1000 
	 loss: 40.0362, MinusLogProbMetric: 40.0362, val_loss: 40.4543, val_MinusLogProbMetric: 40.4543

Epoch 96: val_loss did not improve from 40.29971
196/196 - 10s - loss: 40.0362 - MinusLogProbMetric: 40.0362 - val_loss: 40.4543 - val_MinusLogProbMetric: 40.4543 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 97/1000
2023-09-13 16:03:07.362 
Epoch 97/1000 
	 loss: 40.0650, MinusLogProbMetric: 40.0650, val_loss: 40.3614, val_MinusLogProbMetric: 40.3614

Epoch 97: val_loss did not improve from 40.29971
196/196 - 9s - loss: 40.0650 - MinusLogProbMetric: 40.0650 - val_loss: 40.3614 - val_MinusLogProbMetric: 40.3614 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 98/1000
2023-09-13 16:03:16.624 
Epoch 98/1000 
	 loss: 40.0234, MinusLogProbMetric: 40.0234, val_loss: 40.3478, val_MinusLogProbMetric: 40.3478

Epoch 98: val_loss did not improve from 40.29971
196/196 - 9s - loss: 40.0234 - MinusLogProbMetric: 40.0234 - val_loss: 40.3478 - val_MinusLogProbMetric: 40.3478 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 99/1000
2023-09-13 16:03:25.534 
Epoch 99/1000 
	 loss: 40.0340, MinusLogProbMetric: 40.0340, val_loss: 40.3868, val_MinusLogProbMetric: 40.3868

Epoch 99: val_loss did not improve from 40.29971
196/196 - 9s - loss: 40.0340 - MinusLogProbMetric: 40.0340 - val_loss: 40.3868 - val_MinusLogProbMetric: 40.3868 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 100/1000
2023-09-13 16:03:34.530 
Epoch 100/1000 
	 loss: 39.9927, MinusLogProbMetric: 39.9927, val_loss: 40.5346, val_MinusLogProbMetric: 40.5346

Epoch 100: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9927 - MinusLogProbMetric: 39.9927 - val_loss: 40.5346 - val_MinusLogProbMetric: 40.5346 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 101/1000
2023-09-13 16:03:43.565 
Epoch 101/1000 
	 loss: 40.0235, MinusLogProbMetric: 40.0235, val_loss: 40.3804, val_MinusLogProbMetric: 40.3804

Epoch 101: val_loss did not improve from 40.29971
196/196 - 9s - loss: 40.0235 - MinusLogProbMetric: 40.0235 - val_loss: 40.3804 - val_MinusLogProbMetric: 40.3804 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 102/1000
2023-09-13 16:03:52.795 
Epoch 102/1000 
	 loss: 40.0152, MinusLogProbMetric: 40.0152, val_loss: 40.6101, val_MinusLogProbMetric: 40.6101

Epoch 102: val_loss did not improve from 40.29971
196/196 - 9s - loss: 40.0152 - MinusLogProbMetric: 40.0152 - val_loss: 40.6101 - val_MinusLogProbMetric: 40.6101 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 103/1000
2023-09-13 16:04:01.842 
Epoch 103/1000 
	 loss: 40.0076, MinusLogProbMetric: 40.0076, val_loss: 40.7995, val_MinusLogProbMetric: 40.7995

Epoch 103: val_loss did not improve from 40.29971
196/196 - 9s - loss: 40.0076 - MinusLogProbMetric: 40.0076 - val_loss: 40.7995 - val_MinusLogProbMetric: 40.7995 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 104/1000
2023-09-13 16:04:11.007 
Epoch 104/1000 
	 loss: 40.0070, MinusLogProbMetric: 40.0070, val_loss: 40.4825, val_MinusLogProbMetric: 40.4825

Epoch 104: val_loss did not improve from 40.29971
196/196 - 9s - loss: 40.0070 - MinusLogProbMetric: 40.0070 - val_loss: 40.4825 - val_MinusLogProbMetric: 40.4825 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 105/1000
2023-09-13 16:04:20.245 
Epoch 105/1000 
	 loss: 39.9610, MinusLogProbMetric: 39.9610, val_loss: 40.3237, val_MinusLogProbMetric: 40.3237

Epoch 105: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9610 - MinusLogProbMetric: 39.9610 - val_loss: 40.3237 - val_MinusLogProbMetric: 40.3237 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 106/1000
2023-09-13 16:04:29.130 
Epoch 106/1000 
	 loss: 39.9963, MinusLogProbMetric: 39.9963, val_loss: 40.3377, val_MinusLogProbMetric: 40.3377

Epoch 106: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9963 - MinusLogProbMetric: 39.9963 - val_loss: 40.3377 - val_MinusLogProbMetric: 40.3377 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 107/1000
2023-09-13 16:04:38.275 
Epoch 107/1000 
	 loss: 39.9789, MinusLogProbMetric: 39.9789, val_loss: 40.3810, val_MinusLogProbMetric: 40.3810

Epoch 107: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9789 - MinusLogProbMetric: 39.9789 - val_loss: 40.3810 - val_MinusLogProbMetric: 40.3810 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 108/1000
2023-09-13 16:04:47.421 
Epoch 108/1000 
	 loss: 39.9546, MinusLogProbMetric: 39.9546, val_loss: 40.3304, val_MinusLogProbMetric: 40.3304

Epoch 108: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9546 - MinusLogProbMetric: 39.9546 - val_loss: 40.3304 - val_MinusLogProbMetric: 40.3304 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 109/1000
2023-09-13 16:04:56.606 
Epoch 109/1000 
	 loss: 39.9851, MinusLogProbMetric: 39.9851, val_loss: 40.4515, val_MinusLogProbMetric: 40.4515

Epoch 109: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9851 - MinusLogProbMetric: 39.9851 - val_loss: 40.4515 - val_MinusLogProbMetric: 40.4515 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 110/1000
2023-09-13 16:05:05.650 
Epoch 110/1000 
	 loss: 39.9679, MinusLogProbMetric: 39.9679, val_loss: 40.3310, val_MinusLogProbMetric: 40.3310

Epoch 110: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9679 - MinusLogProbMetric: 39.9679 - val_loss: 40.3310 - val_MinusLogProbMetric: 40.3310 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 111/1000
2023-09-13 16:05:15.072 
Epoch 111/1000 
	 loss: 39.9546, MinusLogProbMetric: 39.9546, val_loss: 40.4871, val_MinusLogProbMetric: 40.4871

Epoch 111: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9546 - MinusLogProbMetric: 39.9546 - val_loss: 40.4871 - val_MinusLogProbMetric: 40.4871 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 112/1000
2023-09-13 16:05:26.047 
Epoch 112/1000 
	 loss: 39.9771, MinusLogProbMetric: 39.9771, val_loss: 40.4667, val_MinusLogProbMetric: 40.4667

Epoch 112: val_loss did not improve from 40.29971
196/196 - 11s - loss: 39.9771 - MinusLogProbMetric: 39.9771 - val_loss: 40.4667 - val_MinusLogProbMetric: 40.4667 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 113/1000
2023-09-13 16:05:35.630 
Epoch 113/1000 
	 loss: 39.9401, MinusLogProbMetric: 39.9401, val_loss: 40.4182, val_MinusLogProbMetric: 40.4182

Epoch 113: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.9401 - MinusLogProbMetric: 39.9401 - val_loss: 40.4182 - val_MinusLogProbMetric: 40.4182 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 114/1000
2023-09-13 16:05:45.133 
Epoch 114/1000 
	 loss: 39.9346, MinusLogProbMetric: 39.9346, val_loss: 40.5588, val_MinusLogProbMetric: 40.5588

Epoch 114: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.9346 - MinusLogProbMetric: 39.9346 - val_loss: 40.5588 - val_MinusLogProbMetric: 40.5588 - lr: 0.0010 - 10s/epoch - 48ms/step
Epoch 115/1000
2023-09-13 16:05:54.924 
Epoch 115/1000 
	 loss: 39.9520, MinusLogProbMetric: 39.9520, val_loss: 40.3802, val_MinusLogProbMetric: 40.3802

Epoch 115: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.9520 - MinusLogProbMetric: 39.9520 - val_loss: 40.3802 - val_MinusLogProbMetric: 40.3802 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 116/1000
2023-09-13 16:06:06.128 
Epoch 116/1000 
	 loss: 39.9140, MinusLogProbMetric: 39.9140, val_loss: 40.3883, val_MinusLogProbMetric: 40.3883

Epoch 116: val_loss did not improve from 40.29971
196/196 - 11s - loss: 39.9140 - MinusLogProbMetric: 39.9140 - val_loss: 40.3883 - val_MinusLogProbMetric: 40.3883 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 117/1000
2023-09-13 16:06:15.769 
Epoch 117/1000 
	 loss: 39.9727, MinusLogProbMetric: 39.9727, val_loss: 40.4291, val_MinusLogProbMetric: 40.4291

Epoch 117: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.9727 - MinusLogProbMetric: 39.9727 - val_loss: 40.4291 - val_MinusLogProbMetric: 40.4291 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 118/1000
2023-09-13 16:06:27.425 
Epoch 118/1000 
	 loss: 39.9187, MinusLogProbMetric: 39.9187, val_loss: 40.4736, val_MinusLogProbMetric: 40.4736

Epoch 118: val_loss did not improve from 40.29971
196/196 - 12s - loss: 39.9187 - MinusLogProbMetric: 39.9187 - val_loss: 40.4736 - val_MinusLogProbMetric: 40.4736 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 119/1000
2023-09-13 16:06:37.110 
Epoch 119/1000 
	 loss: 39.9433, MinusLogProbMetric: 39.9433, val_loss: 40.4413, val_MinusLogProbMetric: 40.4413

Epoch 119: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.9433 - MinusLogProbMetric: 39.9433 - val_loss: 40.4413 - val_MinusLogProbMetric: 40.4413 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 120/1000
2023-09-13 16:06:46.349 
Epoch 120/1000 
	 loss: 39.9217, MinusLogProbMetric: 39.9217, val_loss: 40.4159, val_MinusLogProbMetric: 40.4159

Epoch 120: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9217 - MinusLogProbMetric: 39.9217 - val_loss: 40.4159 - val_MinusLogProbMetric: 40.4159 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 121/1000
2023-09-13 16:06:55.241 
Epoch 121/1000 
	 loss: 39.9315, MinusLogProbMetric: 39.9315, val_loss: 40.5600, val_MinusLogProbMetric: 40.5600

Epoch 121: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9315 - MinusLogProbMetric: 39.9315 - val_loss: 40.5600 - val_MinusLogProbMetric: 40.5600 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 122/1000
2023-09-13 16:07:04.891 
Epoch 122/1000 
	 loss: 39.9282, MinusLogProbMetric: 39.9282, val_loss: 40.7505, val_MinusLogProbMetric: 40.7505

Epoch 122: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.9282 - MinusLogProbMetric: 39.9282 - val_loss: 40.7505 - val_MinusLogProbMetric: 40.7505 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 123/1000
2023-09-13 16:07:16.416 
Epoch 123/1000 
	 loss: 39.9317, MinusLogProbMetric: 39.9317, val_loss: 40.5126, val_MinusLogProbMetric: 40.5126

Epoch 123: val_loss did not improve from 40.29971
196/196 - 12s - loss: 39.9317 - MinusLogProbMetric: 39.9317 - val_loss: 40.5126 - val_MinusLogProbMetric: 40.5126 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 124/1000
2023-09-13 16:07:27.497 
Epoch 124/1000 
	 loss: 39.9053, MinusLogProbMetric: 39.9053, val_loss: 40.4515, val_MinusLogProbMetric: 40.4515

Epoch 124: val_loss did not improve from 40.29971
196/196 - 11s - loss: 39.9053 - MinusLogProbMetric: 39.9053 - val_loss: 40.4515 - val_MinusLogProbMetric: 40.4515 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 125/1000
2023-09-13 16:07:37.381 
Epoch 125/1000 
	 loss: 39.8958, MinusLogProbMetric: 39.8958, val_loss: 40.6020, val_MinusLogProbMetric: 40.6020

Epoch 125: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8958 - MinusLogProbMetric: 39.8958 - val_loss: 40.6020 - val_MinusLogProbMetric: 40.6020 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 126/1000
2023-09-13 16:07:47.462 
Epoch 126/1000 
	 loss: 39.9283, MinusLogProbMetric: 39.9283, val_loss: 40.4743, val_MinusLogProbMetric: 40.4743

Epoch 126: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.9283 - MinusLogProbMetric: 39.9283 - val_loss: 40.4743 - val_MinusLogProbMetric: 40.4743 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 127/1000
2023-09-13 16:07:56.896 
Epoch 127/1000 
	 loss: 39.9188, MinusLogProbMetric: 39.9188, val_loss: 40.3706, val_MinusLogProbMetric: 40.3706

Epoch 127: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.9188 - MinusLogProbMetric: 39.9188 - val_loss: 40.3706 - val_MinusLogProbMetric: 40.3706 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 128/1000
2023-09-13 16:08:07.269 
Epoch 128/1000 
	 loss: 39.8928, MinusLogProbMetric: 39.8928, val_loss: 40.4513, val_MinusLogProbMetric: 40.4513

Epoch 128: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8928 - MinusLogProbMetric: 39.8928 - val_loss: 40.4513 - val_MinusLogProbMetric: 40.4513 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 129/1000
2023-09-13 16:08:18.758 
Epoch 129/1000 
	 loss: 39.9037, MinusLogProbMetric: 39.9037, val_loss: 40.4332, val_MinusLogProbMetric: 40.4332

Epoch 129: val_loss did not improve from 40.29971
196/196 - 11s - loss: 39.9037 - MinusLogProbMetric: 39.9037 - val_loss: 40.4332 - val_MinusLogProbMetric: 40.4332 - lr: 0.0010 - 11s/epoch - 59ms/step
Epoch 130/1000
2023-09-13 16:08:30.366 
Epoch 130/1000 
	 loss: 39.8968, MinusLogProbMetric: 39.8968, val_loss: 40.4035, val_MinusLogProbMetric: 40.4035

Epoch 130: val_loss did not improve from 40.29971
196/196 - 12s - loss: 39.8968 - MinusLogProbMetric: 39.8968 - val_loss: 40.4035 - val_MinusLogProbMetric: 40.4035 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 131/1000
2023-09-13 16:08:41.987 
Epoch 131/1000 
	 loss: 39.8771, MinusLogProbMetric: 39.8771, val_loss: 40.4681, val_MinusLogProbMetric: 40.4681

Epoch 131: val_loss did not improve from 40.29971
196/196 - 12s - loss: 39.8771 - MinusLogProbMetric: 39.8771 - val_loss: 40.4681 - val_MinusLogProbMetric: 40.4681 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 132/1000
2023-09-13 16:08:51.564 
Epoch 132/1000 
	 loss: 39.8853, MinusLogProbMetric: 39.8853, val_loss: 40.5903, val_MinusLogProbMetric: 40.5903

Epoch 132: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8853 - MinusLogProbMetric: 39.8853 - val_loss: 40.5903 - val_MinusLogProbMetric: 40.5903 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 133/1000
2023-09-13 16:09:01.085 
Epoch 133/1000 
	 loss: 39.8773, MinusLogProbMetric: 39.8773, val_loss: 40.3670, val_MinusLogProbMetric: 40.3670

Epoch 133: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8773 - MinusLogProbMetric: 39.8773 - val_loss: 40.3670 - val_MinusLogProbMetric: 40.3670 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 134/1000
2023-09-13 16:09:11.014 
Epoch 134/1000 
	 loss: 39.8863, MinusLogProbMetric: 39.8863, val_loss: 40.4953, val_MinusLogProbMetric: 40.4953

Epoch 134: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8863 - MinusLogProbMetric: 39.8863 - val_loss: 40.4953 - val_MinusLogProbMetric: 40.4953 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 135/1000
2023-09-13 16:09:21.417 
Epoch 135/1000 
	 loss: 39.8795, MinusLogProbMetric: 39.8795, val_loss: 40.4016, val_MinusLogProbMetric: 40.4016

Epoch 135: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8795 - MinusLogProbMetric: 39.8795 - val_loss: 40.4016 - val_MinusLogProbMetric: 40.4016 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 136/1000
2023-09-13 16:09:30.822 
Epoch 136/1000 
	 loss: 39.8877, MinusLogProbMetric: 39.8877, val_loss: 40.4082, val_MinusLogProbMetric: 40.4082

Epoch 136: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.8877 - MinusLogProbMetric: 39.8877 - val_loss: 40.4082 - val_MinusLogProbMetric: 40.4082 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 137/1000
2023-09-13 16:09:40.184 
Epoch 137/1000 
	 loss: 39.8390, MinusLogProbMetric: 39.8390, val_loss: 40.4986, val_MinusLogProbMetric: 40.4986

Epoch 137: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.8390 - MinusLogProbMetric: 39.8390 - val_loss: 40.4986 - val_MinusLogProbMetric: 40.4986 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 138/1000
2023-09-13 16:09:49.723 
Epoch 138/1000 
	 loss: 39.8537, MinusLogProbMetric: 39.8537, val_loss: 40.4317, val_MinusLogProbMetric: 40.4317

Epoch 138: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8537 - MinusLogProbMetric: 39.8537 - val_loss: 40.4317 - val_MinusLogProbMetric: 40.4317 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 139/1000
2023-09-13 16:09:59.252 
Epoch 139/1000 
	 loss: 39.8562, MinusLogProbMetric: 39.8562, val_loss: 40.3867, val_MinusLogProbMetric: 40.3867

Epoch 139: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8562 - MinusLogProbMetric: 39.8562 - val_loss: 40.3867 - val_MinusLogProbMetric: 40.3867 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 140/1000
2023-09-13 16:10:09.174 
Epoch 140/1000 
	 loss: 39.8669, MinusLogProbMetric: 39.8669, val_loss: 40.4181, val_MinusLogProbMetric: 40.4181

Epoch 140: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.8669 - MinusLogProbMetric: 39.8669 - val_loss: 40.4181 - val_MinusLogProbMetric: 40.4181 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 141/1000
2023-09-13 16:10:20.771 
Epoch 141/1000 
	 loss: 39.8392, MinusLogProbMetric: 39.8392, val_loss: 40.3975, val_MinusLogProbMetric: 40.3975

Epoch 141: val_loss did not improve from 40.29971
196/196 - 12s - loss: 39.8392 - MinusLogProbMetric: 39.8392 - val_loss: 40.3975 - val_MinusLogProbMetric: 40.3975 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 142/1000
2023-09-13 16:10:30.003 
Epoch 142/1000 
	 loss: 39.8260, MinusLogProbMetric: 39.8260, val_loss: 40.7064, val_MinusLogProbMetric: 40.7064

Epoch 142: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.8260 - MinusLogProbMetric: 39.8260 - val_loss: 40.7064 - val_MinusLogProbMetric: 40.7064 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 143/1000
2023-09-13 16:10:39.489 
Epoch 143/1000 
	 loss: 39.8383, MinusLogProbMetric: 39.8383, val_loss: 40.3450, val_MinusLogProbMetric: 40.3450

Epoch 143: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.8383 - MinusLogProbMetric: 39.8383 - val_loss: 40.3450 - val_MinusLogProbMetric: 40.3450 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 144/1000
2023-09-13 16:10:48.922 
Epoch 144/1000 
	 loss: 39.8228, MinusLogProbMetric: 39.8228, val_loss: 40.4016, val_MinusLogProbMetric: 40.4016

Epoch 144: val_loss did not improve from 40.29971
196/196 - 9s - loss: 39.8228 - MinusLogProbMetric: 39.8228 - val_loss: 40.4016 - val_MinusLogProbMetric: 40.4016 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 145/1000
2023-09-13 16:10:58.569 
Epoch 145/1000 
	 loss: 39.6385, MinusLogProbMetric: 39.6385, val_loss: 40.3511, val_MinusLogProbMetric: 40.3511

Epoch 145: val_loss did not improve from 40.29971
196/196 - 10s - loss: 39.6385 - MinusLogProbMetric: 39.6385 - val_loss: 40.3511 - val_MinusLogProbMetric: 40.3511 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 146/1000
2023-09-13 16:11:09.767 
Epoch 146/1000 
	 loss: 39.6384, MinusLogProbMetric: 39.6384, val_loss: 40.2702, val_MinusLogProbMetric: 40.2702

Epoch 146: val_loss improved from 40.29971 to 40.27020, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_212/weights/best_weights.h5
196/196 - 11s - loss: 39.6384 - MinusLogProbMetric: 39.6384 - val_loss: 40.2702 - val_MinusLogProbMetric: 40.2702 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 147/1000
2023-09-13 16:11:21.435 
Epoch 147/1000 
	 loss: 39.6281, MinusLogProbMetric: 39.6281, val_loss: 40.2906, val_MinusLogProbMetric: 40.2906

Epoch 147: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.6281 - MinusLogProbMetric: 39.6281 - val_loss: 40.2906 - val_MinusLogProbMetric: 40.2906 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 148/1000
2023-09-13 16:11:30.755 
Epoch 148/1000 
	 loss: 39.6306, MinusLogProbMetric: 39.6306, val_loss: 40.2716, val_MinusLogProbMetric: 40.2716

Epoch 148: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.6306 - MinusLogProbMetric: 39.6306 - val_loss: 40.2716 - val_MinusLogProbMetric: 40.2716 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 149/1000
2023-09-13 16:11:41.889 
Epoch 149/1000 
	 loss: 39.6185, MinusLogProbMetric: 39.6185, val_loss: 40.3332, val_MinusLogProbMetric: 40.3332

Epoch 149: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.6185 - MinusLogProbMetric: 39.6185 - val_loss: 40.3332 - val_MinusLogProbMetric: 40.3332 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 150/1000
2023-09-13 16:11:53.565 
Epoch 150/1000 
	 loss: 39.6309, MinusLogProbMetric: 39.6309, val_loss: 40.2948, val_MinusLogProbMetric: 40.2948

Epoch 150: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.6309 - MinusLogProbMetric: 39.6309 - val_loss: 40.2948 - val_MinusLogProbMetric: 40.2948 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 151/1000
2023-09-13 16:12:04.016 
Epoch 151/1000 
	 loss: 39.6245, MinusLogProbMetric: 39.6245, val_loss: 40.2940, val_MinusLogProbMetric: 40.2940

Epoch 151: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.6245 - MinusLogProbMetric: 39.6245 - val_loss: 40.2940 - val_MinusLogProbMetric: 40.2940 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 152/1000
2023-09-13 16:12:14.555 
Epoch 152/1000 
	 loss: 39.6311, MinusLogProbMetric: 39.6311, val_loss: 40.3897, val_MinusLogProbMetric: 40.3897

Epoch 152: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.6311 - MinusLogProbMetric: 39.6311 - val_loss: 40.3897 - val_MinusLogProbMetric: 40.3897 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 153/1000
2023-09-13 16:12:26.077 
Epoch 153/1000 
	 loss: 39.6130, MinusLogProbMetric: 39.6130, val_loss: 40.2842, val_MinusLogProbMetric: 40.2842

Epoch 153: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.6130 - MinusLogProbMetric: 39.6130 - val_loss: 40.2842 - val_MinusLogProbMetric: 40.2842 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 154/1000
2023-09-13 16:12:35.543 
Epoch 154/1000 
	 loss: 39.6146, MinusLogProbMetric: 39.6146, val_loss: 40.3569, val_MinusLogProbMetric: 40.3569

Epoch 154: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.6146 - MinusLogProbMetric: 39.6146 - val_loss: 40.3569 - val_MinusLogProbMetric: 40.3569 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 155/1000
2023-09-13 16:12:45.361 
Epoch 155/1000 
	 loss: 39.6142, MinusLogProbMetric: 39.6142, val_loss: 40.3155, val_MinusLogProbMetric: 40.3155

Epoch 155: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.6142 - MinusLogProbMetric: 39.6142 - val_loss: 40.3155 - val_MinusLogProbMetric: 40.3155 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 156/1000
2023-09-13 16:12:55.832 
Epoch 156/1000 
	 loss: 39.6128, MinusLogProbMetric: 39.6128, val_loss: 40.3115, val_MinusLogProbMetric: 40.3115

Epoch 156: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.6128 - MinusLogProbMetric: 39.6128 - val_loss: 40.3115 - val_MinusLogProbMetric: 40.3115 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 157/1000
2023-09-13 16:13:05.204 
Epoch 157/1000 
	 loss: 39.6086, MinusLogProbMetric: 39.6086, val_loss: 40.2736, val_MinusLogProbMetric: 40.2736

Epoch 157: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.6086 - MinusLogProbMetric: 39.6086 - val_loss: 40.2736 - val_MinusLogProbMetric: 40.2736 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 158/1000
2023-09-13 16:13:14.997 
Epoch 158/1000 
	 loss: 39.6040, MinusLogProbMetric: 39.6040, val_loss: 40.3961, val_MinusLogProbMetric: 40.3961

Epoch 158: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.6040 - MinusLogProbMetric: 39.6040 - val_loss: 40.3961 - val_MinusLogProbMetric: 40.3961 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 159/1000
2023-09-13 16:13:25.930 
Epoch 159/1000 
	 loss: 39.6063, MinusLogProbMetric: 39.6063, val_loss: 40.2942, val_MinusLogProbMetric: 40.2942

Epoch 159: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.6063 - MinusLogProbMetric: 39.6063 - val_loss: 40.2942 - val_MinusLogProbMetric: 40.2942 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 160/1000
2023-09-13 16:13:35.449 
Epoch 160/1000 
	 loss: 39.6096, MinusLogProbMetric: 39.6096, val_loss: 40.3102, val_MinusLogProbMetric: 40.3102

Epoch 160: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.6096 - MinusLogProbMetric: 39.6096 - val_loss: 40.3102 - val_MinusLogProbMetric: 40.3102 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 161/1000
2023-09-13 16:13:44.973 
Epoch 161/1000 
	 loss: 39.6114, MinusLogProbMetric: 39.6114, val_loss: 40.2983, val_MinusLogProbMetric: 40.2983

Epoch 161: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.6114 - MinusLogProbMetric: 39.6114 - val_loss: 40.2983 - val_MinusLogProbMetric: 40.2983 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 162/1000
2023-09-13 16:13:54.164 
Epoch 162/1000 
	 loss: 39.6016, MinusLogProbMetric: 39.6016, val_loss: 40.3080, val_MinusLogProbMetric: 40.3080

Epoch 162: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.6016 - MinusLogProbMetric: 39.6016 - val_loss: 40.3080 - val_MinusLogProbMetric: 40.3080 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 163/1000
2023-09-13 16:14:03.616 
Epoch 163/1000 
	 loss: 39.5956, MinusLogProbMetric: 39.5956, val_loss: 40.3141, val_MinusLogProbMetric: 40.3141

Epoch 163: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.5956 - MinusLogProbMetric: 39.5956 - val_loss: 40.3141 - val_MinusLogProbMetric: 40.3141 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 164/1000
2023-09-13 16:14:14.604 
Epoch 164/1000 
	 loss: 39.6005, MinusLogProbMetric: 39.6005, val_loss: 40.3737, val_MinusLogProbMetric: 40.3737

Epoch 164: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.6005 - MinusLogProbMetric: 39.6005 - val_loss: 40.3737 - val_MinusLogProbMetric: 40.3737 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 165/1000
2023-09-13 16:14:25.761 
Epoch 165/1000 
	 loss: 39.6021, MinusLogProbMetric: 39.6021, val_loss: 40.3382, val_MinusLogProbMetric: 40.3382

Epoch 165: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.6021 - MinusLogProbMetric: 39.6021 - val_loss: 40.3382 - val_MinusLogProbMetric: 40.3382 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 166/1000
2023-09-13 16:14:37.291 
Epoch 166/1000 
	 loss: 39.6027, MinusLogProbMetric: 39.6027, val_loss: 40.3202, val_MinusLogProbMetric: 40.3202

Epoch 166: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.6027 - MinusLogProbMetric: 39.6027 - val_loss: 40.3202 - val_MinusLogProbMetric: 40.3202 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 167/1000
2023-09-13 16:14:47.275 
Epoch 167/1000 
	 loss: 39.5952, MinusLogProbMetric: 39.5952, val_loss: 40.2914, val_MinusLogProbMetric: 40.2914

Epoch 167: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5952 - MinusLogProbMetric: 39.5952 - val_loss: 40.2914 - val_MinusLogProbMetric: 40.2914 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 168/1000
2023-09-13 16:14:58.752 
Epoch 168/1000 
	 loss: 39.5968, MinusLogProbMetric: 39.5968, val_loss: 40.3203, val_MinusLogProbMetric: 40.3203

Epoch 168: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5968 - MinusLogProbMetric: 39.5968 - val_loss: 40.3203 - val_MinusLogProbMetric: 40.3203 - lr: 5.0000e-04 - 11s/epoch - 59ms/step
Epoch 169/1000
2023-09-13 16:15:08.663 
Epoch 169/1000 
	 loss: 39.5911, MinusLogProbMetric: 39.5911, val_loss: 40.3083, val_MinusLogProbMetric: 40.3083

Epoch 169: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5911 - MinusLogProbMetric: 39.5911 - val_loss: 40.3083 - val_MinusLogProbMetric: 40.3083 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 170/1000
2023-09-13 16:15:19.294 
Epoch 170/1000 
	 loss: 39.5818, MinusLogProbMetric: 39.5818, val_loss: 40.3249, val_MinusLogProbMetric: 40.3249

Epoch 170: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5818 - MinusLogProbMetric: 39.5818 - val_loss: 40.3249 - val_MinusLogProbMetric: 40.3249 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 171/1000
2023-09-13 16:15:28.994 
Epoch 171/1000 
	 loss: 39.5853, MinusLogProbMetric: 39.5853, val_loss: 40.3489, val_MinusLogProbMetric: 40.3489

Epoch 171: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5853 - MinusLogProbMetric: 39.5853 - val_loss: 40.3489 - val_MinusLogProbMetric: 40.3489 - lr: 5.0000e-04 - 10s/epoch - 50ms/step
Epoch 172/1000
2023-09-13 16:15:39.864 
Epoch 172/1000 
	 loss: 39.5785, MinusLogProbMetric: 39.5785, val_loss: 40.3938, val_MinusLogProbMetric: 40.3938

Epoch 172: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5785 - MinusLogProbMetric: 39.5785 - val_loss: 40.3938 - val_MinusLogProbMetric: 40.3938 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 173/1000
2023-09-13 16:15:49.421 
Epoch 173/1000 
	 loss: 39.5889, MinusLogProbMetric: 39.5889, val_loss: 40.3204, val_MinusLogProbMetric: 40.3204

Epoch 173: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5889 - MinusLogProbMetric: 39.5889 - val_loss: 40.3204 - val_MinusLogProbMetric: 40.3204 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 174/1000
2023-09-13 16:15:59.650 
Epoch 174/1000 
	 loss: 39.5881, MinusLogProbMetric: 39.5881, val_loss: 40.3350, val_MinusLogProbMetric: 40.3350

Epoch 174: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5881 - MinusLogProbMetric: 39.5881 - val_loss: 40.3350 - val_MinusLogProbMetric: 40.3350 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 175/1000
2023-09-13 16:16:10.555 
Epoch 175/1000 
	 loss: 39.5808, MinusLogProbMetric: 39.5808, val_loss: 40.3632, val_MinusLogProbMetric: 40.3632

Epoch 175: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5808 - MinusLogProbMetric: 39.5808 - val_loss: 40.3632 - val_MinusLogProbMetric: 40.3632 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 176/1000
2023-09-13 16:16:22.245 
Epoch 176/1000 
	 loss: 39.5854, MinusLogProbMetric: 39.5854, val_loss: 40.3891, val_MinusLogProbMetric: 40.3891

Epoch 176: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.5854 - MinusLogProbMetric: 39.5854 - val_loss: 40.3891 - val_MinusLogProbMetric: 40.3891 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 177/1000
2023-09-13 16:16:32.874 
Epoch 177/1000 
	 loss: 39.5830, MinusLogProbMetric: 39.5830, val_loss: 40.3510, val_MinusLogProbMetric: 40.3510

Epoch 177: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5830 - MinusLogProbMetric: 39.5830 - val_loss: 40.3510 - val_MinusLogProbMetric: 40.3510 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 178/1000
2023-09-13 16:16:43.521 
Epoch 178/1000 
	 loss: 39.5788, MinusLogProbMetric: 39.5788, val_loss: 40.3114, val_MinusLogProbMetric: 40.3114

Epoch 178: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5788 - MinusLogProbMetric: 39.5788 - val_loss: 40.3114 - val_MinusLogProbMetric: 40.3114 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 179/1000
2023-09-13 16:16:52.878 
Epoch 179/1000 
	 loss: 39.5763, MinusLogProbMetric: 39.5763, val_loss: 40.3422, val_MinusLogProbMetric: 40.3422

Epoch 179: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.5763 - MinusLogProbMetric: 39.5763 - val_loss: 40.3422 - val_MinusLogProbMetric: 40.3422 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 180/1000
2023-09-13 16:17:04.134 
Epoch 180/1000 
	 loss: 39.5739, MinusLogProbMetric: 39.5739, val_loss: 40.3471, val_MinusLogProbMetric: 40.3471

Epoch 180: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5739 - MinusLogProbMetric: 39.5739 - val_loss: 40.3471 - val_MinusLogProbMetric: 40.3471 - lr: 5.0000e-04 - 11s/epoch - 57ms/step
Epoch 181/1000
2023-09-13 16:17:13.763 
Epoch 181/1000 
	 loss: 39.5719, MinusLogProbMetric: 39.5719, val_loss: 40.3693, val_MinusLogProbMetric: 40.3693

Epoch 181: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5719 - MinusLogProbMetric: 39.5719 - val_loss: 40.3693 - val_MinusLogProbMetric: 40.3693 - lr: 5.0000e-04 - 10s/epoch - 49ms/step
Epoch 182/1000
2023-09-13 16:17:23.076 
Epoch 182/1000 
	 loss: 39.5826, MinusLogProbMetric: 39.5826, val_loss: 40.3221, val_MinusLogProbMetric: 40.3221

Epoch 182: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.5826 - MinusLogProbMetric: 39.5826 - val_loss: 40.3221 - val_MinusLogProbMetric: 40.3221 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 183/1000
2023-09-13 16:17:33.925 
Epoch 183/1000 
	 loss: 39.5781, MinusLogProbMetric: 39.5781, val_loss: 40.3773, val_MinusLogProbMetric: 40.3773

Epoch 183: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5781 - MinusLogProbMetric: 39.5781 - val_loss: 40.3773 - val_MinusLogProbMetric: 40.3773 - lr: 5.0000e-04 - 11s/epoch - 55ms/step
Epoch 184/1000
2023-09-13 16:17:45.497 
Epoch 184/1000 
	 loss: 39.5683, MinusLogProbMetric: 39.5683, val_loss: 40.3328, val_MinusLogProbMetric: 40.3328

Epoch 184: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.5683 - MinusLogProbMetric: 39.5683 - val_loss: 40.3328 - val_MinusLogProbMetric: 40.3328 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 185/1000
2023-09-13 16:17:56.100 
Epoch 185/1000 
	 loss: 39.5715, MinusLogProbMetric: 39.5715, val_loss: 40.3755, val_MinusLogProbMetric: 40.3755

Epoch 185: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5715 - MinusLogProbMetric: 39.5715 - val_loss: 40.3755 - val_MinusLogProbMetric: 40.3755 - lr: 5.0000e-04 - 11s/epoch - 54ms/step
Epoch 186/1000
2023-09-13 16:18:07.160 
Epoch 186/1000 
	 loss: 39.5730, MinusLogProbMetric: 39.5730, val_loss: 40.3898, val_MinusLogProbMetric: 40.3898

Epoch 186: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5730 - MinusLogProbMetric: 39.5730 - val_loss: 40.3898 - val_MinusLogProbMetric: 40.3898 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 187/1000
2023-09-13 16:18:17.149 
Epoch 187/1000 
	 loss: 39.5641, MinusLogProbMetric: 39.5641, val_loss: 40.3527, val_MinusLogProbMetric: 40.3527

Epoch 187: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5641 - MinusLogProbMetric: 39.5641 - val_loss: 40.3527 - val_MinusLogProbMetric: 40.3527 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 188/1000
2023-09-13 16:18:28.510 
Epoch 188/1000 
	 loss: 39.5553, MinusLogProbMetric: 39.5553, val_loss: 40.3595, val_MinusLogProbMetric: 40.3595

Epoch 188: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5553 - MinusLogProbMetric: 39.5553 - val_loss: 40.3595 - val_MinusLogProbMetric: 40.3595 - lr: 5.0000e-04 - 11s/epoch - 58ms/step
Epoch 189/1000
2023-09-13 16:18:38.627 
Epoch 189/1000 
	 loss: 39.5613, MinusLogProbMetric: 39.5613, val_loss: 40.3601, val_MinusLogProbMetric: 40.3601

Epoch 189: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5613 - MinusLogProbMetric: 39.5613 - val_loss: 40.3601 - val_MinusLogProbMetric: 40.3601 - lr: 5.0000e-04 - 10s/epoch - 52ms/step
Epoch 190/1000
2023-09-13 16:18:48.034 
Epoch 190/1000 
	 loss: 39.5549, MinusLogProbMetric: 39.5549, val_loss: 40.3803, val_MinusLogProbMetric: 40.3803

Epoch 190: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.5549 - MinusLogProbMetric: 39.5549 - val_loss: 40.3803 - val_MinusLogProbMetric: 40.3803 - lr: 5.0000e-04 - 9s/epoch - 48ms/step
Epoch 191/1000
2023-09-13 16:18:58.428 
Epoch 191/1000 
	 loss: 39.5577, MinusLogProbMetric: 39.5577, val_loss: 40.3811, val_MinusLogProbMetric: 40.3811

Epoch 191: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5577 - MinusLogProbMetric: 39.5577 - val_loss: 40.3811 - val_MinusLogProbMetric: 40.3811 - lr: 5.0000e-04 - 10s/epoch - 53ms/step
Epoch 192/1000
2023-09-13 16:19:09.932 
Epoch 192/1000 
	 loss: 39.5642, MinusLogProbMetric: 39.5642, val_loss: 40.4354, val_MinusLogProbMetric: 40.4354

Epoch 192: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.5642 - MinusLogProbMetric: 39.5642 - val_loss: 40.4354 - val_MinusLogProbMetric: 40.4354 - lr: 5.0000e-04 - 12s/epoch - 59ms/step
Epoch 193/1000
2023-09-13 16:19:19.190 
Epoch 193/1000 
	 loss: 39.5559, MinusLogProbMetric: 39.5559, val_loss: 40.3866, val_MinusLogProbMetric: 40.3866

Epoch 193: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.5559 - MinusLogProbMetric: 39.5559 - val_loss: 40.3866 - val_MinusLogProbMetric: 40.3866 - lr: 5.0000e-04 - 9s/epoch - 47ms/step
Epoch 194/1000
2023-09-13 16:19:30.226 
Epoch 194/1000 
	 loss: 39.5610, MinusLogProbMetric: 39.5610, val_loss: 40.3721, val_MinusLogProbMetric: 40.3721

Epoch 194: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.5610 - MinusLogProbMetric: 39.5610 - val_loss: 40.3721 - val_MinusLogProbMetric: 40.3721 - lr: 5.0000e-04 - 11s/epoch - 56ms/step
Epoch 195/1000
2023-09-13 16:19:40.191 
Epoch 195/1000 
	 loss: 39.5551, MinusLogProbMetric: 39.5551, val_loss: 40.4059, val_MinusLogProbMetric: 40.4059

Epoch 195: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.5551 - MinusLogProbMetric: 39.5551 - val_loss: 40.4059 - val_MinusLogProbMetric: 40.4059 - lr: 5.0000e-04 - 10s/epoch - 51ms/step
Epoch 196/1000
2023-09-13 16:19:51.865 
Epoch 196/1000 
	 loss: 39.5497, MinusLogProbMetric: 39.5497, val_loss: 40.4032, val_MinusLogProbMetric: 40.4032

Epoch 196: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.5497 - MinusLogProbMetric: 39.5497 - val_loss: 40.4032 - val_MinusLogProbMetric: 40.4032 - lr: 5.0000e-04 - 12s/epoch - 60ms/step
Epoch 197/1000
2023-09-13 16:20:02.790 
Epoch 197/1000 
	 loss: 39.4667, MinusLogProbMetric: 39.4667, val_loss: 40.3251, val_MinusLogProbMetric: 40.3251

Epoch 197: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4667 - MinusLogProbMetric: 39.4667 - val_loss: 40.3251 - val_MinusLogProbMetric: 40.3251 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 198/1000
2023-09-13 16:20:11.757 
Epoch 198/1000 
	 loss: 39.4651, MinusLogProbMetric: 39.4651, val_loss: 40.3244, val_MinusLogProbMetric: 40.3244

Epoch 198: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4651 - MinusLogProbMetric: 39.4651 - val_loss: 40.3244 - val_MinusLogProbMetric: 40.3244 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 199/1000
2023-09-13 16:20:21.180 
Epoch 199/1000 
	 loss: 39.4607, MinusLogProbMetric: 39.4607, val_loss: 40.3386, val_MinusLogProbMetric: 40.3386

Epoch 199: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4607 - MinusLogProbMetric: 39.4607 - val_loss: 40.3386 - val_MinusLogProbMetric: 40.3386 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 200/1000
2023-09-13 16:20:32.490 
Epoch 200/1000 
	 loss: 39.4643, MinusLogProbMetric: 39.4643, val_loss: 40.3318, val_MinusLogProbMetric: 40.3318

Epoch 200: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4643 - MinusLogProbMetric: 39.4643 - val_loss: 40.3318 - val_MinusLogProbMetric: 40.3318 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 201/1000
2023-09-13 16:20:42.805 
Epoch 201/1000 
	 loss: 39.4578, MinusLogProbMetric: 39.4578, val_loss: 40.3488, val_MinusLogProbMetric: 40.3488

Epoch 201: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4578 - MinusLogProbMetric: 39.4578 - val_loss: 40.3488 - val_MinusLogProbMetric: 40.3488 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 202/1000
2023-09-13 16:20:53.744 
Epoch 202/1000 
	 loss: 39.4577, MinusLogProbMetric: 39.4577, val_loss: 40.3375, val_MinusLogProbMetric: 40.3375

Epoch 202: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4577 - MinusLogProbMetric: 39.4577 - val_loss: 40.3375 - val_MinusLogProbMetric: 40.3375 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 203/1000
2023-09-13 16:21:04.911 
Epoch 203/1000 
	 loss: 39.4520, MinusLogProbMetric: 39.4520, val_loss: 40.3266, val_MinusLogProbMetric: 40.3266

Epoch 203: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4520 - MinusLogProbMetric: 39.4520 - val_loss: 40.3266 - val_MinusLogProbMetric: 40.3266 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 204/1000
2023-09-13 16:21:15.716 
Epoch 204/1000 
	 loss: 39.4549, MinusLogProbMetric: 39.4549, val_loss: 40.3482, val_MinusLogProbMetric: 40.3482

Epoch 204: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4549 - MinusLogProbMetric: 39.4549 - val_loss: 40.3482 - val_MinusLogProbMetric: 40.3482 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 205/1000
2023-09-13 16:21:25.466 
Epoch 205/1000 
	 loss: 39.4559, MinusLogProbMetric: 39.4559, val_loss: 40.3515, val_MinusLogProbMetric: 40.3515

Epoch 205: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4559 - MinusLogProbMetric: 39.4559 - val_loss: 40.3515 - val_MinusLogProbMetric: 40.3515 - lr: 2.5000e-04 - 10s/epoch - 50ms/step
Epoch 206/1000
2023-09-13 16:21:34.716 
Epoch 206/1000 
	 loss: 39.4523, MinusLogProbMetric: 39.4523, val_loss: 40.3455, val_MinusLogProbMetric: 40.3455

Epoch 206: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4523 - MinusLogProbMetric: 39.4523 - val_loss: 40.3455 - val_MinusLogProbMetric: 40.3455 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 207/1000
2023-09-13 16:21:44.138 
Epoch 207/1000 
	 loss: 39.4497, MinusLogProbMetric: 39.4497, val_loss: 40.3621, val_MinusLogProbMetric: 40.3621

Epoch 207: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4497 - MinusLogProbMetric: 39.4497 - val_loss: 40.3621 - val_MinusLogProbMetric: 40.3621 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 208/1000
2023-09-13 16:21:53.746 
Epoch 208/1000 
	 loss: 39.4517, MinusLogProbMetric: 39.4517, val_loss: 40.3414, val_MinusLogProbMetric: 40.3414

Epoch 208: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4517 - MinusLogProbMetric: 39.4517 - val_loss: 40.3414 - val_MinusLogProbMetric: 40.3414 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 209/1000
2023-09-13 16:22:03.195 
Epoch 209/1000 
	 loss: 39.4500, MinusLogProbMetric: 39.4500, val_loss: 40.3303, val_MinusLogProbMetric: 40.3303

Epoch 209: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4500 - MinusLogProbMetric: 39.4500 - val_loss: 40.3303 - val_MinusLogProbMetric: 40.3303 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 210/1000
2023-09-13 16:22:14.549 
Epoch 210/1000 
	 loss: 39.4532, MinusLogProbMetric: 39.4532, val_loss: 40.3473, val_MinusLogProbMetric: 40.3473

Epoch 210: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4532 - MinusLogProbMetric: 39.4532 - val_loss: 40.3473 - val_MinusLogProbMetric: 40.3473 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 211/1000
2023-09-13 16:22:26.119 
Epoch 211/1000 
	 loss: 39.4445, MinusLogProbMetric: 39.4445, val_loss: 40.3737, val_MinusLogProbMetric: 40.3737

Epoch 211: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.4445 - MinusLogProbMetric: 39.4445 - val_loss: 40.3737 - val_MinusLogProbMetric: 40.3737 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 212/1000
2023-09-13 16:22:36.725 
Epoch 212/1000 
	 loss: 39.4477, MinusLogProbMetric: 39.4477, val_loss: 40.3480, val_MinusLogProbMetric: 40.3480

Epoch 212: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4477 - MinusLogProbMetric: 39.4477 - val_loss: 40.3480 - val_MinusLogProbMetric: 40.3480 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 213/1000
2023-09-13 16:22:46.144 
Epoch 213/1000 
	 loss: 39.4483, MinusLogProbMetric: 39.4483, val_loss: 40.3327, val_MinusLogProbMetric: 40.3327

Epoch 213: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4483 - MinusLogProbMetric: 39.4483 - val_loss: 40.3327 - val_MinusLogProbMetric: 40.3327 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 214/1000
2023-09-13 16:22:55.118 
Epoch 214/1000 
	 loss: 39.4488, MinusLogProbMetric: 39.4488, val_loss: 40.3594, val_MinusLogProbMetric: 40.3594

Epoch 214: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4488 - MinusLogProbMetric: 39.4488 - val_loss: 40.3594 - val_MinusLogProbMetric: 40.3594 - lr: 2.5000e-04 - 9s/epoch - 46ms/step
Epoch 215/1000
2023-09-13 16:23:04.523 
Epoch 215/1000 
	 loss: 39.4490, MinusLogProbMetric: 39.4490, val_loss: 40.3525, val_MinusLogProbMetric: 40.3525

Epoch 215: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4490 - MinusLogProbMetric: 39.4490 - val_loss: 40.3525 - val_MinusLogProbMetric: 40.3525 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 216/1000
2023-09-13 16:23:13.825 
Epoch 216/1000 
	 loss: 39.4446, MinusLogProbMetric: 39.4446, val_loss: 40.3600, val_MinusLogProbMetric: 40.3600

Epoch 216: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4446 - MinusLogProbMetric: 39.4446 - val_loss: 40.3600 - val_MinusLogProbMetric: 40.3600 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 217/1000
2023-09-13 16:23:24.754 
Epoch 217/1000 
	 loss: 39.4395, MinusLogProbMetric: 39.4395, val_loss: 40.3631, val_MinusLogProbMetric: 40.3631

Epoch 217: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4395 - MinusLogProbMetric: 39.4395 - val_loss: 40.3631 - val_MinusLogProbMetric: 40.3631 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 218/1000
2023-09-13 16:23:35.029 
Epoch 218/1000 
	 loss: 39.4413, MinusLogProbMetric: 39.4413, val_loss: 40.3654, val_MinusLogProbMetric: 40.3654

Epoch 218: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4413 - MinusLogProbMetric: 39.4413 - val_loss: 40.3654 - val_MinusLogProbMetric: 40.3654 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 219/1000
2023-09-13 16:23:46.053 
Epoch 219/1000 
	 loss: 39.4449, MinusLogProbMetric: 39.4449, val_loss: 40.3546, val_MinusLogProbMetric: 40.3546

Epoch 219: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4449 - MinusLogProbMetric: 39.4449 - val_loss: 40.3546 - val_MinusLogProbMetric: 40.3546 - lr: 2.5000e-04 - 11s/epoch - 56ms/step
Epoch 220/1000
2023-09-13 16:23:55.232 
Epoch 220/1000 
	 loss: 39.4439, MinusLogProbMetric: 39.4439, val_loss: 40.3712, val_MinusLogProbMetric: 40.3712

Epoch 220: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4439 - MinusLogProbMetric: 39.4439 - val_loss: 40.3712 - val_MinusLogProbMetric: 40.3712 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 221/1000
2023-09-13 16:24:06.400 
Epoch 221/1000 
	 loss: 39.4392, MinusLogProbMetric: 39.4392, val_loss: 40.3784, val_MinusLogProbMetric: 40.3784

Epoch 221: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4392 - MinusLogProbMetric: 39.4392 - val_loss: 40.3784 - val_MinusLogProbMetric: 40.3784 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 222/1000
2023-09-13 16:24:15.740 
Epoch 222/1000 
	 loss: 39.4394, MinusLogProbMetric: 39.4394, val_loss: 40.3681, val_MinusLogProbMetric: 40.3681

Epoch 222: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4394 - MinusLogProbMetric: 39.4394 - val_loss: 40.3681 - val_MinusLogProbMetric: 40.3681 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 223/1000
2023-09-13 16:24:25.063 
Epoch 223/1000 
	 loss: 39.4350, MinusLogProbMetric: 39.4350, val_loss: 40.3908, val_MinusLogProbMetric: 40.3908

Epoch 223: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4350 - MinusLogProbMetric: 39.4350 - val_loss: 40.3908 - val_MinusLogProbMetric: 40.3908 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 224/1000
2023-09-13 16:24:35.649 
Epoch 224/1000 
	 loss: 39.4422, MinusLogProbMetric: 39.4422, val_loss: 40.3657, val_MinusLogProbMetric: 40.3657

Epoch 224: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4422 - MinusLogProbMetric: 39.4422 - val_loss: 40.3657 - val_MinusLogProbMetric: 40.3657 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 225/1000
2023-09-13 16:24:46.433 
Epoch 225/1000 
	 loss: 39.4359, MinusLogProbMetric: 39.4359, val_loss: 40.3589, val_MinusLogProbMetric: 40.3589

Epoch 225: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4359 - MinusLogProbMetric: 39.4359 - val_loss: 40.3589 - val_MinusLogProbMetric: 40.3589 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 226/1000
2023-09-13 16:24:57.208 
Epoch 226/1000 
	 loss: 39.4342, MinusLogProbMetric: 39.4342, val_loss: 40.3898, val_MinusLogProbMetric: 40.3898

Epoch 226: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4342 - MinusLogProbMetric: 39.4342 - val_loss: 40.3898 - val_MinusLogProbMetric: 40.3898 - lr: 2.5000e-04 - 11s/epoch - 55ms/step
Epoch 227/1000
2023-09-13 16:25:08.865 
Epoch 227/1000 
	 loss: 39.4371, MinusLogProbMetric: 39.4371, val_loss: 40.3679, val_MinusLogProbMetric: 40.3679

Epoch 227: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.4371 - MinusLogProbMetric: 39.4371 - val_loss: 40.3679 - val_MinusLogProbMetric: 40.3679 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 228/1000
2023-09-13 16:25:20.461 
Epoch 228/1000 
	 loss: 39.4376, MinusLogProbMetric: 39.4376, val_loss: 40.3713, val_MinusLogProbMetric: 40.3713

Epoch 228: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.4376 - MinusLogProbMetric: 39.4376 - val_loss: 40.3713 - val_MinusLogProbMetric: 40.3713 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 229/1000
2023-09-13 16:25:31.990 
Epoch 229/1000 
	 loss: 39.4343, MinusLogProbMetric: 39.4343, val_loss: 40.3770, val_MinusLogProbMetric: 40.3770

Epoch 229: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.4343 - MinusLogProbMetric: 39.4343 - val_loss: 40.3770 - val_MinusLogProbMetric: 40.3770 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 230/1000
2023-09-13 16:25:43.206 
Epoch 230/1000 
	 loss: 39.4345, MinusLogProbMetric: 39.4345, val_loss: 40.3754, val_MinusLogProbMetric: 40.3754

Epoch 230: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4345 - MinusLogProbMetric: 39.4345 - val_loss: 40.3754 - val_MinusLogProbMetric: 40.3754 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 231/1000
2023-09-13 16:25:53.647 
Epoch 231/1000 
	 loss: 39.4355, MinusLogProbMetric: 39.4355, val_loss: 40.3828, val_MinusLogProbMetric: 40.3828

Epoch 231: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4355 - MinusLogProbMetric: 39.4355 - val_loss: 40.3828 - val_MinusLogProbMetric: 40.3828 - lr: 2.5000e-04 - 10s/epoch - 53ms/step
Epoch 232/1000
2023-09-13 16:26:03.314 
Epoch 232/1000 
	 loss: 39.4308, MinusLogProbMetric: 39.4308, val_loss: 40.3691, val_MinusLogProbMetric: 40.3691

Epoch 232: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4308 - MinusLogProbMetric: 39.4308 - val_loss: 40.3691 - val_MinusLogProbMetric: 40.3691 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 233/1000
2023-09-13 16:26:12.781 
Epoch 233/1000 
	 loss: 39.4283, MinusLogProbMetric: 39.4283, val_loss: 40.3937, val_MinusLogProbMetric: 40.3937

Epoch 233: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4283 - MinusLogProbMetric: 39.4283 - val_loss: 40.3937 - val_MinusLogProbMetric: 40.3937 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 234/1000
2023-09-13 16:26:22.056 
Epoch 234/1000 
	 loss: 39.4296, MinusLogProbMetric: 39.4296, val_loss: 40.3650, val_MinusLogProbMetric: 40.3650

Epoch 234: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4296 - MinusLogProbMetric: 39.4296 - val_loss: 40.3650 - val_MinusLogProbMetric: 40.3650 - lr: 2.5000e-04 - 9s/epoch - 47ms/step
Epoch 235/1000
2023-09-13 16:26:33.174 
Epoch 235/1000 
	 loss: 39.4305, MinusLogProbMetric: 39.4305, val_loss: 40.3900, val_MinusLogProbMetric: 40.3900

Epoch 235: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4305 - MinusLogProbMetric: 39.4305 - val_loss: 40.3900 - val_MinusLogProbMetric: 40.3900 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 236/1000
2023-09-13 16:26:44.322 
Epoch 236/1000 
	 loss: 39.4283, MinusLogProbMetric: 39.4283, val_loss: 40.3833, val_MinusLogProbMetric: 40.3833

Epoch 236: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4283 - MinusLogProbMetric: 39.4283 - val_loss: 40.3833 - val_MinusLogProbMetric: 40.3833 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 237/1000
2023-09-13 16:26:55.582 
Epoch 237/1000 
	 loss: 39.4284, MinusLogProbMetric: 39.4284, val_loss: 40.3652, val_MinusLogProbMetric: 40.3652

Epoch 237: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4284 - MinusLogProbMetric: 39.4284 - val_loss: 40.3652 - val_MinusLogProbMetric: 40.3652 - lr: 2.5000e-04 - 11s/epoch - 57ms/step
Epoch 238/1000
2023-09-13 16:27:07.191 
Epoch 238/1000 
	 loss: 39.4286, MinusLogProbMetric: 39.4286, val_loss: 40.3951, val_MinusLogProbMetric: 40.3951

Epoch 238: val_loss did not improve from 40.27020
196/196 - 12s - loss: 39.4286 - MinusLogProbMetric: 39.4286 - val_loss: 40.3951 - val_MinusLogProbMetric: 40.3951 - lr: 2.5000e-04 - 12s/epoch - 59ms/step
Epoch 239/1000
2023-09-13 16:27:16.729 
Epoch 239/1000 
	 loss: 39.4226, MinusLogProbMetric: 39.4226, val_loss: 40.3683, val_MinusLogProbMetric: 40.3683

Epoch 239: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4226 - MinusLogProbMetric: 39.4226 - val_loss: 40.3683 - val_MinusLogProbMetric: 40.3683 - lr: 2.5000e-04 - 10s/epoch - 49ms/step
Epoch 240/1000
2023-09-13 16:27:26.130 
Epoch 240/1000 
	 loss: 39.4298, MinusLogProbMetric: 39.4298, val_loss: 40.3909, val_MinusLogProbMetric: 40.3909

Epoch 240: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4298 - MinusLogProbMetric: 39.4298 - val_loss: 40.3909 - val_MinusLogProbMetric: 40.3909 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 241/1000
2023-09-13 16:27:35.542 
Epoch 241/1000 
	 loss: 39.4229, MinusLogProbMetric: 39.4229, val_loss: 40.3959, val_MinusLogProbMetric: 40.3959

Epoch 241: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4229 - MinusLogProbMetric: 39.4229 - val_loss: 40.3959 - val_MinusLogProbMetric: 40.3959 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 242/1000
2023-09-13 16:27:45.051 
Epoch 242/1000 
	 loss: 39.4209, MinusLogProbMetric: 39.4209, val_loss: 40.3738, val_MinusLogProbMetric: 40.3738

Epoch 242: val_loss did not improve from 40.27020
196/196 - 9s - loss: 39.4209 - MinusLogProbMetric: 39.4209 - val_loss: 40.3738 - val_MinusLogProbMetric: 40.3738 - lr: 2.5000e-04 - 9s/epoch - 48ms/step
Epoch 243/1000
2023-09-13 16:27:55.729 
Epoch 243/1000 
	 loss: 39.4211, MinusLogProbMetric: 39.4211, val_loss: 40.3768, val_MinusLogProbMetric: 40.3768

Epoch 243: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4211 - MinusLogProbMetric: 39.4211 - val_loss: 40.3768 - val_MinusLogProbMetric: 40.3768 - lr: 2.5000e-04 - 11s/epoch - 54ms/step
Epoch 244/1000
2023-09-13 16:28:05.829 
Epoch 244/1000 
	 loss: 39.4263, MinusLogProbMetric: 39.4263, val_loss: 40.3763, val_MinusLogProbMetric: 40.3763

Epoch 244: val_loss did not improve from 40.27020
196/196 - 10s - loss: 39.4263 - MinusLogProbMetric: 39.4263 - val_loss: 40.3763 - val_MinusLogProbMetric: 40.3763 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 245/1000
2023-09-13 16:28:17.295 
Epoch 245/1000 
	 loss: 39.4197, MinusLogProbMetric: 39.4197, val_loss: 40.3802, val_MinusLogProbMetric: 40.3802

Epoch 245: val_loss did not improve from 40.27020
196/196 - 11s - loss: 39.4197 - MinusLogProbMetric: 39.4197 - val_loss: 40.3802 - val_MinusLogProbMetric: 40.3802 - lr: 2.5000e-04 - 11s/epoch - 58ms/step
Epoch 246/1000
2023-09-13 16:28:27.533 
Epoch 246/1000 
	 loss: 39.4189, MinusLogProbMetric: 39.4189, val_loss: 40.3836, val_MinusLogProbMetric: 40.3836

Epoch 246: val_loss did not improve from 40.27020
Restoring model weights from the end of the best epoch: 146.
196/196 - 10s - loss: 39.4189 - MinusLogProbMetric: 39.4189 - val_loss: 40.3836 - val_MinusLogProbMetric: 40.3836 - lr: 2.5000e-04 - 10s/epoch - 52ms/step
Epoch 246: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF LR calculation...
niter = 10
batch_size = 100000
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
