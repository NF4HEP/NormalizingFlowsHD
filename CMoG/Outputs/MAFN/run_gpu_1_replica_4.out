2023-09-11 08:32:55.225817: Importing os...
2023-09-11 08:32:55.225860: Importing sys...
2023-09-11 08:32:55.225871: Importing and initializing argparse...
Visible devices: [1]
2023-09-11 08:32:55.241826: Importing timer from timeit...
2023-09-11 08:32:55.242346: Setting env variables for tf import (only device [1] will be available)...
2023-09-11 08:32:55.242393: Importing numpy...
2023-09-11 08:32:55.384681: Importing pandas...
2023-09-11 08:32:55.578613: Importing shutil...
2023-09-11 08:32:55.578646: Importing subprocess...
2023-09-11 08:32:55.578652: Importing tensorflow...
Tensorflow version: 2.9.3
2023-09-11 08:32:57.239654: Importing tensorflow_probability...
Tensorflow probability version: 0.13.0
2023-09-11 08:32:57.514638: Importing textwrap...
2023-09-11 08:32:57.514667: Importing timeit...
2023-09-11 08:32:57.514675: Importing traceback...
2023-09-11 08:32:57.514680: Importing typing...
2023-09-11 08:32:57.514689: Setting tf configs...
2023-09-11 08:32:57.546977: Importing custom module...
Successfully loaded GPU model: Tesla V100S-PCIE-32GB
2023-09-11 08:32:58.761507: All modues imported successfully.
Directory ../../results/MAFN_new/ already exists.
Directory ../../results/MAFN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_5/ already exists.
Skipping it.
===========
Run 5/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_16/ already exists.
Skipping it.
===========
Run 16/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_20/ already exists.
Skipping it.
===========
Run 20/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_26/ already exists.
Skipping it.
===========
Run 26/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_36/ already exists.
Skipping it.
===========
Run 36/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_43/ already exists.
Skipping it.
===========
Run 43/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_54/ already exists.
Skipping it.
===========
Run 54/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_60/ already exists.
Skipping it.
===========
Run 60/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_67/ already exists.
Skipping it.
===========
Run 67/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_76/ already exists.
Skipping it.
===========
Run 76/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_82/ already exists.
Skipping it.
===========
Run 82/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_87/ already exists.
Skipping it.
===========
Run 87/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_96/ already exists.
Skipping it.
===========
Run 96/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_100/ already exists.
Skipping it.
===========
Run 100/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_107/ already exists.
Skipping it.
===========
Run 107/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_116/ already exists.
Skipping it.
===========
Run 116/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_122/ already exists.
Skipping it.
===========
Run 122/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_128/ already exists.
Skipping it.
===========
Run 128/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_137/ already exists.
Skipping it.
===========
Run 137/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_145/ already exists.
Skipping it.
===========
Run 145/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_154/ already exists.
Skipping it.
===========
Run 154/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_158/ already exists.
Skipping it.
===========
Run 158/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_163/ already exists.
Skipping it.
===========
Run 163/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_167/ already exists.
Skipping it.
===========
Run 167/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_174/ already exists.
Skipping it.
===========
Run 174/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_175/ already exists.
Skipping it.
===========
Run 175/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_176/ already exists.
Skipping it.
===========
Run 176/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_177/ already exists.
Skipping it.
===========
Run 177/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_178/ already exists.
Skipping it.
===========
Run 178/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_179/ already exists.
Skipping it.
===========
Run 179/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_180/ already exists.
Skipping it.
===========
Run 180/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_181/ already exists.
Skipping it.
===========
Run 181/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_182/ already exists.
Skipping it.
===========
Run 182/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_183/ already exists.
Skipping it.
===========
Run 183/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_184/ already exists.
Skipping it.
===========
Run 184/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_185/ already exists.
Skipping it.
===========
Run 185/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_186/ already exists.
Skipping it.
===========
Run 186/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_187/ already exists.
Skipping it.
===========
Run 187/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_188/ already exists.
Skipping it.
===========
Run 188/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_189/ already exists.
Skipping it.
===========
Run 189/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_190/ already exists.
Skipping it.
===========
Run 190/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_191/ already exists.
Skipping it.
===========
Run 191/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_192/ already exists.
Skipping it.
===========
Run 192/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_193/ already exists.
Skipping it.
===========
Run 193/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_194/ already exists.
Skipping it.
===========
Run 194/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_195/ already exists.
Skipping it.
===========
Run 195/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_196/ already exists.
Skipping it.
===========
Run 196/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_197/ already exists.
Skipping it.
===========
Run 197/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_198/ already exists.
Skipping it.
===========
Run 198/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_199/ already exists.
Skipping it.
===========
Run 199/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_200/ already exists.
Skipping it.
===========
Run 200/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_201/ already exists.
Skipping it.
===========
Run 201/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_202/ already exists.
Skipping it.
===========
Run 202/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_203/ already exists.
Skipping it.
===========
Run 203/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_204/ already exists.
Skipping it.
===========
Run 204/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_205/ already exists.
Skipping it.
===========
Run 205/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_206/ already exists.
Skipping it.
===========
Run 206/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_207/ already exists.
Skipping it.
===========
Run 207/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_208/ already exists.
Skipping it.
===========
Run 208/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_209/ already exists.
Skipping it.
===========
Run 209/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_210/ already exists.
Skipping it.
===========
Run 210/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_211/ already exists.
Skipping it.
===========
Run 211/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_212/ already exists.
Skipping it.
===========
Run 212/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_213/ already exists.
Skipping it.
===========
Run 213/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_214/ already exists.
Skipping it.
===========
Run 214/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_215/ already exists.
Skipping it.
===========
Run 215/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_216/ already exists.
Skipping it.
===========
Run 216/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_217/ already exists.
Skipping it.
===========
Run 217/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_218/ already exists.
Skipping it.
===========
Run 218/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_219/ already exists.
Skipping it.
===========
Run 219/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_220/ already exists.
Skipping it.
===========
Run 220/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_221/ already exists.
Skipping it.
===========
Run 221/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_222/ already exists.
Skipping it.
===========
Run 222/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_223/ already exists.
Skipping it.
===========
Run 223/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_224/ already exists.
Skipping it.
===========
Run 224/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_225/ already exists.
Skipping it.
===========
Run 225/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_226/ already exists.
Skipping it.
===========
Run 226/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_227/ already exists.
Skipping it.
===========
Run 227/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_228/ already exists.
Skipping it.
===========
Run 228/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_229/ already exists.
Skipping it.
===========
Run 229/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_230/ already exists.
Skipping it.
===========
Run 230/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_231/ already exists.
Skipping it.
===========
Run 231/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_232/ already exists.
Skipping it.
===========
Run 232/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_233/ already exists.
Skipping it.
===========
Run 233/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_234/ already exists.
Skipping it.
===========
Run 234/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_235/ already exists.
Skipping it.
===========
Run 235/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_236/ already exists.
Skipping it.
===========
Run 236/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_237/ already exists.
Skipping it.
===========
Run 237/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_238/ already exists.
Skipping it.
===========
Run 238/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_239/ already exists.
Skipping it.
===========
Run 239/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_240/ already exists.
Skipping it.
===========
Run 240/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_241/ already exists.
Skipping it.
===========
Run 241/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_242/ already exists.
Skipping it.
===========
Run 242/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_243/ already exists.
Skipping it.
===========
Run 243/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_244/ already exists.
Skipping it.
===========
Run 244/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_245/ already exists.
Skipping it.
===========
Run 245/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_246/ already exists.
Skipping it.
===========
Run 246/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_247/ already exists.
Skipping it.
===========
Run 247/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_248/ already exists.
Skipping it.
===========
Run 248/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_249/ already exists.
Skipping it.
===========
Run 249/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_250/ already exists.
Skipping it.
===========
Run 250/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_251/ already exists.
Skipping it.
===========
Run 251/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_252/ already exists.
Skipping it.
===========
Run 252/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_253/ already exists.
Skipping it.
===========
Run 253/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_254/ already exists.
Skipping it.
===========
Run 254/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_255/ already exists.
Skipping it.
===========
Run 255/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_256/ already exists.
Skipping it.
===========
Run 256/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_257/ already exists.
Skipping it.
===========
Run 257/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_258/ already exists.
Skipping it.
===========
Run 258/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_259/ already exists.
Skipping it.
===========
Run 259/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_260/ already exists.
Skipping it.
===========
Run 260/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_261/ already exists.
Skipping it.
===========
Run 261/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_262/ already exists.
Skipping it.
===========
Run 262/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_263/ already exists.
Skipping it.
===========
Run 263/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_264/ already exists.
Skipping it.
===========
Run 264/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_265/ already exists.
Skipping it.
===========
Run 265/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_266/ already exists.
Skipping it.
===========
Run 266/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_267/ already exists.
Skipping it.
===========
Run 267/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_268/ already exists.
Skipping it.
===========
Run 268/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_269/ already exists.
Skipping it.
===========
Run 269/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_270/ already exists.
Skipping it.
===========
Run 270/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_271/ already exists.
Skipping it.
===========
Run 271/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_272/ already exists.
Skipping it.
===========
Run 272/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_273/ already exists.
Skipping it.
===========
Run 273/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_274/ already exists.
Skipping it.
===========
Run 274/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_275/ already exists.
Skipping it.
===========
Run 275/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_276/ already exists.
Skipping it.
===========
Run 276/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_277/ already exists.
Skipping it.
===========
Run 277/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_278/ already exists.
Skipping it.
===========
Run 278/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_279/ already exists.
Skipping it.
===========
Run 279/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_280/ already exists.
Skipping it.
===========
Run 280/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_281/ already exists.
Skipping it.
===========
Run 281/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_282/ already exists.
Skipping it.
===========
Run 282/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_283/ already exists.
Skipping it.
===========
Run 283/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_284/ already exists.
Skipping it.
===========
Run 284/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_285/ already exists.
Skipping it.
===========
Run 285/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_286/ already exists.
Skipping it.
===========
Run 286/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_287/ already exists.
Skipping it.
===========
Run 287/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_288/ already exists.
Skipping it.
===========
Run 288/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_289/ already exists.
Skipping it.
===========
Run 289/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_290/ already exists.
Skipping it.
===========
Run 290/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_291/ already exists.
Skipping it.
===========
Run 291/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_292/ already exists.
Skipping it.
===========
Run 292/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_293/ already exists.
Skipping it.
===========
Run 293/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_294/ already exists.
Skipping it.
===========
Run 294/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_295/ already exists.
Skipping it.
===========
Run 295/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_296/ already exists.
Skipping it.
===========
Run 296/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_297/ already exists.
Skipping it.
===========
Run 297/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_298/ already exists.
Skipping it.
===========
Run 298/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_299/ already exists.
Skipping it.
===========
Run 299/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_300/ already exists.
Skipping it.
===========
Run 300/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_301/ already exists.
Skipping it.
===========
Run 301/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_302/ already exists.
Skipping it.
===========
Run 302/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_303/ already exists.
Skipping it.
===========
Run 303/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_304/ already exists.
Skipping it.
===========
Run 304/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_305/ already exists.
Skipping it.
===========
Run 305/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_306/ already exists.
Skipping it.
===========
Run 306/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_307/ already exists.
Skipping it.
===========
Run 307/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_308/ already exists.
Skipping it.
===========
Run 308/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_309/ already exists.
Skipping it.
===========
Run 309/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_310/ already exists.
Skipping it.
===========
Run 310/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_311/ already exists.
Skipping it.
===========
Run 311/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_312/ already exists.
Skipping it.
===========
Run 312/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_313/ already exists.
Skipping it.
===========
Run 313/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_314/ already exists.
Skipping it.
===========
Run 314/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_315/ already exists.
Skipping it.
===========
Run 315/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_316/ already exists.
Skipping it.
===========
Run 316/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_317/ already exists.
Skipping it.
===========
Run 317/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_318/ already exists.
Skipping it.
===========
Run 318/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_319/ already exists.
Skipping it.
===========
Run 319/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_320/ already exists.
Skipping it.
===========
Run 320/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_321/ already exists.
Skipping it.
===========
Run 321/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_322/ already exists.
Skipping it.
===========
Run 322/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_323/ already exists.
Skipping it.
===========
Run 323/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_324/ already exists.
Skipping it.
===========
Run 324/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_325/ already exists.
Skipping it.
===========
Run 325/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_326/ already exists.
Skipping it.
===========
Run 326/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_327/ already exists.
Skipping it.
===========
Run 327/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_328/ already exists.
Skipping it.
===========
Run 328/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_329/ already exists.
Skipping it.
===========
Run 329/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_330/ already exists.
Skipping it.
===========
Run 330/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_331/ already exists.
Skipping it.
===========
Run 331/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_332/ already exists.
Skipping it.
===========
Run 332/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_333/ already exists.
Skipping it.
===========
Run 333/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_334/ already exists.
Skipping it.
===========
Run 334/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_335/ already exists.
Skipping it.
===========
Run 335/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_336/ already exists.
Skipping it.
===========
Run 336/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_337/ already exists.
Skipping it.
===========
Run 337/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_338/ already exists.
Skipping it.
===========
Run 338/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_339/ already exists.
Skipping it.
===========
Run 339/360 already exists. Skipping it.
===========

===========
Generating train data for run 340.
===========
Train data generated in 0.32 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: <tensorflow_probability.python.bijectors.chain.Chain object at 0x7f69007ba4c0>
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_340/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_340/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: <tensorflow_probability.python.bijectors.chain.Chain object at 0x7f69007ba4c0>
self.nf_dist: tfp.distributions.TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_340/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_340
self.data_kwargs: {'seed': 520}
self.x_data: [[6.0386963  0.30078053 4.582872   ... 4.9010735  5.585139   5.0534396 ]
 [7.9469204  4.5061865  5.2455854  ... 2.9358454  8.744124   6.9367347 ]
 [8.143589   4.4823375  5.2392807  ... 3.0099165  8.623259   7.0103106 ]
 ...
 [8.140467   4.6205688  5.2538304  ... 5.1522036  8.523501   6.461891  ]
 [5.550299   8.4923     5.931979   ... 9.995682   1.7941611  6.8577833 ]
 [7.7436986  5.02466    5.1777496  ... 2.148604   8.593714   7.418009  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1000)]            0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  9018400   
 r)                                                              
                                                                 
=================================================================
Total params: 9,018,400
Trainable params: 9,018,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal/log_prob/add:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7f6902d97430>
self.optimizer_config: {'class_name': 'Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.optimizer_v2.adam.Adam object at 0x7f68800df370>
type(optimizer): <class 'keras.optimizers.optimizer_v2.adam.Adam'>
self.optimizer_config: {'class_name': 'adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.optimizer_v2.adam.Adam object at 0x7f68800df370>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f690076fd00>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f69007375b0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f686c633cd0>, <keras.callbacks.ModelCheckpoint object at 0x7f686c633fa0>, <keras.callbacks.EarlyStopping object at 0x7f686c633d90>, <keras.callbacks.ReduceLROnPlateau object at 0x7f686c633f70>, <keras.callbacks.TerminateOnNaN object at 0x7f686c633ca0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_340/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 340/360 with hyperparameters:
timestamp = 2023-09-11 08:33:01.547422
ndims = 1000
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 9018400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = Tesla V100S-PCIE-32GB
===============

Training model with initial learning rate 0.001...
Train first sample: [ 6.0386963   0.30078053  4.582872    7.656263    0.50402063  8.927606
  5.0806236   0.7069437   3.2612228   9.222077    5.8550296   0.7950525
  3.7572262   5.421181   -0.42896372  5.3715286   5.0170646   4.5275445
  6.268279    8.342493    2.4881694   7.7397876   7.198324   10.337882
  7.1367445   7.992043    3.640705    1.6190335   9.687809   -0.10210621
  4.3673606   0.5702325   9.0355015   9.576009    7.180074    2.9750605
  2.7969558   2.6438603   1.315014    5.2577987   1.5748067   3.07832
  6.905322    7.2643003   0.31143492  3.629692    6.198628    9.935606
  4.738879    9.644313    2.6127305  -0.2701767   4.573748    2.6033232
  8.31127     2.847469    3.1219404   8.036686    8.350981    5.1923842
  7.0816703   3.7841296   0.439943    0.31411228  5.105436    0.16452146
  0.37245148  8.840347    7.522216    2.485342   -0.04555227  9.480491
  3.3716009   2.2168918   5.8693147   1.2792552   2.5388308   9.7780695
  6.3509502   5.2145343   4.668051    7.835037    0.81844634  9.829676
  8.602084    6.4478574   1.8822466   8.708197    9.9343      5.2983065
  4.648863    1.7545191   7.5778584   7.992651    1.2489895   7.932429
  0.19842413 10.670638    6.7138567   5.5415473   2.8593335   8.939356
  1.8772883   8.274395    9.729145    7.7069526   4.83206     0.20179847
  4.5409455   4.72331     2.8598065   4.388705    3.542864    1.3279399
  4.2783537   2.6017168   5.7597165   0.7641455   9.5386305   9.114207
  5.246056    8.810347    9.548426    1.1960151   4.535228    9.936641
 10.11391     6.0469294   1.2320046   5.771403    0.03692677  1.7631103
  9.768336    4.6296864   6.3364687   2.3349156   9.236544    8.197755
  3.2024207   7.716959    2.077003    4.211735    2.1907134   7.0612254
  1.2628212   4.2821627   1.9289484   4.29324     4.816094    7.6030316
  0.34979546  7.054235    2.5239222   2.5584276   7.064572    9.337272
  4.1277614   8.632163    1.1907344   7.2465253   7.3629594   1.4210125
  3.8094866   8.687733    1.3656402   0.28611335  5.895154    4.691248
  7.848699    8.486627    2.7608519   4.164383    5.0772963   6.1176133
 10.264451    6.3248825   3.0036852   2.4301364   9.323013    1.1239512
  6.9529996   8.971375    6.7585683   4.1878514   2.5465474   3.7158139
  7.954454    6.121273    8.889866    8.739019   10.887082    9.803803
  2.4961972   3.7658646   4.353828    5.831876    6.706101    2.2424636
  0.4813192   4.0677247   2.7481353   8.85868     8.81974     8.779158
  6.5635395   3.1331716   5.4378457   8.115037    0.15877736  7.7527685
 -0.23714772  9.2626095   7.987624    0.7620828   6.501852    3.2839687
  1.7200415   1.1543069   7.17581     5.3241725   9.85193    10.548408
 10.603701    2.2370188   9.374007    3.4676795   4.4167695   7.9351892
  2.2672663   5.607824    2.2299185   0.88661635  1.2501802   4.0727944
 -0.12534815  4.24075     6.864432    4.1316953   0.98898524  1.0468978
  2.6923618   1.5284702   9.68549     2.6858997   8.196742    5.9775615
  6.107674    3.8373623   9.739576    3.8176546   7.881323    5.9619036
  4.809063    9.994005    6.06644     0.60921174  5.0061116   8.33161
  7.0547867   8.514869    2.0673354   7.7308583   4.0995107   5.0039496
 10.610853    9.848376    8.120186    4.446167    8.818996    6.304151
  3.6133528   0.34783545  8.203926    4.955636    8.081435    7.584287
  7.8737516   3.389564    7.996908    6.0786796   4.5982037   7.0935416
  0.92889404  1.281023    2.9661057   9.792753    1.4344769   3.2898872
  1.1154623   3.3197548   4.133613    9.714192    7.8477564   3.915498
 -0.54802597  8.3167515   6.381558    1.8454669  11.718771    1.0781447
  8.230542    2.993074    4.4022226   7.81114     6.1109514   8.33177
  6.2205343   0.9577046   9.167438    7.7908244   7.120584    1.3328398
  3.1939583   1.6910427   8.12919     6.4541216   7.9364567  10.26773
  7.809719   10.104616    6.0293574   0.40289783 -0.560338    3.7847402
  7.9600444   9.035484   10.840271    1.0387208  -0.19058862  8.854946
  3.0963922   5.0594854  10.279567    5.074058    6.6726894   3.9883325
  7.652588    4.496253    3.0499647   2.3702488   2.5340867   3.782253
  6.6244855   9.641262    7.137413    6.8682413   1.8626316   4.317209
  4.4707828   6.841525    2.992224    2.4876325   3.3212593   7.333737
  5.75945     0.32461804  0.8335988   3.4026284   8.618828    6.705712
  6.8725452   7.33386     2.8872874   5.3803415   5.1434884   6.246975
  9.339241    0.6288371   8.414895    6.5827723   5.714417    7.4871626
  9.453507    0.7600125   1.494343    7.271453   -0.10680145  4.284081
  3.0645723   2.7818801   6.7562222   0.9355258   8.759254    4.4485765
  4.9456024   5.2843823   6.5932875   3.4578905   0.32452983  3.0972865
  0.45848465  5.198651    2.197647    9.560289    9.731855    6.5005336
  6.619211   10.057005    8.876658    8.295638    3.1194568   3.6742027
  2.26406     5.3983374   9.887169    9.133878    1.5052447   1.7451565
  8.9965925   5.319445    2.527405    6.8142905   6.4233      1.2479438
  4.035429    0.24714679  2.1173966   1.830858    1.9078584   7.0054536
  0.5009528   0.8397763   2.0496254   2.9811964   2.9665575   3.3201675
  7.2900653   9.622518    4.901422    7.8189707   3.9295015   0.91512156
  4.572243    3.2736297   4.8408017   7.065958    4.651118    9.0410385
  8.961053    5.5870433   5.2621417   1.1291223   3.93055     6.9391193
  3.508282    0.4460107   9.179407    7.387717    4.650465    8.17948
  7.53271     5.0031796   8.804058    9.204221    3.6460009   7.006398
  5.8495746   5.197357    9.277365    2.9547234  10.355085    8.981658
  5.367272    8.041138    7.377086    7.5142937   4.0544214   2.2740157
  6.749342    8.733181   -1.1557603   6.3426285   4.84659     8.766928
  2.8006268   4.1529183   4.987336    0.13959682  6.5040164   8.188027
  1.676772    2.4030275   0.5443996   9.24266     5.4919004   9.14114
  5.4362607   7.7436833   3.4114141   2.927477    3.843325    6.4828835
  2.9296427   9.1742115   8.056144   -0.09604371  2.0134284   1.6318083
  0.04543668  2.690591    4.990765    8.81346     2.1004107   4.4873705
 10.513251    7.137761    7.6034775   5.209668    9.811113    5.6359825
  0.19526497  2.564422    4.0089235   6.4994254   7.695936    4.1304693
  7.2958503   8.454953    2.967984    9.869264    7.2374787   8.593143
  5.7742076   7.5300508   7.2095394   7.823381    2.118999    5.039945
  4.053479    9.185997    0.9152442  10.862353    8.841984    0.75618994
  4.901044    7.2554336   7.1853967   9.084257    8.29529     4.220908
  5.8150444   7.7635503   1.2401824   1.3507668   4.54757     3.457343
  7.9834795   5.028612    3.85299     8.574433    8.163936   10.616821
  8.4081      4.1708117   1.2379287   8.800616    1.4772482   4.080577
  8.428701   10.380288    6.389518    6.8510385   0.61914694  4.0696154
  6.8948746   3.383478    0.4705223   3.009568    2.6594605   3.048335
  5.988357    7.1357174   3.261515    4.0008183   0.27625528 -0.3875654
  2.6110508   6.7222776   4.8376966   7.503794    6.6424117   8.686342
  7.1706657   9.419308    7.926278    6.2358265   6.0555067  -0.70361733
 10.064413    1.4912657   8.07811     7.900392    4.8439436   2.0139859
  1.0714337   7.2137423   4.526915    6.6356516   9.933811    1.5130765
  9.312532    3.7438834   3.550579    9.596389    9.815127    1.7642053
  7.4918814  -0.49520278  6.4749107   9.756271    7.145049    4.039104
  3.7851322   4.082335    6.1268287   8.183756    9.32123     0.28198594
  2.5236871  -0.31258178  2.2504802   3.5232162   4.9025984   6.3538814
  7.8291597   9.178961   10.243786    7.067563    8.285971    9.500681
  3.5682902   8.450219    0.17376387  0.216589    2.7681222   4.1601896
  6.1601834   1.706507    6.643297    7.9561872   1.7723906   4.5958123
  5.858561    4.6678243   8.187405    9.715012    8.1015      0.45350024
  7.7912116   0.77989995  2.3104167   1.3162912   1.205177    5.248102
  6.7170506   5.558635    9.548942    2.291232    7.7552695   8.649344
  5.677332    4.394188    6.64837     4.7241607   5.719767    3.967581
  4.259147    7.17209     1.0130833   1.7905484   8.393191    7.4030704
  2.735002    2.5851526   9.099808    7.8557224   6.1393533   2.1640992
  0.7774042   4.113809    6.8772874   9.341514    7.624882   -0.15643695
  2.3431437   3.3053102   1.6893227   7.5518737   7.47631     5.387754
  9.710713    1.6661869   8.289583    1.1974262   3.0808344   7.3471923
  0.8228001   5.6459312   3.6627483   7.2736874   8.484636    7.5182805
  6.5065517   0.4700985   2.234543    5.2005877   3.5432315   2.8302953
  2.0971265   9.56212     3.0628858   4.7415     -0.44130558  9.013574
  1.085037    3.311532    2.5385356   8.806095    2.0905962   7.8503737
  8.578108    9.528165    0.590898    1.9645467   7.9985986   1.753687
  3.172571    1.6611466   1.8709267   4.7864184   1.3145969   3.1479964
  4.083562    0.2390917   3.327033    0.9105044   6.7123947   7.861191
  7.02552     0.75634694  5.9596577   8.067755    2.4828937   7.6143017
  8.580062    7.3855762  -0.04546678  0.0738206   1.8115419   2.7274795
  6.6129613   3.8759396   6.692868    3.7261245   1.3076189   3.1666129
  9.223293    9.462051    2.376804    7.5547466   2.749257    8.444417
  1.3476957   6.958887    0.12667698  9.694718    6.407499    8.479325
  5.627874    4.950144    6.2193155   5.3255057   4.9456944   8.290707
  0.8348843   2.2261314   4.1954646   3.6872017   0.73160475  8.504263
  7.791428    5.3747725   9.8119135   0.7039877   7.6769605   2.5379546
  3.694837    2.045665    7.2654924   0.12175488  7.247275    7.029465
  0.6658832   8.352133    5.5662146   9.030525    7.8712974   5.6255913
  8.1955      3.5710793   4.832326    5.828453   10.745017    1.85231
 -0.526502    3.3114655   4.8024893   0.62556016  4.9190855   9.197764
  6.527681    8.61912     9.540909    9.433219    7.9817605   5.9839487
  4.9048758   0.6134869   5.948723   10.432518    8.046861    3.3048022
  1.5137587   7.991438    7.427192    9.765905    8.476495    5.9867887
  1.0616344   5.6400924   2.9184952   5.1216874   2.580817    8.646928
  7.5732      4.096987    6.089647    4.3319507   8.435398    2.1281555
  7.02788     9.129615    1.7530978   1.3687971   7.042738    7.6120076
  4.263667    6.845998    3.1399002   4.1320887   1.0887251   3.7039056
  2.7662733   3.7930636   9.0424595   1.3231362   3.5029469   6.702694
  9.477917    0.9764585   9.146437    0.77568066  5.0711017   4.2204366
  1.9013925   3.6039436   4.875466    8.647586    9.651502    6.2052207
  8.608539    6.7567143   3.158669    1.8811914   4.3497324   5.161394
  0.6098187   1.152159    6.051886    1.3697395   8.290108    2.6722713
  2.2818537   0.9584924   9.105338    1.0756454   1.5344902   8.241914
  2.561514    6.2516336   7.197662    6.6100316   8.612244    7.1160245
  1.4579626   5.4742584   6.604126    8.5800705   0.06284574  7.271172
  9.004775    7.700049    5.588264    4.5855756   4.7795944   7.2477436
  8.905804    6.081058    9.249524    7.4357276   0.8587049   4.7164693
  2.8504999   3.989924    3.8770769   2.9917765   5.714236    6.905015
  2.6859546   1.846874    0.41534102  4.812243    1.8113589  -0.9216505
  9.0558815   4.663535    1.0859932   8.355898    7.844323    4.0918174
  0.6433816   1.5224574   4.468763    8.928121    1.204919    8.635436
 -0.03399917  4.6824536   6.482672    0.5008905   5.682656    8.837162
  2.072514    7.1392884   6.1446853   2.1056101   0.07073235  0.26507834
  5.238253    9.371503    6.251286    7.188611    5.0308127   6.007279
  1.024926    8.809044    7.712478   10.019146    2.5657964   3.195103
  0.9103755   9.777725    7.5711966   3.4351816   5.4496226   4.112291
  1.660826    1.7369623   9.639072    2.935317    9.930944    0.73487484
  5.733989    1.3034487   0.502199    5.5747876   1.0674012   8.124411
  7.0287094   2.9280264   9.545342    7.30834     2.6214435   7.561452
  7.846946    1.3374016   3.65282     3.05842     6.171471    8.9460125
  1.6092017   8.305956   -0.07000089  6.6192155   4.523222    7.941383
  7.4171886   4.9010735   5.585139    5.0534396 ]
Epoch 1/1000
2023-09-11 08:33:29.482 
Epoch 1/1000 
	 loss: 1547.9681, MinusLogProbMetric: 1547.9681, val_loss: 609.1588, val_MinusLogProbMetric: 609.1588

Epoch 1: val_loss improved from inf to 609.15881, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 28s - loss: 1547.9681 - MinusLogProbMetric: 1547.9681 - val_loss: 609.1588 - val_MinusLogProbMetric: 609.1588 - lr: 0.0010 - 28s/epoch - 143ms/step
Epoch 2/1000
2023-09-11 08:33:36.814 
Epoch 2/1000 
	 loss: 566.1938, MinusLogProbMetric: 566.1938, val_loss: 545.7505, val_MinusLogProbMetric: 545.7505

Epoch 2: val_loss improved from 609.15881 to 545.75049, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 566.1938 - MinusLogProbMetric: 566.1938 - val_loss: 545.7505 - val_MinusLogProbMetric: 545.7505 - lr: 0.0010 - 7s/epoch - 37ms/step
Epoch 3/1000
2023-09-11 08:33:43.972 
Epoch 3/1000 
	 loss: 520.6045, MinusLogProbMetric: 520.6045, val_loss: 499.1904, val_MinusLogProbMetric: 499.1904

Epoch 3: val_loss improved from 545.75049 to 499.19037, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 520.6045 - MinusLogProbMetric: 520.6045 - val_loss: 499.1904 - val_MinusLogProbMetric: 499.1904 - lr: 0.0010 - 7s/epoch - 36ms/step
Epoch 4/1000
2023-09-11 08:33:51.205 
Epoch 4/1000 
	 loss: 503.4648, MinusLogProbMetric: 503.4648, val_loss: 489.4966, val_MinusLogProbMetric: 489.4966

Epoch 4: val_loss improved from 499.19037 to 489.49655, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 503.4648 - MinusLogProbMetric: 503.4648 - val_loss: 489.4966 - val_MinusLogProbMetric: 489.4966 - lr: 0.0010 - 7s/epoch - 37ms/step
Epoch 5/1000
2023-09-11 08:33:58.626 
Epoch 5/1000 
	 loss: 488.5337, MinusLogProbMetric: 488.5337, val_loss: 545.5322, val_MinusLogProbMetric: 545.5322

Epoch 5: val_loss did not improve from 489.49655
196/196 - 7s - loss: 488.5337 - MinusLogProbMetric: 488.5337 - val_loss: 545.5322 - val_MinusLogProbMetric: 545.5322 - lr: 0.0010 - 7s/epoch - 37ms/step
Epoch 6/1000
2023-09-11 08:34:06.089 
Epoch 6/1000 
	 loss: 479.5721, MinusLogProbMetric: 479.5721, val_loss: 556.6989, val_MinusLogProbMetric: 556.6989

Epoch 6: val_loss did not improve from 489.49655
196/196 - 7s - loss: 479.5721 - MinusLogProbMetric: 479.5721 - val_loss: 556.6989 - val_MinusLogProbMetric: 556.6989 - lr: 0.0010 - 7s/epoch - 38ms/step
Epoch 7/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 167: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-11 08:34:12.698 
Epoch 7/1000 
	 loss: inf, MinusLogProbMetric: 20464896.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 7: val_loss did not improve from 489.49655
196/196 - 7s - loss: inf - MinusLogProbMetric: 20464896.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 7s/epoch - 34ms/step
The loss history contains Inf values.
Training failed: trying again with seed 105132 and lr 0.0003333333333333333.
===========
Generating train data for run 340.
===========
Train data generated in 0.25 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: <tensorflow_probability.python.bijectors.chain.Chain object at 0x7f69007f2130>
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_340/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_340/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: <tensorflow_probability.python.bijectors.chain.Chain object at 0x7f69007f2130>
self.nf_dist: tfp.distributions.TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_340/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_340
self.data_kwargs: {'seed': 520}
self.x_data: [[6.0386963  0.30078053 4.582872   ... 4.9010735  5.585139   5.0534396 ]
 [7.9469204  4.5061865  5.2455854  ... 2.9358454  8.744124   6.9367347 ]
 [8.143589   4.4823375  5.2392807  ... 3.0099165  8.623259   7.0103106 ]
 ...
 [8.140467   4.6205688  5.2538304  ... 5.1522036  8.523501   6.461891  ]
 [5.550299   8.4923     5.931979   ... 9.995682   1.7941611  6.8577833 ]
 [7.7436986  5.02466    5.1777496  ... 2.148604   8.593714   7.418009  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_12 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  9018400   
 yer)                                                            
                                                                 
=================================================================
Total params: 9,018,400
Trainable params: 9,018,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal/log_prob/add:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7f6818797ac0>
self.optimizer_config: {'class_name': 'Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.optimizer_v2.adam.Adam object at 0x7f68184e29a0>
type(optimizer): <class 'keras.optimizers.optimizer_v2.adam.Adam'>
self.optimizer_config: {'class_name': 'adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.optimizer_v2.adam.Adam object at 0x7f68184e29a0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f68187b3220>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f68184b8910>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f68184b8fd0>, <keras.callbacks.ModelCheckpoint object at 0x7f68184503d0>, <keras.callbacks.EarlyStopping object at 0x7f6818450370>, <keras.callbacks.ReduceLROnPlateau object at 0x7f6818450400>, <keras.callbacks.TerminateOnNaN object at 0x7f6818450490>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 340/360 with hyperparameters:
timestamp = 2023-09-11 08:34:15.102027
ndims = 1000
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 9018400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = Tesla V100S-PCIE-32GB
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 6.0386963   0.30078053  4.582872    7.656263    0.50402063  8.927606
  5.0806236   0.7069437   3.2612228   9.222077    5.8550296   0.7950525
  3.7572262   5.421181   -0.42896372  5.3715286   5.0170646   4.5275445
  6.268279    8.342493    2.4881694   7.7397876   7.198324   10.337882
  7.1367445   7.992043    3.640705    1.6190335   9.687809   -0.10210621
  4.3673606   0.5702325   9.0355015   9.576009    7.180074    2.9750605
  2.7969558   2.6438603   1.315014    5.2577987   1.5748067   3.07832
  6.905322    7.2643003   0.31143492  3.629692    6.198628    9.935606
  4.738879    9.644313    2.6127305  -0.2701767   4.573748    2.6033232
  8.31127     2.847469    3.1219404   8.036686    8.350981    5.1923842
  7.0816703   3.7841296   0.439943    0.31411228  5.105436    0.16452146
  0.37245148  8.840347    7.522216    2.485342   -0.04555227  9.480491
  3.3716009   2.2168918   5.8693147   1.2792552   2.5388308   9.7780695
  6.3509502   5.2145343   4.668051    7.835037    0.81844634  9.829676
  8.602084    6.4478574   1.8822466   8.708197    9.9343      5.2983065
  4.648863    1.7545191   7.5778584   7.992651    1.2489895   7.932429
  0.19842413 10.670638    6.7138567   5.5415473   2.8593335   8.939356
  1.8772883   8.274395    9.729145    7.7069526   4.83206     0.20179847
  4.5409455   4.72331     2.8598065   4.388705    3.542864    1.3279399
  4.2783537   2.6017168   5.7597165   0.7641455   9.5386305   9.114207
  5.246056    8.810347    9.548426    1.1960151   4.535228    9.936641
 10.11391     6.0469294   1.2320046   5.771403    0.03692677  1.7631103
  9.768336    4.6296864   6.3364687   2.3349156   9.236544    8.197755
  3.2024207   7.716959    2.077003    4.211735    2.1907134   7.0612254
  1.2628212   4.2821627   1.9289484   4.29324     4.816094    7.6030316
  0.34979546  7.054235    2.5239222   2.5584276   7.064572    9.337272
  4.1277614   8.632163    1.1907344   7.2465253   7.3629594   1.4210125
  3.8094866   8.687733    1.3656402   0.28611335  5.895154    4.691248
  7.848699    8.486627    2.7608519   4.164383    5.0772963   6.1176133
 10.264451    6.3248825   3.0036852   2.4301364   9.323013    1.1239512
  6.9529996   8.971375    6.7585683   4.1878514   2.5465474   3.7158139
  7.954454    6.121273    8.889866    8.739019   10.887082    9.803803
  2.4961972   3.7658646   4.353828    5.831876    6.706101    2.2424636
  0.4813192   4.0677247   2.7481353   8.85868     8.81974     8.779158
  6.5635395   3.1331716   5.4378457   8.115037    0.15877736  7.7527685
 -0.23714772  9.2626095   7.987624    0.7620828   6.501852    3.2839687
  1.7200415   1.1543069   7.17581     5.3241725   9.85193    10.548408
 10.603701    2.2370188   9.374007    3.4676795   4.4167695   7.9351892
  2.2672663   5.607824    2.2299185   0.88661635  1.2501802   4.0727944
 -0.12534815  4.24075     6.864432    4.1316953   0.98898524  1.0468978
  2.6923618   1.5284702   9.68549     2.6858997   8.196742    5.9775615
  6.107674    3.8373623   9.739576    3.8176546   7.881323    5.9619036
  4.809063    9.994005    6.06644     0.60921174  5.0061116   8.33161
  7.0547867   8.514869    2.0673354   7.7308583   4.0995107   5.0039496
 10.610853    9.848376    8.120186    4.446167    8.818996    6.304151
  3.6133528   0.34783545  8.203926    4.955636    8.081435    7.584287
  7.8737516   3.389564    7.996908    6.0786796   4.5982037   7.0935416
  0.92889404  1.281023    2.9661057   9.792753    1.4344769   3.2898872
  1.1154623   3.3197548   4.133613    9.714192    7.8477564   3.915498
 -0.54802597  8.3167515   6.381558    1.8454669  11.718771    1.0781447
  8.230542    2.993074    4.4022226   7.81114     6.1109514   8.33177
  6.2205343   0.9577046   9.167438    7.7908244   7.120584    1.3328398
  3.1939583   1.6910427   8.12919     6.4541216   7.9364567  10.26773
  7.809719   10.104616    6.0293574   0.40289783 -0.560338    3.7847402
  7.9600444   9.035484   10.840271    1.0387208  -0.19058862  8.854946
  3.0963922   5.0594854  10.279567    5.074058    6.6726894   3.9883325
  7.652588    4.496253    3.0499647   2.3702488   2.5340867   3.782253
  6.6244855   9.641262    7.137413    6.8682413   1.8626316   4.317209
  4.4707828   6.841525    2.992224    2.4876325   3.3212593   7.333737
  5.75945     0.32461804  0.8335988   3.4026284   8.618828    6.705712
  6.8725452   7.33386     2.8872874   5.3803415   5.1434884   6.246975
  9.339241    0.6288371   8.414895    6.5827723   5.714417    7.4871626
  9.453507    0.7600125   1.494343    7.271453   -0.10680145  4.284081
  3.0645723   2.7818801   6.7562222   0.9355258   8.759254    4.4485765
  4.9456024   5.2843823   6.5932875   3.4578905   0.32452983  3.0972865
  0.45848465  5.198651    2.197647    9.560289    9.731855    6.5005336
  6.619211   10.057005    8.876658    8.295638    3.1194568   3.6742027
  2.26406     5.3983374   9.887169    9.133878    1.5052447   1.7451565
  8.9965925   5.319445    2.527405    6.8142905   6.4233      1.2479438
  4.035429    0.24714679  2.1173966   1.830858    1.9078584   7.0054536
  0.5009528   0.8397763   2.0496254   2.9811964   2.9665575   3.3201675
  7.2900653   9.622518    4.901422    7.8189707   3.9295015   0.91512156
  4.572243    3.2736297   4.8408017   7.065958    4.651118    9.0410385
  8.961053    5.5870433   5.2621417   1.1291223   3.93055     6.9391193
  3.508282    0.4460107   9.179407    7.387717    4.650465    8.17948
  7.53271     5.0031796   8.804058    9.204221    3.6460009   7.006398
  5.8495746   5.197357    9.277365    2.9547234  10.355085    8.981658
  5.367272    8.041138    7.377086    7.5142937   4.0544214   2.2740157
  6.749342    8.733181   -1.1557603   6.3426285   4.84659     8.766928
  2.8006268   4.1529183   4.987336    0.13959682  6.5040164   8.188027
  1.676772    2.4030275   0.5443996   9.24266     5.4919004   9.14114
  5.4362607   7.7436833   3.4114141   2.927477    3.843325    6.4828835
  2.9296427   9.1742115   8.056144   -0.09604371  2.0134284   1.6318083
  0.04543668  2.690591    4.990765    8.81346     2.1004107   4.4873705
 10.513251    7.137761    7.6034775   5.209668    9.811113    5.6359825
  0.19526497  2.564422    4.0089235   6.4994254   7.695936    4.1304693
  7.2958503   8.454953    2.967984    9.869264    7.2374787   8.593143
  5.7742076   7.5300508   7.2095394   7.823381    2.118999    5.039945
  4.053479    9.185997    0.9152442  10.862353    8.841984    0.75618994
  4.901044    7.2554336   7.1853967   9.084257    8.29529     4.220908
  5.8150444   7.7635503   1.2401824   1.3507668   4.54757     3.457343
  7.9834795   5.028612    3.85299     8.574433    8.163936   10.616821
  8.4081      4.1708117   1.2379287   8.800616    1.4772482   4.080577
  8.428701   10.380288    6.389518    6.8510385   0.61914694  4.0696154
  6.8948746   3.383478    0.4705223   3.009568    2.6594605   3.048335
  5.988357    7.1357174   3.261515    4.0008183   0.27625528 -0.3875654
  2.6110508   6.7222776   4.8376966   7.503794    6.6424117   8.686342
  7.1706657   9.419308    7.926278    6.2358265   6.0555067  -0.70361733
 10.064413    1.4912657   8.07811     7.900392    4.8439436   2.0139859
  1.0714337   7.2137423   4.526915    6.6356516   9.933811    1.5130765
  9.312532    3.7438834   3.550579    9.596389    9.815127    1.7642053
  7.4918814  -0.49520278  6.4749107   9.756271    7.145049    4.039104
  3.7851322   4.082335    6.1268287   8.183756    9.32123     0.28198594
  2.5236871  -0.31258178  2.2504802   3.5232162   4.9025984   6.3538814
  7.8291597   9.178961   10.243786    7.067563    8.285971    9.500681
  3.5682902   8.450219    0.17376387  0.216589    2.7681222   4.1601896
  6.1601834   1.706507    6.643297    7.9561872   1.7723906   4.5958123
  5.858561    4.6678243   8.187405    9.715012    8.1015      0.45350024
  7.7912116   0.77989995  2.3104167   1.3162912   1.205177    5.248102
  6.7170506   5.558635    9.548942    2.291232    7.7552695   8.649344
  5.677332    4.394188    6.64837     4.7241607   5.719767    3.967581
  4.259147    7.17209     1.0130833   1.7905484   8.393191    7.4030704
  2.735002    2.5851526   9.099808    7.8557224   6.1393533   2.1640992
  0.7774042   4.113809    6.8772874   9.341514    7.624882   -0.15643695
  2.3431437   3.3053102   1.6893227   7.5518737   7.47631     5.387754
  9.710713    1.6661869   8.289583    1.1974262   3.0808344   7.3471923
  0.8228001   5.6459312   3.6627483   7.2736874   8.484636    7.5182805
  6.5065517   0.4700985   2.234543    5.2005877   3.5432315   2.8302953
  2.0971265   9.56212     3.0628858   4.7415     -0.44130558  9.013574
  1.085037    3.311532    2.5385356   8.806095    2.0905962   7.8503737
  8.578108    9.528165    0.590898    1.9645467   7.9985986   1.753687
  3.172571    1.6611466   1.8709267   4.7864184   1.3145969   3.1479964
  4.083562    0.2390917   3.327033    0.9105044   6.7123947   7.861191
  7.02552     0.75634694  5.9596577   8.067755    2.4828937   7.6143017
  8.580062    7.3855762  -0.04546678  0.0738206   1.8115419   2.7274795
  6.6129613   3.8759396   6.692868    3.7261245   1.3076189   3.1666129
  9.223293    9.462051    2.376804    7.5547466   2.749257    8.444417
  1.3476957   6.958887    0.12667698  9.694718    6.407499    8.479325
  5.627874    4.950144    6.2193155   5.3255057   4.9456944   8.290707
  0.8348843   2.2261314   4.1954646   3.6872017   0.73160475  8.504263
  7.791428    5.3747725   9.8119135   0.7039877   7.6769605   2.5379546
  3.694837    2.045665    7.2654924   0.12175488  7.247275    7.029465
  0.6658832   8.352133    5.5662146   9.030525    7.8712974   5.6255913
  8.1955      3.5710793   4.832326    5.828453   10.745017    1.85231
 -0.526502    3.3114655   4.8024893   0.62556016  4.9190855   9.197764
  6.527681    8.61912     9.540909    9.433219    7.9817605   5.9839487
  4.9048758   0.6134869   5.948723   10.432518    8.046861    3.3048022
  1.5137587   7.991438    7.427192    9.765905    8.476495    5.9867887
  1.0616344   5.6400924   2.9184952   5.1216874   2.580817    8.646928
  7.5732      4.096987    6.089647    4.3319507   8.435398    2.1281555
  7.02788     9.129615    1.7530978   1.3687971   7.042738    7.6120076
  4.263667    6.845998    3.1399002   4.1320887   1.0887251   3.7039056
  2.7662733   3.7930636   9.0424595   1.3231362   3.5029469   6.702694
  9.477917    0.9764585   9.146437    0.77568066  5.0711017   4.2204366
  1.9013925   3.6039436   4.875466    8.647586    9.651502    6.2052207
  8.608539    6.7567143   3.158669    1.8811914   4.3497324   5.161394
  0.6098187   1.152159    6.051886    1.3697395   8.290108    2.6722713
  2.2818537   0.9584924   9.105338    1.0756454   1.5344902   8.241914
  2.561514    6.2516336   7.197662    6.6100316   8.612244    7.1160245
  1.4579626   5.4742584   6.604126    8.5800705   0.06284574  7.271172
  9.004775    7.700049    5.588264    4.5855756   4.7795944   7.2477436
  8.905804    6.081058    9.249524    7.4357276   0.8587049   4.7164693
  2.8504999   3.989924    3.8770769   2.9917765   5.714236    6.905015
  2.6859546   1.846874    0.41534102  4.812243    1.8113589  -0.9216505
  9.0558815   4.663535    1.0859932   8.355898    7.844323    4.0918174
  0.6433816   1.5224574   4.468763    8.928121    1.204919    8.635436
 -0.03399917  4.6824536   6.482672    0.5008905   5.682656    8.837162
  2.072514    7.1392884   6.1446853   2.1056101   0.07073235  0.26507834
  5.238253    9.371503    6.251286    7.188611    5.0308127   6.007279
  1.024926    8.809044    7.712478   10.019146    2.5657964   3.195103
  0.9103755   9.777725    7.5711966   3.4351816   5.4496226   4.112291
  1.660826    1.7369623   9.639072    2.935317    9.930944    0.73487484
  5.733989    1.3034487   0.502199    5.5747876   1.0674012   8.124411
  7.0287094   2.9280264   9.545342    7.30834     2.6214435   7.561452
  7.846946    1.3374016   3.65282     3.05842     6.171471    8.9460125
  1.6092017   8.305956   -0.07000089  6.6192155   4.523222    7.941383
  7.4171886   4.9010735   5.585139    5.0534396 ]
Epoch 1/1000
2023-09-11 08:34:40.172 
Epoch 1/1000 
	 loss: 588.4609, MinusLogProbMetric: 588.4609, val_loss: 456.5951, val_MinusLogProbMetric: 456.5951

Epoch 1: val_loss improved from inf to 456.59512, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 25s - loss: 588.4609 - MinusLogProbMetric: 588.4609 - val_loss: 456.5951 - val_MinusLogProbMetric: 456.5951 - lr: 3.3333e-04 - 25s/epoch - 129ms/step
Epoch 2/1000
2023-09-11 08:34:47.602 
Epoch 2/1000 
	 loss: 451.6514, MinusLogProbMetric: 451.6514, val_loss: 451.0246, val_MinusLogProbMetric: 451.0246

Epoch 2: val_loss improved from 456.59512 to 451.02460, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 451.6514 - MinusLogProbMetric: 451.6514 - val_loss: 451.0246 - val_MinusLogProbMetric: 451.0246 - lr: 3.3333e-04 - 7s/epoch - 37ms/step
Epoch 3/1000
2023-09-11 08:34:54.745 
Epoch 3/1000 
	 loss: 447.4171, MinusLogProbMetric: 447.4171, val_loss: 446.1892, val_MinusLogProbMetric: 446.1892

Epoch 3: val_loss improved from 451.02460 to 446.18921, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 447.4171 - MinusLogProbMetric: 447.4171 - val_loss: 446.1892 - val_MinusLogProbMetric: 446.1892 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 4/1000
2023-09-11 08:35:01.902 
Epoch 4/1000 
	 loss: 442.8983, MinusLogProbMetric: 442.8983, val_loss: 443.0941, val_MinusLogProbMetric: 443.0941

Epoch 4: val_loss improved from 446.18921 to 443.09415, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 442.8983 - MinusLogProbMetric: 442.8983 - val_loss: 443.0941 - val_MinusLogProbMetric: 443.0941 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 5/1000
2023-09-11 08:35:09.168 
Epoch 5/1000 
	 loss: 440.3334, MinusLogProbMetric: 440.3334, val_loss: 442.0277, val_MinusLogProbMetric: 442.0277

Epoch 5: val_loss improved from 443.09415 to 442.02774, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 8s - loss: 440.3334 - MinusLogProbMetric: 440.3334 - val_loss: 442.0277 - val_MinusLogProbMetric: 442.0277 - lr: 3.3333e-04 - 8s/epoch - 41ms/step
Epoch 6/1000
2023-09-11 08:35:17.201 
Epoch 6/1000 
	 loss: 437.7724, MinusLogProbMetric: 437.7724, val_loss: 434.8350, val_MinusLogProbMetric: 434.8350

Epoch 6: val_loss improved from 442.02774 to 434.83502, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 8s - loss: 437.7724 - MinusLogProbMetric: 437.7724 - val_loss: 434.8350 - val_MinusLogProbMetric: 434.8350 - lr: 3.3333e-04 - 8s/epoch - 41ms/step
Epoch 7/1000
2023-09-11 08:35:25.017 
Epoch 7/1000 
	 loss: 436.8064, MinusLogProbMetric: 436.8064, val_loss: 432.0264, val_MinusLogProbMetric: 432.0264

Epoch 7: val_loss improved from 434.83502 to 432.02640, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 436.8064 - MinusLogProbMetric: 436.8064 - val_loss: 432.0264 - val_MinusLogProbMetric: 432.0264 - lr: 3.3333e-04 - 7s/epoch - 37ms/step
Epoch 8/1000
2023-09-11 08:35:32.213 
Epoch 8/1000 
	 loss: 431.6395, MinusLogProbMetric: 431.6395, val_loss: 433.1689, val_MinusLogProbMetric: 433.1689

Epoch 8: val_loss did not improve from 432.02640
196/196 - 7s - loss: 431.6395 - MinusLogProbMetric: 431.6395 - val_loss: 433.1689 - val_MinusLogProbMetric: 433.1689 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 9/1000
2023-09-11 08:35:39.171 
Epoch 9/1000 
	 loss: 431.0322, MinusLogProbMetric: 431.0322, val_loss: 427.1865, val_MinusLogProbMetric: 427.1865

Epoch 9: val_loss improved from 432.02640 to 427.18649, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 431.0322 - MinusLogProbMetric: 431.0322 - val_loss: 427.1865 - val_MinusLogProbMetric: 427.1865 - lr: 3.3333e-04 - 7s/epoch - 38ms/step
Epoch 10/1000
2023-09-11 08:35:46.591 
Epoch 10/1000 
	 loss: 432.7740, MinusLogProbMetric: 432.7740, val_loss: 427.7294, val_MinusLogProbMetric: 427.7294

Epoch 10: val_loss did not improve from 427.18649
196/196 - 7s - loss: 432.7740 - MinusLogProbMetric: 432.7740 - val_loss: 427.7294 - val_MinusLogProbMetric: 427.7294 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 11/1000
2023-09-11 08:35:53.293 
Epoch 11/1000 
	 loss: 428.4998, MinusLogProbMetric: 428.4998, val_loss: 434.7724, val_MinusLogProbMetric: 434.7724

Epoch 11: val_loss did not improve from 427.18649
196/196 - 7s - loss: 428.4998 - MinusLogProbMetric: 428.4998 - val_loss: 434.7724 - val_MinusLogProbMetric: 434.7724 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 12/1000
2023-09-11 08:35:59.985 
Epoch 12/1000 
	 loss: 426.5834, MinusLogProbMetric: 426.5834, val_loss: 424.4924, val_MinusLogProbMetric: 424.4924

Epoch 12: val_loss improved from 427.18649 to 424.49243, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 426.5834 - MinusLogProbMetric: 426.5834 - val_loss: 424.4924 - val_MinusLogProbMetric: 424.4924 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 13/1000
2023-09-11 08:36:07.176 
Epoch 13/1000 
	 loss: 425.5329, MinusLogProbMetric: 425.5329, val_loss: 424.6136, val_MinusLogProbMetric: 424.6136

Epoch 13: val_loss did not improve from 424.49243
196/196 - 7s - loss: 425.5329 - MinusLogProbMetric: 425.5329 - val_loss: 424.6136 - val_MinusLogProbMetric: 424.6136 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 14/1000
2023-09-11 08:36:14.005 
Epoch 14/1000 
	 loss: 427.2639, MinusLogProbMetric: 427.2639, val_loss: 435.6833, val_MinusLogProbMetric: 435.6833

Epoch 14: val_loss did not improve from 424.49243
196/196 - 7s - loss: 427.2639 - MinusLogProbMetric: 427.2639 - val_loss: 435.6833 - val_MinusLogProbMetric: 435.6833 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 15/1000
2023-09-11 08:36:20.358 
Epoch 15/1000 
	 loss: 425.4979, MinusLogProbMetric: 425.4979, val_loss: 426.3066, val_MinusLogProbMetric: 426.3066

Epoch 15: val_loss did not improve from 424.49243
196/196 - 6s - loss: 425.4979 - MinusLogProbMetric: 425.4979 - val_loss: 426.3066 - val_MinusLogProbMetric: 426.3066 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 16/1000
2023-09-11 08:36:26.884 
Epoch 16/1000 
	 loss: 422.6984, MinusLogProbMetric: 422.6984, val_loss: 424.6164, val_MinusLogProbMetric: 424.6164

Epoch 16: val_loss did not improve from 424.49243
196/196 - 7s - loss: 422.6984 - MinusLogProbMetric: 422.6984 - val_loss: 424.6164 - val_MinusLogProbMetric: 424.6164 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 17/1000
2023-09-11 08:36:33.328 
Epoch 17/1000 
	 loss: 420.8123, MinusLogProbMetric: 420.8123, val_loss: 420.2088, val_MinusLogProbMetric: 420.2088

Epoch 17: val_loss improved from 424.49243 to 420.20877, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 420.8123 - MinusLogProbMetric: 420.8123 - val_loss: 420.2088 - val_MinusLogProbMetric: 420.2088 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 18/1000
2023-09-11 08:36:40.108 
Epoch 18/1000 
	 loss: 419.6139, MinusLogProbMetric: 419.6139, val_loss: 420.8867, val_MinusLogProbMetric: 420.8867

Epoch 18: val_loss did not improve from 420.20877
196/196 - 6s - loss: 419.6139 - MinusLogProbMetric: 419.6139 - val_loss: 420.8867 - val_MinusLogProbMetric: 420.8867 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 19/1000
2023-09-11 08:36:46.354 
Epoch 19/1000 
	 loss: 419.9110, MinusLogProbMetric: 419.9110, val_loss: 421.7515, val_MinusLogProbMetric: 421.7515

Epoch 19: val_loss did not improve from 420.20877
196/196 - 6s - loss: 419.9110 - MinusLogProbMetric: 419.9110 - val_loss: 421.7515 - val_MinusLogProbMetric: 421.7515 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 20/1000
2023-09-11 08:36:52.759 
Epoch 20/1000 
	 loss: 419.9936, MinusLogProbMetric: 419.9936, val_loss: 424.4511, val_MinusLogProbMetric: 424.4511

Epoch 20: val_loss did not improve from 420.20877
196/196 - 6s - loss: 419.9936 - MinusLogProbMetric: 419.9936 - val_loss: 424.4511 - val_MinusLogProbMetric: 424.4511 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 21/1000
2023-09-11 08:36:59.184 
Epoch 21/1000 
	 loss: 419.6989, MinusLogProbMetric: 419.6989, val_loss: 418.7101, val_MinusLogProbMetric: 418.7101

Epoch 21: val_loss improved from 420.20877 to 418.71011, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 419.6989 - MinusLogProbMetric: 419.6989 - val_loss: 418.7101 - val_MinusLogProbMetric: 418.7101 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 22/1000
2023-09-11 08:37:06.256 
Epoch 22/1000 
	 loss: 418.7446, MinusLogProbMetric: 418.7446, val_loss: 416.6468, val_MinusLogProbMetric: 416.6468

Epoch 22: val_loss improved from 418.71011 to 416.64676, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 418.7446 - MinusLogProbMetric: 418.7446 - val_loss: 416.6468 - val_MinusLogProbMetric: 416.6468 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 23/1000
2023-09-11 08:37:13.192 
Epoch 23/1000 
	 loss: 416.3655, MinusLogProbMetric: 416.3655, val_loss: 415.1134, val_MinusLogProbMetric: 415.1134

Epoch 23: val_loss improved from 416.64676 to 415.11343, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 416.3655 - MinusLogProbMetric: 416.3655 - val_loss: 415.1134 - val_MinusLogProbMetric: 415.1134 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 24/1000
2023-09-11 08:37:20.121 
Epoch 24/1000 
	 loss: 419.0995, MinusLogProbMetric: 419.0995, val_loss: 420.4737, val_MinusLogProbMetric: 420.4737

Epoch 24: val_loss did not improve from 415.11343
196/196 - 7s - loss: 419.0995 - MinusLogProbMetric: 419.0995 - val_loss: 420.4737 - val_MinusLogProbMetric: 420.4737 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 25/1000
2023-09-11 08:37:26.430 
Epoch 25/1000 
	 loss: 415.8862, MinusLogProbMetric: 415.8862, val_loss: 421.8148, val_MinusLogProbMetric: 421.8148

Epoch 25: val_loss did not improve from 415.11343
196/196 - 6s - loss: 415.8862 - MinusLogProbMetric: 415.8862 - val_loss: 421.8148 - val_MinusLogProbMetric: 421.8148 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 26/1000
2023-09-11 08:37:32.856 
Epoch 26/1000 
	 loss: 415.7827, MinusLogProbMetric: 415.7827, val_loss: 416.0054, val_MinusLogProbMetric: 416.0054

Epoch 26: val_loss did not improve from 415.11343
196/196 - 6s - loss: 415.7827 - MinusLogProbMetric: 415.7827 - val_loss: 416.0054 - val_MinusLogProbMetric: 416.0054 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 27/1000
2023-09-11 08:37:39.592 
Epoch 27/1000 
	 loss: 417.3766, MinusLogProbMetric: 417.3766, val_loss: 422.5866, val_MinusLogProbMetric: 422.5866

Epoch 27: val_loss did not improve from 415.11343
196/196 - 7s - loss: 417.3766 - MinusLogProbMetric: 417.3766 - val_loss: 422.5866 - val_MinusLogProbMetric: 422.5866 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 28/1000
2023-09-11 08:37:46.327 
Epoch 28/1000 
	 loss: 413.4870, MinusLogProbMetric: 413.4870, val_loss: 418.2194, val_MinusLogProbMetric: 418.2194

Epoch 28: val_loss did not improve from 415.11343
196/196 - 7s - loss: 413.4870 - MinusLogProbMetric: 413.4870 - val_loss: 418.2194 - val_MinusLogProbMetric: 418.2194 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 29/1000
2023-09-11 08:37:53.022 
Epoch 29/1000 
	 loss: 413.9305, MinusLogProbMetric: 413.9305, val_loss: 413.5230, val_MinusLogProbMetric: 413.5230

Epoch 29: val_loss improved from 415.11343 to 413.52298, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 413.9305 - MinusLogProbMetric: 413.9305 - val_loss: 413.5230 - val_MinusLogProbMetric: 413.5230 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 30/1000
2023-09-11 08:37:59.537 
Epoch 30/1000 
	 loss: 413.1454, MinusLogProbMetric: 413.1454, val_loss: 415.6606, val_MinusLogProbMetric: 415.6606

Epoch 30: val_loss did not improve from 413.52298
196/196 - 6s - loss: 413.1454 - MinusLogProbMetric: 413.1454 - val_loss: 415.6606 - val_MinusLogProbMetric: 415.6606 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 31/1000
2023-09-11 08:38:05.814 
Epoch 31/1000 
	 loss: 413.6824, MinusLogProbMetric: 413.6824, val_loss: 416.2193, val_MinusLogProbMetric: 416.2193

Epoch 31: val_loss did not improve from 413.52298
196/196 - 6s - loss: 413.6824 - MinusLogProbMetric: 413.6824 - val_loss: 416.2193 - val_MinusLogProbMetric: 416.2193 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 32/1000
2023-09-11 08:38:12.325 
Epoch 32/1000 
	 loss: 413.1174, MinusLogProbMetric: 413.1174, val_loss: 423.8051, val_MinusLogProbMetric: 423.8051

Epoch 32: val_loss did not improve from 413.52298
196/196 - 7s - loss: 413.1174 - MinusLogProbMetric: 413.1174 - val_loss: 423.8051 - val_MinusLogProbMetric: 423.8051 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 33/1000
2023-09-11 08:38:18.674 
Epoch 33/1000 
	 loss: 412.7361, MinusLogProbMetric: 412.7361, val_loss: 413.9423, val_MinusLogProbMetric: 413.9423

Epoch 33: val_loss did not improve from 413.52298
196/196 - 6s - loss: 412.7361 - MinusLogProbMetric: 412.7361 - val_loss: 413.9423 - val_MinusLogProbMetric: 413.9423 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 34/1000
2023-09-11 08:38:25.212 
Epoch 34/1000 
	 loss: 414.2328, MinusLogProbMetric: 414.2328, val_loss: 412.3249, val_MinusLogProbMetric: 412.3249

Epoch 34: val_loss improved from 413.52298 to 412.32489, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 414.2328 - MinusLogProbMetric: 414.2328 - val_loss: 412.3249 - val_MinusLogProbMetric: 412.3249 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 35/1000
2023-09-11 08:38:31.968 
Epoch 35/1000 
	 loss: 413.2016, MinusLogProbMetric: 413.2016, val_loss: 414.5903, val_MinusLogProbMetric: 414.5903

Epoch 35: val_loss did not improve from 412.32489
196/196 - 6s - loss: 413.2016 - MinusLogProbMetric: 413.2016 - val_loss: 414.5903 - val_MinusLogProbMetric: 414.5903 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 36/1000
2023-09-11 08:38:38.369 
Epoch 36/1000 
	 loss: 410.9448, MinusLogProbMetric: 410.9448, val_loss: 418.4043, val_MinusLogProbMetric: 418.4043

Epoch 36: val_loss did not improve from 412.32489
196/196 - 6s - loss: 410.9448 - MinusLogProbMetric: 410.9448 - val_loss: 418.4043 - val_MinusLogProbMetric: 418.4043 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 37/1000
2023-09-11 08:38:44.731 
Epoch 37/1000 
	 loss: 411.7976, MinusLogProbMetric: 411.7976, val_loss: 409.7457, val_MinusLogProbMetric: 409.7457

Epoch 37: val_loss improved from 412.32489 to 409.74567, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 411.7976 - MinusLogProbMetric: 411.7976 - val_loss: 409.7457 - val_MinusLogProbMetric: 409.7457 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 38/1000
2023-09-11 08:38:51.358 
Epoch 38/1000 
	 loss: 412.2704, MinusLogProbMetric: 412.2704, val_loss: 409.4970, val_MinusLogProbMetric: 409.4970

Epoch 38: val_loss improved from 409.74567 to 409.49698, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 412.2704 - MinusLogProbMetric: 412.2704 - val_loss: 409.4970 - val_MinusLogProbMetric: 409.4970 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 39/1000
2023-09-11 08:38:58.154 
Epoch 39/1000 
	 loss: 410.1134, MinusLogProbMetric: 410.1134, val_loss: 408.6990, val_MinusLogProbMetric: 408.6990

Epoch 39: val_loss improved from 409.49698 to 408.69897, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 410.1134 - MinusLogProbMetric: 410.1134 - val_loss: 408.6990 - val_MinusLogProbMetric: 408.6990 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 40/1000
2023-09-11 08:39:04.746 
Epoch 40/1000 
	 loss: 410.9970, MinusLogProbMetric: 410.9970, val_loss: 408.0447, val_MinusLogProbMetric: 408.0447

Epoch 40: val_loss improved from 408.69897 to 408.04471, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 410.9970 - MinusLogProbMetric: 410.9970 - val_loss: 408.0447 - val_MinusLogProbMetric: 408.0447 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 41/1000
2023-09-11 08:39:11.249 
Epoch 41/1000 
	 loss: 417.6018, MinusLogProbMetric: 417.6018, val_loss: 420.5823, val_MinusLogProbMetric: 420.5823

Epoch 41: val_loss did not improve from 408.04471
196/196 - 6s - loss: 417.6018 - MinusLogProbMetric: 417.6018 - val_loss: 420.5823 - val_MinusLogProbMetric: 420.5823 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 42/1000
2023-09-11 08:39:17.814 
Epoch 42/1000 
	 loss: 409.0898, MinusLogProbMetric: 409.0898, val_loss: 411.8400, val_MinusLogProbMetric: 411.8400

Epoch 42: val_loss did not improve from 408.04471
196/196 - 7s - loss: 409.0898 - MinusLogProbMetric: 409.0898 - val_loss: 411.8400 - val_MinusLogProbMetric: 411.8400 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 43/1000
2023-09-11 08:39:24.461 
Epoch 43/1000 
	 loss: 409.7856, MinusLogProbMetric: 409.7856, val_loss: 409.0781, val_MinusLogProbMetric: 409.0781

Epoch 43: val_loss did not improve from 408.04471
196/196 - 7s - loss: 409.7856 - MinusLogProbMetric: 409.7856 - val_loss: 409.0781 - val_MinusLogProbMetric: 409.0781 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 44/1000
2023-09-11 08:39:31.230 
Epoch 44/1000 
	 loss: 408.4433, MinusLogProbMetric: 408.4433, val_loss: 417.9157, val_MinusLogProbMetric: 417.9157

Epoch 44: val_loss did not improve from 408.04471
196/196 - 7s - loss: 408.4433 - MinusLogProbMetric: 408.4433 - val_loss: 417.9157 - val_MinusLogProbMetric: 417.9157 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 45/1000
2023-09-11 08:39:37.948 
Epoch 45/1000 
	 loss: 408.6411, MinusLogProbMetric: 408.6411, val_loss: 408.9660, val_MinusLogProbMetric: 408.9660

Epoch 45: val_loss did not improve from 408.04471
196/196 - 7s - loss: 408.6411 - MinusLogProbMetric: 408.6411 - val_loss: 408.9660 - val_MinusLogProbMetric: 408.9660 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 46/1000
2023-09-11 08:39:44.307 
Epoch 46/1000 
	 loss: 408.4444, MinusLogProbMetric: 408.4444, val_loss: 410.9312, val_MinusLogProbMetric: 410.9312

Epoch 46: val_loss did not improve from 408.04471
196/196 - 6s - loss: 408.4444 - MinusLogProbMetric: 408.4444 - val_loss: 410.9312 - val_MinusLogProbMetric: 410.9312 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 47/1000
2023-09-11 08:39:50.818 
Epoch 47/1000 
	 loss: 408.3106, MinusLogProbMetric: 408.3106, val_loss: 411.1459, val_MinusLogProbMetric: 411.1459

Epoch 47: val_loss did not improve from 408.04471
196/196 - 7s - loss: 408.3106 - MinusLogProbMetric: 408.3106 - val_loss: 411.1459 - val_MinusLogProbMetric: 411.1459 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 48/1000
2023-09-11 08:39:57.122 
Epoch 48/1000 
	 loss: 409.1494, MinusLogProbMetric: 409.1494, val_loss: 406.6058, val_MinusLogProbMetric: 406.6058

Epoch 48: val_loss improved from 408.04471 to 406.60577, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 409.1494 - MinusLogProbMetric: 409.1494 - val_loss: 406.6058 - val_MinusLogProbMetric: 406.6058 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 49/1000
2023-09-11 08:40:03.788 
Epoch 49/1000 
	 loss: 409.6029, MinusLogProbMetric: 409.6029, val_loss: 412.4694, val_MinusLogProbMetric: 412.4694

Epoch 49: val_loss did not improve from 406.60577
196/196 - 6s - loss: 409.6029 - MinusLogProbMetric: 409.6029 - val_loss: 412.4694 - val_MinusLogProbMetric: 412.4694 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 50/1000
2023-09-11 08:40:10.212 
Epoch 50/1000 
	 loss: 408.3966, MinusLogProbMetric: 408.3966, val_loss: 406.6181, val_MinusLogProbMetric: 406.6181

Epoch 50: val_loss did not improve from 406.60577
196/196 - 6s - loss: 408.3966 - MinusLogProbMetric: 408.3966 - val_loss: 406.6181 - val_MinusLogProbMetric: 406.6181 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 51/1000
2023-09-11 08:40:16.525 
Epoch 51/1000 
	 loss: 407.0452, MinusLogProbMetric: 407.0452, val_loss: 414.1150, val_MinusLogProbMetric: 414.1150

Epoch 51: val_loss did not improve from 406.60577
196/196 - 6s - loss: 407.0452 - MinusLogProbMetric: 407.0452 - val_loss: 414.1150 - val_MinusLogProbMetric: 414.1150 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 52/1000
2023-09-11 08:40:22.729 
Epoch 52/1000 
	 loss: 407.4792, MinusLogProbMetric: 407.4792, val_loss: 410.8158, val_MinusLogProbMetric: 410.8158

Epoch 52: val_loss did not improve from 406.60577
196/196 - 6s - loss: 407.4792 - MinusLogProbMetric: 407.4792 - val_loss: 410.8158 - val_MinusLogProbMetric: 410.8158 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 53/1000
2023-09-11 08:40:29.082 
Epoch 53/1000 
	 loss: 408.6764, MinusLogProbMetric: 408.6764, val_loss: 406.5293, val_MinusLogProbMetric: 406.5293

Epoch 53: val_loss improved from 406.60577 to 406.52933, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 408.6764 - MinusLogProbMetric: 408.6764 - val_loss: 406.5293 - val_MinusLogProbMetric: 406.5293 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 54/1000
2023-09-11 08:40:35.698 
Epoch 54/1000 
	 loss: 406.8980, MinusLogProbMetric: 406.8980, val_loss: 414.6143, val_MinusLogProbMetric: 414.6143

Epoch 54: val_loss did not improve from 406.52933
196/196 - 6s - loss: 406.8980 - MinusLogProbMetric: 406.8980 - val_loss: 414.6143 - val_MinusLogProbMetric: 414.6143 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 55/1000
2023-09-11 08:40:42.175 
Epoch 55/1000 
	 loss: 409.3163, MinusLogProbMetric: 409.3163, val_loss: 413.8583, val_MinusLogProbMetric: 413.8583

Epoch 55: val_loss did not improve from 406.52933
196/196 - 6s - loss: 409.3163 - MinusLogProbMetric: 409.3163 - val_loss: 413.8583 - val_MinusLogProbMetric: 413.8583 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 56/1000
2023-09-11 08:40:48.762 
Epoch 56/1000 
	 loss: 406.5988, MinusLogProbMetric: 406.5988, val_loss: 406.4927, val_MinusLogProbMetric: 406.4927

Epoch 56: val_loss improved from 406.52933 to 406.49274, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 406.5988 - MinusLogProbMetric: 406.5988 - val_loss: 406.4927 - val_MinusLogProbMetric: 406.4927 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 57/1000
2023-09-11 08:40:55.180 
Epoch 57/1000 
	 loss: 407.2218, MinusLogProbMetric: 407.2218, val_loss: 409.3238, val_MinusLogProbMetric: 409.3238

Epoch 57: val_loss did not improve from 406.49274
196/196 - 6s - loss: 407.2218 - MinusLogProbMetric: 407.2218 - val_loss: 409.3238 - val_MinusLogProbMetric: 409.3238 - lr: 3.3333e-04 - 6s/epoch - 31ms/step
Epoch 58/1000
2023-09-11 08:41:01.604 
Epoch 58/1000 
	 loss: 406.0366, MinusLogProbMetric: 406.0366, val_loss: 405.9481, val_MinusLogProbMetric: 405.9481

Epoch 58: val_loss improved from 406.49274 to 405.94806, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 406.0366 - MinusLogProbMetric: 406.0366 - val_loss: 405.9481 - val_MinusLogProbMetric: 405.9481 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 59/1000
2023-09-11 08:41:08.249 
Epoch 59/1000 
	 loss: 406.2141, MinusLogProbMetric: 406.2141, val_loss: 406.6928, val_MinusLogProbMetric: 406.6928

Epoch 59: val_loss did not improve from 405.94806
196/196 - 6s - loss: 406.2141 - MinusLogProbMetric: 406.2141 - val_loss: 406.6928 - val_MinusLogProbMetric: 406.6928 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 60/1000
2023-09-11 08:41:14.563 
Epoch 60/1000 
	 loss: 405.5948, MinusLogProbMetric: 405.5948, val_loss: 407.0610, val_MinusLogProbMetric: 407.0610

Epoch 60: val_loss did not improve from 405.94806
196/196 - 6s - loss: 405.5948 - MinusLogProbMetric: 405.5948 - val_loss: 407.0610 - val_MinusLogProbMetric: 407.0610 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 61/1000
2023-09-11 08:41:21.173 
Epoch 61/1000 
	 loss: 406.1701, MinusLogProbMetric: 406.1701, val_loss: 405.0776, val_MinusLogProbMetric: 405.0776

Epoch 61: val_loss improved from 405.94806 to 405.07758, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 406.1701 - MinusLogProbMetric: 406.1701 - val_loss: 405.0776 - val_MinusLogProbMetric: 405.0776 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 62/1000
2023-09-11 08:41:27.942 
Epoch 62/1000 
	 loss: 405.5613, MinusLogProbMetric: 405.5613, val_loss: 406.5219, val_MinusLogProbMetric: 406.5219

Epoch 62: val_loss did not improve from 405.07758
196/196 - 7s - loss: 405.5613 - MinusLogProbMetric: 405.5613 - val_loss: 406.5219 - val_MinusLogProbMetric: 406.5219 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 63/1000
2023-09-11 08:41:34.482 
Epoch 63/1000 
	 loss: 406.1309, MinusLogProbMetric: 406.1309, val_loss: 409.9865, val_MinusLogProbMetric: 409.9865

Epoch 63: val_loss did not improve from 405.07758
196/196 - 7s - loss: 406.1309 - MinusLogProbMetric: 406.1309 - val_loss: 409.9865 - val_MinusLogProbMetric: 409.9865 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 64/1000
2023-09-11 08:41:40.933 
Epoch 64/1000 
	 loss: 407.5336, MinusLogProbMetric: 407.5336, val_loss: 407.0759, val_MinusLogProbMetric: 407.0759

Epoch 64: val_loss did not improve from 405.07758
196/196 - 6s - loss: 407.5336 - MinusLogProbMetric: 407.5336 - val_loss: 407.0759 - val_MinusLogProbMetric: 407.0759 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 65/1000
2023-09-11 08:41:47.432 
Epoch 65/1000 
	 loss: 405.1666, MinusLogProbMetric: 405.1666, val_loss: 409.2063, val_MinusLogProbMetric: 409.2063

Epoch 65: val_loss did not improve from 405.07758
196/196 - 6s - loss: 405.1666 - MinusLogProbMetric: 405.1666 - val_loss: 409.2063 - val_MinusLogProbMetric: 409.2063 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 66/1000
2023-09-11 08:41:53.785 
Epoch 66/1000 
	 loss: 405.2256, MinusLogProbMetric: 405.2256, val_loss: 405.8239, val_MinusLogProbMetric: 405.8239

Epoch 66: val_loss did not improve from 405.07758
196/196 - 6s - loss: 405.2256 - MinusLogProbMetric: 405.2256 - val_loss: 405.8239 - val_MinusLogProbMetric: 405.8239 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 67/1000
2023-09-11 08:42:00.209 
Epoch 67/1000 
	 loss: 404.8295, MinusLogProbMetric: 404.8295, val_loss: 406.4271, val_MinusLogProbMetric: 406.4271

Epoch 67: val_loss did not improve from 405.07758
196/196 - 6s - loss: 404.8295 - MinusLogProbMetric: 404.8295 - val_loss: 406.4271 - val_MinusLogProbMetric: 406.4271 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 68/1000
2023-09-11 08:42:06.567 
Epoch 68/1000 
	 loss: 404.9231, MinusLogProbMetric: 404.9231, val_loss: 423.8463, val_MinusLogProbMetric: 423.8463

Epoch 68: val_loss did not improve from 405.07758
196/196 - 6s - loss: 404.9231 - MinusLogProbMetric: 404.9231 - val_loss: 423.8463 - val_MinusLogProbMetric: 423.8463 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 69/1000
2023-09-11 08:42:12.970 
Epoch 69/1000 
	 loss: 405.0557, MinusLogProbMetric: 405.0557, val_loss: 404.9134, val_MinusLogProbMetric: 404.9134

Epoch 69: val_loss improved from 405.07758 to 404.91339, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 405.0557 - MinusLogProbMetric: 405.0557 - val_loss: 404.9134 - val_MinusLogProbMetric: 404.9134 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 70/1000
2023-09-11 08:42:19.601 
Epoch 70/1000 
	 loss: 404.9230, MinusLogProbMetric: 404.9230, val_loss: 411.8485, val_MinusLogProbMetric: 411.8485

Epoch 70: val_loss did not improve from 404.91339
196/196 - 6s - loss: 404.9230 - MinusLogProbMetric: 404.9230 - val_loss: 411.8485 - val_MinusLogProbMetric: 411.8485 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 71/1000
2023-09-11 08:42:26.016 
Epoch 71/1000 
	 loss: 407.2874, MinusLogProbMetric: 407.2874, val_loss: 410.9659, val_MinusLogProbMetric: 410.9659

Epoch 71: val_loss did not improve from 404.91339
196/196 - 6s - loss: 407.2874 - MinusLogProbMetric: 407.2874 - val_loss: 410.9659 - val_MinusLogProbMetric: 410.9659 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 72/1000
2023-09-11 08:42:32.505 
Epoch 72/1000 
	 loss: 405.2809, MinusLogProbMetric: 405.2809, val_loss: 406.5272, val_MinusLogProbMetric: 406.5272

Epoch 72: val_loss did not improve from 404.91339
196/196 - 6s - loss: 405.2809 - MinusLogProbMetric: 405.2809 - val_loss: 406.5272 - val_MinusLogProbMetric: 406.5272 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 73/1000
2023-09-11 08:42:38.932 
Epoch 73/1000 
	 loss: 404.4436, MinusLogProbMetric: 404.4436, val_loss: 404.3943, val_MinusLogProbMetric: 404.3943

Epoch 73: val_loss improved from 404.91339 to 404.39429, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 404.4436 - MinusLogProbMetric: 404.4436 - val_loss: 404.3943 - val_MinusLogProbMetric: 404.3943 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 74/1000
2023-09-11 08:42:45.611 
Epoch 74/1000 
	 loss: 404.3003, MinusLogProbMetric: 404.3003, val_loss: 405.1939, val_MinusLogProbMetric: 405.1939

Epoch 74: val_loss did not improve from 404.39429
196/196 - 6s - loss: 404.3003 - MinusLogProbMetric: 404.3003 - val_loss: 405.1939 - val_MinusLogProbMetric: 405.1939 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 75/1000
2023-09-11 08:42:51.984 
Epoch 75/1000 
	 loss: 404.1987, MinusLogProbMetric: 404.1987, val_loss: 404.3538, val_MinusLogProbMetric: 404.3538

Epoch 75: val_loss improved from 404.39429 to 404.35382, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 404.1987 - MinusLogProbMetric: 404.1987 - val_loss: 404.3538 - val_MinusLogProbMetric: 404.3538 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 76/1000
2023-09-11 08:42:58.699 
Epoch 76/1000 
	 loss: 403.6358, MinusLogProbMetric: 403.6358, val_loss: 414.1288, val_MinusLogProbMetric: 414.1288

Epoch 76: val_loss did not improve from 404.35382
196/196 - 7s - loss: 403.6358 - MinusLogProbMetric: 403.6358 - val_loss: 414.1288 - val_MinusLogProbMetric: 414.1288 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 77/1000
2023-09-11 08:43:05.148 
Epoch 77/1000 
	 loss: 404.2167, MinusLogProbMetric: 404.2167, val_loss: 424.7099, val_MinusLogProbMetric: 424.7099

Epoch 77: val_loss did not improve from 404.35382
196/196 - 6s - loss: 404.2167 - MinusLogProbMetric: 404.2167 - val_loss: 424.7099 - val_MinusLogProbMetric: 424.7099 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 78/1000
2023-09-11 08:43:11.480 
Epoch 78/1000 
	 loss: 406.7916, MinusLogProbMetric: 406.7916, val_loss: 408.0325, val_MinusLogProbMetric: 408.0325

Epoch 78: val_loss did not improve from 404.35382
196/196 - 6s - loss: 406.7916 - MinusLogProbMetric: 406.7916 - val_loss: 408.0325 - val_MinusLogProbMetric: 408.0325 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 79/1000
2023-09-11 08:43:17.920 
Epoch 79/1000 
	 loss: 404.3676, MinusLogProbMetric: 404.3676, val_loss: 406.6763, val_MinusLogProbMetric: 406.6763

Epoch 79: val_loss did not improve from 404.35382
196/196 - 6s - loss: 404.3676 - MinusLogProbMetric: 404.3676 - val_loss: 406.6763 - val_MinusLogProbMetric: 406.6763 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 80/1000
2023-09-11 08:43:24.327 
Epoch 80/1000 
	 loss: 402.7160, MinusLogProbMetric: 402.7160, val_loss: 405.0618, val_MinusLogProbMetric: 405.0618

Epoch 80: val_loss did not improve from 404.35382
196/196 - 6s - loss: 402.7160 - MinusLogProbMetric: 402.7160 - val_loss: 405.0618 - val_MinusLogProbMetric: 405.0618 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 81/1000
2023-09-11 08:43:30.783 
Epoch 81/1000 
	 loss: 403.2255, MinusLogProbMetric: 403.2255, val_loss: 408.3937, val_MinusLogProbMetric: 408.3937

Epoch 81: val_loss did not improve from 404.35382
196/196 - 6s - loss: 403.2255 - MinusLogProbMetric: 403.2255 - val_loss: 408.3937 - val_MinusLogProbMetric: 408.3937 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 82/1000
2023-09-11 08:43:37.102 
Epoch 82/1000 
	 loss: 403.4859, MinusLogProbMetric: 403.4859, val_loss: 406.0260, val_MinusLogProbMetric: 406.0260

Epoch 82: val_loss did not improve from 404.35382
196/196 - 6s - loss: 403.4859 - MinusLogProbMetric: 403.4859 - val_loss: 406.0260 - val_MinusLogProbMetric: 406.0260 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 83/1000
2023-09-11 08:43:43.489 
Epoch 83/1000 
	 loss: 403.7210, MinusLogProbMetric: 403.7210, val_loss: 405.4341, val_MinusLogProbMetric: 405.4341

Epoch 83: val_loss did not improve from 404.35382
196/196 - 6s - loss: 403.7210 - MinusLogProbMetric: 403.7210 - val_loss: 405.4341 - val_MinusLogProbMetric: 405.4341 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 84/1000
2023-09-11 08:43:49.819 
Epoch 84/1000 
	 loss: 403.0881, MinusLogProbMetric: 403.0881, val_loss: 406.8719, val_MinusLogProbMetric: 406.8719

Epoch 84: val_loss did not improve from 404.35382
196/196 - 6s - loss: 403.0881 - MinusLogProbMetric: 403.0881 - val_loss: 406.8719 - val_MinusLogProbMetric: 406.8719 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 85/1000
2023-09-11 08:43:56.264 
Epoch 85/1000 
	 loss: 402.3064, MinusLogProbMetric: 402.3064, val_loss: 407.2602, val_MinusLogProbMetric: 407.2602

Epoch 85: val_loss did not improve from 404.35382
196/196 - 6s - loss: 402.3064 - MinusLogProbMetric: 402.3064 - val_loss: 407.2602 - val_MinusLogProbMetric: 407.2602 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 86/1000
2023-09-11 08:44:02.721 
Epoch 86/1000 
	 loss: 402.8831, MinusLogProbMetric: 402.8831, val_loss: 403.6365, val_MinusLogProbMetric: 403.6365

Epoch 86: val_loss improved from 404.35382 to 403.63654, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 402.8831 - MinusLogProbMetric: 402.8831 - val_loss: 403.6365 - val_MinusLogProbMetric: 403.6365 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 87/1000
2023-09-11 08:44:09.399 
Epoch 87/1000 
	 loss: 403.9205, MinusLogProbMetric: 403.9205, val_loss: 409.2319, val_MinusLogProbMetric: 409.2319

Epoch 87: val_loss did not improve from 403.63654
196/196 - 6s - loss: 403.9205 - MinusLogProbMetric: 403.9205 - val_loss: 409.2319 - val_MinusLogProbMetric: 409.2319 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 88/1000
2023-09-11 08:44:15.713 
Epoch 88/1000 
	 loss: 402.2308, MinusLogProbMetric: 402.2308, val_loss: 405.7658, val_MinusLogProbMetric: 405.7658

Epoch 88: val_loss did not improve from 403.63654
196/196 - 6s - loss: 402.2308 - MinusLogProbMetric: 402.2308 - val_loss: 405.7658 - val_MinusLogProbMetric: 405.7658 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 89/1000
2023-09-11 08:44:22.209 
Epoch 89/1000 
	 loss: 404.0872, MinusLogProbMetric: 404.0872, val_loss: 406.7789, val_MinusLogProbMetric: 406.7789

Epoch 89: val_loss did not improve from 403.63654
196/196 - 6s - loss: 404.0872 - MinusLogProbMetric: 404.0872 - val_loss: 406.7789 - val_MinusLogProbMetric: 406.7789 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 90/1000
2023-09-11 08:44:28.482 
Epoch 90/1000 
	 loss: 402.3375, MinusLogProbMetric: 402.3375, val_loss: 402.6258, val_MinusLogProbMetric: 402.6258

Epoch 90: val_loss improved from 403.63654 to 402.62582, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 402.3375 - MinusLogProbMetric: 402.3375 - val_loss: 402.6258 - val_MinusLogProbMetric: 402.6258 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 91/1000
2023-09-11 08:44:35.205 
Epoch 91/1000 
	 loss: 402.3789, MinusLogProbMetric: 402.3789, val_loss: 406.4139, val_MinusLogProbMetric: 406.4139

Epoch 91: val_loss did not improve from 402.62582
196/196 - 6s - loss: 402.3789 - MinusLogProbMetric: 402.3789 - val_loss: 406.4139 - val_MinusLogProbMetric: 406.4139 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 92/1000
2023-09-11 08:44:41.464 
Epoch 92/1000 
	 loss: 402.2578, MinusLogProbMetric: 402.2578, val_loss: 402.9531, val_MinusLogProbMetric: 402.9531

Epoch 92: val_loss did not improve from 402.62582
196/196 - 6s - loss: 402.2578 - MinusLogProbMetric: 402.2578 - val_loss: 402.9531 - val_MinusLogProbMetric: 402.9531 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 93/1000
2023-09-11 08:44:47.990 
Epoch 93/1000 
	 loss: 402.3226, MinusLogProbMetric: 402.3226, val_loss: 406.0081, val_MinusLogProbMetric: 406.0081

Epoch 93: val_loss did not improve from 402.62582
196/196 - 7s - loss: 402.3226 - MinusLogProbMetric: 402.3226 - val_loss: 406.0081 - val_MinusLogProbMetric: 406.0081 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 94/1000
2023-09-11 08:44:54.442 
Epoch 94/1000 
	 loss: 402.7402, MinusLogProbMetric: 402.7402, val_loss: 405.2033, val_MinusLogProbMetric: 405.2033

Epoch 94: val_loss did not improve from 402.62582
196/196 - 6s - loss: 402.7402 - MinusLogProbMetric: 402.7402 - val_loss: 405.2033 - val_MinusLogProbMetric: 405.2033 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 95/1000
2023-09-11 08:45:00.873 
Epoch 95/1000 
	 loss: 401.5034, MinusLogProbMetric: 401.5034, val_loss: 402.9517, val_MinusLogProbMetric: 402.9517

Epoch 95: val_loss did not improve from 402.62582
196/196 - 6s - loss: 401.5034 - MinusLogProbMetric: 401.5034 - val_loss: 402.9517 - val_MinusLogProbMetric: 402.9517 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 96/1000
2023-09-11 08:45:07.202 
Epoch 96/1000 
	 loss: 402.0573, MinusLogProbMetric: 402.0573, val_loss: 404.5213, val_MinusLogProbMetric: 404.5213

Epoch 96: val_loss did not improve from 402.62582
196/196 - 6s - loss: 402.0573 - MinusLogProbMetric: 402.0573 - val_loss: 404.5213 - val_MinusLogProbMetric: 404.5213 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 97/1000
2023-09-11 08:45:13.628 
Epoch 97/1000 
	 loss: 401.7532, MinusLogProbMetric: 401.7532, val_loss: 408.4641, val_MinusLogProbMetric: 408.4641

Epoch 97: val_loss did not improve from 402.62582
196/196 - 6s - loss: 401.7532 - MinusLogProbMetric: 401.7532 - val_loss: 408.4641 - val_MinusLogProbMetric: 408.4641 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 98/1000
2023-09-11 08:45:20.079 
Epoch 98/1000 
	 loss: 402.1198, MinusLogProbMetric: 402.1198, val_loss: 403.6929, val_MinusLogProbMetric: 403.6929

Epoch 98: val_loss did not improve from 402.62582
196/196 - 6s - loss: 402.1198 - MinusLogProbMetric: 402.1198 - val_loss: 403.6929 - val_MinusLogProbMetric: 403.6929 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 99/1000
2023-09-11 08:45:26.413 
Epoch 99/1000 
	 loss: 401.7480, MinusLogProbMetric: 401.7480, val_loss: 409.8751, val_MinusLogProbMetric: 409.8751

Epoch 99: val_loss did not improve from 402.62582
196/196 - 6s - loss: 401.7480 - MinusLogProbMetric: 401.7480 - val_loss: 409.8751 - val_MinusLogProbMetric: 409.8751 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 100/1000
2023-09-11 08:45:32.804 
Epoch 100/1000 
	 loss: 403.0851, MinusLogProbMetric: 403.0851, val_loss: 403.7908, val_MinusLogProbMetric: 403.7908

Epoch 100: val_loss did not improve from 402.62582
196/196 - 6s - loss: 403.0851 - MinusLogProbMetric: 403.0851 - val_loss: 403.7908 - val_MinusLogProbMetric: 403.7908 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 101/1000
2023-09-11 08:45:39.228 
Epoch 101/1000 
	 loss: 402.6094, MinusLogProbMetric: 402.6094, val_loss: 406.3223, val_MinusLogProbMetric: 406.3223

Epoch 101: val_loss did not improve from 402.62582
196/196 - 6s - loss: 402.6094 - MinusLogProbMetric: 402.6094 - val_loss: 406.3223 - val_MinusLogProbMetric: 406.3223 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 102/1000
2023-09-11 08:45:45.655 
Epoch 102/1000 
	 loss: 401.0386, MinusLogProbMetric: 401.0386, val_loss: 403.7357, val_MinusLogProbMetric: 403.7357

Epoch 102: val_loss did not improve from 402.62582
196/196 - 6s - loss: 401.0386 - MinusLogProbMetric: 401.0386 - val_loss: 403.7357 - val_MinusLogProbMetric: 403.7357 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 103/1000
2023-09-11 08:45:52.108 
Epoch 103/1000 
	 loss: 401.4590, MinusLogProbMetric: 401.4590, val_loss: 410.3948, val_MinusLogProbMetric: 410.3948

Epoch 103: val_loss did not improve from 402.62582
196/196 - 6s - loss: 401.4590 - MinusLogProbMetric: 401.4590 - val_loss: 410.3948 - val_MinusLogProbMetric: 410.3948 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 104/1000
2023-09-11 08:45:58.461 
Epoch 104/1000 
	 loss: 400.8536, MinusLogProbMetric: 400.8536, val_loss: 404.7650, val_MinusLogProbMetric: 404.7650

Epoch 104: val_loss did not improve from 402.62582
196/196 - 6s - loss: 400.8536 - MinusLogProbMetric: 400.8536 - val_loss: 404.7650 - val_MinusLogProbMetric: 404.7650 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 105/1000
2023-09-11 08:46:05.071 
Epoch 105/1000 
	 loss: 402.0468, MinusLogProbMetric: 402.0468, val_loss: 406.1161, val_MinusLogProbMetric: 406.1161

Epoch 105: val_loss did not improve from 402.62582
196/196 - 7s - loss: 402.0468 - MinusLogProbMetric: 402.0468 - val_loss: 406.1161 - val_MinusLogProbMetric: 406.1161 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 106/1000
2023-09-11 08:46:11.514 
Epoch 106/1000 
	 loss: 411.4931, MinusLogProbMetric: 411.4931, val_loss: 441.0686, val_MinusLogProbMetric: 441.0686

Epoch 106: val_loss did not improve from 402.62582
196/196 - 6s - loss: 411.4931 - MinusLogProbMetric: 411.4931 - val_loss: 441.0686 - val_MinusLogProbMetric: 441.0686 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 107/1000
2023-09-11 08:46:17.950 
Epoch 107/1000 
	 loss: 404.6208, MinusLogProbMetric: 404.6208, val_loss: 404.0734, val_MinusLogProbMetric: 404.0734

Epoch 107: val_loss did not improve from 402.62582
196/196 - 6s - loss: 404.6208 - MinusLogProbMetric: 404.6208 - val_loss: 404.0734 - val_MinusLogProbMetric: 404.0734 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 108/1000
2023-09-11 08:46:24.213 
Epoch 108/1000 
	 loss: 400.3059, MinusLogProbMetric: 400.3059, val_loss: 402.8097, val_MinusLogProbMetric: 402.8097

Epoch 108: val_loss did not improve from 402.62582
196/196 - 6s - loss: 400.3059 - MinusLogProbMetric: 400.3059 - val_loss: 402.8097 - val_MinusLogProbMetric: 402.8097 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 109/1000
2023-09-11 08:46:30.760 
Epoch 109/1000 
	 loss: 400.2384, MinusLogProbMetric: 400.2384, val_loss: 405.7019, val_MinusLogProbMetric: 405.7019

Epoch 109: val_loss did not improve from 402.62582
196/196 - 7s - loss: 400.2384 - MinusLogProbMetric: 400.2384 - val_loss: 405.7019 - val_MinusLogProbMetric: 405.7019 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 110/1000
2023-09-11 08:46:37.404 
Epoch 110/1000 
	 loss: 400.3636, MinusLogProbMetric: 400.3636, val_loss: 408.8690, val_MinusLogProbMetric: 408.8690

Epoch 110: val_loss did not improve from 402.62582
196/196 - 7s - loss: 400.3636 - MinusLogProbMetric: 400.3636 - val_loss: 408.8690 - val_MinusLogProbMetric: 408.8690 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 111/1000
2023-09-11 08:46:44.254 
Epoch 111/1000 
	 loss: 401.7575, MinusLogProbMetric: 401.7575, val_loss: 409.8090, val_MinusLogProbMetric: 409.8090

Epoch 111: val_loss did not improve from 402.62582
196/196 - 7s - loss: 401.7575 - MinusLogProbMetric: 401.7575 - val_loss: 409.8090 - val_MinusLogProbMetric: 409.8090 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 112/1000
2023-09-11 08:46:50.967 
Epoch 112/1000 
	 loss: 401.3711, MinusLogProbMetric: 401.3711, val_loss: 403.3832, val_MinusLogProbMetric: 403.3832

Epoch 112: val_loss did not improve from 402.62582
196/196 - 7s - loss: 401.3711 - MinusLogProbMetric: 401.3711 - val_loss: 403.3832 - val_MinusLogProbMetric: 403.3832 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 113/1000
2023-09-11 08:46:57.699 
Epoch 113/1000 
	 loss: 401.7269, MinusLogProbMetric: 401.7269, val_loss: 403.2166, val_MinusLogProbMetric: 403.2166

Epoch 113: val_loss did not improve from 402.62582
196/196 - 7s - loss: 401.7269 - MinusLogProbMetric: 401.7269 - val_loss: 403.2166 - val_MinusLogProbMetric: 403.2166 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 114/1000
2023-09-11 08:47:04.066 
Epoch 114/1000 
	 loss: 401.4608, MinusLogProbMetric: 401.4608, val_loss: 409.2875, val_MinusLogProbMetric: 409.2875

Epoch 114: val_loss did not improve from 402.62582
196/196 - 6s - loss: 401.4608 - MinusLogProbMetric: 401.4608 - val_loss: 409.2875 - val_MinusLogProbMetric: 409.2875 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 115/1000
2023-09-11 08:47:10.283 
Epoch 115/1000 
	 loss: 400.9496, MinusLogProbMetric: 400.9496, val_loss: 405.5629, val_MinusLogProbMetric: 405.5629

Epoch 115: val_loss did not improve from 402.62582
196/196 - 6s - loss: 400.9496 - MinusLogProbMetric: 400.9496 - val_loss: 405.5629 - val_MinusLogProbMetric: 405.5629 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 116/1000
2023-09-11 08:47:16.693 
Epoch 116/1000 
	 loss: 400.2596, MinusLogProbMetric: 400.2596, val_loss: 403.6494, val_MinusLogProbMetric: 403.6494

Epoch 116: val_loss did not improve from 402.62582
196/196 - 6s - loss: 400.2596 - MinusLogProbMetric: 400.2596 - val_loss: 403.6494 - val_MinusLogProbMetric: 403.6494 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 117/1000
2023-09-11 08:47:23.081 
Epoch 117/1000 
	 loss: 400.6233, MinusLogProbMetric: 400.6233, val_loss: 405.7248, val_MinusLogProbMetric: 405.7248

Epoch 117: val_loss did not improve from 402.62582
196/196 - 6s - loss: 400.6233 - MinusLogProbMetric: 400.6233 - val_loss: 405.7248 - val_MinusLogProbMetric: 405.7248 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 118/1000
2023-09-11 08:47:29.173 
Epoch 118/1000 
	 loss: 399.6992, MinusLogProbMetric: 399.6992, val_loss: 405.0683, val_MinusLogProbMetric: 405.0683

Epoch 118: val_loss did not improve from 402.62582
196/196 - 6s - loss: 399.6992 - MinusLogProbMetric: 399.6992 - val_loss: 405.0683 - val_MinusLogProbMetric: 405.0683 - lr: 3.3333e-04 - 6s/epoch - 31ms/step
Epoch 119/1000
2023-09-11 08:47:35.674 
Epoch 119/1000 
	 loss: 400.0313, MinusLogProbMetric: 400.0313, val_loss: 402.6976, val_MinusLogProbMetric: 402.6976

Epoch 119: val_loss did not improve from 402.62582
196/196 - 6s - loss: 400.0313 - MinusLogProbMetric: 400.0313 - val_loss: 402.6976 - val_MinusLogProbMetric: 402.6976 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 120/1000
2023-09-11 08:47:42.053 
Epoch 120/1000 
	 loss: 400.6096, MinusLogProbMetric: 400.6096, val_loss: 405.3766, val_MinusLogProbMetric: 405.3766

Epoch 120: val_loss did not improve from 402.62582
196/196 - 6s - loss: 400.6096 - MinusLogProbMetric: 400.6096 - val_loss: 405.3766 - val_MinusLogProbMetric: 405.3766 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 121/1000
2023-09-11 08:47:48.468 
Epoch 121/1000 
	 loss: 399.1996, MinusLogProbMetric: 399.1996, val_loss: 418.3806, val_MinusLogProbMetric: 418.3806

Epoch 121: val_loss did not improve from 402.62582
196/196 - 6s - loss: 399.1996 - MinusLogProbMetric: 399.1996 - val_loss: 418.3806 - val_MinusLogProbMetric: 418.3806 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 122/1000
2023-09-11 08:47:54.749 
Epoch 122/1000 
	 loss: 401.6308, MinusLogProbMetric: 401.6308, val_loss: 403.8263, val_MinusLogProbMetric: 403.8263

Epoch 122: val_loss did not improve from 402.62582
196/196 - 6s - loss: 401.6308 - MinusLogProbMetric: 401.6308 - val_loss: 403.8263 - val_MinusLogProbMetric: 403.8263 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 123/1000
2023-09-11 08:48:01.259 
Epoch 123/1000 
	 loss: 399.2059, MinusLogProbMetric: 399.2059, val_loss: 403.7703, val_MinusLogProbMetric: 403.7703

Epoch 123: val_loss did not improve from 402.62582
196/196 - 7s - loss: 399.2059 - MinusLogProbMetric: 399.2059 - val_loss: 403.7703 - val_MinusLogProbMetric: 403.7703 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 124/1000
2023-09-11 08:48:07.490 
Epoch 124/1000 
	 loss: 399.6597, MinusLogProbMetric: 399.6597, val_loss: 403.2087, val_MinusLogProbMetric: 403.2087

Epoch 124: val_loss did not improve from 402.62582
196/196 - 6s - loss: 399.6597 - MinusLogProbMetric: 399.6597 - val_loss: 403.2087 - val_MinusLogProbMetric: 403.2087 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 125/1000
2023-09-11 08:48:13.966 
Epoch 125/1000 
	 loss: 399.1674, MinusLogProbMetric: 399.1674, val_loss: 405.0266, val_MinusLogProbMetric: 405.0266

Epoch 125: val_loss did not improve from 402.62582
196/196 - 6s - loss: 399.1674 - MinusLogProbMetric: 399.1674 - val_loss: 405.0266 - val_MinusLogProbMetric: 405.0266 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 126/1000
2023-09-11 08:48:20.741 
Epoch 126/1000 
	 loss: 400.5363, MinusLogProbMetric: 400.5363, val_loss: 403.5735, val_MinusLogProbMetric: 403.5735

Epoch 126: val_loss did not improve from 402.62582
196/196 - 7s - loss: 400.5363 - MinusLogProbMetric: 400.5363 - val_loss: 403.5735 - val_MinusLogProbMetric: 403.5735 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 127/1000
2023-09-11 08:48:27.698 
Epoch 127/1000 
	 loss: 399.7693, MinusLogProbMetric: 399.7693, val_loss: 405.2260, val_MinusLogProbMetric: 405.2260

Epoch 127: val_loss did not improve from 402.62582
196/196 - 7s - loss: 399.7693 - MinusLogProbMetric: 399.7693 - val_loss: 405.2260 - val_MinusLogProbMetric: 405.2260 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 128/1000
2023-09-11 08:48:34.484 
Epoch 128/1000 
	 loss: 398.7778, MinusLogProbMetric: 398.7778, val_loss: 404.3902, val_MinusLogProbMetric: 404.3902

Epoch 128: val_loss did not improve from 402.62582
196/196 - 7s - loss: 398.7778 - MinusLogProbMetric: 398.7778 - val_loss: 404.3902 - val_MinusLogProbMetric: 404.3902 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 129/1000
2023-09-11 08:48:40.978 
Epoch 129/1000 
	 loss: 399.4973, MinusLogProbMetric: 399.4973, val_loss: 406.5985, val_MinusLogProbMetric: 406.5985

Epoch 129: val_loss did not improve from 402.62582
196/196 - 6s - loss: 399.4973 - MinusLogProbMetric: 399.4973 - val_loss: 406.5985 - val_MinusLogProbMetric: 406.5985 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 130/1000
2023-09-11 08:48:47.469 
Epoch 130/1000 
	 loss: 399.7092, MinusLogProbMetric: 399.7092, val_loss: 403.9375, val_MinusLogProbMetric: 403.9375

Epoch 130: val_loss did not improve from 402.62582
196/196 - 6s - loss: 399.7092 - MinusLogProbMetric: 399.7092 - val_loss: 403.9375 - val_MinusLogProbMetric: 403.9375 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 131/1000
2023-09-11 08:48:53.933 
Epoch 131/1000 
	 loss: 398.7741, MinusLogProbMetric: 398.7741, val_loss: 402.1706, val_MinusLogProbMetric: 402.1706

Epoch 131: val_loss improved from 402.62582 to 402.17056, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 398.7741 - MinusLogProbMetric: 398.7741 - val_loss: 402.1706 - val_MinusLogProbMetric: 402.1706 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 132/1000
2023-09-11 08:49:00.736 
Epoch 132/1000 
	 loss: 399.4752, MinusLogProbMetric: 399.4752, val_loss: 403.4131, val_MinusLogProbMetric: 403.4131

Epoch 132: val_loss did not improve from 402.17056
196/196 - 7s - loss: 399.4752 - MinusLogProbMetric: 399.4752 - val_loss: 403.4131 - val_MinusLogProbMetric: 403.4131 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 133/1000
2023-09-11 08:49:07.293 
Epoch 133/1000 
	 loss: 399.3858, MinusLogProbMetric: 399.3858, val_loss: 402.0088, val_MinusLogProbMetric: 402.0088

Epoch 133: val_loss improved from 402.17056 to 402.00879, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 399.3858 - MinusLogProbMetric: 399.3858 - val_loss: 402.0088 - val_MinusLogProbMetric: 402.0088 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 134/1000
2023-09-11 08:49:14.077 
Epoch 134/1000 
	 loss: 399.0028, MinusLogProbMetric: 399.0028, val_loss: 402.2416, val_MinusLogProbMetric: 402.2416

Epoch 134: val_loss did not improve from 402.00879
196/196 - 7s - loss: 399.0028 - MinusLogProbMetric: 399.0028 - val_loss: 402.2416 - val_MinusLogProbMetric: 402.2416 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 135/1000
2023-09-11 08:49:20.439 
Epoch 135/1000 
	 loss: 399.1979, MinusLogProbMetric: 399.1979, val_loss: 406.2270, val_MinusLogProbMetric: 406.2270

Epoch 135: val_loss did not improve from 402.00879
196/196 - 6s - loss: 399.1979 - MinusLogProbMetric: 399.1979 - val_loss: 406.2270 - val_MinusLogProbMetric: 406.2270 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 136/1000
2023-09-11 08:49:26.918 
Epoch 136/1000 
	 loss: 398.7142, MinusLogProbMetric: 398.7142, val_loss: 402.1015, val_MinusLogProbMetric: 402.1015

Epoch 136: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.7142 - MinusLogProbMetric: 398.7142 - val_loss: 402.1015 - val_MinusLogProbMetric: 402.1015 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 137/1000
2023-09-11 08:49:33.236 
Epoch 137/1000 
	 loss: 400.3893, MinusLogProbMetric: 400.3893, val_loss: 406.7267, val_MinusLogProbMetric: 406.7267

Epoch 137: val_loss did not improve from 402.00879
196/196 - 6s - loss: 400.3893 - MinusLogProbMetric: 400.3893 - val_loss: 406.7267 - val_MinusLogProbMetric: 406.7267 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 138/1000
2023-09-11 08:49:39.747 
Epoch 138/1000 
	 loss: 398.6271, MinusLogProbMetric: 398.6271, val_loss: 403.7959, val_MinusLogProbMetric: 403.7959

Epoch 138: val_loss did not improve from 402.00879
196/196 - 7s - loss: 398.6271 - MinusLogProbMetric: 398.6271 - val_loss: 403.7959 - val_MinusLogProbMetric: 403.7959 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 139/1000
2023-09-11 08:49:46.085 
Epoch 139/1000 
	 loss: 398.3292, MinusLogProbMetric: 398.3292, val_loss: 404.6021, val_MinusLogProbMetric: 404.6021

Epoch 139: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.3292 - MinusLogProbMetric: 398.3292 - val_loss: 404.6021 - val_MinusLogProbMetric: 404.6021 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 140/1000
2023-09-11 08:49:52.560 
Epoch 140/1000 
	 loss: 398.1464, MinusLogProbMetric: 398.1464, val_loss: 402.7084, val_MinusLogProbMetric: 402.7084

Epoch 140: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.1464 - MinusLogProbMetric: 398.1464 - val_loss: 402.7084 - val_MinusLogProbMetric: 402.7084 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 141/1000
2023-09-11 08:49:59.185 
Epoch 141/1000 
	 loss: 399.2990, MinusLogProbMetric: 399.2990, val_loss: 413.1324, val_MinusLogProbMetric: 413.1324

Epoch 141: val_loss did not improve from 402.00879
196/196 - 7s - loss: 399.2990 - MinusLogProbMetric: 399.2990 - val_loss: 413.1324 - val_MinusLogProbMetric: 413.1324 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 142/1000
2023-09-11 08:50:05.996 
Epoch 142/1000 
	 loss: 398.5987, MinusLogProbMetric: 398.5987, val_loss: 402.7177, val_MinusLogProbMetric: 402.7177

Epoch 142: val_loss did not improve from 402.00879
196/196 - 7s - loss: 398.5987 - MinusLogProbMetric: 398.5987 - val_loss: 402.7177 - val_MinusLogProbMetric: 402.7177 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 143/1000
2023-09-11 08:50:12.687 
Epoch 143/1000 
	 loss: 398.7412, MinusLogProbMetric: 398.7412, val_loss: 402.9750, val_MinusLogProbMetric: 402.9750

Epoch 143: val_loss did not improve from 402.00879
196/196 - 7s - loss: 398.7412 - MinusLogProbMetric: 398.7412 - val_loss: 402.9750 - val_MinusLogProbMetric: 402.9750 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 144/1000
2023-09-11 08:50:18.992 
Epoch 144/1000 
	 loss: 397.6922, MinusLogProbMetric: 397.6922, val_loss: 406.3018, val_MinusLogProbMetric: 406.3018

Epoch 144: val_loss did not improve from 402.00879
196/196 - 6s - loss: 397.6922 - MinusLogProbMetric: 397.6922 - val_loss: 406.3018 - val_MinusLogProbMetric: 406.3018 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 145/1000
2023-09-11 08:50:25.323 
Epoch 145/1000 
	 loss: 398.9776, MinusLogProbMetric: 398.9776, val_loss: 402.4613, val_MinusLogProbMetric: 402.4613

Epoch 145: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.9776 - MinusLogProbMetric: 398.9776 - val_loss: 402.4613 - val_MinusLogProbMetric: 402.4613 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 146/1000
2023-09-11 08:50:31.768 
Epoch 146/1000 
	 loss: 398.0302, MinusLogProbMetric: 398.0302, val_loss: 406.8769, val_MinusLogProbMetric: 406.8769

Epoch 146: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.0302 - MinusLogProbMetric: 398.0302 - val_loss: 406.8769 - val_MinusLogProbMetric: 406.8769 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 147/1000
2023-09-11 08:50:38.260 
Epoch 147/1000 
	 loss: 398.6273, MinusLogProbMetric: 398.6273, val_loss: 402.4616, val_MinusLogProbMetric: 402.4616

Epoch 147: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.6273 - MinusLogProbMetric: 398.6273 - val_loss: 402.4616 - val_MinusLogProbMetric: 402.4616 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 148/1000
2023-09-11 08:50:44.708 
Epoch 148/1000 
	 loss: 398.2832, MinusLogProbMetric: 398.2832, val_loss: 403.1698, val_MinusLogProbMetric: 403.1698

Epoch 148: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.2832 - MinusLogProbMetric: 398.2832 - val_loss: 403.1698 - val_MinusLogProbMetric: 403.1698 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 149/1000
2023-09-11 08:50:51.076 
Epoch 149/1000 
	 loss: 397.7232, MinusLogProbMetric: 397.7232, val_loss: 402.9883, val_MinusLogProbMetric: 402.9883

Epoch 149: val_loss did not improve from 402.00879
196/196 - 6s - loss: 397.7232 - MinusLogProbMetric: 397.7232 - val_loss: 402.9883 - val_MinusLogProbMetric: 402.9883 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 150/1000
2023-09-11 08:50:57.568 
Epoch 150/1000 
	 loss: 397.8764, MinusLogProbMetric: 397.8764, val_loss: 410.2993, val_MinusLogProbMetric: 410.2993

Epoch 150: val_loss did not improve from 402.00879
196/196 - 6s - loss: 397.8764 - MinusLogProbMetric: 397.8764 - val_loss: 410.2993 - val_MinusLogProbMetric: 410.2993 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 151/1000
2023-09-11 08:51:03.964 
Epoch 151/1000 
	 loss: 398.8849, MinusLogProbMetric: 398.8849, val_loss: 405.4218, val_MinusLogProbMetric: 405.4218

Epoch 151: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.8849 - MinusLogProbMetric: 398.8849 - val_loss: 405.4218 - val_MinusLogProbMetric: 405.4218 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 152/1000
2023-09-11 08:51:10.412 
Epoch 152/1000 
	 loss: 396.9711, MinusLogProbMetric: 396.9711, val_loss: 403.5515, val_MinusLogProbMetric: 403.5515

Epoch 152: val_loss did not improve from 402.00879
196/196 - 6s - loss: 396.9711 - MinusLogProbMetric: 396.9711 - val_loss: 403.5515 - val_MinusLogProbMetric: 403.5515 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 153/1000
2023-09-11 08:51:16.815 
Epoch 153/1000 
	 loss: 397.9386, MinusLogProbMetric: 397.9386, val_loss: 402.9896, val_MinusLogProbMetric: 402.9896

Epoch 153: val_loss did not improve from 402.00879
196/196 - 6s - loss: 397.9386 - MinusLogProbMetric: 397.9386 - val_loss: 402.9896 - val_MinusLogProbMetric: 402.9896 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 154/1000
2023-09-11 08:51:23.046 
Epoch 154/1000 
	 loss: 398.0463, MinusLogProbMetric: 398.0463, val_loss: 404.1534, val_MinusLogProbMetric: 404.1534

Epoch 154: val_loss did not improve from 402.00879
196/196 - 6s - loss: 398.0463 - MinusLogProbMetric: 398.0463 - val_loss: 404.1534 - val_MinusLogProbMetric: 404.1534 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 155/1000
2023-09-11 08:51:29.441 
Epoch 155/1000 
	 loss: 397.5291, MinusLogProbMetric: 397.5291, val_loss: 404.4828, val_MinusLogProbMetric: 404.4828

Epoch 155: val_loss did not improve from 402.00879
196/196 - 6s - loss: 397.5291 - MinusLogProbMetric: 397.5291 - val_loss: 404.4828 - val_MinusLogProbMetric: 404.4828 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 156/1000
2023-09-11 08:51:35.842 
Epoch 156/1000 
	 loss: 397.4073, MinusLogProbMetric: 397.4073, val_loss: 403.3315, val_MinusLogProbMetric: 403.3315

Epoch 156: val_loss did not improve from 402.00879
196/196 - 6s - loss: 397.4073 - MinusLogProbMetric: 397.4073 - val_loss: 403.3315 - val_MinusLogProbMetric: 403.3315 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 157/1000
2023-09-11 08:51:42.550 
Epoch 157/1000 
	 loss: 398.7558, MinusLogProbMetric: 398.7558, val_loss: 401.8175, val_MinusLogProbMetric: 401.8175

Epoch 157: val_loss improved from 402.00879 to 401.81750, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 398.7558 - MinusLogProbMetric: 398.7558 - val_loss: 401.8175 - val_MinusLogProbMetric: 401.8175 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 158/1000
2023-09-11 08:51:49.489 
Epoch 158/1000 
	 loss: 399.5043, MinusLogProbMetric: 399.5043, val_loss: 402.2369, val_MinusLogProbMetric: 402.2369

Epoch 158: val_loss did not improve from 401.81750
196/196 - 7s - loss: 399.5043 - MinusLogProbMetric: 399.5043 - val_loss: 402.2369 - val_MinusLogProbMetric: 402.2369 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 159/1000
2023-09-11 08:51:55.738 
Epoch 159/1000 
	 loss: 397.7767, MinusLogProbMetric: 397.7767, val_loss: 406.6482, val_MinusLogProbMetric: 406.6482

Epoch 159: val_loss did not improve from 401.81750
196/196 - 6s - loss: 397.7767 - MinusLogProbMetric: 397.7767 - val_loss: 406.6482 - val_MinusLogProbMetric: 406.6482 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 160/1000
2023-09-11 08:52:02.157 
Epoch 160/1000 
	 loss: 396.7398, MinusLogProbMetric: 396.7398, val_loss: 406.6060, val_MinusLogProbMetric: 406.6060

Epoch 160: val_loss did not improve from 401.81750
196/196 - 6s - loss: 396.7398 - MinusLogProbMetric: 396.7398 - val_loss: 406.6060 - val_MinusLogProbMetric: 406.6060 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 161/1000
2023-09-11 08:52:08.647 
Epoch 161/1000 
	 loss: 397.9896, MinusLogProbMetric: 397.9896, val_loss: 406.2193, val_MinusLogProbMetric: 406.2193

Epoch 161: val_loss did not improve from 401.81750
196/196 - 6s - loss: 397.9896 - MinusLogProbMetric: 397.9896 - val_loss: 406.2193 - val_MinusLogProbMetric: 406.2193 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 162/1000
2023-09-11 08:52:14.987 
Epoch 162/1000 
	 loss: 400.1434, MinusLogProbMetric: 400.1434, val_loss: 405.5071, val_MinusLogProbMetric: 405.5071

Epoch 162: val_loss did not improve from 401.81750
196/196 - 6s - loss: 400.1434 - MinusLogProbMetric: 400.1434 - val_loss: 405.5071 - val_MinusLogProbMetric: 405.5071 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 163/1000
2023-09-11 08:52:21.408 
Epoch 163/1000 
	 loss: 396.9522, MinusLogProbMetric: 396.9522, val_loss: 401.7864, val_MinusLogProbMetric: 401.7864

Epoch 163: val_loss improved from 401.81750 to 401.78641, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 396.9522 - MinusLogProbMetric: 396.9522 - val_loss: 401.7864 - val_MinusLogProbMetric: 401.7864 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 164/1000
2023-09-11 08:52:28.188 
Epoch 164/1000 
	 loss: 396.6311, MinusLogProbMetric: 396.6311, val_loss: 414.4883, val_MinusLogProbMetric: 414.4883

Epoch 164: val_loss did not improve from 401.78641
196/196 - 7s - loss: 396.6311 - MinusLogProbMetric: 396.6311 - val_loss: 414.4883 - val_MinusLogProbMetric: 414.4883 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 165/1000
2023-09-11 08:52:34.545 
Epoch 165/1000 
	 loss: 397.8670, MinusLogProbMetric: 397.8670, val_loss: 406.1540, val_MinusLogProbMetric: 406.1540

Epoch 165: val_loss did not improve from 401.78641
196/196 - 6s - loss: 397.8670 - MinusLogProbMetric: 397.8670 - val_loss: 406.1540 - val_MinusLogProbMetric: 406.1540 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 166/1000
2023-09-11 08:52:40.938 
Epoch 166/1000 
	 loss: 398.7422, MinusLogProbMetric: 398.7422, val_loss: 404.6729, val_MinusLogProbMetric: 404.6729

Epoch 166: val_loss did not improve from 401.78641
196/196 - 6s - loss: 398.7422 - MinusLogProbMetric: 398.7422 - val_loss: 404.6729 - val_MinusLogProbMetric: 404.6729 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 167/1000
2023-09-11 08:52:47.392 
Epoch 167/1000 
	 loss: 396.6773, MinusLogProbMetric: 396.6773, val_loss: 405.2924, val_MinusLogProbMetric: 405.2924

Epoch 167: val_loss did not improve from 401.78641
196/196 - 6s - loss: 396.6773 - MinusLogProbMetric: 396.6773 - val_loss: 405.2924 - val_MinusLogProbMetric: 405.2924 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 168/1000
2023-09-11 08:52:53.803 
Epoch 168/1000 
	 loss: 398.1522, MinusLogProbMetric: 398.1522, val_loss: 401.7910, val_MinusLogProbMetric: 401.7910

Epoch 168: val_loss did not improve from 401.78641
196/196 - 6s - loss: 398.1522 - MinusLogProbMetric: 398.1522 - val_loss: 401.7910 - val_MinusLogProbMetric: 401.7910 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 169/1000
2023-09-11 08:53:00.238 
Epoch 169/1000 
	 loss: 397.2037, MinusLogProbMetric: 397.2037, val_loss: 403.0049, val_MinusLogProbMetric: 403.0049

Epoch 169: val_loss did not improve from 401.78641
196/196 - 6s - loss: 397.2037 - MinusLogProbMetric: 397.2037 - val_loss: 403.0049 - val_MinusLogProbMetric: 403.0049 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 170/1000
2023-09-11 08:53:06.644 
Epoch 170/1000 
	 loss: 396.4775, MinusLogProbMetric: 396.4775, val_loss: 404.5413, val_MinusLogProbMetric: 404.5413

Epoch 170: val_loss did not improve from 401.78641
196/196 - 6s - loss: 396.4775 - MinusLogProbMetric: 396.4775 - val_loss: 404.5413 - val_MinusLogProbMetric: 404.5413 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 171/1000
2023-09-11 08:53:13.306 
Epoch 171/1000 
	 loss: 397.0403, MinusLogProbMetric: 397.0403, val_loss: 403.7286, val_MinusLogProbMetric: 403.7286

Epoch 171: val_loss did not improve from 401.78641
196/196 - 7s - loss: 397.0403 - MinusLogProbMetric: 397.0403 - val_loss: 403.7286 - val_MinusLogProbMetric: 403.7286 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 172/1000
2023-09-11 08:53:20.070 
Epoch 172/1000 
	 loss: 396.4571, MinusLogProbMetric: 396.4571, val_loss: 402.3271, val_MinusLogProbMetric: 402.3271

Epoch 172: val_loss did not improve from 401.78641
196/196 - 7s - loss: 396.4571 - MinusLogProbMetric: 396.4571 - val_loss: 402.3271 - val_MinusLogProbMetric: 402.3271 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 173/1000
2023-09-11 08:53:26.632 
Epoch 173/1000 
	 loss: 398.1677, MinusLogProbMetric: 398.1677, val_loss: 402.0393, val_MinusLogProbMetric: 402.0393

Epoch 173: val_loss did not improve from 401.78641
196/196 - 7s - loss: 398.1677 - MinusLogProbMetric: 398.1677 - val_loss: 402.0393 - val_MinusLogProbMetric: 402.0393 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 174/1000
2023-09-11 08:53:33.008 
Epoch 174/1000 
	 loss: 396.4507, MinusLogProbMetric: 396.4507, val_loss: 402.6007, val_MinusLogProbMetric: 402.6007

Epoch 174: val_loss did not improve from 401.78641
196/196 - 6s - loss: 396.4507 - MinusLogProbMetric: 396.4507 - val_loss: 402.6007 - val_MinusLogProbMetric: 402.6007 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 175/1000
2023-09-11 08:53:39.316 
Epoch 175/1000 
	 loss: 396.2596, MinusLogProbMetric: 396.2596, val_loss: 407.8957, val_MinusLogProbMetric: 407.8957

Epoch 175: val_loss did not improve from 401.78641
196/196 - 6s - loss: 396.2596 - MinusLogProbMetric: 396.2596 - val_loss: 407.8957 - val_MinusLogProbMetric: 407.8957 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 176/1000
2023-09-11 08:53:45.596 
Epoch 176/1000 
	 loss: 398.1996, MinusLogProbMetric: 398.1996, val_loss: 401.8985, val_MinusLogProbMetric: 401.8985

Epoch 176: val_loss did not improve from 401.78641
196/196 - 6s - loss: 398.1996 - MinusLogProbMetric: 398.1996 - val_loss: 401.8985 - val_MinusLogProbMetric: 401.8985 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 177/1000
2023-09-11 08:53:51.829 
Epoch 177/1000 
	 loss: 395.8498, MinusLogProbMetric: 395.8498, val_loss: 403.7950, val_MinusLogProbMetric: 403.7950

Epoch 177: val_loss did not improve from 401.78641
196/196 - 6s - loss: 395.8498 - MinusLogProbMetric: 395.8498 - val_loss: 403.7950 - val_MinusLogProbMetric: 403.7950 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 178/1000
2023-09-11 08:53:58.182 
Epoch 178/1000 
	 loss: 396.7438, MinusLogProbMetric: 396.7438, val_loss: 401.1537, val_MinusLogProbMetric: 401.1537

Epoch 178: val_loss improved from 401.78641 to 401.15369, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 396.7438 - MinusLogProbMetric: 396.7438 - val_loss: 401.1537 - val_MinusLogProbMetric: 401.1537 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 179/1000
2023-09-11 08:54:04.774 
Epoch 179/1000 
	 loss: 396.5532, MinusLogProbMetric: 396.5532, val_loss: 403.3419, val_MinusLogProbMetric: 403.3419

Epoch 179: val_loss did not improve from 401.15369
196/196 - 6s - loss: 396.5532 - MinusLogProbMetric: 396.5532 - val_loss: 403.3419 - val_MinusLogProbMetric: 403.3419 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 180/1000
2023-09-11 08:54:11.120 
Epoch 180/1000 
	 loss: 397.4705, MinusLogProbMetric: 397.4705, val_loss: 410.8975, val_MinusLogProbMetric: 410.8975

Epoch 180: val_loss did not improve from 401.15369
196/196 - 6s - loss: 397.4705 - MinusLogProbMetric: 397.4705 - val_loss: 410.8975 - val_MinusLogProbMetric: 410.8975 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 181/1000
2023-09-11 08:54:17.487 
Epoch 181/1000 
	 loss: 396.0915, MinusLogProbMetric: 396.0915, val_loss: 402.4453, val_MinusLogProbMetric: 402.4453

Epoch 181: val_loss did not improve from 401.15369
196/196 - 6s - loss: 396.0915 - MinusLogProbMetric: 396.0915 - val_loss: 402.4453 - val_MinusLogProbMetric: 402.4453 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 182/1000
2023-09-11 08:54:23.941 
Epoch 182/1000 
	 loss: 397.1697, MinusLogProbMetric: 397.1697, val_loss: 402.9216, val_MinusLogProbMetric: 402.9216

Epoch 182: val_loss did not improve from 401.15369
196/196 - 6s - loss: 397.1697 - MinusLogProbMetric: 397.1697 - val_loss: 402.9216 - val_MinusLogProbMetric: 402.9216 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 183/1000
2023-09-11 08:54:30.168 
Epoch 183/1000 
	 loss: 396.7473, MinusLogProbMetric: 396.7473, val_loss: 401.4838, val_MinusLogProbMetric: 401.4838

Epoch 183: val_loss did not improve from 401.15369
196/196 - 6s - loss: 396.7473 - MinusLogProbMetric: 396.7473 - val_loss: 401.4838 - val_MinusLogProbMetric: 401.4838 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 184/1000
2023-09-11 08:54:36.668 
Epoch 184/1000 
	 loss: 395.8134, MinusLogProbMetric: 395.8134, val_loss: 409.1286, val_MinusLogProbMetric: 409.1286

Epoch 184: val_loss did not improve from 401.15369
196/196 - 6s - loss: 395.8134 - MinusLogProbMetric: 395.8134 - val_loss: 409.1286 - val_MinusLogProbMetric: 409.1286 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 185/1000
2023-09-11 08:54:43.115 
Epoch 185/1000 
	 loss: 396.6099, MinusLogProbMetric: 396.6099, val_loss: 403.0454, val_MinusLogProbMetric: 403.0454

Epoch 185: val_loss did not improve from 401.15369
196/196 - 6s - loss: 396.6099 - MinusLogProbMetric: 396.6099 - val_loss: 403.0454 - val_MinusLogProbMetric: 403.0454 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 186/1000
2023-09-11 08:54:49.867 
Epoch 186/1000 
	 loss: 396.6930, MinusLogProbMetric: 396.6930, val_loss: 401.5874, val_MinusLogProbMetric: 401.5874

Epoch 186: val_loss did not improve from 401.15369
196/196 - 7s - loss: 396.6930 - MinusLogProbMetric: 396.6930 - val_loss: 401.5874 - val_MinusLogProbMetric: 401.5874 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 187/1000
2023-09-11 08:54:56.850 
Epoch 187/1000 
	 loss: 397.2686, MinusLogProbMetric: 397.2686, val_loss: 403.6572, val_MinusLogProbMetric: 403.6572

Epoch 187: val_loss did not improve from 401.15369
196/196 - 7s - loss: 397.2686 - MinusLogProbMetric: 397.2686 - val_loss: 403.6572 - val_MinusLogProbMetric: 403.6572 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 188/1000
2023-09-11 08:55:03.579 
Epoch 188/1000 
	 loss: 395.3929, MinusLogProbMetric: 395.3929, val_loss: 404.4040, val_MinusLogProbMetric: 404.4040

Epoch 188: val_loss did not improve from 401.15369
196/196 - 7s - loss: 395.3929 - MinusLogProbMetric: 395.3929 - val_loss: 404.4040 - val_MinusLogProbMetric: 404.4040 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 189/1000
2023-09-11 08:55:10.140 
Epoch 189/1000 
	 loss: 397.3649, MinusLogProbMetric: 397.3649, val_loss: 403.9328, val_MinusLogProbMetric: 403.9328

Epoch 189: val_loss did not improve from 401.15369
196/196 - 7s - loss: 397.3649 - MinusLogProbMetric: 397.3649 - val_loss: 403.9328 - val_MinusLogProbMetric: 403.9328 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 190/1000
2023-09-11 08:55:16.434 
Epoch 190/1000 
	 loss: 395.7315, MinusLogProbMetric: 395.7315, val_loss: 401.0445, val_MinusLogProbMetric: 401.0445

Epoch 190: val_loss improved from 401.15369 to 401.04446, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 395.7315 - MinusLogProbMetric: 395.7315 - val_loss: 401.0445 - val_MinusLogProbMetric: 401.0445 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 191/1000
2023-09-11 08:55:23.152 
Epoch 191/1000 
	 loss: 396.5376, MinusLogProbMetric: 396.5376, val_loss: 406.8176, val_MinusLogProbMetric: 406.8176

Epoch 191: val_loss did not improve from 401.04446
196/196 - 6s - loss: 396.5376 - MinusLogProbMetric: 396.5376 - val_loss: 406.8176 - val_MinusLogProbMetric: 406.8176 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 192/1000
2023-09-11 08:55:29.582 
Epoch 192/1000 
	 loss: 395.3190, MinusLogProbMetric: 395.3190, val_loss: 404.5696, val_MinusLogProbMetric: 404.5696

Epoch 192: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.3190 - MinusLogProbMetric: 395.3190 - val_loss: 404.5696 - val_MinusLogProbMetric: 404.5696 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 193/1000
2023-09-11 08:55:36.157 
Epoch 193/1000 
	 loss: 395.9078, MinusLogProbMetric: 395.9078, val_loss: 402.3103, val_MinusLogProbMetric: 402.3103

Epoch 193: val_loss did not improve from 401.04446
196/196 - 7s - loss: 395.9078 - MinusLogProbMetric: 395.9078 - val_loss: 402.3103 - val_MinusLogProbMetric: 402.3103 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 194/1000
2023-09-11 08:55:42.686 
Epoch 194/1000 
	 loss: 400.4440, MinusLogProbMetric: 400.4440, val_loss: 405.4843, val_MinusLogProbMetric: 405.4843

Epoch 194: val_loss did not improve from 401.04446
196/196 - 7s - loss: 400.4440 - MinusLogProbMetric: 400.4440 - val_loss: 405.4843 - val_MinusLogProbMetric: 405.4843 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 195/1000
2023-09-11 08:55:49.099 
Epoch 195/1000 
	 loss: 394.8071, MinusLogProbMetric: 394.8071, val_loss: 403.4760, val_MinusLogProbMetric: 403.4760

Epoch 195: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.8071 - MinusLogProbMetric: 394.8071 - val_loss: 403.4760 - val_MinusLogProbMetric: 403.4760 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 196/1000
2023-09-11 08:55:55.574 
Epoch 196/1000 
	 loss: 396.0493, MinusLogProbMetric: 396.0493, val_loss: 402.6694, val_MinusLogProbMetric: 402.6694

Epoch 196: val_loss did not improve from 401.04446
196/196 - 6s - loss: 396.0493 - MinusLogProbMetric: 396.0493 - val_loss: 402.6694 - val_MinusLogProbMetric: 402.6694 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 197/1000
2023-09-11 08:56:02.065 
Epoch 197/1000 
	 loss: 395.3427, MinusLogProbMetric: 395.3427, val_loss: 404.2373, val_MinusLogProbMetric: 404.2373

Epoch 197: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.3427 - MinusLogProbMetric: 395.3427 - val_loss: 404.2373 - val_MinusLogProbMetric: 404.2373 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 198/1000
2023-09-11 08:56:08.622 
Epoch 198/1000 
	 loss: 396.4742, MinusLogProbMetric: 396.4742, val_loss: 402.4596, val_MinusLogProbMetric: 402.4596

Epoch 198: val_loss did not improve from 401.04446
196/196 - 7s - loss: 396.4742 - MinusLogProbMetric: 396.4742 - val_loss: 402.4596 - val_MinusLogProbMetric: 402.4596 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 199/1000
2023-09-11 08:56:15.041 
Epoch 199/1000 
	 loss: 395.4383, MinusLogProbMetric: 395.4383, val_loss: 403.2031, val_MinusLogProbMetric: 403.2031

Epoch 199: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.4383 - MinusLogProbMetric: 395.4383 - val_loss: 403.2031 - val_MinusLogProbMetric: 403.2031 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 200/1000
2023-09-11 08:56:21.384 
Epoch 200/1000 
	 loss: 395.6343, MinusLogProbMetric: 395.6343, val_loss: 401.6686, val_MinusLogProbMetric: 401.6686

Epoch 200: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.6343 - MinusLogProbMetric: 395.6343 - val_loss: 401.6686 - val_MinusLogProbMetric: 401.6686 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 201/1000
2023-09-11 08:56:28.187 
Epoch 201/1000 
	 loss: 395.3366, MinusLogProbMetric: 395.3366, val_loss: 404.0528, val_MinusLogProbMetric: 404.0528

Epoch 201: val_loss did not improve from 401.04446
196/196 - 7s - loss: 395.3366 - MinusLogProbMetric: 395.3366 - val_loss: 404.0528 - val_MinusLogProbMetric: 404.0528 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 202/1000
2023-09-11 08:56:35.047 
Epoch 202/1000 
	 loss: 395.1038, MinusLogProbMetric: 395.1038, val_loss: 403.7687, val_MinusLogProbMetric: 403.7687

Epoch 202: val_loss did not improve from 401.04446
196/196 - 7s - loss: 395.1038 - MinusLogProbMetric: 395.1038 - val_loss: 403.7687 - val_MinusLogProbMetric: 403.7687 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 203/1000
2023-09-11 08:56:41.507 
Epoch 203/1000 
	 loss: 395.6839, MinusLogProbMetric: 395.6839, val_loss: 403.2011, val_MinusLogProbMetric: 403.2011

Epoch 203: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.6839 - MinusLogProbMetric: 395.6839 - val_loss: 403.2011 - val_MinusLogProbMetric: 403.2011 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 204/1000
2023-09-11 08:56:47.972 
Epoch 204/1000 
	 loss: 395.8528, MinusLogProbMetric: 395.8528, val_loss: 401.6943, val_MinusLogProbMetric: 401.6943

Epoch 204: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.8528 - MinusLogProbMetric: 395.8528 - val_loss: 401.6943 - val_MinusLogProbMetric: 401.6943 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 205/1000
2023-09-11 08:56:54.383 
Epoch 205/1000 
	 loss: 395.4655, MinusLogProbMetric: 395.4655, val_loss: 407.9283, val_MinusLogProbMetric: 407.9283

Epoch 205: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.4655 - MinusLogProbMetric: 395.4655 - val_loss: 407.9283 - val_MinusLogProbMetric: 407.9283 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 206/1000
2023-09-11 08:57:00.815 
Epoch 206/1000 
	 loss: 394.6142, MinusLogProbMetric: 394.6142, val_loss: 403.2776, val_MinusLogProbMetric: 403.2776

Epoch 206: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.6142 - MinusLogProbMetric: 394.6142 - val_loss: 403.2776 - val_MinusLogProbMetric: 403.2776 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 207/1000
2023-09-11 08:57:07.142 
Epoch 207/1000 
	 loss: 394.7821, MinusLogProbMetric: 394.7821, val_loss: 402.7022, val_MinusLogProbMetric: 402.7022

Epoch 207: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.7821 - MinusLogProbMetric: 394.7821 - val_loss: 402.7022 - val_MinusLogProbMetric: 402.7022 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 208/1000
2023-09-11 08:57:13.475 
Epoch 208/1000 
	 loss: 394.9765, MinusLogProbMetric: 394.9765, val_loss: 402.8991, val_MinusLogProbMetric: 402.8991

Epoch 208: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.9765 - MinusLogProbMetric: 394.9765 - val_loss: 402.8991 - val_MinusLogProbMetric: 402.8991 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 209/1000
2023-09-11 08:57:19.884 
Epoch 209/1000 
	 loss: 395.4357, MinusLogProbMetric: 395.4357, val_loss: 404.8763, val_MinusLogProbMetric: 404.8763

Epoch 209: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.4357 - MinusLogProbMetric: 395.4357 - val_loss: 404.8763 - val_MinusLogProbMetric: 404.8763 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 210/1000
2023-09-11 08:57:26.371 
Epoch 210/1000 
	 loss: 397.2596, MinusLogProbMetric: 397.2596, val_loss: 402.2583, val_MinusLogProbMetric: 402.2583

Epoch 210: val_loss did not improve from 401.04446
196/196 - 6s - loss: 397.2596 - MinusLogProbMetric: 397.2596 - val_loss: 402.2583 - val_MinusLogProbMetric: 402.2583 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 211/1000
2023-09-11 08:57:32.767 
Epoch 211/1000 
	 loss: 394.3534, MinusLogProbMetric: 394.3534, val_loss: 402.4545, val_MinusLogProbMetric: 402.4545

Epoch 211: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.3534 - MinusLogProbMetric: 394.3534 - val_loss: 402.4545 - val_MinusLogProbMetric: 402.4545 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 212/1000
2023-09-11 08:57:39.174 
Epoch 212/1000 
	 loss: 395.0184, MinusLogProbMetric: 395.0184, val_loss: 402.6595, val_MinusLogProbMetric: 402.6595

Epoch 212: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.0184 - MinusLogProbMetric: 395.0184 - val_loss: 402.6595 - val_MinusLogProbMetric: 402.6595 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 213/1000
2023-09-11 08:57:45.676 
Epoch 213/1000 
	 loss: 394.6074, MinusLogProbMetric: 394.6074, val_loss: 405.4634, val_MinusLogProbMetric: 405.4634

Epoch 213: val_loss did not improve from 401.04446
196/196 - 7s - loss: 394.6074 - MinusLogProbMetric: 394.6074 - val_loss: 405.4634 - val_MinusLogProbMetric: 405.4634 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 214/1000
2023-09-11 08:57:52.137 
Epoch 214/1000 
	 loss: 396.0207, MinusLogProbMetric: 396.0207, val_loss: 403.0463, val_MinusLogProbMetric: 403.0463

Epoch 214: val_loss did not improve from 401.04446
196/196 - 6s - loss: 396.0207 - MinusLogProbMetric: 396.0207 - val_loss: 403.0463 - val_MinusLogProbMetric: 403.0463 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 215/1000
2023-09-11 08:57:58.732 
Epoch 215/1000 
	 loss: 394.5856, MinusLogProbMetric: 394.5856, val_loss: 402.9374, val_MinusLogProbMetric: 402.9374

Epoch 215: val_loss did not improve from 401.04446
196/196 - 7s - loss: 394.5856 - MinusLogProbMetric: 394.5856 - val_loss: 402.9374 - val_MinusLogProbMetric: 402.9374 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 216/1000
2023-09-11 08:58:05.585 
Epoch 216/1000 
	 loss: 394.6894, MinusLogProbMetric: 394.6894, val_loss: 401.8462, val_MinusLogProbMetric: 401.8462

Epoch 216: val_loss did not improve from 401.04446
196/196 - 7s - loss: 394.6894 - MinusLogProbMetric: 394.6894 - val_loss: 401.8462 - val_MinusLogProbMetric: 401.8462 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 217/1000
2023-09-11 08:58:12.596 
Epoch 217/1000 
	 loss: 394.6018, MinusLogProbMetric: 394.6018, val_loss: 402.2177, val_MinusLogProbMetric: 402.2177

Epoch 217: val_loss did not improve from 401.04446
196/196 - 7s - loss: 394.6018 - MinusLogProbMetric: 394.6018 - val_loss: 402.2177 - val_MinusLogProbMetric: 402.2177 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 218/1000
2023-09-11 08:58:19.254 
Epoch 218/1000 
	 loss: 395.5304, MinusLogProbMetric: 395.5304, val_loss: 403.6565, val_MinusLogProbMetric: 403.6565

Epoch 218: val_loss did not improve from 401.04446
196/196 - 7s - loss: 395.5304 - MinusLogProbMetric: 395.5304 - val_loss: 403.6565 - val_MinusLogProbMetric: 403.6565 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 219/1000
2023-09-11 08:58:25.670 
Epoch 219/1000 
	 loss: 394.2855, MinusLogProbMetric: 394.2855, val_loss: 404.8351, val_MinusLogProbMetric: 404.8351

Epoch 219: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.2855 - MinusLogProbMetric: 394.2855 - val_loss: 404.8351 - val_MinusLogProbMetric: 404.8351 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 220/1000
2023-09-11 08:58:31.976 
Epoch 220/1000 
	 loss: 394.8220, MinusLogProbMetric: 394.8220, val_loss: 405.7387, val_MinusLogProbMetric: 405.7387

Epoch 220: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.8220 - MinusLogProbMetric: 394.8220 - val_loss: 405.7387 - val_MinusLogProbMetric: 405.7387 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 221/1000
2023-09-11 08:58:38.575 
Epoch 221/1000 
	 loss: 394.4919, MinusLogProbMetric: 394.4919, val_loss: 407.7797, val_MinusLogProbMetric: 407.7797

Epoch 221: val_loss did not improve from 401.04446
196/196 - 7s - loss: 394.4919 - MinusLogProbMetric: 394.4919 - val_loss: 407.7797 - val_MinusLogProbMetric: 407.7797 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 222/1000
2023-09-11 08:58:45.046 
Epoch 222/1000 
	 loss: 395.2422, MinusLogProbMetric: 395.2422, val_loss: 402.1387, val_MinusLogProbMetric: 402.1387

Epoch 222: val_loss did not improve from 401.04446
196/196 - 6s - loss: 395.2422 - MinusLogProbMetric: 395.2422 - val_loss: 402.1387 - val_MinusLogProbMetric: 402.1387 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 223/1000
2023-09-11 08:58:51.482 
Epoch 223/1000 
	 loss: 394.2343, MinusLogProbMetric: 394.2343, val_loss: 402.6687, val_MinusLogProbMetric: 402.6687

Epoch 223: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.2343 - MinusLogProbMetric: 394.2343 - val_loss: 402.6687 - val_MinusLogProbMetric: 402.6687 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 224/1000
2023-09-11 08:58:58.006 
Epoch 224/1000 
	 loss: 394.4880, MinusLogProbMetric: 394.4880, val_loss: 402.3413, val_MinusLogProbMetric: 402.3413

Epoch 224: val_loss did not improve from 401.04446
196/196 - 7s - loss: 394.4880 - MinusLogProbMetric: 394.4880 - val_loss: 402.3413 - val_MinusLogProbMetric: 402.3413 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 225/1000
2023-09-11 08:59:04.501 
Epoch 225/1000 
	 loss: 393.9121, MinusLogProbMetric: 393.9121, val_loss: 408.3302, val_MinusLogProbMetric: 408.3302

Epoch 225: val_loss did not improve from 401.04446
196/196 - 6s - loss: 393.9121 - MinusLogProbMetric: 393.9121 - val_loss: 408.3302 - val_MinusLogProbMetric: 408.3302 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 226/1000
2023-09-11 08:59:11.145 
Epoch 226/1000 
	 loss: 395.1733, MinusLogProbMetric: 395.1733, val_loss: 404.3053, val_MinusLogProbMetric: 404.3053

Epoch 226: val_loss did not improve from 401.04446
196/196 - 7s - loss: 395.1733 - MinusLogProbMetric: 395.1733 - val_loss: 404.3053 - val_MinusLogProbMetric: 404.3053 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 227/1000
2023-09-11 08:59:17.466 
Epoch 227/1000 
	 loss: 394.3738, MinusLogProbMetric: 394.3738, val_loss: 409.5386, val_MinusLogProbMetric: 409.5386

Epoch 227: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.3738 - MinusLogProbMetric: 394.3738 - val_loss: 409.5386 - val_MinusLogProbMetric: 409.5386 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 228/1000
2023-09-11 08:59:23.867 
Epoch 228/1000 
	 loss: 396.9289, MinusLogProbMetric: 396.9289, val_loss: 402.6281, val_MinusLogProbMetric: 402.6281

Epoch 228: val_loss did not improve from 401.04446
196/196 - 6s - loss: 396.9289 - MinusLogProbMetric: 396.9289 - val_loss: 402.6281 - val_MinusLogProbMetric: 402.6281 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 229/1000
2023-09-11 08:59:30.313 
Epoch 229/1000 
	 loss: 393.7982, MinusLogProbMetric: 393.7982, val_loss: 403.0423, val_MinusLogProbMetric: 403.0423

Epoch 229: val_loss did not improve from 401.04446
196/196 - 6s - loss: 393.7982 - MinusLogProbMetric: 393.7982 - val_loss: 403.0423 - val_MinusLogProbMetric: 403.0423 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 230/1000
2023-09-11 08:59:36.929 
Epoch 230/1000 
	 loss: 393.6852, MinusLogProbMetric: 393.6852, val_loss: 402.0900, val_MinusLogProbMetric: 402.0900

Epoch 230: val_loss did not improve from 401.04446
196/196 - 7s - loss: 393.6852 - MinusLogProbMetric: 393.6852 - val_loss: 402.0900 - val_MinusLogProbMetric: 402.0900 - lr: 3.3333e-04 - 7s/epoch - 34ms/step
Epoch 231/1000
2023-09-11 08:59:43.849 
Epoch 231/1000 
	 loss: 395.2546, MinusLogProbMetric: 395.2546, val_loss: 426.3668, val_MinusLogProbMetric: 426.3668

Epoch 231: val_loss did not improve from 401.04446
196/196 - 7s - loss: 395.2546 - MinusLogProbMetric: 395.2546 - val_loss: 426.3668 - val_MinusLogProbMetric: 426.3668 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 232/1000
2023-09-11 08:59:50.713 
Epoch 232/1000 
	 loss: 394.8522, MinusLogProbMetric: 394.8522, val_loss: 403.4955, val_MinusLogProbMetric: 403.4955

Epoch 232: val_loss did not improve from 401.04446
196/196 - 7s - loss: 394.8522 - MinusLogProbMetric: 394.8522 - val_loss: 403.4955 - val_MinusLogProbMetric: 403.4955 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 233/1000
2023-09-11 08:59:57.053 
Epoch 233/1000 
	 loss: 393.7240, MinusLogProbMetric: 393.7240, val_loss: 403.2707, val_MinusLogProbMetric: 403.2707

Epoch 233: val_loss did not improve from 401.04446
196/196 - 6s - loss: 393.7240 - MinusLogProbMetric: 393.7240 - val_loss: 403.2707 - val_MinusLogProbMetric: 403.2707 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 234/1000
2023-09-11 09:00:03.427 
Epoch 234/1000 
	 loss: 393.8625, MinusLogProbMetric: 393.8625, val_loss: 403.3097, val_MinusLogProbMetric: 403.3097

Epoch 234: val_loss did not improve from 401.04446
196/196 - 6s - loss: 393.8625 - MinusLogProbMetric: 393.8625 - val_loss: 403.3097 - val_MinusLogProbMetric: 403.3097 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 235/1000
2023-09-11 09:00:09.916 
Epoch 235/1000 
	 loss: 394.3756, MinusLogProbMetric: 394.3756, val_loss: 404.8785, val_MinusLogProbMetric: 404.8785

Epoch 235: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.3756 - MinusLogProbMetric: 394.3756 - val_loss: 404.8785 - val_MinusLogProbMetric: 404.8785 - lr: 3.3333e-04 - 6s/epoch - 33ms/step
Epoch 236/1000
2023-09-11 09:00:16.161 
Epoch 236/1000 
	 loss: 393.5040, MinusLogProbMetric: 393.5040, val_loss: 403.9549, val_MinusLogProbMetric: 403.9549

Epoch 236: val_loss did not improve from 401.04446
196/196 - 6s - loss: 393.5040 - MinusLogProbMetric: 393.5040 - val_loss: 403.9549 - val_MinusLogProbMetric: 403.9549 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 237/1000
2023-09-11 09:00:22.410 
Epoch 237/1000 
	 loss: 394.7242, MinusLogProbMetric: 394.7242, val_loss: 403.4127, val_MinusLogProbMetric: 403.4127

Epoch 237: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.7242 - MinusLogProbMetric: 394.7242 - val_loss: 403.4127 - val_MinusLogProbMetric: 403.4127 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 238/1000
2023-09-11 09:00:28.920 
Epoch 238/1000 
	 loss: 393.7337, MinusLogProbMetric: 393.7337, val_loss: 403.8091, val_MinusLogProbMetric: 403.8091

Epoch 238: val_loss did not improve from 401.04446
196/196 - 7s - loss: 393.7337 - MinusLogProbMetric: 393.7337 - val_loss: 403.8091 - val_MinusLogProbMetric: 403.8091 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 239/1000
2023-09-11 09:00:35.458 
Epoch 239/1000 
	 loss: 393.3270, MinusLogProbMetric: 393.3270, val_loss: 404.2646, val_MinusLogProbMetric: 404.2646

Epoch 239: val_loss did not improve from 401.04446
196/196 - 7s - loss: 393.3270 - MinusLogProbMetric: 393.3270 - val_loss: 404.2646 - val_MinusLogProbMetric: 404.2646 - lr: 3.3333e-04 - 7s/epoch - 33ms/step
Epoch 240/1000
2023-09-11 09:00:41.715 
Epoch 240/1000 
	 loss: 394.6229, MinusLogProbMetric: 394.6229, val_loss: 402.6260, val_MinusLogProbMetric: 402.6260

Epoch 240: val_loss did not improve from 401.04446
196/196 - 6s - loss: 394.6229 - MinusLogProbMetric: 394.6229 - val_loss: 402.6260 - val_MinusLogProbMetric: 402.6260 - lr: 3.3333e-04 - 6s/epoch - 32ms/step
Epoch 241/1000
2023-09-11 09:00:48.196 
Epoch 241/1000 
	 loss: 388.4005, MinusLogProbMetric: 388.4005, val_loss: 399.4747, val_MinusLogProbMetric: 399.4747

Epoch 241: val_loss improved from 401.04446 to 399.47470, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_340/weights/best_weights.h5
196/196 - 7s - loss: 388.4005 - MinusLogProbMetric: 388.4005 - val_loss: 399.4747 - val_MinusLogProbMetric: 399.4747 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 242/1000
2023-09-11 09:00:54.934 
Epoch 242/1000 
	 loss: 388.4455, MinusLogProbMetric: 388.4455, val_loss: 399.8012, val_MinusLogProbMetric: 399.8012

Epoch 242: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.4455 - MinusLogProbMetric: 388.4455 - val_loss: 399.8012 - val_MinusLogProbMetric: 399.8012 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 243/1000
2023-09-11 09:01:01.135 
Epoch 243/1000 
	 loss: 388.0318, MinusLogProbMetric: 388.0318, val_loss: 400.1140, val_MinusLogProbMetric: 400.1140

Epoch 243: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.0318 - MinusLogProbMetric: 388.0318 - val_loss: 400.1140 - val_MinusLogProbMetric: 400.1140 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 244/1000
2023-09-11 09:01:07.191 
Epoch 244/1000 
	 loss: 392.8239, MinusLogProbMetric: 392.8239, val_loss: 400.0628, val_MinusLogProbMetric: 400.0628

Epoch 244: val_loss did not improve from 399.47470
196/196 - 6s - loss: 392.8239 - MinusLogProbMetric: 392.8239 - val_loss: 400.0628 - val_MinusLogProbMetric: 400.0628 - lr: 1.6667e-04 - 6s/epoch - 31ms/step
Epoch 245/1000
2023-09-11 09:01:13.388 
Epoch 245/1000 
	 loss: 388.4234, MinusLogProbMetric: 388.4234, val_loss: 401.1133, val_MinusLogProbMetric: 401.1133

Epoch 245: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.4234 - MinusLogProbMetric: 388.4234 - val_loss: 401.1133 - val_MinusLogProbMetric: 401.1133 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 246/1000
2023-09-11 09:01:19.879 
Epoch 246/1000 
	 loss: 388.3805, MinusLogProbMetric: 388.3805, val_loss: 399.8644, val_MinusLogProbMetric: 399.8644

Epoch 246: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.3805 - MinusLogProbMetric: 388.3805 - val_loss: 399.8644 - val_MinusLogProbMetric: 399.8644 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 247/1000
2023-09-11 09:01:26.762 
Epoch 247/1000 
	 loss: 388.7039, MinusLogProbMetric: 388.7039, val_loss: 404.1451, val_MinusLogProbMetric: 404.1451

Epoch 247: val_loss did not improve from 399.47470
196/196 - 7s - loss: 388.7039 - MinusLogProbMetric: 388.7039 - val_loss: 404.1451 - val_MinusLogProbMetric: 404.1451 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 248/1000
2023-09-11 09:01:33.818 
Epoch 248/1000 
	 loss: 388.4454, MinusLogProbMetric: 388.4454, val_loss: 401.8288, val_MinusLogProbMetric: 401.8288

Epoch 248: val_loss did not improve from 399.47470
196/196 - 7s - loss: 388.4454 - MinusLogProbMetric: 388.4454 - val_loss: 401.8288 - val_MinusLogProbMetric: 401.8288 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 249/1000
2023-09-11 09:01:40.466 
Epoch 249/1000 
	 loss: 388.3213, MinusLogProbMetric: 388.3213, val_loss: 399.7165, val_MinusLogProbMetric: 399.7165

Epoch 249: val_loss did not improve from 399.47470
196/196 - 7s - loss: 388.3213 - MinusLogProbMetric: 388.3213 - val_loss: 399.7165 - val_MinusLogProbMetric: 399.7165 - lr: 1.6667e-04 - 7s/epoch - 34ms/step
Epoch 250/1000
2023-09-11 09:01:46.874 
Epoch 250/1000 
	 loss: 390.1605, MinusLogProbMetric: 390.1605, val_loss: 401.0568, val_MinusLogProbMetric: 401.0568

Epoch 250: val_loss did not improve from 399.47470
196/196 - 6s - loss: 390.1605 - MinusLogProbMetric: 390.1605 - val_loss: 401.0568 - val_MinusLogProbMetric: 401.0568 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 251/1000
2023-09-11 09:01:53.240 
Epoch 251/1000 
	 loss: 388.5121, MinusLogProbMetric: 388.5121, val_loss: 400.2022, val_MinusLogProbMetric: 400.2022

Epoch 251: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.5121 - MinusLogProbMetric: 388.5121 - val_loss: 400.2022 - val_MinusLogProbMetric: 400.2022 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 252/1000
2023-09-11 09:01:59.545 
Epoch 252/1000 
	 loss: 389.0152, MinusLogProbMetric: 389.0152, val_loss: 399.8604, val_MinusLogProbMetric: 399.8604

Epoch 252: val_loss did not improve from 399.47470
196/196 - 6s - loss: 389.0152 - MinusLogProbMetric: 389.0152 - val_loss: 399.8604 - val_MinusLogProbMetric: 399.8604 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 253/1000
2023-09-11 09:02:06.002 
Epoch 253/1000 
	 loss: 389.0321, MinusLogProbMetric: 389.0321, val_loss: 400.1839, val_MinusLogProbMetric: 400.1839

Epoch 253: val_loss did not improve from 399.47470
196/196 - 6s - loss: 389.0321 - MinusLogProbMetric: 389.0321 - val_loss: 400.1839 - val_MinusLogProbMetric: 400.1839 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 254/1000
2023-09-11 09:02:12.406 
Epoch 254/1000 
	 loss: 388.1251, MinusLogProbMetric: 388.1251, val_loss: 401.2084, val_MinusLogProbMetric: 401.2084

Epoch 254: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.1251 - MinusLogProbMetric: 388.1251 - val_loss: 401.2084 - val_MinusLogProbMetric: 401.2084 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 255/1000
2023-09-11 09:02:18.881 
Epoch 255/1000 
	 loss: 388.8920, MinusLogProbMetric: 388.8920, val_loss: 400.2882, val_MinusLogProbMetric: 400.2882

Epoch 255: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.8920 - MinusLogProbMetric: 388.8920 - val_loss: 400.2882 - val_MinusLogProbMetric: 400.2882 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 256/1000
2023-09-11 09:02:25.348 
Epoch 256/1000 
	 loss: 388.6366, MinusLogProbMetric: 388.6366, val_loss: 408.6497, val_MinusLogProbMetric: 408.6497

Epoch 256: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.6366 - MinusLogProbMetric: 388.6366 - val_loss: 408.6497 - val_MinusLogProbMetric: 408.6497 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 257/1000
2023-09-11 09:02:31.779 
Epoch 257/1000 
	 loss: 388.3943, MinusLogProbMetric: 388.3943, val_loss: 399.6919, val_MinusLogProbMetric: 399.6919

Epoch 257: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.3943 - MinusLogProbMetric: 388.3943 - val_loss: 399.6919 - val_MinusLogProbMetric: 399.6919 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 258/1000
2023-09-11 09:02:38.199 
Epoch 258/1000 
	 loss: 388.7298, MinusLogProbMetric: 388.7298, val_loss: 400.3063, val_MinusLogProbMetric: 400.3063

Epoch 258: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.7298 - MinusLogProbMetric: 388.7298 - val_loss: 400.3063 - val_MinusLogProbMetric: 400.3063 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 259/1000
2023-09-11 09:02:44.653 
Epoch 259/1000 
	 loss: 387.7264, MinusLogProbMetric: 387.7264, val_loss: 400.0388, val_MinusLogProbMetric: 400.0388

Epoch 259: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.7264 - MinusLogProbMetric: 387.7264 - val_loss: 400.0388 - val_MinusLogProbMetric: 400.0388 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 260/1000
2023-09-11 09:02:51.040 
Epoch 260/1000 
	 loss: 388.9461, MinusLogProbMetric: 388.9461, val_loss: 399.7680, val_MinusLogProbMetric: 399.7680

Epoch 260: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.9461 - MinusLogProbMetric: 388.9461 - val_loss: 399.7680 - val_MinusLogProbMetric: 399.7680 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 261/1000
2023-09-11 09:02:57.513 
Epoch 261/1000 
	 loss: 388.4461, MinusLogProbMetric: 388.4461, val_loss: 399.8676, val_MinusLogProbMetric: 399.8676

Epoch 261: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.4461 - MinusLogProbMetric: 388.4461 - val_loss: 399.8676 - val_MinusLogProbMetric: 399.8676 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 262/1000
2023-09-11 09:03:04.288 
Epoch 262/1000 
	 loss: 389.1451, MinusLogProbMetric: 389.1451, val_loss: 401.3981, val_MinusLogProbMetric: 401.3981

Epoch 262: val_loss did not improve from 399.47470
196/196 - 7s - loss: 389.1451 - MinusLogProbMetric: 389.1451 - val_loss: 401.3981 - val_MinusLogProbMetric: 401.3981 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 263/1000
2023-09-11 09:03:11.344 
Epoch 263/1000 
	 loss: 402.4860, MinusLogProbMetric: 402.4860, val_loss: 402.4421, val_MinusLogProbMetric: 402.4421

Epoch 263: val_loss did not improve from 399.47470
196/196 - 7s - loss: 402.4860 - MinusLogProbMetric: 402.4860 - val_loss: 402.4421 - val_MinusLogProbMetric: 402.4421 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 264/1000
2023-09-11 09:03:17.990 
Epoch 264/1000 
	 loss: 388.3154, MinusLogProbMetric: 388.3154, val_loss: 400.4887, val_MinusLogProbMetric: 400.4887

Epoch 264: val_loss did not improve from 399.47470
196/196 - 7s - loss: 388.3154 - MinusLogProbMetric: 388.3154 - val_loss: 400.4887 - val_MinusLogProbMetric: 400.4887 - lr: 1.6667e-04 - 7s/epoch - 34ms/step
Epoch 265/1000
2023-09-11 09:03:24.428 
Epoch 265/1000 
	 loss: 387.6624, MinusLogProbMetric: 387.6624, val_loss: 400.4595, val_MinusLogProbMetric: 400.4595

Epoch 265: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.6624 - MinusLogProbMetric: 387.6624 - val_loss: 400.4595 - val_MinusLogProbMetric: 400.4595 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 266/1000
2023-09-11 09:03:30.936 
Epoch 266/1000 
	 loss: 387.8613, MinusLogProbMetric: 387.8613, val_loss: 404.1605, val_MinusLogProbMetric: 404.1605

Epoch 266: val_loss did not improve from 399.47470
196/196 - 7s - loss: 387.8613 - MinusLogProbMetric: 387.8613 - val_loss: 404.1605 - val_MinusLogProbMetric: 404.1605 - lr: 1.6667e-04 - 7s/epoch - 33ms/step
Epoch 267/1000
2023-09-11 09:03:37.353 
Epoch 267/1000 
	 loss: 387.9006, MinusLogProbMetric: 387.9006, val_loss: 401.0029, val_MinusLogProbMetric: 401.0029

Epoch 267: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.9006 - MinusLogProbMetric: 387.9006 - val_loss: 401.0029 - val_MinusLogProbMetric: 401.0029 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 268/1000
2023-09-11 09:03:43.685 
Epoch 268/1000 
	 loss: 388.2483, MinusLogProbMetric: 388.2483, val_loss: 401.5166, val_MinusLogProbMetric: 401.5166

Epoch 268: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.2483 - MinusLogProbMetric: 388.2483 - val_loss: 401.5166 - val_MinusLogProbMetric: 401.5166 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 269/1000
2023-09-11 09:03:50.079 
Epoch 269/1000 
	 loss: 387.8270, MinusLogProbMetric: 387.8270, val_loss: 403.1830, val_MinusLogProbMetric: 403.1830

Epoch 269: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.8270 - MinusLogProbMetric: 387.8270 - val_loss: 403.1830 - val_MinusLogProbMetric: 403.1830 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 270/1000
2023-09-11 09:03:56.570 
Epoch 270/1000 
	 loss: 388.0584, MinusLogProbMetric: 388.0584, val_loss: 401.1325, val_MinusLogProbMetric: 401.1325

Epoch 270: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.0584 - MinusLogProbMetric: 388.0584 - val_loss: 401.1325 - val_MinusLogProbMetric: 401.1325 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 271/1000
2023-09-11 09:04:02.956 
Epoch 271/1000 
	 loss: 387.8548, MinusLogProbMetric: 387.8548, val_loss: 401.5576, val_MinusLogProbMetric: 401.5576

Epoch 271: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.8548 - MinusLogProbMetric: 387.8548 - val_loss: 401.5576 - val_MinusLogProbMetric: 401.5576 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 272/1000
2023-09-11 09:04:09.344 
Epoch 272/1000 
	 loss: 388.4467, MinusLogProbMetric: 388.4467, val_loss: 401.1008, val_MinusLogProbMetric: 401.1008

Epoch 272: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.4467 - MinusLogProbMetric: 388.4467 - val_loss: 401.1008 - val_MinusLogProbMetric: 401.1008 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 273/1000
2023-09-11 09:04:15.716 
Epoch 273/1000 
	 loss: 387.7545, MinusLogProbMetric: 387.7545, val_loss: 401.9497, val_MinusLogProbMetric: 401.9497

Epoch 273: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.7545 - MinusLogProbMetric: 387.7545 - val_loss: 401.9497 - val_MinusLogProbMetric: 401.9497 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 274/1000
2023-09-11 09:04:22.053 
Epoch 274/1000 
	 loss: 388.2660, MinusLogProbMetric: 388.2660, val_loss: 400.5193, val_MinusLogProbMetric: 400.5193

Epoch 274: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.2660 - MinusLogProbMetric: 388.2660 - val_loss: 400.5193 - val_MinusLogProbMetric: 400.5193 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 275/1000
2023-09-11 09:04:28.391 
Epoch 275/1000 
	 loss: 388.0333, MinusLogProbMetric: 388.0333, val_loss: 400.7422, val_MinusLogProbMetric: 400.7422

Epoch 275: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.0333 - MinusLogProbMetric: 388.0333 - val_loss: 400.7422 - val_MinusLogProbMetric: 400.7422 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 276/1000
2023-09-11 09:04:34.875 
Epoch 276/1000 
	 loss: 388.1888, MinusLogProbMetric: 388.1888, val_loss: 402.0566, val_MinusLogProbMetric: 402.0566

Epoch 276: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.1888 - MinusLogProbMetric: 388.1888 - val_loss: 402.0566 - val_MinusLogProbMetric: 402.0566 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 277/1000
2023-09-11 09:04:41.652 
Epoch 277/1000 
	 loss: 387.6855, MinusLogProbMetric: 387.6855, val_loss: 400.2975, val_MinusLogProbMetric: 400.2975

Epoch 277: val_loss did not improve from 399.47470
196/196 - 7s - loss: 387.6855 - MinusLogProbMetric: 387.6855 - val_loss: 400.2975 - val_MinusLogProbMetric: 400.2975 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 278/1000
2023-09-11 09:04:48.588 
Epoch 278/1000 
	 loss: 387.7916, MinusLogProbMetric: 387.7916, val_loss: 400.3685, val_MinusLogProbMetric: 400.3685

Epoch 278: val_loss did not improve from 399.47470
196/196 - 7s - loss: 387.7916 - MinusLogProbMetric: 387.7916 - val_loss: 400.3685 - val_MinusLogProbMetric: 400.3685 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 279/1000
2023-09-11 09:04:55.195 
Epoch 279/1000 
	 loss: 387.5219, MinusLogProbMetric: 387.5219, val_loss: 401.7038, val_MinusLogProbMetric: 401.7038

Epoch 279: val_loss did not improve from 399.47470
196/196 - 7s - loss: 387.5219 - MinusLogProbMetric: 387.5219 - val_loss: 401.7038 - val_MinusLogProbMetric: 401.7038 - lr: 1.6667e-04 - 7s/epoch - 34ms/step
Epoch 280/1000
2023-09-11 09:05:01.699 
Epoch 280/1000 
	 loss: 387.7730, MinusLogProbMetric: 387.7730, val_loss: 400.5611, val_MinusLogProbMetric: 400.5611

Epoch 280: val_loss did not improve from 399.47470
196/196 - 7s - loss: 387.7730 - MinusLogProbMetric: 387.7730 - val_loss: 400.5611 - val_MinusLogProbMetric: 400.5611 - lr: 1.6667e-04 - 7s/epoch - 33ms/step
Epoch 281/1000
2023-09-11 09:05:08.095 
Epoch 281/1000 
	 loss: 387.9345, MinusLogProbMetric: 387.9345, val_loss: 401.0809, val_MinusLogProbMetric: 401.0809

Epoch 281: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.9345 - MinusLogProbMetric: 387.9345 - val_loss: 401.0809 - val_MinusLogProbMetric: 401.0809 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 282/1000
2023-09-11 09:05:14.565 
Epoch 282/1000 
	 loss: 387.6715, MinusLogProbMetric: 387.6715, val_loss: 402.9351, val_MinusLogProbMetric: 402.9351

Epoch 282: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.6715 - MinusLogProbMetric: 387.6715 - val_loss: 402.9351 - val_MinusLogProbMetric: 402.9351 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 283/1000
2023-09-11 09:05:21.039 
Epoch 283/1000 
	 loss: 388.0476, MinusLogProbMetric: 388.0476, val_loss: 401.8419, val_MinusLogProbMetric: 401.8419

Epoch 283: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.0476 - MinusLogProbMetric: 388.0476 - val_loss: 401.8419 - val_MinusLogProbMetric: 401.8419 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 284/1000
2023-09-11 09:05:27.582 
Epoch 284/1000 
	 loss: 387.4168, MinusLogProbMetric: 387.4168, val_loss: 402.6364, val_MinusLogProbMetric: 402.6364

Epoch 284: val_loss did not improve from 399.47470
196/196 - 7s - loss: 387.4168 - MinusLogProbMetric: 387.4168 - val_loss: 402.6364 - val_MinusLogProbMetric: 402.6364 - lr: 1.6667e-04 - 7s/epoch - 33ms/step
Epoch 285/1000
2023-09-11 09:05:34.036 
Epoch 285/1000 
	 loss: 387.4731, MinusLogProbMetric: 387.4731, val_loss: 400.9201, val_MinusLogProbMetric: 400.9201

Epoch 285: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.4731 - MinusLogProbMetric: 387.4731 - val_loss: 400.9201 - val_MinusLogProbMetric: 400.9201 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 286/1000
2023-09-11 09:05:40.532 
Epoch 286/1000 
	 loss: 388.4426, MinusLogProbMetric: 388.4426, val_loss: 401.4806, val_MinusLogProbMetric: 401.4806

Epoch 286: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.4426 - MinusLogProbMetric: 388.4426 - val_loss: 401.4806 - val_MinusLogProbMetric: 401.4806 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 287/1000
2023-09-11 09:05:46.882 
Epoch 287/1000 
	 loss: 387.6965, MinusLogProbMetric: 387.6965, val_loss: 401.1776, val_MinusLogProbMetric: 401.1776

Epoch 287: val_loss did not improve from 399.47470
196/196 - 6s - loss: 387.6965 - MinusLogProbMetric: 387.6965 - val_loss: 401.1776 - val_MinusLogProbMetric: 401.1776 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 288/1000
2023-09-11 09:05:53.435 
Epoch 288/1000 
	 loss: 387.4687, MinusLogProbMetric: 387.4687, val_loss: 401.5137, val_MinusLogProbMetric: 401.5137

Epoch 288: val_loss did not improve from 399.47470
196/196 - 7s - loss: 387.4687 - MinusLogProbMetric: 387.4687 - val_loss: 401.5137 - val_MinusLogProbMetric: 401.5137 - lr: 1.6667e-04 - 7s/epoch - 33ms/step
Epoch 289/1000
2023-09-11 09:05:59.706 
Epoch 289/1000 
	 loss: 388.5942, MinusLogProbMetric: 388.5942, val_loss: 402.0866, val_MinusLogProbMetric: 402.0866

Epoch 289: val_loss did not improve from 399.47470
196/196 - 6s - loss: 388.5942 - MinusLogProbMetric: 388.5942 - val_loss: 402.0866 - val_MinusLogProbMetric: 402.0866 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 290/1000
2023-09-11 09:06:06.015 
Epoch 290/1000 
	 loss: 386.9261, MinusLogProbMetric: 386.9261, val_loss: 402.6933, val_MinusLogProbMetric: 402.6933

Epoch 290: val_loss did not improve from 399.47470
196/196 - 6s - loss: 386.9261 - MinusLogProbMetric: 386.9261 - val_loss: 402.6933 - val_MinusLogProbMetric: 402.6933 - lr: 1.6667e-04 - 6s/epoch - 32ms/step
Epoch 291/1000
2023-09-11 09:06:12.719 
Epoch 291/1000 
	 loss: 388.1314, MinusLogProbMetric: 388.1314, val_loss: 401.4728, val_MinusLogProbMetric: 401.4728

Epoch 291: val_loss did not improve from 399.47470
196/196 - 7s - loss: 388.1314 - MinusLogProbMetric: 388.1314 - val_loss: 401.4728 - val_MinusLogProbMetric: 401.4728 - lr: 1.6667e-04 - 7s/epoch - 34ms/step
Epoch 292/1000
2023-09-11 09:06:19.793 
Epoch 292/1000 
	 loss: 384.7230, MinusLogProbMetric: 384.7230, val_loss: 400.5297, val_MinusLogProbMetric: 400.5297

Epoch 292: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.7230 - MinusLogProbMetric: 384.7230 - val_loss: 400.5297 - val_MinusLogProbMetric: 400.5297 - lr: 8.3333e-05 - 7s/epoch - 36ms/step
Epoch 293/1000
2023-09-11 09:06:26.668 
Epoch 293/1000 
	 loss: 384.4762, MinusLogProbMetric: 384.4762, val_loss: 401.4927, val_MinusLogProbMetric: 401.4927

Epoch 293: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.4762 - MinusLogProbMetric: 384.4762 - val_loss: 401.4927 - val_MinusLogProbMetric: 401.4927 - lr: 8.3333e-05 - 7s/epoch - 35ms/step
Epoch 294/1000
2023-09-11 09:06:33.046 
Epoch 294/1000 
	 loss: 384.4134, MinusLogProbMetric: 384.4134, val_loss: 401.2213, val_MinusLogProbMetric: 401.2213

Epoch 294: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.4134 - MinusLogProbMetric: 384.4134 - val_loss: 401.2213 - val_MinusLogProbMetric: 401.2213 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 295/1000
2023-09-11 09:06:39.374 
Epoch 295/1000 
	 loss: 384.4681, MinusLogProbMetric: 384.4681, val_loss: 401.5624, val_MinusLogProbMetric: 401.5624

Epoch 295: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.4681 - MinusLogProbMetric: 384.4681 - val_loss: 401.5624 - val_MinusLogProbMetric: 401.5624 - lr: 8.3333e-05 - 6s/epoch - 32ms/step
Epoch 296/1000
2023-09-11 09:06:45.791 
Epoch 296/1000 
	 loss: 384.5112, MinusLogProbMetric: 384.5112, val_loss: 401.0116, val_MinusLogProbMetric: 401.0116

Epoch 296: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.5112 - MinusLogProbMetric: 384.5112 - val_loss: 401.0116 - val_MinusLogProbMetric: 401.0116 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 297/1000
2023-09-11 09:06:52.230 
Epoch 297/1000 
	 loss: 384.6382, MinusLogProbMetric: 384.6382, val_loss: 401.5419, val_MinusLogProbMetric: 401.5419

Epoch 297: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.6382 - MinusLogProbMetric: 384.6382 - val_loss: 401.5419 - val_MinusLogProbMetric: 401.5419 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 298/1000
2023-09-11 09:06:58.671 
Epoch 298/1000 
	 loss: 384.6778, MinusLogProbMetric: 384.6778, val_loss: 401.6344, val_MinusLogProbMetric: 401.6344

Epoch 298: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.6778 - MinusLogProbMetric: 384.6778 - val_loss: 401.6344 - val_MinusLogProbMetric: 401.6344 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 299/1000
2023-09-11 09:07:05.062 
Epoch 299/1000 
	 loss: 384.6194, MinusLogProbMetric: 384.6194, val_loss: 401.9202, val_MinusLogProbMetric: 401.9202

Epoch 299: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.6194 - MinusLogProbMetric: 384.6194 - val_loss: 401.9202 - val_MinusLogProbMetric: 401.9202 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 300/1000
2023-09-11 09:07:11.498 
Epoch 300/1000 
	 loss: 384.4964, MinusLogProbMetric: 384.4964, val_loss: 402.0298, val_MinusLogProbMetric: 402.0298

Epoch 300: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.4964 - MinusLogProbMetric: 384.4964 - val_loss: 402.0298 - val_MinusLogProbMetric: 402.0298 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 301/1000
2023-09-11 09:07:18.149 
Epoch 301/1000 
	 loss: 384.7990, MinusLogProbMetric: 384.7990, val_loss: 401.8400, val_MinusLogProbMetric: 401.8400

Epoch 301: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.7990 - MinusLogProbMetric: 384.7990 - val_loss: 401.8400 - val_MinusLogProbMetric: 401.8400 - lr: 8.3333e-05 - 7s/epoch - 34ms/step
Epoch 302/1000
2023-09-11 09:07:24.671 
Epoch 302/1000 
	 loss: 384.4714, MinusLogProbMetric: 384.4714, val_loss: 401.4824, val_MinusLogProbMetric: 401.4824

Epoch 302: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.4714 - MinusLogProbMetric: 384.4714 - val_loss: 401.4824 - val_MinusLogProbMetric: 401.4824 - lr: 8.3333e-05 - 7s/epoch - 33ms/step
Epoch 303/1000
2023-09-11 09:07:31.105 
Epoch 303/1000 
	 loss: 384.7453, MinusLogProbMetric: 384.7453, val_loss: 402.0789, val_MinusLogProbMetric: 402.0789

Epoch 303: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.7453 - MinusLogProbMetric: 384.7453 - val_loss: 402.0789 - val_MinusLogProbMetric: 402.0789 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 304/1000
2023-09-11 09:07:37.348 
Epoch 304/1000 
	 loss: 384.3583, MinusLogProbMetric: 384.3583, val_loss: 401.9589, val_MinusLogProbMetric: 401.9589

Epoch 304: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3583 - MinusLogProbMetric: 384.3583 - val_loss: 401.9589 - val_MinusLogProbMetric: 401.9589 - lr: 8.3333e-05 - 6s/epoch - 32ms/step
Epoch 305/1000
2023-09-11 09:07:43.882 
Epoch 305/1000 
	 loss: 384.5197, MinusLogProbMetric: 384.5197, val_loss: 403.7279, val_MinusLogProbMetric: 403.7279

Epoch 305: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.5197 - MinusLogProbMetric: 384.5197 - val_loss: 403.7279 - val_MinusLogProbMetric: 403.7279 - lr: 8.3333e-05 - 7s/epoch - 33ms/step
Epoch 306/1000
2023-09-11 09:07:50.801 
Epoch 306/1000 
	 loss: 384.6570, MinusLogProbMetric: 384.6570, val_loss: 403.0039, val_MinusLogProbMetric: 403.0039

Epoch 306: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.6570 - MinusLogProbMetric: 384.6570 - val_loss: 403.0039 - val_MinusLogProbMetric: 403.0039 - lr: 8.3333e-05 - 7s/epoch - 35ms/step
Epoch 307/1000
2023-09-11 09:07:57.809 
Epoch 307/1000 
	 loss: 384.6341, MinusLogProbMetric: 384.6341, val_loss: 402.3574, val_MinusLogProbMetric: 402.3574

Epoch 307: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.6341 - MinusLogProbMetric: 384.6341 - val_loss: 402.3574 - val_MinusLogProbMetric: 402.3574 - lr: 8.3333e-05 - 7s/epoch - 36ms/step
Epoch 308/1000
2023-09-11 09:08:04.089 
Epoch 308/1000 
	 loss: 384.6920, MinusLogProbMetric: 384.6920, val_loss: 402.1712, val_MinusLogProbMetric: 402.1712

Epoch 308: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.6920 - MinusLogProbMetric: 384.6920 - val_loss: 402.1712 - val_MinusLogProbMetric: 402.1712 - lr: 8.3333e-05 - 6s/epoch - 32ms/step
Epoch 309/1000
2023-09-11 09:08:10.638 
Epoch 309/1000 
	 loss: 384.5111, MinusLogProbMetric: 384.5111, val_loss: 404.3180, val_MinusLogProbMetric: 404.3180

Epoch 309: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.5111 - MinusLogProbMetric: 384.5111 - val_loss: 404.3180 - val_MinusLogProbMetric: 404.3180 - lr: 8.3333e-05 - 7s/epoch - 33ms/step
Epoch 310/1000
2023-09-11 09:08:16.977 
Epoch 310/1000 
	 loss: 384.3884, MinusLogProbMetric: 384.3884, val_loss: 403.7796, val_MinusLogProbMetric: 403.7796

Epoch 310: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3884 - MinusLogProbMetric: 384.3884 - val_loss: 403.7796 - val_MinusLogProbMetric: 403.7796 - lr: 8.3333e-05 - 6s/epoch - 32ms/step
Epoch 311/1000
2023-09-11 09:08:23.544 
Epoch 311/1000 
	 loss: 384.6358, MinusLogProbMetric: 384.6358, val_loss: 402.4820, val_MinusLogProbMetric: 402.4820

Epoch 311: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.6358 - MinusLogProbMetric: 384.6358 - val_loss: 402.4820 - val_MinusLogProbMetric: 402.4820 - lr: 8.3333e-05 - 7s/epoch - 34ms/step
Epoch 312/1000
2023-09-11 09:08:29.984 
Epoch 312/1000 
	 loss: 384.5242, MinusLogProbMetric: 384.5242, val_loss: 401.8686, val_MinusLogProbMetric: 401.8686

Epoch 312: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.5242 - MinusLogProbMetric: 384.5242 - val_loss: 401.8686 - val_MinusLogProbMetric: 401.8686 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 313/1000
2023-09-11 09:08:36.529 
Epoch 313/1000 
	 loss: 384.4682, MinusLogProbMetric: 384.4682, val_loss: 404.0870, val_MinusLogProbMetric: 404.0870

Epoch 313: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.4682 - MinusLogProbMetric: 384.4682 - val_loss: 404.0870 - val_MinusLogProbMetric: 404.0870 - lr: 8.3333e-05 - 7s/epoch - 33ms/step
Epoch 314/1000
2023-09-11 09:08:43.084 
Epoch 314/1000 
	 loss: 384.4182, MinusLogProbMetric: 384.4182, val_loss: 403.4977, val_MinusLogProbMetric: 403.4977

Epoch 314: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.4182 - MinusLogProbMetric: 384.4182 - val_loss: 403.4977 - val_MinusLogProbMetric: 403.4977 - lr: 8.3333e-05 - 7s/epoch - 33ms/step
Epoch 315/1000
2023-09-11 09:08:49.318 
Epoch 315/1000 
	 loss: 384.5939, MinusLogProbMetric: 384.5939, val_loss: 404.8273, val_MinusLogProbMetric: 404.8273

Epoch 315: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.5939 - MinusLogProbMetric: 384.5939 - val_loss: 404.8273 - val_MinusLogProbMetric: 404.8273 - lr: 8.3333e-05 - 6s/epoch - 32ms/step
Epoch 316/1000
2023-09-11 09:08:55.714 
Epoch 316/1000 
	 loss: 384.4852, MinusLogProbMetric: 384.4852, val_loss: 402.4130, val_MinusLogProbMetric: 402.4130

Epoch 316: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.4852 - MinusLogProbMetric: 384.4852 - val_loss: 402.4130 - val_MinusLogProbMetric: 402.4130 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 317/1000
2023-09-11 09:09:02.163 
Epoch 317/1000 
	 loss: 384.3716, MinusLogProbMetric: 384.3716, val_loss: 402.7375, val_MinusLogProbMetric: 402.7375

Epoch 317: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3716 - MinusLogProbMetric: 384.3716 - val_loss: 402.7375 - val_MinusLogProbMetric: 402.7375 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 318/1000
2023-09-11 09:09:08.539 
Epoch 318/1000 
	 loss: 384.5370, MinusLogProbMetric: 384.5370, val_loss: 404.5758, val_MinusLogProbMetric: 404.5758

Epoch 318: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.5370 - MinusLogProbMetric: 384.5370 - val_loss: 404.5758 - val_MinusLogProbMetric: 404.5758 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 319/1000
2023-09-11 09:09:14.928 
Epoch 319/1000 
	 loss: 384.4242, MinusLogProbMetric: 384.4242, val_loss: 403.7831, val_MinusLogProbMetric: 403.7831

Epoch 319: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.4242 - MinusLogProbMetric: 384.4242 - val_loss: 403.7831 - val_MinusLogProbMetric: 403.7831 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 320/1000
2023-09-11 09:09:21.794 
Epoch 320/1000 
	 loss: 384.4447, MinusLogProbMetric: 384.4447, val_loss: 403.6947, val_MinusLogProbMetric: 403.6947

Epoch 320: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.4447 - MinusLogProbMetric: 384.4447 - val_loss: 403.6947 - val_MinusLogProbMetric: 403.6947 - lr: 8.3333e-05 - 7s/epoch - 35ms/step
Epoch 321/1000
2023-09-11 09:09:28.709 
Epoch 321/1000 
	 loss: 384.4408, MinusLogProbMetric: 384.4408, val_loss: 404.3401, val_MinusLogProbMetric: 404.3401

Epoch 321: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.4408 - MinusLogProbMetric: 384.4408 - val_loss: 404.3401 - val_MinusLogProbMetric: 404.3401 - lr: 8.3333e-05 - 7s/epoch - 35ms/step
Epoch 322/1000
2023-09-11 09:09:35.242 
Epoch 322/1000 
	 loss: 384.3344, MinusLogProbMetric: 384.3344, val_loss: 406.1521, val_MinusLogProbMetric: 406.1521

Epoch 322: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.3344 - MinusLogProbMetric: 384.3344 - val_loss: 406.1521 - val_MinusLogProbMetric: 406.1521 - lr: 8.3333e-05 - 7s/epoch - 33ms/step
Epoch 323/1000
2023-09-11 09:09:41.667 
Epoch 323/1000 
	 loss: 384.4494, MinusLogProbMetric: 384.4494, val_loss: 403.7692, val_MinusLogProbMetric: 403.7692

Epoch 323: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.4494 - MinusLogProbMetric: 384.4494 - val_loss: 403.7692 - val_MinusLogProbMetric: 403.7692 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 324/1000
2023-09-11 09:09:48.021 
Epoch 324/1000 
	 loss: 384.4916, MinusLogProbMetric: 384.4916, val_loss: 405.3150, val_MinusLogProbMetric: 405.3150

Epoch 324: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.4916 - MinusLogProbMetric: 384.4916 - val_loss: 405.3150 - val_MinusLogProbMetric: 405.3150 - lr: 8.3333e-05 - 6s/epoch - 32ms/step
Epoch 325/1000
2023-09-11 09:09:54.448 
Epoch 325/1000 
	 loss: 384.2227, MinusLogProbMetric: 384.2227, val_loss: 403.8026, val_MinusLogProbMetric: 403.8026

Epoch 325: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.2227 - MinusLogProbMetric: 384.2227 - val_loss: 403.8026 - val_MinusLogProbMetric: 403.8026 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 326/1000
2023-09-11 09:10:00.923 
Epoch 326/1000 
	 loss: 384.3272, MinusLogProbMetric: 384.3272, val_loss: 403.0375, val_MinusLogProbMetric: 403.0375

Epoch 326: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3272 - MinusLogProbMetric: 384.3272 - val_loss: 403.0375 - val_MinusLogProbMetric: 403.0375 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 327/1000
2023-09-11 09:10:07.380 
Epoch 327/1000 
	 loss: 384.2890, MinusLogProbMetric: 384.2890, val_loss: 404.0964, val_MinusLogProbMetric: 404.0964

Epoch 327: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.2890 - MinusLogProbMetric: 384.2890 - val_loss: 404.0964 - val_MinusLogProbMetric: 404.0964 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 328/1000
2023-09-11 09:10:13.798 
Epoch 328/1000 
	 loss: 384.3960, MinusLogProbMetric: 384.3960, val_loss: 404.3084, val_MinusLogProbMetric: 404.3084

Epoch 328: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3960 - MinusLogProbMetric: 384.3960 - val_loss: 404.3084 - val_MinusLogProbMetric: 404.3084 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 329/1000
2023-09-11 09:10:20.285 
Epoch 329/1000 
	 loss: 384.3802, MinusLogProbMetric: 384.3802, val_loss: 403.8332, val_MinusLogProbMetric: 403.8332

Epoch 329: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3802 - MinusLogProbMetric: 384.3802 - val_loss: 403.8332 - val_MinusLogProbMetric: 403.8332 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 330/1000
2023-09-11 09:10:26.878 
Epoch 330/1000 
	 loss: 384.2298, MinusLogProbMetric: 384.2298, val_loss: 404.1560, val_MinusLogProbMetric: 404.1560

Epoch 330: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.2298 - MinusLogProbMetric: 384.2298 - val_loss: 404.1560 - val_MinusLogProbMetric: 404.1560 - lr: 8.3333e-05 - 7s/epoch - 34ms/step
Epoch 331/1000
2023-09-11 09:10:33.296 
Epoch 331/1000 
	 loss: 384.5858, MinusLogProbMetric: 384.5858, val_loss: 403.2666, val_MinusLogProbMetric: 403.2666

Epoch 331: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.5858 - MinusLogProbMetric: 384.5858 - val_loss: 403.2666 - val_MinusLogProbMetric: 403.2666 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 332/1000
2023-09-11 09:10:39.691 
Epoch 332/1000 
	 loss: 384.1405, MinusLogProbMetric: 384.1405, val_loss: 404.0034, val_MinusLogProbMetric: 404.0034

Epoch 332: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.1405 - MinusLogProbMetric: 384.1405 - val_loss: 404.0034 - val_MinusLogProbMetric: 404.0034 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 333/1000
2023-09-11 09:10:46.138 
Epoch 333/1000 
	 loss: 384.2226, MinusLogProbMetric: 384.2226, val_loss: 407.9579, val_MinusLogProbMetric: 407.9579

Epoch 333: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.2226 - MinusLogProbMetric: 384.2226 - val_loss: 407.9579 - val_MinusLogProbMetric: 407.9579 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 334/1000
2023-09-11 09:10:52.530 
Epoch 334/1000 
	 loss: 384.3843, MinusLogProbMetric: 384.3843, val_loss: 403.8206, val_MinusLogProbMetric: 403.8206

Epoch 334: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3843 - MinusLogProbMetric: 384.3843 - val_loss: 403.8206 - val_MinusLogProbMetric: 403.8206 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 335/1000
2023-09-11 09:10:59.265 
Epoch 335/1000 
	 loss: 384.3665, MinusLogProbMetric: 384.3665, val_loss: 405.1697, val_MinusLogProbMetric: 405.1697

Epoch 335: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.3665 - MinusLogProbMetric: 384.3665 - val_loss: 405.1697 - val_MinusLogProbMetric: 405.1697 - lr: 8.3333e-05 - 7s/epoch - 34ms/step
Epoch 336/1000
2023-09-11 09:11:06.375 
Epoch 336/1000 
	 loss: 384.3465, MinusLogProbMetric: 384.3465, val_loss: 404.4476, val_MinusLogProbMetric: 404.4476

Epoch 336: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.3465 - MinusLogProbMetric: 384.3465 - val_loss: 404.4476 - val_MinusLogProbMetric: 404.4476 - lr: 8.3333e-05 - 7s/epoch - 36ms/step
Epoch 337/1000
2023-09-11 09:11:13.053 
Epoch 337/1000 
	 loss: 384.2049, MinusLogProbMetric: 384.2049, val_loss: 404.3833, val_MinusLogProbMetric: 404.3833

Epoch 337: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.2049 - MinusLogProbMetric: 384.2049 - val_loss: 404.3833 - val_MinusLogProbMetric: 404.3833 - lr: 8.3333e-05 - 7s/epoch - 34ms/step
Epoch 338/1000
2023-09-11 09:11:19.406 
Epoch 338/1000 
	 loss: 384.3145, MinusLogProbMetric: 384.3145, val_loss: 405.5669, val_MinusLogProbMetric: 405.5669

Epoch 338: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.3145 - MinusLogProbMetric: 384.3145 - val_loss: 405.5669 - val_MinusLogProbMetric: 405.5669 - lr: 8.3333e-05 - 6s/epoch - 32ms/step
Epoch 339/1000
2023-09-11 09:11:26.019 
Epoch 339/1000 
	 loss: 384.0780, MinusLogProbMetric: 384.0780, val_loss: 406.3817, val_MinusLogProbMetric: 406.3817

Epoch 339: val_loss did not improve from 399.47470
196/196 - 7s - loss: 384.0780 - MinusLogProbMetric: 384.0780 - val_loss: 406.3817 - val_MinusLogProbMetric: 406.3817 - lr: 8.3333e-05 - 7s/epoch - 34ms/step
Epoch 340/1000
2023-09-11 09:11:32.418 
Epoch 340/1000 
	 loss: 384.2203, MinusLogProbMetric: 384.2203, val_loss: 405.5599, val_MinusLogProbMetric: 405.5599

Epoch 340: val_loss did not improve from 399.47470
196/196 - 6s - loss: 384.2203 - MinusLogProbMetric: 384.2203 - val_loss: 405.5599 - val_MinusLogProbMetric: 405.5599 - lr: 8.3333e-05 - 6s/epoch - 33ms/step
Epoch 341/1000
2023-09-11 09:11:38.928 
Epoch 341/1000 
	 loss: 384.2690, MinusLogProbMetric: 384.2690, val_loss: 404.6218, val_MinusLogProbMetric: 404.6218

Epoch 341: val_loss did not improve from 399.47470
Restoring model weights from the end of the best epoch: 241.
196/196 - 7s - loss: 384.2690 - MinusLogProbMetric: 384.2690 - val_loss: 404.6218 - val_MinusLogProbMetric: 404.6218 - lr: 8.3333e-05 - 7s/epoch - 34ms/step
Epoch 341: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 2437.97701581195 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting TopKV2
WARNING:tensorflow:Using a while_loop for converting TopKV2
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 17309.470323344925 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting TopKV2
WARNING:tensorflow:Using a while_loop for converting TopKV2
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
WARNING:tensorflow:Using a while_loop for converting StridedSlice
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
