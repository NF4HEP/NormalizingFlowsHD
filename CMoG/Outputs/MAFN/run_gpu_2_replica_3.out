2023-09-09 22:36:25.770668: Importing os...
2023-09-09 22:36:25.770708: Importing sys...
2023-09-09 22:36:25.770714: Importing and initializing argparse...
Visible devices: [2]
2023-09-09 22:36:25.778409: Importing timer from timeit...
2023-09-09 22:36:25.778700: Setting env variables for tf import (only device [2] will be available)...
2023-09-09 22:36:25.778722: Importing numpy...
2023-09-09 22:36:26.030869: Importing pandas...
2023-09-09 22:36:26.519865: Importing shutil...
2023-09-09 22:36:26.519893: Importing subprocess...
2023-09-09 22:36:26.519899: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-09 22:36:33.753245: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-09 22:36:34.797461: Importing textwrap...
2023-09-09 22:36:34.797587: Importing timeit...
2023-09-09 22:36:34.797609: Importing traceback...
2023-09-09 22:36:34.797618: Importing typing...
2023-09-09 22:36:34.797643: Setting tf configs...
2023-09-09 22:36:35.170793: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-09 22:36:38.082418: All modues imported successfully.
Directory ../../results/MAFN_new/ already exists.
Directory ../../results/MAFN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_5/ already exists.
Skipping it.
===========
Run 5/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_16/ already exists.
Skipping it.
===========
Run 16/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_20/ already exists.
Skipping it.
===========
Run 20/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_26/ already exists.
Skipping it.
===========
Run 26/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_36/ already exists.
Skipping it.
===========
Run 36/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_43/ already exists.
Skipping it.
===========
Run 43/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_54/ already exists.
Skipping it.
===========
Run 54/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_60/ already exists.
Skipping it.
===========
Run 60/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_67/ already exists.
Skipping it.
===========
Run 67/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_76/ already exists.
Skipping it.
===========
Run 76/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_82/ already exists.
Skipping it.
===========
Run 82/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_87/ already exists.
Skipping it.
===========
Run 87/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_96/ already exists.
Skipping it.
===========
Run 96/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_100/ already exists.
Skipping it.
===========
Run 100/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_107/ already exists.
Skipping it.
===========
Run 107/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_116/ already exists.
Skipping it.
===========
Run 116/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_122/ already exists.
Skipping it.
===========
Run 122/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_128/ already exists.
Skipping it.
===========
Run 128/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_137/ already exists.
Skipping it.
===========
Run 137/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_145/ already exists.
Skipping it.
===========
Run 145/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_154/ already exists.
Skipping it.
===========
Run 154/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_158/ already exists.
Skipping it.
===========
Run 158/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_163/ already exists.
Skipping it.
===========
Run 163/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_167/ already exists.
Skipping it.
===========
Run 167/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_174/ already exists.
Skipping it.
===========
Run 174/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_175/ already exists.
Skipping it.
===========
Run 175/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_176/ already exists.
Skipping it.
===========
Run 176/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_177/ already exists.
Skipping it.
===========
Run 177/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_178/ already exists.
Skipping it.
===========
Run 178/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_179/ already exists.
Skipping it.
===========
Run 179/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_180/ already exists.
Skipping it.
===========
Run 180/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_181/ already exists.
Skipping it.
===========
Run 181/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_182/ already exists.
Skipping it.
===========
Run 182/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_183/ already exists.
Skipping it.
===========
Run 183/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_184/ already exists.
Skipping it.
===========
Run 184/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_185/ already exists.
Skipping it.
===========
Run 185/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_186/ already exists.
Skipping it.
===========
Run 186/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_187/ already exists.
Skipping it.
===========
Run 187/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_188/ already exists.
Skipping it.
===========
Run 188/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_189/ already exists.
Skipping it.
===========
Run 189/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_190/ already exists.
Skipping it.
===========
Run 190/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_191/ already exists.
Skipping it.
===========
Run 191/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_192/ already exists.
Skipping it.
===========
Run 192/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_193/ already exists.
Skipping it.
===========
Run 193/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_194/ already exists.
Skipping it.
===========
Run 194/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_195/ already exists.
Skipping it.
===========
Run 195/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_196/ already exists.
Skipping it.
===========
Run 196/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_197/ already exists.
Skipping it.
===========
Run 197/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_198/ already exists.
Skipping it.
===========
Run 198/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_199/ already exists.
Skipping it.
===========
Run 199/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_200/ already exists.
Skipping it.
===========
Run 200/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_201/ already exists.
Skipping it.
===========
Run 201/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_202/ already exists.
Skipping it.
===========
Run 202/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_203/ already exists.
Skipping it.
===========
Run 203/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_204/ already exists.
Skipping it.
===========
Run 204/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_205/ already exists.
Skipping it.
===========
Run 205/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_206/ already exists.
Skipping it.
===========
Run 206/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_207/ already exists.
Skipping it.
===========
Run 207/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_208/ already exists.
Skipping it.
===========
Run 208/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_209/ already exists.
Skipping it.
===========
Run 209/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_210/ already exists.
Skipping it.
===========
Run 210/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_211/ already exists.
Skipping it.
===========
Run 211/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_212/ already exists.
Skipping it.
===========
Run 212/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_213/ already exists.
Skipping it.
===========
Run 213/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_214/ already exists.
Skipping it.
===========
Run 214/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_215/ already exists.
Skipping it.
===========
Run 215/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_216/ already exists.
Skipping it.
===========
Run 216/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_217/ already exists.
Skipping it.
===========
Run 217/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_218/ already exists.
Skipping it.
===========
Run 218/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_219/ already exists.
Skipping it.
===========
Run 219/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_220/ already exists.
Skipping it.
===========
Run 220/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_221/ already exists.
Skipping it.
===========
Run 221/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_222/ already exists.
Skipping it.
===========
Run 222/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_223/ already exists.
Skipping it.
===========
Run 223/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_224/ already exists.
Skipping it.
===========
Run 224/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_225/ already exists.
Skipping it.
===========
Run 225/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_226/ already exists.
Skipping it.
===========
Run 226/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_227/ already exists.
Skipping it.
===========
Run 227/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_228/ already exists.
Skipping it.
===========
Run 228/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_229/ already exists.
Skipping it.
===========
Run 229/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_230/ already exists.
Skipping it.
===========
Run 230/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_231/ already exists.
Skipping it.
===========
Run 231/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_232/ already exists.
Skipping it.
===========
Run 232/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_233/ already exists.
Skipping it.
===========
Run 233/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_234/ already exists.
Skipping it.
===========
Run 234/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_235/ already exists.
Skipping it.
===========
Run 235/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_236/ already exists.
Skipping it.
===========
Run 236/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_237/ already exists.
Skipping it.
===========
Run 237/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_238/ already exists.
Skipping it.
===========
Run 238/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_239/ already exists.
Skipping it.
===========
Run 239/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_240/ already exists.
Skipping it.
===========
Run 240/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_241/ already exists.
Skipping it.
===========
Run 241/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_242/ already exists.
Skipping it.
===========
Run 242/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_243/ already exists.
Skipping it.
===========
Run 243/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_244/ already exists.
Skipping it.
===========
Run 244/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_245/ already exists.
Skipping it.
===========
Run 245/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_246/ already exists.
Skipping it.
===========
Run 246/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_247/ already exists.
Skipping it.
===========
Run 247/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_248/ already exists.
Skipping it.
===========
Run 248/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_249/ already exists.
Skipping it.
===========
Run 249/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_250/ already exists.
Skipping it.
===========
Run 250/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_251/ already exists.
Skipping it.
===========
Run 251/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_252/ already exists.
Skipping it.
===========
Run 252/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_253/ already exists.
Skipping it.
===========
Run 253/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_254/ already exists.
Skipping it.
===========
Run 254/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_255/ already exists.
Skipping it.
===========
Run 255/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_256/ already exists.
Skipping it.
===========
Run 256/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_257/ already exists.
Skipping it.
===========
Run 257/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_258/ already exists.
Skipping it.
===========
Run 258/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_259/ already exists.
Skipping it.
===========
Run 259/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_260/ already exists.
Skipping it.
===========
Run 260/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_261/ already exists.
Skipping it.
===========
Run 261/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_262/ already exists.
Skipping it.
===========
Run 262/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_263/ already exists.
Skipping it.
===========
Run 263/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_264/ already exists.
Skipping it.
===========
Run 264/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_265/ already exists.
Skipping it.
===========
Run 265/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_266/ already exists.
Skipping it.
===========
Run 266/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_267/ already exists.
Skipping it.
===========
Run 267/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_268/ already exists.
Skipping it.
===========
Run 268/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_269/ already exists.
Skipping it.
===========
Run 269/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_270/ already exists.
Skipping it.
===========
Run 270/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_271/ already exists.
Skipping it.
===========
Run 271/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_272/ already exists.
Skipping it.
===========
Run 272/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_273/ already exists.
Skipping it.
===========
Run 273/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_274/ already exists.
Skipping it.
===========
Run 274/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_275/ already exists.
Skipping it.
===========
Run 275/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_276/ already exists.
Skipping it.
===========
Run 276/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_277/ already exists.
Skipping it.
===========
Run 277/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_278/ already exists.
Skipping it.
===========
Run 278/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_279/ already exists.
Skipping it.
===========
Run 279/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_280/ already exists.
Skipping it.
===========
Run 280/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_281/ already exists.
Skipping it.
===========
Run 281/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_282/ already exists.
Skipping it.
===========
Run 282/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_283/ already exists.
Skipping it.
===========
Run 283/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_284/ already exists.
Skipping it.
===========
Run 284/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_285/ already exists.
Skipping it.
===========
Run 285/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_286/ already exists.
Skipping it.
===========
Run 286/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_287/ already exists.
Skipping it.
===========
Run 287/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_288/ already exists.
Skipping it.
===========
Run 288/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_289/ already exists.
Skipping it.
===========
Run 289/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_290/ already exists.
Skipping it.
===========
Run 290/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_291/ already exists.
Skipping it.
===========
Run 291/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_292/ already exists.
Skipping it.
===========
Run 292/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_293/ already exists.
Skipping it.
===========
Run 293/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_294/ already exists.
Skipping it.
===========
Run 294/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_295/ already exists.
Skipping it.
===========
Run 295/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_296/ already exists.
Skipping it.
===========
Run 296/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_297/ already exists.
Skipping it.
===========
Run 297/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_298/ already exists.
Skipping it.
===========
Run 298/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_299/ already exists.
Skipping it.
===========
Run 299/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_300/ already exists.
Skipping it.
===========
Run 300/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_301/ already exists.
Skipping it.
===========
Run 301/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_302/ already exists.
Skipping it.
===========
Run 302/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_303/ already exists.
Skipping it.
===========
Run 303/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_304/ already exists.
Skipping it.
===========
Run 304/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_305/ already exists.
Skipping it.
===========
Run 305/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_306/ already exists.
Skipping it.
===========
Run 306/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_307/ already exists.
Skipping it.
===========
Run 307/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_308/ already exists.
Skipping it.
===========
Run 308/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_309/ already exists.
Skipping it.
===========
Run 309/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_310/ already exists.
Skipping it.
===========
Run 310/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_311/ already exists.
Skipping it.
===========
Run 311/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_312/ already exists.
Skipping it.
===========
Run 312/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_313/ already exists.
Skipping it.
===========
Run 313/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_314/ already exists.
Skipping it.
===========
Run 314/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_315/ already exists.
Skipping it.
===========
Run 315/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_316/ already exists.
Skipping it.
===========
Run 316/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_317/ already exists.
Skipping it.
===========
Run 317/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_318/ already exists.
Skipping it.
===========
Run 318/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_319/ already exists.
Skipping it.
===========
Run 319/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_320/ already exists.
Skipping it.
===========
Run 320/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_321/ already exists.
Skipping it.
===========
Run 321/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_322/ already exists.
Skipping it.
===========
Run 322/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_323/ already exists.
Skipping it.
===========
Run 323/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_324/ already exists.
Skipping it.
===========
Run 324/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_325/ already exists.
Skipping it.
===========
Run 325/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_326/ already exists.
Skipping it.
===========
Run 326/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_327/ already exists.
Skipping it.
===========
Run 327/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_328/ already exists.
Skipping it.
===========
Run 328/360 already exists. Skipping it.
===========

===========
Generating train data for run 329.
===========
Train data generated in 3.08 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_329/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_329/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_329/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_329
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.437488    7.1322474   6.533019   ...  9.559031    1.9697884
   6.253516  ]
 [ 6.105814   -0.33694893  4.861082   ...  4.728712    6.8399925
   2.9518385 ]
 [ 5.5099134   8.416618    3.6192868  ... 10.13037     0.5513004
   6.6116333 ]
 ...
 [ 8.378759    5.1539607   5.2823405  ...  4.1604185   7.9323363
   6.8563857 ]
 [ 8.088472    5.184855    5.311574   ...  3.8879027   7.132432
   7.66768   ]
 [ 5.6874776   6.932827    6.1243634  ...  9.540177    3.2688973
   7.1452303 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1000)]            0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  2095760   
 r)                                                              
                                                                 
=================================================================
Total params: 2,095,760
Trainable params: 2,095,760
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7efc404dcca0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7efc404dcd60>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7efc404dcd60>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7efd053dfe80>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7efc40336a10>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7efc4034aaa0>, <keras.callbacks.ModelCheckpoint object at 0x7efc40553d90>, <keras.callbacks.EarlyStopping object at 0x7efc4034af50>, <keras.callbacks.ReduceLROnPlateau object at 0x7efc40551ba0>, <keras.callbacks.TerminateOnNaN object at 0x7efc4034b0a0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_329/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 329/360 with hyperparameters:
timestamp = 2023-09-09 22:36:48.970810
ndims = 1000
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 2095760
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.43748808e+00  7.13224745e+00  6.53301907e+00  5.31066608e+00
  3.79545021e+00  6.28738737e+00  2.71391177e+00  8.88872051e+00
  9.43951797e+00  4.12179470e+00  7.81367683e+00  5.36657619e+00
  5.55121899e+00  9.56866932e+00  7.94146359e-01  9.63486314e-01
 -1.46448463e-02  7.97977352e+00  8.35143089e+00  9.09444618e+00
  9.51050758e+00  8.15759563e+00  4.87677431e+00  8.12364483e+00
 -5.86649776e-01  6.22392607e+00  1.30506945e+00  9.45408440e+00
  7.08888865e+00  3.35072994e+00  2.25734115e+00  8.41814995e+00
  4.58319330e+00  5.61194181e+00  2.26602942e-01  5.45686245e+00
  6.14353561e+00  6.25023174e+00  9.57346344e+00  6.36795044e+00
  3.20757818e+00  4.83043623e+00  7.51926565e+00  6.34396672e-01
  6.89045191e+00  6.62100124e+00  2.44563007e+00  1.28772116e+00
  3.22250342e+00  4.52788544e+00  5.89035130e+00  4.86346960e+00
  9.48264980e+00 -1.13163722e+00  3.37091446e+00  9.05362010e-01
  6.78129101e+00  1.94818664e+00  4.17912102e+00  3.18960547e+00
  1.62776482e+00  1.21974039e+00  7.33607817e+00  1.62089002e+00
  2.96397400e+00  4.52560091e+00  8.39162827e+00  1.51216686e+00
  8.25380135e+00  5.98394752e-01  9.67017937e+00  4.48699141e+00
  1.02882853e+01  5.70898390e+00  6.28753185e+00  6.97938085e-01
  2.82613039e+00  1.18152845e+00  2.21910620e+00  1.18442059e-01
  3.30913496e+00  4.37123442e+00 -6.00820422e-01  7.13190508e+00
  5.83363104e+00  2.43325353e+00  5.20436668e+00  1.77731943e+00
  6.29233789e+00  9.14511585e+00  2.47849083e+00  7.14207220e+00
  1.59640992e+00  7.87721014e+00  3.72595000e+00  1.65804911e+00
  6.26306725e+00  6.14266574e-01  9.35802937e+00 -5.55100851e-02
  6.81794071e+00  2.07937002e+00  7.28380156e+00  1.05093136e+01
  1.40520501e+00  5.19018650e+00  6.29479265e+00  5.23412371e+00
  2.19359255e+00  9.70839596e+00  4.63605547e+00  9.80713272e+00
  6.71604156e+00  2.83194685e+00  8.21691513e+00  3.91888070e+00
  8.82857418e+00  5.65095377e+00  7.74853373e+00  6.66070604e+00
  8.72240067e+00  4.82063627e+00  9.65159893e+00  7.37593651e+00
  5.52394199e+00  6.06229258e+00  6.28078938e-01  3.63155842e+00
  6.63515043e+00  3.13720345e+00  6.10160494e+00  4.59917688e+00
  1.67009079e+00  2.67929316e+00  5.87469530e+00  5.35120296e+00
  5.20565653e+00  6.30662727e+00  7.39564276e+00  4.35430813e+00
  8.88551044e+00  2.87358689e+00  4.32844305e+00  9.07120323e+00
  8.34959602e+00  6.54305315e+00  6.36145771e-01  9.69855213e+00
  6.49582243e+00  1.02082977e+01  1.42218649e+00  7.77432966e+00
  1.58041847e+00  6.40702820e+00  1.07924449e+00  8.47589207e+00
  8.23396206e+00  5.41745853e+00  3.85215545e+00  7.45270491e-01
  6.41533756e+00  4.21811962e+00  7.45381451e+00  8.68435764e+00
  9.59165764e+00  9.22718906e+00 -1.01518297e+00  4.78479671e+00
  7.09206533e+00  2.16092372e+00  5.71304035e+00  1.19908273e-01
  3.16043782e+00  9.20669734e-02  8.17029667e+00  2.31537890e+00
  3.80825901e+00  9.06393814e+00  7.17630625e+00  1.20758474e-01
  1.57467747e+00  6.56413174e+00  5.80603886e+00  1.90417314e+00
  9.26850033e+00  5.71055651e+00  5.48348093e+00  5.70006657e+00
  7.34501457e+00  3.06974077e+00  4.17449951e+00  1.88637686e+00
  1.59649813e+00  8.74714470e+00  7.68149471e+00  5.14725018e+00
  1.94792962e+00  2.93671155e+00  6.94045722e-01  4.93041849e+00
  2.29451370e+00  6.96200371e+00  2.94133329e+00  7.65987992e-01
 -2.16490626e-02  6.85447574e-01  6.85941124e+00  4.85409117e+00
  5.72059441e+00  8.98723507e+00  9.62737179e+00  2.21571255e+00
  6.79449415e+00  2.29369974e+00  5.30113637e-01  7.87245512e+00
  3.63518763e+00  4.00529575e+00  5.20808411e+00  8.23005772e+00
  6.37014103e+00  8.26017952e+00  3.29657626e+00  7.93651295e+00
  1.78429985e+00  9.56696796e+00  7.06810617e+00  2.25382471e+00
  9.54646778e+00  7.23986912e+00  2.52804947e+00  2.58364177e+00
  5.52888250e+00  1.77395463e-01  2.06791592e+00  4.35356903e+00
  3.59637356e+00  3.74388838e+00  2.40446615e+00  5.81385517e+00
  8.67110729e+00  1.17576969e+00  4.94048452e+00  9.40345764e-01
  6.09276962e+00  3.86963511e+00  6.18902493e+00  1.56115341e+00
  2.90525699e+00  4.87162495e+00  3.71526504e+00  9.40074253e+00
  7.42161226e+00  7.27192879e+00  1.00699673e+01  1.18854022e+00
  5.78801632e+00  5.48251772e+00  9.94960403e+00  2.90021896e+00
  4.43213892e+00  4.77912188e-01  3.98015082e-01  1.12766476e+01
  6.74848080e+00  7.22801781e+00  2.82795882e+00  5.88993359e+00
  6.98136806e-01  3.23450828e+00  9.72003841e+00  8.30174351e+00
  3.07273555e+00  9.91379070e+00  1.91660452e+00  9.71661282e+00
  9.90089893e+00  8.15846062e+00  7.03740978e+00  9.58544540e+00
  2.93002963e+00  8.31967926e+00  5.99808025e+00  7.28550479e-02
  3.85735941e+00  9.70761538e-01  9.23753738e+00  5.46686459e+00
  5.50278473e+00  6.01728964e+00  4.34324074e+00  1.36993062e+00
  8.45484543e+00  4.68175888e-01  5.26911163e+00  1.84141123e+00
  3.81864011e-01  7.90763950e+00  9.70255852e+00  9.84720516e+00
  9.43443680e+00  7.68962574e+00  3.80397248e+00  6.65612042e-01
  5.16863966e+00  2.47927332e+00  4.73985672e-01  1.05347097e+00
  7.32991314e+00  9.36276674e-01  7.35460091e+00  1.67862105e+00
  4.33905751e-01  1.59291720e+00  7.84084034e+00  2.43011403e+00
  4.25165033e+00  5.68983269e+00  8.60872746e+00  7.16398525e+00
  2.72054410e+00  1.94252491e+00 -1.85395658e-01  3.34451747e+00
  1.99218881e+00  3.79499388e+00  5.96836662e+00  7.37168837e+00
  2.49210262e+00  3.98509121e+00  9.37832177e-01  8.80943108e+00
  2.57825583e-01  6.98963022e+00  7.78174019e+00  7.89891291e+00
  2.61566496e+00  3.04674053e+00  6.46863794e+00  2.90103054e+00
  4.06367350e+00  2.83596921e+00  5.16630077e+00  6.22896612e-01
  7.82478142e+00  3.80227089e-01  3.55100584e+00  3.55920887e+00
  5.84608507e+00  9.32784271e+00  6.44432068e+00  6.71383977e-01
  3.80863142e+00  5.12159157e+00  5.26213694e+00  6.50915527e+00
  3.31823993e+00  1.51588440e+00  3.74508786e+00  9.63789845e+00
  2.82012701e+00  9.30117702e+00  5.18297386e+00  5.08122492e+00
  9.10340309e+00  4.14017344e+00  8.16922951e+00  3.49889684e+00
  9.15036392e+00  7.04796791e+00  6.91863298e+00  3.43821239e+00
  7.49771976e+00  6.58094883e+00  1.52206314e+00  1.66219306e+00
  8.96467304e+00  9.71891689e+00  6.03888035e+00  6.12453365e+00
  8.36337280e+00  4.72068548e+00  7.40723658e+00  4.66089344e+00
  9.60812855e+00  1.02327881e+01  8.27917576e+00  1.76802504e+00
  5.86829615e+00  4.09585905e+00 -5.26962698e-01  4.35076141e+00
  2.46013212e+00  8.68481445e+00  3.86820614e-01  9.69470692e+00
  3.67586684e+00  3.92413521e+00 -9.84535664e-02  2.63078451e+00
  4.00670385e+00  1.10941935e+01  5.17772198e-01  9.30033970e+00
  9.24112511e+00  2.92216539e+00  3.37561965e+00  2.46589732e+00
  6.14229774e+00  4.67309088e-01 -8.67828280e-02  4.08560181e+00
  3.99175465e-01  2.54151607e+00  2.21575212e+00  2.50912642e+00
  1.27955842e+00 -7.25474238e-01  8.21681261e-01  6.53614998e+00
  1.04211264e+01  9.34315395e+00  3.89995766e+00  3.41503716e+00
  6.30898190e+00  4.78263617e+00  1.00384960e+01  1.44826126e+00
  8.01760387e+00  3.30487871e+00  2.22230029e+00  6.98749399e+00
  2.56673408e+00  6.51266956e+00  5.16357517e+00  4.21222687e+00
  5.53316402e+00  2.87564898e+00  6.88569880e+00  5.24295902e+00
  3.83784485e+00  8.63262177e+00  9.42399979e+00  4.50341552e-01
  2.33270240e+00  2.46700525e+00  8.57210445e+00  9.93498421e+00
  9.70180130e+00  9.04918671e+00  2.82848668e+00  1.01604681e+01
  2.13376069e+00  1.08001816e+00  1.01585007e+01  2.37143421e+00
  6.89639854e+00  6.13785625e-01  6.39277411e+00  8.98899841e+00
  3.29311657e+00  3.45347357e+00  3.81167507e+00  7.88749123e+00
  1.59779358e+00  5.66715002e-01  4.65487051e+00  4.15191126e+00
  8.22690773e+00  2.27221990e+00  5.74325514e+00  9.80365372e+00
  6.51945877e+00  8.45271111e+00  9.52017021e+00  7.24792719e+00
  6.43911409e+00  8.51561165e+00  1.02915831e+01  4.50498724e+00
  9.14542615e-01  2.86150455e+00  2.13800192e-01  3.66317129e+00
  1.32120097e+00  6.51088238e+00  3.09616232e+00  9.20569038e+00
  9.73210716e+00  5.21707201e+00  3.67960548e+00  5.34920645e+00
  8.44879818e+00  4.15654373e+00  5.51069403e+00  2.64717555e+00
  4.56229973e+00  4.03184319e+00  2.53720236e+00  4.99534702e+00
  2.31029892e+00  3.48865128e+00  8.25072670e+00  7.54355812e+00
  2.20225477e+00  1.13970642e+01  8.49588680e+00  7.10883319e-01
  2.74363828e+00  4.99293470e+00  1.34385705e-01  3.21501279e+00
  8.21650314e+00  6.79964018e+00  6.27488852e+00  7.14794111e+00
  1.90239477e+00  3.45294881e+00  7.35099411e+00  9.33995914e+00
  6.05294037e+00  2.90113711e+00 -1.24432337e+00  6.42705727e+00
  5.68964370e-02  3.37960458e+00  4.96043348e+00  9.90640545e+00
  1.23383534e+00  4.00741386e+00  6.40055537e-03  3.24708557e+00
  6.32790136e+00  2.19222999e+00  2.08447242e+00  1.32372677e+00
  5.92049932e+00  6.88256168e+00  7.01928997e+00  1.04399967e+01
 -2.88216442e-01  6.52927542e+00  6.16809750e+00  6.00324678e+00
  9.71869183e+00  1.13557257e-01  7.11323690e+00  7.71879911e+00
  5.03887224e+00  3.76561260e+00  8.05337811e+00  3.14987302e-01
  5.12668896e+00  5.27989054e+00  6.75082159e+00  1.43525863e+00
  2.57989788e+00  4.62727022e+00  6.04563522e+00  9.48542213e+00
  7.09511852e+00  1.17622685e+00  9.15441227e+00  9.80256653e+00
  5.09900427e+00  9.44795132e+00  5.51893759e+00  1.03330717e+01
  8.30469704e+00  1.07898369e+01  1.01827803e+01 -5.05745411e-04
  1.73885703e+00  3.52059174e+00  9.45347977e+00  3.41492081e+00
  1.14690316e+00  9.65928459e+00  4.69807243e+00  9.03562832e+00
  1.17234612e+00  6.69798565e+00  4.43081808e+00  8.74517798e-01
  6.92903471e+00  2.09807229e+00 -7.14968681e-01  5.73539436e-01
  6.28464758e-01  8.92654991e+00  8.03050327e+00  9.02817154e+00
  7.40084696e+00  5.17232370e+00  3.25738239e+00  1.01524630e+01
  3.55576420e+00  3.88637328e+00  4.20779133e+00  8.97262955e+00
  1.70729637e+00  3.30006480e+00  5.26616716e+00  9.60324168e-01
  6.40397358e+00  4.05875492e+00  2.62214065e+00  2.05707121e+00
  4.09347248e+00  3.94071198e+00  5.06777287e+00  3.40968561e+00
  8.99762726e+00  1.47003901e+00  8.83282781e-01  3.52675414e+00
  5.27389050e+00  6.61437607e+00  5.19436264e+00  9.38774395e+00
  3.59817815e+00  7.51900101e+00  6.17228937e+00  8.14072514e+00
  1.00964031e+01  8.67543316e+00  7.67522526e+00  6.90801048e+00
  3.51598859e+00  5.34878731e-01  6.36672795e-01  2.41127205e+00
  3.82626390e+00  5.18385172e+00  5.83661032e+00  9.15472126e+00
  8.23223293e-01  2.42483902e+00  5.41429329e+00  8.00633621e+00
  7.98597336e+00  9.41291142e+00  9.83840275e+00  4.71966314e+00
  4.63481140e+00  4.06945586e-01  6.68186712e+00  6.24139881e+00
  8.50881863e+00  7.10938215e-01  4.35715389e+00  5.98537350e+00
  2.39591932e+00  1.52024806e+00  9.15522194e+00  1.84586793e-01
  3.84848523e+00  1.13246572e+00  4.45568275e+00  9.84170437e+00
  4.21756744e+00  6.01763248e+00  7.27610350e-01  3.31445408e+00
  4.36259508e+00  4.26714516e+00  6.67291355e+00  3.47573233e+00
  6.96841526e+00  6.61320925e+00  4.78718519e+00  3.85241342e+00
  5.65875959e+00  9.63071108e-01  8.21956635e+00  7.05007601e+00
  7.35808372e+00  5.60682201e+00  8.74726832e-01  4.78749466e+00
  4.08274555e+00  3.05295515e+00 -2.82806456e-02  7.37880754e+00
  1.13245630e+00  6.21132517e+00  7.19738770e+00  6.62598848e+00
  8.44676971e+00  7.01955557e-01  8.75954437e+00  1.91597685e-01
  6.34029531e+00  4.09656525e+00  4.70814228e+00  3.66343403e+00
  1.92009354e+00 -2.97656119e-01  4.93795109e+00  7.03719902e+00
  3.54990387e+00  2.22650814e+00  1.47342825e+00  1.87733543e+00
  9.82225418e-01  1.97523093e+00  2.90856576e+00 -1.95377409e-01
  7.63740540e-01  8.23801708e+00  1.92524207e+00  4.57951069e+00
  8.07519722e+00  4.80337429e+00  1.63165092e+00  2.09296656e+00
  4.45628262e+00  5.24322176e+00  3.30323172e+00  7.77983236e+00
  7.60303879e+00  8.98269558e+00  3.17642242e-01  9.00031185e+00
  3.89518857e+00  8.87557316e+00  6.54464340e+00  9.40222740e+00
  7.76669884e+00  3.63010335e+00  4.89937687e+00  3.79815769e+00
  3.43109441e+00  2.11776972e+00  4.50608540e+00  6.73585749e+00
  2.77784801e+00  4.75118494e+00  1.41163933e+00  1.43678403e+00
  4.72844005e-01  1.01116915e+01  4.33705822e-02  1.87914848e+00
  6.03755856e+00  1.65911603e+00  9.08522511e+00  7.11956310e+00
  8.27528858e+00  4.67179298e+00  1.46821272e+00  5.57443333e+00
  9.03736591e+00  7.08154297e+00  2.92699647e+00  9.28951740e+00
  3.66812515e+00  1.79973990e-02  2.40762663e+00  1.92846382e+00
  8.69157314e+00  4.33280611e+00  4.23879671e+00  3.11560988e+00
  9.60638237e+00  1.10599823e+01  9.74016571e+00  3.66849303e+00
  9.42271328e+00  8.38017178e+00  6.39697123e+00  3.64649916e+00
  1.97412837e+00  2.19269991e+00  9.55885601e+00  2.80885458e+00
  4.91888142e+00  5.15744495e+00  8.31021786e+00  8.34845829e+00
  1.55545843e+00  3.92147779e+00  8.22108078e+00  7.88888502e+00
  1.22066307e+00  1.52498245e+00  3.15602779e+00  9.93907928e-01
  4.50527048e+00  1.36449265e+00  5.00522995e+00  2.42850351e+00
  5.87198400e+00 -1.04476917e+00  9.73143959e+00  9.51038170e+00
  4.31158495e+00  3.61805153e+00  1.88797522e+00  5.04972935e+00
  4.03085709e-01  4.60245562e+00  3.75540328e+00  4.01810455e+00
  8.59900475e+00  7.06478453e+00  9.62819099e+00  3.01856041e+00
  9.00697613e+00  8.57353497e+00  4.79125214e+00  6.26140499e+00
  2.85231853e+00  1.06102486e+01  1.06103802e+00  2.18488646e+00
  3.15353966e+00  4.29014683e+00  7.35634613e+00  5.12752581e+00
  4.86164331e+00  6.53155148e-01  5.14040470e+00  5.27053058e-01
  1.85232019e+00  9.85549164e+00  2.36561966e+00  8.83290672e+00
  8.07797718e+00  2.24759030e+00  5.88459301e+00  1.65719461e+00
  7.13856363e+00  6.36659193e+00  8.30550766e+00  4.64638376e+00
  8.86743259e+00 -1.78816348e-01  2.12690020e+00  7.22018147e+00
  4.37131548e+00  1.50182629e+00  1.44224501e+00  8.23597240e+00
  2.87912059e+00  8.82868195e+00  6.72185993e+00  4.10417318e+00
  3.72402120e+00  4.76707935e+00  8.69713497e+00  8.02846813e+00
 -5.91852479e-02  6.92536926e+00  9.99452686e+00  7.10508966e+00
  1.77003264e+00  5.62554789e+00  1.03404069e+00  4.70238781e+00
  9.31285954e+00  8.93695068e+00  2.82111669e+00  3.46559119e+00
  6.18987942e+00  9.39866257e+00  5.47782779e-01  2.72644186e+00
  8.94318962e+00  4.69057751e+00  1.03748589e+01  2.52786398e+00
  5.76243114e+00  3.48165631e+00  3.81163502e+00  3.76940107e+00
  4.03297091e+00  4.00298834e+00  8.04087162e+00  7.70173693e+00
  7.10223532e+00  3.21729660e+00  5.74228382e+00  6.87862539e+00
  7.01803017e+00  3.45543861e+00  7.26741600e+00  7.03988886e+00
  1.35023844e+00  8.91982746e+00  4.43680811e+00  5.25290489e+00
  3.51280975e+00  6.24143553e+00  6.52131414e+00  4.72280169e+00
  8.25355721e+00  6.25390244e+00  5.13515329e+00  4.87421942e+00
  7.67947769e+00  3.34088635e+00  2.31048179e+00  4.33013082e-01
  8.68751335e+00  9.47573662e+00  1.55903900e+00  3.07618022e+00
  1.50216174e+00  1.19446433e+00  9.29029846e+00  1.65662837e+00
  9.56382942e+00  9.47769403e-01  8.08623123e+00  5.85028315e+00
  4.43489981e+00  3.51404214e+00  7.59146261e+00  3.24519110e+00
  6.24453449e+00  3.84153080e+00  4.75549126e+00  8.96583271e+00
  5.54600143e+00  7.46122551e+00  6.96567345e+00  4.11713839e-01
  7.67649698e+00  2.08050108e+00  9.21236324e+00  1.41680741e+00
  3.03086996e+00  1.13182259e+00  4.03754902e+00  8.78156567e+00
  2.95456624e+00  1.61442590e+00  3.30749226e+00  8.14694023e+00
  1.37203860e+00  1.63373399e+00  6.45686090e-01  7.07791662e+00
  3.06980824e+00  4.66480160e+00  7.18863678e+00  3.41025472e+00
  7.26521921e+00  7.07599974e+00  2.82888842e+00  1.03278141e+01
  1.74131536e+00  2.78822184e+00  1.28855526e+00  3.68360829e+00
  5.39412928e+00  5.52329063e+00  8.01896572e+00  8.91389751e+00
  2.46595716e+00  6.16491985e+00  1.14002132e+00  3.73238707e+00
  3.28532362e+00  2.97972035e+00  4.97999954e+00  7.17574263e+00
  7.50538170e-01  1.02770720e+01  7.28148460e+00  2.06288123e+00
  9.35947418e+00  5.11205769e+00  9.92250729e+00  1.66801298e+00
  3.66859484e+00  3.06588221e+00  3.05286908e+00  5.87349463e+00
  9.89076328e+00  8.08929062e+00  6.18565559e+00  5.57329512e+00
  9.22900391e+00  3.96593451e+00  8.75203419e+00  8.35547829e+00
  2.17680025e+00  7.65000153e+00  1.08980224e-01  3.05595231e+00
  2.58785725e+00  5.23494005e+00  7.61446953e+00  4.45858717e-01
  4.63132048e+00  9.55903053e+00  1.96978843e+00  6.25351620e+00]
Epoch 1/1000
2023-09-09 22:37:41.709 
Epoch 1/1000 
	 loss: 1965.2573, MinusLogProbMetric: 1965.2573, val_loss: 658.4099, val_MinusLogProbMetric: 658.4099

Epoch 1: val_loss improved from inf to 658.40985, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 53s - loss: 1965.2573 - MinusLogProbMetric: 1965.2573 - val_loss: 658.4099 - val_MinusLogProbMetric: 658.4099 - lr: 0.0010 - 53s/epoch - 269ms/step
Epoch 2/1000
2023-09-09 22:37:51.423 
Epoch 2/1000 
	 loss: 593.9665, MinusLogProbMetric: 593.9665, val_loss: 557.2801, val_MinusLogProbMetric: 557.2801

Epoch 2: val_loss improved from 658.40985 to 557.28009, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 593.9665 - MinusLogProbMetric: 593.9665 - val_loss: 557.2801 - val_MinusLogProbMetric: 557.2801 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 3/1000
2023-09-09 22:38:01.729 
Epoch 3/1000 
	 loss: 542.8422, MinusLogProbMetric: 542.8422, val_loss: 515.8719, val_MinusLogProbMetric: 515.8719

Epoch 3: val_loss improved from 557.28009 to 515.87189, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 542.8422 - MinusLogProbMetric: 542.8422 - val_loss: 515.8719 - val_MinusLogProbMetric: 515.8719 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 4/1000
2023-09-09 22:38:11.129 
Epoch 4/1000 
	 loss: 556.4933, MinusLogProbMetric: 556.4933, val_loss: 502.3012, val_MinusLogProbMetric: 502.3012

Epoch 4: val_loss improved from 515.87189 to 502.30121, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 556.4933 - MinusLogProbMetric: 556.4933 - val_loss: 502.3012 - val_MinusLogProbMetric: 502.3012 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 5/1000
2023-09-09 22:38:21.193 
Epoch 5/1000 
	 loss: 492.1553, MinusLogProbMetric: 492.1553, val_loss: 494.3298, val_MinusLogProbMetric: 494.3298

Epoch 5: val_loss improved from 502.30121 to 494.32977, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 492.1553 - MinusLogProbMetric: 492.1553 - val_loss: 494.3298 - val_MinusLogProbMetric: 494.3298 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 6/1000
2023-09-09 22:38:31.610 
Epoch 6/1000 
	 loss: 485.9838, MinusLogProbMetric: 485.9838, val_loss: 481.3402, val_MinusLogProbMetric: 481.3402

Epoch 6: val_loss improved from 494.32977 to 481.34018, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 485.9838 - MinusLogProbMetric: 485.9838 - val_loss: 481.3402 - val_MinusLogProbMetric: 481.3402 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 7/1000
2023-09-09 22:38:41.102 
Epoch 7/1000 
	 loss: 484.0590, MinusLogProbMetric: 484.0590, val_loss: 509.6372, val_MinusLogProbMetric: 509.6372

Epoch 7: val_loss did not improve from 481.34018
196/196 - 9s - loss: 484.0590 - MinusLogProbMetric: 484.0590 - val_loss: 509.6372 - val_MinusLogProbMetric: 509.6372 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 8/1000
2023-09-09 22:38:51.235 
Epoch 8/1000 
	 loss: 472.5349, MinusLogProbMetric: 472.5349, val_loss: 467.4760, val_MinusLogProbMetric: 467.4760

Epoch 8: val_loss improved from 481.34018 to 467.47604, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 472.5349 - MinusLogProbMetric: 472.5349 - val_loss: 467.4760 - val_MinusLogProbMetric: 467.4760 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 9/1000
2023-09-09 22:39:00.762 
Epoch 9/1000 
	 loss: 466.6146, MinusLogProbMetric: 466.6146, val_loss: 466.4603, val_MinusLogProbMetric: 466.4603

Epoch 9: val_loss improved from 467.47604 to 466.46027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 466.6146 - MinusLogProbMetric: 466.6146 - val_loss: 466.4603 - val_MinusLogProbMetric: 466.4603 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 10/1000
2023-09-09 22:39:10.599 
Epoch 10/1000 
	 loss: 459.9885, MinusLogProbMetric: 459.9885, val_loss: 448.8891, val_MinusLogProbMetric: 448.8891

Epoch 10: val_loss improved from 466.46027 to 448.88913, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 459.9885 - MinusLogProbMetric: 459.9885 - val_loss: 448.8891 - val_MinusLogProbMetric: 448.8891 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 11/1000
2023-09-09 22:39:19.572 
Epoch 11/1000 
	 loss: 456.4272, MinusLogProbMetric: 456.4272, val_loss: 474.1402, val_MinusLogProbMetric: 474.1402

Epoch 11: val_loss did not improve from 448.88913
196/196 - 9s - loss: 456.4272 - MinusLogProbMetric: 456.4272 - val_loss: 474.1402 - val_MinusLogProbMetric: 474.1402 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 12/1000
2023-09-09 22:39:29.435 
Epoch 12/1000 
	 loss: 455.4118, MinusLogProbMetric: 455.4118, val_loss: 443.6709, val_MinusLogProbMetric: 443.6709

Epoch 12: val_loss improved from 448.88913 to 443.67087, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 455.4118 - MinusLogProbMetric: 455.4118 - val_loss: 443.6709 - val_MinusLogProbMetric: 443.6709 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 13/1000
2023-09-09 22:39:39.628 
Epoch 13/1000 
	 loss: 446.7195, MinusLogProbMetric: 446.7195, val_loss: 440.0946, val_MinusLogProbMetric: 440.0946

Epoch 13: val_loss improved from 443.67087 to 440.09464, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 446.7195 - MinusLogProbMetric: 446.7195 - val_loss: 440.0946 - val_MinusLogProbMetric: 440.0946 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 14/1000
2023-09-09 22:39:48.481 
Epoch 14/1000 
	 loss: 444.7234, MinusLogProbMetric: 444.7234, val_loss: 438.2526, val_MinusLogProbMetric: 438.2526

Epoch 14: val_loss improved from 440.09464 to 438.25256, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 444.7234 - MinusLogProbMetric: 444.7234 - val_loss: 438.2526 - val_MinusLogProbMetric: 438.2526 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 15/1000
2023-09-09 22:39:58.671 
Epoch 15/1000 
	 loss: 444.8135, MinusLogProbMetric: 444.8135, val_loss: 441.4967, val_MinusLogProbMetric: 441.4967

Epoch 15: val_loss did not improve from 438.25256
196/196 - 10s - loss: 444.8135 - MinusLogProbMetric: 444.8135 - val_loss: 441.4967 - val_MinusLogProbMetric: 441.4967 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 16/1000
2023-09-09 22:40:07.296 
Epoch 16/1000 
	 loss: 448.0123, MinusLogProbMetric: 448.0123, val_loss: 439.7536, val_MinusLogProbMetric: 439.7536

Epoch 16: val_loss did not improve from 438.25256
196/196 - 9s - loss: 448.0123 - MinusLogProbMetric: 448.0123 - val_loss: 439.7536 - val_MinusLogProbMetric: 439.7536 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 17/1000
2023-09-09 22:40:17.346 
Epoch 17/1000 
	 loss: 439.6001, MinusLogProbMetric: 439.6001, val_loss: 460.0759, val_MinusLogProbMetric: 460.0759

Epoch 17: val_loss did not improve from 438.25256
196/196 - 10s - loss: 439.6001 - MinusLogProbMetric: 439.6001 - val_loss: 460.0759 - val_MinusLogProbMetric: 460.0759 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 18/1000
2023-09-09 22:40:26.138 
Epoch 18/1000 
	 loss: 437.4967, MinusLogProbMetric: 437.4967, val_loss: 438.8591, val_MinusLogProbMetric: 438.8591

Epoch 18: val_loss did not improve from 438.25256
196/196 - 9s - loss: 437.4967 - MinusLogProbMetric: 437.4967 - val_loss: 438.8591 - val_MinusLogProbMetric: 438.8591 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 19/1000
2023-09-09 22:40:35.706 
Epoch 19/1000 
	 loss: 438.6933, MinusLogProbMetric: 438.6933, val_loss: 432.8307, val_MinusLogProbMetric: 432.8307

Epoch 19: val_loss improved from 438.25256 to 432.83069, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 438.6933 - MinusLogProbMetric: 438.6933 - val_loss: 432.8307 - val_MinusLogProbMetric: 432.8307 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 20/1000
2023-09-09 22:40:44.412 
Epoch 20/1000 
	 loss: 434.5497, MinusLogProbMetric: 434.5497, val_loss: 429.5649, val_MinusLogProbMetric: 429.5649

Epoch 20: val_loss improved from 432.83069 to 429.56491, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 434.5497 - MinusLogProbMetric: 434.5497 - val_loss: 429.5649 - val_MinusLogProbMetric: 429.5649 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 21/1000
2023-09-09 22:40:54.381 
Epoch 21/1000 
	 loss: 436.6755, MinusLogProbMetric: 436.6755, val_loss: 431.4087, val_MinusLogProbMetric: 431.4087

Epoch 21: val_loss did not improve from 429.56491
196/196 - 10s - loss: 436.6755 - MinusLogProbMetric: 436.6755 - val_loss: 431.4087 - val_MinusLogProbMetric: 431.4087 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 22/1000
2023-09-09 22:41:03.540 
Epoch 22/1000 
	 loss: 432.1282, MinusLogProbMetric: 432.1282, val_loss: 438.2488, val_MinusLogProbMetric: 438.2488

Epoch 22: val_loss did not improve from 429.56491
196/196 - 9s - loss: 432.1282 - MinusLogProbMetric: 432.1282 - val_loss: 438.2488 - val_MinusLogProbMetric: 438.2488 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 23/1000
2023-09-09 22:41:12.439 
Epoch 23/1000 
	 loss: 435.3480, MinusLogProbMetric: 435.3480, val_loss: 444.0315, val_MinusLogProbMetric: 444.0315

Epoch 23: val_loss did not improve from 429.56491
196/196 - 9s - loss: 435.3480 - MinusLogProbMetric: 435.3480 - val_loss: 444.0315 - val_MinusLogProbMetric: 444.0315 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 24/1000
2023-09-09 22:41:20.751 
Epoch 24/1000 
	 loss: 432.7010, MinusLogProbMetric: 432.7010, val_loss: 445.4287, val_MinusLogProbMetric: 445.4287

Epoch 24: val_loss did not improve from 429.56491
196/196 - 8s - loss: 432.7010 - MinusLogProbMetric: 432.7010 - val_loss: 445.4287 - val_MinusLogProbMetric: 445.4287 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 25/1000
2023-09-09 22:41:30.971 
Epoch 25/1000 
	 loss: 429.3131, MinusLogProbMetric: 429.3131, val_loss: 424.4847, val_MinusLogProbMetric: 424.4847

Epoch 25: val_loss improved from 429.56491 to 424.48474, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 11s - loss: 429.3131 - MinusLogProbMetric: 429.3131 - val_loss: 424.4847 - val_MinusLogProbMetric: 424.4847 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 26/1000
2023-09-09 22:41:40.265 
Epoch 26/1000 
	 loss: 436.9902, MinusLogProbMetric: 436.9902, val_loss: 423.1308, val_MinusLogProbMetric: 423.1308

Epoch 26: val_loss improved from 424.48474 to 423.13080, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 436.9902 - MinusLogProbMetric: 436.9902 - val_loss: 423.1308 - val_MinusLogProbMetric: 423.1308 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 27/1000
2023-09-09 22:41:49.604 
Epoch 27/1000 
	 loss: 431.2499, MinusLogProbMetric: 431.2499, val_loss: 519.9523, val_MinusLogProbMetric: 519.9523

Epoch 27: val_loss did not improve from 423.13080
196/196 - 9s - loss: 431.2499 - MinusLogProbMetric: 431.2499 - val_loss: 519.9523 - val_MinusLogProbMetric: 519.9523 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 28/1000
2023-09-09 22:41:59.274 
Epoch 28/1000 
	 loss: 429.8219, MinusLogProbMetric: 429.8219, val_loss: 424.8728, val_MinusLogProbMetric: 424.8728

Epoch 28: val_loss did not improve from 423.13080
196/196 - 10s - loss: 429.8219 - MinusLogProbMetric: 429.8219 - val_loss: 424.8728 - val_MinusLogProbMetric: 424.8728 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 29/1000
2023-09-09 22:42:07.815 
Epoch 29/1000 
	 loss: 426.6490, MinusLogProbMetric: 426.6490, val_loss: 432.5858, val_MinusLogProbMetric: 432.5858

Epoch 29: val_loss did not improve from 423.13080
196/196 - 9s - loss: 426.6490 - MinusLogProbMetric: 426.6490 - val_loss: 432.5858 - val_MinusLogProbMetric: 432.5858 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 30/1000
2023-09-09 22:42:17.654 
Epoch 30/1000 
	 loss: 428.5346, MinusLogProbMetric: 428.5346, val_loss: 436.9593, val_MinusLogProbMetric: 436.9593

Epoch 30: val_loss did not improve from 423.13080
196/196 - 10s - loss: 428.5346 - MinusLogProbMetric: 428.5346 - val_loss: 436.9593 - val_MinusLogProbMetric: 436.9593 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 31/1000
2023-09-09 22:42:26.682 
Epoch 31/1000 
	 loss: 428.6908, MinusLogProbMetric: 428.6908, val_loss: 424.8924, val_MinusLogProbMetric: 424.8924

Epoch 31: val_loss did not improve from 423.13080
196/196 - 9s - loss: 428.6908 - MinusLogProbMetric: 428.6908 - val_loss: 424.8924 - val_MinusLogProbMetric: 424.8924 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 32/1000
2023-09-09 22:42:35.602 
Epoch 32/1000 
	 loss: 424.0538, MinusLogProbMetric: 424.0538, val_loss: 428.4506, val_MinusLogProbMetric: 428.4506

Epoch 32: val_loss did not improve from 423.13080
196/196 - 9s - loss: 424.0538 - MinusLogProbMetric: 424.0538 - val_loss: 428.4506 - val_MinusLogProbMetric: 428.4506 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 33/1000
2023-09-09 22:42:44.530 
Epoch 33/1000 
	 loss: 424.7537, MinusLogProbMetric: 424.7537, val_loss: 420.7107, val_MinusLogProbMetric: 420.7107

Epoch 33: val_loss improved from 423.13080 to 420.71069, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 424.7537 - MinusLogProbMetric: 424.7537 - val_loss: 420.7107 - val_MinusLogProbMetric: 420.7107 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 34/1000
2023-09-09 22:42:54.729 
Epoch 34/1000 
	 loss: 425.0766, MinusLogProbMetric: 425.0766, val_loss: 427.8710, val_MinusLogProbMetric: 427.8710

Epoch 34: val_loss did not improve from 420.71069
196/196 - 10s - loss: 425.0766 - MinusLogProbMetric: 425.0766 - val_loss: 427.8710 - val_MinusLogProbMetric: 427.8710 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 35/1000
2023-09-09 22:43:03.122 
Epoch 35/1000 
	 loss: 426.2894, MinusLogProbMetric: 426.2894, val_loss: 423.4654, val_MinusLogProbMetric: 423.4654

Epoch 35: val_loss did not improve from 420.71069
196/196 - 8s - loss: 426.2894 - MinusLogProbMetric: 426.2894 - val_loss: 423.4654 - val_MinusLogProbMetric: 423.4654 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 36/1000
2023-09-09 22:43:12.880 
Epoch 36/1000 
	 loss: 424.0857, MinusLogProbMetric: 424.0857, val_loss: 420.2715, val_MinusLogProbMetric: 420.2715

Epoch 36: val_loss improved from 420.71069 to 420.27155, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 424.0857 - MinusLogProbMetric: 424.0857 - val_loss: 420.2715 - val_MinusLogProbMetric: 420.2715 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 37/1000
2023-09-09 22:43:22.388 
Epoch 37/1000 
	 loss: 433.1159, MinusLogProbMetric: 433.1159, val_loss: 422.4578, val_MinusLogProbMetric: 422.4578

Epoch 37: val_loss did not improve from 420.27155
196/196 - 9s - loss: 433.1159 - MinusLogProbMetric: 433.1159 - val_loss: 422.4578 - val_MinusLogProbMetric: 422.4578 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 38/1000
2023-09-09 22:43:31.870 
Epoch 38/1000 
	 loss: 426.5410, MinusLogProbMetric: 426.5410, val_loss: 420.2556, val_MinusLogProbMetric: 420.2556

Epoch 38: val_loss improved from 420.27155 to 420.25562, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 426.5410 - MinusLogProbMetric: 426.5410 - val_loss: 420.2556 - val_MinusLogProbMetric: 420.2556 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 39/1000
2023-09-09 22:43:41.089 
Epoch 39/1000 
	 loss: 424.1052, MinusLogProbMetric: 424.1052, val_loss: 418.2059, val_MinusLogProbMetric: 418.2059

Epoch 39: val_loss improved from 420.25562 to 418.20590, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 424.1052 - MinusLogProbMetric: 424.1052 - val_loss: 418.2059 - val_MinusLogProbMetric: 418.2059 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 40/1000
2023-09-09 22:43:51.479 
Epoch 40/1000 
	 loss: 427.3316, MinusLogProbMetric: 427.3316, val_loss: 429.2944, val_MinusLogProbMetric: 429.2944

Epoch 40: val_loss did not improve from 418.20590
196/196 - 10s - loss: 427.3316 - MinusLogProbMetric: 427.3316 - val_loss: 429.2944 - val_MinusLogProbMetric: 429.2944 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 41/1000
2023-09-09 22:44:01.644 
Epoch 41/1000 
	 loss: 420.8073, MinusLogProbMetric: 420.8073, val_loss: 418.4002, val_MinusLogProbMetric: 418.4002

Epoch 41: val_loss did not improve from 418.20590
196/196 - 10s - loss: 420.8073 - MinusLogProbMetric: 420.8073 - val_loss: 418.4002 - val_MinusLogProbMetric: 418.4002 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 42/1000
2023-09-09 22:44:10.965 
Epoch 42/1000 
	 loss: 425.1083, MinusLogProbMetric: 425.1083, val_loss: 420.2391, val_MinusLogProbMetric: 420.2391

Epoch 42: val_loss did not improve from 418.20590
196/196 - 9s - loss: 425.1083 - MinusLogProbMetric: 425.1083 - val_loss: 420.2391 - val_MinusLogProbMetric: 420.2391 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 43/1000
2023-09-09 22:44:20.830 
Epoch 43/1000 
	 loss: 423.4674, MinusLogProbMetric: 423.4674, val_loss: 414.2918, val_MinusLogProbMetric: 414.2918

Epoch 43: val_loss improved from 418.20590 to 414.29184, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 423.4674 - MinusLogProbMetric: 423.4674 - val_loss: 414.2918 - val_MinusLogProbMetric: 414.2918 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 44/1000
2023-09-09 22:44:30.364 
Epoch 44/1000 
	 loss: 447.5960, MinusLogProbMetric: 447.5960, val_loss: 425.8200, val_MinusLogProbMetric: 425.8200

Epoch 44: val_loss did not improve from 414.29184
196/196 - 9s - loss: 447.5960 - MinusLogProbMetric: 447.5960 - val_loss: 425.8200 - val_MinusLogProbMetric: 425.8200 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 45/1000
2023-09-09 22:44:40.856 
Epoch 45/1000 
	 loss: 419.6674, MinusLogProbMetric: 419.6674, val_loss: 436.7006, val_MinusLogProbMetric: 436.7006

Epoch 45: val_loss did not improve from 414.29184
196/196 - 10s - loss: 419.6674 - MinusLogProbMetric: 419.6674 - val_loss: 436.7006 - val_MinusLogProbMetric: 436.7006 - lr: 0.0010 - 10s/epoch - 54ms/step
Epoch 46/1000
2023-09-09 22:44:50.292 
Epoch 46/1000 
	 loss: 417.4409, MinusLogProbMetric: 417.4409, val_loss: 414.6863, val_MinusLogProbMetric: 414.6863

Epoch 46: val_loss did not improve from 414.29184
196/196 - 9s - loss: 417.4409 - MinusLogProbMetric: 417.4409 - val_loss: 414.6863 - val_MinusLogProbMetric: 414.6863 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 47/1000
2023-09-09 22:45:00.826 
Epoch 47/1000 
	 loss: 418.5717, MinusLogProbMetric: 418.5717, val_loss: 427.0000, val_MinusLogProbMetric: 427.0000

Epoch 47: val_loss did not improve from 414.29184
196/196 - 11s - loss: 418.5717 - MinusLogProbMetric: 418.5717 - val_loss: 427.0000 - val_MinusLogProbMetric: 427.0000 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 48/1000
2023-09-09 22:45:10.751 
Epoch 48/1000 
	 loss: 417.1418, MinusLogProbMetric: 417.1418, val_loss: 421.9574, val_MinusLogProbMetric: 421.9574

Epoch 48: val_loss did not improve from 414.29184
196/196 - 10s - loss: 417.1418 - MinusLogProbMetric: 417.1418 - val_loss: 421.9574 - val_MinusLogProbMetric: 421.9574 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 49/1000
2023-09-09 22:45:20.135 
Epoch 49/1000 
	 loss: 418.6178, MinusLogProbMetric: 418.6178, val_loss: 414.5710, val_MinusLogProbMetric: 414.5710

Epoch 49: val_loss did not improve from 414.29184
196/196 - 9s - loss: 418.6178 - MinusLogProbMetric: 418.6178 - val_loss: 414.5710 - val_MinusLogProbMetric: 414.5710 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 50/1000
2023-09-09 22:45:30.263 
Epoch 50/1000 
	 loss: 415.7205, MinusLogProbMetric: 415.7205, val_loss: 415.0179, val_MinusLogProbMetric: 415.0179

Epoch 50: val_loss did not improve from 414.29184
196/196 - 10s - loss: 415.7205 - MinusLogProbMetric: 415.7205 - val_loss: 415.0179 - val_MinusLogProbMetric: 415.0179 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 51/1000
2023-09-09 22:45:39.690 
Epoch 51/1000 
	 loss: 419.1537, MinusLogProbMetric: 419.1537, val_loss: 420.0011, val_MinusLogProbMetric: 420.0011

Epoch 51: val_loss did not improve from 414.29184
196/196 - 9s - loss: 419.1537 - MinusLogProbMetric: 419.1537 - val_loss: 420.0011 - val_MinusLogProbMetric: 420.0011 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 52/1000
2023-09-09 22:45:49.292 
Epoch 52/1000 
	 loss: 416.7163, MinusLogProbMetric: 416.7163, val_loss: 420.0748, val_MinusLogProbMetric: 420.0748

Epoch 52: val_loss did not improve from 414.29184
196/196 - 10s - loss: 416.7163 - MinusLogProbMetric: 416.7163 - val_loss: 420.0748 - val_MinusLogProbMetric: 420.0748 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 53/1000
2023-09-09 22:45:58.236 
Epoch 53/1000 
	 loss: 415.6329, MinusLogProbMetric: 415.6329, val_loss: 411.7803, val_MinusLogProbMetric: 411.7803

Epoch 53: val_loss improved from 414.29184 to 411.78033, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 415.6329 - MinusLogProbMetric: 415.6329 - val_loss: 411.7803 - val_MinusLogProbMetric: 411.7803 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 54/1000
2023-09-09 22:46:08.931 
Epoch 54/1000 
	 loss: 415.9335, MinusLogProbMetric: 415.9335, val_loss: 418.7932, val_MinusLogProbMetric: 418.7932

Epoch 54: val_loss did not improve from 411.78033
196/196 - 10s - loss: 415.9335 - MinusLogProbMetric: 415.9335 - val_loss: 418.7932 - val_MinusLogProbMetric: 418.7932 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 55/1000
2023-09-09 22:46:17.767 
Epoch 55/1000 
	 loss: 417.6976, MinusLogProbMetric: 417.6976, val_loss: 413.6879, val_MinusLogProbMetric: 413.6879

Epoch 55: val_loss did not improve from 411.78033
196/196 - 9s - loss: 417.6976 - MinusLogProbMetric: 417.6976 - val_loss: 413.6879 - val_MinusLogProbMetric: 413.6879 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 56/1000
2023-09-09 22:46:27.473 
Epoch 56/1000 
	 loss: 416.3233, MinusLogProbMetric: 416.3233, val_loss: 444.4596, val_MinusLogProbMetric: 444.4596

Epoch 56: val_loss did not improve from 411.78033
196/196 - 10s - loss: 416.3233 - MinusLogProbMetric: 416.3233 - val_loss: 444.4596 - val_MinusLogProbMetric: 444.4596 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 57/1000
2023-09-09 22:46:36.558 
Epoch 57/1000 
	 loss: 417.3588, MinusLogProbMetric: 417.3588, val_loss: 437.7317, val_MinusLogProbMetric: 437.7317

Epoch 57: val_loss did not improve from 411.78033
196/196 - 9s - loss: 417.3588 - MinusLogProbMetric: 417.3588 - val_loss: 437.7317 - val_MinusLogProbMetric: 437.7317 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 58/1000
2023-09-09 22:46:46.770 
Epoch 58/1000 
	 loss: 416.8660, MinusLogProbMetric: 416.8660, val_loss: 411.7565, val_MinusLogProbMetric: 411.7565

Epoch 58: val_loss improved from 411.78033 to 411.75647, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 11s - loss: 416.8660 - MinusLogProbMetric: 416.8660 - val_loss: 411.7565 - val_MinusLogProbMetric: 411.7565 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 59/1000
2023-09-09 22:46:57.223 
Epoch 59/1000 
	 loss: 414.1923, MinusLogProbMetric: 414.1923, val_loss: 415.6391, val_MinusLogProbMetric: 415.6391

Epoch 59: val_loss did not improve from 411.75647
196/196 - 10s - loss: 414.1923 - MinusLogProbMetric: 414.1923 - val_loss: 415.6391 - val_MinusLogProbMetric: 415.6391 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 60/1000
2023-09-09 22:47:07.201 
Epoch 60/1000 
	 loss: 1135.4893, MinusLogProbMetric: 1135.4893, val_loss: 520.7954, val_MinusLogProbMetric: 520.7954

Epoch 60: val_loss did not improve from 411.75647
196/196 - 10s - loss: 1135.4893 - MinusLogProbMetric: 1135.4893 - val_loss: 520.7954 - val_MinusLogProbMetric: 520.7954 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 61/1000
2023-09-09 22:47:17.882 
Epoch 61/1000 
	 loss: 483.0869, MinusLogProbMetric: 483.0869, val_loss: 473.5724, val_MinusLogProbMetric: 473.5724

Epoch 61: val_loss did not improve from 411.75647
196/196 - 11s - loss: 483.0869 - MinusLogProbMetric: 483.0869 - val_loss: 473.5724 - val_MinusLogProbMetric: 473.5724 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 62/1000
2023-09-09 22:47:27.202 
Epoch 62/1000 
	 loss: 455.9262, MinusLogProbMetric: 455.9262, val_loss: 447.7717, val_MinusLogProbMetric: 447.7717

Epoch 62: val_loss did not improve from 411.75647
196/196 - 9s - loss: 455.9262 - MinusLogProbMetric: 455.9262 - val_loss: 447.7717 - val_MinusLogProbMetric: 447.7717 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 63/1000
2023-09-09 22:47:37.130 
Epoch 63/1000 
	 loss: 443.2841, MinusLogProbMetric: 443.2841, val_loss: 448.3116, val_MinusLogProbMetric: 448.3116

Epoch 63: val_loss did not improve from 411.75647
196/196 - 10s - loss: 443.2841 - MinusLogProbMetric: 443.2841 - val_loss: 448.3116 - val_MinusLogProbMetric: 448.3116 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 64/1000
2023-09-09 22:47:46.565 
Epoch 64/1000 
	 loss: 437.0664, MinusLogProbMetric: 437.0664, val_loss: 437.7465, val_MinusLogProbMetric: 437.7465

Epoch 64: val_loss did not improve from 411.75647
196/196 - 9s - loss: 437.0664 - MinusLogProbMetric: 437.0664 - val_loss: 437.7465 - val_MinusLogProbMetric: 437.7465 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 65/1000
2023-09-09 22:47:56.495 
Epoch 65/1000 
	 loss: 433.2375, MinusLogProbMetric: 433.2375, val_loss: 431.3316, val_MinusLogProbMetric: 431.3316

Epoch 65: val_loss did not improve from 411.75647
196/196 - 10s - loss: 433.2375 - MinusLogProbMetric: 433.2375 - val_loss: 431.3316 - val_MinusLogProbMetric: 431.3316 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 66/1000
2023-09-09 22:48:05.336 
Epoch 66/1000 
	 loss: 429.8775, MinusLogProbMetric: 429.8775, val_loss: 427.1836, val_MinusLogProbMetric: 427.1836

Epoch 66: val_loss did not improve from 411.75647
196/196 - 9s - loss: 429.8775 - MinusLogProbMetric: 429.8775 - val_loss: 427.1836 - val_MinusLogProbMetric: 427.1836 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 67/1000
2023-09-09 22:48:15.344 
Epoch 67/1000 
	 loss: 428.5899, MinusLogProbMetric: 428.5899, val_loss: 477.9434, val_MinusLogProbMetric: 477.9434

Epoch 67: val_loss did not improve from 411.75647
196/196 - 10s - loss: 428.5899 - MinusLogProbMetric: 428.5899 - val_loss: 477.9434 - val_MinusLogProbMetric: 477.9434 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 68/1000
2023-09-09 22:48:24.377 
Epoch 68/1000 
	 loss: 427.1608, MinusLogProbMetric: 427.1608, val_loss: 424.5334, val_MinusLogProbMetric: 424.5334

Epoch 68: val_loss did not improve from 411.75647
196/196 - 9s - loss: 427.1608 - MinusLogProbMetric: 427.1608 - val_loss: 424.5334 - val_MinusLogProbMetric: 424.5334 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 69/1000
2023-09-09 22:48:34.650 
Epoch 69/1000 
	 loss: 424.0400, MinusLogProbMetric: 424.0400, val_loss: 424.1693, val_MinusLogProbMetric: 424.1693

Epoch 69: val_loss did not improve from 411.75647
196/196 - 10s - loss: 424.0400 - MinusLogProbMetric: 424.0400 - val_loss: 424.1693 - val_MinusLogProbMetric: 424.1693 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 70/1000
2023-09-09 22:48:43.466 
Epoch 70/1000 
	 loss: 423.8113, MinusLogProbMetric: 423.8113, val_loss: 420.7289, val_MinusLogProbMetric: 420.7289

Epoch 70: val_loss did not improve from 411.75647
196/196 - 9s - loss: 423.8113 - MinusLogProbMetric: 423.8113 - val_loss: 420.7289 - val_MinusLogProbMetric: 420.7289 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 71/1000
2023-09-09 22:48:53.803 
Epoch 71/1000 
	 loss: 422.1056, MinusLogProbMetric: 422.1056, val_loss: 461.1625, val_MinusLogProbMetric: 461.1625

Epoch 71: val_loss did not improve from 411.75647
196/196 - 10s - loss: 422.1056 - MinusLogProbMetric: 422.1056 - val_loss: 461.1625 - val_MinusLogProbMetric: 461.1625 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 72/1000
2023-09-09 22:49:02.683 
Epoch 72/1000 
	 loss: 420.2401, MinusLogProbMetric: 420.2401, val_loss: 422.0137, val_MinusLogProbMetric: 422.0137

Epoch 72: val_loss did not improve from 411.75647
196/196 - 9s - loss: 420.2401 - MinusLogProbMetric: 420.2401 - val_loss: 422.0137 - val_MinusLogProbMetric: 422.0137 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 73/1000
2023-09-09 22:49:12.203 
Epoch 73/1000 
	 loss: 419.8379, MinusLogProbMetric: 419.8379, val_loss: 418.5664, val_MinusLogProbMetric: 418.5664

Epoch 73: val_loss did not improve from 411.75647
196/196 - 10s - loss: 419.8379 - MinusLogProbMetric: 419.8379 - val_loss: 418.5664 - val_MinusLogProbMetric: 418.5664 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 74/1000
2023-09-09 22:49:21.938 
Epoch 74/1000 
	 loss: 418.8947, MinusLogProbMetric: 418.8947, val_loss: 419.9662, val_MinusLogProbMetric: 419.9662

Epoch 74: val_loss did not improve from 411.75647
196/196 - 10s - loss: 418.8947 - MinusLogProbMetric: 418.8947 - val_loss: 419.9662 - val_MinusLogProbMetric: 419.9662 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 75/1000
2023-09-09 22:49:30.713 
Epoch 75/1000 
	 loss: 419.9890, MinusLogProbMetric: 419.9890, val_loss: 419.7855, val_MinusLogProbMetric: 419.7855

Epoch 75: val_loss did not improve from 411.75647
196/196 - 9s - loss: 419.9890 - MinusLogProbMetric: 419.9890 - val_loss: 419.7855 - val_MinusLogProbMetric: 419.7855 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 76/1000
2023-09-09 22:49:39.777 
Epoch 76/1000 
	 loss: 416.8046, MinusLogProbMetric: 416.8046, val_loss: 416.3232, val_MinusLogProbMetric: 416.3232

Epoch 76: val_loss did not improve from 411.75647
196/196 - 9s - loss: 416.8046 - MinusLogProbMetric: 416.8046 - val_loss: 416.3232 - val_MinusLogProbMetric: 416.3232 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 77/1000
2023-09-09 22:49:48.821 
Epoch 77/1000 
	 loss: 417.7951, MinusLogProbMetric: 417.7951, val_loss: 414.2962, val_MinusLogProbMetric: 414.2962

Epoch 77: val_loss did not improve from 411.75647
196/196 - 9s - loss: 417.7951 - MinusLogProbMetric: 417.7951 - val_loss: 414.2962 - val_MinusLogProbMetric: 414.2962 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 78/1000
2023-09-09 22:49:58.707 
Epoch 78/1000 
	 loss: 417.3962, MinusLogProbMetric: 417.3962, val_loss: 419.3037, val_MinusLogProbMetric: 419.3037

Epoch 78: val_loss did not improve from 411.75647
196/196 - 10s - loss: 417.3962 - MinusLogProbMetric: 417.3962 - val_loss: 419.3037 - val_MinusLogProbMetric: 419.3037 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 79/1000
2023-09-09 22:50:07.373 
Epoch 79/1000 
	 loss: 415.3930, MinusLogProbMetric: 415.3930, val_loss: 423.2573, val_MinusLogProbMetric: 423.2573

Epoch 79: val_loss did not improve from 411.75647
196/196 - 9s - loss: 415.3930 - MinusLogProbMetric: 415.3930 - val_loss: 423.2573 - val_MinusLogProbMetric: 423.2573 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 80/1000
2023-09-09 22:50:16.915 
Epoch 80/1000 
	 loss: 414.8729, MinusLogProbMetric: 414.8729, val_loss: 412.8586, val_MinusLogProbMetric: 412.8586

Epoch 80: val_loss did not improve from 411.75647
196/196 - 10s - loss: 414.8729 - MinusLogProbMetric: 414.8729 - val_loss: 412.8586 - val_MinusLogProbMetric: 412.8586 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 81/1000
2023-09-09 22:50:26.008 
Epoch 81/1000 
	 loss: 414.3170, MinusLogProbMetric: 414.3170, val_loss: 431.6768, val_MinusLogProbMetric: 431.6768

Epoch 81: val_loss did not improve from 411.75647
196/196 - 9s - loss: 414.3170 - MinusLogProbMetric: 414.3170 - val_loss: 431.6768 - val_MinusLogProbMetric: 431.6768 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 82/1000
2023-09-09 22:50:35.662 
Epoch 82/1000 
	 loss: 414.8924, MinusLogProbMetric: 414.8924, val_loss: 417.5862, val_MinusLogProbMetric: 417.5862

Epoch 82: val_loss did not improve from 411.75647
196/196 - 10s - loss: 414.8924 - MinusLogProbMetric: 414.8924 - val_loss: 417.5862 - val_MinusLogProbMetric: 417.5862 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 83/1000
2023-09-09 22:50:44.482 
Epoch 83/1000 
	 loss: 413.5382, MinusLogProbMetric: 413.5382, val_loss: 416.9676, val_MinusLogProbMetric: 416.9676

Epoch 83: val_loss did not improve from 411.75647
196/196 - 9s - loss: 413.5382 - MinusLogProbMetric: 413.5382 - val_loss: 416.9676 - val_MinusLogProbMetric: 416.9676 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 84/1000
2023-09-09 22:50:53.640 
Epoch 84/1000 
	 loss: 413.6946, MinusLogProbMetric: 413.6946, val_loss: 416.1564, val_MinusLogProbMetric: 416.1564

Epoch 84: val_loss did not improve from 411.75647
196/196 - 9s - loss: 413.6946 - MinusLogProbMetric: 413.6946 - val_loss: 416.1564 - val_MinusLogProbMetric: 416.1564 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 85/1000
2023-09-09 22:51:02.671 
Epoch 85/1000 
	 loss: 414.2455, MinusLogProbMetric: 414.2455, val_loss: 413.7641, val_MinusLogProbMetric: 413.7641

Epoch 85: val_loss did not improve from 411.75647
196/196 - 9s - loss: 414.2455 - MinusLogProbMetric: 414.2455 - val_loss: 413.7641 - val_MinusLogProbMetric: 413.7641 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 86/1000
2023-09-09 22:51:12.168 
Epoch 86/1000 
	 loss: 411.6045, MinusLogProbMetric: 411.6045, val_loss: 457.9490, val_MinusLogProbMetric: 457.9490

Epoch 86: val_loss did not improve from 411.75647
196/196 - 9s - loss: 411.6045 - MinusLogProbMetric: 411.6045 - val_loss: 457.9490 - val_MinusLogProbMetric: 457.9490 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 87/1000
2023-09-09 22:51:21.131 
Epoch 87/1000 
	 loss: 418.9844, MinusLogProbMetric: 418.9844, val_loss: 411.2333, val_MinusLogProbMetric: 411.2333

Epoch 87: val_loss improved from 411.75647 to 411.23328, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 418.9844 - MinusLogProbMetric: 418.9844 - val_loss: 411.2333 - val_MinusLogProbMetric: 411.2333 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 88/1000
2023-09-09 22:51:31.251 
Epoch 88/1000 
	 loss: 413.0283, MinusLogProbMetric: 413.0283, val_loss: 409.5233, val_MinusLogProbMetric: 409.5233

Epoch 88: val_loss improved from 411.23328 to 409.52325, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 413.0283 - MinusLogProbMetric: 413.0283 - val_loss: 409.5233 - val_MinusLogProbMetric: 409.5233 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 89/1000
2023-09-09 22:51:40.716 
Epoch 89/1000 
	 loss: 412.0949, MinusLogProbMetric: 412.0949, val_loss: 413.6764, val_MinusLogProbMetric: 413.6764

Epoch 89: val_loss did not improve from 409.52325
196/196 - 9s - loss: 412.0949 - MinusLogProbMetric: 412.0949 - val_loss: 413.6764 - val_MinusLogProbMetric: 413.6764 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 90/1000
2023-09-09 22:51:49.753 
Epoch 90/1000 
	 loss: 412.4873, MinusLogProbMetric: 412.4873, val_loss: 414.9585, val_MinusLogProbMetric: 414.9585

Epoch 90: val_loss did not improve from 409.52325
196/196 - 9s - loss: 412.4873 - MinusLogProbMetric: 412.4873 - val_loss: 414.9585 - val_MinusLogProbMetric: 414.9585 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 91/1000
2023-09-09 22:51:58.018 
Epoch 91/1000 
	 loss: 412.1140, MinusLogProbMetric: 412.1140, val_loss: 410.8725, val_MinusLogProbMetric: 410.8725

Epoch 91: val_loss did not improve from 409.52325
196/196 - 8s - loss: 412.1140 - MinusLogProbMetric: 412.1140 - val_loss: 410.8725 - val_MinusLogProbMetric: 410.8725 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 92/1000
2023-09-09 22:52:07.999 
Epoch 92/1000 
	 loss: 411.3330, MinusLogProbMetric: 411.3330, val_loss: 411.0031, val_MinusLogProbMetric: 411.0031

Epoch 92: val_loss did not improve from 409.52325
196/196 - 10s - loss: 411.3330 - MinusLogProbMetric: 411.3330 - val_loss: 411.0031 - val_MinusLogProbMetric: 411.0031 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 93/1000
2023-09-09 22:52:17.913 
Epoch 93/1000 
	 loss: 410.5443, MinusLogProbMetric: 410.5443, val_loss: 419.5484, val_MinusLogProbMetric: 419.5484

Epoch 93: val_loss did not improve from 409.52325
196/196 - 10s - loss: 410.5443 - MinusLogProbMetric: 410.5443 - val_loss: 419.5484 - val_MinusLogProbMetric: 419.5484 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 94/1000
2023-09-09 22:52:26.869 
Epoch 94/1000 
	 loss: 410.7667, MinusLogProbMetric: 410.7667, val_loss: 414.5042, val_MinusLogProbMetric: 414.5042

Epoch 94: val_loss did not improve from 409.52325
196/196 - 9s - loss: 410.7667 - MinusLogProbMetric: 410.7667 - val_loss: 414.5042 - val_MinusLogProbMetric: 414.5042 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 95/1000
2023-09-09 22:52:36.214 
Epoch 95/1000 
	 loss: 410.8683, MinusLogProbMetric: 410.8683, val_loss: 408.7836, val_MinusLogProbMetric: 408.7836

Epoch 95: val_loss improved from 409.52325 to 408.78363, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 410.8683 - MinusLogProbMetric: 410.8683 - val_loss: 408.7836 - val_MinusLogProbMetric: 408.7836 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 96/1000
2023-09-09 22:52:45.510 
Epoch 96/1000 
	 loss: 412.2563, MinusLogProbMetric: 412.2563, val_loss: 413.1513, val_MinusLogProbMetric: 413.1513

Epoch 96: val_loss did not improve from 408.78363
196/196 - 9s - loss: 412.2563 - MinusLogProbMetric: 412.2563 - val_loss: 413.1513 - val_MinusLogProbMetric: 413.1513 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 97/1000
2023-09-09 22:52:54.897 
Epoch 97/1000 
	 loss: 410.6461, MinusLogProbMetric: 410.6461, val_loss: 415.9481, val_MinusLogProbMetric: 415.9481

Epoch 97: val_loss did not improve from 408.78363
196/196 - 9s - loss: 410.6461 - MinusLogProbMetric: 410.6461 - val_loss: 415.9481 - val_MinusLogProbMetric: 415.9481 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 98/1000
2023-09-09 22:53:03.472 
Epoch 98/1000 
	 loss: 410.5651, MinusLogProbMetric: 410.5651, val_loss: 409.4526, val_MinusLogProbMetric: 409.4526

Epoch 98: val_loss did not improve from 408.78363
196/196 - 9s - loss: 410.5651 - MinusLogProbMetric: 410.5651 - val_loss: 409.4526 - val_MinusLogProbMetric: 409.4526 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 99/1000
2023-09-09 22:53:12.917 
Epoch 99/1000 
	 loss: 409.8434, MinusLogProbMetric: 409.8434, val_loss: 406.7876, val_MinusLogProbMetric: 406.7876

Epoch 99: val_loss improved from 408.78363 to 406.78760, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 409.8434 - MinusLogProbMetric: 409.8434 - val_loss: 406.7876 - val_MinusLogProbMetric: 406.7876 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 100/1000
2023-09-09 22:53:22.225 
Epoch 100/1000 
	 loss: 409.2297, MinusLogProbMetric: 409.2297, val_loss: 407.8384, val_MinusLogProbMetric: 407.8384

Epoch 100: val_loss did not improve from 406.78760
196/196 - 9s - loss: 409.2297 - MinusLogProbMetric: 409.2297 - val_loss: 407.8384 - val_MinusLogProbMetric: 407.8384 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 101/1000
2023-09-09 22:53:32.152 
Epoch 101/1000 
	 loss: 409.2109, MinusLogProbMetric: 409.2109, val_loss: 411.1537, val_MinusLogProbMetric: 411.1537

Epoch 101: val_loss did not improve from 406.78760
196/196 - 10s - loss: 409.2109 - MinusLogProbMetric: 409.2109 - val_loss: 411.1537 - val_MinusLogProbMetric: 411.1537 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 102/1000
2023-09-09 22:53:40.959 
Epoch 102/1000 
	 loss: 410.6126, MinusLogProbMetric: 410.6126, val_loss: 405.6160, val_MinusLogProbMetric: 405.6160

Epoch 102: val_loss improved from 406.78760 to 405.61603, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 410.6126 - MinusLogProbMetric: 410.6126 - val_loss: 405.6160 - val_MinusLogProbMetric: 405.6160 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 103/1000
2023-09-09 22:53:51.657 
Epoch 103/1000 
	 loss: 409.5046, MinusLogProbMetric: 409.5046, val_loss: 408.2022, val_MinusLogProbMetric: 408.2022

Epoch 103: val_loss did not improve from 405.61603
196/196 - 10s - loss: 409.5046 - MinusLogProbMetric: 409.5046 - val_loss: 408.2022 - val_MinusLogProbMetric: 408.2022 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 104/1000
2023-09-09 22:54:01.320 
Epoch 104/1000 
	 loss: 408.0108, MinusLogProbMetric: 408.0108, val_loss: 407.0549, val_MinusLogProbMetric: 407.0549

Epoch 104: val_loss did not improve from 405.61603
196/196 - 10s - loss: 408.0108 - MinusLogProbMetric: 408.0108 - val_loss: 407.0549 - val_MinusLogProbMetric: 407.0549 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 105/1000
2023-09-09 22:54:11.009 
Epoch 105/1000 
	 loss: 410.1534, MinusLogProbMetric: 410.1534, val_loss: 416.8170, val_MinusLogProbMetric: 416.8170

Epoch 105: val_loss did not improve from 405.61603
196/196 - 10s - loss: 410.1534 - MinusLogProbMetric: 410.1534 - val_loss: 416.8170 - val_MinusLogProbMetric: 416.8170 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 106/1000
2023-09-09 22:54:19.711 
Epoch 106/1000 
	 loss: 408.3959, MinusLogProbMetric: 408.3959, val_loss: 406.2445, val_MinusLogProbMetric: 406.2445

Epoch 106: val_loss did not improve from 405.61603
196/196 - 9s - loss: 408.3959 - MinusLogProbMetric: 408.3959 - val_loss: 406.2445 - val_MinusLogProbMetric: 406.2445 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 107/1000
2023-09-09 22:54:29.541 
Epoch 107/1000 
	 loss: 408.5330, MinusLogProbMetric: 408.5330, val_loss: 415.0720, val_MinusLogProbMetric: 415.0720

Epoch 107: val_loss did not improve from 405.61603
196/196 - 10s - loss: 408.5330 - MinusLogProbMetric: 408.5330 - val_loss: 415.0720 - val_MinusLogProbMetric: 415.0720 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 108/1000
2023-09-09 22:54:38.593 
Epoch 108/1000 
	 loss: 407.4026, MinusLogProbMetric: 407.4026, val_loss: 413.7071, val_MinusLogProbMetric: 413.7071

Epoch 108: val_loss did not improve from 405.61603
196/196 - 9s - loss: 407.4026 - MinusLogProbMetric: 407.4026 - val_loss: 413.7071 - val_MinusLogProbMetric: 413.7071 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 109/1000
2023-09-09 22:54:48.149 
Epoch 109/1000 
	 loss: 408.0839, MinusLogProbMetric: 408.0839, val_loss: 406.2810, val_MinusLogProbMetric: 406.2810

Epoch 109: val_loss did not improve from 405.61603
196/196 - 10s - loss: 408.0839 - MinusLogProbMetric: 408.0839 - val_loss: 406.2810 - val_MinusLogProbMetric: 406.2810 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 110/1000
2023-09-09 22:54:58.184 
Epoch 110/1000 
	 loss: 408.8498, MinusLogProbMetric: 408.8498, val_loss: 407.2614, val_MinusLogProbMetric: 407.2614

Epoch 110: val_loss did not improve from 405.61603
196/196 - 10s - loss: 408.8498 - MinusLogProbMetric: 408.8498 - val_loss: 407.2614 - val_MinusLogProbMetric: 407.2614 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 111/1000
2023-09-09 22:55:07.767 
Epoch 111/1000 
	 loss: 407.9312, MinusLogProbMetric: 407.9312, val_loss: 406.8459, val_MinusLogProbMetric: 406.8459

Epoch 111: val_loss did not improve from 405.61603
196/196 - 10s - loss: 407.9312 - MinusLogProbMetric: 407.9312 - val_loss: 406.8459 - val_MinusLogProbMetric: 406.8459 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 112/1000
2023-09-09 22:55:17.496 
Epoch 112/1000 
	 loss: 407.5246, MinusLogProbMetric: 407.5246, val_loss: 415.9347, val_MinusLogProbMetric: 415.9347

Epoch 112: val_loss did not improve from 405.61603
196/196 - 10s - loss: 407.5246 - MinusLogProbMetric: 407.5246 - val_loss: 415.9347 - val_MinusLogProbMetric: 415.9347 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 113/1000
2023-09-09 22:55:26.161 
Epoch 113/1000 
	 loss: 407.1827, MinusLogProbMetric: 407.1827, val_loss: 406.1887, val_MinusLogProbMetric: 406.1887

Epoch 113: val_loss did not improve from 405.61603
196/196 - 9s - loss: 407.1827 - MinusLogProbMetric: 407.1827 - val_loss: 406.1887 - val_MinusLogProbMetric: 406.1887 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 114/1000
2023-09-09 22:55:35.719 
Epoch 114/1000 
	 loss: 407.7542, MinusLogProbMetric: 407.7542, val_loss: 406.2299, val_MinusLogProbMetric: 406.2299

Epoch 114: val_loss did not improve from 405.61603
196/196 - 10s - loss: 407.7542 - MinusLogProbMetric: 407.7542 - val_loss: 406.2299 - val_MinusLogProbMetric: 406.2299 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 115/1000
2023-09-09 22:55:45.775 
Epoch 115/1000 
	 loss: 406.6366, MinusLogProbMetric: 406.6366, val_loss: 404.0823, val_MinusLogProbMetric: 404.0823

Epoch 115: val_loss improved from 405.61603 to 404.08234, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 406.6366 - MinusLogProbMetric: 406.6366 - val_loss: 404.0823 - val_MinusLogProbMetric: 404.0823 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 116/1000
2023-09-09 22:55:56.286 
Epoch 116/1000 
	 loss: 406.6928, MinusLogProbMetric: 406.6928, val_loss: 411.8344, val_MinusLogProbMetric: 411.8344

Epoch 116: val_loss did not improve from 404.08234
196/196 - 10s - loss: 406.6928 - MinusLogProbMetric: 406.6928 - val_loss: 411.8344 - val_MinusLogProbMetric: 411.8344 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 117/1000
2023-09-09 22:56:05.878 
Epoch 117/1000 
	 loss: 409.1591, MinusLogProbMetric: 409.1591, val_loss: 404.5699, val_MinusLogProbMetric: 404.5699

Epoch 117: val_loss did not improve from 404.08234
196/196 - 10s - loss: 409.1591 - MinusLogProbMetric: 409.1591 - val_loss: 404.5699 - val_MinusLogProbMetric: 404.5699 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 118/1000
2023-09-09 22:56:16.191 
Epoch 118/1000 
	 loss: 406.2748, MinusLogProbMetric: 406.2748, val_loss: 406.9815, val_MinusLogProbMetric: 406.9815

Epoch 118: val_loss did not improve from 404.08234
196/196 - 10s - loss: 406.2748 - MinusLogProbMetric: 406.2748 - val_loss: 406.9815 - val_MinusLogProbMetric: 406.9815 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 119/1000
2023-09-09 22:56:26.184 
Epoch 119/1000 
	 loss: 406.8531, MinusLogProbMetric: 406.8531, val_loss: 407.1878, val_MinusLogProbMetric: 407.1878

Epoch 119: val_loss did not improve from 404.08234
196/196 - 10s - loss: 406.8531 - MinusLogProbMetric: 406.8531 - val_loss: 407.1878 - val_MinusLogProbMetric: 407.1878 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 120/1000
2023-09-09 22:56:35.559 
Epoch 120/1000 
	 loss: 407.3054, MinusLogProbMetric: 407.3054, val_loss: 413.8824, val_MinusLogProbMetric: 413.8824

Epoch 120: val_loss did not improve from 404.08234
196/196 - 9s - loss: 407.3054 - MinusLogProbMetric: 407.3054 - val_loss: 413.8824 - val_MinusLogProbMetric: 413.8824 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 121/1000
2023-09-09 22:56:44.759 
Epoch 121/1000 
	 loss: 406.1919, MinusLogProbMetric: 406.1919, val_loss: 407.4437, val_MinusLogProbMetric: 407.4437

Epoch 121: val_loss did not improve from 404.08234
196/196 - 9s - loss: 406.1919 - MinusLogProbMetric: 406.1919 - val_loss: 407.4437 - val_MinusLogProbMetric: 407.4437 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 122/1000
2023-09-09 22:56:54.764 
Epoch 122/1000 
	 loss: 405.7944, MinusLogProbMetric: 405.7944, val_loss: 405.8378, val_MinusLogProbMetric: 405.8378

Epoch 122: val_loss did not improve from 404.08234
196/196 - 10s - loss: 405.7944 - MinusLogProbMetric: 405.7944 - val_loss: 405.8378 - val_MinusLogProbMetric: 405.8378 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 123/1000
2023-09-09 22:57:05.223 
Epoch 123/1000 
	 loss: 405.8587, MinusLogProbMetric: 405.8587, val_loss: 406.5529, val_MinusLogProbMetric: 406.5529

Epoch 123: val_loss did not improve from 404.08234
196/196 - 10s - loss: 405.8587 - MinusLogProbMetric: 405.8587 - val_loss: 406.5529 - val_MinusLogProbMetric: 406.5529 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 124/1000
2023-09-09 22:57:15.172 
Epoch 124/1000 
	 loss: 407.6981, MinusLogProbMetric: 407.6981, val_loss: 405.6289, val_MinusLogProbMetric: 405.6289

Epoch 124: val_loss did not improve from 404.08234
196/196 - 10s - loss: 407.6981 - MinusLogProbMetric: 407.6981 - val_loss: 405.6289 - val_MinusLogProbMetric: 405.6289 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 125/1000
2023-09-09 22:57:25.058 
Epoch 125/1000 
	 loss: 406.3006, MinusLogProbMetric: 406.3006, val_loss: 403.2252, val_MinusLogProbMetric: 403.2252

Epoch 125: val_loss improved from 404.08234 to 403.22522, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 406.3006 - MinusLogProbMetric: 406.3006 - val_loss: 403.2252 - val_MinusLogProbMetric: 403.2252 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 126/1000
2023-09-09 22:57:34.952 
Epoch 126/1000 
	 loss: 406.1517, MinusLogProbMetric: 406.1517, val_loss: 415.7137, val_MinusLogProbMetric: 415.7137

Epoch 126: val_loss did not improve from 403.22522
196/196 - 10s - loss: 406.1517 - MinusLogProbMetric: 406.1517 - val_loss: 415.7137 - val_MinusLogProbMetric: 415.7137 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 127/1000
2023-09-09 22:57:44.964 
Epoch 127/1000 
	 loss: 405.6676, MinusLogProbMetric: 405.6676, val_loss: 407.0021, val_MinusLogProbMetric: 407.0021

Epoch 127: val_loss did not improve from 403.22522
196/196 - 10s - loss: 405.6676 - MinusLogProbMetric: 405.6676 - val_loss: 407.0021 - val_MinusLogProbMetric: 407.0021 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 128/1000
2023-09-09 22:57:54.368 
Epoch 128/1000 
	 loss: 406.9988, MinusLogProbMetric: 406.9988, val_loss: 404.7790, val_MinusLogProbMetric: 404.7790

Epoch 128: val_loss did not improve from 403.22522
196/196 - 9s - loss: 406.9988 - MinusLogProbMetric: 406.9988 - val_loss: 404.7790 - val_MinusLogProbMetric: 404.7790 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 129/1000
2023-09-09 22:58:04.574 
Epoch 129/1000 
	 loss: 405.5734, MinusLogProbMetric: 405.5734, val_loss: 404.7797, val_MinusLogProbMetric: 404.7797

Epoch 129: val_loss did not improve from 403.22522
196/196 - 10s - loss: 405.5734 - MinusLogProbMetric: 405.5734 - val_loss: 404.7797 - val_MinusLogProbMetric: 404.7797 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 130/1000
2023-09-09 22:58:13.997 
Epoch 130/1000 
	 loss: 406.4674, MinusLogProbMetric: 406.4674, val_loss: 413.9416, val_MinusLogProbMetric: 413.9416

Epoch 130: val_loss did not improve from 403.22522
196/196 - 9s - loss: 406.4674 - MinusLogProbMetric: 406.4674 - val_loss: 413.9416 - val_MinusLogProbMetric: 413.9416 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 131/1000
2023-09-09 22:58:23.932 
Epoch 131/1000 
	 loss: 405.2574, MinusLogProbMetric: 405.2574, val_loss: 406.3587, val_MinusLogProbMetric: 406.3587

Epoch 131: val_loss did not improve from 403.22522
196/196 - 10s - loss: 405.2574 - MinusLogProbMetric: 405.2574 - val_loss: 406.3587 - val_MinusLogProbMetric: 406.3587 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 132/1000
2023-09-09 22:58:33.534 
Epoch 132/1000 
	 loss: 405.4026, MinusLogProbMetric: 405.4026, val_loss: 405.3018, val_MinusLogProbMetric: 405.3018

Epoch 132: val_loss did not improve from 403.22522
196/196 - 10s - loss: 405.4026 - MinusLogProbMetric: 405.4026 - val_loss: 405.3018 - val_MinusLogProbMetric: 405.3018 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 133/1000
2023-09-09 22:58:43.305 
Epoch 133/1000 
	 loss: 406.0245, MinusLogProbMetric: 406.0245, val_loss: 403.6287, val_MinusLogProbMetric: 403.6287

Epoch 133: val_loss did not improve from 403.22522
196/196 - 10s - loss: 406.0245 - MinusLogProbMetric: 406.0245 - val_loss: 403.6287 - val_MinusLogProbMetric: 403.6287 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 134/1000
2023-09-09 22:58:53.170 
Epoch 134/1000 
	 loss: 405.0830, MinusLogProbMetric: 405.0830, val_loss: 409.6825, val_MinusLogProbMetric: 409.6825

Epoch 134: val_loss did not improve from 403.22522
196/196 - 10s - loss: 405.0830 - MinusLogProbMetric: 405.0830 - val_loss: 409.6825 - val_MinusLogProbMetric: 409.6825 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 135/1000
2023-09-09 22:59:02.365 
Epoch 135/1000 
	 loss: 405.2790, MinusLogProbMetric: 405.2790, val_loss: 403.5614, val_MinusLogProbMetric: 403.5614

Epoch 135: val_loss did not improve from 403.22522
196/196 - 9s - loss: 405.2790 - MinusLogProbMetric: 405.2790 - val_loss: 403.5614 - val_MinusLogProbMetric: 403.5614 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 136/1000
2023-09-09 22:59:11.106 
Epoch 136/1000 
	 loss: 406.0576, MinusLogProbMetric: 406.0576, val_loss: 404.9386, val_MinusLogProbMetric: 404.9386

Epoch 136: val_loss did not improve from 403.22522
196/196 - 9s - loss: 406.0576 - MinusLogProbMetric: 406.0576 - val_loss: 404.9386 - val_MinusLogProbMetric: 404.9386 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 137/1000
2023-09-09 22:59:21.070 
Epoch 137/1000 
	 loss: 408.8292, MinusLogProbMetric: 408.8292, val_loss: 405.6036, val_MinusLogProbMetric: 405.6036

Epoch 137: val_loss did not improve from 403.22522
196/196 - 10s - loss: 408.8292 - MinusLogProbMetric: 408.8292 - val_loss: 405.6036 - val_MinusLogProbMetric: 405.6036 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 138/1000
2023-09-09 22:59:30.907 
Epoch 138/1000 
	 loss: 404.5169, MinusLogProbMetric: 404.5169, val_loss: 407.1221, val_MinusLogProbMetric: 407.1221

Epoch 138: val_loss did not improve from 403.22522
196/196 - 10s - loss: 404.5169 - MinusLogProbMetric: 404.5169 - val_loss: 407.1221 - val_MinusLogProbMetric: 407.1221 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 139/1000
2023-09-09 22:59:39.843 
Epoch 139/1000 
	 loss: 406.1500, MinusLogProbMetric: 406.1500, val_loss: 404.3617, val_MinusLogProbMetric: 404.3617

Epoch 139: val_loss did not improve from 403.22522
196/196 - 9s - loss: 406.1500 - MinusLogProbMetric: 406.1500 - val_loss: 404.3617 - val_MinusLogProbMetric: 404.3617 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 140/1000
2023-09-09 22:59:49.182 
Epoch 140/1000 
	 loss: 406.3355, MinusLogProbMetric: 406.3355, val_loss: 410.9216, val_MinusLogProbMetric: 410.9216

Epoch 140: val_loss did not improve from 403.22522
196/196 - 9s - loss: 406.3355 - MinusLogProbMetric: 406.3355 - val_loss: 410.9216 - val_MinusLogProbMetric: 410.9216 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 141/1000
2023-09-09 22:59:57.882 
Epoch 141/1000 
	 loss: 404.0232, MinusLogProbMetric: 404.0232, val_loss: 404.2075, val_MinusLogProbMetric: 404.2075

Epoch 141: val_loss did not improve from 403.22522
196/196 - 9s - loss: 404.0232 - MinusLogProbMetric: 404.0232 - val_loss: 404.2075 - val_MinusLogProbMetric: 404.2075 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 142/1000
2023-09-09 23:00:07.229 
Epoch 142/1000 
	 loss: 405.4286, MinusLogProbMetric: 405.4286, val_loss: 403.4631, val_MinusLogProbMetric: 403.4631

Epoch 142: val_loss did not improve from 403.22522
196/196 - 9s - loss: 405.4286 - MinusLogProbMetric: 405.4286 - val_loss: 403.4631 - val_MinusLogProbMetric: 403.4631 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 143/1000
2023-09-09 23:00:15.898 
Epoch 143/1000 
	 loss: 404.8889, MinusLogProbMetric: 404.8889, val_loss: 403.9986, val_MinusLogProbMetric: 403.9986

Epoch 143: val_loss did not improve from 403.22522
196/196 - 9s - loss: 404.8889 - MinusLogProbMetric: 404.8889 - val_loss: 403.9986 - val_MinusLogProbMetric: 403.9986 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 144/1000
2023-09-09 23:00:25.212 
Epoch 144/1000 
	 loss: 404.7852, MinusLogProbMetric: 404.7852, val_loss: 402.7137, val_MinusLogProbMetric: 402.7137

Epoch 144: val_loss improved from 403.22522 to 402.71365, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 404.7852 - MinusLogProbMetric: 404.7852 - val_loss: 402.7137 - val_MinusLogProbMetric: 402.7137 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 145/1000
2023-09-09 23:00:34.783 
Epoch 145/1000 
	 loss: 404.5587, MinusLogProbMetric: 404.5587, val_loss: 402.8071, val_MinusLogProbMetric: 402.8071

Epoch 145: val_loss did not improve from 402.71365
196/196 - 9s - loss: 404.5587 - MinusLogProbMetric: 404.5587 - val_loss: 402.8071 - val_MinusLogProbMetric: 402.8071 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 146/1000
2023-09-09 23:00:43.951 
Epoch 146/1000 
	 loss: 404.8008, MinusLogProbMetric: 404.8008, val_loss: 409.2979, val_MinusLogProbMetric: 409.2979

Epoch 146: val_loss did not improve from 402.71365
196/196 - 9s - loss: 404.8008 - MinusLogProbMetric: 404.8008 - val_loss: 409.2979 - val_MinusLogProbMetric: 409.2979 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 147/1000
2023-09-09 23:00:52.549 
Epoch 147/1000 
	 loss: 403.9317, MinusLogProbMetric: 403.9317, val_loss: 404.1184, val_MinusLogProbMetric: 404.1184

Epoch 147: val_loss did not improve from 402.71365
196/196 - 9s - loss: 403.9317 - MinusLogProbMetric: 403.9317 - val_loss: 404.1184 - val_MinusLogProbMetric: 404.1184 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 148/1000
2023-09-09 23:01:02.004 
Epoch 148/1000 
	 loss: 404.3268, MinusLogProbMetric: 404.3268, val_loss: 407.3741, val_MinusLogProbMetric: 407.3741

Epoch 148: val_loss did not improve from 402.71365
196/196 - 9s - loss: 404.3268 - MinusLogProbMetric: 404.3268 - val_loss: 407.3741 - val_MinusLogProbMetric: 407.3741 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 149/1000
2023-09-09 23:01:10.894 
Epoch 149/1000 
	 loss: 404.2488, MinusLogProbMetric: 404.2488, val_loss: 410.1484, val_MinusLogProbMetric: 410.1484

Epoch 149: val_loss did not improve from 402.71365
196/196 - 9s - loss: 404.2488 - MinusLogProbMetric: 404.2488 - val_loss: 410.1484 - val_MinusLogProbMetric: 410.1484 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 150/1000
2023-09-09 23:01:20.429 
Epoch 150/1000 
	 loss: 403.6505, MinusLogProbMetric: 403.6505, val_loss: 406.8249, val_MinusLogProbMetric: 406.8249

Epoch 150: val_loss did not improve from 402.71365
196/196 - 10s - loss: 403.6505 - MinusLogProbMetric: 403.6505 - val_loss: 406.8249 - val_MinusLogProbMetric: 406.8249 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 151/1000
2023-09-09 23:01:29.605 
Epoch 151/1000 
	 loss: 405.0988, MinusLogProbMetric: 405.0988, val_loss: 413.2472, val_MinusLogProbMetric: 413.2472

Epoch 151: val_loss did not improve from 402.71365
196/196 - 9s - loss: 405.0988 - MinusLogProbMetric: 405.0988 - val_loss: 413.2472 - val_MinusLogProbMetric: 413.2472 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 152/1000
2023-09-09 23:01:38.834 
Epoch 152/1000 
	 loss: 403.5646, MinusLogProbMetric: 403.5646, val_loss: 404.9293, val_MinusLogProbMetric: 404.9293

Epoch 152: val_loss did not improve from 402.71365
196/196 - 9s - loss: 403.5646 - MinusLogProbMetric: 403.5646 - val_loss: 404.9293 - val_MinusLogProbMetric: 404.9293 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 153/1000
2023-09-09 23:01:47.893 
Epoch 153/1000 
	 loss: 403.7022, MinusLogProbMetric: 403.7022, val_loss: 406.2740, val_MinusLogProbMetric: 406.2740

Epoch 153: val_loss did not improve from 402.71365
196/196 - 9s - loss: 403.7022 - MinusLogProbMetric: 403.7022 - val_loss: 406.2740 - val_MinusLogProbMetric: 406.2740 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 154/1000
2023-09-09 23:01:57.406 
Epoch 154/1000 
	 loss: 407.3399, MinusLogProbMetric: 407.3399, val_loss: 408.6048, val_MinusLogProbMetric: 408.6048

Epoch 154: val_loss did not improve from 402.71365
196/196 - 10s - loss: 407.3399 - MinusLogProbMetric: 407.3399 - val_loss: 408.6048 - val_MinusLogProbMetric: 408.6048 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 155/1000
2023-09-09 23:02:06.044 
Epoch 155/1000 
	 loss: 402.9127, MinusLogProbMetric: 402.9127, val_loss: 406.5141, val_MinusLogProbMetric: 406.5141

Epoch 155: val_loss did not improve from 402.71365
196/196 - 9s - loss: 402.9127 - MinusLogProbMetric: 402.9127 - val_loss: 406.5141 - val_MinusLogProbMetric: 406.5141 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 156/1000
2023-09-09 23:02:15.813 
Epoch 156/1000 
	 loss: 403.2881, MinusLogProbMetric: 403.2881, val_loss: 415.1717, val_MinusLogProbMetric: 415.1717

Epoch 156: val_loss did not improve from 402.71365
196/196 - 10s - loss: 403.2881 - MinusLogProbMetric: 403.2881 - val_loss: 415.1717 - val_MinusLogProbMetric: 415.1717 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 157/1000
2023-09-09 23:02:24.562 
Epoch 157/1000 
	 loss: 405.3849, MinusLogProbMetric: 405.3849, val_loss: 400.9859, val_MinusLogProbMetric: 400.9859

Epoch 157: val_loss improved from 402.71365 to 400.98593, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 405.3849 - MinusLogProbMetric: 405.3849 - val_loss: 400.9859 - val_MinusLogProbMetric: 400.9859 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 158/1000
2023-09-09 23:02:34.673 
Epoch 158/1000 
	 loss: 405.5516, MinusLogProbMetric: 405.5516, val_loss: 401.4288, val_MinusLogProbMetric: 401.4288

Epoch 158: val_loss did not improve from 400.98593
196/196 - 10s - loss: 405.5516 - MinusLogProbMetric: 405.5516 - val_loss: 401.4288 - val_MinusLogProbMetric: 401.4288 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 159/1000
2023-09-09 23:02:43.520 
Epoch 159/1000 
	 loss: 403.2591, MinusLogProbMetric: 403.2591, val_loss: 403.8504, val_MinusLogProbMetric: 403.8504

Epoch 159: val_loss did not improve from 400.98593
196/196 - 9s - loss: 403.2591 - MinusLogProbMetric: 403.2591 - val_loss: 403.8504 - val_MinusLogProbMetric: 403.8504 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 160/1000
2023-09-09 23:02:53.468 
Epoch 160/1000 
	 loss: 402.6430, MinusLogProbMetric: 402.6430, val_loss: 407.1440, val_MinusLogProbMetric: 407.1440

Epoch 160: val_loss did not improve from 400.98593
196/196 - 10s - loss: 402.6430 - MinusLogProbMetric: 402.6430 - val_loss: 407.1440 - val_MinusLogProbMetric: 407.1440 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 161/1000
2023-09-09 23:03:02.031 
Epoch 161/1000 
	 loss: 403.6702, MinusLogProbMetric: 403.6702, val_loss: 402.0725, val_MinusLogProbMetric: 402.0725

Epoch 161: val_loss did not improve from 400.98593
196/196 - 9s - loss: 403.6702 - MinusLogProbMetric: 403.6702 - val_loss: 402.0725 - val_MinusLogProbMetric: 402.0725 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 162/1000
2023-09-09 23:03:11.158 
Epoch 162/1000 
	 loss: 404.9981, MinusLogProbMetric: 404.9981, val_loss: 401.6261, val_MinusLogProbMetric: 401.6261

Epoch 162: val_loss did not improve from 400.98593
196/196 - 9s - loss: 404.9981 - MinusLogProbMetric: 404.9981 - val_loss: 401.6261 - val_MinusLogProbMetric: 401.6261 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 163/1000
2023-09-09 23:03:19.476 
Epoch 163/1000 
	 loss: 402.1861, MinusLogProbMetric: 402.1861, val_loss: 403.5789, val_MinusLogProbMetric: 403.5789

Epoch 163: val_loss did not improve from 400.98593
196/196 - 8s - loss: 402.1861 - MinusLogProbMetric: 402.1861 - val_loss: 403.5789 - val_MinusLogProbMetric: 403.5789 - lr: 0.0010 - 8s/epoch - 42ms/step
Epoch 164/1000
2023-09-09 23:03:28.214 
Epoch 164/1000 
	 loss: 403.1432, MinusLogProbMetric: 403.1432, val_loss: 407.3579, val_MinusLogProbMetric: 407.3579

Epoch 164: val_loss did not improve from 400.98593
196/196 - 9s - loss: 403.1432 - MinusLogProbMetric: 403.1432 - val_loss: 407.3579 - val_MinusLogProbMetric: 407.3579 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 165/1000
2023-09-09 23:03:36.827 
Epoch 165/1000 
	 loss: 403.0684, MinusLogProbMetric: 403.0684, val_loss: 412.4049, val_MinusLogProbMetric: 412.4049

Epoch 165: val_loss did not improve from 400.98593
196/196 - 9s - loss: 403.0684 - MinusLogProbMetric: 403.0684 - val_loss: 412.4049 - val_MinusLogProbMetric: 412.4049 - lr: 0.0010 - 9s/epoch - 44ms/step
Epoch 166/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 70: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-09 23:03:40.559 
Epoch 166/1000 
	 loss: inf, MinusLogProbMetric: 92035126119592885472011875254272.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 166: val_loss did not improve from 400.98593
196/196 - 4s - loss: inf - MinusLogProbMetric: 92035126119592885472011875254272.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 4s/epoch - 19ms/step
The loss history contains Inf values.
Training failed: trying again with seed 326159 and lr 0.0003333333333333333.
===========
Generating train data for run 329.
===========
Train data generated in 2.60 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_329/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_329/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_329/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_329
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.437488    7.1322474   6.533019   ...  9.559031    1.9697884
   6.253516  ]
 [ 6.105814   -0.33694893  4.861082   ...  4.728712    6.8399925
   2.9518385 ]
 [ 5.5099134   8.416618    3.6192868  ... 10.13037     0.5513004
   6.6116333 ]
 ...
 [ 8.378759    5.1539607   5.2823405  ...  4.1604185   7.9323363
   6.8563857 ]
 [ 8.088472    5.184855    5.311574   ...  3.8879027   7.132432
   7.66768   ]
 [ 5.6874776   6.932827    6.1243634  ...  9.540177    3.2688973
   7.1452303 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 1000)]            0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  2095760   
 yer)                                                            
                                                                 
=================================================================
Total params: 2,095,760
Trainable params: 2,095,760
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7effebd6d840>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effed5664d0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effed5664d0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effed511f60>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7effed3c8d60>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7effed3c9240>, <keras.callbacks.ModelCheckpoint object at 0x7effed3c9300>, <keras.callbacks.EarlyStopping object at 0x7effed3c9570>, <keras.callbacks.ReduceLROnPlateau object at 0x7effed3c95a0>, <keras.callbacks.TerminateOnNaN object at 0x7effed3c91e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 329/360 with hyperparameters:
timestamp = 2023-09-09 23:03:46.130365
ndims = 1000
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 2095760
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 5.43748808e+00  7.13224745e+00  6.53301907e+00  5.31066608e+00
  3.79545021e+00  6.28738737e+00  2.71391177e+00  8.88872051e+00
  9.43951797e+00  4.12179470e+00  7.81367683e+00  5.36657619e+00
  5.55121899e+00  9.56866932e+00  7.94146359e-01  9.63486314e-01
 -1.46448463e-02  7.97977352e+00  8.35143089e+00  9.09444618e+00
  9.51050758e+00  8.15759563e+00  4.87677431e+00  8.12364483e+00
 -5.86649776e-01  6.22392607e+00  1.30506945e+00  9.45408440e+00
  7.08888865e+00  3.35072994e+00  2.25734115e+00  8.41814995e+00
  4.58319330e+00  5.61194181e+00  2.26602942e-01  5.45686245e+00
  6.14353561e+00  6.25023174e+00  9.57346344e+00  6.36795044e+00
  3.20757818e+00  4.83043623e+00  7.51926565e+00  6.34396672e-01
  6.89045191e+00  6.62100124e+00  2.44563007e+00  1.28772116e+00
  3.22250342e+00  4.52788544e+00  5.89035130e+00  4.86346960e+00
  9.48264980e+00 -1.13163722e+00  3.37091446e+00  9.05362010e-01
  6.78129101e+00  1.94818664e+00  4.17912102e+00  3.18960547e+00
  1.62776482e+00  1.21974039e+00  7.33607817e+00  1.62089002e+00
  2.96397400e+00  4.52560091e+00  8.39162827e+00  1.51216686e+00
  8.25380135e+00  5.98394752e-01  9.67017937e+00  4.48699141e+00
  1.02882853e+01  5.70898390e+00  6.28753185e+00  6.97938085e-01
  2.82613039e+00  1.18152845e+00  2.21910620e+00  1.18442059e-01
  3.30913496e+00  4.37123442e+00 -6.00820422e-01  7.13190508e+00
  5.83363104e+00  2.43325353e+00  5.20436668e+00  1.77731943e+00
  6.29233789e+00  9.14511585e+00  2.47849083e+00  7.14207220e+00
  1.59640992e+00  7.87721014e+00  3.72595000e+00  1.65804911e+00
  6.26306725e+00  6.14266574e-01  9.35802937e+00 -5.55100851e-02
  6.81794071e+00  2.07937002e+00  7.28380156e+00  1.05093136e+01
  1.40520501e+00  5.19018650e+00  6.29479265e+00  5.23412371e+00
  2.19359255e+00  9.70839596e+00  4.63605547e+00  9.80713272e+00
  6.71604156e+00  2.83194685e+00  8.21691513e+00  3.91888070e+00
  8.82857418e+00  5.65095377e+00  7.74853373e+00  6.66070604e+00
  8.72240067e+00  4.82063627e+00  9.65159893e+00  7.37593651e+00
  5.52394199e+00  6.06229258e+00  6.28078938e-01  3.63155842e+00
  6.63515043e+00  3.13720345e+00  6.10160494e+00  4.59917688e+00
  1.67009079e+00  2.67929316e+00  5.87469530e+00  5.35120296e+00
  5.20565653e+00  6.30662727e+00  7.39564276e+00  4.35430813e+00
  8.88551044e+00  2.87358689e+00  4.32844305e+00  9.07120323e+00
  8.34959602e+00  6.54305315e+00  6.36145771e-01  9.69855213e+00
  6.49582243e+00  1.02082977e+01  1.42218649e+00  7.77432966e+00
  1.58041847e+00  6.40702820e+00  1.07924449e+00  8.47589207e+00
  8.23396206e+00  5.41745853e+00  3.85215545e+00  7.45270491e-01
  6.41533756e+00  4.21811962e+00  7.45381451e+00  8.68435764e+00
  9.59165764e+00  9.22718906e+00 -1.01518297e+00  4.78479671e+00
  7.09206533e+00  2.16092372e+00  5.71304035e+00  1.19908273e-01
  3.16043782e+00  9.20669734e-02  8.17029667e+00  2.31537890e+00
  3.80825901e+00  9.06393814e+00  7.17630625e+00  1.20758474e-01
  1.57467747e+00  6.56413174e+00  5.80603886e+00  1.90417314e+00
  9.26850033e+00  5.71055651e+00  5.48348093e+00  5.70006657e+00
  7.34501457e+00  3.06974077e+00  4.17449951e+00  1.88637686e+00
  1.59649813e+00  8.74714470e+00  7.68149471e+00  5.14725018e+00
  1.94792962e+00  2.93671155e+00  6.94045722e-01  4.93041849e+00
  2.29451370e+00  6.96200371e+00  2.94133329e+00  7.65987992e-01
 -2.16490626e-02  6.85447574e-01  6.85941124e+00  4.85409117e+00
  5.72059441e+00  8.98723507e+00  9.62737179e+00  2.21571255e+00
  6.79449415e+00  2.29369974e+00  5.30113637e-01  7.87245512e+00
  3.63518763e+00  4.00529575e+00  5.20808411e+00  8.23005772e+00
  6.37014103e+00  8.26017952e+00  3.29657626e+00  7.93651295e+00
  1.78429985e+00  9.56696796e+00  7.06810617e+00  2.25382471e+00
  9.54646778e+00  7.23986912e+00  2.52804947e+00  2.58364177e+00
  5.52888250e+00  1.77395463e-01  2.06791592e+00  4.35356903e+00
  3.59637356e+00  3.74388838e+00  2.40446615e+00  5.81385517e+00
  8.67110729e+00  1.17576969e+00  4.94048452e+00  9.40345764e-01
  6.09276962e+00  3.86963511e+00  6.18902493e+00  1.56115341e+00
  2.90525699e+00  4.87162495e+00  3.71526504e+00  9.40074253e+00
  7.42161226e+00  7.27192879e+00  1.00699673e+01  1.18854022e+00
  5.78801632e+00  5.48251772e+00  9.94960403e+00  2.90021896e+00
  4.43213892e+00  4.77912188e-01  3.98015082e-01  1.12766476e+01
  6.74848080e+00  7.22801781e+00  2.82795882e+00  5.88993359e+00
  6.98136806e-01  3.23450828e+00  9.72003841e+00  8.30174351e+00
  3.07273555e+00  9.91379070e+00  1.91660452e+00  9.71661282e+00
  9.90089893e+00  8.15846062e+00  7.03740978e+00  9.58544540e+00
  2.93002963e+00  8.31967926e+00  5.99808025e+00  7.28550479e-02
  3.85735941e+00  9.70761538e-01  9.23753738e+00  5.46686459e+00
  5.50278473e+00  6.01728964e+00  4.34324074e+00  1.36993062e+00
  8.45484543e+00  4.68175888e-01  5.26911163e+00  1.84141123e+00
  3.81864011e-01  7.90763950e+00  9.70255852e+00  9.84720516e+00
  9.43443680e+00  7.68962574e+00  3.80397248e+00  6.65612042e-01
  5.16863966e+00  2.47927332e+00  4.73985672e-01  1.05347097e+00
  7.32991314e+00  9.36276674e-01  7.35460091e+00  1.67862105e+00
  4.33905751e-01  1.59291720e+00  7.84084034e+00  2.43011403e+00
  4.25165033e+00  5.68983269e+00  8.60872746e+00  7.16398525e+00
  2.72054410e+00  1.94252491e+00 -1.85395658e-01  3.34451747e+00
  1.99218881e+00  3.79499388e+00  5.96836662e+00  7.37168837e+00
  2.49210262e+00  3.98509121e+00  9.37832177e-01  8.80943108e+00
  2.57825583e-01  6.98963022e+00  7.78174019e+00  7.89891291e+00
  2.61566496e+00  3.04674053e+00  6.46863794e+00  2.90103054e+00
  4.06367350e+00  2.83596921e+00  5.16630077e+00  6.22896612e-01
  7.82478142e+00  3.80227089e-01  3.55100584e+00  3.55920887e+00
  5.84608507e+00  9.32784271e+00  6.44432068e+00  6.71383977e-01
  3.80863142e+00  5.12159157e+00  5.26213694e+00  6.50915527e+00
  3.31823993e+00  1.51588440e+00  3.74508786e+00  9.63789845e+00
  2.82012701e+00  9.30117702e+00  5.18297386e+00  5.08122492e+00
  9.10340309e+00  4.14017344e+00  8.16922951e+00  3.49889684e+00
  9.15036392e+00  7.04796791e+00  6.91863298e+00  3.43821239e+00
  7.49771976e+00  6.58094883e+00  1.52206314e+00  1.66219306e+00
  8.96467304e+00  9.71891689e+00  6.03888035e+00  6.12453365e+00
  8.36337280e+00  4.72068548e+00  7.40723658e+00  4.66089344e+00
  9.60812855e+00  1.02327881e+01  8.27917576e+00  1.76802504e+00
  5.86829615e+00  4.09585905e+00 -5.26962698e-01  4.35076141e+00
  2.46013212e+00  8.68481445e+00  3.86820614e-01  9.69470692e+00
  3.67586684e+00  3.92413521e+00 -9.84535664e-02  2.63078451e+00
  4.00670385e+00  1.10941935e+01  5.17772198e-01  9.30033970e+00
  9.24112511e+00  2.92216539e+00  3.37561965e+00  2.46589732e+00
  6.14229774e+00  4.67309088e-01 -8.67828280e-02  4.08560181e+00
  3.99175465e-01  2.54151607e+00  2.21575212e+00  2.50912642e+00
  1.27955842e+00 -7.25474238e-01  8.21681261e-01  6.53614998e+00
  1.04211264e+01  9.34315395e+00  3.89995766e+00  3.41503716e+00
  6.30898190e+00  4.78263617e+00  1.00384960e+01  1.44826126e+00
  8.01760387e+00  3.30487871e+00  2.22230029e+00  6.98749399e+00
  2.56673408e+00  6.51266956e+00  5.16357517e+00  4.21222687e+00
  5.53316402e+00  2.87564898e+00  6.88569880e+00  5.24295902e+00
  3.83784485e+00  8.63262177e+00  9.42399979e+00  4.50341552e-01
  2.33270240e+00  2.46700525e+00  8.57210445e+00  9.93498421e+00
  9.70180130e+00  9.04918671e+00  2.82848668e+00  1.01604681e+01
  2.13376069e+00  1.08001816e+00  1.01585007e+01  2.37143421e+00
  6.89639854e+00  6.13785625e-01  6.39277411e+00  8.98899841e+00
  3.29311657e+00  3.45347357e+00  3.81167507e+00  7.88749123e+00
  1.59779358e+00  5.66715002e-01  4.65487051e+00  4.15191126e+00
  8.22690773e+00  2.27221990e+00  5.74325514e+00  9.80365372e+00
  6.51945877e+00  8.45271111e+00  9.52017021e+00  7.24792719e+00
  6.43911409e+00  8.51561165e+00  1.02915831e+01  4.50498724e+00
  9.14542615e-01  2.86150455e+00  2.13800192e-01  3.66317129e+00
  1.32120097e+00  6.51088238e+00  3.09616232e+00  9.20569038e+00
  9.73210716e+00  5.21707201e+00  3.67960548e+00  5.34920645e+00
  8.44879818e+00  4.15654373e+00  5.51069403e+00  2.64717555e+00
  4.56229973e+00  4.03184319e+00  2.53720236e+00  4.99534702e+00
  2.31029892e+00  3.48865128e+00  8.25072670e+00  7.54355812e+00
  2.20225477e+00  1.13970642e+01  8.49588680e+00  7.10883319e-01
  2.74363828e+00  4.99293470e+00  1.34385705e-01  3.21501279e+00
  8.21650314e+00  6.79964018e+00  6.27488852e+00  7.14794111e+00
  1.90239477e+00  3.45294881e+00  7.35099411e+00  9.33995914e+00
  6.05294037e+00  2.90113711e+00 -1.24432337e+00  6.42705727e+00
  5.68964370e-02  3.37960458e+00  4.96043348e+00  9.90640545e+00
  1.23383534e+00  4.00741386e+00  6.40055537e-03  3.24708557e+00
  6.32790136e+00  2.19222999e+00  2.08447242e+00  1.32372677e+00
  5.92049932e+00  6.88256168e+00  7.01928997e+00  1.04399967e+01
 -2.88216442e-01  6.52927542e+00  6.16809750e+00  6.00324678e+00
  9.71869183e+00  1.13557257e-01  7.11323690e+00  7.71879911e+00
  5.03887224e+00  3.76561260e+00  8.05337811e+00  3.14987302e-01
  5.12668896e+00  5.27989054e+00  6.75082159e+00  1.43525863e+00
  2.57989788e+00  4.62727022e+00  6.04563522e+00  9.48542213e+00
  7.09511852e+00  1.17622685e+00  9.15441227e+00  9.80256653e+00
  5.09900427e+00  9.44795132e+00  5.51893759e+00  1.03330717e+01
  8.30469704e+00  1.07898369e+01  1.01827803e+01 -5.05745411e-04
  1.73885703e+00  3.52059174e+00  9.45347977e+00  3.41492081e+00
  1.14690316e+00  9.65928459e+00  4.69807243e+00  9.03562832e+00
  1.17234612e+00  6.69798565e+00  4.43081808e+00  8.74517798e-01
  6.92903471e+00  2.09807229e+00 -7.14968681e-01  5.73539436e-01
  6.28464758e-01  8.92654991e+00  8.03050327e+00  9.02817154e+00
  7.40084696e+00  5.17232370e+00  3.25738239e+00  1.01524630e+01
  3.55576420e+00  3.88637328e+00  4.20779133e+00  8.97262955e+00
  1.70729637e+00  3.30006480e+00  5.26616716e+00  9.60324168e-01
  6.40397358e+00  4.05875492e+00  2.62214065e+00  2.05707121e+00
  4.09347248e+00  3.94071198e+00  5.06777287e+00  3.40968561e+00
  8.99762726e+00  1.47003901e+00  8.83282781e-01  3.52675414e+00
  5.27389050e+00  6.61437607e+00  5.19436264e+00  9.38774395e+00
  3.59817815e+00  7.51900101e+00  6.17228937e+00  8.14072514e+00
  1.00964031e+01  8.67543316e+00  7.67522526e+00  6.90801048e+00
  3.51598859e+00  5.34878731e-01  6.36672795e-01  2.41127205e+00
  3.82626390e+00  5.18385172e+00  5.83661032e+00  9.15472126e+00
  8.23223293e-01  2.42483902e+00  5.41429329e+00  8.00633621e+00
  7.98597336e+00  9.41291142e+00  9.83840275e+00  4.71966314e+00
  4.63481140e+00  4.06945586e-01  6.68186712e+00  6.24139881e+00
  8.50881863e+00  7.10938215e-01  4.35715389e+00  5.98537350e+00
  2.39591932e+00  1.52024806e+00  9.15522194e+00  1.84586793e-01
  3.84848523e+00  1.13246572e+00  4.45568275e+00  9.84170437e+00
  4.21756744e+00  6.01763248e+00  7.27610350e-01  3.31445408e+00
  4.36259508e+00  4.26714516e+00  6.67291355e+00  3.47573233e+00
  6.96841526e+00  6.61320925e+00  4.78718519e+00  3.85241342e+00
  5.65875959e+00  9.63071108e-01  8.21956635e+00  7.05007601e+00
  7.35808372e+00  5.60682201e+00  8.74726832e-01  4.78749466e+00
  4.08274555e+00  3.05295515e+00 -2.82806456e-02  7.37880754e+00
  1.13245630e+00  6.21132517e+00  7.19738770e+00  6.62598848e+00
  8.44676971e+00  7.01955557e-01  8.75954437e+00  1.91597685e-01
  6.34029531e+00  4.09656525e+00  4.70814228e+00  3.66343403e+00
  1.92009354e+00 -2.97656119e-01  4.93795109e+00  7.03719902e+00
  3.54990387e+00  2.22650814e+00  1.47342825e+00  1.87733543e+00
  9.82225418e-01  1.97523093e+00  2.90856576e+00 -1.95377409e-01
  7.63740540e-01  8.23801708e+00  1.92524207e+00  4.57951069e+00
  8.07519722e+00  4.80337429e+00  1.63165092e+00  2.09296656e+00
  4.45628262e+00  5.24322176e+00  3.30323172e+00  7.77983236e+00
  7.60303879e+00  8.98269558e+00  3.17642242e-01  9.00031185e+00
  3.89518857e+00  8.87557316e+00  6.54464340e+00  9.40222740e+00
  7.76669884e+00  3.63010335e+00  4.89937687e+00  3.79815769e+00
  3.43109441e+00  2.11776972e+00  4.50608540e+00  6.73585749e+00
  2.77784801e+00  4.75118494e+00  1.41163933e+00  1.43678403e+00
  4.72844005e-01  1.01116915e+01  4.33705822e-02  1.87914848e+00
  6.03755856e+00  1.65911603e+00  9.08522511e+00  7.11956310e+00
  8.27528858e+00  4.67179298e+00  1.46821272e+00  5.57443333e+00
  9.03736591e+00  7.08154297e+00  2.92699647e+00  9.28951740e+00
  3.66812515e+00  1.79973990e-02  2.40762663e+00  1.92846382e+00
  8.69157314e+00  4.33280611e+00  4.23879671e+00  3.11560988e+00
  9.60638237e+00  1.10599823e+01  9.74016571e+00  3.66849303e+00
  9.42271328e+00  8.38017178e+00  6.39697123e+00  3.64649916e+00
  1.97412837e+00  2.19269991e+00  9.55885601e+00  2.80885458e+00
  4.91888142e+00  5.15744495e+00  8.31021786e+00  8.34845829e+00
  1.55545843e+00  3.92147779e+00  8.22108078e+00  7.88888502e+00
  1.22066307e+00  1.52498245e+00  3.15602779e+00  9.93907928e-01
  4.50527048e+00  1.36449265e+00  5.00522995e+00  2.42850351e+00
  5.87198400e+00 -1.04476917e+00  9.73143959e+00  9.51038170e+00
  4.31158495e+00  3.61805153e+00  1.88797522e+00  5.04972935e+00
  4.03085709e-01  4.60245562e+00  3.75540328e+00  4.01810455e+00
  8.59900475e+00  7.06478453e+00  9.62819099e+00  3.01856041e+00
  9.00697613e+00  8.57353497e+00  4.79125214e+00  6.26140499e+00
  2.85231853e+00  1.06102486e+01  1.06103802e+00  2.18488646e+00
  3.15353966e+00  4.29014683e+00  7.35634613e+00  5.12752581e+00
  4.86164331e+00  6.53155148e-01  5.14040470e+00  5.27053058e-01
  1.85232019e+00  9.85549164e+00  2.36561966e+00  8.83290672e+00
  8.07797718e+00  2.24759030e+00  5.88459301e+00  1.65719461e+00
  7.13856363e+00  6.36659193e+00  8.30550766e+00  4.64638376e+00
  8.86743259e+00 -1.78816348e-01  2.12690020e+00  7.22018147e+00
  4.37131548e+00  1.50182629e+00  1.44224501e+00  8.23597240e+00
  2.87912059e+00  8.82868195e+00  6.72185993e+00  4.10417318e+00
  3.72402120e+00  4.76707935e+00  8.69713497e+00  8.02846813e+00
 -5.91852479e-02  6.92536926e+00  9.99452686e+00  7.10508966e+00
  1.77003264e+00  5.62554789e+00  1.03404069e+00  4.70238781e+00
  9.31285954e+00  8.93695068e+00  2.82111669e+00  3.46559119e+00
  6.18987942e+00  9.39866257e+00  5.47782779e-01  2.72644186e+00
  8.94318962e+00  4.69057751e+00  1.03748589e+01  2.52786398e+00
  5.76243114e+00  3.48165631e+00  3.81163502e+00  3.76940107e+00
  4.03297091e+00  4.00298834e+00  8.04087162e+00  7.70173693e+00
  7.10223532e+00  3.21729660e+00  5.74228382e+00  6.87862539e+00
  7.01803017e+00  3.45543861e+00  7.26741600e+00  7.03988886e+00
  1.35023844e+00  8.91982746e+00  4.43680811e+00  5.25290489e+00
  3.51280975e+00  6.24143553e+00  6.52131414e+00  4.72280169e+00
  8.25355721e+00  6.25390244e+00  5.13515329e+00  4.87421942e+00
  7.67947769e+00  3.34088635e+00  2.31048179e+00  4.33013082e-01
  8.68751335e+00  9.47573662e+00  1.55903900e+00  3.07618022e+00
  1.50216174e+00  1.19446433e+00  9.29029846e+00  1.65662837e+00
  9.56382942e+00  9.47769403e-01  8.08623123e+00  5.85028315e+00
  4.43489981e+00  3.51404214e+00  7.59146261e+00  3.24519110e+00
  6.24453449e+00  3.84153080e+00  4.75549126e+00  8.96583271e+00
  5.54600143e+00  7.46122551e+00  6.96567345e+00  4.11713839e-01
  7.67649698e+00  2.08050108e+00  9.21236324e+00  1.41680741e+00
  3.03086996e+00  1.13182259e+00  4.03754902e+00  8.78156567e+00
  2.95456624e+00  1.61442590e+00  3.30749226e+00  8.14694023e+00
  1.37203860e+00  1.63373399e+00  6.45686090e-01  7.07791662e+00
  3.06980824e+00  4.66480160e+00  7.18863678e+00  3.41025472e+00
  7.26521921e+00  7.07599974e+00  2.82888842e+00  1.03278141e+01
  1.74131536e+00  2.78822184e+00  1.28855526e+00  3.68360829e+00
  5.39412928e+00  5.52329063e+00  8.01896572e+00  8.91389751e+00
  2.46595716e+00  6.16491985e+00  1.14002132e+00  3.73238707e+00
  3.28532362e+00  2.97972035e+00  4.97999954e+00  7.17574263e+00
  7.50538170e-01  1.02770720e+01  7.28148460e+00  2.06288123e+00
  9.35947418e+00  5.11205769e+00  9.92250729e+00  1.66801298e+00
  3.66859484e+00  3.06588221e+00  3.05286908e+00  5.87349463e+00
  9.89076328e+00  8.08929062e+00  6.18565559e+00  5.57329512e+00
  9.22900391e+00  3.96593451e+00  8.75203419e+00  8.35547829e+00
  2.17680025e+00  7.65000153e+00  1.08980224e-01  3.05595231e+00
  2.58785725e+00  5.23494005e+00  7.61446953e+00  4.45858717e-01
  4.63132048e+00  9.55903053e+00  1.96978843e+00  6.25351620e+00]
Epoch 1/1000
2023-09-09 23:04:29.508 
Epoch 1/1000 
	 loss: 431.5643, MinusLogProbMetric: 431.5643, val_loss: 400.0999, val_MinusLogProbMetric: 400.0999

Epoch 1: val_loss improved from inf to 400.09991, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 43s - loss: 431.5643 - MinusLogProbMetric: 431.5643 - val_loss: 400.0999 - val_MinusLogProbMetric: 400.0999 - lr: 3.3333e-04 - 43s/epoch - 221ms/step
Epoch 2/1000
2023-09-09 23:04:38.336 
Epoch 2/1000 
	 loss: 398.7733, MinusLogProbMetric: 398.7733, val_loss: 398.8551, val_MinusLogProbMetric: 398.8551

Epoch 2: val_loss improved from 400.09991 to 398.85510, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 398.7733 - MinusLogProbMetric: 398.7733 - val_loss: 398.8551 - val_MinusLogProbMetric: 398.8551 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 3/1000
2023-09-09 23:04:48.808 
Epoch 3/1000 
	 loss: 398.6269, MinusLogProbMetric: 398.6269, val_loss: 399.2496, val_MinusLogProbMetric: 399.2496

Epoch 3: val_loss did not improve from 398.85510
196/196 - 10s - loss: 398.6269 - MinusLogProbMetric: 398.6269 - val_loss: 399.2496 - val_MinusLogProbMetric: 399.2496 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 4/1000
2023-09-09 23:04:58.331 
Epoch 4/1000 
	 loss: 398.8825, MinusLogProbMetric: 398.8825, val_loss: 398.8062, val_MinusLogProbMetric: 398.8062

Epoch 4: val_loss improved from 398.85510 to 398.80624, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 398.8825 - MinusLogProbMetric: 398.8825 - val_loss: 398.8062 - val_MinusLogProbMetric: 398.8062 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 5/1000
2023-09-09 23:05:07.570 
Epoch 5/1000 
	 loss: 398.6793, MinusLogProbMetric: 398.6793, val_loss: 399.2713, val_MinusLogProbMetric: 399.2713

Epoch 5: val_loss did not improve from 398.80624
196/196 - 9s - loss: 398.6793 - MinusLogProbMetric: 398.6793 - val_loss: 399.2713 - val_MinusLogProbMetric: 399.2713 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 6/1000
2023-09-09 23:05:16.830 
Epoch 6/1000 
	 loss: 399.3009, MinusLogProbMetric: 399.3009, val_loss: 398.5331, val_MinusLogProbMetric: 398.5331

Epoch 6: val_loss improved from 398.80624 to 398.53314, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 399.3009 - MinusLogProbMetric: 399.3009 - val_loss: 398.5331 - val_MinusLogProbMetric: 398.5331 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 7/1000
2023-09-09 23:05:25.942 
Epoch 7/1000 
	 loss: 399.6925, MinusLogProbMetric: 399.6925, val_loss: 398.7694, val_MinusLogProbMetric: 398.7694

Epoch 7: val_loss did not improve from 398.53314
196/196 - 9s - loss: 399.6925 - MinusLogProbMetric: 399.6925 - val_loss: 398.7694 - val_MinusLogProbMetric: 398.7694 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 8/1000
2023-09-09 23:05:35.159 
Epoch 8/1000 
	 loss: 400.5883, MinusLogProbMetric: 400.5883, val_loss: 401.9498, val_MinusLogProbMetric: 401.9498

Epoch 8: val_loss did not improve from 398.53314
196/196 - 9s - loss: 400.5883 - MinusLogProbMetric: 400.5883 - val_loss: 401.9498 - val_MinusLogProbMetric: 401.9498 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 9/1000
2023-09-09 23:05:43.903 
Epoch 9/1000 
	 loss: 398.1645, MinusLogProbMetric: 398.1645, val_loss: 400.3341, val_MinusLogProbMetric: 400.3341

Epoch 9: val_loss did not improve from 398.53314
196/196 - 9s - loss: 398.1645 - MinusLogProbMetric: 398.1645 - val_loss: 400.3341 - val_MinusLogProbMetric: 400.3341 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 10/1000
2023-09-09 23:05:53.544 
Epoch 10/1000 
	 loss: 399.5630, MinusLogProbMetric: 399.5630, val_loss: 399.8693, val_MinusLogProbMetric: 399.8693

Epoch 10: val_loss did not improve from 398.53314
196/196 - 10s - loss: 399.5630 - MinusLogProbMetric: 399.5630 - val_loss: 399.8693 - val_MinusLogProbMetric: 399.8693 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 11/1000
2023-09-09 23:06:02.229 
Epoch 11/1000 
	 loss: 399.0789, MinusLogProbMetric: 399.0789, val_loss: 398.6331, val_MinusLogProbMetric: 398.6331

Epoch 11: val_loss did not improve from 398.53314
196/196 - 9s - loss: 399.0789 - MinusLogProbMetric: 399.0789 - val_loss: 398.6331 - val_MinusLogProbMetric: 398.6331 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 12/1000
2023-09-09 23:06:11.813 
Epoch 12/1000 
	 loss: 399.5362, MinusLogProbMetric: 399.5362, val_loss: 406.8012, val_MinusLogProbMetric: 406.8012

Epoch 12: val_loss did not improve from 398.53314
196/196 - 10s - loss: 399.5362 - MinusLogProbMetric: 399.5362 - val_loss: 406.8012 - val_MinusLogProbMetric: 406.8012 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 13/1000
2023-09-09 23:06:20.243 
Epoch 13/1000 
	 loss: 400.1498, MinusLogProbMetric: 400.1498, val_loss: 400.9222, val_MinusLogProbMetric: 400.9222

Epoch 13: val_loss did not improve from 398.53314
196/196 - 8s - loss: 400.1498 - MinusLogProbMetric: 400.1498 - val_loss: 400.9222 - val_MinusLogProbMetric: 400.9222 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 14/1000
2023-09-09 23:06:29.645 
Epoch 14/1000 
	 loss: 397.6278, MinusLogProbMetric: 397.6278, val_loss: 398.2129, val_MinusLogProbMetric: 398.2129

Epoch 14: val_loss improved from 398.53314 to 398.21289, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 397.6278 - MinusLogProbMetric: 397.6278 - val_loss: 398.2129 - val_MinusLogProbMetric: 398.2129 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 15/1000
2023-09-09 23:06:39.153 
Epoch 15/1000 
	 loss: 399.3012, MinusLogProbMetric: 399.3012, val_loss: 398.1235, val_MinusLogProbMetric: 398.1235

Epoch 15: val_loss improved from 398.21289 to 398.12354, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 399.3012 - MinusLogProbMetric: 399.3012 - val_loss: 398.1235 - val_MinusLogProbMetric: 398.1235 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 16/1000
2023-09-09 23:06:48.084 
Epoch 16/1000 
	 loss: 399.2481, MinusLogProbMetric: 399.2481, val_loss: 397.9592, val_MinusLogProbMetric: 397.9592

Epoch 16: val_loss improved from 398.12354 to 397.95917, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 399.2481 - MinusLogProbMetric: 399.2481 - val_loss: 397.9592 - val_MinusLogProbMetric: 397.9592 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 17/1000
2023-09-09 23:06:57.849 
Epoch 17/1000 
	 loss: 496.2681, MinusLogProbMetric: 496.2681, val_loss: 429.6446, val_MinusLogProbMetric: 429.6446

Epoch 17: val_loss did not improve from 397.95917
196/196 - 9s - loss: 496.2681 - MinusLogProbMetric: 496.2681 - val_loss: 429.6446 - val_MinusLogProbMetric: 429.6446 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 18/1000
2023-09-09 23:07:06.541 
Epoch 18/1000 
	 loss: 416.7387, MinusLogProbMetric: 416.7387, val_loss: 410.6493, val_MinusLogProbMetric: 410.6493

Epoch 18: val_loss did not improve from 397.95917
196/196 - 9s - loss: 416.7387 - MinusLogProbMetric: 416.7387 - val_loss: 410.6493 - val_MinusLogProbMetric: 410.6493 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 19/1000
2023-09-09 23:07:15.977 
Epoch 19/1000 
	 loss: 407.6401, MinusLogProbMetric: 407.6401, val_loss: 406.1384, val_MinusLogProbMetric: 406.1384

Epoch 19: val_loss did not improve from 397.95917
196/196 - 9s - loss: 407.6401 - MinusLogProbMetric: 407.6401 - val_loss: 406.1384 - val_MinusLogProbMetric: 406.1384 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 20/1000
2023-09-09 23:07:24.350 
Epoch 20/1000 
	 loss: 404.3199, MinusLogProbMetric: 404.3199, val_loss: 404.1621, val_MinusLogProbMetric: 404.1621

Epoch 20: val_loss did not improve from 397.95917
196/196 - 8s - loss: 404.3199 - MinusLogProbMetric: 404.3199 - val_loss: 404.1621 - val_MinusLogProbMetric: 404.1621 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 21/1000
2023-09-09 23:07:34.032 
Epoch 21/1000 
	 loss: 402.5458, MinusLogProbMetric: 402.5458, val_loss: 403.5844, val_MinusLogProbMetric: 403.5844

Epoch 21: val_loss did not improve from 397.95917
196/196 - 10s - loss: 402.5458 - MinusLogProbMetric: 402.5458 - val_loss: 403.5844 - val_MinusLogProbMetric: 403.5844 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 22/1000
2023-09-09 23:07:42.420 
Epoch 22/1000 
	 loss: 401.3422, MinusLogProbMetric: 401.3422, val_loss: 402.8925, val_MinusLogProbMetric: 402.8925

Epoch 22: val_loss did not improve from 397.95917
196/196 - 8s - loss: 401.3422 - MinusLogProbMetric: 401.3422 - val_loss: 402.8925 - val_MinusLogProbMetric: 402.8925 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 23/1000
2023-09-09 23:07:51.894 
Epoch 23/1000 
	 loss: 400.4058, MinusLogProbMetric: 400.4058, val_loss: 401.3710, val_MinusLogProbMetric: 401.3710

Epoch 23: val_loss did not improve from 397.95917
196/196 - 9s - loss: 400.4058 - MinusLogProbMetric: 400.4058 - val_loss: 401.3710 - val_MinusLogProbMetric: 401.3710 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 24/1000
2023-09-09 23:08:00.562 
Epoch 24/1000 
	 loss: 399.8556, MinusLogProbMetric: 399.8556, val_loss: 400.9097, val_MinusLogProbMetric: 400.9097

Epoch 24: val_loss did not improve from 397.95917
196/196 - 9s - loss: 399.8556 - MinusLogProbMetric: 399.8556 - val_loss: 400.9097 - val_MinusLogProbMetric: 400.9097 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 25/1000
2023-09-09 23:08:10.179 
Epoch 25/1000 
	 loss: 399.3927, MinusLogProbMetric: 399.3927, val_loss: 401.2733, val_MinusLogProbMetric: 401.2733

Epoch 25: val_loss did not improve from 397.95917
196/196 - 10s - loss: 399.3927 - MinusLogProbMetric: 399.3927 - val_loss: 401.2733 - val_MinusLogProbMetric: 401.2733 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 26/1000
2023-09-09 23:08:18.318 
Epoch 26/1000 
	 loss: 398.8354, MinusLogProbMetric: 398.8354, val_loss: 399.5278, val_MinusLogProbMetric: 399.5278

Epoch 26: val_loss did not improve from 397.95917
196/196 - 8s - loss: 398.8354 - MinusLogProbMetric: 398.8354 - val_loss: 399.5278 - val_MinusLogProbMetric: 399.5278 - lr: 3.3333e-04 - 8s/epoch - 42ms/step
Epoch 27/1000
2023-09-09 23:08:27.394 
Epoch 27/1000 
	 loss: 398.6613, MinusLogProbMetric: 398.6613, val_loss: 401.4783, val_MinusLogProbMetric: 401.4783

Epoch 27: val_loss did not improve from 397.95917
196/196 - 9s - loss: 398.6613 - MinusLogProbMetric: 398.6613 - val_loss: 401.4783 - val_MinusLogProbMetric: 401.4783 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 28/1000
2023-09-09 23:08:35.918 
Epoch 28/1000 
	 loss: 398.5229, MinusLogProbMetric: 398.5229, val_loss: 399.2606, val_MinusLogProbMetric: 399.2606

Epoch 28: val_loss did not improve from 397.95917
196/196 - 9s - loss: 398.5229 - MinusLogProbMetric: 398.5229 - val_loss: 399.2606 - val_MinusLogProbMetric: 399.2606 - lr: 3.3333e-04 - 9s/epoch - 43ms/step
Epoch 29/1000
2023-09-09 23:08:45.271 
Epoch 29/1000 
	 loss: 398.3056, MinusLogProbMetric: 398.3056, val_loss: 399.7525, val_MinusLogProbMetric: 399.7525

Epoch 29: val_loss did not improve from 397.95917
196/196 - 9s - loss: 398.3056 - MinusLogProbMetric: 398.3056 - val_loss: 399.7525 - val_MinusLogProbMetric: 399.7525 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 30/1000
2023-09-09 23:08:53.467 
Epoch 30/1000 
	 loss: 398.0309, MinusLogProbMetric: 398.0309, val_loss: 398.7645, val_MinusLogProbMetric: 398.7645

Epoch 30: val_loss did not improve from 397.95917
196/196 - 8s - loss: 398.0309 - MinusLogProbMetric: 398.0309 - val_loss: 398.7645 - val_MinusLogProbMetric: 398.7645 - lr: 3.3333e-04 - 8s/epoch - 42ms/step
Epoch 31/1000
2023-09-09 23:09:03.091 
Epoch 31/1000 
	 loss: 397.8442, MinusLogProbMetric: 397.8442, val_loss: 398.7432, val_MinusLogProbMetric: 398.7432

Epoch 31: val_loss did not improve from 397.95917
196/196 - 10s - loss: 397.8442 - MinusLogProbMetric: 397.8442 - val_loss: 398.7432 - val_MinusLogProbMetric: 398.7432 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 32/1000
2023-09-09 23:09:10.754 
Epoch 32/1000 
	 loss: 397.5468, MinusLogProbMetric: 397.5468, val_loss: 398.9873, val_MinusLogProbMetric: 398.9873

Epoch 32: val_loss did not improve from 397.95917
196/196 - 8s - loss: 397.5468 - MinusLogProbMetric: 397.5468 - val_loss: 398.9873 - val_MinusLogProbMetric: 398.9873 - lr: 3.3333e-04 - 8s/epoch - 39ms/step
Epoch 33/1000
2023-09-09 23:09:20.146 
Epoch 33/1000 
	 loss: 397.5767, MinusLogProbMetric: 397.5767, val_loss: 399.0098, val_MinusLogProbMetric: 399.0098

Epoch 33: val_loss did not improve from 397.95917
196/196 - 9s - loss: 397.5767 - MinusLogProbMetric: 397.5767 - val_loss: 399.0098 - val_MinusLogProbMetric: 399.0098 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 34/1000
2023-09-09 23:09:28.108 
Epoch 34/1000 
	 loss: 397.5595, MinusLogProbMetric: 397.5595, val_loss: 398.9871, val_MinusLogProbMetric: 398.9871

Epoch 34: val_loss did not improve from 397.95917
196/196 - 8s - loss: 397.5595 - MinusLogProbMetric: 397.5595 - val_loss: 398.9871 - val_MinusLogProbMetric: 398.9871 - lr: 3.3333e-04 - 8s/epoch - 41ms/step
Epoch 35/1000
2023-09-09 23:09:37.222 
Epoch 35/1000 
	 loss: 397.7289, MinusLogProbMetric: 397.7289, val_loss: 397.2074, val_MinusLogProbMetric: 397.2074

Epoch 35: val_loss improved from 397.95917 to 397.20743, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 397.7289 - MinusLogProbMetric: 397.7289 - val_loss: 397.2074 - val_MinusLogProbMetric: 397.2074 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 36/1000
2023-09-09 23:09:46.082 
Epoch 36/1000 
	 loss: 397.2081, MinusLogProbMetric: 397.2081, val_loss: 399.2562, val_MinusLogProbMetric: 399.2562

Epoch 36: val_loss did not improve from 397.20743
196/196 - 9s - loss: 397.2081 - MinusLogProbMetric: 397.2081 - val_loss: 399.2562 - val_MinusLogProbMetric: 399.2562 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 37/1000
2023-09-09 23:09:54.920 
Epoch 37/1000 
	 loss: 397.1359, MinusLogProbMetric: 397.1359, val_loss: 397.4175, val_MinusLogProbMetric: 397.4175

Epoch 37: val_loss did not improve from 397.20743
196/196 - 9s - loss: 397.1359 - MinusLogProbMetric: 397.1359 - val_loss: 397.4175 - val_MinusLogProbMetric: 397.4175 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 38/1000
2023-09-09 23:10:03.221 
Epoch 38/1000 
	 loss: 397.4908, MinusLogProbMetric: 397.4908, val_loss: 397.0562, val_MinusLogProbMetric: 397.0562

Epoch 38: val_loss improved from 397.20743 to 397.05621, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 397.4908 - MinusLogProbMetric: 397.4908 - val_loss: 397.0562 - val_MinusLogProbMetric: 397.0562 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 39/1000
2023-09-09 23:10:12.917 
Epoch 39/1000 
	 loss: 397.0538, MinusLogProbMetric: 397.0538, val_loss: 397.7732, val_MinusLogProbMetric: 397.7732

Epoch 39: val_loss did not improve from 397.05621
196/196 - 9s - loss: 397.0538 - MinusLogProbMetric: 397.0538 - val_loss: 397.7732 - val_MinusLogProbMetric: 397.7732 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 40/1000
2023-09-09 23:10:21.283 
Epoch 40/1000 
	 loss: 396.9234, MinusLogProbMetric: 396.9234, val_loss: 402.6282, val_MinusLogProbMetric: 402.6282

Epoch 40: val_loss did not improve from 397.05621
196/196 - 8s - loss: 396.9234 - MinusLogProbMetric: 396.9234 - val_loss: 402.6282 - val_MinusLogProbMetric: 402.6282 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 41/1000
2023-09-09 23:10:30.340 
Epoch 41/1000 
	 loss: 396.9498, MinusLogProbMetric: 396.9498, val_loss: 397.2975, val_MinusLogProbMetric: 397.2975

Epoch 41: val_loss did not improve from 397.05621
196/196 - 9s - loss: 396.9498 - MinusLogProbMetric: 396.9498 - val_loss: 397.2975 - val_MinusLogProbMetric: 397.2975 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 42/1000
2023-09-09 23:10:38.880 
Epoch 42/1000 
	 loss: 396.9124, MinusLogProbMetric: 396.9124, val_loss: 400.9822, val_MinusLogProbMetric: 400.9822

Epoch 42: val_loss did not improve from 397.05621
196/196 - 9s - loss: 396.9124 - MinusLogProbMetric: 396.9124 - val_loss: 400.9822 - val_MinusLogProbMetric: 400.9822 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 43/1000
2023-09-09 23:10:47.532 
Epoch 43/1000 
	 loss: 397.1627, MinusLogProbMetric: 397.1627, val_loss: 396.6214, val_MinusLogProbMetric: 396.6214

Epoch 43: val_loss improved from 397.05621 to 396.62140, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 9s - loss: 397.1627 - MinusLogProbMetric: 397.1627 - val_loss: 396.6214 - val_MinusLogProbMetric: 396.6214 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 44/1000
2023-09-09 23:10:56.458 
Epoch 44/1000 
	 loss: 396.7629, MinusLogProbMetric: 396.7629, val_loss: 397.8002, val_MinusLogProbMetric: 397.8002

Epoch 44: val_loss did not improve from 396.62140
196/196 - 9s - loss: 396.7629 - MinusLogProbMetric: 396.7629 - val_loss: 397.8002 - val_MinusLogProbMetric: 397.8002 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 45/1000
2023-09-09 23:11:05.105 
Epoch 45/1000 
	 loss: 396.8817, MinusLogProbMetric: 396.8817, val_loss: 396.7829, val_MinusLogProbMetric: 396.7829

Epoch 45: val_loss did not improve from 396.62140
196/196 - 9s - loss: 396.8817 - MinusLogProbMetric: 396.8817 - val_loss: 396.7829 - val_MinusLogProbMetric: 396.7829 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 46/1000
2023-09-09 23:11:13.699 
Epoch 46/1000 
	 loss: 396.6094, MinusLogProbMetric: 396.6094, val_loss: 398.3021, val_MinusLogProbMetric: 398.3021

Epoch 46: val_loss did not improve from 396.62140
196/196 - 9s - loss: 396.6094 - MinusLogProbMetric: 396.6094 - val_loss: 398.3021 - val_MinusLogProbMetric: 398.3021 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 47/1000
2023-09-09 23:11:23.094 
Epoch 47/1000 
	 loss: 396.6100, MinusLogProbMetric: 396.6100, val_loss: 397.4975, val_MinusLogProbMetric: 397.4975

Epoch 47: val_loss did not improve from 396.62140
196/196 - 9s - loss: 396.6100 - MinusLogProbMetric: 396.6100 - val_loss: 397.4975 - val_MinusLogProbMetric: 397.4975 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 48/1000
2023-09-09 23:11:31.390 
Epoch 48/1000 
	 loss: 396.5921, MinusLogProbMetric: 396.5921, val_loss: 397.5613, val_MinusLogProbMetric: 397.5613

Epoch 48: val_loss did not improve from 396.62140
196/196 - 8s - loss: 396.5921 - MinusLogProbMetric: 396.5921 - val_loss: 397.5613 - val_MinusLogProbMetric: 397.5613 - lr: 3.3333e-04 - 8s/epoch - 42ms/step
Epoch 49/1000
2023-09-09 23:11:40.941 
Epoch 49/1000 
	 loss: 396.7794, MinusLogProbMetric: 396.7794, val_loss: 396.5828, val_MinusLogProbMetric: 396.5828

Epoch 49: val_loss improved from 396.62140 to 396.58279, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 10s - loss: 396.7794 - MinusLogProbMetric: 396.7794 - val_loss: 396.5828 - val_MinusLogProbMetric: 396.5828 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 50/1000
2023-09-09 23:11:49.829 
Epoch 50/1000 
	 loss: 396.8697, MinusLogProbMetric: 396.8697, val_loss: 397.5068, val_MinusLogProbMetric: 397.5068

Epoch 50: val_loss did not improve from 396.58279
196/196 - 9s - loss: 396.8697 - MinusLogProbMetric: 396.8697 - val_loss: 397.5068 - val_MinusLogProbMetric: 397.5068 - lr: 3.3333e-04 - 9s/epoch - 43ms/step
Epoch 51/1000
2023-09-09 23:11:58.863 
Epoch 51/1000 
	 loss: 396.1919, MinusLogProbMetric: 396.1919, val_loss: 398.4925, val_MinusLogProbMetric: 398.4925

Epoch 51: val_loss did not improve from 396.58279
196/196 - 9s - loss: 396.1919 - MinusLogProbMetric: 396.1919 - val_loss: 398.4925 - val_MinusLogProbMetric: 398.4925 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 52/1000
2023-09-09 23:12:04.671 
Epoch 52/1000 
	 loss: 396.5926, MinusLogProbMetric: 396.5926, val_loss: 399.4862, val_MinusLogProbMetric: 399.4862

Epoch 52: val_loss did not improve from 396.58279
196/196 - 6s - loss: 396.5926 - MinusLogProbMetric: 396.5926 - val_loss: 399.4862 - val_MinusLogProbMetric: 399.4862 - lr: 3.3333e-04 - 6s/epoch - 30ms/step
Epoch 53/1000
2023-09-09 23:12:14.841 
Epoch 53/1000 
	 loss: 396.4566, MinusLogProbMetric: 396.4566, val_loss: 398.0295, val_MinusLogProbMetric: 398.0295

Epoch 53: val_loss did not improve from 396.58279
196/196 - 10s - loss: 396.4566 - MinusLogProbMetric: 396.4566 - val_loss: 398.0295 - val_MinusLogProbMetric: 398.0295 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 54/1000
2023-09-09 23:12:28.525 
Epoch 54/1000 
	 loss: 396.0918, MinusLogProbMetric: 396.0918, val_loss: 398.2253, val_MinusLogProbMetric: 398.2253

Epoch 54: val_loss did not improve from 396.58279
196/196 - 14s - loss: 396.0918 - MinusLogProbMetric: 396.0918 - val_loss: 398.2253 - val_MinusLogProbMetric: 398.2253 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 55/1000
2023-09-09 23:12:40.027 
Epoch 55/1000 
	 loss: 396.8090, MinusLogProbMetric: 396.8090, val_loss: 396.6528, val_MinusLogProbMetric: 396.6528

Epoch 55: val_loss did not improve from 396.58279
196/196 - 12s - loss: 396.8090 - MinusLogProbMetric: 396.8090 - val_loss: 396.6528 - val_MinusLogProbMetric: 396.6528 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 56/1000
2023-09-09 23:12:53.753 
Epoch 56/1000 
	 loss: 396.4052, MinusLogProbMetric: 396.4052, val_loss: 398.1828, val_MinusLogProbMetric: 398.1828

Epoch 56: val_loss did not improve from 396.58279
196/196 - 14s - loss: 396.4052 - MinusLogProbMetric: 396.4052 - val_loss: 398.1828 - val_MinusLogProbMetric: 398.1828 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 57/1000
2023-09-09 23:13:03.037 
Epoch 57/1000 
	 loss: 396.0014, MinusLogProbMetric: 396.0014, val_loss: 397.6123, val_MinusLogProbMetric: 397.6123

Epoch 57: val_loss did not improve from 396.58279
196/196 - 9s - loss: 396.0014 - MinusLogProbMetric: 396.0014 - val_loss: 397.6123 - val_MinusLogProbMetric: 397.6123 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 58/1000
2023-09-09 23:13:14.050 
Epoch 58/1000 
	 loss: 396.0954, MinusLogProbMetric: 396.0954, val_loss: 397.1977, val_MinusLogProbMetric: 397.1977

Epoch 58: val_loss did not improve from 396.58279
196/196 - 11s - loss: 396.0954 - MinusLogProbMetric: 396.0954 - val_loss: 397.1977 - val_MinusLogProbMetric: 397.1977 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 59/1000
2023-09-09 23:13:25.553 
Epoch 59/1000 
	 loss: 400.2147, MinusLogProbMetric: 400.2147, val_loss: 396.8379, val_MinusLogProbMetric: 396.8379

Epoch 59: val_loss did not improve from 396.58279
196/196 - 11s - loss: 400.2147 - MinusLogProbMetric: 400.2147 - val_loss: 396.8379 - val_MinusLogProbMetric: 396.8379 - lr: 3.3333e-04 - 11s/epoch - 59ms/step
Epoch 60/1000
2023-09-09 23:13:36.877 
Epoch 60/1000 
	 loss: 395.6002, MinusLogProbMetric: 395.6002, val_loss: 396.7955, val_MinusLogProbMetric: 396.7955

Epoch 60: val_loss did not improve from 396.58279
196/196 - 11s - loss: 395.6002 - MinusLogProbMetric: 395.6002 - val_loss: 396.7955 - val_MinusLogProbMetric: 396.7955 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 61/1000
2023-09-09 23:13:49.129 
Epoch 61/1000 
	 loss: 395.2702, MinusLogProbMetric: 395.2702, val_loss: 396.5788, val_MinusLogProbMetric: 396.5788

Epoch 61: val_loss improved from 396.58279 to 396.57877, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 13s - loss: 395.2702 - MinusLogProbMetric: 395.2702 - val_loss: 396.5788 - val_MinusLogProbMetric: 396.5788 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 62/1000
2023-09-09 23:14:01.386 
Epoch 62/1000 
	 loss: 395.9138, MinusLogProbMetric: 395.9138, val_loss: 397.1320, val_MinusLogProbMetric: 397.1320

Epoch 62: val_loss did not improve from 396.57877
196/196 - 12s - loss: 395.9138 - MinusLogProbMetric: 395.9138 - val_loss: 397.1320 - val_MinusLogProbMetric: 397.1320 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 63/1000
2023-09-09 23:14:13.744 
Epoch 63/1000 
	 loss: 395.8206, MinusLogProbMetric: 395.8206, val_loss: 397.2362, val_MinusLogProbMetric: 397.2362

Epoch 63: val_loss did not improve from 396.57877
196/196 - 12s - loss: 395.8206 - MinusLogProbMetric: 395.8206 - val_loss: 397.2362 - val_MinusLogProbMetric: 397.2362 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 64/1000
2023-09-09 23:14:25.998 
Epoch 64/1000 
	 loss: 395.8818, MinusLogProbMetric: 395.8818, val_loss: 397.2788, val_MinusLogProbMetric: 397.2788

Epoch 64: val_loss did not improve from 396.57877
196/196 - 12s - loss: 395.8818 - MinusLogProbMetric: 395.8818 - val_loss: 397.2788 - val_MinusLogProbMetric: 397.2788 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 65/1000
2023-09-09 23:14:42.169 
Epoch 65/1000 
	 loss: 395.9470, MinusLogProbMetric: 395.9470, val_loss: 397.1839, val_MinusLogProbMetric: 397.1839

Epoch 65: val_loss did not improve from 396.57877
196/196 - 16s - loss: 395.9470 - MinusLogProbMetric: 395.9470 - val_loss: 397.1839 - val_MinusLogProbMetric: 397.1839 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 66/1000
2023-09-09 23:14:55.028 
Epoch 66/1000 
	 loss: 395.3339, MinusLogProbMetric: 395.3339, val_loss: 396.6723, val_MinusLogProbMetric: 396.6723

Epoch 66: val_loss did not improve from 396.57877
196/196 - 13s - loss: 395.3339 - MinusLogProbMetric: 395.3339 - val_loss: 396.6723 - val_MinusLogProbMetric: 396.6723 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 67/1000
2023-09-09 23:15:10.153 
Epoch 67/1000 
	 loss: 395.9850, MinusLogProbMetric: 395.9850, val_loss: 396.5687, val_MinusLogProbMetric: 396.5687

Epoch 67: val_loss improved from 396.57877 to 396.56873, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 16s - loss: 395.9850 - MinusLogProbMetric: 395.9850 - val_loss: 396.5687 - val_MinusLogProbMetric: 396.5687 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 68/1000
2023-09-09 23:15:23.453 
Epoch 68/1000 
	 loss: 397.0064, MinusLogProbMetric: 397.0064, val_loss: 396.6573, val_MinusLogProbMetric: 396.6573

Epoch 68: val_loss did not improve from 396.56873
196/196 - 13s - loss: 397.0064 - MinusLogProbMetric: 397.0064 - val_loss: 396.6573 - val_MinusLogProbMetric: 396.6573 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 69/1000
2023-09-09 23:15:37.355 
Epoch 69/1000 
	 loss: 395.2794, MinusLogProbMetric: 395.2794, val_loss: 396.9871, val_MinusLogProbMetric: 396.9871

Epoch 69: val_loss did not improve from 396.56873
196/196 - 14s - loss: 395.2794 - MinusLogProbMetric: 395.2794 - val_loss: 396.9871 - val_MinusLogProbMetric: 396.9871 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 70/1000
2023-09-09 23:15:50.369 
Epoch 70/1000 
	 loss: 395.4295, MinusLogProbMetric: 395.4295, val_loss: 397.4198, val_MinusLogProbMetric: 397.4198

Epoch 70: val_loss did not improve from 396.56873
196/196 - 13s - loss: 395.4295 - MinusLogProbMetric: 395.4295 - val_loss: 397.4198 - val_MinusLogProbMetric: 397.4198 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 71/1000
2023-09-09 23:16:05.357 
Epoch 71/1000 
	 loss: 395.6762, MinusLogProbMetric: 395.6762, val_loss: 398.4312, val_MinusLogProbMetric: 398.4312

Epoch 71: val_loss did not improve from 396.56873
196/196 - 15s - loss: 395.6762 - MinusLogProbMetric: 395.6762 - val_loss: 398.4312 - val_MinusLogProbMetric: 398.4312 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 72/1000
2023-09-09 23:16:17.881 
Epoch 72/1000 
	 loss: 395.8164, MinusLogProbMetric: 395.8164, val_loss: 396.0074, val_MinusLogProbMetric: 396.0074

Epoch 72: val_loss improved from 396.56873 to 396.00739, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 13s - loss: 395.8164 - MinusLogProbMetric: 395.8164 - val_loss: 396.0074 - val_MinusLogProbMetric: 396.0074 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 73/1000
2023-09-09 23:16:32.363 
Epoch 73/1000 
	 loss: 395.5968, MinusLogProbMetric: 395.5968, val_loss: 397.3978, val_MinusLogProbMetric: 397.3978

Epoch 73: val_loss did not improve from 396.00739
196/196 - 14s - loss: 395.5968 - MinusLogProbMetric: 395.5968 - val_loss: 397.3978 - val_MinusLogProbMetric: 397.3978 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 74/1000
2023-09-09 23:16:44.698 
Epoch 74/1000 
	 loss: 396.3595, MinusLogProbMetric: 396.3595, val_loss: 395.9145, val_MinusLogProbMetric: 395.9145

Epoch 74: val_loss improved from 396.00739 to 395.91449, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 13s - loss: 396.3595 - MinusLogProbMetric: 396.3595 - val_loss: 395.9145 - val_MinusLogProbMetric: 395.9145 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 75/1000
2023-09-09 23:16:58.752 
Epoch 75/1000 
	 loss: 395.2509, MinusLogProbMetric: 395.2509, val_loss: 399.2458, val_MinusLogProbMetric: 399.2458

Epoch 75: val_loss did not improve from 395.91449
196/196 - 13s - loss: 395.2509 - MinusLogProbMetric: 395.2509 - val_loss: 399.2458 - val_MinusLogProbMetric: 399.2458 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 76/1000
2023-09-09 23:17:12.990 
Epoch 76/1000 
	 loss: 395.7553, MinusLogProbMetric: 395.7553, val_loss: 412.8129, val_MinusLogProbMetric: 412.8129

Epoch 76: val_loss did not improve from 395.91449
196/196 - 14s - loss: 395.7553 - MinusLogProbMetric: 395.7553 - val_loss: 412.8129 - val_MinusLogProbMetric: 412.8129 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 77/1000
2023-09-09 23:17:29.290 
Epoch 77/1000 
	 loss: 395.7815, MinusLogProbMetric: 395.7815, val_loss: 396.8771, val_MinusLogProbMetric: 396.8771

Epoch 77: val_loss did not improve from 395.91449
196/196 - 16s - loss: 395.7815 - MinusLogProbMetric: 395.7815 - val_loss: 396.8771 - val_MinusLogProbMetric: 396.8771 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 78/1000
2023-09-09 23:17:44.329 
Epoch 78/1000 
	 loss: 395.4857, MinusLogProbMetric: 395.4857, val_loss: 395.4038, val_MinusLogProbMetric: 395.4038

Epoch 78: val_loss improved from 395.91449 to 395.40384, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 16s - loss: 395.4857 - MinusLogProbMetric: 395.4857 - val_loss: 395.4038 - val_MinusLogProbMetric: 395.4038 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 79/1000
2023-09-09 23:18:00.688 
Epoch 79/1000 
	 loss: 395.6848, MinusLogProbMetric: 395.6848, val_loss: 396.8500, val_MinusLogProbMetric: 396.8500

Epoch 79: val_loss did not improve from 395.40384
196/196 - 16s - loss: 395.6848 - MinusLogProbMetric: 395.6848 - val_loss: 396.8500 - val_MinusLogProbMetric: 396.8500 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 80/1000
2023-09-09 23:18:15.567 
Epoch 80/1000 
	 loss: 395.6701, MinusLogProbMetric: 395.6701, val_loss: 395.9468, val_MinusLogProbMetric: 395.9468

Epoch 80: val_loss did not improve from 395.40384
196/196 - 15s - loss: 395.6701 - MinusLogProbMetric: 395.6701 - val_loss: 395.9468 - val_MinusLogProbMetric: 395.9468 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 81/1000
2023-09-09 23:18:31.724 
Epoch 81/1000 
	 loss: 395.5074, MinusLogProbMetric: 395.5074, val_loss: 398.9833, val_MinusLogProbMetric: 398.9834

Epoch 81: val_loss did not improve from 395.40384
196/196 - 16s - loss: 395.5074 - MinusLogProbMetric: 395.5074 - val_loss: 398.9833 - val_MinusLogProbMetric: 398.9834 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 82/1000
2023-09-09 23:18:47.524 
Epoch 82/1000 
	 loss: 395.7864, MinusLogProbMetric: 395.7864, val_loss: 396.6199, val_MinusLogProbMetric: 396.6199

Epoch 82: val_loss did not improve from 395.40384
196/196 - 16s - loss: 395.7864 - MinusLogProbMetric: 395.7864 - val_loss: 396.6199 - val_MinusLogProbMetric: 396.6199 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 83/1000
2023-09-09 23:19:02.474 
Epoch 83/1000 
	 loss: 396.1089, MinusLogProbMetric: 396.1089, val_loss: 400.2659, val_MinusLogProbMetric: 400.2659

Epoch 83: val_loss did not improve from 395.40384
196/196 - 15s - loss: 396.1089 - MinusLogProbMetric: 396.1089 - val_loss: 400.2659 - val_MinusLogProbMetric: 400.2659 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 84/1000
2023-09-09 23:19:17.407 
Epoch 84/1000 
	 loss: 395.2326, MinusLogProbMetric: 395.2326, val_loss: 395.8796, val_MinusLogProbMetric: 395.8796

Epoch 84: val_loss did not improve from 395.40384
196/196 - 15s - loss: 395.2326 - MinusLogProbMetric: 395.2326 - val_loss: 395.8796 - val_MinusLogProbMetric: 395.8796 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 85/1000
2023-09-09 23:19:32.693 
Epoch 85/1000 
	 loss: 395.5405, MinusLogProbMetric: 395.5405, val_loss: 395.7275, val_MinusLogProbMetric: 395.7275

Epoch 85: val_loss did not improve from 395.40384
196/196 - 15s - loss: 395.5405 - MinusLogProbMetric: 395.5405 - val_loss: 395.7275 - val_MinusLogProbMetric: 395.7275 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 86/1000
2023-09-09 23:19:48.795 
Epoch 86/1000 
	 loss: 395.1696, MinusLogProbMetric: 395.1696, val_loss: 396.2958, val_MinusLogProbMetric: 396.2958

Epoch 86: val_loss did not improve from 395.40384
196/196 - 16s - loss: 395.1696 - MinusLogProbMetric: 395.1696 - val_loss: 396.2958 - val_MinusLogProbMetric: 396.2958 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 87/1000
2023-09-09 23:20:03.986 
Epoch 87/1000 
	 loss: 395.9077, MinusLogProbMetric: 395.9077, val_loss: 395.3894, val_MinusLogProbMetric: 395.3894

Epoch 87: val_loss improved from 395.40384 to 395.38937, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 16s - loss: 395.9077 - MinusLogProbMetric: 395.9077 - val_loss: 395.3894 - val_MinusLogProbMetric: 395.3894 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 88/1000
2023-09-09 23:20:21.416 
Epoch 88/1000 
	 loss: 394.8878, MinusLogProbMetric: 394.8878, val_loss: 395.6889, val_MinusLogProbMetric: 395.6889

Epoch 88: val_loss did not improve from 395.38937
196/196 - 17s - loss: 394.8878 - MinusLogProbMetric: 394.8878 - val_loss: 395.6889 - val_MinusLogProbMetric: 395.6889 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 89/1000
2023-09-09 23:20:37.174 
Epoch 89/1000 
	 loss: 395.4629, MinusLogProbMetric: 395.4629, val_loss: 401.1072, val_MinusLogProbMetric: 401.1072

Epoch 89: val_loss did not improve from 395.38937
196/196 - 16s - loss: 395.4629 - MinusLogProbMetric: 395.4629 - val_loss: 401.1072 - val_MinusLogProbMetric: 401.1072 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 90/1000
2023-09-09 23:20:53.085 
Epoch 90/1000 
	 loss: 396.7332, MinusLogProbMetric: 396.7332, val_loss: 396.7997, val_MinusLogProbMetric: 396.7997

Epoch 90: val_loss did not improve from 395.38937
196/196 - 16s - loss: 396.7332 - MinusLogProbMetric: 396.7332 - val_loss: 396.7997 - val_MinusLogProbMetric: 396.7997 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 91/1000
2023-09-09 23:21:08.877 
Epoch 91/1000 
	 loss: 395.1436, MinusLogProbMetric: 395.1436, val_loss: 400.1576, val_MinusLogProbMetric: 400.1576

Epoch 91: val_loss did not improve from 395.38937
196/196 - 16s - loss: 395.1436 - MinusLogProbMetric: 395.1436 - val_loss: 400.1576 - val_MinusLogProbMetric: 400.1576 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 92/1000
2023-09-09 23:21:23.110 
Epoch 92/1000 
	 loss: 395.1188, MinusLogProbMetric: 395.1188, val_loss: 397.6979, val_MinusLogProbMetric: 397.6979

Epoch 92: val_loss did not improve from 395.38937
196/196 - 14s - loss: 395.1188 - MinusLogProbMetric: 395.1188 - val_loss: 397.6979 - val_MinusLogProbMetric: 397.6979 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 93/1000
2023-09-09 23:21:37.324 
Epoch 93/1000 
	 loss: 395.4522, MinusLogProbMetric: 395.4522, val_loss: 396.8394, val_MinusLogProbMetric: 396.8394

Epoch 93: val_loss did not improve from 395.38937
196/196 - 14s - loss: 395.4522 - MinusLogProbMetric: 395.4522 - val_loss: 396.8394 - val_MinusLogProbMetric: 396.8394 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 94/1000
2023-09-09 23:21:54.734 
Epoch 94/1000 
	 loss: 395.1397, MinusLogProbMetric: 395.1397, val_loss: 397.8440, val_MinusLogProbMetric: 397.8440

Epoch 94: val_loss did not improve from 395.38937
196/196 - 17s - loss: 395.1397 - MinusLogProbMetric: 395.1397 - val_loss: 397.8440 - val_MinusLogProbMetric: 397.8440 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 95/1000
2023-09-09 23:22:09.960 
Epoch 95/1000 
	 loss: 395.0799, MinusLogProbMetric: 395.0799, val_loss: 399.0069, val_MinusLogProbMetric: 399.0069

Epoch 95: val_loss did not improve from 395.38937
196/196 - 15s - loss: 395.0799 - MinusLogProbMetric: 395.0799 - val_loss: 399.0069 - val_MinusLogProbMetric: 399.0069 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 96/1000
2023-09-09 23:22:25.789 
Epoch 96/1000 
	 loss: 395.8484, MinusLogProbMetric: 395.8484, val_loss: 400.1377, val_MinusLogProbMetric: 400.1377

Epoch 96: val_loss did not improve from 395.38937
196/196 - 16s - loss: 395.8484 - MinusLogProbMetric: 395.8484 - val_loss: 400.1377 - val_MinusLogProbMetric: 400.1377 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 97/1000
2023-09-09 23:22:40.806 
Epoch 97/1000 
	 loss: 395.2428, MinusLogProbMetric: 395.2428, val_loss: 398.4165, val_MinusLogProbMetric: 398.4165

Epoch 97: val_loss did not improve from 395.38937
196/196 - 15s - loss: 395.2428 - MinusLogProbMetric: 395.2428 - val_loss: 398.4165 - val_MinusLogProbMetric: 398.4165 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 98/1000
2023-09-09 23:22:55.248 
Epoch 98/1000 
	 loss: 395.0020, MinusLogProbMetric: 395.0020, val_loss: 395.5940, val_MinusLogProbMetric: 395.5940

Epoch 98: val_loss did not improve from 395.38937
196/196 - 14s - loss: 395.0020 - MinusLogProbMetric: 395.0020 - val_loss: 395.5940 - val_MinusLogProbMetric: 395.5940 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 99/1000
2023-09-09 23:23:10.259 
Epoch 99/1000 
	 loss: 395.1387, MinusLogProbMetric: 395.1387, val_loss: 396.0048, val_MinusLogProbMetric: 396.0048

Epoch 99: val_loss did not improve from 395.38937
196/196 - 15s - loss: 395.1387 - MinusLogProbMetric: 395.1387 - val_loss: 396.0048 - val_MinusLogProbMetric: 396.0048 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 100/1000
2023-09-09 23:23:22.884 
Epoch 100/1000 
	 loss: 394.8267, MinusLogProbMetric: 394.8267, val_loss: 396.8753, val_MinusLogProbMetric: 396.8753

Epoch 100: val_loss did not improve from 395.38937
196/196 - 13s - loss: 394.8267 - MinusLogProbMetric: 394.8267 - val_loss: 396.8753 - val_MinusLogProbMetric: 396.8753 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 101/1000
2023-09-09 23:23:37.270 
Epoch 101/1000 
	 loss: 395.1035, MinusLogProbMetric: 395.1035, val_loss: 396.1211, val_MinusLogProbMetric: 396.1211

Epoch 101: val_loss did not improve from 395.38937
196/196 - 14s - loss: 395.1035 - MinusLogProbMetric: 395.1035 - val_loss: 396.1211 - val_MinusLogProbMetric: 396.1211 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 102/1000
2023-09-09 23:23:50.380 
Epoch 102/1000 
	 loss: 394.7933, MinusLogProbMetric: 394.7933, val_loss: 398.2416, val_MinusLogProbMetric: 398.2416

Epoch 102: val_loss did not improve from 395.38937
196/196 - 13s - loss: 394.7933 - MinusLogProbMetric: 394.7933 - val_loss: 398.2416 - val_MinusLogProbMetric: 398.2416 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 103/1000
2023-09-09 23:24:03.127 
Epoch 103/1000 
	 loss: 395.1358, MinusLogProbMetric: 395.1358, val_loss: 394.9896, val_MinusLogProbMetric: 394.9896

Epoch 103: val_loss improved from 395.38937 to 394.98962, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 13s - loss: 395.1358 - MinusLogProbMetric: 395.1358 - val_loss: 394.9896 - val_MinusLogProbMetric: 394.9896 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 104/1000
2023-09-09 23:24:17.039 
Epoch 104/1000 
	 loss: 394.8693, MinusLogProbMetric: 394.8693, val_loss: 396.2986, val_MinusLogProbMetric: 396.2986

Epoch 104: val_loss did not improve from 394.98962
196/196 - 13s - loss: 394.8693 - MinusLogProbMetric: 394.8693 - val_loss: 396.2986 - val_MinusLogProbMetric: 396.2986 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 105/1000
2023-09-09 23:24:31.569 
Epoch 105/1000 
	 loss: 395.5181, MinusLogProbMetric: 395.5181, val_loss: 396.7100, val_MinusLogProbMetric: 396.7100

Epoch 105: val_loss did not improve from 394.98962
196/196 - 15s - loss: 395.5181 - MinusLogProbMetric: 395.5181 - val_loss: 396.7100 - val_MinusLogProbMetric: 396.7100 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 106/1000
2023-09-09 23:24:45.098 
Epoch 106/1000 
	 loss: 394.8083, MinusLogProbMetric: 394.8083, val_loss: 396.4658, val_MinusLogProbMetric: 396.4658

Epoch 106: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.8083 - MinusLogProbMetric: 394.8083 - val_loss: 396.4658 - val_MinusLogProbMetric: 396.4658 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 107/1000
2023-09-09 23:24:58.883 
Epoch 107/1000 
	 loss: 396.2897, MinusLogProbMetric: 396.2897, val_loss: 395.4913, val_MinusLogProbMetric: 395.4913

Epoch 107: val_loss did not improve from 394.98962
196/196 - 14s - loss: 396.2897 - MinusLogProbMetric: 396.2897 - val_loss: 395.4913 - val_MinusLogProbMetric: 395.4913 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 108/1000
2023-09-09 23:25:12.354 
Epoch 108/1000 
	 loss: 394.3939, MinusLogProbMetric: 394.3939, val_loss: 395.3776, val_MinusLogProbMetric: 395.3776

Epoch 108: val_loss did not improve from 394.98962
196/196 - 13s - loss: 394.3939 - MinusLogProbMetric: 394.3939 - val_loss: 395.3776 - val_MinusLogProbMetric: 395.3776 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 109/1000
2023-09-09 23:25:25.809 
Epoch 109/1000 
	 loss: 394.9659, MinusLogProbMetric: 394.9659, val_loss: 395.8962, val_MinusLogProbMetric: 395.8962

Epoch 109: val_loss did not improve from 394.98962
196/196 - 13s - loss: 394.9659 - MinusLogProbMetric: 394.9659 - val_loss: 395.8962 - val_MinusLogProbMetric: 395.8962 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 110/1000
2023-09-09 23:25:41.391 
Epoch 110/1000 
	 loss: 394.6618, MinusLogProbMetric: 394.6618, val_loss: 400.0364, val_MinusLogProbMetric: 400.0364

Epoch 110: val_loss did not improve from 394.98962
196/196 - 16s - loss: 394.6618 - MinusLogProbMetric: 394.6618 - val_loss: 400.0364 - val_MinusLogProbMetric: 400.0364 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 111/1000
2023-09-09 23:25:53.181 
Epoch 111/1000 
	 loss: 394.6804, MinusLogProbMetric: 394.6804, val_loss: 397.6886, val_MinusLogProbMetric: 397.6886

Epoch 111: val_loss did not improve from 394.98962
196/196 - 12s - loss: 394.6804 - MinusLogProbMetric: 394.6804 - val_loss: 397.6886 - val_MinusLogProbMetric: 397.6886 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 112/1000
2023-09-09 23:26:07.027 
Epoch 112/1000 
	 loss: 398.4863, MinusLogProbMetric: 398.4863, val_loss: 395.1015, val_MinusLogProbMetric: 395.1015

Epoch 112: val_loss did not improve from 394.98962
196/196 - 14s - loss: 398.4863 - MinusLogProbMetric: 398.4863 - val_loss: 395.1015 - val_MinusLogProbMetric: 395.1015 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 113/1000
2023-09-09 23:26:19.881 
Epoch 113/1000 
	 loss: 394.0181, MinusLogProbMetric: 394.0181, val_loss: 396.7878, val_MinusLogProbMetric: 396.7878

Epoch 113: val_loss did not improve from 394.98962
196/196 - 13s - loss: 394.0181 - MinusLogProbMetric: 394.0181 - val_loss: 396.7878 - val_MinusLogProbMetric: 396.7878 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 114/1000
2023-09-09 23:26:34.019 
Epoch 114/1000 
	 loss: 394.6010, MinusLogProbMetric: 394.6010, val_loss: 395.0457, val_MinusLogProbMetric: 395.0457

Epoch 114: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.6010 - MinusLogProbMetric: 394.6010 - val_loss: 395.0457 - val_MinusLogProbMetric: 395.0457 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 115/1000
2023-09-09 23:26:46.040 
Epoch 115/1000 
	 loss: 394.5183, MinusLogProbMetric: 394.5183, val_loss: 395.6924, val_MinusLogProbMetric: 395.6924

Epoch 115: val_loss did not improve from 394.98962
196/196 - 12s - loss: 394.5183 - MinusLogProbMetric: 394.5183 - val_loss: 395.6924 - val_MinusLogProbMetric: 395.6924 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 116/1000
2023-09-09 23:27:00.161 
Epoch 116/1000 
	 loss: 394.9679, MinusLogProbMetric: 394.9679, val_loss: 395.3357, val_MinusLogProbMetric: 395.3357

Epoch 116: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.9679 - MinusLogProbMetric: 394.9679 - val_loss: 395.3357 - val_MinusLogProbMetric: 395.3357 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 117/1000
2023-09-09 23:27:14.092 
Epoch 117/1000 
	 loss: 395.0631, MinusLogProbMetric: 395.0631, val_loss: 397.5361, val_MinusLogProbMetric: 397.5361

Epoch 117: val_loss did not improve from 394.98962
196/196 - 14s - loss: 395.0631 - MinusLogProbMetric: 395.0631 - val_loss: 397.5361 - val_MinusLogProbMetric: 397.5361 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 118/1000
2023-09-09 23:27:28.405 
Epoch 118/1000 
	 loss: 394.5703, MinusLogProbMetric: 394.5703, val_loss: 398.4633, val_MinusLogProbMetric: 398.4633

Epoch 118: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.5703 - MinusLogProbMetric: 394.5703 - val_loss: 398.4633 - val_MinusLogProbMetric: 398.4633 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 119/1000
2023-09-09 23:27:42.216 
Epoch 119/1000 
	 loss: 394.6233, MinusLogProbMetric: 394.6233, val_loss: 395.9548, val_MinusLogProbMetric: 395.9548

Epoch 119: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.6233 - MinusLogProbMetric: 394.6233 - val_loss: 395.9548 - val_MinusLogProbMetric: 395.9548 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 120/1000
2023-09-09 23:27:56.629 
Epoch 120/1000 
	 loss: 394.9461, MinusLogProbMetric: 394.9461, val_loss: 395.0006, val_MinusLogProbMetric: 395.0006

Epoch 120: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.9461 - MinusLogProbMetric: 394.9461 - val_loss: 395.0006 - val_MinusLogProbMetric: 395.0006 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 121/1000
2023-09-09 23:28:12.114 
Epoch 121/1000 
	 loss: 394.5548, MinusLogProbMetric: 394.5548, val_loss: 396.7519, val_MinusLogProbMetric: 396.7519

Epoch 121: val_loss did not improve from 394.98962
196/196 - 15s - loss: 394.5548 - MinusLogProbMetric: 394.5548 - val_loss: 396.7519 - val_MinusLogProbMetric: 396.7519 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 122/1000
2023-09-09 23:28:27.289 
Epoch 122/1000 
	 loss: 394.3958, MinusLogProbMetric: 394.3958, val_loss: 395.8578, val_MinusLogProbMetric: 395.8578

Epoch 122: val_loss did not improve from 394.98962
196/196 - 15s - loss: 394.3958 - MinusLogProbMetric: 394.3958 - val_loss: 395.8578 - val_MinusLogProbMetric: 395.8578 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 123/1000
2023-09-09 23:28:40.006 
Epoch 123/1000 
	 loss: 394.7448, MinusLogProbMetric: 394.7448, val_loss: 400.1789, val_MinusLogProbMetric: 400.1789

Epoch 123: val_loss did not improve from 394.98962
196/196 - 13s - loss: 394.7448 - MinusLogProbMetric: 394.7448 - val_loss: 400.1789 - val_MinusLogProbMetric: 400.1789 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 124/1000
2023-09-09 23:28:53.608 
Epoch 124/1000 
	 loss: 394.4553, MinusLogProbMetric: 394.4553, val_loss: 396.1730, val_MinusLogProbMetric: 396.1730

Epoch 124: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.4553 - MinusLogProbMetric: 394.4553 - val_loss: 396.1730 - val_MinusLogProbMetric: 396.1730 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 125/1000
2023-09-09 23:29:06.606 
Epoch 125/1000 
	 loss: 394.5316, MinusLogProbMetric: 394.5316, val_loss: 396.8916, val_MinusLogProbMetric: 396.8916

Epoch 125: val_loss did not improve from 394.98962
196/196 - 13s - loss: 394.5316 - MinusLogProbMetric: 394.5316 - val_loss: 396.8916 - val_MinusLogProbMetric: 396.8916 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 126/1000
2023-09-09 23:29:20.602 
Epoch 126/1000 
	 loss: 394.9590, MinusLogProbMetric: 394.9590, val_loss: 395.3721, val_MinusLogProbMetric: 395.3721

Epoch 126: val_loss did not improve from 394.98962
196/196 - 14s - loss: 394.9590 - MinusLogProbMetric: 394.9590 - val_loss: 395.3721 - val_MinusLogProbMetric: 395.3721 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 127/1000
2023-09-09 23:29:33.263 
Epoch 127/1000 
	 loss: 394.3942, MinusLogProbMetric: 394.3942, val_loss: 394.6007, val_MinusLogProbMetric: 394.6007

Epoch 127: val_loss improved from 394.98962 to 394.60068, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 13s - loss: 394.3942 - MinusLogProbMetric: 394.3942 - val_loss: 394.6007 - val_MinusLogProbMetric: 394.6007 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 128/1000
2023-09-09 23:29:47.431 
Epoch 128/1000 
	 loss: 394.7042, MinusLogProbMetric: 394.7042, val_loss: 396.6241, val_MinusLogProbMetric: 396.6241

Epoch 128: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.7042 - MinusLogProbMetric: 394.7042 - val_loss: 396.6241 - val_MinusLogProbMetric: 396.6241 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 129/1000
2023-09-09 23:29:59.789 
Epoch 129/1000 
	 loss: 394.2061, MinusLogProbMetric: 394.2061, val_loss: 398.9458, val_MinusLogProbMetric: 398.9458

Epoch 129: val_loss did not improve from 394.60068
196/196 - 12s - loss: 394.2061 - MinusLogProbMetric: 394.2061 - val_loss: 398.9458 - val_MinusLogProbMetric: 398.9458 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 130/1000
2023-09-09 23:30:15.674 
Epoch 130/1000 
	 loss: 394.6916, MinusLogProbMetric: 394.6916, val_loss: 394.8457, val_MinusLogProbMetric: 394.8457

Epoch 130: val_loss did not improve from 394.60068
196/196 - 16s - loss: 394.6916 - MinusLogProbMetric: 394.6916 - val_loss: 394.8457 - val_MinusLogProbMetric: 394.8457 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 131/1000
2023-09-09 23:30:29.408 
Epoch 131/1000 
	 loss: 394.5003, MinusLogProbMetric: 394.5003, val_loss: 395.5066, val_MinusLogProbMetric: 395.5066

Epoch 131: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.5003 - MinusLogProbMetric: 394.5003 - val_loss: 395.5066 - val_MinusLogProbMetric: 395.5066 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 132/1000
2023-09-09 23:30:43.169 
Epoch 132/1000 
	 loss: 395.2951, MinusLogProbMetric: 395.2951, val_loss: 396.2024, val_MinusLogProbMetric: 396.2024

Epoch 132: val_loss did not improve from 394.60068
196/196 - 14s - loss: 395.2951 - MinusLogProbMetric: 395.2951 - val_loss: 396.2024 - val_MinusLogProbMetric: 396.2024 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 133/1000
2023-09-09 23:30:56.907 
Epoch 133/1000 
	 loss: 394.0265, MinusLogProbMetric: 394.0265, val_loss: 399.2689, val_MinusLogProbMetric: 399.2689

Epoch 133: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.0265 - MinusLogProbMetric: 394.0265 - val_loss: 399.2689 - val_MinusLogProbMetric: 399.2689 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 134/1000
2023-09-09 23:31:12.677 
Epoch 134/1000 
	 loss: 394.9679, MinusLogProbMetric: 394.9679, val_loss: 398.1536, val_MinusLogProbMetric: 398.1536

Epoch 134: val_loss did not improve from 394.60068
196/196 - 16s - loss: 394.9679 - MinusLogProbMetric: 394.9679 - val_loss: 398.1536 - val_MinusLogProbMetric: 398.1536 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 135/1000
2023-09-09 23:31:26.973 
Epoch 135/1000 
	 loss: 393.8683, MinusLogProbMetric: 393.8683, val_loss: 396.8890, val_MinusLogProbMetric: 396.8890

Epoch 135: val_loss did not improve from 394.60068
196/196 - 14s - loss: 393.8683 - MinusLogProbMetric: 393.8683 - val_loss: 396.8890 - val_MinusLogProbMetric: 396.8890 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 136/1000
2023-09-09 23:31:39.749 
Epoch 136/1000 
	 loss: 395.0449, MinusLogProbMetric: 395.0449, val_loss: 394.8742, val_MinusLogProbMetric: 394.8742

Epoch 136: val_loss did not improve from 394.60068
196/196 - 13s - loss: 395.0449 - MinusLogProbMetric: 395.0449 - val_loss: 394.8742 - val_MinusLogProbMetric: 394.8742 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 137/1000
2023-09-09 23:31:53.316 
Epoch 137/1000 
	 loss: 394.0900, MinusLogProbMetric: 394.0900, val_loss: 395.5035, val_MinusLogProbMetric: 395.5035

Epoch 137: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.0900 - MinusLogProbMetric: 394.0900 - val_loss: 395.5035 - val_MinusLogProbMetric: 395.5035 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 138/1000
2023-09-09 23:32:06.748 
Epoch 138/1000 
	 loss: 394.2774, MinusLogProbMetric: 394.2774, val_loss: 396.3993, val_MinusLogProbMetric: 396.3993

Epoch 138: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.2774 - MinusLogProbMetric: 394.2774 - val_loss: 396.3993 - val_MinusLogProbMetric: 396.3993 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 139/1000
2023-09-09 23:32:21.335 
Epoch 139/1000 
	 loss: 395.3393, MinusLogProbMetric: 395.3393, val_loss: 396.7840, val_MinusLogProbMetric: 396.7840

Epoch 139: val_loss did not improve from 394.60068
196/196 - 15s - loss: 395.3393 - MinusLogProbMetric: 395.3393 - val_loss: 396.7840 - val_MinusLogProbMetric: 396.7840 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 140/1000
2023-09-09 23:32:34.374 
Epoch 140/1000 
	 loss: 393.8857, MinusLogProbMetric: 393.8857, val_loss: 396.3131, val_MinusLogProbMetric: 396.3131

Epoch 140: val_loss did not improve from 394.60068
196/196 - 13s - loss: 393.8857 - MinusLogProbMetric: 393.8857 - val_loss: 396.3131 - val_MinusLogProbMetric: 396.3131 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 141/1000
2023-09-09 23:32:49.133 
Epoch 141/1000 
	 loss: 394.2082, MinusLogProbMetric: 394.2082, val_loss: 398.9810, val_MinusLogProbMetric: 398.9810

Epoch 141: val_loss did not improve from 394.60068
196/196 - 15s - loss: 394.2082 - MinusLogProbMetric: 394.2082 - val_loss: 398.9810 - val_MinusLogProbMetric: 398.9810 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 142/1000
2023-09-09 23:33:02.613 
Epoch 142/1000 
	 loss: 394.2515, MinusLogProbMetric: 394.2515, val_loss: 397.9521, val_MinusLogProbMetric: 397.9521

Epoch 142: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.2515 - MinusLogProbMetric: 394.2515 - val_loss: 397.9521 - val_MinusLogProbMetric: 397.9521 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 143/1000
2023-09-09 23:33:16.184 
Epoch 143/1000 
	 loss: 394.4696, MinusLogProbMetric: 394.4696, val_loss: 395.6337, val_MinusLogProbMetric: 395.6337

Epoch 143: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.4696 - MinusLogProbMetric: 394.4696 - val_loss: 395.6337 - val_MinusLogProbMetric: 395.6337 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 144/1000
2023-09-09 23:33:29.124 
Epoch 144/1000 
	 loss: 394.5405, MinusLogProbMetric: 394.5405, val_loss: 395.0652, val_MinusLogProbMetric: 395.0652

Epoch 144: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.5405 - MinusLogProbMetric: 394.5405 - val_loss: 395.0652 - val_MinusLogProbMetric: 395.0652 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 145/1000
2023-09-09 23:33:43.480 
Epoch 145/1000 
	 loss: 394.4686, MinusLogProbMetric: 394.4686, val_loss: 395.6225, val_MinusLogProbMetric: 395.6225

Epoch 145: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.4686 - MinusLogProbMetric: 394.4686 - val_loss: 395.6225 - val_MinusLogProbMetric: 395.6225 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 146/1000
2023-09-09 23:33:57.118 
Epoch 146/1000 
	 loss: 394.1468, MinusLogProbMetric: 394.1468, val_loss: 407.2775, val_MinusLogProbMetric: 407.2775

Epoch 146: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.1468 - MinusLogProbMetric: 394.1468 - val_loss: 407.2775 - val_MinusLogProbMetric: 407.2775 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 147/1000
2023-09-09 23:34:11.682 
Epoch 147/1000 
	 loss: 394.3097, MinusLogProbMetric: 394.3097, val_loss: 398.1984, val_MinusLogProbMetric: 398.1984

Epoch 147: val_loss did not improve from 394.60068
196/196 - 15s - loss: 394.3097 - MinusLogProbMetric: 394.3097 - val_loss: 398.1984 - val_MinusLogProbMetric: 398.1984 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 148/1000
2023-09-09 23:34:25.788 
Epoch 148/1000 
	 loss: 394.4855, MinusLogProbMetric: 394.4855, val_loss: 401.9397, val_MinusLogProbMetric: 401.9397

Epoch 148: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.4855 - MinusLogProbMetric: 394.4855 - val_loss: 401.9397 - val_MinusLogProbMetric: 401.9397 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 149/1000
2023-09-09 23:34:39.380 
Epoch 149/1000 
	 loss: 393.8711, MinusLogProbMetric: 393.8711, val_loss: 400.3846, val_MinusLogProbMetric: 400.3846

Epoch 149: val_loss did not improve from 394.60068
196/196 - 14s - loss: 393.8711 - MinusLogProbMetric: 393.8711 - val_loss: 400.3846 - val_MinusLogProbMetric: 400.3846 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 150/1000
2023-09-09 23:34:53.644 
Epoch 150/1000 
	 loss: 394.2696, MinusLogProbMetric: 394.2696, val_loss: 400.4745, val_MinusLogProbMetric: 400.4745

Epoch 150: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.2696 - MinusLogProbMetric: 394.2696 - val_loss: 400.4745 - val_MinusLogProbMetric: 400.4745 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 151/1000
2023-09-09 23:35:07.552 
Epoch 151/1000 
	 loss: 393.9695, MinusLogProbMetric: 393.9695, val_loss: 395.2223, val_MinusLogProbMetric: 395.2223

Epoch 151: val_loss did not improve from 394.60068
196/196 - 14s - loss: 393.9695 - MinusLogProbMetric: 393.9695 - val_loss: 395.2223 - val_MinusLogProbMetric: 395.2223 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 152/1000
2023-09-09 23:35:19.935 
Epoch 152/1000 
	 loss: 394.3163, MinusLogProbMetric: 394.3163, val_loss: 395.7107, val_MinusLogProbMetric: 395.7107

Epoch 152: val_loss did not improve from 394.60068
196/196 - 12s - loss: 394.3163 - MinusLogProbMetric: 394.3163 - val_loss: 395.7107 - val_MinusLogProbMetric: 395.7107 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 153/1000
2023-09-09 23:35:32.564 
Epoch 153/1000 
	 loss: 394.0056, MinusLogProbMetric: 394.0056, val_loss: 397.6307, val_MinusLogProbMetric: 397.6307

Epoch 153: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.0056 - MinusLogProbMetric: 394.0056 - val_loss: 397.6307 - val_MinusLogProbMetric: 397.6307 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 154/1000
2023-09-09 23:35:45.261 
Epoch 154/1000 
	 loss: 394.4222, MinusLogProbMetric: 394.4222, val_loss: 396.8900, val_MinusLogProbMetric: 396.8900

Epoch 154: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.4222 - MinusLogProbMetric: 394.4222 - val_loss: 396.8900 - val_MinusLogProbMetric: 396.8900 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 155/1000
2023-09-09 23:36:00.783 
Epoch 155/1000 
	 loss: 393.9914, MinusLogProbMetric: 393.9914, val_loss: 395.8690, val_MinusLogProbMetric: 395.8690

Epoch 155: val_loss did not improve from 394.60068
196/196 - 16s - loss: 393.9914 - MinusLogProbMetric: 393.9914 - val_loss: 395.8690 - val_MinusLogProbMetric: 395.8690 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 156/1000
2023-09-09 23:36:14.770 
Epoch 156/1000 
	 loss: 394.1301, MinusLogProbMetric: 394.1301, val_loss: 396.2165, val_MinusLogProbMetric: 396.2165

Epoch 156: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.1301 - MinusLogProbMetric: 394.1301 - val_loss: 396.2165 - val_MinusLogProbMetric: 396.2165 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 157/1000
2023-09-09 23:36:28.196 
Epoch 157/1000 
	 loss: 394.1440, MinusLogProbMetric: 394.1440, val_loss: 395.6954, val_MinusLogProbMetric: 395.6954

Epoch 157: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.1440 - MinusLogProbMetric: 394.1440 - val_loss: 395.6954 - val_MinusLogProbMetric: 395.6954 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 158/1000
2023-09-09 23:36:43.278 
Epoch 158/1000 
	 loss: 394.3736, MinusLogProbMetric: 394.3736, val_loss: 399.5386, val_MinusLogProbMetric: 399.5386

Epoch 158: val_loss did not improve from 394.60068
196/196 - 15s - loss: 394.3736 - MinusLogProbMetric: 394.3736 - val_loss: 399.5386 - val_MinusLogProbMetric: 399.5386 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 159/1000
2023-09-09 23:36:55.856 
Epoch 159/1000 
	 loss: 394.1863, MinusLogProbMetric: 394.1863, val_loss: 398.5573, val_MinusLogProbMetric: 398.5573

Epoch 159: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.1863 - MinusLogProbMetric: 394.1863 - val_loss: 398.5573 - val_MinusLogProbMetric: 398.5573 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 160/1000
2023-09-09 23:37:08.835 
Epoch 160/1000 
	 loss: 394.2055, MinusLogProbMetric: 394.2055, val_loss: 396.0439, val_MinusLogProbMetric: 396.0439

Epoch 160: val_loss did not improve from 394.60068
196/196 - 13s - loss: 394.2055 - MinusLogProbMetric: 394.2055 - val_loss: 396.0439 - val_MinusLogProbMetric: 396.0439 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 161/1000
2023-09-09 23:37:22.569 
Epoch 161/1000 
	 loss: 393.7352, MinusLogProbMetric: 393.7352, val_loss: 394.6639, val_MinusLogProbMetric: 394.6639

Epoch 161: val_loss did not improve from 394.60068
196/196 - 14s - loss: 393.7352 - MinusLogProbMetric: 393.7352 - val_loss: 394.6639 - val_MinusLogProbMetric: 394.6639 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 162/1000
2023-09-09 23:37:36.207 
Epoch 162/1000 
	 loss: 394.1778, MinusLogProbMetric: 394.1778, val_loss: 396.5315, val_MinusLogProbMetric: 396.5315

Epoch 162: val_loss did not improve from 394.60068
196/196 - 14s - loss: 394.1778 - MinusLogProbMetric: 394.1778 - val_loss: 396.5315 - val_MinusLogProbMetric: 396.5315 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 163/1000
2023-09-09 23:37:48.499 
Epoch 163/1000 
	 loss: 394.3751, MinusLogProbMetric: 394.3751, val_loss: 396.2733, val_MinusLogProbMetric: 396.2733

Epoch 163: val_loss did not improve from 394.60068
196/196 - 12s - loss: 394.3751 - MinusLogProbMetric: 394.3751 - val_loss: 396.2733 - val_MinusLogProbMetric: 396.2733 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 164/1000
2023-09-09 23:38:03.628 
Epoch 164/1000 
	 loss: 393.9186, MinusLogProbMetric: 393.9186, val_loss: 396.2746, val_MinusLogProbMetric: 396.2746

Epoch 164: val_loss did not improve from 394.60068
196/196 - 15s - loss: 393.9186 - MinusLogProbMetric: 393.9186 - val_loss: 396.2746 - val_MinusLogProbMetric: 396.2746 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 165/1000
2023-09-09 23:38:17.401 
Epoch 165/1000 
	 loss: 394.2420, MinusLogProbMetric: 394.2420, val_loss: 394.5034, val_MinusLogProbMetric: 394.5034

Epoch 165: val_loss improved from 394.60068 to 394.50336, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 14s - loss: 394.2420 - MinusLogProbMetric: 394.2420 - val_loss: 394.5034 - val_MinusLogProbMetric: 394.5034 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 166/1000
2023-09-09 23:38:31.697 
Epoch 166/1000 
	 loss: 393.7070, MinusLogProbMetric: 393.7070, val_loss: 396.3211, val_MinusLogProbMetric: 396.3211

Epoch 166: val_loss did not improve from 394.50336
196/196 - 14s - loss: 393.7070 - MinusLogProbMetric: 393.7070 - val_loss: 396.3211 - val_MinusLogProbMetric: 396.3211 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 167/1000
2023-09-09 23:38:45.949 
Epoch 167/1000 
	 loss: 394.2830, MinusLogProbMetric: 394.2830, val_loss: 396.3392, val_MinusLogProbMetric: 396.3392

Epoch 167: val_loss did not improve from 394.50336
196/196 - 14s - loss: 394.2830 - MinusLogProbMetric: 394.2830 - val_loss: 396.3392 - val_MinusLogProbMetric: 396.3392 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 168/1000
2023-09-09 23:39:00.432 
Epoch 168/1000 
	 loss: 394.2955, MinusLogProbMetric: 394.2955, val_loss: 395.4829, val_MinusLogProbMetric: 395.4829

Epoch 168: val_loss did not improve from 394.50336
196/196 - 14s - loss: 394.2955 - MinusLogProbMetric: 394.2955 - val_loss: 395.4829 - val_MinusLogProbMetric: 395.4829 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 169/1000
2023-09-09 23:39:13.496 
Epoch 169/1000 
	 loss: 393.4792, MinusLogProbMetric: 393.4792, val_loss: 396.0933, val_MinusLogProbMetric: 396.0933

Epoch 169: val_loss did not improve from 394.50336
196/196 - 13s - loss: 393.4792 - MinusLogProbMetric: 393.4792 - val_loss: 396.0933 - val_MinusLogProbMetric: 396.0933 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 170/1000
2023-09-09 23:39:28.633 
Epoch 170/1000 
	 loss: 394.4713, MinusLogProbMetric: 394.4713, val_loss: 396.3422, val_MinusLogProbMetric: 396.3422

Epoch 170: val_loss did not improve from 394.50336
196/196 - 15s - loss: 394.4713 - MinusLogProbMetric: 394.4713 - val_loss: 396.3422 - val_MinusLogProbMetric: 396.3422 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 171/1000
2023-09-09 23:39:42.810 
Epoch 171/1000 
	 loss: 394.8812, MinusLogProbMetric: 394.8812, val_loss: 396.6858, val_MinusLogProbMetric: 396.6858

Epoch 171: val_loss did not improve from 394.50336
196/196 - 14s - loss: 394.8812 - MinusLogProbMetric: 394.8812 - val_loss: 396.6858 - val_MinusLogProbMetric: 396.6858 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 172/1000
2023-09-09 23:39:56.505 
Epoch 172/1000 
	 loss: 393.3916, MinusLogProbMetric: 393.3916, val_loss: 395.6511, val_MinusLogProbMetric: 395.6511

Epoch 172: val_loss did not improve from 394.50336
196/196 - 14s - loss: 393.3916 - MinusLogProbMetric: 393.3916 - val_loss: 395.6511 - val_MinusLogProbMetric: 395.6511 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 173/1000
2023-09-09 23:40:10.501 
Epoch 173/1000 
	 loss: 393.8754, MinusLogProbMetric: 393.8754, val_loss: 399.4247, val_MinusLogProbMetric: 399.4247

Epoch 173: val_loss did not improve from 394.50336
196/196 - 14s - loss: 393.8754 - MinusLogProbMetric: 393.8754 - val_loss: 399.4247 - val_MinusLogProbMetric: 399.4247 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 174/1000
2023-09-09 23:40:23.083 
Epoch 174/1000 
	 loss: 393.5524, MinusLogProbMetric: 393.5524, val_loss: 396.6796, val_MinusLogProbMetric: 396.6796

Epoch 174: val_loss did not improve from 394.50336
196/196 - 13s - loss: 393.5524 - MinusLogProbMetric: 393.5524 - val_loss: 396.6796 - val_MinusLogProbMetric: 396.6796 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 175/1000
2023-09-09 23:40:37.525 
Epoch 175/1000 
	 loss: 394.1397, MinusLogProbMetric: 394.1397, val_loss: 395.1320, val_MinusLogProbMetric: 395.1320

Epoch 175: val_loss did not improve from 394.50336
196/196 - 14s - loss: 394.1397 - MinusLogProbMetric: 394.1397 - val_loss: 395.1320 - val_MinusLogProbMetric: 395.1320 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 176/1000
2023-09-09 23:40:51.269 
Epoch 176/1000 
	 loss: 393.1475, MinusLogProbMetric: 393.1475, val_loss: 396.4419, val_MinusLogProbMetric: 396.4419

Epoch 176: val_loss did not improve from 394.50336
196/196 - 14s - loss: 393.1475 - MinusLogProbMetric: 393.1475 - val_loss: 396.4419 - val_MinusLogProbMetric: 396.4419 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 177/1000
2023-09-09 23:41:04.900 
Epoch 177/1000 
	 loss: 394.0740, MinusLogProbMetric: 394.0740, val_loss: 395.0553, val_MinusLogProbMetric: 395.0553

Epoch 177: val_loss did not improve from 394.50336
196/196 - 14s - loss: 394.0740 - MinusLogProbMetric: 394.0740 - val_loss: 395.0553 - val_MinusLogProbMetric: 395.0553 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 178/1000
2023-09-09 23:41:17.251 
Epoch 178/1000 
	 loss: 393.8786, MinusLogProbMetric: 393.8786, val_loss: 396.6363, val_MinusLogProbMetric: 396.6363

Epoch 178: val_loss did not improve from 394.50336
196/196 - 12s - loss: 393.8786 - MinusLogProbMetric: 393.8786 - val_loss: 396.6363 - val_MinusLogProbMetric: 396.6363 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 179/1000
2023-09-09 23:41:30.086 
Epoch 179/1000 
	 loss: 396.9744, MinusLogProbMetric: 396.9744, val_loss: 396.1757, val_MinusLogProbMetric: 396.1757

Epoch 179: val_loss did not improve from 394.50336
196/196 - 13s - loss: 396.9744 - MinusLogProbMetric: 396.9744 - val_loss: 396.1757 - val_MinusLogProbMetric: 396.1757 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 180/1000
2023-09-09 23:41:45.527 
Epoch 180/1000 
	 loss: 392.6322, MinusLogProbMetric: 392.6322, val_loss: 395.6944, val_MinusLogProbMetric: 395.6944

Epoch 180: val_loss did not improve from 394.50336
196/196 - 15s - loss: 392.6322 - MinusLogProbMetric: 392.6322 - val_loss: 395.6944 - val_MinusLogProbMetric: 395.6944 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 181/1000
2023-09-09 23:41:58.485 
Epoch 181/1000 
	 loss: 393.4852, MinusLogProbMetric: 393.4852, val_loss: 396.6911, val_MinusLogProbMetric: 396.6911

Epoch 181: val_loss did not improve from 394.50336
196/196 - 13s - loss: 393.4852 - MinusLogProbMetric: 393.4852 - val_loss: 396.6911 - val_MinusLogProbMetric: 396.6911 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 182/1000
2023-09-09 23:42:13.070 
Epoch 182/1000 
	 loss: 393.4319, MinusLogProbMetric: 393.4319, val_loss: 397.6217, val_MinusLogProbMetric: 397.6217

Epoch 182: val_loss did not improve from 394.50336
196/196 - 15s - loss: 393.4319 - MinusLogProbMetric: 393.4319 - val_loss: 397.6217 - val_MinusLogProbMetric: 397.6217 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 183/1000
2023-09-09 23:42:25.636 
Epoch 183/1000 
	 loss: 393.9915, MinusLogProbMetric: 393.9915, val_loss: 394.5464, val_MinusLogProbMetric: 394.5464

Epoch 183: val_loss did not improve from 394.50336
196/196 - 13s - loss: 393.9915 - MinusLogProbMetric: 393.9915 - val_loss: 394.5464 - val_MinusLogProbMetric: 394.5464 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 184/1000
2023-09-09 23:42:39.443 
Epoch 184/1000 
	 loss: 393.5442, MinusLogProbMetric: 393.5442, val_loss: 396.9233, val_MinusLogProbMetric: 396.9233

Epoch 184: val_loss did not improve from 394.50336
196/196 - 14s - loss: 393.5442 - MinusLogProbMetric: 393.5442 - val_loss: 396.9233 - val_MinusLogProbMetric: 396.9233 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 185/1000
2023-09-09 23:42:54.596 
Epoch 185/1000 
	 loss: 393.2744, MinusLogProbMetric: 393.2744, val_loss: 396.2660, val_MinusLogProbMetric: 396.2660

Epoch 185: val_loss did not improve from 394.50336
196/196 - 15s - loss: 393.2744 - MinusLogProbMetric: 393.2744 - val_loss: 396.2660 - val_MinusLogProbMetric: 396.2660 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 186/1000
2023-09-09 23:43:07.150 
Epoch 186/1000 
	 loss: 394.9634, MinusLogProbMetric: 394.9634, val_loss: 395.4300, val_MinusLogProbMetric: 395.4300

Epoch 186: val_loss did not improve from 394.50336
196/196 - 13s - loss: 394.9634 - MinusLogProbMetric: 394.9634 - val_loss: 395.4300 - val_MinusLogProbMetric: 395.4300 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 187/1000
2023-09-09 23:43:21.169 
Epoch 187/1000 
	 loss: 393.2190, MinusLogProbMetric: 393.2190, val_loss: 398.5206, val_MinusLogProbMetric: 398.5206

Epoch 187: val_loss did not improve from 394.50336
196/196 - 14s - loss: 393.2190 - MinusLogProbMetric: 393.2190 - val_loss: 398.5206 - val_MinusLogProbMetric: 398.5206 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 188/1000
2023-09-09 23:43:33.749 
Epoch 188/1000 
	 loss: 397.0836, MinusLogProbMetric: 397.0836, val_loss: 395.1068, val_MinusLogProbMetric: 395.1068

Epoch 188: val_loss did not improve from 394.50336
196/196 - 13s - loss: 397.0836 - MinusLogProbMetric: 397.0836 - val_loss: 395.1068 - val_MinusLogProbMetric: 395.1068 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 189/1000
2023-09-09 23:43:48.098 
Epoch 189/1000 
	 loss: 392.8756, MinusLogProbMetric: 392.8756, val_loss: 396.4474, val_MinusLogProbMetric: 396.4474

Epoch 189: val_loss did not improve from 394.50336
196/196 - 14s - loss: 392.8756 - MinusLogProbMetric: 392.8756 - val_loss: 396.4474 - val_MinusLogProbMetric: 396.4474 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 190/1000
2023-09-09 23:43:59.960 
Epoch 190/1000 
	 loss: 393.9261, MinusLogProbMetric: 393.9261, val_loss: 395.5372, val_MinusLogProbMetric: 395.5372

Epoch 190: val_loss did not improve from 394.50336
196/196 - 12s - loss: 393.9261 - MinusLogProbMetric: 393.9261 - val_loss: 395.5372 - val_MinusLogProbMetric: 395.5372 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 191/1000
2023-09-09 23:44:13.461 
Epoch 191/1000 
	 loss: 392.9377, MinusLogProbMetric: 392.9377, val_loss: 396.1781, val_MinusLogProbMetric: 396.1781

Epoch 191: val_loss did not improve from 394.50336
196/196 - 13s - loss: 392.9377 - MinusLogProbMetric: 392.9377 - val_loss: 396.1781 - val_MinusLogProbMetric: 396.1781 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 192/1000
2023-09-09 23:44:27.177 
Epoch 192/1000 
	 loss: 394.6339, MinusLogProbMetric: 394.6339, val_loss: 398.6705, val_MinusLogProbMetric: 398.6705

Epoch 192: val_loss did not improve from 394.50336
196/196 - 14s - loss: 394.6339 - MinusLogProbMetric: 394.6339 - val_loss: 398.6705 - val_MinusLogProbMetric: 398.6705 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 193/1000
2023-09-09 23:44:39.555 
Epoch 193/1000 
	 loss: 392.7720, MinusLogProbMetric: 392.7720, val_loss: 398.8598, val_MinusLogProbMetric: 398.8598

Epoch 193: val_loss did not improve from 394.50336
196/196 - 12s - loss: 392.7720 - MinusLogProbMetric: 392.7720 - val_loss: 398.8598 - val_MinusLogProbMetric: 398.8598 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 194/1000
2023-09-09 23:44:53.469 
Epoch 194/1000 
	 loss: 393.3006, MinusLogProbMetric: 393.3006, val_loss: 404.6473, val_MinusLogProbMetric: 404.6473

Epoch 194: val_loss did not improve from 394.50336
196/196 - 14s - loss: 393.3006 - MinusLogProbMetric: 393.3006 - val_loss: 404.6473 - val_MinusLogProbMetric: 404.6473 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 195/1000
2023-09-09 23:45:04.974 
Epoch 195/1000 
	 loss: 393.8445, MinusLogProbMetric: 393.8445, val_loss: 394.3471, val_MinusLogProbMetric: 394.3471

Epoch 195: val_loss improved from 394.50336 to 394.34714, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 12s - loss: 393.8445 - MinusLogProbMetric: 393.8445 - val_loss: 394.3471 - val_MinusLogProbMetric: 394.3471 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 196/1000
2023-09-09 23:45:19.378 
Epoch 196/1000 
	 loss: 393.1358, MinusLogProbMetric: 393.1358, val_loss: 396.6797, val_MinusLogProbMetric: 396.6797

Epoch 196: val_loss did not improve from 394.34714
196/196 - 14s - loss: 393.1358 - MinusLogProbMetric: 393.1358 - val_loss: 396.6797 - val_MinusLogProbMetric: 396.6797 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 197/1000
2023-09-09 23:45:32.107 
Epoch 197/1000 
	 loss: 393.6286, MinusLogProbMetric: 393.6286, val_loss: 394.7597, val_MinusLogProbMetric: 394.7597

Epoch 197: val_loss did not improve from 394.34714
196/196 - 13s - loss: 393.6286 - MinusLogProbMetric: 393.6286 - val_loss: 394.7597 - val_MinusLogProbMetric: 394.7597 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 198/1000
2023-09-09 23:45:45.643 
Epoch 198/1000 
	 loss: 394.5644, MinusLogProbMetric: 394.5644, val_loss: 395.4955, val_MinusLogProbMetric: 395.4955

Epoch 198: val_loss did not improve from 394.34714
196/196 - 14s - loss: 394.5644 - MinusLogProbMetric: 394.5644 - val_loss: 395.4955 - val_MinusLogProbMetric: 395.4955 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 199/1000
2023-09-09 23:45:58.549 
Epoch 199/1000 
	 loss: 392.6554, MinusLogProbMetric: 392.6554, val_loss: 396.6397, val_MinusLogProbMetric: 396.6397

Epoch 199: val_loss did not improve from 394.34714
196/196 - 13s - loss: 392.6554 - MinusLogProbMetric: 392.6554 - val_loss: 396.6397 - val_MinusLogProbMetric: 396.6397 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 200/1000
2023-09-09 23:46:11.839 
Epoch 200/1000 
	 loss: 394.2435, MinusLogProbMetric: 394.2435, val_loss: 399.8597, val_MinusLogProbMetric: 399.8597

Epoch 200: val_loss did not improve from 394.34714
196/196 - 13s - loss: 394.2435 - MinusLogProbMetric: 394.2435 - val_loss: 399.8597 - val_MinusLogProbMetric: 399.8597 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 201/1000
2023-09-09 23:46:24.789 
Epoch 201/1000 
	 loss: 393.0911, MinusLogProbMetric: 393.0911, val_loss: 397.3164, val_MinusLogProbMetric: 397.3164

Epoch 201: val_loss did not improve from 394.34714
196/196 - 13s - loss: 393.0911 - MinusLogProbMetric: 393.0911 - val_loss: 397.3164 - val_MinusLogProbMetric: 397.3164 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 202/1000
2023-09-09 23:46:38.990 
Epoch 202/1000 
	 loss: 393.3809, MinusLogProbMetric: 393.3809, val_loss: 396.8533, val_MinusLogProbMetric: 396.8533

Epoch 202: val_loss did not improve from 394.34714
196/196 - 14s - loss: 393.3809 - MinusLogProbMetric: 393.3809 - val_loss: 396.8533 - val_MinusLogProbMetric: 396.8533 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 203/1000
2023-09-09 23:46:52.598 
Epoch 203/1000 
	 loss: 393.2393, MinusLogProbMetric: 393.2393, val_loss: 421.7880, val_MinusLogProbMetric: 421.7880

Epoch 203: val_loss did not improve from 394.34714
196/196 - 14s - loss: 393.2393 - MinusLogProbMetric: 393.2393 - val_loss: 421.7880 - val_MinusLogProbMetric: 421.7880 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 204/1000
2023-09-09 23:47:06.526 
Epoch 204/1000 
	 loss: 393.7995, MinusLogProbMetric: 393.7995, val_loss: 402.5314, val_MinusLogProbMetric: 402.5314

Epoch 204: val_loss did not improve from 394.34714
196/196 - 14s - loss: 393.7995 - MinusLogProbMetric: 393.7995 - val_loss: 402.5314 - val_MinusLogProbMetric: 402.5314 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 205/1000
2023-09-09 23:47:19.909 
Epoch 205/1000 
	 loss: 393.9378, MinusLogProbMetric: 393.9378, val_loss: 404.4083, val_MinusLogProbMetric: 404.4083

Epoch 205: val_loss did not improve from 394.34714
196/196 - 13s - loss: 393.9378 - MinusLogProbMetric: 393.9378 - val_loss: 404.4083 - val_MinusLogProbMetric: 404.4083 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 206/1000
2023-09-09 23:47:33.333 
Epoch 206/1000 
	 loss: 393.1816, MinusLogProbMetric: 393.1816, val_loss: 397.1204, val_MinusLogProbMetric: 397.1204

Epoch 206: val_loss did not improve from 394.34714
196/196 - 13s - loss: 393.1816 - MinusLogProbMetric: 393.1816 - val_loss: 397.1204 - val_MinusLogProbMetric: 397.1204 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 207/1000
2023-09-09 23:47:47.559 
Epoch 207/1000 
	 loss: 393.2570, MinusLogProbMetric: 393.2570, val_loss: 398.2658, val_MinusLogProbMetric: 398.2658

Epoch 207: val_loss did not improve from 394.34714
196/196 - 14s - loss: 393.2570 - MinusLogProbMetric: 393.2570 - val_loss: 398.2658 - val_MinusLogProbMetric: 398.2658 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 208/1000
2023-09-09 23:47:59.630 
Epoch 208/1000 
	 loss: 393.6035, MinusLogProbMetric: 393.6035, val_loss: 394.8744, val_MinusLogProbMetric: 394.8744

Epoch 208: val_loss did not improve from 394.34714
196/196 - 12s - loss: 393.6035 - MinusLogProbMetric: 393.6035 - val_loss: 394.8744 - val_MinusLogProbMetric: 394.8744 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 209/1000
2023-09-09 23:48:12.417 
Epoch 209/1000 
	 loss: 393.2261, MinusLogProbMetric: 393.2261, val_loss: 396.2834, val_MinusLogProbMetric: 396.2834

Epoch 209: val_loss did not improve from 394.34714
196/196 - 13s - loss: 393.2261 - MinusLogProbMetric: 393.2261 - val_loss: 396.2834 - val_MinusLogProbMetric: 396.2834 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 210/1000
2023-09-09 23:48:25.220 
Epoch 210/1000 
	 loss: 393.3661, MinusLogProbMetric: 393.3661, val_loss: 399.7314, val_MinusLogProbMetric: 399.7314

Epoch 210: val_loss did not improve from 394.34714
196/196 - 13s - loss: 393.3661 - MinusLogProbMetric: 393.3661 - val_loss: 399.7314 - val_MinusLogProbMetric: 399.7314 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 211/1000
2023-09-09 23:48:39.780 
Epoch 211/1000 
	 loss: 392.9759, MinusLogProbMetric: 392.9759, val_loss: 395.4562, val_MinusLogProbMetric: 395.4562

Epoch 211: val_loss did not improve from 394.34714
196/196 - 15s - loss: 392.9759 - MinusLogProbMetric: 392.9759 - val_loss: 395.4562 - val_MinusLogProbMetric: 395.4562 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 212/1000
2023-09-09 23:48:54.250 
Epoch 212/1000 
	 loss: 393.2008, MinusLogProbMetric: 393.2008, val_loss: 396.7112, val_MinusLogProbMetric: 396.7112

Epoch 212: val_loss did not improve from 394.34714
196/196 - 14s - loss: 393.2008 - MinusLogProbMetric: 393.2008 - val_loss: 396.7112 - val_MinusLogProbMetric: 396.7112 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 213/1000
2023-09-09 23:49:08.668 
Epoch 213/1000 
	 loss: 395.9548, MinusLogProbMetric: 395.9548, val_loss: 394.7470, val_MinusLogProbMetric: 394.7470

Epoch 213: val_loss did not improve from 394.34714
196/196 - 14s - loss: 395.9548 - MinusLogProbMetric: 395.9548 - val_loss: 394.7470 - val_MinusLogProbMetric: 394.7470 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 214/1000
2023-09-09 23:49:22.141 
Epoch 214/1000 
	 loss: 392.5535, MinusLogProbMetric: 392.5535, val_loss: 396.4486, val_MinusLogProbMetric: 396.4486

Epoch 214: val_loss did not improve from 394.34714
196/196 - 13s - loss: 392.5535 - MinusLogProbMetric: 392.5535 - val_loss: 396.4486 - val_MinusLogProbMetric: 396.4486 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 215/1000
2023-09-09 23:49:36.296 
Epoch 215/1000 
	 loss: 392.9656, MinusLogProbMetric: 392.9656, val_loss: 395.8644, val_MinusLogProbMetric: 395.8644

Epoch 215: val_loss did not improve from 394.34714
196/196 - 14s - loss: 392.9656 - MinusLogProbMetric: 392.9656 - val_loss: 395.8644 - val_MinusLogProbMetric: 395.8644 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 216/1000
2023-09-09 23:49:49.448 
Epoch 216/1000 
	 loss: 393.3770, MinusLogProbMetric: 393.3770, val_loss: 393.6663, val_MinusLogProbMetric: 393.6663

Epoch 216: val_loss improved from 394.34714 to 393.66632, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 14s - loss: 393.3770 - MinusLogProbMetric: 393.3770 - val_loss: 393.6663 - val_MinusLogProbMetric: 393.6663 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 217/1000
2023-09-09 23:50:00.941 
Epoch 217/1000 
	 loss: 393.4327, MinusLogProbMetric: 393.4327, val_loss: 397.8405, val_MinusLogProbMetric: 397.8405

Epoch 217: val_loss did not improve from 393.66632
196/196 - 11s - loss: 393.4327 - MinusLogProbMetric: 393.4327 - val_loss: 397.8405 - val_MinusLogProbMetric: 397.8405 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 218/1000
2023-09-09 23:50:14.041 
Epoch 218/1000 
	 loss: 393.1766, MinusLogProbMetric: 393.1766, val_loss: 396.4541, val_MinusLogProbMetric: 396.4541

Epoch 218: val_loss did not improve from 393.66632
196/196 - 13s - loss: 393.1766 - MinusLogProbMetric: 393.1766 - val_loss: 396.4541 - val_MinusLogProbMetric: 396.4541 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 219/1000
2023-09-09 23:50:28.725 
Epoch 219/1000 
	 loss: 393.4265, MinusLogProbMetric: 393.4265, val_loss: 398.5695, val_MinusLogProbMetric: 398.5695

Epoch 219: val_loss did not improve from 393.66632
196/196 - 15s - loss: 393.4265 - MinusLogProbMetric: 393.4265 - val_loss: 398.5695 - val_MinusLogProbMetric: 398.5695 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 220/1000
2023-09-09 23:50:41.208 
Epoch 220/1000 
	 loss: 393.4988, MinusLogProbMetric: 393.4988, val_loss: 396.0629, val_MinusLogProbMetric: 396.0629

Epoch 220: val_loss did not improve from 393.66632
196/196 - 12s - loss: 393.4988 - MinusLogProbMetric: 393.4988 - val_loss: 396.0629 - val_MinusLogProbMetric: 396.0629 - lr: 3.3333e-04 - 12s/epoch - 64ms/step
Epoch 221/1000
2023-09-09 23:50:56.946 
Epoch 221/1000 
	 loss: 392.8665, MinusLogProbMetric: 392.8665, val_loss: 396.0636, val_MinusLogProbMetric: 396.0636

Epoch 221: val_loss did not improve from 393.66632
196/196 - 16s - loss: 392.8665 - MinusLogProbMetric: 392.8665 - val_loss: 396.0636 - val_MinusLogProbMetric: 396.0636 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 222/1000
2023-09-09 23:51:10.074 
Epoch 222/1000 
	 loss: 393.2243, MinusLogProbMetric: 393.2243, val_loss: 397.9451, val_MinusLogProbMetric: 397.9451

Epoch 222: val_loss did not improve from 393.66632
196/196 - 13s - loss: 393.2243 - MinusLogProbMetric: 393.2243 - val_loss: 397.9451 - val_MinusLogProbMetric: 397.9451 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 223/1000
2023-09-09 23:51:22.700 
Epoch 223/1000 
	 loss: 393.0101, MinusLogProbMetric: 393.0101, val_loss: 403.5837, val_MinusLogProbMetric: 403.5837

Epoch 223: val_loss did not improve from 393.66632
196/196 - 13s - loss: 393.0101 - MinusLogProbMetric: 393.0101 - val_loss: 403.5837 - val_MinusLogProbMetric: 403.5837 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 224/1000
2023-09-09 23:51:36.460 
Epoch 224/1000 
	 loss: 393.2406, MinusLogProbMetric: 393.2406, val_loss: 396.2422, val_MinusLogProbMetric: 396.2422

Epoch 224: val_loss did not improve from 393.66632
196/196 - 14s - loss: 393.2406 - MinusLogProbMetric: 393.2406 - val_loss: 396.2422 - val_MinusLogProbMetric: 396.2422 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 225/1000
2023-09-09 23:51:49.400 
Epoch 225/1000 
	 loss: 392.9643, MinusLogProbMetric: 392.9643, val_loss: 395.2420, val_MinusLogProbMetric: 395.2420

Epoch 225: val_loss did not improve from 393.66632
196/196 - 13s - loss: 392.9643 - MinusLogProbMetric: 392.9643 - val_loss: 395.2420 - val_MinusLogProbMetric: 395.2420 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 226/1000
2023-09-09 23:52:01.176 
Epoch 226/1000 
	 loss: 393.2018, MinusLogProbMetric: 393.2018, val_loss: 397.4248, val_MinusLogProbMetric: 397.4248

Epoch 226: val_loss did not improve from 393.66632
196/196 - 12s - loss: 393.2018 - MinusLogProbMetric: 393.2018 - val_loss: 397.4248 - val_MinusLogProbMetric: 397.4248 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 227/1000
2023-09-09 23:52:13.855 
Epoch 227/1000 
	 loss: 393.0524, MinusLogProbMetric: 393.0524, val_loss: 397.0558, val_MinusLogProbMetric: 397.0558

Epoch 227: val_loss did not improve from 393.66632
196/196 - 13s - loss: 393.0524 - MinusLogProbMetric: 393.0524 - val_loss: 397.0558 - val_MinusLogProbMetric: 397.0558 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 228/1000
2023-09-09 23:52:24.865 
Epoch 228/1000 
	 loss: 393.6126, MinusLogProbMetric: 393.6126, val_loss: 395.4819, val_MinusLogProbMetric: 395.4819

Epoch 228: val_loss did not improve from 393.66632
196/196 - 11s - loss: 393.6126 - MinusLogProbMetric: 393.6126 - val_loss: 395.4819 - val_MinusLogProbMetric: 395.4819 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 229/1000
2023-09-09 23:52:38.762 
Epoch 229/1000 
	 loss: 393.0163, MinusLogProbMetric: 393.0163, val_loss: 395.5470, val_MinusLogProbMetric: 395.5470

Epoch 229: val_loss did not improve from 393.66632
196/196 - 14s - loss: 393.0163 - MinusLogProbMetric: 393.0163 - val_loss: 395.5470 - val_MinusLogProbMetric: 395.5470 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 230/1000
2023-09-09 23:52:53.960 
Epoch 230/1000 
	 loss: 393.4850, MinusLogProbMetric: 393.4850, val_loss: 399.9678, val_MinusLogProbMetric: 399.9678

Epoch 230: val_loss did not improve from 393.66632
196/196 - 15s - loss: 393.4850 - MinusLogProbMetric: 393.4850 - val_loss: 399.9678 - val_MinusLogProbMetric: 399.9678 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 231/1000
2023-09-09 23:53:06.384 
Epoch 231/1000 
	 loss: 393.1013, MinusLogProbMetric: 393.1013, val_loss: 394.0635, val_MinusLogProbMetric: 394.0635

Epoch 231: val_loss did not improve from 393.66632
196/196 - 12s - loss: 393.1013 - MinusLogProbMetric: 393.1013 - val_loss: 394.0635 - val_MinusLogProbMetric: 394.0635 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 232/1000
2023-09-09 23:53:21.676 
Epoch 232/1000 
	 loss: 393.0438, MinusLogProbMetric: 393.0438, val_loss: 396.1977, val_MinusLogProbMetric: 396.1977

Epoch 232: val_loss did not improve from 393.66632
196/196 - 15s - loss: 393.0438 - MinusLogProbMetric: 393.0438 - val_loss: 396.1977 - val_MinusLogProbMetric: 396.1977 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 233/1000
2023-09-09 23:53:33.190 
Epoch 233/1000 
	 loss: 397.5135, MinusLogProbMetric: 397.5135, val_loss: 396.0802, val_MinusLogProbMetric: 396.0802

Epoch 233: val_loss did not improve from 393.66632
196/196 - 12s - loss: 397.5135 - MinusLogProbMetric: 397.5135 - val_loss: 396.0802 - val_MinusLogProbMetric: 396.0802 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 234/1000
2023-09-09 23:53:46.566 
Epoch 234/1000 
	 loss: 392.3900, MinusLogProbMetric: 392.3900, val_loss: 395.2626, val_MinusLogProbMetric: 395.2626

Epoch 234: val_loss did not improve from 393.66632
196/196 - 13s - loss: 392.3900 - MinusLogProbMetric: 392.3900 - val_loss: 395.2626 - val_MinusLogProbMetric: 395.2626 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 235/1000
2023-09-09 23:54:00.367 
Epoch 235/1000 
	 loss: 392.5125, MinusLogProbMetric: 392.5125, val_loss: 396.8350, val_MinusLogProbMetric: 396.8350

Epoch 235: val_loss did not improve from 393.66632
196/196 - 14s - loss: 392.5125 - MinusLogProbMetric: 392.5125 - val_loss: 396.8350 - val_MinusLogProbMetric: 396.8350 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 236/1000
2023-09-09 23:54:15.070 
Epoch 236/1000 
	 loss: 393.3064, MinusLogProbMetric: 393.3064, val_loss: 395.8076, val_MinusLogProbMetric: 395.8076

Epoch 236: val_loss did not improve from 393.66632
196/196 - 15s - loss: 393.3064 - MinusLogProbMetric: 393.3064 - val_loss: 395.8076 - val_MinusLogProbMetric: 395.8076 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 237/1000
2023-09-09 23:54:28.749 
Epoch 237/1000 
	 loss: 392.9926, MinusLogProbMetric: 392.9926, val_loss: 398.2552, val_MinusLogProbMetric: 398.2552

Epoch 237: val_loss did not improve from 393.66632
196/196 - 14s - loss: 392.9926 - MinusLogProbMetric: 392.9926 - val_loss: 398.2552 - val_MinusLogProbMetric: 398.2552 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 238/1000
2023-09-09 23:54:43.627 
Epoch 238/1000 
	 loss: 392.9287, MinusLogProbMetric: 392.9287, val_loss: 395.3412, val_MinusLogProbMetric: 395.3412

Epoch 238: val_loss did not improve from 393.66632
196/196 - 15s - loss: 392.9287 - MinusLogProbMetric: 392.9287 - val_loss: 395.3412 - val_MinusLogProbMetric: 395.3412 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 239/1000
2023-09-09 23:54:57.136 
Epoch 239/1000 
	 loss: 392.9136, MinusLogProbMetric: 392.9136, val_loss: 396.8718, val_MinusLogProbMetric: 396.8718

Epoch 239: val_loss did not improve from 393.66632
196/196 - 13s - loss: 392.9136 - MinusLogProbMetric: 392.9136 - val_loss: 396.8718 - val_MinusLogProbMetric: 396.8718 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 240/1000
2023-09-09 23:55:09.717 
Epoch 240/1000 
	 loss: 393.4218, MinusLogProbMetric: 393.4218, val_loss: 397.8751, val_MinusLogProbMetric: 397.8751

Epoch 240: val_loss did not improve from 393.66632
196/196 - 13s - loss: 393.4218 - MinusLogProbMetric: 393.4218 - val_loss: 397.8751 - val_MinusLogProbMetric: 397.8751 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 241/1000
2023-09-09 23:55:23.596 
Epoch 241/1000 
	 loss: 393.3332, MinusLogProbMetric: 393.3332, val_loss: 396.2013, val_MinusLogProbMetric: 396.2013

Epoch 241: val_loss did not improve from 393.66632
196/196 - 14s - loss: 393.3332 - MinusLogProbMetric: 393.3332 - val_loss: 396.2013 - val_MinusLogProbMetric: 396.2013 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 242/1000
2023-09-09 23:55:36.220 
Epoch 242/1000 
	 loss: 392.7511, MinusLogProbMetric: 392.7511, val_loss: 397.0074, val_MinusLogProbMetric: 397.0074

Epoch 242: val_loss did not improve from 393.66632
196/196 - 13s - loss: 392.7511 - MinusLogProbMetric: 392.7511 - val_loss: 397.0074 - val_MinusLogProbMetric: 397.0074 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 243/1000
2023-09-09 23:55:48.421 
Epoch 243/1000 
	 loss: 393.1008, MinusLogProbMetric: 393.1008, val_loss: 396.4356, val_MinusLogProbMetric: 396.4356

Epoch 243: val_loss did not improve from 393.66632
196/196 - 12s - loss: 393.1008 - MinusLogProbMetric: 393.1008 - val_loss: 396.4356 - val_MinusLogProbMetric: 396.4356 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 244/1000
2023-09-09 23:56:03.051 
Epoch 244/1000 
	 loss: 393.6953, MinusLogProbMetric: 393.6953, val_loss: 394.3608, val_MinusLogProbMetric: 394.3608

Epoch 244: val_loss did not improve from 393.66632
196/196 - 15s - loss: 393.6953 - MinusLogProbMetric: 393.6953 - val_loss: 394.3608 - val_MinusLogProbMetric: 394.3608 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 245/1000
2023-09-09 23:56:16.619 
Epoch 245/1000 
	 loss: 392.6479, MinusLogProbMetric: 392.6479, val_loss: 396.5335, val_MinusLogProbMetric: 396.5335

Epoch 245: val_loss did not improve from 393.66632
196/196 - 14s - loss: 392.6479 - MinusLogProbMetric: 392.6479 - val_loss: 396.5335 - val_MinusLogProbMetric: 396.5335 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 246/1000
2023-09-09 23:56:30.009 
Epoch 246/1000 
	 loss: 392.9828, MinusLogProbMetric: 392.9828, val_loss: 395.9640, val_MinusLogProbMetric: 395.9640

Epoch 246: val_loss did not improve from 393.66632
196/196 - 13s - loss: 392.9828 - MinusLogProbMetric: 392.9828 - val_loss: 395.9640 - val_MinusLogProbMetric: 395.9640 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 247/1000
2023-09-09 23:56:42.859 
Epoch 247/1000 
	 loss: 393.4916, MinusLogProbMetric: 393.4916, val_loss: 393.3095, val_MinusLogProbMetric: 393.3095

Epoch 247: val_loss improved from 393.66632 to 393.30954, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 13s - loss: 393.4916 - MinusLogProbMetric: 393.4916 - val_loss: 393.3095 - val_MinusLogProbMetric: 393.3095 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 248/1000
2023-09-09 23:56:57.463 
Epoch 248/1000 
	 loss: 392.6491, MinusLogProbMetric: 392.6491, val_loss: 396.2824, val_MinusLogProbMetric: 396.2824

Epoch 248: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.6491 - MinusLogProbMetric: 392.6491 - val_loss: 396.2824 - val_MinusLogProbMetric: 396.2824 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 249/1000
2023-09-09 23:57:11.571 
Epoch 249/1000 
	 loss: 393.8951, MinusLogProbMetric: 393.8951, val_loss: 394.6477, val_MinusLogProbMetric: 394.6477

Epoch 249: val_loss did not improve from 393.30954
196/196 - 14s - loss: 393.8951 - MinusLogProbMetric: 393.8951 - val_loss: 394.6477 - val_MinusLogProbMetric: 394.6477 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 250/1000
2023-09-09 23:57:24.871 
Epoch 250/1000 
	 loss: 392.4793, MinusLogProbMetric: 392.4793, val_loss: 396.4171, val_MinusLogProbMetric: 396.4171

Epoch 250: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.4793 - MinusLogProbMetric: 392.4793 - val_loss: 396.4171 - val_MinusLogProbMetric: 396.4171 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 251/1000
2023-09-09 23:57:37.073 
Epoch 251/1000 
	 loss: 392.6053, MinusLogProbMetric: 392.6053, val_loss: 396.8911, val_MinusLogProbMetric: 396.8911

Epoch 251: val_loss did not improve from 393.30954
196/196 - 12s - loss: 392.6053 - MinusLogProbMetric: 392.6053 - val_loss: 396.8911 - val_MinusLogProbMetric: 396.8911 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 252/1000
2023-09-09 23:57:50.124 
Epoch 252/1000 
	 loss: 392.9682, MinusLogProbMetric: 392.9682, val_loss: 394.8533, val_MinusLogProbMetric: 394.8533

Epoch 252: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.9682 - MinusLogProbMetric: 392.9682 - val_loss: 394.8533 - val_MinusLogProbMetric: 394.8533 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 253/1000
2023-09-09 23:58:03.325 
Epoch 253/1000 
	 loss: 393.2535, MinusLogProbMetric: 393.2535, val_loss: 395.7075, val_MinusLogProbMetric: 395.7075

Epoch 253: val_loss did not improve from 393.30954
196/196 - 13s - loss: 393.2535 - MinusLogProbMetric: 393.2535 - val_loss: 395.7075 - val_MinusLogProbMetric: 395.7075 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 254/1000
2023-09-09 23:58:15.409 
Epoch 254/1000 
	 loss: 392.8330, MinusLogProbMetric: 392.8330, val_loss: 394.4267, val_MinusLogProbMetric: 394.4267

Epoch 254: val_loss did not improve from 393.30954
196/196 - 12s - loss: 392.8330 - MinusLogProbMetric: 392.8330 - val_loss: 394.4267 - val_MinusLogProbMetric: 394.4267 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 255/1000
2023-09-09 23:58:30.268 
Epoch 255/1000 
	 loss: 393.3915, MinusLogProbMetric: 393.3915, val_loss: 393.8009, val_MinusLogProbMetric: 393.8009

Epoch 255: val_loss did not improve from 393.30954
196/196 - 15s - loss: 393.3915 - MinusLogProbMetric: 393.3915 - val_loss: 393.8009 - val_MinusLogProbMetric: 393.8009 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 256/1000
2023-09-09 23:58:43.140 
Epoch 256/1000 
	 loss: 392.7519, MinusLogProbMetric: 392.7519, val_loss: 396.9002, val_MinusLogProbMetric: 396.9002

Epoch 256: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.7519 - MinusLogProbMetric: 392.7519 - val_loss: 396.9002 - val_MinusLogProbMetric: 396.9002 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 257/1000
2023-09-09 23:58:56.868 
Epoch 257/1000 
	 loss: 392.8730, MinusLogProbMetric: 392.8730, val_loss: 395.5052, val_MinusLogProbMetric: 395.5052

Epoch 257: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.8730 - MinusLogProbMetric: 392.8730 - val_loss: 395.5052 - val_MinusLogProbMetric: 395.5052 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 258/1000
2023-09-09 23:59:10.869 
Epoch 258/1000 
	 loss: 393.4834, MinusLogProbMetric: 393.4834, val_loss: 394.0361, val_MinusLogProbMetric: 394.0361

Epoch 258: val_loss did not improve from 393.30954
196/196 - 14s - loss: 393.4834 - MinusLogProbMetric: 393.4834 - val_loss: 394.0361 - val_MinusLogProbMetric: 394.0361 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 259/1000
2023-09-09 23:59:24.710 
Epoch 259/1000 
	 loss: 392.5205, MinusLogProbMetric: 392.5205, val_loss: 396.6958, val_MinusLogProbMetric: 396.6958

Epoch 259: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.5205 - MinusLogProbMetric: 392.5205 - val_loss: 396.6958 - val_MinusLogProbMetric: 396.6958 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 260/1000
2023-09-09 23:59:37.750 
Epoch 260/1000 
	 loss: 393.4657, MinusLogProbMetric: 393.4657, val_loss: 395.2579, val_MinusLogProbMetric: 395.2579

Epoch 260: val_loss did not improve from 393.30954
196/196 - 13s - loss: 393.4657 - MinusLogProbMetric: 393.4657 - val_loss: 395.2579 - val_MinusLogProbMetric: 395.2579 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 261/1000
2023-09-09 23:59:50.690 
Epoch 261/1000 
	 loss: 392.4294, MinusLogProbMetric: 392.4294, val_loss: 395.0714, val_MinusLogProbMetric: 395.0714

Epoch 261: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.4294 - MinusLogProbMetric: 392.4294 - val_loss: 395.0714 - val_MinusLogProbMetric: 395.0714 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 262/1000
2023-09-10 00:00:05.694 
Epoch 262/1000 
	 loss: 393.5617, MinusLogProbMetric: 393.5617, val_loss: 393.7240, val_MinusLogProbMetric: 393.7240

Epoch 262: val_loss did not improve from 393.30954
196/196 - 15s - loss: 393.5617 - MinusLogProbMetric: 393.5617 - val_loss: 393.7240 - val_MinusLogProbMetric: 393.7240 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 263/1000
2023-09-10 00:00:18.188 
Epoch 263/1000 
	 loss: 392.8221, MinusLogProbMetric: 392.8221, val_loss: 397.7427, val_MinusLogProbMetric: 397.7427

Epoch 263: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.8221 - MinusLogProbMetric: 392.8221 - val_loss: 397.7427 - val_MinusLogProbMetric: 397.7427 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 264/1000
2023-09-10 00:00:31.554 
Epoch 264/1000 
	 loss: 392.7515, MinusLogProbMetric: 392.7515, val_loss: 396.6510, val_MinusLogProbMetric: 396.6510

Epoch 264: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.7515 - MinusLogProbMetric: 392.7515 - val_loss: 396.6510 - val_MinusLogProbMetric: 396.6510 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 265/1000
2023-09-10 00:00:43.389 
Epoch 265/1000 
	 loss: 392.7178, MinusLogProbMetric: 392.7178, val_loss: 396.0382, val_MinusLogProbMetric: 396.0382

Epoch 265: val_loss did not improve from 393.30954
196/196 - 12s - loss: 392.7178 - MinusLogProbMetric: 392.7178 - val_loss: 396.0382 - val_MinusLogProbMetric: 396.0382 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 266/1000
2023-09-10 00:00:58.101 
Epoch 266/1000 
	 loss: 392.9019, MinusLogProbMetric: 392.9019, val_loss: 397.3346, val_MinusLogProbMetric: 397.3346

Epoch 266: val_loss did not improve from 393.30954
196/196 - 15s - loss: 392.9019 - MinusLogProbMetric: 392.9019 - val_loss: 397.3346 - val_MinusLogProbMetric: 397.3346 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 267/1000
2023-09-10 00:01:11.402 
Epoch 267/1000 
	 loss: 395.0132, MinusLogProbMetric: 395.0132, val_loss: 395.5092, val_MinusLogProbMetric: 395.5092

Epoch 267: val_loss did not improve from 393.30954
196/196 - 13s - loss: 395.0132 - MinusLogProbMetric: 395.0132 - val_loss: 395.5092 - val_MinusLogProbMetric: 395.5092 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 268/1000
2023-09-10 00:01:24.505 
Epoch 268/1000 
	 loss: 392.0264, MinusLogProbMetric: 392.0264, val_loss: 394.5836, val_MinusLogProbMetric: 394.5836

Epoch 268: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.0264 - MinusLogProbMetric: 392.0264 - val_loss: 394.5836 - val_MinusLogProbMetric: 394.5836 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 269/1000
2023-09-10 00:01:39.539 
Epoch 269/1000 
	 loss: 392.7648, MinusLogProbMetric: 392.7648, val_loss: 400.3956, val_MinusLogProbMetric: 400.3956

Epoch 269: val_loss did not improve from 393.30954
196/196 - 15s - loss: 392.7648 - MinusLogProbMetric: 392.7648 - val_loss: 400.3956 - val_MinusLogProbMetric: 400.3956 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 270/1000
2023-09-10 00:01:53.671 
Epoch 270/1000 
	 loss: 392.6590, MinusLogProbMetric: 392.6590, val_loss: 395.1855, val_MinusLogProbMetric: 395.1855

Epoch 270: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.6590 - MinusLogProbMetric: 392.6590 - val_loss: 395.1855 - val_MinusLogProbMetric: 395.1855 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 271/1000
2023-09-10 00:02:08.402 
Epoch 271/1000 
	 loss: 392.7460, MinusLogProbMetric: 392.7460, val_loss: 395.6310, val_MinusLogProbMetric: 395.6310

Epoch 271: val_loss did not improve from 393.30954
196/196 - 15s - loss: 392.7460 - MinusLogProbMetric: 392.7460 - val_loss: 395.6310 - val_MinusLogProbMetric: 395.6310 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 272/1000
2023-09-10 00:02:22.448 
Epoch 272/1000 
	 loss: 392.6734, MinusLogProbMetric: 392.6734, val_loss: 399.2939, val_MinusLogProbMetric: 399.2939

Epoch 272: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.6734 - MinusLogProbMetric: 392.6734 - val_loss: 399.2939 - val_MinusLogProbMetric: 399.2939 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 273/1000
2023-09-10 00:02:36.710 
Epoch 273/1000 
	 loss: 392.6636, MinusLogProbMetric: 392.6636, val_loss: 397.5545, val_MinusLogProbMetric: 397.5545

Epoch 273: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.6636 - MinusLogProbMetric: 392.6636 - val_loss: 397.5545 - val_MinusLogProbMetric: 397.5545 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 274/1000
2023-09-10 00:02:49.955 
Epoch 274/1000 
	 loss: 393.5806, MinusLogProbMetric: 393.5806, val_loss: 396.1010, val_MinusLogProbMetric: 396.1010

Epoch 274: val_loss did not improve from 393.30954
196/196 - 13s - loss: 393.5806 - MinusLogProbMetric: 393.5806 - val_loss: 396.1010 - val_MinusLogProbMetric: 396.1010 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 275/1000
2023-09-10 00:03:02.593 
Epoch 275/1000 
	 loss: 392.2152, MinusLogProbMetric: 392.2152, val_loss: 400.9982, val_MinusLogProbMetric: 400.9982

Epoch 275: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.2152 - MinusLogProbMetric: 392.2152 - val_loss: 400.9982 - val_MinusLogProbMetric: 400.9982 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 276/1000
2023-09-10 00:03:16.592 
Epoch 276/1000 
	 loss: 392.9323, MinusLogProbMetric: 392.9323, val_loss: 396.0999, val_MinusLogProbMetric: 396.0999

Epoch 276: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.9323 - MinusLogProbMetric: 392.9323 - val_loss: 396.0999 - val_MinusLogProbMetric: 396.0999 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 277/1000
2023-09-10 00:03:30.942 
Epoch 277/1000 
	 loss: 392.9503, MinusLogProbMetric: 392.9503, val_loss: 400.7675, val_MinusLogProbMetric: 400.7675

Epoch 277: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.9503 - MinusLogProbMetric: 392.9503 - val_loss: 400.7675 - val_MinusLogProbMetric: 400.7675 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 278/1000
2023-09-10 00:03:44.174 
Epoch 278/1000 
	 loss: 392.8752, MinusLogProbMetric: 392.8752, val_loss: 395.9371, val_MinusLogProbMetric: 395.9371

Epoch 278: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.8752 - MinusLogProbMetric: 392.8752 - val_loss: 395.9371 - val_MinusLogProbMetric: 395.9371 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 279/1000
2023-09-10 00:03:58.097 
Epoch 279/1000 
	 loss: 392.4508, MinusLogProbMetric: 392.4508, val_loss: 398.0861, val_MinusLogProbMetric: 398.0861

Epoch 279: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.4508 - MinusLogProbMetric: 392.4508 - val_loss: 398.0861 - val_MinusLogProbMetric: 398.0861 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 280/1000
2023-09-10 00:04:10.262 
Epoch 280/1000 
	 loss: 392.3883, MinusLogProbMetric: 392.3883, val_loss: 397.0346, val_MinusLogProbMetric: 397.0346

Epoch 280: val_loss did not improve from 393.30954
196/196 - 12s - loss: 392.3883 - MinusLogProbMetric: 392.3883 - val_loss: 397.0346 - val_MinusLogProbMetric: 397.0346 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 281/1000
2023-09-10 00:04:22.269 
Epoch 281/1000 
	 loss: 396.7059, MinusLogProbMetric: 396.7059, val_loss: 398.9117, val_MinusLogProbMetric: 398.9117

Epoch 281: val_loss did not improve from 393.30954
196/196 - 12s - loss: 396.7059 - MinusLogProbMetric: 396.7059 - val_loss: 398.9117 - val_MinusLogProbMetric: 398.9117 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 282/1000
2023-09-10 00:04:35.933 
Epoch 282/1000 
	 loss: 391.8500, MinusLogProbMetric: 391.8500, val_loss: 401.2462, val_MinusLogProbMetric: 401.2462

Epoch 282: val_loss did not improve from 393.30954
196/196 - 14s - loss: 391.8500 - MinusLogProbMetric: 391.8500 - val_loss: 401.2462 - val_MinusLogProbMetric: 401.2462 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 283/1000
2023-09-10 00:04:48.232 
Epoch 283/1000 
	 loss: 392.2154, MinusLogProbMetric: 392.2154, val_loss: 396.0278, val_MinusLogProbMetric: 396.0278

Epoch 283: val_loss did not improve from 393.30954
196/196 - 12s - loss: 392.2154 - MinusLogProbMetric: 392.2154 - val_loss: 396.0278 - val_MinusLogProbMetric: 396.0278 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 284/1000
2023-09-10 00:05:03.555 
Epoch 284/1000 
	 loss: 392.7234, MinusLogProbMetric: 392.7234, val_loss: 395.9715, val_MinusLogProbMetric: 395.9715

Epoch 284: val_loss did not improve from 393.30954
196/196 - 15s - loss: 392.7234 - MinusLogProbMetric: 392.7234 - val_loss: 395.9715 - val_MinusLogProbMetric: 395.9715 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 285/1000
2023-09-10 00:05:17.314 
Epoch 285/1000 
	 loss: 392.6219, MinusLogProbMetric: 392.6219, val_loss: 395.5102, val_MinusLogProbMetric: 395.5102

Epoch 285: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.6219 - MinusLogProbMetric: 392.6219 - val_loss: 395.5102 - val_MinusLogProbMetric: 395.5102 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 286/1000
2023-09-10 00:05:32.977 
Epoch 286/1000 
	 loss: 392.8530, MinusLogProbMetric: 392.8530, val_loss: 396.5085, val_MinusLogProbMetric: 396.5085

Epoch 286: val_loss did not improve from 393.30954
196/196 - 16s - loss: 392.8530 - MinusLogProbMetric: 392.8530 - val_loss: 396.5085 - val_MinusLogProbMetric: 396.5085 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 287/1000
2023-09-10 00:05:48.028 
Epoch 287/1000 
	 loss: 392.5753, MinusLogProbMetric: 392.5753, val_loss: 395.7080, val_MinusLogProbMetric: 395.7080

Epoch 287: val_loss did not improve from 393.30954
196/196 - 15s - loss: 392.5753 - MinusLogProbMetric: 392.5753 - val_loss: 395.7080 - val_MinusLogProbMetric: 395.7080 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 288/1000
2023-09-10 00:06:02.267 
Epoch 288/1000 
	 loss: 392.5954, MinusLogProbMetric: 392.5954, val_loss: 398.0238, val_MinusLogProbMetric: 398.0238

Epoch 288: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.5954 - MinusLogProbMetric: 392.5954 - val_loss: 398.0238 - val_MinusLogProbMetric: 398.0238 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 289/1000
2023-09-10 00:06:17.984 
Epoch 289/1000 
	 loss: 393.0883, MinusLogProbMetric: 393.0883, val_loss: 398.2028, val_MinusLogProbMetric: 398.2028

Epoch 289: val_loss did not improve from 393.30954
196/196 - 16s - loss: 393.0883 - MinusLogProbMetric: 393.0883 - val_loss: 398.2028 - val_MinusLogProbMetric: 398.2028 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 290/1000
2023-09-10 00:06:32.754 
Epoch 290/1000 
	 loss: 392.6357, MinusLogProbMetric: 392.6357, val_loss: 394.9880, val_MinusLogProbMetric: 394.9880

Epoch 290: val_loss did not improve from 393.30954
196/196 - 15s - loss: 392.6357 - MinusLogProbMetric: 392.6357 - val_loss: 394.9880 - val_MinusLogProbMetric: 394.9880 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 291/1000
2023-09-10 00:06:46.738 
Epoch 291/1000 
	 loss: 391.8928, MinusLogProbMetric: 391.8928, val_loss: 400.1456, val_MinusLogProbMetric: 400.1456

Epoch 291: val_loss did not improve from 393.30954
196/196 - 14s - loss: 391.8928 - MinusLogProbMetric: 391.8928 - val_loss: 400.1456 - val_MinusLogProbMetric: 400.1456 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 292/1000
2023-09-10 00:07:00.082 
Epoch 292/1000 
	 loss: 393.0939, MinusLogProbMetric: 393.0939, val_loss: 400.4338, val_MinusLogProbMetric: 400.4338

Epoch 292: val_loss did not improve from 393.30954
196/196 - 13s - loss: 393.0939 - MinusLogProbMetric: 393.0939 - val_loss: 400.4338 - val_MinusLogProbMetric: 400.4338 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 293/1000
2023-09-10 00:07:15.651 
Epoch 293/1000 
	 loss: 392.8374, MinusLogProbMetric: 392.8374, val_loss: 395.9375, val_MinusLogProbMetric: 395.9375

Epoch 293: val_loss did not improve from 393.30954
196/196 - 16s - loss: 392.8374 - MinusLogProbMetric: 392.8374 - val_loss: 395.9375 - val_MinusLogProbMetric: 395.9375 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 294/1000
2023-09-10 00:07:29.528 
Epoch 294/1000 
	 loss: 392.3040, MinusLogProbMetric: 392.3040, val_loss: 400.8282, val_MinusLogProbMetric: 400.8282

Epoch 294: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.3040 - MinusLogProbMetric: 392.3040 - val_loss: 400.8282 - val_MinusLogProbMetric: 400.8282 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 295/1000
2023-09-10 00:07:42.855 
Epoch 295/1000 
	 loss: 392.4596, MinusLogProbMetric: 392.4596, val_loss: 395.7313, val_MinusLogProbMetric: 395.7313

Epoch 295: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.4596 - MinusLogProbMetric: 392.4596 - val_loss: 395.7313 - val_MinusLogProbMetric: 395.7313 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 296/1000
2023-09-10 00:07:56.793 
Epoch 296/1000 
	 loss: 392.6659, MinusLogProbMetric: 392.6659, val_loss: 396.8905, val_MinusLogProbMetric: 396.8905

Epoch 296: val_loss did not improve from 393.30954
196/196 - 14s - loss: 392.6659 - MinusLogProbMetric: 392.6659 - val_loss: 396.8905 - val_MinusLogProbMetric: 396.8905 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 297/1000
2023-09-10 00:08:10.072 
Epoch 297/1000 
	 loss: 392.4863, MinusLogProbMetric: 392.4863, val_loss: 395.5943, val_MinusLogProbMetric: 395.5943

Epoch 297: val_loss did not improve from 393.30954
196/196 - 13s - loss: 392.4863 - MinusLogProbMetric: 392.4863 - val_loss: 395.5943 - val_MinusLogProbMetric: 395.5943 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 298/1000
2023-09-10 00:08:23.212 
Epoch 298/1000 
	 loss: 389.5498, MinusLogProbMetric: 389.5498, val_loss: 393.5934, val_MinusLogProbMetric: 393.5934

Epoch 298: val_loss did not improve from 393.30954
196/196 - 13s - loss: 389.5498 - MinusLogProbMetric: 389.5498 - val_loss: 393.5934 - val_MinusLogProbMetric: 393.5934 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 299/1000
2023-09-10 00:08:37.832 
Epoch 299/1000 
	 loss: 389.3040, MinusLogProbMetric: 389.3040, val_loss: 393.8257, val_MinusLogProbMetric: 393.8257

Epoch 299: val_loss did not improve from 393.30954
196/196 - 15s - loss: 389.3040 - MinusLogProbMetric: 389.3040 - val_loss: 393.8257 - val_MinusLogProbMetric: 393.8257 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 300/1000
2023-09-10 00:08:50.409 
Epoch 300/1000 
	 loss: 389.1554, MinusLogProbMetric: 389.1554, val_loss: 394.2758, val_MinusLogProbMetric: 394.2758

Epoch 300: val_loss did not improve from 393.30954
196/196 - 13s - loss: 389.1554 - MinusLogProbMetric: 389.1554 - val_loss: 394.2758 - val_MinusLogProbMetric: 394.2758 - lr: 1.6667e-04 - 13s/epoch - 64ms/step
Epoch 301/1000
2023-09-10 00:09:06.022 
Epoch 301/1000 
	 loss: 389.5108, MinusLogProbMetric: 389.5108, val_loss: 393.4071, val_MinusLogProbMetric: 393.4071

Epoch 301: val_loss did not improve from 393.30954
196/196 - 16s - loss: 389.5108 - MinusLogProbMetric: 389.5108 - val_loss: 393.4071 - val_MinusLogProbMetric: 393.4071 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 302/1000
2023-09-10 00:09:19.146 
Epoch 302/1000 
	 loss: 389.2671, MinusLogProbMetric: 389.2671, val_loss: 395.0013, val_MinusLogProbMetric: 395.0013

Epoch 302: val_loss did not improve from 393.30954
196/196 - 13s - loss: 389.2671 - MinusLogProbMetric: 389.2671 - val_loss: 395.0013 - val_MinusLogProbMetric: 395.0013 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 303/1000
2023-09-10 00:09:32.354 
Epoch 303/1000 
	 loss: 389.3140, MinusLogProbMetric: 389.3140, val_loss: 393.3011, val_MinusLogProbMetric: 393.3011

Epoch 303: val_loss improved from 393.30954 to 393.30106, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 14s - loss: 389.3140 - MinusLogProbMetric: 389.3140 - val_loss: 393.3011 - val_MinusLogProbMetric: 393.3011 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 304/1000
2023-09-10 00:09:46.783 
Epoch 304/1000 
	 loss: 389.2634, MinusLogProbMetric: 389.2634, val_loss: 394.4684, val_MinusLogProbMetric: 394.4684

Epoch 304: val_loss did not improve from 393.30106
196/196 - 14s - loss: 389.2634 - MinusLogProbMetric: 389.2634 - val_loss: 394.4684 - val_MinusLogProbMetric: 394.4684 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 305/1000
2023-09-10 00:10:00.908 
Epoch 305/1000 
	 loss: 389.5948, MinusLogProbMetric: 389.5948, val_loss: 395.0486, val_MinusLogProbMetric: 395.0486

Epoch 305: val_loss did not improve from 393.30106
196/196 - 14s - loss: 389.5948 - MinusLogProbMetric: 389.5948 - val_loss: 395.0486 - val_MinusLogProbMetric: 395.0486 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 306/1000
2023-09-10 00:10:14.142 
Epoch 306/1000 
	 loss: 389.5948, MinusLogProbMetric: 389.5948, val_loss: 393.0133, val_MinusLogProbMetric: 393.0133

Epoch 306: val_loss improved from 393.30106 to 393.01331, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 14s - loss: 389.5948 - MinusLogProbMetric: 389.5948 - val_loss: 393.0133 - val_MinusLogProbMetric: 393.0133 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 307/1000
2023-09-10 00:10:28.157 
Epoch 307/1000 
	 loss: 389.6283, MinusLogProbMetric: 389.6283, val_loss: 393.4129, val_MinusLogProbMetric: 393.4129

Epoch 307: val_loss did not improve from 393.01331
196/196 - 13s - loss: 389.6283 - MinusLogProbMetric: 389.6283 - val_loss: 393.4129 - val_MinusLogProbMetric: 393.4129 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 308/1000
2023-09-10 00:10:41.948 
Epoch 308/1000 
	 loss: 389.4301, MinusLogProbMetric: 389.4301, val_loss: 394.0569, val_MinusLogProbMetric: 394.0569

Epoch 308: val_loss did not improve from 393.01331
196/196 - 14s - loss: 389.4301 - MinusLogProbMetric: 389.4301 - val_loss: 394.0569 - val_MinusLogProbMetric: 394.0569 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 309/1000
2023-09-10 00:10:55.263 
Epoch 309/1000 
	 loss: 390.0528, MinusLogProbMetric: 390.0528, val_loss: 393.3733, val_MinusLogProbMetric: 393.3733

Epoch 309: val_loss did not improve from 393.01331
196/196 - 13s - loss: 390.0528 - MinusLogProbMetric: 390.0528 - val_loss: 393.3733 - val_MinusLogProbMetric: 393.3733 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 310/1000
2023-09-10 00:11:09.599 
Epoch 310/1000 
	 loss: 389.6837, MinusLogProbMetric: 389.6837, val_loss: 393.9821, val_MinusLogProbMetric: 393.9821

Epoch 310: val_loss did not improve from 393.01331
196/196 - 14s - loss: 389.6837 - MinusLogProbMetric: 389.6837 - val_loss: 393.9821 - val_MinusLogProbMetric: 393.9821 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 311/1000
2023-09-10 00:11:24.308 
Epoch 311/1000 
	 loss: 389.4336, MinusLogProbMetric: 389.4336, val_loss: 393.1256, val_MinusLogProbMetric: 393.1256

Epoch 311: val_loss did not improve from 393.01331
196/196 - 15s - loss: 389.4336 - MinusLogProbMetric: 389.4336 - val_loss: 393.1256 - val_MinusLogProbMetric: 393.1256 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 312/1000
2023-09-10 00:11:37.706 
Epoch 312/1000 
	 loss: 389.4294, MinusLogProbMetric: 389.4294, val_loss: 397.5736, val_MinusLogProbMetric: 397.5736

Epoch 312: val_loss did not improve from 393.01331
196/196 - 13s - loss: 389.4294 - MinusLogProbMetric: 389.4294 - val_loss: 397.5736 - val_MinusLogProbMetric: 397.5736 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 313/1000
2023-09-10 00:11:52.348 
Epoch 313/1000 
	 loss: 389.4395, MinusLogProbMetric: 389.4395, val_loss: 394.8621, val_MinusLogProbMetric: 394.8621

Epoch 313: val_loss did not improve from 393.01331
196/196 - 15s - loss: 389.4395 - MinusLogProbMetric: 389.4395 - val_loss: 394.8621 - val_MinusLogProbMetric: 394.8621 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 314/1000
2023-09-10 00:12:06.729 
Epoch 314/1000 
	 loss: 389.9444, MinusLogProbMetric: 389.9444, val_loss: 393.3974, val_MinusLogProbMetric: 393.3974

Epoch 314: val_loss did not improve from 393.01331
196/196 - 14s - loss: 389.9444 - MinusLogProbMetric: 389.9444 - val_loss: 393.3974 - val_MinusLogProbMetric: 393.3974 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 315/1000
2023-09-10 00:12:18.659 
Epoch 315/1000 
	 loss: 389.1638, MinusLogProbMetric: 389.1638, val_loss: 393.4678, val_MinusLogProbMetric: 393.4678

Epoch 315: val_loss did not improve from 393.01331
196/196 - 12s - loss: 389.1638 - MinusLogProbMetric: 389.1638 - val_loss: 393.4678 - val_MinusLogProbMetric: 393.4678 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 316/1000
2023-09-10 00:12:32.049 
Epoch 316/1000 
	 loss: 389.4845, MinusLogProbMetric: 389.4845, val_loss: 394.0309, val_MinusLogProbMetric: 394.0309

Epoch 316: val_loss did not improve from 393.01331
196/196 - 13s - loss: 389.4845 - MinusLogProbMetric: 389.4845 - val_loss: 394.0309 - val_MinusLogProbMetric: 394.0309 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 317/1000
2023-09-10 00:12:45.523 
Epoch 317/1000 
	 loss: 389.8463, MinusLogProbMetric: 389.8463, val_loss: 395.3696, val_MinusLogProbMetric: 395.3696

Epoch 317: val_loss did not improve from 393.01331
196/196 - 13s - loss: 389.8463 - MinusLogProbMetric: 389.8463 - val_loss: 395.3696 - val_MinusLogProbMetric: 395.3696 - lr: 1.6667e-04 - 13s/epoch - 69ms/step
Epoch 318/1000
2023-09-10 00:12:59.456 
Epoch 318/1000 
	 loss: 389.4917, MinusLogProbMetric: 389.4917, val_loss: 393.7100, val_MinusLogProbMetric: 393.7100

Epoch 318: val_loss did not improve from 393.01331
196/196 - 14s - loss: 389.4917 - MinusLogProbMetric: 389.4917 - val_loss: 393.7100 - val_MinusLogProbMetric: 393.7100 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 319/1000
2023-09-10 00:13:12.098 
Epoch 319/1000 
	 loss: 389.3238, MinusLogProbMetric: 389.3238, val_loss: 393.3954, val_MinusLogProbMetric: 393.3954

Epoch 319: val_loss did not improve from 393.01331
196/196 - 13s - loss: 389.3238 - MinusLogProbMetric: 389.3238 - val_loss: 393.3954 - val_MinusLogProbMetric: 393.3954 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 320/1000
2023-09-10 00:13:25.372 
Epoch 320/1000 
	 loss: 389.3367, MinusLogProbMetric: 389.3367, val_loss: 394.2750, val_MinusLogProbMetric: 394.2750

Epoch 320: val_loss did not improve from 393.01331
196/196 - 13s - loss: 389.3367 - MinusLogProbMetric: 389.3367 - val_loss: 394.2750 - val_MinusLogProbMetric: 394.2750 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 321/1000
2023-09-10 00:13:37.236 
Epoch 321/1000 
	 loss: 389.5186, MinusLogProbMetric: 389.5186, val_loss: 394.5343, val_MinusLogProbMetric: 394.5343

Epoch 321: val_loss did not improve from 393.01331
196/196 - 12s - loss: 389.5186 - MinusLogProbMetric: 389.5186 - val_loss: 394.5343 - val_MinusLogProbMetric: 394.5343 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 322/1000
2023-09-10 00:13:51.189 
Epoch 322/1000 
	 loss: 390.0446, MinusLogProbMetric: 390.0446, val_loss: 391.5542, val_MinusLogProbMetric: 391.5542

Epoch 322: val_loss improved from 393.01331 to 391.55420, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_329/weights/best_weights.h5
196/196 - 15s - loss: 390.0446 - MinusLogProbMetric: 390.0446 - val_loss: 391.5542 - val_MinusLogProbMetric: 391.5542 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 323/1000
2023-09-10 00:14:06.291 
Epoch 323/1000 
	 loss: 389.8701, MinusLogProbMetric: 389.8701, val_loss: 394.9512, val_MinusLogProbMetric: 394.9512

Epoch 323: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.8701 - MinusLogProbMetric: 389.8701 - val_loss: 394.9512 - val_MinusLogProbMetric: 394.9512 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 324/1000
2023-09-10 00:14:18.892 
Epoch 324/1000 
	 loss: 389.6866, MinusLogProbMetric: 389.6866, val_loss: 393.6819, val_MinusLogProbMetric: 393.6819

Epoch 324: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.6866 - MinusLogProbMetric: 389.6866 - val_loss: 393.6819 - val_MinusLogProbMetric: 393.6819 - lr: 1.6667e-04 - 13s/epoch - 64ms/step
Epoch 325/1000
2023-09-10 00:14:32.995 
Epoch 325/1000 
	 loss: 389.5664, MinusLogProbMetric: 389.5664, val_loss: 393.6332, val_MinusLogProbMetric: 393.6332

Epoch 325: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.5664 - MinusLogProbMetric: 389.5664 - val_loss: 393.6332 - val_MinusLogProbMetric: 393.6332 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 326/1000
2023-09-10 00:14:46.749 
Epoch 326/1000 
	 loss: 389.3653, MinusLogProbMetric: 389.3653, val_loss: 393.8111, val_MinusLogProbMetric: 393.8111

Epoch 326: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.3653 - MinusLogProbMetric: 389.3653 - val_loss: 393.8111 - val_MinusLogProbMetric: 393.8111 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 327/1000
2023-09-10 00:14:58.742 
Epoch 327/1000 
	 loss: 389.7528, MinusLogProbMetric: 389.7528, val_loss: 392.0864, val_MinusLogProbMetric: 392.0864

Epoch 327: val_loss did not improve from 391.55420
196/196 - 12s - loss: 389.7528 - MinusLogProbMetric: 389.7528 - val_loss: 392.0864 - val_MinusLogProbMetric: 392.0864 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 328/1000
2023-09-10 00:15:14.118 
Epoch 328/1000 
	 loss: 389.2814, MinusLogProbMetric: 389.2814, val_loss: 393.9364, val_MinusLogProbMetric: 393.9364

Epoch 328: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.2814 - MinusLogProbMetric: 389.2814 - val_loss: 393.9364 - val_MinusLogProbMetric: 393.9364 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 329/1000
2023-09-10 00:15:28.194 
Epoch 329/1000 
	 loss: 389.3652, MinusLogProbMetric: 389.3652, val_loss: 393.8879, val_MinusLogProbMetric: 393.8879

Epoch 329: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.3652 - MinusLogProbMetric: 389.3652 - val_loss: 393.8879 - val_MinusLogProbMetric: 393.8879 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 330/1000
2023-09-10 00:15:41.062 
Epoch 330/1000 
	 loss: 389.3836, MinusLogProbMetric: 389.3836, val_loss: 394.0428, val_MinusLogProbMetric: 394.0428

Epoch 330: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.3836 - MinusLogProbMetric: 389.3836 - val_loss: 394.0428 - val_MinusLogProbMetric: 394.0428 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 331/1000
2023-09-10 00:15:55.592 
Epoch 331/1000 
	 loss: 389.6774, MinusLogProbMetric: 389.6774, val_loss: 394.0547, val_MinusLogProbMetric: 394.0547

Epoch 331: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.6774 - MinusLogProbMetric: 389.6774 - val_loss: 394.0547 - val_MinusLogProbMetric: 394.0547 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 332/1000
2023-09-10 00:16:09.966 
Epoch 332/1000 
	 loss: 389.4872, MinusLogProbMetric: 389.4872, val_loss: 394.1518, val_MinusLogProbMetric: 394.1518

Epoch 332: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.4872 - MinusLogProbMetric: 389.4872 - val_loss: 394.1518 - val_MinusLogProbMetric: 394.1518 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 333/1000
2023-09-10 00:16:26.091 
Epoch 333/1000 
	 loss: 389.4141, MinusLogProbMetric: 389.4141, val_loss: 394.9938, val_MinusLogProbMetric: 394.9938

Epoch 333: val_loss did not improve from 391.55420
196/196 - 16s - loss: 389.4141 - MinusLogProbMetric: 389.4141 - val_loss: 394.9938 - val_MinusLogProbMetric: 394.9938 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 334/1000
2023-09-10 00:16:41.129 
Epoch 334/1000 
	 loss: 389.4782, MinusLogProbMetric: 389.4782, val_loss: 394.2595, val_MinusLogProbMetric: 394.2595

Epoch 334: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.4782 - MinusLogProbMetric: 389.4782 - val_loss: 394.2595 - val_MinusLogProbMetric: 394.2595 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 335/1000
2023-09-10 00:16:54.424 
Epoch 335/1000 
	 loss: 389.4294, MinusLogProbMetric: 389.4294, val_loss: 393.1876, val_MinusLogProbMetric: 393.1876

Epoch 335: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.4294 - MinusLogProbMetric: 389.4294 - val_loss: 393.1876 - val_MinusLogProbMetric: 393.1876 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 336/1000
2023-09-10 00:17:08.484 
Epoch 336/1000 
	 loss: 388.9696, MinusLogProbMetric: 388.9696, val_loss: 395.0529, val_MinusLogProbMetric: 395.0529

Epoch 336: val_loss did not improve from 391.55420
196/196 - 14s - loss: 388.9696 - MinusLogProbMetric: 388.9696 - val_loss: 395.0529 - val_MinusLogProbMetric: 395.0529 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 337/1000
2023-09-10 00:17:23.335 
Epoch 337/1000 
	 loss: 389.5125, MinusLogProbMetric: 389.5125, val_loss: 393.9881, val_MinusLogProbMetric: 393.9881

Epoch 337: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.5125 - MinusLogProbMetric: 389.5125 - val_loss: 393.9881 - val_MinusLogProbMetric: 393.9881 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 338/1000
2023-09-10 00:17:37.045 
Epoch 338/1000 
	 loss: 389.7106, MinusLogProbMetric: 389.7106, val_loss: 393.5334, val_MinusLogProbMetric: 393.5334

Epoch 338: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.7106 - MinusLogProbMetric: 389.7106 - val_loss: 393.5334 - val_MinusLogProbMetric: 393.5334 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 339/1000
2023-09-10 00:17:51.415 
Epoch 339/1000 
	 loss: 389.4333, MinusLogProbMetric: 389.4333, val_loss: 395.6132, val_MinusLogProbMetric: 395.6132

Epoch 339: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.4333 - MinusLogProbMetric: 389.4333 - val_loss: 395.6132 - val_MinusLogProbMetric: 395.6132 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 340/1000
2023-09-10 00:18:05.890 
Epoch 340/1000 
	 loss: 389.5640, MinusLogProbMetric: 389.5640, val_loss: 394.5236, val_MinusLogProbMetric: 394.5236

Epoch 340: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.5640 - MinusLogProbMetric: 389.5640 - val_loss: 394.5236 - val_MinusLogProbMetric: 394.5236 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 341/1000
2023-09-10 00:18:21.119 
Epoch 341/1000 
	 loss: 389.7601, MinusLogProbMetric: 389.7601, val_loss: 393.6285, val_MinusLogProbMetric: 393.6285

Epoch 341: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.7601 - MinusLogProbMetric: 389.7601 - val_loss: 393.6285 - val_MinusLogProbMetric: 393.6285 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 342/1000
2023-09-10 00:18:35.652 
Epoch 342/1000 
	 loss: 389.5082, MinusLogProbMetric: 389.5082, val_loss: 393.8715, val_MinusLogProbMetric: 393.8715

Epoch 342: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.5082 - MinusLogProbMetric: 389.5082 - val_loss: 393.8715 - val_MinusLogProbMetric: 393.8715 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 343/1000
2023-09-10 00:18:49.828 
Epoch 343/1000 
	 loss: 389.6812, MinusLogProbMetric: 389.6812, val_loss: 394.2511, val_MinusLogProbMetric: 394.2511

Epoch 343: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.6812 - MinusLogProbMetric: 389.6812 - val_loss: 394.2511 - val_MinusLogProbMetric: 394.2511 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 344/1000
2023-09-10 00:19:03.022 
Epoch 344/1000 
	 loss: 389.6292, MinusLogProbMetric: 389.6292, val_loss: 394.4324, val_MinusLogProbMetric: 394.4324

Epoch 344: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.6292 - MinusLogProbMetric: 389.6292 - val_loss: 394.4324 - val_MinusLogProbMetric: 394.4324 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 345/1000
2023-09-10 00:19:17.644 
Epoch 345/1000 
	 loss: 389.1921, MinusLogProbMetric: 389.1921, val_loss: 393.7982, val_MinusLogProbMetric: 393.7982

Epoch 345: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.1921 - MinusLogProbMetric: 389.1921 - val_loss: 393.7982 - val_MinusLogProbMetric: 393.7982 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 346/1000
2023-09-10 00:19:30.454 
Epoch 346/1000 
	 loss: 389.4471, MinusLogProbMetric: 389.4471, val_loss: 395.3851, val_MinusLogProbMetric: 395.3851

Epoch 346: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.4471 - MinusLogProbMetric: 389.4471 - val_loss: 395.3851 - val_MinusLogProbMetric: 395.3851 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 347/1000
2023-09-10 00:19:45.005 
Epoch 347/1000 
	 loss: 389.3984, MinusLogProbMetric: 389.3984, val_loss: 394.0941, val_MinusLogProbMetric: 394.0941

Epoch 347: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.3984 - MinusLogProbMetric: 389.3984 - val_loss: 394.0941 - val_MinusLogProbMetric: 394.0941 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 348/1000
2023-09-10 00:19:56.398 
Epoch 348/1000 
	 loss: 389.3479, MinusLogProbMetric: 389.3479, val_loss: 392.6930, val_MinusLogProbMetric: 392.6930

Epoch 348: val_loss did not improve from 391.55420
196/196 - 11s - loss: 389.3479 - MinusLogProbMetric: 389.3479 - val_loss: 392.6930 - val_MinusLogProbMetric: 392.6930 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 349/1000
2023-09-10 00:20:10.245 
Epoch 349/1000 
	 loss: 389.9419, MinusLogProbMetric: 389.9419, val_loss: 392.9580, val_MinusLogProbMetric: 392.9580

Epoch 349: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.9419 - MinusLogProbMetric: 389.9419 - val_loss: 392.9580 - val_MinusLogProbMetric: 392.9580 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 350/1000
2023-09-10 00:20:23.812 
Epoch 350/1000 
	 loss: 389.4684, MinusLogProbMetric: 389.4684, val_loss: 393.9788, val_MinusLogProbMetric: 393.9788

Epoch 350: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.4684 - MinusLogProbMetric: 389.4684 - val_loss: 393.9788 - val_MinusLogProbMetric: 393.9788 - lr: 1.6667e-04 - 14s/epoch - 69ms/step
Epoch 351/1000
2023-09-10 00:20:35.848 
Epoch 351/1000 
	 loss: 389.5178, MinusLogProbMetric: 389.5178, val_loss: 393.4834, val_MinusLogProbMetric: 393.4834

Epoch 351: val_loss did not improve from 391.55420
196/196 - 12s - loss: 389.5178 - MinusLogProbMetric: 389.5178 - val_loss: 393.4834 - val_MinusLogProbMetric: 393.4834 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 352/1000
2023-09-10 00:20:49.954 
Epoch 352/1000 
	 loss: 389.5079, MinusLogProbMetric: 389.5079, val_loss: 393.3769, val_MinusLogProbMetric: 393.3769

Epoch 352: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.5079 - MinusLogProbMetric: 389.5079 - val_loss: 393.3769 - val_MinusLogProbMetric: 393.3769 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 353/1000
2023-09-10 00:21:03.783 
Epoch 353/1000 
	 loss: 389.6900, MinusLogProbMetric: 389.6900, val_loss: 392.8836, val_MinusLogProbMetric: 392.8836

Epoch 353: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.6900 - MinusLogProbMetric: 389.6900 - val_loss: 392.8836 - val_MinusLogProbMetric: 392.8836 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 354/1000
2023-09-10 00:21:16.250 
Epoch 354/1000 
	 loss: 389.4486, MinusLogProbMetric: 389.4486, val_loss: 394.5023, val_MinusLogProbMetric: 394.5023

Epoch 354: val_loss did not improve from 391.55420
196/196 - 12s - loss: 389.4486 - MinusLogProbMetric: 389.4486 - val_loss: 394.5023 - val_MinusLogProbMetric: 394.5023 - lr: 1.6667e-04 - 12s/epoch - 64ms/step
Epoch 355/1000
2023-09-10 00:21:29.488 
Epoch 355/1000 
	 loss: 389.6196, MinusLogProbMetric: 389.6196, val_loss: 394.6315, val_MinusLogProbMetric: 394.6315

Epoch 355: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.6196 - MinusLogProbMetric: 389.6196 - val_loss: 394.6315 - val_MinusLogProbMetric: 394.6315 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 356/1000
2023-09-10 00:21:43.333 
Epoch 356/1000 
	 loss: 389.6520, MinusLogProbMetric: 389.6520, val_loss: 394.2951, val_MinusLogProbMetric: 394.2951

Epoch 356: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.6520 - MinusLogProbMetric: 389.6520 - val_loss: 394.2951 - val_MinusLogProbMetric: 394.2951 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 357/1000
2023-09-10 00:21:57.696 
Epoch 357/1000 
	 loss: 389.7227, MinusLogProbMetric: 389.7227, val_loss: 393.6812, val_MinusLogProbMetric: 393.6812

Epoch 357: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.7227 - MinusLogProbMetric: 389.7227 - val_loss: 393.6812 - val_MinusLogProbMetric: 393.6812 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 358/1000
2023-09-10 00:22:11.790 
Epoch 358/1000 
	 loss: 389.5082, MinusLogProbMetric: 389.5082, val_loss: 394.5730, val_MinusLogProbMetric: 394.5730

Epoch 358: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.5082 - MinusLogProbMetric: 389.5082 - val_loss: 394.5730 - val_MinusLogProbMetric: 394.5730 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 359/1000
2023-09-10 00:22:26.239 
Epoch 359/1000 
	 loss: 389.6047, MinusLogProbMetric: 389.6047, val_loss: 394.9136, val_MinusLogProbMetric: 394.9136

Epoch 359: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.6047 - MinusLogProbMetric: 389.6047 - val_loss: 394.9136 - val_MinusLogProbMetric: 394.9136 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 360/1000
2023-09-10 00:22:39.628 
Epoch 360/1000 
	 loss: 389.9878, MinusLogProbMetric: 389.9878, val_loss: 395.0192, val_MinusLogProbMetric: 395.0192

Epoch 360: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.9878 - MinusLogProbMetric: 389.9878 - val_loss: 395.0192 - val_MinusLogProbMetric: 395.0192 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 361/1000
2023-09-10 00:22:52.586 
Epoch 361/1000 
	 loss: 389.1348, MinusLogProbMetric: 389.1348, val_loss: 394.0768, val_MinusLogProbMetric: 394.0768

Epoch 361: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.1348 - MinusLogProbMetric: 389.1348 - val_loss: 394.0768 - val_MinusLogProbMetric: 394.0768 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 362/1000
2023-09-10 00:23:04.794 
Epoch 362/1000 
	 loss: 389.2214, MinusLogProbMetric: 389.2214, val_loss: 393.6606, val_MinusLogProbMetric: 393.6606

Epoch 362: val_loss did not improve from 391.55420
196/196 - 12s - loss: 389.2214 - MinusLogProbMetric: 389.2214 - val_loss: 393.6606 - val_MinusLogProbMetric: 393.6606 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 363/1000
2023-09-10 00:23:14.145 
Epoch 363/1000 
	 loss: 389.6071, MinusLogProbMetric: 389.6071, val_loss: 395.1366, val_MinusLogProbMetric: 395.1366

Epoch 363: val_loss did not improve from 391.55420
196/196 - 9s - loss: 389.6071 - MinusLogProbMetric: 389.6071 - val_loss: 395.1366 - val_MinusLogProbMetric: 395.1366 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 364/1000
2023-09-10 00:23:29.113 
Epoch 364/1000 
	 loss: 389.9663, MinusLogProbMetric: 389.9663, val_loss: 394.2898, val_MinusLogProbMetric: 394.2898

Epoch 364: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.9663 - MinusLogProbMetric: 389.9663 - val_loss: 394.2898 - val_MinusLogProbMetric: 394.2898 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 365/1000
2023-09-10 00:23:43.866 
Epoch 365/1000 
	 loss: 389.6936, MinusLogProbMetric: 389.6936, val_loss: 394.6133, val_MinusLogProbMetric: 394.6133

Epoch 365: val_loss did not improve from 391.55420
196/196 - 15s - loss: 389.6936 - MinusLogProbMetric: 389.6936 - val_loss: 394.6133 - val_MinusLogProbMetric: 394.6133 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 366/1000
2023-09-10 00:23:56.066 
Epoch 366/1000 
	 loss: 389.6581, MinusLogProbMetric: 389.6581, val_loss: 393.6952, val_MinusLogProbMetric: 393.6952

Epoch 366: val_loss did not improve from 391.55420
196/196 - 12s - loss: 389.6581 - MinusLogProbMetric: 389.6581 - val_loss: 393.6952 - val_MinusLogProbMetric: 393.6952 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 367/1000
2023-09-10 00:24:09.830 
Epoch 367/1000 
	 loss: 389.4646, MinusLogProbMetric: 389.4646, val_loss: 394.8561, val_MinusLogProbMetric: 394.8561

Epoch 367: val_loss did not improve from 391.55420
196/196 - 14s - loss: 389.4646 - MinusLogProbMetric: 389.4646 - val_loss: 394.8561 - val_MinusLogProbMetric: 394.8561 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 368/1000
2023-09-10 00:24:21.665 
Epoch 368/1000 
	 loss: 389.3374, MinusLogProbMetric: 389.3374, val_loss: 394.4380, val_MinusLogProbMetric: 394.4380

Epoch 368: val_loss did not improve from 391.55420
196/196 - 12s - loss: 389.3374 - MinusLogProbMetric: 389.3374 - val_loss: 394.4380 - val_MinusLogProbMetric: 394.4380 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 369/1000
2023-09-10 00:24:33.048 
Epoch 369/1000 
	 loss: 389.3481, MinusLogProbMetric: 389.3481, val_loss: 399.6322, val_MinusLogProbMetric: 399.6322

Epoch 369: val_loss did not improve from 391.55420
196/196 - 11s - loss: 389.3481 - MinusLogProbMetric: 389.3481 - val_loss: 399.6322 - val_MinusLogProbMetric: 399.6322 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 370/1000
2023-09-10 00:24:46.028 
Epoch 370/1000 
	 loss: 389.6179, MinusLogProbMetric: 389.6179, val_loss: 393.9594, val_MinusLogProbMetric: 393.9594

Epoch 370: val_loss did not improve from 391.55420
196/196 - 13s - loss: 389.6179 - MinusLogProbMetric: 389.6179 - val_loss: 393.9594 - val_MinusLogProbMetric: 393.9594 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 371/1000
2023-09-10 00:24:56.568 
Epoch 371/1000 
	 loss: 389.4095, MinusLogProbMetric: 389.4095, val_loss: 394.9867, val_MinusLogProbMetric: 394.9867

Epoch 371: val_loss did not improve from 391.55420
196/196 - 11s - loss: 389.4095 - MinusLogProbMetric: 389.4095 - val_loss: 394.9867 - val_MinusLogProbMetric: 394.9867 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 372/1000
2023-09-10 00:25:08.749 
Epoch 372/1000 
	 loss: 390.0257, MinusLogProbMetric: 390.0257, val_loss: 393.1832, val_MinusLogProbMetric: 393.1832

Epoch 372: val_loss did not improve from 391.55420
196/196 - 12s - loss: 390.0257 - MinusLogProbMetric: 390.0257 - val_loss: 393.1832 - val_MinusLogProbMetric: 393.1832 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 373/1000
2023-09-10 00:25:20.306 
Epoch 373/1000 
	 loss: 387.9509, MinusLogProbMetric: 387.9509, val_loss: 392.3759, val_MinusLogProbMetric: 392.3759

Epoch 373: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.9509 - MinusLogProbMetric: 387.9509 - val_loss: 392.3759 - val_MinusLogProbMetric: 392.3759 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 374/1000
2023-09-10 00:25:31.556 
Epoch 374/1000 
	 loss: 387.8253, MinusLogProbMetric: 387.8253, val_loss: 392.6538, val_MinusLogProbMetric: 392.6538

Epoch 374: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.8253 - MinusLogProbMetric: 387.8253 - val_loss: 392.6538 - val_MinusLogProbMetric: 392.6538 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 375/1000
2023-09-10 00:25:44.814 
Epoch 375/1000 
	 loss: 387.7641, MinusLogProbMetric: 387.7641, val_loss: 392.7010, val_MinusLogProbMetric: 392.7010

Epoch 375: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.7641 - MinusLogProbMetric: 387.7641 - val_loss: 392.7010 - val_MinusLogProbMetric: 392.7010 - lr: 8.3333e-05 - 13s/epoch - 68ms/step
Epoch 376/1000
2023-09-10 00:25:56.529 
Epoch 376/1000 
	 loss: 387.8011, MinusLogProbMetric: 387.8011, val_loss: 393.2853, val_MinusLogProbMetric: 393.2853

Epoch 376: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.8011 - MinusLogProbMetric: 387.8011 - val_loss: 393.2853 - val_MinusLogProbMetric: 393.2853 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-10 00:26:09.341 
Epoch 377/1000 
	 loss: 387.8549, MinusLogProbMetric: 387.8549, val_loss: 394.0240, val_MinusLogProbMetric: 394.0240

Epoch 377: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.8549 - MinusLogProbMetric: 387.8549 - val_loss: 394.0240 - val_MinusLogProbMetric: 394.0240 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 378/1000
2023-09-10 00:26:21.281 
Epoch 378/1000 
	 loss: 388.1264, MinusLogProbMetric: 388.1264, val_loss: 394.2933, val_MinusLogProbMetric: 394.2933

Epoch 378: val_loss did not improve from 391.55420
196/196 - 12s - loss: 388.1264 - MinusLogProbMetric: 388.1264 - val_loss: 394.2933 - val_MinusLogProbMetric: 394.2933 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 379/1000
2023-09-10 00:26:32.675 
Epoch 379/1000 
	 loss: 387.8270, MinusLogProbMetric: 387.8270, val_loss: 393.5781, val_MinusLogProbMetric: 393.5781

Epoch 379: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.8270 - MinusLogProbMetric: 387.8270 - val_loss: 393.5781 - val_MinusLogProbMetric: 393.5781 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 380/1000
2023-09-10 00:26:44.658 
Epoch 380/1000 
	 loss: 387.9427, MinusLogProbMetric: 387.9427, val_loss: 392.4587, val_MinusLogProbMetric: 392.4587

Epoch 380: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.9427 - MinusLogProbMetric: 387.9427 - val_loss: 392.4587 - val_MinusLogProbMetric: 392.4587 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 381/1000
2023-09-10 00:26:56.958 
Epoch 381/1000 
	 loss: 387.7133, MinusLogProbMetric: 387.7133, val_loss: 393.4737, val_MinusLogProbMetric: 393.4737

Epoch 381: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.7133 - MinusLogProbMetric: 387.7133 - val_loss: 393.4737 - val_MinusLogProbMetric: 393.4737 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 382/1000
2023-09-10 00:27:08.157 
Epoch 382/1000 
	 loss: 387.7448, MinusLogProbMetric: 387.7448, val_loss: 393.1677, val_MinusLogProbMetric: 393.1677

Epoch 382: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.7448 - MinusLogProbMetric: 387.7448 - val_loss: 393.1677 - val_MinusLogProbMetric: 393.1677 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 383/1000
2023-09-10 00:27:21.178 
Epoch 383/1000 
	 loss: 387.7247, MinusLogProbMetric: 387.7247, val_loss: 392.6704, val_MinusLogProbMetric: 392.6704

Epoch 383: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.7247 - MinusLogProbMetric: 387.7247 - val_loss: 392.6704 - val_MinusLogProbMetric: 392.6704 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 384/1000
2023-09-10 00:27:32.814 
Epoch 384/1000 
	 loss: 387.7522, MinusLogProbMetric: 387.7522, val_loss: 393.4302, val_MinusLogProbMetric: 393.4302

Epoch 384: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.7522 - MinusLogProbMetric: 387.7522 - val_loss: 393.4302 - val_MinusLogProbMetric: 393.4302 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 385/1000
2023-09-10 00:27:44.498 
Epoch 385/1000 
	 loss: 387.9630, MinusLogProbMetric: 387.9630, val_loss: 392.8897, val_MinusLogProbMetric: 392.8897

Epoch 385: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.9630 - MinusLogProbMetric: 387.9630 - val_loss: 392.8897 - val_MinusLogProbMetric: 392.8897 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 386/1000
2023-09-10 00:27:56.826 
Epoch 386/1000 
	 loss: 387.7924, MinusLogProbMetric: 387.7924, val_loss: 393.4726, val_MinusLogProbMetric: 393.4726

Epoch 386: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.7924 - MinusLogProbMetric: 387.7924 - val_loss: 393.4726 - val_MinusLogProbMetric: 393.4726 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 387/1000
2023-09-10 00:28:08.181 
Epoch 387/1000 
	 loss: 387.8377, MinusLogProbMetric: 387.8377, val_loss: 392.9921, val_MinusLogProbMetric: 392.9921

Epoch 387: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.8377 - MinusLogProbMetric: 387.8377 - val_loss: 392.9921 - val_MinusLogProbMetric: 392.9921 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 388/1000
2023-09-10 00:28:19.700 
Epoch 388/1000 
	 loss: 387.7715, MinusLogProbMetric: 387.7715, val_loss: 394.2403, val_MinusLogProbMetric: 394.2403

Epoch 388: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.7715 - MinusLogProbMetric: 387.7715 - val_loss: 394.2403 - val_MinusLogProbMetric: 394.2403 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 389/1000
2023-09-10 00:28:31.890 
Epoch 389/1000 
	 loss: 388.2266, MinusLogProbMetric: 388.2266, val_loss: 393.6897, val_MinusLogProbMetric: 393.6897

Epoch 389: val_loss did not improve from 391.55420
196/196 - 12s - loss: 388.2266 - MinusLogProbMetric: 388.2266 - val_loss: 393.6897 - val_MinusLogProbMetric: 393.6897 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 390/1000
2023-09-10 00:28:44.677 
Epoch 390/1000 
	 loss: 387.8624, MinusLogProbMetric: 387.8624, val_loss: 393.7056, val_MinusLogProbMetric: 393.7056

Epoch 390: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.8624 - MinusLogProbMetric: 387.8624 - val_loss: 393.7056 - val_MinusLogProbMetric: 393.7056 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 391/1000
2023-09-10 00:28:57.015 
Epoch 391/1000 
	 loss: 388.1011, MinusLogProbMetric: 388.1011, val_loss: 393.1005, val_MinusLogProbMetric: 393.1005

Epoch 391: val_loss did not improve from 391.55420
196/196 - 12s - loss: 388.1011 - MinusLogProbMetric: 388.1011 - val_loss: 393.1005 - val_MinusLogProbMetric: 393.1005 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 392/1000
2023-09-10 00:29:10.116 
Epoch 392/1000 
	 loss: 387.7670, MinusLogProbMetric: 387.7670, val_loss: 392.9096, val_MinusLogProbMetric: 392.9096

Epoch 392: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.7670 - MinusLogProbMetric: 387.7670 - val_loss: 392.9096 - val_MinusLogProbMetric: 392.9096 - lr: 8.3333e-05 - 13s/epoch - 67ms/step
Epoch 393/1000
2023-09-10 00:29:21.568 
Epoch 393/1000 
	 loss: 387.7966, MinusLogProbMetric: 387.7966, val_loss: 392.5301, val_MinusLogProbMetric: 392.5301

Epoch 393: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.7966 - MinusLogProbMetric: 387.7966 - val_loss: 392.5301 - val_MinusLogProbMetric: 392.5301 - lr: 8.3333e-05 - 11s/epoch - 59ms/step
Epoch 394/1000
2023-09-10 00:29:34.440 
Epoch 394/1000 
	 loss: 387.7666, MinusLogProbMetric: 387.7666, val_loss: 393.4333, val_MinusLogProbMetric: 393.4333

Epoch 394: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.7666 - MinusLogProbMetric: 387.7666 - val_loss: 393.4333 - val_MinusLogProbMetric: 393.4333 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 395/1000
2023-09-10 00:29:45.571 
Epoch 395/1000 
	 loss: 387.7780, MinusLogProbMetric: 387.7780, val_loss: 392.9618, val_MinusLogProbMetric: 392.9618

Epoch 395: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.7780 - MinusLogProbMetric: 387.7780 - val_loss: 392.9618 - val_MinusLogProbMetric: 392.9618 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 396/1000
2023-09-10 00:29:58.249 
Epoch 396/1000 
	 loss: 387.6290, MinusLogProbMetric: 387.6290, val_loss: 392.7730, val_MinusLogProbMetric: 392.7730

Epoch 396: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.6290 - MinusLogProbMetric: 387.6290 - val_loss: 392.7730 - val_MinusLogProbMetric: 392.7730 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 397/1000
2023-09-10 00:30:09.415 
Epoch 397/1000 
	 loss: 387.8134, MinusLogProbMetric: 387.8134, val_loss: 393.7000, val_MinusLogProbMetric: 393.7000

Epoch 397: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.8134 - MinusLogProbMetric: 387.8134 - val_loss: 393.7000 - val_MinusLogProbMetric: 393.7000 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 398/1000
2023-09-10 00:30:22.568 
Epoch 398/1000 
	 loss: 387.8711, MinusLogProbMetric: 387.8711, val_loss: 393.1724, val_MinusLogProbMetric: 393.1724

Epoch 398: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.8711 - MinusLogProbMetric: 387.8711 - val_loss: 393.1724 - val_MinusLogProbMetric: 393.1724 - lr: 8.3333e-05 - 13s/epoch - 67ms/step
Epoch 399/1000
2023-09-10 00:30:33.516 
Epoch 399/1000 
	 loss: 387.9442, MinusLogProbMetric: 387.9442, val_loss: 393.4843, val_MinusLogProbMetric: 393.4843

Epoch 399: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.9442 - MinusLogProbMetric: 387.9442 - val_loss: 393.4843 - val_MinusLogProbMetric: 393.4843 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 400/1000
2023-09-10 00:30:46.489 
Epoch 400/1000 
	 loss: 388.0560, MinusLogProbMetric: 388.0560, val_loss: 392.7648, val_MinusLogProbMetric: 392.7648

Epoch 400: val_loss did not improve from 391.55420
196/196 - 13s - loss: 388.0560 - MinusLogProbMetric: 388.0560 - val_loss: 392.7648 - val_MinusLogProbMetric: 392.7648 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 401/1000
2023-09-10 00:30:58.923 
Epoch 401/1000 
	 loss: 387.6048, MinusLogProbMetric: 387.6048, val_loss: 393.0446, val_MinusLogProbMetric: 393.0446

Epoch 401: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.6048 - MinusLogProbMetric: 387.6048 - val_loss: 393.0446 - val_MinusLogProbMetric: 393.0446 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 402/1000
2023-09-10 00:31:10.631 
Epoch 402/1000 
	 loss: 387.8028, MinusLogProbMetric: 387.8028, val_loss: 393.2976, val_MinusLogProbMetric: 393.2976

Epoch 402: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.8028 - MinusLogProbMetric: 387.8028 - val_loss: 393.2976 - val_MinusLogProbMetric: 393.2976 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 403/1000
2023-09-10 00:31:22.498 
Epoch 403/1000 
	 loss: 388.1615, MinusLogProbMetric: 388.1615, val_loss: 392.6841, val_MinusLogProbMetric: 392.6841

Epoch 403: val_loss did not improve from 391.55420
196/196 - 12s - loss: 388.1615 - MinusLogProbMetric: 388.1615 - val_loss: 392.6841 - val_MinusLogProbMetric: 392.6841 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 404/1000
2023-09-10 00:31:33.835 
Epoch 404/1000 
	 loss: 387.8339, MinusLogProbMetric: 387.8339, val_loss: 393.4201, val_MinusLogProbMetric: 393.4201

Epoch 404: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.8339 - MinusLogProbMetric: 387.8339 - val_loss: 393.4201 - val_MinusLogProbMetric: 393.4201 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 405/1000
2023-09-10 00:31:46.537 
Epoch 405/1000 
	 loss: 387.6176, MinusLogProbMetric: 387.6176, val_loss: 392.6969, val_MinusLogProbMetric: 392.6969

Epoch 405: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.6176 - MinusLogProbMetric: 387.6176 - val_loss: 392.6969 - val_MinusLogProbMetric: 392.6969 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 406/1000
2023-09-10 00:31:58.050 
Epoch 406/1000 
	 loss: 387.5086, MinusLogProbMetric: 387.5086, val_loss: 393.3299, val_MinusLogProbMetric: 393.3299

Epoch 406: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.5086 - MinusLogProbMetric: 387.5086 - val_loss: 393.3299 - val_MinusLogProbMetric: 393.3299 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 407/1000
2023-09-10 00:32:10.454 
Epoch 407/1000 
	 loss: 388.0071, MinusLogProbMetric: 388.0071, val_loss: 393.7140, val_MinusLogProbMetric: 393.7140

Epoch 407: val_loss did not improve from 391.55420
196/196 - 12s - loss: 388.0071 - MinusLogProbMetric: 388.0071 - val_loss: 393.7140 - val_MinusLogProbMetric: 393.7140 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 408/1000
2023-09-10 00:32:23.430 
Epoch 408/1000 
	 loss: 388.0268, MinusLogProbMetric: 388.0268, val_loss: 393.3290, val_MinusLogProbMetric: 393.3290

Epoch 408: val_loss did not improve from 391.55420
196/196 - 13s - loss: 388.0268 - MinusLogProbMetric: 388.0268 - val_loss: 393.3290 - val_MinusLogProbMetric: 393.3290 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 409/1000
2023-09-10 00:32:34.323 
Epoch 409/1000 
	 loss: 387.7243, MinusLogProbMetric: 387.7243, val_loss: 392.8380, val_MinusLogProbMetric: 392.8380

Epoch 409: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.7243 - MinusLogProbMetric: 387.7243 - val_loss: 392.8380 - val_MinusLogProbMetric: 392.8380 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 410/1000
2023-09-10 00:32:46.058 
Epoch 410/1000 
	 loss: 387.7914, MinusLogProbMetric: 387.7914, val_loss: 392.9104, val_MinusLogProbMetric: 392.9104

Epoch 410: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.7914 - MinusLogProbMetric: 387.7914 - val_loss: 392.9104 - val_MinusLogProbMetric: 392.9104 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 411/1000
2023-09-10 00:32:56.965 
Epoch 411/1000 
	 loss: 388.1182, MinusLogProbMetric: 388.1182, val_loss: 392.5895, val_MinusLogProbMetric: 392.5895

Epoch 411: val_loss did not improve from 391.55420
196/196 - 11s - loss: 388.1182 - MinusLogProbMetric: 388.1182 - val_loss: 392.5895 - val_MinusLogProbMetric: 392.5895 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 412/1000
2023-09-10 00:33:09.005 
Epoch 412/1000 
	 loss: 387.7260, MinusLogProbMetric: 387.7260, val_loss: 392.7858, val_MinusLogProbMetric: 392.7858

Epoch 412: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.7260 - MinusLogProbMetric: 387.7260 - val_loss: 392.7858 - val_MinusLogProbMetric: 392.7858 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 413/1000
2023-09-10 00:33:20.199 
Epoch 413/1000 
	 loss: 387.5154, MinusLogProbMetric: 387.5154, val_loss: 393.1047, val_MinusLogProbMetric: 393.1047

Epoch 413: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.5154 - MinusLogProbMetric: 387.5154 - val_loss: 393.1047 - val_MinusLogProbMetric: 393.1047 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 414/1000
2023-09-10 00:33:33.271 
Epoch 414/1000 
	 loss: 387.6032, MinusLogProbMetric: 387.6032, val_loss: 392.8406, val_MinusLogProbMetric: 392.8406

Epoch 414: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.6032 - MinusLogProbMetric: 387.6032 - val_loss: 392.8406 - val_MinusLogProbMetric: 392.8406 - lr: 8.3333e-05 - 13s/epoch - 67ms/step
Epoch 415/1000
2023-09-10 00:33:46.811 
Epoch 415/1000 
	 loss: 387.5269, MinusLogProbMetric: 387.5269, val_loss: 392.6941, val_MinusLogProbMetric: 392.6941

Epoch 415: val_loss did not improve from 391.55420
196/196 - 14s - loss: 387.5269 - MinusLogProbMetric: 387.5269 - val_loss: 392.6941 - val_MinusLogProbMetric: 392.6941 - lr: 8.3333e-05 - 14s/epoch - 69ms/step
Epoch 416/1000
2023-09-10 00:33:58.535 
Epoch 416/1000 
	 loss: 387.4587, MinusLogProbMetric: 387.4587, val_loss: 393.2741, val_MinusLogProbMetric: 393.2741

Epoch 416: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.4587 - MinusLogProbMetric: 387.4587 - val_loss: 393.2741 - val_MinusLogProbMetric: 393.2741 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 417/1000
2023-09-10 00:34:11.282 
Epoch 417/1000 
	 loss: 388.1069, MinusLogProbMetric: 388.1069, val_loss: 393.0163, val_MinusLogProbMetric: 393.0163

Epoch 417: val_loss did not improve from 391.55420
196/196 - 13s - loss: 388.1069 - MinusLogProbMetric: 388.1069 - val_loss: 393.0163 - val_MinusLogProbMetric: 393.0163 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 418/1000
2023-09-10 00:34:22.169 
Epoch 418/1000 
	 loss: 387.5665, MinusLogProbMetric: 387.5665, val_loss: 393.2635, val_MinusLogProbMetric: 393.2635

Epoch 418: val_loss did not improve from 391.55420
196/196 - 11s - loss: 387.5665 - MinusLogProbMetric: 387.5665 - val_loss: 393.2635 - val_MinusLogProbMetric: 393.2635 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 419/1000
2023-09-10 00:34:35.249 
Epoch 419/1000 
	 loss: 387.9751, MinusLogProbMetric: 387.9751, val_loss: 394.4650, val_MinusLogProbMetric: 394.4650

Epoch 419: val_loss did not improve from 391.55420
196/196 - 13s - loss: 387.9751 - MinusLogProbMetric: 387.9751 - val_loss: 394.4650 - val_MinusLogProbMetric: 394.4650 - lr: 8.3333e-05 - 13s/epoch - 67ms/step
Epoch 420/1000
2023-09-10 00:34:46.966 
Epoch 420/1000 
	 loss: 387.8466, MinusLogProbMetric: 387.8466, val_loss: 393.9201, val_MinusLogProbMetric: 393.9201

Epoch 420: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.8466 - MinusLogProbMetric: 387.8466 - val_loss: 393.9201 - val_MinusLogProbMetric: 393.9201 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 421/1000
2023-09-10 00:34:59.399 
Epoch 421/1000 
	 loss: 387.8327, MinusLogProbMetric: 387.8327, val_loss: 393.1466, val_MinusLogProbMetric: 393.1466

Epoch 421: val_loss did not improve from 391.55420
196/196 - 12s - loss: 387.8327 - MinusLogProbMetric: 387.8327 - val_loss: 393.1466 - val_MinusLogProbMetric: 393.1466 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 422/1000
2023-09-10 00:35:11.157 
Epoch 422/1000 
	 loss: 387.9288, MinusLogProbMetric: 387.9288, val_loss: 393.4730, val_MinusLogProbMetric: 393.4730

Epoch 422: val_loss did not improve from 391.55420
Restoring model weights from the end of the best epoch: 322.
196/196 - 12s - loss: 387.9288 - MinusLogProbMetric: 387.9288 - val_loss: 393.4730 - val_MinusLogProbMetric: 393.4730 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 422: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 890.1731863609748 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 916.0706596520031 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 890.852654044982 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 873.9373987360159 seconds.
Training succeeded with seed 377.
Model trained in 5485.04 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 3684.91 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 3686.10 s.
===========
Run 329/360 done in 10795.66 s.
===========

===========
Generating train data for run 330.
===========
Train data generated in 2.78 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_330/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_330/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_330/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_330
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.437488    7.1322474   6.533019   ...  9.559031    1.9697884
   6.253516  ]
 [ 6.105814   -0.33694893  4.861082   ...  4.728712    6.8399925
   2.9518385 ]
 [ 5.5099134   8.416618    3.6192868  ... 10.13037     0.5513004
   6.6116333 ]
 ...
 [ 8.378759    5.1539607   5.2823405  ...  4.1604185   7.9323363
   6.8563857 ]
 [ 8.088472    5.184855    5.311574   ...  3.8879027   7.132432
   7.66768   ]
 [ 5.6874776   6.932827    6.1243634  ...  9.540177    3.2688973
   7.1452303 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_2 (LogProbLa  (None,)                  4509200   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,509,200
Trainable params: 4,509,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_2/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_2'")
self.model: <keras.engine.functional.Functional object at 0x7effecba2290>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effcb037b50>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effcb037b50>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effcafd5480>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7effcaffd900>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7effcaffd5d0>, <keras.callbacks.ModelCheckpoint object at 0x7effcaffcb20>, <keras.callbacks.EarlyStopping object at 0x7effcaffc970>, <keras.callbacks.ReduceLROnPlateau object at 0x7effcaffc0d0>, <keras.callbacks.TerminateOnNaN object at 0x7effcaffe1d0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_330/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 330/360 with hyperparameters:
timestamp = 2023-09-10 01:36:44.331046
ndims = 1000
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 4509200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.43748808e+00  7.13224745e+00  6.53301907e+00  5.31066608e+00
  3.79545021e+00  6.28738737e+00  2.71391177e+00  8.88872051e+00
  9.43951797e+00  4.12179470e+00  7.81367683e+00  5.36657619e+00
  5.55121899e+00  9.56866932e+00  7.94146359e-01  9.63486314e-01
 -1.46448463e-02  7.97977352e+00  8.35143089e+00  9.09444618e+00
  9.51050758e+00  8.15759563e+00  4.87677431e+00  8.12364483e+00
 -5.86649776e-01  6.22392607e+00  1.30506945e+00  9.45408440e+00
  7.08888865e+00  3.35072994e+00  2.25734115e+00  8.41814995e+00
  4.58319330e+00  5.61194181e+00  2.26602942e-01  5.45686245e+00
  6.14353561e+00  6.25023174e+00  9.57346344e+00  6.36795044e+00
  3.20757818e+00  4.83043623e+00  7.51926565e+00  6.34396672e-01
  6.89045191e+00  6.62100124e+00  2.44563007e+00  1.28772116e+00
  3.22250342e+00  4.52788544e+00  5.89035130e+00  4.86346960e+00
  9.48264980e+00 -1.13163722e+00  3.37091446e+00  9.05362010e-01
  6.78129101e+00  1.94818664e+00  4.17912102e+00  3.18960547e+00
  1.62776482e+00  1.21974039e+00  7.33607817e+00  1.62089002e+00
  2.96397400e+00  4.52560091e+00  8.39162827e+00  1.51216686e+00
  8.25380135e+00  5.98394752e-01  9.67017937e+00  4.48699141e+00
  1.02882853e+01  5.70898390e+00  6.28753185e+00  6.97938085e-01
  2.82613039e+00  1.18152845e+00  2.21910620e+00  1.18442059e-01
  3.30913496e+00  4.37123442e+00 -6.00820422e-01  7.13190508e+00
  5.83363104e+00  2.43325353e+00  5.20436668e+00  1.77731943e+00
  6.29233789e+00  9.14511585e+00  2.47849083e+00  7.14207220e+00
  1.59640992e+00  7.87721014e+00  3.72595000e+00  1.65804911e+00
  6.26306725e+00  6.14266574e-01  9.35802937e+00 -5.55100851e-02
  6.81794071e+00  2.07937002e+00  7.28380156e+00  1.05093136e+01
  1.40520501e+00  5.19018650e+00  6.29479265e+00  5.23412371e+00
  2.19359255e+00  9.70839596e+00  4.63605547e+00  9.80713272e+00
  6.71604156e+00  2.83194685e+00  8.21691513e+00  3.91888070e+00
  8.82857418e+00  5.65095377e+00  7.74853373e+00  6.66070604e+00
  8.72240067e+00  4.82063627e+00  9.65159893e+00  7.37593651e+00
  5.52394199e+00  6.06229258e+00  6.28078938e-01  3.63155842e+00
  6.63515043e+00  3.13720345e+00  6.10160494e+00  4.59917688e+00
  1.67009079e+00  2.67929316e+00  5.87469530e+00  5.35120296e+00
  5.20565653e+00  6.30662727e+00  7.39564276e+00  4.35430813e+00
  8.88551044e+00  2.87358689e+00  4.32844305e+00  9.07120323e+00
  8.34959602e+00  6.54305315e+00  6.36145771e-01  9.69855213e+00
  6.49582243e+00  1.02082977e+01  1.42218649e+00  7.77432966e+00
  1.58041847e+00  6.40702820e+00  1.07924449e+00  8.47589207e+00
  8.23396206e+00  5.41745853e+00  3.85215545e+00  7.45270491e-01
  6.41533756e+00  4.21811962e+00  7.45381451e+00  8.68435764e+00
  9.59165764e+00  9.22718906e+00 -1.01518297e+00  4.78479671e+00
  7.09206533e+00  2.16092372e+00  5.71304035e+00  1.19908273e-01
  3.16043782e+00  9.20669734e-02  8.17029667e+00  2.31537890e+00
  3.80825901e+00  9.06393814e+00  7.17630625e+00  1.20758474e-01
  1.57467747e+00  6.56413174e+00  5.80603886e+00  1.90417314e+00
  9.26850033e+00  5.71055651e+00  5.48348093e+00  5.70006657e+00
  7.34501457e+00  3.06974077e+00  4.17449951e+00  1.88637686e+00
  1.59649813e+00  8.74714470e+00  7.68149471e+00  5.14725018e+00
  1.94792962e+00  2.93671155e+00  6.94045722e-01  4.93041849e+00
  2.29451370e+00  6.96200371e+00  2.94133329e+00  7.65987992e-01
 -2.16490626e-02  6.85447574e-01  6.85941124e+00  4.85409117e+00
  5.72059441e+00  8.98723507e+00  9.62737179e+00  2.21571255e+00
  6.79449415e+00  2.29369974e+00  5.30113637e-01  7.87245512e+00
  3.63518763e+00  4.00529575e+00  5.20808411e+00  8.23005772e+00
  6.37014103e+00  8.26017952e+00  3.29657626e+00  7.93651295e+00
  1.78429985e+00  9.56696796e+00  7.06810617e+00  2.25382471e+00
  9.54646778e+00  7.23986912e+00  2.52804947e+00  2.58364177e+00
  5.52888250e+00  1.77395463e-01  2.06791592e+00  4.35356903e+00
  3.59637356e+00  3.74388838e+00  2.40446615e+00  5.81385517e+00
  8.67110729e+00  1.17576969e+00  4.94048452e+00  9.40345764e-01
  6.09276962e+00  3.86963511e+00  6.18902493e+00  1.56115341e+00
  2.90525699e+00  4.87162495e+00  3.71526504e+00  9.40074253e+00
  7.42161226e+00  7.27192879e+00  1.00699673e+01  1.18854022e+00
  5.78801632e+00  5.48251772e+00  9.94960403e+00  2.90021896e+00
  4.43213892e+00  4.77912188e-01  3.98015082e-01  1.12766476e+01
  6.74848080e+00  7.22801781e+00  2.82795882e+00  5.88993359e+00
  6.98136806e-01  3.23450828e+00  9.72003841e+00  8.30174351e+00
  3.07273555e+00  9.91379070e+00  1.91660452e+00  9.71661282e+00
  9.90089893e+00  8.15846062e+00  7.03740978e+00  9.58544540e+00
  2.93002963e+00  8.31967926e+00  5.99808025e+00  7.28550479e-02
  3.85735941e+00  9.70761538e-01  9.23753738e+00  5.46686459e+00
  5.50278473e+00  6.01728964e+00  4.34324074e+00  1.36993062e+00
  8.45484543e+00  4.68175888e-01  5.26911163e+00  1.84141123e+00
  3.81864011e-01  7.90763950e+00  9.70255852e+00  9.84720516e+00
  9.43443680e+00  7.68962574e+00  3.80397248e+00  6.65612042e-01
  5.16863966e+00  2.47927332e+00  4.73985672e-01  1.05347097e+00
  7.32991314e+00  9.36276674e-01  7.35460091e+00  1.67862105e+00
  4.33905751e-01  1.59291720e+00  7.84084034e+00  2.43011403e+00
  4.25165033e+00  5.68983269e+00  8.60872746e+00  7.16398525e+00
  2.72054410e+00  1.94252491e+00 -1.85395658e-01  3.34451747e+00
  1.99218881e+00  3.79499388e+00  5.96836662e+00  7.37168837e+00
  2.49210262e+00  3.98509121e+00  9.37832177e-01  8.80943108e+00
  2.57825583e-01  6.98963022e+00  7.78174019e+00  7.89891291e+00
  2.61566496e+00  3.04674053e+00  6.46863794e+00  2.90103054e+00
  4.06367350e+00  2.83596921e+00  5.16630077e+00  6.22896612e-01
  7.82478142e+00  3.80227089e-01  3.55100584e+00  3.55920887e+00
  5.84608507e+00  9.32784271e+00  6.44432068e+00  6.71383977e-01
  3.80863142e+00  5.12159157e+00  5.26213694e+00  6.50915527e+00
  3.31823993e+00  1.51588440e+00  3.74508786e+00  9.63789845e+00
  2.82012701e+00  9.30117702e+00  5.18297386e+00  5.08122492e+00
  9.10340309e+00  4.14017344e+00  8.16922951e+00  3.49889684e+00
  9.15036392e+00  7.04796791e+00  6.91863298e+00  3.43821239e+00
  7.49771976e+00  6.58094883e+00  1.52206314e+00  1.66219306e+00
  8.96467304e+00  9.71891689e+00  6.03888035e+00  6.12453365e+00
  8.36337280e+00  4.72068548e+00  7.40723658e+00  4.66089344e+00
  9.60812855e+00  1.02327881e+01  8.27917576e+00  1.76802504e+00
  5.86829615e+00  4.09585905e+00 -5.26962698e-01  4.35076141e+00
  2.46013212e+00  8.68481445e+00  3.86820614e-01  9.69470692e+00
  3.67586684e+00  3.92413521e+00 -9.84535664e-02  2.63078451e+00
  4.00670385e+00  1.10941935e+01  5.17772198e-01  9.30033970e+00
  9.24112511e+00  2.92216539e+00  3.37561965e+00  2.46589732e+00
  6.14229774e+00  4.67309088e-01 -8.67828280e-02  4.08560181e+00
  3.99175465e-01  2.54151607e+00  2.21575212e+00  2.50912642e+00
  1.27955842e+00 -7.25474238e-01  8.21681261e-01  6.53614998e+00
  1.04211264e+01  9.34315395e+00  3.89995766e+00  3.41503716e+00
  6.30898190e+00  4.78263617e+00  1.00384960e+01  1.44826126e+00
  8.01760387e+00  3.30487871e+00  2.22230029e+00  6.98749399e+00
  2.56673408e+00  6.51266956e+00  5.16357517e+00  4.21222687e+00
  5.53316402e+00  2.87564898e+00  6.88569880e+00  5.24295902e+00
  3.83784485e+00  8.63262177e+00  9.42399979e+00  4.50341552e-01
  2.33270240e+00  2.46700525e+00  8.57210445e+00  9.93498421e+00
  9.70180130e+00  9.04918671e+00  2.82848668e+00  1.01604681e+01
  2.13376069e+00  1.08001816e+00  1.01585007e+01  2.37143421e+00
  6.89639854e+00  6.13785625e-01  6.39277411e+00  8.98899841e+00
  3.29311657e+00  3.45347357e+00  3.81167507e+00  7.88749123e+00
  1.59779358e+00  5.66715002e-01  4.65487051e+00  4.15191126e+00
  8.22690773e+00  2.27221990e+00  5.74325514e+00  9.80365372e+00
  6.51945877e+00  8.45271111e+00  9.52017021e+00  7.24792719e+00
  6.43911409e+00  8.51561165e+00  1.02915831e+01  4.50498724e+00
  9.14542615e-01  2.86150455e+00  2.13800192e-01  3.66317129e+00
  1.32120097e+00  6.51088238e+00  3.09616232e+00  9.20569038e+00
  9.73210716e+00  5.21707201e+00  3.67960548e+00  5.34920645e+00
  8.44879818e+00  4.15654373e+00  5.51069403e+00  2.64717555e+00
  4.56229973e+00  4.03184319e+00  2.53720236e+00  4.99534702e+00
  2.31029892e+00  3.48865128e+00  8.25072670e+00  7.54355812e+00
  2.20225477e+00  1.13970642e+01  8.49588680e+00  7.10883319e-01
  2.74363828e+00  4.99293470e+00  1.34385705e-01  3.21501279e+00
  8.21650314e+00  6.79964018e+00  6.27488852e+00  7.14794111e+00
  1.90239477e+00  3.45294881e+00  7.35099411e+00  9.33995914e+00
  6.05294037e+00  2.90113711e+00 -1.24432337e+00  6.42705727e+00
  5.68964370e-02  3.37960458e+00  4.96043348e+00  9.90640545e+00
  1.23383534e+00  4.00741386e+00  6.40055537e-03  3.24708557e+00
  6.32790136e+00  2.19222999e+00  2.08447242e+00  1.32372677e+00
  5.92049932e+00  6.88256168e+00  7.01928997e+00  1.04399967e+01
 -2.88216442e-01  6.52927542e+00  6.16809750e+00  6.00324678e+00
  9.71869183e+00  1.13557257e-01  7.11323690e+00  7.71879911e+00
  5.03887224e+00  3.76561260e+00  8.05337811e+00  3.14987302e-01
  5.12668896e+00  5.27989054e+00  6.75082159e+00  1.43525863e+00
  2.57989788e+00  4.62727022e+00  6.04563522e+00  9.48542213e+00
  7.09511852e+00  1.17622685e+00  9.15441227e+00  9.80256653e+00
  5.09900427e+00  9.44795132e+00  5.51893759e+00  1.03330717e+01
  8.30469704e+00  1.07898369e+01  1.01827803e+01 -5.05745411e-04
  1.73885703e+00  3.52059174e+00  9.45347977e+00  3.41492081e+00
  1.14690316e+00  9.65928459e+00  4.69807243e+00  9.03562832e+00
  1.17234612e+00  6.69798565e+00  4.43081808e+00  8.74517798e-01
  6.92903471e+00  2.09807229e+00 -7.14968681e-01  5.73539436e-01
  6.28464758e-01  8.92654991e+00  8.03050327e+00  9.02817154e+00
  7.40084696e+00  5.17232370e+00  3.25738239e+00  1.01524630e+01
  3.55576420e+00  3.88637328e+00  4.20779133e+00  8.97262955e+00
  1.70729637e+00  3.30006480e+00  5.26616716e+00  9.60324168e-01
  6.40397358e+00  4.05875492e+00  2.62214065e+00  2.05707121e+00
  4.09347248e+00  3.94071198e+00  5.06777287e+00  3.40968561e+00
  8.99762726e+00  1.47003901e+00  8.83282781e-01  3.52675414e+00
  5.27389050e+00  6.61437607e+00  5.19436264e+00  9.38774395e+00
  3.59817815e+00  7.51900101e+00  6.17228937e+00  8.14072514e+00
  1.00964031e+01  8.67543316e+00  7.67522526e+00  6.90801048e+00
  3.51598859e+00  5.34878731e-01  6.36672795e-01  2.41127205e+00
  3.82626390e+00  5.18385172e+00  5.83661032e+00  9.15472126e+00
  8.23223293e-01  2.42483902e+00  5.41429329e+00  8.00633621e+00
  7.98597336e+00  9.41291142e+00  9.83840275e+00  4.71966314e+00
  4.63481140e+00  4.06945586e-01  6.68186712e+00  6.24139881e+00
  8.50881863e+00  7.10938215e-01  4.35715389e+00  5.98537350e+00
  2.39591932e+00  1.52024806e+00  9.15522194e+00  1.84586793e-01
  3.84848523e+00  1.13246572e+00  4.45568275e+00  9.84170437e+00
  4.21756744e+00  6.01763248e+00  7.27610350e-01  3.31445408e+00
  4.36259508e+00  4.26714516e+00  6.67291355e+00  3.47573233e+00
  6.96841526e+00  6.61320925e+00  4.78718519e+00  3.85241342e+00
  5.65875959e+00  9.63071108e-01  8.21956635e+00  7.05007601e+00
  7.35808372e+00  5.60682201e+00  8.74726832e-01  4.78749466e+00
  4.08274555e+00  3.05295515e+00 -2.82806456e-02  7.37880754e+00
  1.13245630e+00  6.21132517e+00  7.19738770e+00  6.62598848e+00
  8.44676971e+00  7.01955557e-01  8.75954437e+00  1.91597685e-01
  6.34029531e+00  4.09656525e+00  4.70814228e+00  3.66343403e+00
  1.92009354e+00 -2.97656119e-01  4.93795109e+00  7.03719902e+00
  3.54990387e+00  2.22650814e+00  1.47342825e+00  1.87733543e+00
  9.82225418e-01  1.97523093e+00  2.90856576e+00 -1.95377409e-01
  7.63740540e-01  8.23801708e+00  1.92524207e+00  4.57951069e+00
  8.07519722e+00  4.80337429e+00  1.63165092e+00  2.09296656e+00
  4.45628262e+00  5.24322176e+00  3.30323172e+00  7.77983236e+00
  7.60303879e+00  8.98269558e+00  3.17642242e-01  9.00031185e+00
  3.89518857e+00  8.87557316e+00  6.54464340e+00  9.40222740e+00
  7.76669884e+00  3.63010335e+00  4.89937687e+00  3.79815769e+00
  3.43109441e+00  2.11776972e+00  4.50608540e+00  6.73585749e+00
  2.77784801e+00  4.75118494e+00  1.41163933e+00  1.43678403e+00
  4.72844005e-01  1.01116915e+01  4.33705822e-02  1.87914848e+00
  6.03755856e+00  1.65911603e+00  9.08522511e+00  7.11956310e+00
  8.27528858e+00  4.67179298e+00  1.46821272e+00  5.57443333e+00
  9.03736591e+00  7.08154297e+00  2.92699647e+00  9.28951740e+00
  3.66812515e+00  1.79973990e-02  2.40762663e+00  1.92846382e+00
  8.69157314e+00  4.33280611e+00  4.23879671e+00  3.11560988e+00
  9.60638237e+00  1.10599823e+01  9.74016571e+00  3.66849303e+00
  9.42271328e+00  8.38017178e+00  6.39697123e+00  3.64649916e+00
  1.97412837e+00  2.19269991e+00  9.55885601e+00  2.80885458e+00
  4.91888142e+00  5.15744495e+00  8.31021786e+00  8.34845829e+00
  1.55545843e+00  3.92147779e+00  8.22108078e+00  7.88888502e+00
  1.22066307e+00  1.52498245e+00  3.15602779e+00  9.93907928e-01
  4.50527048e+00  1.36449265e+00  5.00522995e+00  2.42850351e+00
  5.87198400e+00 -1.04476917e+00  9.73143959e+00  9.51038170e+00
  4.31158495e+00  3.61805153e+00  1.88797522e+00  5.04972935e+00
  4.03085709e-01  4.60245562e+00  3.75540328e+00  4.01810455e+00
  8.59900475e+00  7.06478453e+00  9.62819099e+00  3.01856041e+00
  9.00697613e+00  8.57353497e+00  4.79125214e+00  6.26140499e+00
  2.85231853e+00  1.06102486e+01  1.06103802e+00  2.18488646e+00
  3.15353966e+00  4.29014683e+00  7.35634613e+00  5.12752581e+00
  4.86164331e+00  6.53155148e-01  5.14040470e+00  5.27053058e-01
  1.85232019e+00  9.85549164e+00  2.36561966e+00  8.83290672e+00
  8.07797718e+00  2.24759030e+00  5.88459301e+00  1.65719461e+00
  7.13856363e+00  6.36659193e+00  8.30550766e+00  4.64638376e+00
  8.86743259e+00 -1.78816348e-01  2.12690020e+00  7.22018147e+00
  4.37131548e+00  1.50182629e+00  1.44224501e+00  8.23597240e+00
  2.87912059e+00  8.82868195e+00  6.72185993e+00  4.10417318e+00
  3.72402120e+00  4.76707935e+00  8.69713497e+00  8.02846813e+00
 -5.91852479e-02  6.92536926e+00  9.99452686e+00  7.10508966e+00
  1.77003264e+00  5.62554789e+00  1.03404069e+00  4.70238781e+00
  9.31285954e+00  8.93695068e+00  2.82111669e+00  3.46559119e+00
  6.18987942e+00  9.39866257e+00  5.47782779e-01  2.72644186e+00
  8.94318962e+00  4.69057751e+00  1.03748589e+01  2.52786398e+00
  5.76243114e+00  3.48165631e+00  3.81163502e+00  3.76940107e+00
  4.03297091e+00  4.00298834e+00  8.04087162e+00  7.70173693e+00
  7.10223532e+00  3.21729660e+00  5.74228382e+00  6.87862539e+00
  7.01803017e+00  3.45543861e+00  7.26741600e+00  7.03988886e+00
  1.35023844e+00  8.91982746e+00  4.43680811e+00  5.25290489e+00
  3.51280975e+00  6.24143553e+00  6.52131414e+00  4.72280169e+00
  8.25355721e+00  6.25390244e+00  5.13515329e+00  4.87421942e+00
  7.67947769e+00  3.34088635e+00  2.31048179e+00  4.33013082e-01
  8.68751335e+00  9.47573662e+00  1.55903900e+00  3.07618022e+00
  1.50216174e+00  1.19446433e+00  9.29029846e+00  1.65662837e+00
  9.56382942e+00  9.47769403e-01  8.08623123e+00  5.85028315e+00
  4.43489981e+00  3.51404214e+00  7.59146261e+00  3.24519110e+00
  6.24453449e+00  3.84153080e+00  4.75549126e+00  8.96583271e+00
  5.54600143e+00  7.46122551e+00  6.96567345e+00  4.11713839e-01
  7.67649698e+00  2.08050108e+00  9.21236324e+00  1.41680741e+00
  3.03086996e+00  1.13182259e+00  4.03754902e+00  8.78156567e+00
  2.95456624e+00  1.61442590e+00  3.30749226e+00  8.14694023e+00
  1.37203860e+00  1.63373399e+00  6.45686090e-01  7.07791662e+00
  3.06980824e+00  4.66480160e+00  7.18863678e+00  3.41025472e+00
  7.26521921e+00  7.07599974e+00  2.82888842e+00  1.03278141e+01
  1.74131536e+00  2.78822184e+00  1.28855526e+00  3.68360829e+00
  5.39412928e+00  5.52329063e+00  8.01896572e+00  8.91389751e+00
  2.46595716e+00  6.16491985e+00  1.14002132e+00  3.73238707e+00
  3.28532362e+00  2.97972035e+00  4.97999954e+00  7.17574263e+00
  7.50538170e-01  1.02770720e+01  7.28148460e+00  2.06288123e+00
  9.35947418e+00  5.11205769e+00  9.92250729e+00  1.66801298e+00
  3.66859484e+00  3.06588221e+00  3.05286908e+00  5.87349463e+00
  9.89076328e+00  8.08929062e+00  6.18565559e+00  5.57329512e+00
  9.22900391e+00  3.96593451e+00  8.75203419e+00  8.35547829e+00
  2.17680025e+00  7.65000153e+00  1.08980224e-01  3.05595231e+00
  2.58785725e+00  5.23494005e+00  7.61446953e+00  4.45858717e-01
  4.63132048e+00  9.55903053e+00  1.96978843e+00  6.25351620e+00]
Epoch 1/1000
2023-09-10 01:37:43.879 
Epoch 1/1000 
	 loss: 1907.5305, MinusLogProbMetric: 1907.5305, val_loss: 715.5930, val_MinusLogProbMetric: 715.5930

Epoch 1: val_loss improved from inf to 715.59302, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 60s - loss: 1907.5305 - MinusLogProbMetric: 1907.5305 - val_loss: 715.5930 - val_MinusLogProbMetric: 715.5930 - lr: 0.0010 - 60s/epoch - 305ms/step
Epoch 2/1000
2023-09-10 01:37:57.647 
Epoch 2/1000 
	 loss: 586.3636, MinusLogProbMetric: 586.3636, val_loss: 551.3821, val_MinusLogProbMetric: 551.3821

Epoch 2: val_loss improved from 715.59302 to 551.38214, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 586.3636 - MinusLogProbMetric: 586.3636 - val_loss: 551.3821 - val_MinusLogProbMetric: 551.3821 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 3/1000
2023-09-10 01:38:10.989 
Epoch 3/1000 
	 loss: 534.5215, MinusLogProbMetric: 534.5215, val_loss: 504.8651, val_MinusLogProbMetric: 504.8651

Epoch 3: val_loss improved from 551.38214 to 504.86508, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 534.5215 - MinusLogProbMetric: 534.5215 - val_loss: 504.8651 - val_MinusLogProbMetric: 504.8651 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 4/1000
2023-09-10 01:38:25.042 
Epoch 4/1000 
	 loss: 502.5278, MinusLogProbMetric: 502.5278, val_loss: 484.2186, val_MinusLogProbMetric: 484.2186

Epoch 4: val_loss improved from 504.86508 to 484.21860, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 502.5278 - MinusLogProbMetric: 502.5278 - val_loss: 484.2186 - val_MinusLogProbMetric: 484.2186 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 5/1000
2023-09-10 01:38:39.217 
Epoch 5/1000 
	 loss: 492.4975, MinusLogProbMetric: 492.4975, val_loss: 479.9177, val_MinusLogProbMetric: 479.9177

Epoch 5: val_loss improved from 484.21860 to 479.91766, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 492.4975 - MinusLogProbMetric: 492.4975 - val_loss: 479.9177 - val_MinusLogProbMetric: 479.9177 - lr: 0.0010 - 14s/epoch - 73ms/step
Epoch 6/1000
2023-09-10 01:38:52.489 
Epoch 6/1000 
	 loss: 485.0955, MinusLogProbMetric: 485.0955, val_loss: 482.5311, val_MinusLogProbMetric: 482.5311

Epoch 6: val_loss did not improve from 479.91766
196/196 - 13s - loss: 485.0955 - MinusLogProbMetric: 485.0955 - val_loss: 482.5311 - val_MinusLogProbMetric: 482.5311 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 7/1000
2023-09-10 01:39:06.464 
Epoch 7/1000 
	 loss: 470.1193, MinusLogProbMetric: 470.1193, val_loss: 460.7097, val_MinusLogProbMetric: 460.7097

Epoch 7: val_loss improved from 479.91766 to 460.70969, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 15s - loss: 470.1193 - MinusLogProbMetric: 470.1193 - val_loss: 460.7097 - val_MinusLogProbMetric: 460.7097 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 8/1000
2023-09-10 01:39:19.258 
Epoch 8/1000 
	 loss: 461.9788, MinusLogProbMetric: 461.9788, val_loss: 454.6996, val_MinusLogProbMetric: 454.6996

Epoch 8: val_loss improved from 460.70969 to 454.69965, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 461.9788 - MinusLogProbMetric: 461.9788 - val_loss: 454.6996 - val_MinusLogProbMetric: 454.6996 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 9/1000
2023-09-10 01:39:31.728 
Epoch 9/1000 
	 loss: 460.5692, MinusLogProbMetric: 460.5692, val_loss: 457.7816, val_MinusLogProbMetric: 457.7816

Epoch 9: val_loss did not improve from 454.69965
196/196 - 12s - loss: 460.5692 - MinusLogProbMetric: 460.5692 - val_loss: 457.7816 - val_MinusLogProbMetric: 457.7816 - lr: 0.0010 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-10 01:39:44.568 
Epoch 10/1000 
	 loss: 452.2587, MinusLogProbMetric: 452.2587, val_loss: 448.3934, val_MinusLogProbMetric: 448.3934

Epoch 10: val_loss improved from 454.69965 to 448.39340, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 452.2587 - MinusLogProbMetric: 452.2587 - val_loss: 448.3934 - val_MinusLogProbMetric: 448.3934 - lr: 0.0010 - 13s/epoch - 67ms/step
Epoch 11/1000
2023-09-10 01:39:57.644 
Epoch 11/1000 
	 loss: 452.3213, MinusLogProbMetric: 452.3213, val_loss: 438.4516, val_MinusLogProbMetric: 438.4516

Epoch 11: val_loss improved from 448.39340 to 438.45160, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 452.3213 - MinusLogProbMetric: 452.3213 - val_loss: 438.4516 - val_MinusLogProbMetric: 438.4516 - lr: 0.0010 - 14s/epoch - 70ms/step
Epoch 12/1000
2023-09-10 01:40:10.613 
Epoch 12/1000 
	 loss: 448.5429, MinusLogProbMetric: 448.5429, val_loss: 437.7880, val_MinusLogProbMetric: 437.7880

Epoch 12: val_loss improved from 438.45160 to 437.78799, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 448.5429 - MinusLogProbMetric: 448.5429 - val_loss: 437.7880 - val_MinusLogProbMetric: 437.7880 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 13/1000
2023-09-10 01:40:24.249 
Epoch 13/1000 
	 loss: 444.5313, MinusLogProbMetric: 444.5313, val_loss: 442.6990, val_MinusLogProbMetric: 442.6990

Epoch 13: val_loss did not improve from 437.78799
196/196 - 13s - loss: 444.5313 - MinusLogProbMetric: 444.5313 - val_loss: 442.6990 - val_MinusLogProbMetric: 442.6990 - lr: 0.0010 - 13s/epoch - 68ms/step
Epoch 14/1000
2023-09-10 01:40:35.369 
Epoch 14/1000 
	 loss: 442.0748, MinusLogProbMetric: 442.0748, val_loss: 435.3797, val_MinusLogProbMetric: 435.3797

Epoch 14: val_loss improved from 437.78799 to 435.37973, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 442.0748 - MinusLogProbMetric: 442.0748 - val_loss: 435.3797 - val_MinusLogProbMetric: 435.3797 - lr: 0.0010 - 12s/epoch - 62ms/step
Epoch 15/1000
2023-09-10 01:40:51.020 
Epoch 15/1000 
	 loss: 438.1774, MinusLogProbMetric: 438.1774, val_loss: 445.3798, val_MinusLogProbMetric: 445.3798

Epoch 15: val_loss did not improve from 435.37973
196/196 - 15s - loss: 438.1774 - MinusLogProbMetric: 438.1774 - val_loss: 445.3798 - val_MinusLogProbMetric: 445.3798 - lr: 0.0010 - 15s/epoch - 75ms/step
Epoch 16/1000
2023-09-10 01:41:04.177 
Epoch 16/1000 
	 loss: 437.2930, MinusLogProbMetric: 437.2930, val_loss: 433.0397, val_MinusLogProbMetric: 433.0397

Epoch 16: val_loss improved from 435.37973 to 433.03967, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 437.2930 - MinusLogProbMetric: 437.2930 - val_loss: 433.0397 - val_MinusLogProbMetric: 433.0397 - lr: 0.0010 - 14s/epoch - 69ms/step
Epoch 17/1000
2023-09-10 01:41:17.400 
Epoch 17/1000 
	 loss: 436.5196, MinusLogProbMetric: 436.5196, val_loss: 433.2762, val_MinusLogProbMetric: 433.2762

Epoch 17: val_loss did not improve from 433.03967
196/196 - 13s - loss: 436.5196 - MinusLogProbMetric: 436.5196 - val_loss: 433.2762 - val_MinusLogProbMetric: 433.2762 - lr: 0.0010 - 13s/epoch - 65ms/step
Epoch 18/1000
2023-09-10 01:41:32.121 
Epoch 18/1000 
	 loss: 432.5898, MinusLogProbMetric: 432.5898, val_loss: 429.5424, val_MinusLogProbMetric: 429.5424

Epoch 18: val_loss improved from 433.03967 to 429.54239, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 15s - loss: 432.5898 - MinusLogProbMetric: 432.5898 - val_loss: 429.5424 - val_MinusLogProbMetric: 429.5424 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 19/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 139: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-10 01:41:44.120 
Epoch 19/1000 
	 loss: inf, MinusLogProbMetric: 629945557345368091298684156772352.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 19: val_loss did not improve from 429.54239
196/196 - 12s - loss: inf - MinusLogProbMetric: 629945557345368091298684156772352.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 12s/epoch - 59ms/step
The loss history contains Inf values.
Training failed: trying again with seed 326159 and lr 0.0003333333333333333.
===========
Generating train data for run 330.
===========
Train data generated in 2.75 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_330/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_330/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_330/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_330
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.437488    7.1322474   6.533019   ...  9.559031    1.9697884
   6.253516  ]
 [ 6.105814   -0.33694893  4.861082   ...  4.728712    6.8399925
   2.9518385 ]
 [ 5.5099134   8.416618    3.6192868  ... 10.13037     0.5513004
   6.6116333 ]
 ...
 [ 8.378759    5.1539607   5.2823405  ...  4.1604185   7.9323363
   6.8563857 ]
 [ 8.088472    5.184855    5.311574   ...  3.8879027   7.132432
   7.66768   ]
 [ 5.6874776   6.932827    6.1243634  ...  9.540177    3.2688973
   7.1452303 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_3 (LogProbLa  (None,)                  4509200   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,509,200
Trainable params: 4,509,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_3/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_3'")
self.model: <keras.engine.functional.Functional object at 0x7effc257a980>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effc24eb9a0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effc24eb9a0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effc257b220>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7effcb4bd990>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7effcb4bdc90>, <keras.callbacks.ModelCheckpoint object at 0x7effcb4bd9c0>, <keras.callbacks.EarlyStopping object at 0x7effcb4bd7e0>, <keras.callbacks.ReduceLROnPlateau object at 0x7effcb4bc940>, <keras.callbacks.TerminateOnNaN object at 0x7effcb4bcf10>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 330/360 with hyperparameters:
timestamp = 2023-09-10 01:41:51.073618
ndims = 1000
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 4509200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 5.43748808e+00  7.13224745e+00  6.53301907e+00  5.31066608e+00
  3.79545021e+00  6.28738737e+00  2.71391177e+00  8.88872051e+00
  9.43951797e+00  4.12179470e+00  7.81367683e+00  5.36657619e+00
  5.55121899e+00  9.56866932e+00  7.94146359e-01  9.63486314e-01
 -1.46448463e-02  7.97977352e+00  8.35143089e+00  9.09444618e+00
  9.51050758e+00  8.15759563e+00  4.87677431e+00  8.12364483e+00
 -5.86649776e-01  6.22392607e+00  1.30506945e+00  9.45408440e+00
  7.08888865e+00  3.35072994e+00  2.25734115e+00  8.41814995e+00
  4.58319330e+00  5.61194181e+00  2.26602942e-01  5.45686245e+00
  6.14353561e+00  6.25023174e+00  9.57346344e+00  6.36795044e+00
  3.20757818e+00  4.83043623e+00  7.51926565e+00  6.34396672e-01
  6.89045191e+00  6.62100124e+00  2.44563007e+00  1.28772116e+00
  3.22250342e+00  4.52788544e+00  5.89035130e+00  4.86346960e+00
  9.48264980e+00 -1.13163722e+00  3.37091446e+00  9.05362010e-01
  6.78129101e+00  1.94818664e+00  4.17912102e+00  3.18960547e+00
  1.62776482e+00  1.21974039e+00  7.33607817e+00  1.62089002e+00
  2.96397400e+00  4.52560091e+00  8.39162827e+00  1.51216686e+00
  8.25380135e+00  5.98394752e-01  9.67017937e+00  4.48699141e+00
  1.02882853e+01  5.70898390e+00  6.28753185e+00  6.97938085e-01
  2.82613039e+00  1.18152845e+00  2.21910620e+00  1.18442059e-01
  3.30913496e+00  4.37123442e+00 -6.00820422e-01  7.13190508e+00
  5.83363104e+00  2.43325353e+00  5.20436668e+00  1.77731943e+00
  6.29233789e+00  9.14511585e+00  2.47849083e+00  7.14207220e+00
  1.59640992e+00  7.87721014e+00  3.72595000e+00  1.65804911e+00
  6.26306725e+00  6.14266574e-01  9.35802937e+00 -5.55100851e-02
  6.81794071e+00  2.07937002e+00  7.28380156e+00  1.05093136e+01
  1.40520501e+00  5.19018650e+00  6.29479265e+00  5.23412371e+00
  2.19359255e+00  9.70839596e+00  4.63605547e+00  9.80713272e+00
  6.71604156e+00  2.83194685e+00  8.21691513e+00  3.91888070e+00
  8.82857418e+00  5.65095377e+00  7.74853373e+00  6.66070604e+00
  8.72240067e+00  4.82063627e+00  9.65159893e+00  7.37593651e+00
  5.52394199e+00  6.06229258e+00  6.28078938e-01  3.63155842e+00
  6.63515043e+00  3.13720345e+00  6.10160494e+00  4.59917688e+00
  1.67009079e+00  2.67929316e+00  5.87469530e+00  5.35120296e+00
  5.20565653e+00  6.30662727e+00  7.39564276e+00  4.35430813e+00
  8.88551044e+00  2.87358689e+00  4.32844305e+00  9.07120323e+00
  8.34959602e+00  6.54305315e+00  6.36145771e-01  9.69855213e+00
  6.49582243e+00  1.02082977e+01  1.42218649e+00  7.77432966e+00
  1.58041847e+00  6.40702820e+00  1.07924449e+00  8.47589207e+00
  8.23396206e+00  5.41745853e+00  3.85215545e+00  7.45270491e-01
  6.41533756e+00  4.21811962e+00  7.45381451e+00  8.68435764e+00
  9.59165764e+00  9.22718906e+00 -1.01518297e+00  4.78479671e+00
  7.09206533e+00  2.16092372e+00  5.71304035e+00  1.19908273e-01
  3.16043782e+00  9.20669734e-02  8.17029667e+00  2.31537890e+00
  3.80825901e+00  9.06393814e+00  7.17630625e+00  1.20758474e-01
  1.57467747e+00  6.56413174e+00  5.80603886e+00  1.90417314e+00
  9.26850033e+00  5.71055651e+00  5.48348093e+00  5.70006657e+00
  7.34501457e+00  3.06974077e+00  4.17449951e+00  1.88637686e+00
  1.59649813e+00  8.74714470e+00  7.68149471e+00  5.14725018e+00
  1.94792962e+00  2.93671155e+00  6.94045722e-01  4.93041849e+00
  2.29451370e+00  6.96200371e+00  2.94133329e+00  7.65987992e-01
 -2.16490626e-02  6.85447574e-01  6.85941124e+00  4.85409117e+00
  5.72059441e+00  8.98723507e+00  9.62737179e+00  2.21571255e+00
  6.79449415e+00  2.29369974e+00  5.30113637e-01  7.87245512e+00
  3.63518763e+00  4.00529575e+00  5.20808411e+00  8.23005772e+00
  6.37014103e+00  8.26017952e+00  3.29657626e+00  7.93651295e+00
  1.78429985e+00  9.56696796e+00  7.06810617e+00  2.25382471e+00
  9.54646778e+00  7.23986912e+00  2.52804947e+00  2.58364177e+00
  5.52888250e+00  1.77395463e-01  2.06791592e+00  4.35356903e+00
  3.59637356e+00  3.74388838e+00  2.40446615e+00  5.81385517e+00
  8.67110729e+00  1.17576969e+00  4.94048452e+00  9.40345764e-01
  6.09276962e+00  3.86963511e+00  6.18902493e+00  1.56115341e+00
  2.90525699e+00  4.87162495e+00  3.71526504e+00  9.40074253e+00
  7.42161226e+00  7.27192879e+00  1.00699673e+01  1.18854022e+00
  5.78801632e+00  5.48251772e+00  9.94960403e+00  2.90021896e+00
  4.43213892e+00  4.77912188e-01  3.98015082e-01  1.12766476e+01
  6.74848080e+00  7.22801781e+00  2.82795882e+00  5.88993359e+00
  6.98136806e-01  3.23450828e+00  9.72003841e+00  8.30174351e+00
  3.07273555e+00  9.91379070e+00  1.91660452e+00  9.71661282e+00
  9.90089893e+00  8.15846062e+00  7.03740978e+00  9.58544540e+00
  2.93002963e+00  8.31967926e+00  5.99808025e+00  7.28550479e-02
  3.85735941e+00  9.70761538e-01  9.23753738e+00  5.46686459e+00
  5.50278473e+00  6.01728964e+00  4.34324074e+00  1.36993062e+00
  8.45484543e+00  4.68175888e-01  5.26911163e+00  1.84141123e+00
  3.81864011e-01  7.90763950e+00  9.70255852e+00  9.84720516e+00
  9.43443680e+00  7.68962574e+00  3.80397248e+00  6.65612042e-01
  5.16863966e+00  2.47927332e+00  4.73985672e-01  1.05347097e+00
  7.32991314e+00  9.36276674e-01  7.35460091e+00  1.67862105e+00
  4.33905751e-01  1.59291720e+00  7.84084034e+00  2.43011403e+00
  4.25165033e+00  5.68983269e+00  8.60872746e+00  7.16398525e+00
  2.72054410e+00  1.94252491e+00 -1.85395658e-01  3.34451747e+00
  1.99218881e+00  3.79499388e+00  5.96836662e+00  7.37168837e+00
  2.49210262e+00  3.98509121e+00  9.37832177e-01  8.80943108e+00
  2.57825583e-01  6.98963022e+00  7.78174019e+00  7.89891291e+00
  2.61566496e+00  3.04674053e+00  6.46863794e+00  2.90103054e+00
  4.06367350e+00  2.83596921e+00  5.16630077e+00  6.22896612e-01
  7.82478142e+00  3.80227089e-01  3.55100584e+00  3.55920887e+00
  5.84608507e+00  9.32784271e+00  6.44432068e+00  6.71383977e-01
  3.80863142e+00  5.12159157e+00  5.26213694e+00  6.50915527e+00
  3.31823993e+00  1.51588440e+00  3.74508786e+00  9.63789845e+00
  2.82012701e+00  9.30117702e+00  5.18297386e+00  5.08122492e+00
  9.10340309e+00  4.14017344e+00  8.16922951e+00  3.49889684e+00
  9.15036392e+00  7.04796791e+00  6.91863298e+00  3.43821239e+00
  7.49771976e+00  6.58094883e+00  1.52206314e+00  1.66219306e+00
  8.96467304e+00  9.71891689e+00  6.03888035e+00  6.12453365e+00
  8.36337280e+00  4.72068548e+00  7.40723658e+00  4.66089344e+00
  9.60812855e+00  1.02327881e+01  8.27917576e+00  1.76802504e+00
  5.86829615e+00  4.09585905e+00 -5.26962698e-01  4.35076141e+00
  2.46013212e+00  8.68481445e+00  3.86820614e-01  9.69470692e+00
  3.67586684e+00  3.92413521e+00 -9.84535664e-02  2.63078451e+00
  4.00670385e+00  1.10941935e+01  5.17772198e-01  9.30033970e+00
  9.24112511e+00  2.92216539e+00  3.37561965e+00  2.46589732e+00
  6.14229774e+00  4.67309088e-01 -8.67828280e-02  4.08560181e+00
  3.99175465e-01  2.54151607e+00  2.21575212e+00  2.50912642e+00
  1.27955842e+00 -7.25474238e-01  8.21681261e-01  6.53614998e+00
  1.04211264e+01  9.34315395e+00  3.89995766e+00  3.41503716e+00
  6.30898190e+00  4.78263617e+00  1.00384960e+01  1.44826126e+00
  8.01760387e+00  3.30487871e+00  2.22230029e+00  6.98749399e+00
  2.56673408e+00  6.51266956e+00  5.16357517e+00  4.21222687e+00
  5.53316402e+00  2.87564898e+00  6.88569880e+00  5.24295902e+00
  3.83784485e+00  8.63262177e+00  9.42399979e+00  4.50341552e-01
  2.33270240e+00  2.46700525e+00  8.57210445e+00  9.93498421e+00
  9.70180130e+00  9.04918671e+00  2.82848668e+00  1.01604681e+01
  2.13376069e+00  1.08001816e+00  1.01585007e+01  2.37143421e+00
  6.89639854e+00  6.13785625e-01  6.39277411e+00  8.98899841e+00
  3.29311657e+00  3.45347357e+00  3.81167507e+00  7.88749123e+00
  1.59779358e+00  5.66715002e-01  4.65487051e+00  4.15191126e+00
  8.22690773e+00  2.27221990e+00  5.74325514e+00  9.80365372e+00
  6.51945877e+00  8.45271111e+00  9.52017021e+00  7.24792719e+00
  6.43911409e+00  8.51561165e+00  1.02915831e+01  4.50498724e+00
  9.14542615e-01  2.86150455e+00  2.13800192e-01  3.66317129e+00
  1.32120097e+00  6.51088238e+00  3.09616232e+00  9.20569038e+00
  9.73210716e+00  5.21707201e+00  3.67960548e+00  5.34920645e+00
  8.44879818e+00  4.15654373e+00  5.51069403e+00  2.64717555e+00
  4.56229973e+00  4.03184319e+00  2.53720236e+00  4.99534702e+00
  2.31029892e+00  3.48865128e+00  8.25072670e+00  7.54355812e+00
  2.20225477e+00  1.13970642e+01  8.49588680e+00  7.10883319e-01
  2.74363828e+00  4.99293470e+00  1.34385705e-01  3.21501279e+00
  8.21650314e+00  6.79964018e+00  6.27488852e+00  7.14794111e+00
  1.90239477e+00  3.45294881e+00  7.35099411e+00  9.33995914e+00
  6.05294037e+00  2.90113711e+00 -1.24432337e+00  6.42705727e+00
  5.68964370e-02  3.37960458e+00  4.96043348e+00  9.90640545e+00
  1.23383534e+00  4.00741386e+00  6.40055537e-03  3.24708557e+00
  6.32790136e+00  2.19222999e+00  2.08447242e+00  1.32372677e+00
  5.92049932e+00  6.88256168e+00  7.01928997e+00  1.04399967e+01
 -2.88216442e-01  6.52927542e+00  6.16809750e+00  6.00324678e+00
  9.71869183e+00  1.13557257e-01  7.11323690e+00  7.71879911e+00
  5.03887224e+00  3.76561260e+00  8.05337811e+00  3.14987302e-01
  5.12668896e+00  5.27989054e+00  6.75082159e+00  1.43525863e+00
  2.57989788e+00  4.62727022e+00  6.04563522e+00  9.48542213e+00
  7.09511852e+00  1.17622685e+00  9.15441227e+00  9.80256653e+00
  5.09900427e+00  9.44795132e+00  5.51893759e+00  1.03330717e+01
  8.30469704e+00  1.07898369e+01  1.01827803e+01 -5.05745411e-04
  1.73885703e+00  3.52059174e+00  9.45347977e+00  3.41492081e+00
  1.14690316e+00  9.65928459e+00  4.69807243e+00  9.03562832e+00
  1.17234612e+00  6.69798565e+00  4.43081808e+00  8.74517798e-01
  6.92903471e+00  2.09807229e+00 -7.14968681e-01  5.73539436e-01
  6.28464758e-01  8.92654991e+00  8.03050327e+00  9.02817154e+00
  7.40084696e+00  5.17232370e+00  3.25738239e+00  1.01524630e+01
  3.55576420e+00  3.88637328e+00  4.20779133e+00  8.97262955e+00
  1.70729637e+00  3.30006480e+00  5.26616716e+00  9.60324168e-01
  6.40397358e+00  4.05875492e+00  2.62214065e+00  2.05707121e+00
  4.09347248e+00  3.94071198e+00  5.06777287e+00  3.40968561e+00
  8.99762726e+00  1.47003901e+00  8.83282781e-01  3.52675414e+00
  5.27389050e+00  6.61437607e+00  5.19436264e+00  9.38774395e+00
  3.59817815e+00  7.51900101e+00  6.17228937e+00  8.14072514e+00
  1.00964031e+01  8.67543316e+00  7.67522526e+00  6.90801048e+00
  3.51598859e+00  5.34878731e-01  6.36672795e-01  2.41127205e+00
  3.82626390e+00  5.18385172e+00  5.83661032e+00  9.15472126e+00
  8.23223293e-01  2.42483902e+00  5.41429329e+00  8.00633621e+00
  7.98597336e+00  9.41291142e+00  9.83840275e+00  4.71966314e+00
  4.63481140e+00  4.06945586e-01  6.68186712e+00  6.24139881e+00
  8.50881863e+00  7.10938215e-01  4.35715389e+00  5.98537350e+00
  2.39591932e+00  1.52024806e+00  9.15522194e+00  1.84586793e-01
  3.84848523e+00  1.13246572e+00  4.45568275e+00  9.84170437e+00
  4.21756744e+00  6.01763248e+00  7.27610350e-01  3.31445408e+00
  4.36259508e+00  4.26714516e+00  6.67291355e+00  3.47573233e+00
  6.96841526e+00  6.61320925e+00  4.78718519e+00  3.85241342e+00
  5.65875959e+00  9.63071108e-01  8.21956635e+00  7.05007601e+00
  7.35808372e+00  5.60682201e+00  8.74726832e-01  4.78749466e+00
  4.08274555e+00  3.05295515e+00 -2.82806456e-02  7.37880754e+00
  1.13245630e+00  6.21132517e+00  7.19738770e+00  6.62598848e+00
  8.44676971e+00  7.01955557e-01  8.75954437e+00  1.91597685e-01
  6.34029531e+00  4.09656525e+00  4.70814228e+00  3.66343403e+00
  1.92009354e+00 -2.97656119e-01  4.93795109e+00  7.03719902e+00
  3.54990387e+00  2.22650814e+00  1.47342825e+00  1.87733543e+00
  9.82225418e-01  1.97523093e+00  2.90856576e+00 -1.95377409e-01
  7.63740540e-01  8.23801708e+00  1.92524207e+00  4.57951069e+00
  8.07519722e+00  4.80337429e+00  1.63165092e+00  2.09296656e+00
  4.45628262e+00  5.24322176e+00  3.30323172e+00  7.77983236e+00
  7.60303879e+00  8.98269558e+00  3.17642242e-01  9.00031185e+00
  3.89518857e+00  8.87557316e+00  6.54464340e+00  9.40222740e+00
  7.76669884e+00  3.63010335e+00  4.89937687e+00  3.79815769e+00
  3.43109441e+00  2.11776972e+00  4.50608540e+00  6.73585749e+00
  2.77784801e+00  4.75118494e+00  1.41163933e+00  1.43678403e+00
  4.72844005e-01  1.01116915e+01  4.33705822e-02  1.87914848e+00
  6.03755856e+00  1.65911603e+00  9.08522511e+00  7.11956310e+00
  8.27528858e+00  4.67179298e+00  1.46821272e+00  5.57443333e+00
  9.03736591e+00  7.08154297e+00  2.92699647e+00  9.28951740e+00
  3.66812515e+00  1.79973990e-02  2.40762663e+00  1.92846382e+00
  8.69157314e+00  4.33280611e+00  4.23879671e+00  3.11560988e+00
  9.60638237e+00  1.10599823e+01  9.74016571e+00  3.66849303e+00
  9.42271328e+00  8.38017178e+00  6.39697123e+00  3.64649916e+00
  1.97412837e+00  2.19269991e+00  9.55885601e+00  2.80885458e+00
  4.91888142e+00  5.15744495e+00  8.31021786e+00  8.34845829e+00
  1.55545843e+00  3.92147779e+00  8.22108078e+00  7.88888502e+00
  1.22066307e+00  1.52498245e+00  3.15602779e+00  9.93907928e-01
  4.50527048e+00  1.36449265e+00  5.00522995e+00  2.42850351e+00
  5.87198400e+00 -1.04476917e+00  9.73143959e+00  9.51038170e+00
  4.31158495e+00  3.61805153e+00  1.88797522e+00  5.04972935e+00
  4.03085709e-01  4.60245562e+00  3.75540328e+00  4.01810455e+00
  8.59900475e+00  7.06478453e+00  9.62819099e+00  3.01856041e+00
  9.00697613e+00  8.57353497e+00  4.79125214e+00  6.26140499e+00
  2.85231853e+00  1.06102486e+01  1.06103802e+00  2.18488646e+00
  3.15353966e+00  4.29014683e+00  7.35634613e+00  5.12752581e+00
  4.86164331e+00  6.53155148e-01  5.14040470e+00  5.27053058e-01
  1.85232019e+00  9.85549164e+00  2.36561966e+00  8.83290672e+00
  8.07797718e+00  2.24759030e+00  5.88459301e+00  1.65719461e+00
  7.13856363e+00  6.36659193e+00  8.30550766e+00  4.64638376e+00
  8.86743259e+00 -1.78816348e-01  2.12690020e+00  7.22018147e+00
  4.37131548e+00  1.50182629e+00  1.44224501e+00  8.23597240e+00
  2.87912059e+00  8.82868195e+00  6.72185993e+00  4.10417318e+00
  3.72402120e+00  4.76707935e+00  8.69713497e+00  8.02846813e+00
 -5.91852479e-02  6.92536926e+00  9.99452686e+00  7.10508966e+00
  1.77003264e+00  5.62554789e+00  1.03404069e+00  4.70238781e+00
  9.31285954e+00  8.93695068e+00  2.82111669e+00  3.46559119e+00
  6.18987942e+00  9.39866257e+00  5.47782779e-01  2.72644186e+00
  8.94318962e+00  4.69057751e+00  1.03748589e+01  2.52786398e+00
  5.76243114e+00  3.48165631e+00  3.81163502e+00  3.76940107e+00
  4.03297091e+00  4.00298834e+00  8.04087162e+00  7.70173693e+00
  7.10223532e+00  3.21729660e+00  5.74228382e+00  6.87862539e+00
  7.01803017e+00  3.45543861e+00  7.26741600e+00  7.03988886e+00
  1.35023844e+00  8.91982746e+00  4.43680811e+00  5.25290489e+00
  3.51280975e+00  6.24143553e+00  6.52131414e+00  4.72280169e+00
  8.25355721e+00  6.25390244e+00  5.13515329e+00  4.87421942e+00
  7.67947769e+00  3.34088635e+00  2.31048179e+00  4.33013082e-01
  8.68751335e+00  9.47573662e+00  1.55903900e+00  3.07618022e+00
  1.50216174e+00  1.19446433e+00  9.29029846e+00  1.65662837e+00
  9.56382942e+00  9.47769403e-01  8.08623123e+00  5.85028315e+00
  4.43489981e+00  3.51404214e+00  7.59146261e+00  3.24519110e+00
  6.24453449e+00  3.84153080e+00  4.75549126e+00  8.96583271e+00
  5.54600143e+00  7.46122551e+00  6.96567345e+00  4.11713839e-01
  7.67649698e+00  2.08050108e+00  9.21236324e+00  1.41680741e+00
  3.03086996e+00  1.13182259e+00  4.03754902e+00  8.78156567e+00
  2.95456624e+00  1.61442590e+00  3.30749226e+00  8.14694023e+00
  1.37203860e+00  1.63373399e+00  6.45686090e-01  7.07791662e+00
  3.06980824e+00  4.66480160e+00  7.18863678e+00  3.41025472e+00
  7.26521921e+00  7.07599974e+00  2.82888842e+00  1.03278141e+01
  1.74131536e+00  2.78822184e+00  1.28855526e+00  3.68360829e+00
  5.39412928e+00  5.52329063e+00  8.01896572e+00  8.91389751e+00
  2.46595716e+00  6.16491985e+00  1.14002132e+00  3.73238707e+00
  3.28532362e+00  2.97972035e+00  4.97999954e+00  7.17574263e+00
  7.50538170e-01  1.02770720e+01  7.28148460e+00  2.06288123e+00
  9.35947418e+00  5.11205769e+00  9.92250729e+00  1.66801298e+00
  3.66859484e+00  3.06588221e+00  3.05286908e+00  5.87349463e+00
  9.89076328e+00  8.08929062e+00  6.18565559e+00  5.57329512e+00
  9.22900391e+00  3.96593451e+00  8.75203419e+00  8.35547829e+00
  2.17680025e+00  7.65000153e+00  1.08980224e-01  3.05595231e+00
  2.58785725e+00  5.23494005e+00  7.61446953e+00  4.45858717e-01
  4.63132048e+00  9.55903053e+00  1.96978843e+00  6.25351620e+00]
Epoch 1/1000
2023-09-10 01:42:53.352 
Epoch 1/1000 
	 loss: 455.7922, MinusLogProbMetric: 455.7922, val_loss: 417.7816, val_MinusLogProbMetric: 417.7816

Epoch 1: val_loss improved from inf to 417.78165, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 62s - loss: 455.7922 - MinusLogProbMetric: 455.7922 - val_loss: 417.7816 - val_MinusLogProbMetric: 417.7816 - lr: 3.3333e-04 - 62s/epoch - 318ms/step
Epoch 2/1000
2023-09-10 01:43:07.388 
Epoch 2/1000 
	 loss: 416.5770, MinusLogProbMetric: 416.5770, val_loss: 416.6342, val_MinusLogProbMetric: 416.6342

Epoch 2: val_loss improved from 417.78165 to 416.63416, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 416.5770 - MinusLogProbMetric: 416.5770 - val_loss: 416.6342 - val_MinusLogProbMetric: 416.6342 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 3/1000
2023-09-10 01:43:21.922 
Epoch 3/1000 
	 loss: 416.6759, MinusLogProbMetric: 416.6759, val_loss: 417.6314, val_MinusLogProbMetric: 417.6314

Epoch 3: val_loss did not improve from 416.63416
196/196 - 14s - loss: 416.6759 - MinusLogProbMetric: 416.6759 - val_loss: 417.6314 - val_MinusLogProbMetric: 417.6314 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 4/1000
2023-09-10 01:43:35.261 
Epoch 4/1000 
	 loss: 416.9101, MinusLogProbMetric: 416.9101, val_loss: 415.9729, val_MinusLogProbMetric: 415.9729

Epoch 4: val_loss improved from 416.63416 to 415.97290, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 416.9101 - MinusLogProbMetric: 416.9101 - val_loss: 415.9729 - val_MinusLogProbMetric: 415.9729 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 5/1000
2023-09-10 01:43:49.335 
Epoch 5/1000 
	 loss: 415.7343, MinusLogProbMetric: 415.7343, val_loss: 418.0446, val_MinusLogProbMetric: 418.0446

Epoch 5: val_loss did not improve from 415.97290
196/196 - 14s - loss: 415.7343 - MinusLogProbMetric: 415.7343 - val_loss: 418.0446 - val_MinusLogProbMetric: 418.0446 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 6/1000
2023-09-10 01:44:00.429 
Epoch 6/1000 
	 loss: 415.0691, MinusLogProbMetric: 415.0691, val_loss: 421.0824, val_MinusLogProbMetric: 421.0824

Epoch 6: val_loss did not improve from 415.97290
196/196 - 11s - loss: 415.0691 - MinusLogProbMetric: 415.0691 - val_loss: 421.0824 - val_MinusLogProbMetric: 421.0824 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 7/1000
2023-09-10 01:44:14.957 
Epoch 7/1000 
	 loss: 414.9576, MinusLogProbMetric: 414.9576, val_loss: 415.7206, val_MinusLogProbMetric: 415.7206

Epoch 7: val_loss improved from 415.97290 to 415.72061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 15s - loss: 414.9576 - MinusLogProbMetric: 414.9576 - val_loss: 415.7206 - val_MinusLogProbMetric: 415.7206 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 8/1000
2023-09-10 01:44:29.622 
Epoch 8/1000 
	 loss: 416.3599, MinusLogProbMetric: 416.3599, val_loss: 412.8113, val_MinusLogProbMetric: 412.8113

Epoch 8: val_loss improved from 415.72061 to 412.81134, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 416.3599 - MinusLogProbMetric: 416.3599 - val_loss: 412.8113 - val_MinusLogProbMetric: 412.8113 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 9/1000
2023-09-10 01:44:42.921 
Epoch 9/1000 
	 loss: 414.4996, MinusLogProbMetric: 414.4996, val_loss: 415.7885, val_MinusLogProbMetric: 415.7885

Epoch 9: val_loss did not improve from 412.81134
196/196 - 13s - loss: 414.4996 - MinusLogProbMetric: 414.4996 - val_loss: 415.7885 - val_MinusLogProbMetric: 415.7885 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 10/1000
2023-09-10 01:44:56.543 
Epoch 10/1000 
	 loss: 411.9749, MinusLogProbMetric: 411.9749, val_loss: 412.4135, val_MinusLogProbMetric: 412.4135

Epoch 10: val_loss improved from 412.81134 to 412.41345, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 411.9749 - MinusLogProbMetric: 411.9749 - val_loss: 412.4135 - val_MinusLogProbMetric: 412.4135 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 11/1000
2023-09-10 01:45:11.003 
Epoch 11/1000 
	 loss: 413.0648, MinusLogProbMetric: 413.0648, val_loss: 415.7642, val_MinusLogProbMetric: 415.7642

Epoch 11: val_loss did not improve from 412.41345
196/196 - 14s - loss: 413.0648 - MinusLogProbMetric: 413.0648 - val_loss: 415.7642 - val_MinusLogProbMetric: 415.7642 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 12/1000
2023-09-10 01:45:23.454 
Epoch 12/1000 
	 loss: 411.8488, MinusLogProbMetric: 411.8488, val_loss: 413.3050, val_MinusLogProbMetric: 413.3050

Epoch 12: val_loss did not improve from 412.41345
196/196 - 12s - loss: 411.8488 - MinusLogProbMetric: 411.8488 - val_loss: 413.3050 - val_MinusLogProbMetric: 413.3050 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 13/1000
2023-09-10 01:45:37.366 
Epoch 13/1000 
	 loss: 411.7868, MinusLogProbMetric: 411.7868, val_loss: 411.4720, val_MinusLogProbMetric: 411.4720

Epoch 13: val_loss improved from 412.41345 to 411.47205, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 411.7868 - MinusLogProbMetric: 411.7868 - val_loss: 411.4720 - val_MinusLogProbMetric: 411.4720 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 14/1000
2023-09-10 01:45:50.665 
Epoch 14/1000 
	 loss: 411.3921, MinusLogProbMetric: 411.3921, val_loss: 450.3929, val_MinusLogProbMetric: 450.3929

Epoch 14: val_loss did not improve from 411.47205
196/196 - 13s - loss: 411.3921 - MinusLogProbMetric: 411.3921 - val_loss: 450.3929 - val_MinusLogProbMetric: 450.3929 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 15/1000
2023-09-10 01:46:04.437 
Epoch 15/1000 
	 loss: 411.9289, MinusLogProbMetric: 411.9289, val_loss: 430.6670, val_MinusLogProbMetric: 430.6670

Epoch 15: val_loss did not improve from 411.47205
196/196 - 14s - loss: 411.9289 - MinusLogProbMetric: 411.9289 - val_loss: 430.6670 - val_MinusLogProbMetric: 430.6670 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 16/1000
2023-09-10 01:46:20.359 
Epoch 16/1000 
	 loss: 411.1080, MinusLogProbMetric: 411.1080, val_loss: 411.4781, val_MinusLogProbMetric: 411.4781

Epoch 16: val_loss did not improve from 411.47205
196/196 - 16s - loss: 411.1080 - MinusLogProbMetric: 411.1080 - val_loss: 411.4781 - val_MinusLogProbMetric: 411.4781 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 17/1000
2023-09-10 01:46:32.549 
Epoch 17/1000 
	 loss: 410.3178, MinusLogProbMetric: 410.3178, val_loss: 437.1787, val_MinusLogProbMetric: 437.1787

Epoch 17: val_loss did not improve from 411.47205
196/196 - 12s - loss: 410.3178 - MinusLogProbMetric: 410.3178 - val_loss: 437.1787 - val_MinusLogProbMetric: 437.1787 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 18/1000
2023-09-10 01:46:47.872 
Epoch 18/1000 
	 loss: 409.8506, MinusLogProbMetric: 409.8506, val_loss: 409.6371, val_MinusLogProbMetric: 409.6371

Epoch 18: val_loss improved from 411.47205 to 409.63715, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 16s - loss: 409.8506 - MinusLogProbMetric: 409.8506 - val_loss: 409.6371 - val_MinusLogProbMetric: 409.6371 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 19/1000
2023-09-10 01:47:04.008 
Epoch 19/1000 
	 loss: 409.2037, MinusLogProbMetric: 409.2037, val_loss: 409.8525, val_MinusLogProbMetric: 409.8525

Epoch 19: val_loss did not improve from 409.63715
196/196 - 16s - loss: 409.2037 - MinusLogProbMetric: 409.2037 - val_loss: 409.8525 - val_MinusLogProbMetric: 409.8525 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 20/1000
2023-09-10 01:47:17.126 
Epoch 20/1000 
	 loss: 409.1145, MinusLogProbMetric: 409.1145, val_loss: 409.0836, val_MinusLogProbMetric: 409.0836

Epoch 20: val_loss improved from 409.63715 to 409.08362, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 409.1145 - MinusLogProbMetric: 409.1145 - val_loss: 409.0836 - val_MinusLogProbMetric: 409.0836 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 21/1000
2023-09-10 01:47:35.791 
Epoch 21/1000 
	 loss: 409.9843, MinusLogProbMetric: 409.9843, val_loss: 416.2664, val_MinusLogProbMetric: 416.2664

Epoch 21: val_loss did not improve from 409.08362
196/196 - 18s - loss: 409.9843 - MinusLogProbMetric: 409.9843 - val_loss: 416.2664 - val_MinusLogProbMetric: 416.2664 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 22/1000
2023-09-10 01:47:51.589 
Epoch 22/1000 
	 loss: 408.2551, MinusLogProbMetric: 408.2551, val_loss: 408.3923, val_MinusLogProbMetric: 408.3923

Epoch 22: val_loss improved from 409.08362 to 408.39227, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 17s - loss: 408.2551 - MinusLogProbMetric: 408.2551 - val_loss: 408.3923 - val_MinusLogProbMetric: 408.3923 - lr: 3.3333e-04 - 17s/epoch - 84ms/step
Epoch 23/1000
2023-09-10 01:48:05.850 
Epoch 23/1000 
	 loss: 408.4386, MinusLogProbMetric: 408.4386, val_loss: 425.5332, val_MinusLogProbMetric: 425.5332

Epoch 23: val_loss did not improve from 408.39227
196/196 - 13s - loss: 408.4386 - MinusLogProbMetric: 408.4386 - val_loss: 425.5332 - val_MinusLogProbMetric: 425.5332 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 24/1000
2023-09-10 01:48:20.529 
Epoch 24/1000 
	 loss: 409.4403, MinusLogProbMetric: 409.4403, val_loss: 409.3588, val_MinusLogProbMetric: 409.3588

Epoch 24: val_loss did not improve from 408.39227
196/196 - 15s - loss: 409.4403 - MinusLogProbMetric: 409.4403 - val_loss: 409.3588 - val_MinusLogProbMetric: 409.3588 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 25/1000
2023-09-10 01:48:35.837 
Epoch 25/1000 
	 loss: 407.2572, MinusLogProbMetric: 407.2572, val_loss: 407.6711, val_MinusLogProbMetric: 407.6711

Epoch 25: val_loss improved from 408.39227 to 407.67114, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 16s - loss: 407.2572 - MinusLogProbMetric: 407.2572 - val_loss: 407.6711 - val_MinusLogProbMetric: 407.6711 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 26/1000
2023-09-10 01:48:52.790 
Epoch 26/1000 
	 loss: 407.8408, MinusLogProbMetric: 407.8408, val_loss: 407.3363, val_MinusLogProbMetric: 407.3363

Epoch 26: val_loss improved from 407.67114 to 407.33633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 17s - loss: 407.8408 - MinusLogProbMetric: 407.8408 - val_loss: 407.3363 - val_MinusLogProbMetric: 407.3363 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 27/1000
2023-09-10 01:49:08.748 
Epoch 27/1000 
	 loss: 412.5936, MinusLogProbMetric: 412.5936, val_loss: 418.0350, val_MinusLogProbMetric: 418.0350

Epoch 27: val_loss did not improve from 407.33633
196/196 - 15s - loss: 412.5936 - MinusLogProbMetric: 412.5936 - val_loss: 418.0350 - val_MinusLogProbMetric: 418.0350 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 28/1000
2023-09-10 01:49:23.168 
Epoch 28/1000 
	 loss: 407.4140, MinusLogProbMetric: 407.4140, val_loss: 407.0346, val_MinusLogProbMetric: 407.0346

Epoch 28: val_loss improved from 407.33633 to 407.03464, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 15s - loss: 407.4140 - MinusLogProbMetric: 407.4140 - val_loss: 407.0346 - val_MinusLogProbMetric: 407.0346 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 29/1000
2023-09-10 01:49:39.771 
Epoch 29/1000 
	 loss: 405.8123, MinusLogProbMetric: 405.8123, val_loss: 406.4285, val_MinusLogProbMetric: 406.4285

Epoch 29: val_loss improved from 407.03464 to 406.42853, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 17s - loss: 405.8123 - MinusLogProbMetric: 405.8123 - val_loss: 406.4285 - val_MinusLogProbMetric: 406.4285 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 30/1000
2023-09-10 01:49:54.775 
Epoch 30/1000 
	 loss: 407.3858, MinusLogProbMetric: 407.3858, val_loss: 406.0654, val_MinusLogProbMetric: 406.0654

Epoch 30: val_loss improved from 406.42853 to 406.06537, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 15s - loss: 407.3858 - MinusLogProbMetric: 407.3858 - val_loss: 406.0654 - val_MinusLogProbMetric: 406.0654 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 31/1000
2023-09-10 01:50:10.263 
Epoch 31/1000 
	 loss: 407.2279, MinusLogProbMetric: 407.2279, val_loss: 409.6241, val_MinusLogProbMetric: 409.6241

Epoch 31: val_loss did not improve from 406.06537
196/196 - 15s - loss: 407.2279 - MinusLogProbMetric: 407.2279 - val_loss: 409.6241 - val_MinusLogProbMetric: 409.6241 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 32/1000
2023-09-10 01:50:25.846 
Epoch 32/1000 
	 loss: 405.6585, MinusLogProbMetric: 405.6585, val_loss: 410.0506, val_MinusLogProbMetric: 410.0506

Epoch 32: val_loss did not improve from 406.06537
196/196 - 16s - loss: 405.6585 - MinusLogProbMetric: 405.6585 - val_loss: 410.0506 - val_MinusLogProbMetric: 410.0506 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 33/1000
2023-09-10 01:50:42.137 
Epoch 33/1000 
	 loss: 405.6920, MinusLogProbMetric: 405.6920, val_loss: 406.0508, val_MinusLogProbMetric: 406.0508

Epoch 33: val_loss improved from 406.06537 to 406.05078, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 17s - loss: 405.6920 - MinusLogProbMetric: 405.6920 - val_loss: 406.0508 - val_MinusLogProbMetric: 406.0508 - lr: 3.3333e-04 - 17s/epoch - 84ms/step
Epoch 34/1000
2023-09-10 01:50:58.792 
Epoch 34/1000 
	 loss: 406.1042, MinusLogProbMetric: 406.1042, val_loss: 405.2420, val_MinusLogProbMetric: 405.2420

Epoch 34: val_loss improved from 406.05078 to 405.24197, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 17s - loss: 406.1042 - MinusLogProbMetric: 406.1042 - val_loss: 405.2420 - val_MinusLogProbMetric: 405.2420 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 35/1000
2023-09-10 01:51:12.300 
Epoch 35/1000 
	 loss: 410.2558, MinusLogProbMetric: 410.2558, val_loss: 404.6923, val_MinusLogProbMetric: 404.6923

Epoch 35: val_loss improved from 405.24197 to 404.69232, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 410.2558 - MinusLogProbMetric: 410.2558 - val_loss: 404.6923 - val_MinusLogProbMetric: 404.6923 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 36/1000
2023-09-10 01:51:28.086 
Epoch 36/1000 
	 loss: 406.7480, MinusLogProbMetric: 406.7480, val_loss: 409.0651, val_MinusLogProbMetric: 409.0651

Epoch 36: val_loss did not improve from 404.69232
196/196 - 15s - loss: 406.7480 - MinusLogProbMetric: 406.7480 - val_loss: 409.0651 - val_MinusLogProbMetric: 409.0651 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 37/1000
2023-09-10 01:51:44.018 
Epoch 37/1000 
	 loss: 404.1837, MinusLogProbMetric: 404.1837, val_loss: 412.6639, val_MinusLogProbMetric: 412.6639

Epoch 37: val_loss did not improve from 404.69232
196/196 - 16s - loss: 404.1837 - MinusLogProbMetric: 404.1837 - val_loss: 412.6639 - val_MinusLogProbMetric: 412.6639 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 38/1000
2023-09-10 01:51:59.491 
Epoch 38/1000 
	 loss: 406.0502, MinusLogProbMetric: 406.0502, val_loss: 403.9335, val_MinusLogProbMetric: 403.9335

Epoch 38: val_loss improved from 404.69232 to 403.93350, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 16s - loss: 406.0502 - MinusLogProbMetric: 406.0502 - val_loss: 403.9335 - val_MinusLogProbMetric: 403.9335 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 39/1000
2023-09-10 01:52:15.309 
Epoch 39/1000 
	 loss: 404.8592, MinusLogProbMetric: 404.8592, val_loss: 403.5919, val_MinusLogProbMetric: 403.5919

Epoch 39: val_loss improved from 403.93350 to 403.59189, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 16s - loss: 404.8592 - MinusLogProbMetric: 404.8592 - val_loss: 403.5919 - val_MinusLogProbMetric: 403.5919 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 40/1000
2023-09-10 01:52:29.897 
Epoch 40/1000 
	 loss: 405.5146, MinusLogProbMetric: 405.5146, val_loss: 414.8776, val_MinusLogProbMetric: 414.8776

Epoch 40: val_loss did not improve from 403.59189
196/196 - 14s - loss: 405.5146 - MinusLogProbMetric: 405.5146 - val_loss: 414.8776 - val_MinusLogProbMetric: 414.8776 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 41/1000
2023-09-10 01:52:44.809 
Epoch 41/1000 
	 loss: 405.1422, MinusLogProbMetric: 405.1422, val_loss: 407.8386, val_MinusLogProbMetric: 407.8386

Epoch 41: val_loss did not improve from 403.59189
196/196 - 15s - loss: 405.1422 - MinusLogProbMetric: 405.1422 - val_loss: 407.8386 - val_MinusLogProbMetric: 407.8386 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 42/1000
2023-09-10 01:52:59.476 
Epoch 42/1000 
	 loss: 404.2561, MinusLogProbMetric: 404.2561, val_loss: 408.2466, val_MinusLogProbMetric: 408.2466

Epoch 42: val_loss did not improve from 403.59189
196/196 - 15s - loss: 404.2561 - MinusLogProbMetric: 404.2561 - val_loss: 408.2466 - val_MinusLogProbMetric: 408.2466 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 43/1000
2023-09-10 01:53:15.733 
Epoch 43/1000 
	 loss: 404.3352, MinusLogProbMetric: 404.3352, val_loss: 412.7315, val_MinusLogProbMetric: 412.7315

Epoch 43: val_loss did not improve from 403.59189
196/196 - 16s - loss: 404.3352 - MinusLogProbMetric: 404.3352 - val_loss: 412.7315 - val_MinusLogProbMetric: 412.7315 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 44/1000
2023-09-10 01:53:30.004 
Epoch 44/1000 
	 loss: 404.8466, MinusLogProbMetric: 404.8466, val_loss: 407.4458, val_MinusLogProbMetric: 407.4458

Epoch 44: val_loss did not improve from 403.59189
196/196 - 14s - loss: 404.8466 - MinusLogProbMetric: 404.8466 - val_loss: 407.4458 - val_MinusLogProbMetric: 407.4458 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 45/1000
2023-09-10 01:53:45.564 
Epoch 45/1000 
	 loss: 404.3866, MinusLogProbMetric: 404.3866, val_loss: 403.0557, val_MinusLogProbMetric: 403.0557

Epoch 45: val_loss improved from 403.59189 to 403.05573, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 16s - loss: 404.3866 - MinusLogProbMetric: 404.3866 - val_loss: 403.0557 - val_MinusLogProbMetric: 403.0557 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 46/1000
2023-09-10 01:53:59.010 
Epoch 46/1000 
	 loss: 403.1940, MinusLogProbMetric: 403.1940, val_loss: 404.3538, val_MinusLogProbMetric: 404.3538

Epoch 46: val_loss did not improve from 403.05573
196/196 - 13s - loss: 403.1940 - MinusLogProbMetric: 403.1940 - val_loss: 404.3538 - val_MinusLogProbMetric: 404.3538 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 47/1000
2023-09-10 01:54:13.832 
Epoch 47/1000 
	 loss: 404.1555, MinusLogProbMetric: 404.1555, val_loss: 405.6897, val_MinusLogProbMetric: 405.6897

Epoch 47: val_loss did not improve from 403.05573
196/196 - 15s - loss: 404.1555 - MinusLogProbMetric: 404.1555 - val_loss: 405.6897 - val_MinusLogProbMetric: 405.6897 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 48/1000
2023-09-10 01:54:29.262 
Epoch 48/1000 
	 loss: 403.8818, MinusLogProbMetric: 403.8818, val_loss: 404.9084, val_MinusLogProbMetric: 404.9084

Epoch 48: val_loss did not improve from 403.05573
196/196 - 15s - loss: 403.8818 - MinusLogProbMetric: 403.8818 - val_loss: 404.9084 - val_MinusLogProbMetric: 404.9084 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 49/1000
2023-09-10 01:54:44.862 
Epoch 49/1000 
	 loss: 403.1625, MinusLogProbMetric: 403.1625, val_loss: 404.2158, val_MinusLogProbMetric: 404.2158

Epoch 49: val_loss did not improve from 403.05573
196/196 - 16s - loss: 403.1625 - MinusLogProbMetric: 403.1625 - val_loss: 404.2158 - val_MinusLogProbMetric: 404.2158 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 50/1000
2023-09-10 01:54:57.356 
Epoch 50/1000 
	 loss: 403.0935, MinusLogProbMetric: 403.0935, val_loss: 402.6415, val_MinusLogProbMetric: 402.6415

Epoch 50: val_loss improved from 403.05573 to 402.64151, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 403.0935 - MinusLogProbMetric: 403.0935 - val_loss: 402.6415 - val_MinusLogProbMetric: 402.6415 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 51/1000
2023-09-10 01:55:11.791 
Epoch 51/1000 
	 loss: 404.0735, MinusLogProbMetric: 404.0735, val_loss: 409.9759, val_MinusLogProbMetric: 409.9759

Epoch 51: val_loss did not improve from 402.64151
196/196 - 14s - loss: 404.0735 - MinusLogProbMetric: 404.0735 - val_loss: 409.9759 - val_MinusLogProbMetric: 409.9759 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 52/1000
2023-09-10 01:55:26.130 
Epoch 52/1000 
	 loss: 402.7028, MinusLogProbMetric: 402.7028, val_loss: 407.7084, val_MinusLogProbMetric: 407.7084

Epoch 52: val_loss did not improve from 402.64151
196/196 - 14s - loss: 402.7028 - MinusLogProbMetric: 402.7028 - val_loss: 407.7084 - val_MinusLogProbMetric: 407.7084 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 53/1000
2023-09-10 01:55:40.127 
Epoch 53/1000 
	 loss: 402.8647, MinusLogProbMetric: 402.8647, val_loss: 402.7993, val_MinusLogProbMetric: 402.7993

Epoch 53: val_loss did not improve from 402.64151
196/196 - 14s - loss: 402.8647 - MinusLogProbMetric: 402.8647 - val_loss: 402.7993 - val_MinusLogProbMetric: 402.7993 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 54/1000
2023-09-10 01:55:55.458 
Epoch 54/1000 
	 loss: 403.0584, MinusLogProbMetric: 403.0584, val_loss: 401.5619, val_MinusLogProbMetric: 401.5619

Epoch 54: val_loss improved from 402.64151 to 401.56186, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 16s - loss: 403.0584 - MinusLogProbMetric: 403.0584 - val_loss: 401.5619 - val_MinusLogProbMetric: 401.5619 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 55/1000
2023-09-10 01:56:09.816 
Epoch 55/1000 
	 loss: 402.5757, MinusLogProbMetric: 402.5757, val_loss: 402.5962, val_MinusLogProbMetric: 402.5962

Epoch 55: val_loss did not improve from 401.56186
196/196 - 14s - loss: 402.5757 - MinusLogProbMetric: 402.5757 - val_loss: 402.5962 - val_MinusLogProbMetric: 402.5962 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 56/1000
2023-09-10 01:56:22.350 
Epoch 56/1000 
	 loss: 402.5604, MinusLogProbMetric: 402.5604, val_loss: 402.8929, val_MinusLogProbMetric: 402.8929

Epoch 56: val_loss did not improve from 401.56186
196/196 - 13s - loss: 402.5604 - MinusLogProbMetric: 402.5604 - val_loss: 402.8929 - val_MinusLogProbMetric: 402.8929 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 57/1000
2023-09-10 01:56:37.127 
Epoch 57/1000 
	 loss: 403.3792, MinusLogProbMetric: 403.3792, val_loss: 434.3627, val_MinusLogProbMetric: 434.3627

Epoch 57: val_loss did not improve from 401.56186
196/196 - 15s - loss: 403.3792 - MinusLogProbMetric: 403.3792 - val_loss: 434.3627 - val_MinusLogProbMetric: 434.3627 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 58/1000
2023-09-10 01:56:52.977 
Epoch 58/1000 
	 loss: 402.0943, MinusLogProbMetric: 402.0943, val_loss: 402.8517, val_MinusLogProbMetric: 402.8517

Epoch 58: val_loss did not improve from 401.56186
196/196 - 16s - loss: 402.0943 - MinusLogProbMetric: 402.0943 - val_loss: 402.8517 - val_MinusLogProbMetric: 402.8517 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 59/1000
2023-09-10 01:57:07.701 
Epoch 59/1000 
	 loss: 402.2931, MinusLogProbMetric: 402.2931, val_loss: 403.7169, val_MinusLogProbMetric: 403.7169

Epoch 59: val_loss did not improve from 401.56186
196/196 - 15s - loss: 402.2931 - MinusLogProbMetric: 402.2931 - val_loss: 403.7169 - val_MinusLogProbMetric: 403.7169 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 60/1000
2023-09-10 01:57:21.619 
Epoch 60/1000 
	 loss: 402.2730, MinusLogProbMetric: 402.2730, val_loss: 402.3175, val_MinusLogProbMetric: 402.3175

Epoch 60: val_loss did not improve from 401.56186
196/196 - 14s - loss: 402.2730 - MinusLogProbMetric: 402.2730 - val_loss: 402.3175 - val_MinusLogProbMetric: 402.3175 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 61/1000
2023-09-10 01:57:35.651 
Epoch 61/1000 
	 loss: 403.6091, MinusLogProbMetric: 403.6091, val_loss: 405.4525, val_MinusLogProbMetric: 405.4525

Epoch 61: val_loss did not improve from 401.56186
196/196 - 14s - loss: 403.6091 - MinusLogProbMetric: 403.6091 - val_loss: 405.4525 - val_MinusLogProbMetric: 405.4525 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 62/1000
2023-09-10 01:57:48.568 
Epoch 62/1000 
	 loss: 401.1463, MinusLogProbMetric: 401.1463, val_loss: 401.8904, val_MinusLogProbMetric: 401.8904

Epoch 62: val_loss did not improve from 401.56186
196/196 - 13s - loss: 401.1463 - MinusLogProbMetric: 401.1463 - val_loss: 401.8904 - val_MinusLogProbMetric: 401.8904 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 63/1000
2023-09-10 01:58:01.846 
Epoch 63/1000 
	 loss: 401.6191, MinusLogProbMetric: 401.6191, val_loss: 406.7569, val_MinusLogProbMetric: 406.7569

Epoch 63: val_loss did not improve from 401.56186
196/196 - 13s - loss: 401.6191 - MinusLogProbMetric: 401.6191 - val_loss: 406.7569 - val_MinusLogProbMetric: 406.7569 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 64/1000
2023-09-10 01:58:10.924 
Epoch 64/1000 
	 loss: 402.0085, MinusLogProbMetric: 402.0085, val_loss: 402.5419, val_MinusLogProbMetric: 402.5419

Epoch 64: val_loss did not improve from 401.56186
196/196 - 9s - loss: 402.0085 - MinusLogProbMetric: 402.0085 - val_loss: 402.5419 - val_MinusLogProbMetric: 402.5419 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 65/1000
2023-09-10 01:58:19.228 
Epoch 65/1000 
	 loss: 401.2379, MinusLogProbMetric: 401.2379, val_loss: 402.7199, val_MinusLogProbMetric: 402.7199

Epoch 65: val_loss did not improve from 401.56186
196/196 - 8s - loss: 401.2379 - MinusLogProbMetric: 401.2379 - val_loss: 402.7199 - val_MinusLogProbMetric: 402.7199 - lr: 3.3333e-04 - 8s/epoch - 42ms/step
Epoch 66/1000
2023-09-10 01:58:31.329 
Epoch 66/1000 
	 loss: 402.9082, MinusLogProbMetric: 402.9082, val_loss: 402.8498, val_MinusLogProbMetric: 402.8498

Epoch 66: val_loss did not improve from 401.56186
196/196 - 12s - loss: 402.9082 - MinusLogProbMetric: 402.9082 - val_loss: 402.8498 - val_MinusLogProbMetric: 402.8498 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 67/1000
2023-09-10 01:58:42.207 
Epoch 67/1000 
	 loss: 400.9198, MinusLogProbMetric: 400.9198, val_loss: 402.4592, val_MinusLogProbMetric: 402.4592

Epoch 67: val_loss did not improve from 401.56186
196/196 - 11s - loss: 400.9198 - MinusLogProbMetric: 400.9198 - val_loss: 402.4592 - val_MinusLogProbMetric: 402.4592 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 68/1000
2023-09-10 01:58:53.728 
Epoch 68/1000 
	 loss: 401.3539, MinusLogProbMetric: 401.3539, val_loss: 402.9422, val_MinusLogProbMetric: 402.9422

Epoch 68: val_loss did not improve from 401.56186
196/196 - 12s - loss: 401.3539 - MinusLogProbMetric: 401.3539 - val_loss: 402.9422 - val_MinusLogProbMetric: 402.9422 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 69/1000
2023-09-10 01:59:05.475 
Epoch 69/1000 
	 loss: 400.9737, MinusLogProbMetric: 400.9737, val_loss: 401.1770, val_MinusLogProbMetric: 401.1770

Epoch 69: val_loss improved from 401.56186 to 401.17700, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 400.9737 - MinusLogProbMetric: 400.9737 - val_loss: 401.1770 - val_MinusLogProbMetric: 401.1770 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 70/1000
2023-09-10 01:59:19.809 
Epoch 70/1000 
	 loss: 401.4675, MinusLogProbMetric: 401.4675, val_loss: 411.3803, val_MinusLogProbMetric: 411.3803

Epoch 70: val_loss did not improve from 401.17700
196/196 - 13s - loss: 401.4675 - MinusLogProbMetric: 401.4675 - val_loss: 411.3803 - val_MinusLogProbMetric: 411.3803 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 71/1000
2023-09-10 01:59:33.688 
Epoch 71/1000 
	 loss: 400.7793, MinusLogProbMetric: 400.7793, val_loss: 403.8233, val_MinusLogProbMetric: 403.8233

Epoch 71: val_loss did not improve from 401.17700
196/196 - 14s - loss: 400.7793 - MinusLogProbMetric: 400.7793 - val_loss: 403.8233 - val_MinusLogProbMetric: 403.8233 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 72/1000
2023-09-10 01:59:44.962 
Epoch 72/1000 
	 loss: 401.6156, MinusLogProbMetric: 401.6156, val_loss: 403.1719, val_MinusLogProbMetric: 403.1719

Epoch 72: val_loss did not improve from 401.17700
196/196 - 11s - loss: 401.6156 - MinusLogProbMetric: 401.6156 - val_loss: 403.1719 - val_MinusLogProbMetric: 403.1719 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 73/1000
2023-09-10 01:59:59.123 
Epoch 73/1000 
	 loss: 400.8539, MinusLogProbMetric: 400.8539, val_loss: 404.4944, val_MinusLogProbMetric: 404.4944

Epoch 73: val_loss did not improve from 401.17700
196/196 - 14s - loss: 400.8539 - MinusLogProbMetric: 400.8539 - val_loss: 404.4944 - val_MinusLogProbMetric: 404.4944 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 74/1000
2023-09-10 02:00:09.376 
Epoch 74/1000 
	 loss: 400.7962, MinusLogProbMetric: 400.7962, val_loss: 401.3455, val_MinusLogProbMetric: 401.3455

Epoch 74: val_loss did not improve from 401.17700
196/196 - 10s - loss: 400.7962 - MinusLogProbMetric: 400.7962 - val_loss: 401.3455 - val_MinusLogProbMetric: 401.3455 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 75/1000
2023-09-10 02:00:21.010 
Epoch 75/1000 
	 loss: 400.5220, MinusLogProbMetric: 400.5220, val_loss: 403.1057, val_MinusLogProbMetric: 403.1057

Epoch 75: val_loss did not improve from 401.17700
196/196 - 12s - loss: 400.5220 - MinusLogProbMetric: 400.5220 - val_loss: 403.1057 - val_MinusLogProbMetric: 403.1057 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 76/1000
2023-09-10 02:00:32.973 
Epoch 76/1000 
	 loss: 400.0113, MinusLogProbMetric: 400.0113, val_loss: 401.9318, val_MinusLogProbMetric: 401.9318

Epoch 76: val_loss did not improve from 401.17700
196/196 - 12s - loss: 400.0113 - MinusLogProbMetric: 400.0113 - val_loss: 401.9318 - val_MinusLogProbMetric: 401.9318 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 77/1000
2023-09-10 02:00:47.784 
Epoch 77/1000 
	 loss: 400.6722, MinusLogProbMetric: 400.6722, val_loss: 403.7193, val_MinusLogProbMetric: 403.7193

Epoch 77: val_loss did not improve from 401.17700
196/196 - 15s - loss: 400.6722 - MinusLogProbMetric: 400.6722 - val_loss: 403.7193 - val_MinusLogProbMetric: 403.7193 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 78/1000
2023-09-10 02:01:01.667 
Epoch 78/1000 
	 loss: 400.3521, MinusLogProbMetric: 400.3521, val_loss: 402.8950, val_MinusLogProbMetric: 402.8950

Epoch 78: val_loss did not improve from 401.17700
196/196 - 14s - loss: 400.3521 - MinusLogProbMetric: 400.3521 - val_loss: 402.8950 - val_MinusLogProbMetric: 402.8950 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 79/1000
2023-09-10 02:01:13.101 
Epoch 79/1000 
	 loss: 400.5802, MinusLogProbMetric: 400.5802, val_loss: 401.5811, val_MinusLogProbMetric: 401.5811

Epoch 79: val_loss did not improve from 401.17700
196/196 - 11s - loss: 400.5802 - MinusLogProbMetric: 400.5802 - val_loss: 401.5811 - val_MinusLogProbMetric: 401.5811 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 80/1000
2023-09-10 02:01:26.903 
Epoch 80/1000 
	 loss: 399.9710, MinusLogProbMetric: 399.9710, val_loss: 400.7977, val_MinusLogProbMetric: 400.7977

Epoch 80: val_loss improved from 401.17700 to 400.79770, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 399.9710 - MinusLogProbMetric: 399.9710 - val_loss: 400.7977 - val_MinusLogProbMetric: 400.7977 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 81/1000
2023-09-10 02:01:39.892 
Epoch 81/1000 
	 loss: 399.5712, MinusLogProbMetric: 399.5712, val_loss: 402.1642, val_MinusLogProbMetric: 402.1642

Epoch 81: val_loss did not improve from 400.79770
196/196 - 13s - loss: 399.5712 - MinusLogProbMetric: 399.5712 - val_loss: 402.1642 - val_MinusLogProbMetric: 402.1642 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 82/1000
2023-09-10 02:01:53.233 
Epoch 82/1000 
	 loss: 400.1899, MinusLogProbMetric: 400.1899, val_loss: 401.4501, val_MinusLogProbMetric: 401.4501

Epoch 82: val_loss did not improve from 400.79770
196/196 - 13s - loss: 400.1899 - MinusLogProbMetric: 400.1899 - val_loss: 401.4501 - val_MinusLogProbMetric: 401.4501 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 83/1000
2023-09-10 02:02:05.328 
Epoch 83/1000 
	 loss: 402.8208, MinusLogProbMetric: 402.8208, val_loss: 400.7383, val_MinusLogProbMetric: 400.7383

Epoch 83: val_loss improved from 400.79770 to 400.73831, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 402.8208 - MinusLogProbMetric: 402.8208 - val_loss: 400.7383 - val_MinusLogProbMetric: 400.7383 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 84/1000
2023-09-10 02:02:17.908 
Epoch 84/1000 
	 loss: 399.4008, MinusLogProbMetric: 399.4008, val_loss: 401.1267, val_MinusLogProbMetric: 401.1267

Epoch 84: val_loss did not improve from 400.73831
196/196 - 12s - loss: 399.4008 - MinusLogProbMetric: 399.4008 - val_loss: 401.1267 - val_MinusLogProbMetric: 401.1267 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 85/1000
2023-09-10 02:02:29.721 
Epoch 85/1000 
	 loss: 400.4077, MinusLogProbMetric: 400.4077, val_loss: 402.2025, val_MinusLogProbMetric: 402.2025

Epoch 85: val_loss did not improve from 400.73831
196/196 - 12s - loss: 400.4077 - MinusLogProbMetric: 400.4077 - val_loss: 402.2025 - val_MinusLogProbMetric: 402.2025 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 86/1000
2023-09-10 02:02:43.446 
Epoch 86/1000 
	 loss: 399.5616, MinusLogProbMetric: 399.5616, val_loss: 401.2381, val_MinusLogProbMetric: 401.2381

Epoch 86: val_loss did not improve from 400.73831
196/196 - 14s - loss: 399.5616 - MinusLogProbMetric: 399.5616 - val_loss: 401.2381 - val_MinusLogProbMetric: 401.2381 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 87/1000
2023-09-10 02:02:54.602 
Epoch 87/1000 
	 loss: 399.1472, MinusLogProbMetric: 399.1472, val_loss: 400.0675, val_MinusLogProbMetric: 400.0675

Epoch 87: val_loss improved from 400.73831 to 400.06750, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 399.1472 - MinusLogProbMetric: 399.1472 - val_loss: 400.0675 - val_MinusLogProbMetric: 400.0675 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 88/1000
2023-09-10 02:03:07.088 
Epoch 88/1000 
	 loss: 399.6707, MinusLogProbMetric: 399.6707, val_loss: 400.7272, val_MinusLogProbMetric: 400.7272

Epoch 88: val_loss did not improve from 400.06750
196/196 - 12s - loss: 399.6707 - MinusLogProbMetric: 399.6707 - val_loss: 400.7272 - val_MinusLogProbMetric: 400.7272 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 89/1000
2023-09-10 02:03:17.713 
Epoch 89/1000 
	 loss: 399.3549, MinusLogProbMetric: 399.3549, val_loss: 404.7025, val_MinusLogProbMetric: 404.7025

Epoch 89: val_loss did not improve from 400.06750
196/196 - 11s - loss: 399.3549 - MinusLogProbMetric: 399.3549 - val_loss: 404.7025 - val_MinusLogProbMetric: 404.7025 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 90/1000
2023-09-10 02:03:30.396 
Epoch 90/1000 
	 loss: 399.3389, MinusLogProbMetric: 399.3389, val_loss: 403.0757, val_MinusLogProbMetric: 403.0757

Epoch 90: val_loss did not improve from 400.06750
196/196 - 13s - loss: 399.3389 - MinusLogProbMetric: 399.3389 - val_loss: 403.0757 - val_MinusLogProbMetric: 403.0757 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 91/1000
2023-09-10 02:03:40.601 
Epoch 91/1000 
	 loss: 399.1161, MinusLogProbMetric: 399.1161, val_loss: 404.7287, val_MinusLogProbMetric: 404.7287

Epoch 91: val_loss did not improve from 400.06750
196/196 - 10s - loss: 399.1161 - MinusLogProbMetric: 399.1161 - val_loss: 404.7287 - val_MinusLogProbMetric: 404.7287 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 92/1000
2023-09-10 02:03:54.705 
Epoch 92/1000 
	 loss: 400.3197, MinusLogProbMetric: 400.3197, val_loss: 406.5847, val_MinusLogProbMetric: 406.5847

Epoch 92: val_loss did not improve from 400.06750
196/196 - 14s - loss: 400.3197 - MinusLogProbMetric: 400.3197 - val_loss: 406.5847 - val_MinusLogProbMetric: 406.5847 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 93/1000
2023-09-10 02:04:05.744 
Epoch 93/1000 
	 loss: 399.2550, MinusLogProbMetric: 399.2550, val_loss: 400.7401, val_MinusLogProbMetric: 400.7401

Epoch 93: val_loss did not improve from 400.06750
196/196 - 11s - loss: 399.2550 - MinusLogProbMetric: 399.2550 - val_loss: 400.7401 - val_MinusLogProbMetric: 400.7401 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 94/1000
2023-09-10 02:04:17.426 
Epoch 94/1000 
	 loss: 398.7892, MinusLogProbMetric: 398.7892, val_loss: 400.9304, val_MinusLogProbMetric: 400.9304

Epoch 94: val_loss did not improve from 400.06750
196/196 - 12s - loss: 398.7892 - MinusLogProbMetric: 398.7892 - val_loss: 400.9304 - val_MinusLogProbMetric: 400.9304 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 95/1000
2023-09-10 02:04:27.361 
Epoch 95/1000 
	 loss: 399.0440, MinusLogProbMetric: 399.0440, val_loss: 405.6250, val_MinusLogProbMetric: 405.6250

Epoch 95: val_loss did not improve from 400.06750
196/196 - 10s - loss: 399.0440 - MinusLogProbMetric: 399.0440 - val_loss: 405.6250 - val_MinusLogProbMetric: 405.6250 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 96/1000
2023-09-10 02:04:38.878 
Epoch 96/1000 
	 loss: 398.8195, MinusLogProbMetric: 398.8195, val_loss: 401.6005, val_MinusLogProbMetric: 401.6005

Epoch 96: val_loss did not improve from 400.06750
196/196 - 12s - loss: 398.8195 - MinusLogProbMetric: 398.8195 - val_loss: 401.6005 - val_MinusLogProbMetric: 401.6005 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 97/1000
2023-09-10 02:04:48.369 
Epoch 97/1000 
	 loss: 399.1646, MinusLogProbMetric: 399.1646, val_loss: 398.9169, val_MinusLogProbMetric: 398.9169

Epoch 97: val_loss improved from 400.06750 to 398.91693, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 10s - loss: 399.1646 - MinusLogProbMetric: 399.1646 - val_loss: 398.9169 - val_MinusLogProbMetric: 398.9169 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 98/1000
2023-09-10 02:04:59.297 
Epoch 98/1000 
	 loss: 398.8631, MinusLogProbMetric: 398.8631, val_loss: 402.6097, val_MinusLogProbMetric: 402.6097

Epoch 98: val_loss did not improve from 398.91693
196/196 - 10s - loss: 398.8631 - MinusLogProbMetric: 398.8631 - val_loss: 402.6097 - val_MinusLogProbMetric: 402.6097 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 99/1000
2023-09-10 02:05:13.020 
Epoch 99/1000 
	 loss: 398.2518, MinusLogProbMetric: 398.2518, val_loss: 399.5584, val_MinusLogProbMetric: 399.5584

Epoch 99: val_loss did not improve from 398.91693
196/196 - 14s - loss: 398.2518 - MinusLogProbMetric: 398.2518 - val_loss: 399.5584 - val_MinusLogProbMetric: 399.5584 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 100/1000
2023-09-10 02:05:27.290 
Epoch 100/1000 
	 loss: 400.8473, MinusLogProbMetric: 400.8473, val_loss: 399.9538, val_MinusLogProbMetric: 399.9538

Epoch 100: val_loss did not improve from 398.91693
196/196 - 14s - loss: 400.8473 - MinusLogProbMetric: 400.8473 - val_loss: 399.9538 - val_MinusLogProbMetric: 399.9538 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 101/1000
2023-09-10 02:05:40.094 
Epoch 101/1000 
	 loss: 398.6971, MinusLogProbMetric: 398.6971, val_loss: 400.7438, val_MinusLogProbMetric: 400.7438

Epoch 101: val_loss did not improve from 398.91693
196/196 - 13s - loss: 398.6971 - MinusLogProbMetric: 398.6971 - val_loss: 400.7438 - val_MinusLogProbMetric: 400.7438 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 102/1000
2023-09-10 02:05:53.725 
Epoch 102/1000 
	 loss: 398.2473, MinusLogProbMetric: 398.2473, val_loss: 399.9051, val_MinusLogProbMetric: 399.9051

Epoch 102: val_loss did not improve from 398.91693
196/196 - 14s - loss: 398.2473 - MinusLogProbMetric: 398.2473 - val_loss: 399.9051 - val_MinusLogProbMetric: 399.9051 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 103/1000
2023-09-10 02:06:07.781 
Epoch 103/1000 
	 loss: 399.2075, MinusLogProbMetric: 399.2075, val_loss: 399.2969, val_MinusLogProbMetric: 399.2969

Epoch 103: val_loss did not improve from 398.91693
196/196 - 14s - loss: 399.2075 - MinusLogProbMetric: 399.2075 - val_loss: 399.2969 - val_MinusLogProbMetric: 399.2969 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 104/1000
2023-09-10 02:06:19.064 
Epoch 104/1000 
	 loss: 398.1166, MinusLogProbMetric: 398.1166, val_loss: 400.9612, val_MinusLogProbMetric: 400.9612

Epoch 104: val_loss did not improve from 398.91693
196/196 - 11s - loss: 398.1166 - MinusLogProbMetric: 398.1166 - val_loss: 400.9612 - val_MinusLogProbMetric: 400.9612 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 105/1000
2023-09-10 02:06:31.669 
Epoch 105/1000 
	 loss: 398.5302, MinusLogProbMetric: 398.5302, val_loss: 400.5114, val_MinusLogProbMetric: 400.5114

Epoch 105: val_loss did not improve from 398.91693
196/196 - 13s - loss: 398.5302 - MinusLogProbMetric: 398.5302 - val_loss: 400.5114 - val_MinusLogProbMetric: 400.5114 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 106/1000
2023-09-10 02:06:43.109 
Epoch 106/1000 
	 loss: 397.9803, MinusLogProbMetric: 397.9803, val_loss: 401.8083, val_MinusLogProbMetric: 401.8083

Epoch 106: val_loss did not improve from 398.91693
196/196 - 11s - loss: 397.9803 - MinusLogProbMetric: 397.9803 - val_loss: 401.8083 - val_MinusLogProbMetric: 401.8083 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 107/1000
2023-09-10 02:06:54.964 
Epoch 107/1000 
	 loss: 397.9744, MinusLogProbMetric: 397.9744, val_loss: 401.2458, val_MinusLogProbMetric: 401.2458

Epoch 107: val_loss did not improve from 398.91693
196/196 - 12s - loss: 397.9744 - MinusLogProbMetric: 397.9744 - val_loss: 401.2458 - val_MinusLogProbMetric: 401.2458 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 108/1000
2023-09-10 02:07:06.361 
Epoch 108/1000 
	 loss: 398.7774, MinusLogProbMetric: 398.7774, val_loss: 398.6802, val_MinusLogProbMetric: 398.6802

Epoch 108: val_loss improved from 398.91693 to 398.68021, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 398.7774 - MinusLogProbMetric: 398.7774 - val_loss: 398.6802 - val_MinusLogProbMetric: 398.6802 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 109/1000
2023-09-10 02:07:21.357 
Epoch 109/1000 
	 loss: 397.9577, MinusLogProbMetric: 397.9577, val_loss: 400.5782, val_MinusLogProbMetric: 400.5782

Epoch 109: val_loss did not improve from 398.68021
196/196 - 14s - loss: 397.9577 - MinusLogProbMetric: 397.9577 - val_loss: 400.5782 - val_MinusLogProbMetric: 400.5782 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 110/1000
2023-09-10 02:07:32.868 
Epoch 110/1000 
	 loss: 398.0527, MinusLogProbMetric: 398.0527, val_loss: 400.6654, val_MinusLogProbMetric: 400.6654

Epoch 110: val_loss did not improve from 398.68021
196/196 - 12s - loss: 398.0527 - MinusLogProbMetric: 398.0527 - val_loss: 400.6654 - val_MinusLogProbMetric: 400.6654 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 111/1000
2023-09-10 02:07:46.590 
Epoch 111/1000 
	 loss: 400.3141, MinusLogProbMetric: 400.3141, val_loss: 399.5235, val_MinusLogProbMetric: 399.5235

Epoch 111: val_loss did not improve from 398.68021
196/196 - 14s - loss: 400.3141 - MinusLogProbMetric: 400.3141 - val_loss: 399.5235 - val_MinusLogProbMetric: 399.5235 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 112/1000
2023-09-10 02:07:57.364 
Epoch 112/1000 
	 loss: 398.1316, MinusLogProbMetric: 398.1316, val_loss: 398.8798, val_MinusLogProbMetric: 398.8798

Epoch 112: val_loss did not improve from 398.68021
196/196 - 11s - loss: 398.1316 - MinusLogProbMetric: 398.1316 - val_loss: 398.8798 - val_MinusLogProbMetric: 398.8798 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 113/1000
2023-09-10 02:08:09.628 
Epoch 113/1000 
	 loss: 397.2967, MinusLogProbMetric: 397.2967, val_loss: 400.3554, val_MinusLogProbMetric: 400.3554

Epoch 113: val_loss did not improve from 398.68021
196/196 - 12s - loss: 397.2967 - MinusLogProbMetric: 397.2967 - val_loss: 400.3554 - val_MinusLogProbMetric: 400.3554 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 114/1000
2023-09-10 02:08:22.470 
Epoch 114/1000 
	 loss: 398.0593, MinusLogProbMetric: 398.0593, val_loss: 402.6431, val_MinusLogProbMetric: 402.6431

Epoch 114: val_loss did not improve from 398.68021
196/196 - 13s - loss: 398.0593 - MinusLogProbMetric: 398.0593 - val_loss: 402.6431 - val_MinusLogProbMetric: 402.6431 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 115/1000
2023-09-10 02:08:36.369 
Epoch 115/1000 
	 loss: 397.4709, MinusLogProbMetric: 397.4709, val_loss: 404.5939, val_MinusLogProbMetric: 404.5939

Epoch 115: val_loss did not improve from 398.68021
196/196 - 14s - loss: 397.4709 - MinusLogProbMetric: 397.4709 - val_loss: 404.5939 - val_MinusLogProbMetric: 404.5939 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 116/1000
2023-09-10 02:08:46.768 
Epoch 116/1000 
	 loss: 397.7385, MinusLogProbMetric: 397.7385, val_loss: 400.5577, val_MinusLogProbMetric: 400.5577

Epoch 116: val_loss did not improve from 398.68021
196/196 - 10s - loss: 397.7385 - MinusLogProbMetric: 397.7385 - val_loss: 400.5577 - val_MinusLogProbMetric: 400.5577 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 117/1000
2023-09-10 02:08:59.512 
Epoch 117/1000 
	 loss: 397.6314, MinusLogProbMetric: 397.6314, val_loss: 399.7164, val_MinusLogProbMetric: 399.7164

Epoch 117: val_loss did not improve from 398.68021
196/196 - 13s - loss: 397.6314 - MinusLogProbMetric: 397.6314 - val_loss: 399.7164 - val_MinusLogProbMetric: 399.7164 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 118/1000
2023-09-10 02:09:09.728 
Epoch 118/1000 
	 loss: 397.8087, MinusLogProbMetric: 397.8087, val_loss: 402.8433, val_MinusLogProbMetric: 402.8433

Epoch 118: val_loss did not improve from 398.68021
196/196 - 10s - loss: 397.8087 - MinusLogProbMetric: 397.8087 - val_loss: 402.8433 - val_MinusLogProbMetric: 402.8433 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 119/1000
2023-09-10 02:09:21.382 
Epoch 119/1000 
	 loss: 397.3946, MinusLogProbMetric: 397.3946, val_loss: 405.7696, val_MinusLogProbMetric: 405.7696

Epoch 119: val_loss did not improve from 398.68021
196/196 - 12s - loss: 397.3946 - MinusLogProbMetric: 397.3946 - val_loss: 405.7696 - val_MinusLogProbMetric: 405.7696 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 120/1000
2023-09-10 02:09:34.747 
Epoch 120/1000 
	 loss: 397.2580, MinusLogProbMetric: 397.2580, val_loss: 402.0387, val_MinusLogProbMetric: 402.0387

Epoch 120: val_loss did not improve from 398.68021
196/196 - 13s - loss: 397.2580 - MinusLogProbMetric: 397.2580 - val_loss: 402.0387 - val_MinusLogProbMetric: 402.0387 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 121/1000
2023-09-10 02:09:49.280 
Epoch 121/1000 
	 loss: 397.7022, MinusLogProbMetric: 397.7022, val_loss: 403.3048, val_MinusLogProbMetric: 403.3048

Epoch 121: val_loss did not improve from 398.68021
196/196 - 15s - loss: 397.7022 - MinusLogProbMetric: 397.7022 - val_loss: 403.3048 - val_MinusLogProbMetric: 403.3048 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 122/1000
2023-09-10 02:10:01.570 
Epoch 122/1000 
	 loss: 398.4986, MinusLogProbMetric: 398.4986, val_loss: 410.1861, val_MinusLogProbMetric: 410.1861

Epoch 122: val_loss did not improve from 398.68021
196/196 - 12s - loss: 398.4986 - MinusLogProbMetric: 398.4986 - val_loss: 410.1861 - val_MinusLogProbMetric: 410.1861 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 123/1000
2023-09-10 02:10:15.336 
Epoch 123/1000 
	 loss: 397.2998, MinusLogProbMetric: 397.2998, val_loss: 400.5799, val_MinusLogProbMetric: 400.5799

Epoch 123: val_loss did not improve from 398.68021
196/196 - 14s - loss: 397.2998 - MinusLogProbMetric: 397.2998 - val_loss: 400.5799 - val_MinusLogProbMetric: 400.5799 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 124/1000
2023-09-10 02:10:26.829 
Epoch 124/1000 
	 loss: 397.6442, MinusLogProbMetric: 397.6442, val_loss: 398.4609, val_MinusLogProbMetric: 398.4609

Epoch 124: val_loss improved from 398.68021 to 398.46091, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 397.6442 - MinusLogProbMetric: 397.6442 - val_loss: 398.4609 - val_MinusLogProbMetric: 398.4609 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 125/1000
2023-09-10 02:10:40.563 
Epoch 125/1000 
	 loss: 396.7396, MinusLogProbMetric: 396.7396, val_loss: 406.2677, val_MinusLogProbMetric: 406.2677

Epoch 125: val_loss did not improve from 398.46091
196/196 - 13s - loss: 396.7396 - MinusLogProbMetric: 396.7396 - val_loss: 406.2677 - val_MinusLogProbMetric: 406.2677 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 126/1000
2023-09-10 02:10:52.198 
Epoch 126/1000 
	 loss: 397.8794, MinusLogProbMetric: 397.8794, val_loss: 399.8528, val_MinusLogProbMetric: 399.8528

Epoch 126: val_loss did not improve from 398.46091
196/196 - 12s - loss: 397.8794 - MinusLogProbMetric: 397.8794 - val_loss: 399.8528 - val_MinusLogProbMetric: 399.8528 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 127/1000
2023-09-10 02:11:06.334 
Epoch 127/1000 
	 loss: 399.3298, MinusLogProbMetric: 399.3298, val_loss: 399.5019, val_MinusLogProbMetric: 399.5019

Epoch 127: val_loss did not improve from 398.46091
196/196 - 14s - loss: 399.3298 - MinusLogProbMetric: 399.3298 - val_loss: 399.5019 - val_MinusLogProbMetric: 399.5019 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 128/1000
2023-09-10 02:11:18.429 
Epoch 128/1000 
	 loss: 397.0125, MinusLogProbMetric: 397.0125, val_loss: 398.3648, val_MinusLogProbMetric: 398.3648

Epoch 128: val_loss improved from 398.46091 to 398.36481, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 397.0125 - MinusLogProbMetric: 397.0125 - val_loss: 398.3648 - val_MinusLogProbMetric: 398.3648 - lr: 3.3333e-04 - 12s/epoch - 64ms/step
Epoch 129/1000
2023-09-10 02:11:33.363 
Epoch 129/1000 
	 loss: 396.9506, MinusLogProbMetric: 396.9506, val_loss: 399.2908, val_MinusLogProbMetric: 399.2908

Epoch 129: val_loss did not improve from 398.36481
196/196 - 15s - loss: 396.9506 - MinusLogProbMetric: 396.9506 - val_loss: 399.2908 - val_MinusLogProbMetric: 399.2908 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 130/1000
2023-09-10 02:11:47.809 
Epoch 130/1000 
	 loss: 397.6643, MinusLogProbMetric: 397.6643, val_loss: 397.7760, val_MinusLogProbMetric: 397.7760

Epoch 130: val_loss improved from 398.36481 to 397.77600, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 15s - loss: 397.6643 - MinusLogProbMetric: 397.6643 - val_loss: 397.7760 - val_MinusLogProbMetric: 397.7760 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 131/1000
2023-09-10 02:12:01.759 
Epoch 131/1000 
	 loss: 397.0356, MinusLogProbMetric: 397.0356, val_loss: 398.5179, val_MinusLogProbMetric: 398.5179

Epoch 131: val_loss did not improve from 397.77600
196/196 - 13s - loss: 397.0356 - MinusLogProbMetric: 397.0356 - val_loss: 398.5179 - val_MinusLogProbMetric: 398.5179 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 132/1000
2023-09-10 02:12:13.779 
Epoch 132/1000 
	 loss: 397.2738, MinusLogProbMetric: 397.2738, val_loss: 403.7145, val_MinusLogProbMetric: 403.7145

Epoch 132: val_loss did not improve from 397.77600
196/196 - 12s - loss: 397.2738 - MinusLogProbMetric: 397.2738 - val_loss: 403.7145 - val_MinusLogProbMetric: 403.7145 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 133/1000
2023-09-10 02:12:26.214 
Epoch 133/1000 
	 loss: 398.0405, MinusLogProbMetric: 398.0405, val_loss: 403.4617, val_MinusLogProbMetric: 403.4617

Epoch 133: val_loss did not improve from 397.77600
196/196 - 12s - loss: 398.0405 - MinusLogProbMetric: 398.0405 - val_loss: 403.4617 - val_MinusLogProbMetric: 403.4617 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 134/1000
2023-09-10 02:12:37.923 
Epoch 134/1000 
	 loss: 396.7896, MinusLogProbMetric: 396.7896, val_loss: 400.2899, val_MinusLogProbMetric: 400.2899

Epoch 134: val_loss did not improve from 397.77600
196/196 - 12s - loss: 396.7896 - MinusLogProbMetric: 396.7896 - val_loss: 400.2899 - val_MinusLogProbMetric: 400.2899 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 135/1000
2023-09-10 02:12:49.012 
Epoch 135/1000 
	 loss: 397.1939, MinusLogProbMetric: 397.1939, val_loss: 398.6766, val_MinusLogProbMetric: 398.6766

Epoch 135: val_loss did not improve from 397.77600
196/196 - 11s - loss: 397.1939 - MinusLogProbMetric: 397.1939 - val_loss: 398.6766 - val_MinusLogProbMetric: 398.6766 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 136/1000
2023-09-10 02:13:00.448 
Epoch 136/1000 
	 loss: 397.1064, MinusLogProbMetric: 397.1064, val_loss: 399.6726, val_MinusLogProbMetric: 399.6726

Epoch 136: val_loss did not improve from 397.77600
196/196 - 11s - loss: 397.1064 - MinusLogProbMetric: 397.1064 - val_loss: 399.6726 - val_MinusLogProbMetric: 399.6726 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 137/1000
2023-09-10 02:13:12.514 
Epoch 137/1000 
	 loss: 396.2263, MinusLogProbMetric: 396.2263, val_loss: 399.7988, val_MinusLogProbMetric: 399.7988

Epoch 137: val_loss did not improve from 397.77600
196/196 - 12s - loss: 396.2263 - MinusLogProbMetric: 396.2263 - val_loss: 399.7988 - val_MinusLogProbMetric: 399.7988 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 138/1000
2023-09-10 02:13:23.716 
Epoch 138/1000 
	 loss: 398.3957, MinusLogProbMetric: 398.3957, val_loss: 398.6504, val_MinusLogProbMetric: 398.6504

Epoch 138: val_loss did not improve from 397.77600
196/196 - 11s - loss: 398.3957 - MinusLogProbMetric: 398.3957 - val_loss: 398.6504 - val_MinusLogProbMetric: 398.6504 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 139/1000
2023-09-10 02:13:33.528 
Epoch 139/1000 
	 loss: 397.0132, MinusLogProbMetric: 397.0132, val_loss: 402.3310, val_MinusLogProbMetric: 402.3310

Epoch 139: val_loss did not improve from 397.77600
196/196 - 10s - loss: 397.0132 - MinusLogProbMetric: 397.0132 - val_loss: 402.3310 - val_MinusLogProbMetric: 402.3310 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 140/1000
2023-09-10 02:13:44.995 
Epoch 140/1000 
	 loss: 396.6143, MinusLogProbMetric: 396.6143, val_loss: 400.0978, val_MinusLogProbMetric: 400.0978

Epoch 140: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.6143 - MinusLogProbMetric: 396.6143 - val_loss: 400.0978 - val_MinusLogProbMetric: 400.0978 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 141/1000
2023-09-10 02:13:54.944 
Epoch 141/1000 
	 loss: 396.3272, MinusLogProbMetric: 396.3272, val_loss: 398.9486, val_MinusLogProbMetric: 398.9486

Epoch 141: val_loss did not improve from 397.77600
196/196 - 10s - loss: 396.3272 - MinusLogProbMetric: 396.3272 - val_loss: 398.9486 - val_MinusLogProbMetric: 398.9486 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 142/1000
2023-09-10 02:14:07.868 
Epoch 142/1000 
	 loss: 396.4543, MinusLogProbMetric: 396.4543, val_loss: 399.7522, val_MinusLogProbMetric: 399.7522

Epoch 142: val_loss did not improve from 397.77600
196/196 - 13s - loss: 396.4543 - MinusLogProbMetric: 396.4543 - val_loss: 399.7522 - val_MinusLogProbMetric: 399.7522 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 143/1000
2023-09-10 02:14:17.994 
Epoch 143/1000 
	 loss: 396.3954, MinusLogProbMetric: 396.3954, val_loss: 399.1014, val_MinusLogProbMetric: 399.1014

Epoch 143: val_loss did not improve from 397.77600
196/196 - 10s - loss: 396.3954 - MinusLogProbMetric: 396.3954 - val_loss: 399.1014 - val_MinusLogProbMetric: 399.1014 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 144/1000
2023-09-10 02:14:30.515 
Epoch 144/1000 
	 loss: 396.5164, MinusLogProbMetric: 396.5164, val_loss: 398.9334, val_MinusLogProbMetric: 398.9334

Epoch 144: val_loss did not improve from 397.77600
196/196 - 13s - loss: 396.5164 - MinusLogProbMetric: 396.5164 - val_loss: 398.9334 - val_MinusLogProbMetric: 398.9334 - lr: 3.3333e-04 - 13s/epoch - 64ms/step
Epoch 145/1000
2023-09-10 02:14:42.979 
Epoch 145/1000 
	 loss: 397.2962, MinusLogProbMetric: 397.2962, val_loss: 399.4720, val_MinusLogProbMetric: 399.4720

Epoch 145: val_loss did not improve from 397.77600
196/196 - 12s - loss: 397.2962 - MinusLogProbMetric: 397.2962 - val_loss: 399.4720 - val_MinusLogProbMetric: 399.4720 - lr: 3.3333e-04 - 12s/epoch - 64ms/step
Epoch 146/1000
2023-09-10 02:14:55.071 
Epoch 146/1000 
	 loss: 397.0494, MinusLogProbMetric: 397.0494, val_loss: 399.8946, val_MinusLogProbMetric: 399.8946

Epoch 146: val_loss did not improve from 397.77600
196/196 - 12s - loss: 397.0494 - MinusLogProbMetric: 397.0494 - val_loss: 399.8946 - val_MinusLogProbMetric: 399.8946 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 147/1000
2023-09-10 02:15:05.247 
Epoch 147/1000 
	 loss: 395.8468, MinusLogProbMetric: 395.8468, val_loss: 398.6649, val_MinusLogProbMetric: 398.6649

Epoch 147: val_loss did not improve from 397.77600
196/196 - 10s - loss: 395.8468 - MinusLogProbMetric: 395.8468 - val_loss: 398.6649 - val_MinusLogProbMetric: 398.6649 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 148/1000
2023-09-10 02:15:16.993 
Epoch 148/1000 
	 loss: 396.0442, MinusLogProbMetric: 396.0442, val_loss: 411.9345, val_MinusLogProbMetric: 411.9345

Epoch 148: val_loss did not improve from 397.77600
196/196 - 12s - loss: 396.0442 - MinusLogProbMetric: 396.0442 - val_loss: 411.9345 - val_MinusLogProbMetric: 411.9345 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 149/1000
2023-09-10 02:15:27.838 
Epoch 149/1000 
	 loss: 396.8651, MinusLogProbMetric: 396.8651, val_loss: 401.0411, val_MinusLogProbMetric: 401.0411

Epoch 149: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.8651 - MinusLogProbMetric: 396.8651 - val_loss: 401.0411 - val_MinusLogProbMetric: 401.0411 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 150/1000
2023-09-10 02:15:38.934 
Epoch 150/1000 
	 loss: 396.3661, MinusLogProbMetric: 396.3661, val_loss: 398.9441, val_MinusLogProbMetric: 398.9441

Epoch 150: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.3661 - MinusLogProbMetric: 396.3661 - val_loss: 398.9441 - val_MinusLogProbMetric: 398.9441 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 151/1000
2023-09-10 02:15:51.129 
Epoch 151/1000 
	 loss: 396.1175, MinusLogProbMetric: 396.1175, val_loss: 399.9279, val_MinusLogProbMetric: 399.9279

Epoch 151: val_loss did not improve from 397.77600
196/196 - 12s - loss: 396.1175 - MinusLogProbMetric: 396.1175 - val_loss: 399.9279 - val_MinusLogProbMetric: 399.9279 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 152/1000
2023-09-10 02:16:03.480 
Epoch 152/1000 
	 loss: 395.9413, MinusLogProbMetric: 395.9413, val_loss: 400.5414, val_MinusLogProbMetric: 400.5414

Epoch 152: val_loss did not improve from 397.77600
196/196 - 12s - loss: 395.9413 - MinusLogProbMetric: 395.9413 - val_loss: 400.5414 - val_MinusLogProbMetric: 400.5414 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 153/1000
2023-09-10 02:16:14.948 
Epoch 153/1000 
	 loss: 396.1094, MinusLogProbMetric: 396.1094, val_loss: 406.8265, val_MinusLogProbMetric: 406.8265

Epoch 153: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.1094 - MinusLogProbMetric: 396.1094 - val_loss: 406.8265 - val_MinusLogProbMetric: 406.8265 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 154/1000
2023-09-10 02:16:26.410 
Epoch 154/1000 
	 loss: 396.8876, MinusLogProbMetric: 396.8876, val_loss: 398.0466, val_MinusLogProbMetric: 398.0466

Epoch 154: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.8876 - MinusLogProbMetric: 396.8876 - val_loss: 398.0466 - val_MinusLogProbMetric: 398.0466 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 155/1000
2023-09-10 02:16:37.401 
Epoch 155/1000 
	 loss: 395.9544, MinusLogProbMetric: 395.9544, val_loss: 404.5542, val_MinusLogProbMetric: 404.5542

Epoch 155: val_loss did not improve from 397.77600
196/196 - 11s - loss: 395.9544 - MinusLogProbMetric: 395.9544 - val_loss: 404.5542 - val_MinusLogProbMetric: 404.5542 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 156/1000
2023-09-10 02:16:49.459 
Epoch 156/1000 
	 loss: 396.2142, MinusLogProbMetric: 396.2142, val_loss: 399.0646, val_MinusLogProbMetric: 399.0646

Epoch 156: val_loss did not improve from 397.77600
196/196 - 12s - loss: 396.2142 - MinusLogProbMetric: 396.2142 - val_loss: 399.0646 - val_MinusLogProbMetric: 399.0646 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 157/1000
2023-09-10 02:16:58.843 
Epoch 157/1000 
	 loss: 396.0530, MinusLogProbMetric: 396.0530, val_loss: 401.9852, val_MinusLogProbMetric: 401.9852

Epoch 157: val_loss did not improve from 397.77600
196/196 - 9s - loss: 396.0530 - MinusLogProbMetric: 396.0530 - val_loss: 401.9852 - val_MinusLogProbMetric: 401.9852 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 158/1000
2023-09-10 02:17:10.165 
Epoch 158/1000 
	 loss: 396.5364, MinusLogProbMetric: 396.5364, val_loss: 399.0179, val_MinusLogProbMetric: 399.0179

Epoch 158: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.5364 - MinusLogProbMetric: 396.5364 - val_loss: 399.0179 - val_MinusLogProbMetric: 399.0179 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 159/1000
2023-09-10 02:17:19.509 
Epoch 159/1000 
	 loss: 395.3746, MinusLogProbMetric: 395.3746, val_loss: 400.7361, val_MinusLogProbMetric: 400.7361

Epoch 159: val_loss did not improve from 397.77600
196/196 - 9s - loss: 395.3746 - MinusLogProbMetric: 395.3746 - val_loss: 400.7361 - val_MinusLogProbMetric: 400.7361 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 160/1000
2023-09-10 02:17:29.524 
Epoch 160/1000 
	 loss: 396.1438, MinusLogProbMetric: 396.1438, val_loss: 409.6935, val_MinusLogProbMetric: 409.6935

Epoch 160: val_loss did not improve from 397.77600
196/196 - 10s - loss: 396.1438 - MinusLogProbMetric: 396.1438 - val_loss: 409.6935 - val_MinusLogProbMetric: 409.6935 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 161/1000
2023-09-10 02:17:40.482 
Epoch 161/1000 
	 loss: 396.3123, MinusLogProbMetric: 396.3123, val_loss: 399.0967, val_MinusLogProbMetric: 399.0967

Epoch 161: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.3123 - MinusLogProbMetric: 396.3123 - val_loss: 399.0967 - val_MinusLogProbMetric: 399.0967 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 162/1000
2023-09-10 02:17:51.455 
Epoch 162/1000 
	 loss: 396.3889, MinusLogProbMetric: 396.3889, val_loss: 398.8034, val_MinusLogProbMetric: 398.8034

Epoch 162: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.3889 - MinusLogProbMetric: 396.3889 - val_loss: 398.8034 - val_MinusLogProbMetric: 398.8034 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 163/1000
2023-09-10 02:18:03.309 
Epoch 163/1000 
	 loss: 396.2160, MinusLogProbMetric: 396.2160, val_loss: 402.4750, val_MinusLogProbMetric: 402.4750

Epoch 163: val_loss did not improve from 397.77600
196/196 - 12s - loss: 396.2160 - MinusLogProbMetric: 396.2160 - val_loss: 402.4750 - val_MinusLogProbMetric: 402.4750 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 164/1000
2023-09-10 02:18:12.797 
Epoch 164/1000 
	 loss: 395.3031, MinusLogProbMetric: 395.3031, val_loss: 398.9688, val_MinusLogProbMetric: 398.9688

Epoch 164: val_loss did not improve from 397.77600
196/196 - 9s - loss: 395.3031 - MinusLogProbMetric: 395.3031 - val_loss: 398.9688 - val_MinusLogProbMetric: 398.9688 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 165/1000
2023-09-10 02:18:23.317 
Epoch 165/1000 
	 loss: 396.4854, MinusLogProbMetric: 396.4854, val_loss: 399.4794, val_MinusLogProbMetric: 399.4794

Epoch 165: val_loss did not improve from 397.77600
196/196 - 11s - loss: 396.4854 - MinusLogProbMetric: 396.4854 - val_loss: 399.4794 - val_MinusLogProbMetric: 399.4794 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 166/1000
2023-09-10 02:18:35.609 
Epoch 166/1000 
	 loss: 395.3598, MinusLogProbMetric: 395.3598, val_loss: 398.3791, val_MinusLogProbMetric: 398.3791

Epoch 166: val_loss did not improve from 397.77600
196/196 - 12s - loss: 395.3598 - MinusLogProbMetric: 395.3598 - val_loss: 398.3791 - val_MinusLogProbMetric: 398.3791 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 167/1000
2023-09-10 02:18:45.507 
Epoch 167/1000 
	 loss: 396.1232, MinusLogProbMetric: 396.1232, val_loss: 399.1793, val_MinusLogProbMetric: 399.1793

Epoch 167: val_loss did not improve from 397.77600
196/196 - 10s - loss: 396.1232 - MinusLogProbMetric: 396.1232 - val_loss: 399.1793 - val_MinusLogProbMetric: 399.1793 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 168/1000
2023-09-10 02:18:57.626 
Epoch 168/1000 
	 loss: 395.5485, MinusLogProbMetric: 395.5485, val_loss: 398.7629, val_MinusLogProbMetric: 398.7629

Epoch 168: val_loss did not improve from 397.77600
196/196 - 12s - loss: 395.5485 - MinusLogProbMetric: 395.5485 - val_loss: 398.7629 - val_MinusLogProbMetric: 398.7629 - lr: 3.3333e-04 - 12s/epoch - 62ms/step
Epoch 169/1000
2023-09-10 02:19:09.391 
Epoch 169/1000 
	 loss: 395.6032, MinusLogProbMetric: 395.6032, val_loss: 400.2123, val_MinusLogProbMetric: 400.2123

Epoch 169: val_loss did not improve from 397.77600
196/196 - 12s - loss: 395.6032 - MinusLogProbMetric: 395.6032 - val_loss: 400.2123 - val_MinusLogProbMetric: 400.2123 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 170/1000
2023-09-10 02:19:21.778 
Epoch 170/1000 
	 loss: 397.0368, MinusLogProbMetric: 397.0368, val_loss: 399.1187, val_MinusLogProbMetric: 399.1187

Epoch 170: val_loss did not improve from 397.77600
196/196 - 12s - loss: 397.0368 - MinusLogProbMetric: 397.0368 - val_loss: 399.1187 - val_MinusLogProbMetric: 399.1187 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 171/1000
2023-09-10 02:19:32.852 
Epoch 171/1000 
	 loss: 395.0346, MinusLogProbMetric: 395.0346, val_loss: 401.7712, val_MinusLogProbMetric: 401.7712

Epoch 171: val_loss did not improve from 397.77600
196/196 - 11s - loss: 395.0346 - MinusLogProbMetric: 395.0346 - val_loss: 401.7712 - val_MinusLogProbMetric: 401.7712 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 172/1000
2023-09-10 02:19:44.609 
Epoch 172/1000 
	 loss: 395.6118, MinusLogProbMetric: 395.6118, val_loss: 400.8703, val_MinusLogProbMetric: 400.8703

Epoch 172: val_loss did not improve from 397.77600
196/196 - 12s - loss: 395.6118 - MinusLogProbMetric: 395.6118 - val_loss: 400.8703 - val_MinusLogProbMetric: 400.8703 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 173/1000
2023-09-10 02:19:56.381 
Epoch 173/1000 
	 loss: 395.3608, MinusLogProbMetric: 395.3608, val_loss: 399.8307, val_MinusLogProbMetric: 399.8307

Epoch 173: val_loss did not improve from 397.77600
196/196 - 12s - loss: 395.3608 - MinusLogProbMetric: 395.3608 - val_loss: 399.8307 - val_MinusLogProbMetric: 399.8307 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 174/1000
2023-09-10 02:20:07.336 
Epoch 174/1000 
	 loss: 395.6132, MinusLogProbMetric: 395.6132, val_loss: 398.1354, val_MinusLogProbMetric: 398.1354

Epoch 174: val_loss did not improve from 397.77600
196/196 - 11s - loss: 395.6132 - MinusLogProbMetric: 395.6132 - val_loss: 398.1354 - val_MinusLogProbMetric: 398.1354 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 175/1000
2023-09-10 02:20:18.734 
Epoch 175/1000 
	 loss: 395.3381, MinusLogProbMetric: 395.3381, val_loss: 400.3061, val_MinusLogProbMetric: 400.3061

Epoch 175: val_loss did not improve from 397.77600
196/196 - 11s - loss: 395.3381 - MinusLogProbMetric: 395.3381 - val_loss: 400.3061 - val_MinusLogProbMetric: 400.3061 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 176/1000
2023-09-10 02:20:28.962 
Epoch 176/1000 
	 loss: 395.0152, MinusLogProbMetric: 395.0152, val_loss: 403.6087, val_MinusLogProbMetric: 403.6087

Epoch 176: val_loss did not improve from 397.77600
196/196 - 10s - loss: 395.0152 - MinusLogProbMetric: 395.0152 - val_loss: 403.6087 - val_MinusLogProbMetric: 403.6087 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 177/1000
2023-09-10 02:20:40.192 
Epoch 177/1000 
	 loss: 395.5462, MinusLogProbMetric: 395.5462, val_loss: 398.2316, val_MinusLogProbMetric: 398.2316

Epoch 177: val_loss did not improve from 397.77600
196/196 - 11s - loss: 395.5462 - MinusLogProbMetric: 395.5462 - val_loss: 398.2316 - val_MinusLogProbMetric: 398.2316 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 178/1000
2023-09-10 02:20:49.809 
Epoch 178/1000 
	 loss: 395.1131, MinusLogProbMetric: 395.1131, val_loss: 398.5546, val_MinusLogProbMetric: 398.5546

Epoch 178: val_loss did not improve from 397.77600
196/196 - 10s - loss: 395.1131 - MinusLogProbMetric: 395.1131 - val_loss: 398.5546 - val_MinusLogProbMetric: 398.5546 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 179/1000
2023-09-10 02:21:02.204 
Epoch 179/1000 
	 loss: 395.4155, MinusLogProbMetric: 395.4155, val_loss: 398.8180, val_MinusLogProbMetric: 398.8180

Epoch 179: val_loss did not improve from 397.77600
196/196 - 12s - loss: 395.4155 - MinusLogProbMetric: 395.4155 - val_loss: 398.8180 - val_MinusLogProbMetric: 398.8180 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 180/1000
2023-09-10 02:21:11.682 
Epoch 180/1000 
	 loss: 394.8107, MinusLogProbMetric: 394.8107, val_loss: 398.6425, val_MinusLogProbMetric: 398.6425

Epoch 180: val_loss did not improve from 397.77600
196/196 - 9s - loss: 394.8107 - MinusLogProbMetric: 394.8107 - val_loss: 398.6425 - val_MinusLogProbMetric: 398.6425 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 181/1000
2023-09-10 02:21:23.090 
Epoch 181/1000 
	 loss: 390.4244, MinusLogProbMetric: 390.4244, val_loss: 395.9309, val_MinusLogProbMetric: 395.9309

Epoch 181: val_loss improved from 397.77600 to 395.93088, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 390.4244 - MinusLogProbMetric: 390.4244 - val_loss: 395.9309 - val_MinusLogProbMetric: 395.9309 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 182/1000
2023-09-10 02:21:33.737 
Epoch 182/1000 
	 loss: 390.2990, MinusLogProbMetric: 390.2990, val_loss: 396.6983, val_MinusLogProbMetric: 396.6983

Epoch 182: val_loss did not improve from 395.93088
196/196 - 10s - loss: 390.2990 - MinusLogProbMetric: 390.2990 - val_loss: 396.6983 - val_MinusLogProbMetric: 396.6983 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 183/1000
2023-09-10 02:21:44.708 
Epoch 183/1000 
	 loss: 390.4644, MinusLogProbMetric: 390.4644, val_loss: 395.2671, val_MinusLogProbMetric: 395.2671

Epoch 183: val_loss improved from 395.93088 to 395.26712, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 390.4644 - MinusLogProbMetric: 390.4644 - val_loss: 395.2671 - val_MinusLogProbMetric: 395.2671 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 184/1000
2023-09-10 02:21:56.180 
Epoch 184/1000 
	 loss: 390.4346, MinusLogProbMetric: 390.4346, val_loss: 395.5586, val_MinusLogProbMetric: 395.5586

Epoch 184: val_loss did not improve from 395.26712
196/196 - 11s - loss: 390.4346 - MinusLogProbMetric: 390.4346 - val_loss: 395.5586 - val_MinusLogProbMetric: 395.5586 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 185/1000
2023-09-10 02:22:08.868 
Epoch 185/1000 
	 loss: 390.8385, MinusLogProbMetric: 390.8385, val_loss: 396.3037, val_MinusLogProbMetric: 396.3037

Epoch 185: val_loss did not improve from 395.26712
196/196 - 13s - loss: 390.8385 - MinusLogProbMetric: 390.8385 - val_loss: 396.3037 - val_MinusLogProbMetric: 396.3037 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 186/1000
2023-09-10 02:22:19.927 
Epoch 186/1000 
	 loss: 390.4991, MinusLogProbMetric: 390.4991, val_loss: 399.2117, val_MinusLogProbMetric: 399.2117

Epoch 186: val_loss did not improve from 395.26712
196/196 - 11s - loss: 390.4991 - MinusLogProbMetric: 390.4991 - val_loss: 399.2117 - val_MinusLogProbMetric: 399.2117 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 187/1000
2023-09-10 02:22:29.958 
Epoch 187/1000 
	 loss: 390.4727, MinusLogProbMetric: 390.4727, val_loss: 395.3047, val_MinusLogProbMetric: 395.3047

Epoch 187: val_loss did not improve from 395.26712
196/196 - 10s - loss: 390.4727 - MinusLogProbMetric: 390.4727 - val_loss: 395.3047 - val_MinusLogProbMetric: 395.3047 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 188/1000
2023-09-10 02:22:41.754 
Epoch 188/1000 
	 loss: 390.6878, MinusLogProbMetric: 390.6878, val_loss: 395.1323, val_MinusLogProbMetric: 395.1323

Epoch 188: val_loss improved from 395.26712 to 395.13226, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 390.6878 - MinusLogProbMetric: 390.6878 - val_loss: 395.1323 - val_MinusLogProbMetric: 395.1323 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 189/1000
2023-09-10 02:22:52.128 
Epoch 189/1000 
	 loss: 390.5126, MinusLogProbMetric: 390.5126, val_loss: 395.0478, val_MinusLogProbMetric: 395.0478

Epoch 189: val_loss improved from 395.13226 to 395.04776, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 390.5126 - MinusLogProbMetric: 390.5126 - val_loss: 395.0478 - val_MinusLogProbMetric: 395.0478 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 190/1000
2023-09-10 02:23:04.138 
Epoch 190/1000 
	 loss: 390.3351, MinusLogProbMetric: 390.3351, val_loss: 398.1960, val_MinusLogProbMetric: 398.1960

Epoch 190: val_loss did not improve from 395.04776
196/196 - 12s - loss: 390.3351 - MinusLogProbMetric: 390.3351 - val_loss: 398.1960 - val_MinusLogProbMetric: 398.1960 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 191/1000
2023-09-10 02:23:14.398 
Epoch 191/1000 
	 loss: 390.5922, MinusLogProbMetric: 390.5922, val_loss: 395.0373, val_MinusLogProbMetric: 395.0373

Epoch 191: val_loss improved from 395.04776 to 395.03732, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 390.5922 - MinusLogProbMetric: 390.5922 - val_loss: 395.0373 - val_MinusLogProbMetric: 395.0373 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 192/1000
2023-09-10 02:23:26.952 
Epoch 192/1000 
	 loss: 390.3758, MinusLogProbMetric: 390.3758, val_loss: 396.9736, val_MinusLogProbMetric: 396.9736

Epoch 192: val_loss did not improve from 395.03732
196/196 - 12s - loss: 390.3758 - MinusLogProbMetric: 390.3758 - val_loss: 396.9736 - val_MinusLogProbMetric: 396.9736 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 193/1000
2023-09-10 02:23:38.074 
Epoch 193/1000 
	 loss: 390.7479, MinusLogProbMetric: 390.7479, val_loss: 396.8302, val_MinusLogProbMetric: 396.8302

Epoch 193: val_loss did not improve from 395.03732
196/196 - 11s - loss: 390.7479 - MinusLogProbMetric: 390.7479 - val_loss: 396.8302 - val_MinusLogProbMetric: 396.8302 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 194/1000
2023-09-10 02:23:49.855 
Epoch 194/1000 
	 loss: 390.3432, MinusLogProbMetric: 390.3432, val_loss: 395.4464, val_MinusLogProbMetric: 395.4464

Epoch 194: val_loss did not improve from 395.03732
196/196 - 12s - loss: 390.3432 - MinusLogProbMetric: 390.3432 - val_loss: 395.4464 - val_MinusLogProbMetric: 395.4464 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 195/1000
2023-09-10 02:24:00.573 
Epoch 195/1000 
	 loss: 390.4217, MinusLogProbMetric: 390.4217, val_loss: 397.3472, val_MinusLogProbMetric: 397.3472

Epoch 195: val_loss did not improve from 395.03732
196/196 - 11s - loss: 390.4217 - MinusLogProbMetric: 390.4217 - val_loss: 397.3472 - val_MinusLogProbMetric: 397.3472 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 196/1000
2023-09-10 02:24:11.358 
Epoch 196/1000 
	 loss: 390.5734, MinusLogProbMetric: 390.5734, val_loss: 397.0479, val_MinusLogProbMetric: 397.0479

Epoch 196: val_loss did not improve from 395.03732
196/196 - 11s - loss: 390.5734 - MinusLogProbMetric: 390.5734 - val_loss: 397.0479 - val_MinusLogProbMetric: 397.0479 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 197/1000
2023-09-10 02:24:22.389 
Epoch 197/1000 
	 loss: 390.3864, MinusLogProbMetric: 390.3864, val_loss: 394.7452, val_MinusLogProbMetric: 394.7452

Epoch 197: val_loss improved from 395.03732 to 394.74521, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 390.3864 - MinusLogProbMetric: 390.3864 - val_loss: 394.7452 - val_MinusLogProbMetric: 394.7452 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 198/1000
2023-09-10 02:24:32.868 
Epoch 198/1000 
	 loss: 390.3521, MinusLogProbMetric: 390.3521, val_loss: 397.9374, val_MinusLogProbMetric: 397.9374

Epoch 198: val_loss did not improve from 394.74521
196/196 - 10s - loss: 390.3521 - MinusLogProbMetric: 390.3521 - val_loss: 397.9374 - val_MinusLogProbMetric: 397.9374 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 199/1000
2023-09-10 02:24:43.991 
Epoch 199/1000 
	 loss: 390.4467, MinusLogProbMetric: 390.4467, val_loss: 395.4855, val_MinusLogProbMetric: 395.4855

Epoch 199: val_loss did not improve from 394.74521
196/196 - 11s - loss: 390.4467 - MinusLogProbMetric: 390.4467 - val_loss: 395.4855 - val_MinusLogProbMetric: 395.4855 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 200/1000
2023-09-10 02:24:54.940 
Epoch 200/1000 
	 loss: 390.5634, MinusLogProbMetric: 390.5634, val_loss: 394.6787, val_MinusLogProbMetric: 394.6787

Epoch 200: val_loss improved from 394.74521 to 394.67868, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 390.5634 - MinusLogProbMetric: 390.5634 - val_loss: 394.6787 - val_MinusLogProbMetric: 394.6787 - lr: 1.6667e-04 - 11s/epoch - 59ms/step
Epoch 201/1000
2023-09-10 02:25:06.333 
Epoch 201/1000 
	 loss: 390.2659, MinusLogProbMetric: 390.2659, val_loss: 395.2434, val_MinusLogProbMetric: 395.2434

Epoch 201: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.2659 - MinusLogProbMetric: 390.2659 - val_loss: 395.2434 - val_MinusLogProbMetric: 395.2434 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 202/1000
2023-09-10 02:25:17.891 
Epoch 202/1000 
	 loss: 390.4306, MinusLogProbMetric: 390.4306, val_loss: 395.2843, val_MinusLogProbMetric: 395.2843

Epoch 202: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.4306 - MinusLogProbMetric: 390.4306 - val_loss: 395.2843 - val_MinusLogProbMetric: 395.2843 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 203/1000
2023-09-10 02:25:29.808 
Epoch 203/1000 
	 loss: 390.3527, MinusLogProbMetric: 390.3527, val_loss: 396.5481, val_MinusLogProbMetric: 396.5481

Epoch 203: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.3527 - MinusLogProbMetric: 390.3527 - val_loss: 396.5481 - val_MinusLogProbMetric: 396.5481 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 204/1000
2023-09-10 02:25:39.419 
Epoch 204/1000 
	 loss: 390.3914, MinusLogProbMetric: 390.3914, val_loss: 397.6179, val_MinusLogProbMetric: 397.6179

Epoch 204: val_loss did not improve from 394.67868
196/196 - 10s - loss: 390.3914 - MinusLogProbMetric: 390.3914 - val_loss: 397.6179 - val_MinusLogProbMetric: 397.6179 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 205/1000
2023-09-10 02:25:50.785 
Epoch 205/1000 
	 loss: 390.3729, MinusLogProbMetric: 390.3729, val_loss: 395.1142, val_MinusLogProbMetric: 395.1142

Epoch 205: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.3729 - MinusLogProbMetric: 390.3729 - val_loss: 395.1142 - val_MinusLogProbMetric: 395.1142 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 206/1000
2023-09-10 02:26:04.644 
Epoch 206/1000 
	 loss: 390.2007, MinusLogProbMetric: 390.2007, val_loss: 397.4863, val_MinusLogProbMetric: 397.4863

Epoch 206: val_loss did not improve from 394.67868
196/196 - 14s - loss: 390.2007 - MinusLogProbMetric: 390.2007 - val_loss: 397.4863 - val_MinusLogProbMetric: 397.4863 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 207/1000
2023-09-10 02:26:15.378 
Epoch 207/1000 
	 loss: 390.4532, MinusLogProbMetric: 390.4532, val_loss: 396.0063, val_MinusLogProbMetric: 396.0063

Epoch 207: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.4532 - MinusLogProbMetric: 390.4532 - val_loss: 396.0063 - val_MinusLogProbMetric: 396.0063 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 208/1000
2023-09-10 02:26:27.146 
Epoch 208/1000 
	 loss: 390.2670, MinusLogProbMetric: 390.2670, val_loss: 397.0985, val_MinusLogProbMetric: 397.0985

Epoch 208: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.2670 - MinusLogProbMetric: 390.2670 - val_loss: 397.0985 - val_MinusLogProbMetric: 397.0985 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 209/1000
2023-09-10 02:26:37.441 
Epoch 209/1000 
	 loss: 390.3809, MinusLogProbMetric: 390.3809, val_loss: 397.6971, val_MinusLogProbMetric: 397.6971

Epoch 209: val_loss did not improve from 394.67868
196/196 - 10s - loss: 390.3809 - MinusLogProbMetric: 390.3809 - val_loss: 397.6971 - val_MinusLogProbMetric: 397.6971 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 210/1000
2023-09-10 02:26:48.462 
Epoch 210/1000 
	 loss: 390.0686, MinusLogProbMetric: 390.0686, val_loss: 395.5827, val_MinusLogProbMetric: 395.5827

Epoch 210: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.0686 - MinusLogProbMetric: 390.0686 - val_loss: 395.5827 - val_MinusLogProbMetric: 395.5827 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 211/1000
2023-09-10 02:27:00.259 
Epoch 211/1000 
	 loss: 390.1801, MinusLogProbMetric: 390.1801, val_loss: 397.9575, val_MinusLogProbMetric: 397.9575

Epoch 211: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.1801 - MinusLogProbMetric: 390.1801 - val_loss: 397.9575 - val_MinusLogProbMetric: 397.9575 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 212/1000
2023-09-10 02:27:11.871 
Epoch 212/1000 
	 loss: 390.6392, MinusLogProbMetric: 390.6392, val_loss: 395.2451, val_MinusLogProbMetric: 395.2451

Epoch 212: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.6392 - MinusLogProbMetric: 390.6392 - val_loss: 395.2451 - val_MinusLogProbMetric: 395.2451 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 213/1000
2023-09-10 02:27:22.856 
Epoch 213/1000 
	 loss: 390.1063, MinusLogProbMetric: 390.1063, val_loss: 395.2747, val_MinusLogProbMetric: 395.2747

Epoch 213: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.1063 - MinusLogProbMetric: 390.1063 - val_loss: 395.2747 - val_MinusLogProbMetric: 395.2747 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 214/1000
2023-09-10 02:27:34.800 
Epoch 214/1000 
	 loss: 390.3978, MinusLogProbMetric: 390.3978, val_loss: 395.2729, val_MinusLogProbMetric: 395.2729

Epoch 214: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.3978 - MinusLogProbMetric: 390.3978 - val_loss: 395.2729 - val_MinusLogProbMetric: 395.2729 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 215/1000
2023-09-10 02:27:45.316 
Epoch 215/1000 
	 loss: 390.1989, MinusLogProbMetric: 390.1989, val_loss: 397.7462, val_MinusLogProbMetric: 397.7462

Epoch 215: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.1989 - MinusLogProbMetric: 390.1989 - val_loss: 397.7462 - val_MinusLogProbMetric: 397.7462 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 216/1000
2023-09-10 02:27:56.749 
Epoch 216/1000 
	 loss: 390.3005, MinusLogProbMetric: 390.3005, val_loss: 396.0446, val_MinusLogProbMetric: 396.0446

Epoch 216: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.3005 - MinusLogProbMetric: 390.3005 - val_loss: 396.0446 - val_MinusLogProbMetric: 396.0446 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 217/1000
2023-09-10 02:28:08.122 
Epoch 217/1000 
	 loss: 390.1666, MinusLogProbMetric: 390.1666, val_loss: 396.5710, val_MinusLogProbMetric: 396.5710

Epoch 217: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.1666 - MinusLogProbMetric: 390.1666 - val_loss: 396.5710 - val_MinusLogProbMetric: 396.5710 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 218/1000
2023-09-10 02:28:20.050 
Epoch 218/1000 
	 loss: 390.1772, MinusLogProbMetric: 390.1772, val_loss: 395.2732, val_MinusLogProbMetric: 395.2732

Epoch 218: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.1772 - MinusLogProbMetric: 390.1772 - val_loss: 395.2732 - val_MinusLogProbMetric: 395.2732 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 219/1000
2023-09-10 02:28:30.277 
Epoch 219/1000 
	 loss: 390.4774, MinusLogProbMetric: 390.4774, val_loss: 395.6716, val_MinusLogProbMetric: 395.6716

Epoch 219: val_loss did not improve from 394.67868
196/196 - 10s - loss: 390.4774 - MinusLogProbMetric: 390.4774 - val_loss: 395.6716 - val_MinusLogProbMetric: 395.6716 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 220/1000
2023-09-10 02:28:41.225 
Epoch 220/1000 
	 loss: 390.1969, MinusLogProbMetric: 390.1969, val_loss: 396.9615, val_MinusLogProbMetric: 396.9615

Epoch 220: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.1969 - MinusLogProbMetric: 390.1969 - val_loss: 396.9615 - val_MinusLogProbMetric: 396.9615 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 221/1000
2023-09-10 02:28:52.958 
Epoch 221/1000 
	 loss: 390.1160, MinusLogProbMetric: 390.1160, val_loss: 395.1633, val_MinusLogProbMetric: 395.1633

Epoch 221: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.1160 - MinusLogProbMetric: 390.1160 - val_loss: 395.1633 - val_MinusLogProbMetric: 395.1633 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 222/1000
2023-09-10 02:29:04.860 
Epoch 222/1000 
	 loss: 390.3686, MinusLogProbMetric: 390.3686, val_loss: 395.3658, val_MinusLogProbMetric: 395.3658

Epoch 222: val_loss did not improve from 394.67868
196/196 - 12s - loss: 390.3686 - MinusLogProbMetric: 390.3686 - val_loss: 395.3658 - val_MinusLogProbMetric: 395.3658 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 223/1000
2023-09-10 02:29:15.416 
Epoch 223/1000 
	 loss: 390.0796, MinusLogProbMetric: 390.0796, val_loss: 395.8520, val_MinusLogProbMetric: 395.8520

Epoch 223: val_loss did not improve from 394.67868
196/196 - 11s - loss: 390.0796 - MinusLogProbMetric: 390.0796 - val_loss: 395.8520 - val_MinusLogProbMetric: 395.8520 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 224/1000
2023-09-10 02:29:25.588 
Epoch 224/1000 
	 loss: 389.9496, MinusLogProbMetric: 389.9496, val_loss: 395.2930, val_MinusLogProbMetric: 395.2930

Epoch 224: val_loss did not improve from 394.67868
196/196 - 10s - loss: 389.9496 - MinusLogProbMetric: 389.9496 - val_loss: 395.2930 - val_MinusLogProbMetric: 395.2930 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 225/1000
2023-09-10 02:29:37.353 
Epoch 225/1000 
	 loss: 390.4865, MinusLogProbMetric: 390.4865, val_loss: 394.6360, val_MinusLogProbMetric: 394.6360

Epoch 225: val_loss improved from 394.67868 to 394.63605, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 390.4865 - MinusLogProbMetric: 390.4865 - val_loss: 394.6360 - val_MinusLogProbMetric: 394.6360 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 226/1000
2023-09-10 02:29:48.207 
Epoch 226/1000 
	 loss: 389.9171, MinusLogProbMetric: 389.9171, val_loss: 395.7656, val_MinusLogProbMetric: 395.7656

Epoch 226: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.9171 - MinusLogProbMetric: 389.9171 - val_loss: 395.7656 - val_MinusLogProbMetric: 395.7656 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 227/1000
2023-09-10 02:30:00.180 
Epoch 227/1000 
	 loss: 390.2216, MinusLogProbMetric: 390.2216, val_loss: 395.2060, val_MinusLogProbMetric: 395.2060

Epoch 227: val_loss did not improve from 394.63605
196/196 - 12s - loss: 390.2216 - MinusLogProbMetric: 390.2216 - val_loss: 395.2060 - val_MinusLogProbMetric: 395.2060 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 228/1000
2023-09-10 02:30:10.785 
Epoch 228/1000 
	 loss: 389.9888, MinusLogProbMetric: 389.9888, val_loss: 395.0742, val_MinusLogProbMetric: 395.0742

Epoch 228: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.9888 - MinusLogProbMetric: 389.9888 - val_loss: 395.0742 - val_MinusLogProbMetric: 395.0742 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 229/1000
2023-09-10 02:30:22.333 
Epoch 229/1000 
	 loss: 390.1024, MinusLogProbMetric: 390.1024, val_loss: 398.4796, val_MinusLogProbMetric: 398.4796

Epoch 229: val_loss did not improve from 394.63605
196/196 - 12s - loss: 390.1024 - MinusLogProbMetric: 390.1024 - val_loss: 398.4796 - val_MinusLogProbMetric: 398.4796 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 230/1000
2023-09-10 02:30:32.457 
Epoch 230/1000 
	 loss: 390.1689, MinusLogProbMetric: 390.1689, val_loss: 394.9382, val_MinusLogProbMetric: 394.9382

Epoch 230: val_loss did not improve from 394.63605
196/196 - 10s - loss: 390.1689 - MinusLogProbMetric: 390.1689 - val_loss: 394.9382 - val_MinusLogProbMetric: 394.9382 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 231/1000
2023-09-10 02:30:44.197 
Epoch 231/1000 
	 loss: 389.8781, MinusLogProbMetric: 389.8781, val_loss: 395.4015, val_MinusLogProbMetric: 395.4015

Epoch 231: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.8781 - MinusLogProbMetric: 389.8781 - val_loss: 395.4015 - val_MinusLogProbMetric: 395.4015 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 232/1000
2023-09-10 02:30:54.911 
Epoch 232/1000 
	 loss: 390.0278, MinusLogProbMetric: 390.0278, val_loss: 395.7326, val_MinusLogProbMetric: 395.7326

Epoch 232: val_loss did not improve from 394.63605
196/196 - 11s - loss: 390.0278 - MinusLogProbMetric: 390.0278 - val_loss: 395.7326 - val_MinusLogProbMetric: 395.7326 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 233/1000
2023-09-10 02:31:04.520 
Epoch 233/1000 
	 loss: 389.9221, MinusLogProbMetric: 389.9221, val_loss: 396.5066, val_MinusLogProbMetric: 396.5066

Epoch 233: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.9221 - MinusLogProbMetric: 389.9221 - val_loss: 396.5066 - val_MinusLogProbMetric: 396.5066 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 234/1000
2023-09-10 02:31:15.543 
Epoch 234/1000 
	 loss: 390.1752, MinusLogProbMetric: 390.1752, val_loss: 395.8503, val_MinusLogProbMetric: 395.8503

Epoch 234: val_loss did not improve from 394.63605
196/196 - 11s - loss: 390.1752 - MinusLogProbMetric: 390.1752 - val_loss: 395.8503 - val_MinusLogProbMetric: 395.8503 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 235/1000
2023-09-10 02:31:26.686 
Epoch 235/1000 
	 loss: 389.9811, MinusLogProbMetric: 389.9811, val_loss: 395.0888, val_MinusLogProbMetric: 395.0888

Epoch 235: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.9811 - MinusLogProbMetric: 389.9811 - val_loss: 395.0888 - val_MinusLogProbMetric: 395.0888 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 236/1000
2023-09-10 02:31:37.908 
Epoch 236/1000 
	 loss: 389.9263, MinusLogProbMetric: 389.9263, val_loss: 402.1341, val_MinusLogProbMetric: 402.1341

Epoch 236: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.9263 - MinusLogProbMetric: 389.9263 - val_loss: 402.1341 - val_MinusLogProbMetric: 402.1341 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 237/1000
2023-09-10 02:31:48.212 
Epoch 237/1000 
	 loss: 389.9030, MinusLogProbMetric: 389.9030, val_loss: 395.9224, val_MinusLogProbMetric: 395.9224

Epoch 237: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.9030 - MinusLogProbMetric: 389.9030 - val_loss: 395.9224 - val_MinusLogProbMetric: 395.9224 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 238/1000
2023-09-10 02:31:59.651 
Epoch 238/1000 
	 loss: 389.9572, MinusLogProbMetric: 389.9572, val_loss: 397.4705, val_MinusLogProbMetric: 397.4705

Epoch 238: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.9572 - MinusLogProbMetric: 389.9572 - val_loss: 397.4705 - val_MinusLogProbMetric: 397.4705 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 239/1000
2023-09-10 02:32:10.419 
Epoch 239/1000 
	 loss: 389.8794, MinusLogProbMetric: 389.8794, val_loss: 395.9405, val_MinusLogProbMetric: 395.9405

Epoch 239: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.8794 - MinusLogProbMetric: 389.8794 - val_loss: 395.9405 - val_MinusLogProbMetric: 395.9405 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 240/1000
2023-09-10 02:32:19.220 
Epoch 240/1000 
	 loss: 389.9694, MinusLogProbMetric: 389.9694, val_loss: 395.0503, val_MinusLogProbMetric: 395.0503

Epoch 240: val_loss did not improve from 394.63605
196/196 - 9s - loss: 389.9694 - MinusLogProbMetric: 389.9694 - val_loss: 395.0503 - val_MinusLogProbMetric: 395.0503 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 241/1000
2023-09-10 02:32:29.449 
Epoch 241/1000 
	 loss: 389.9282, MinusLogProbMetric: 389.9282, val_loss: 397.4216, val_MinusLogProbMetric: 397.4216

Epoch 241: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.9282 - MinusLogProbMetric: 389.9282 - val_loss: 397.4216 - val_MinusLogProbMetric: 397.4216 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 242/1000
2023-09-10 02:32:39.553 
Epoch 242/1000 
	 loss: 389.9186, MinusLogProbMetric: 389.9186, val_loss: 395.4613, val_MinusLogProbMetric: 395.4613

Epoch 242: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.9186 - MinusLogProbMetric: 389.9186 - val_loss: 395.4613 - val_MinusLogProbMetric: 395.4613 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 243/1000
2023-09-10 02:32:49.221 
Epoch 243/1000 
	 loss: 389.9673, MinusLogProbMetric: 389.9673, val_loss: 394.8706, val_MinusLogProbMetric: 394.8706

Epoch 243: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.9673 - MinusLogProbMetric: 389.9673 - val_loss: 394.8706 - val_MinusLogProbMetric: 394.8706 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 244/1000
2023-09-10 02:33:00.275 
Epoch 244/1000 
	 loss: 389.7879, MinusLogProbMetric: 389.7879, val_loss: 395.1609, val_MinusLogProbMetric: 395.1609

Epoch 244: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.7879 - MinusLogProbMetric: 389.7879 - val_loss: 395.1609 - val_MinusLogProbMetric: 395.1609 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 245/1000
2023-09-10 02:33:10.434 
Epoch 245/1000 
	 loss: 390.1465, MinusLogProbMetric: 390.1465, val_loss: 399.9792, val_MinusLogProbMetric: 399.9792

Epoch 245: val_loss did not improve from 394.63605
196/196 - 10s - loss: 390.1465 - MinusLogProbMetric: 390.1465 - val_loss: 399.9792 - val_MinusLogProbMetric: 399.9792 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 246/1000
2023-09-10 02:33:21.870 
Epoch 246/1000 
	 loss: 389.6453, MinusLogProbMetric: 389.6453, val_loss: 395.2621, val_MinusLogProbMetric: 395.2621

Epoch 246: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.6453 - MinusLogProbMetric: 389.6453 - val_loss: 395.2621 - val_MinusLogProbMetric: 395.2621 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 247/1000
2023-09-10 02:33:30.837 
Epoch 247/1000 
	 loss: 389.7968, MinusLogProbMetric: 389.7968, val_loss: 395.6389, val_MinusLogProbMetric: 395.6389

Epoch 247: val_loss did not improve from 394.63605
196/196 - 9s - loss: 389.7968 - MinusLogProbMetric: 389.7968 - val_loss: 395.6389 - val_MinusLogProbMetric: 395.6389 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 248/1000
2023-09-10 02:33:41.715 
Epoch 248/1000 
	 loss: 389.8449, MinusLogProbMetric: 389.8449, val_loss: 395.5533, val_MinusLogProbMetric: 395.5533

Epoch 248: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.8449 - MinusLogProbMetric: 389.8449 - val_loss: 395.5533 - val_MinusLogProbMetric: 395.5533 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 249/1000
2023-09-10 02:33:51.745 
Epoch 249/1000 
	 loss: 389.7339, MinusLogProbMetric: 389.7339, val_loss: 396.4742, val_MinusLogProbMetric: 396.4742

Epoch 249: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.7339 - MinusLogProbMetric: 389.7339 - val_loss: 396.4742 - val_MinusLogProbMetric: 396.4742 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 250/1000
2023-09-10 02:34:01.677 
Epoch 250/1000 
	 loss: 390.0684, MinusLogProbMetric: 390.0684, val_loss: 395.9558, val_MinusLogProbMetric: 395.9558

Epoch 250: val_loss did not improve from 394.63605
196/196 - 10s - loss: 390.0684 - MinusLogProbMetric: 390.0684 - val_loss: 395.9558 - val_MinusLogProbMetric: 395.9558 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 251/1000
2023-09-10 02:34:11.782 
Epoch 251/1000 
	 loss: 389.7045, MinusLogProbMetric: 389.7045, val_loss: 395.7342, val_MinusLogProbMetric: 395.7342

Epoch 251: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.7045 - MinusLogProbMetric: 389.7045 - val_loss: 395.7342 - val_MinusLogProbMetric: 395.7342 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 252/1000
2023-09-10 02:34:22.702 
Epoch 252/1000 
	 loss: 389.7490, MinusLogProbMetric: 389.7490, val_loss: 397.8143, val_MinusLogProbMetric: 397.8143

Epoch 252: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.7490 - MinusLogProbMetric: 389.7490 - val_loss: 397.8143 - val_MinusLogProbMetric: 397.8143 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 253/1000
2023-09-10 02:34:32.650 
Epoch 253/1000 
	 loss: 389.7923, MinusLogProbMetric: 389.7923, val_loss: 397.6547, val_MinusLogProbMetric: 397.6547

Epoch 253: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.7923 - MinusLogProbMetric: 389.7923 - val_loss: 397.6547 - val_MinusLogProbMetric: 397.6547 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 254/1000
2023-09-10 02:34:44.345 
Epoch 254/1000 
	 loss: 389.7048, MinusLogProbMetric: 389.7048, val_loss: 395.2840, val_MinusLogProbMetric: 395.2840

Epoch 254: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.7048 - MinusLogProbMetric: 389.7048 - val_loss: 395.2840 - val_MinusLogProbMetric: 395.2840 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 255/1000
2023-09-10 02:34:56.372 
Epoch 255/1000 
	 loss: 389.8652, MinusLogProbMetric: 389.8652, val_loss: 396.5981, val_MinusLogProbMetric: 396.5981

Epoch 255: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.8652 - MinusLogProbMetric: 389.8652 - val_loss: 396.5981 - val_MinusLogProbMetric: 396.5981 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 256/1000
2023-09-10 02:35:06.782 
Epoch 256/1000 
	 loss: 389.5639, MinusLogProbMetric: 389.5639, val_loss: 397.0070, val_MinusLogProbMetric: 397.0070

Epoch 256: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.5639 - MinusLogProbMetric: 389.5639 - val_loss: 397.0070 - val_MinusLogProbMetric: 397.0070 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 257/1000
2023-09-10 02:35:18.589 
Epoch 257/1000 
	 loss: 389.7888, MinusLogProbMetric: 389.7888, val_loss: 395.5856, val_MinusLogProbMetric: 395.5856

Epoch 257: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.7888 - MinusLogProbMetric: 389.7888 - val_loss: 395.5856 - val_MinusLogProbMetric: 395.5856 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 258/1000
2023-09-10 02:35:29.166 
Epoch 258/1000 
	 loss: 390.3947, MinusLogProbMetric: 390.3947, val_loss: 401.9151, val_MinusLogProbMetric: 401.9151

Epoch 258: val_loss did not improve from 394.63605
196/196 - 11s - loss: 390.3947 - MinusLogProbMetric: 390.3947 - val_loss: 401.9151 - val_MinusLogProbMetric: 401.9151 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 259/1000
2023-09-10 02:35:41.551 
Epoch 259/1000 
	 loss: 389.4020, MinusLogProbMetric: 389.4020, val_loss: 397.0616, val_MinusLogProbMetric: 397.0616

Epoch 259: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.4020 - MinusLogProbMetric: 389.4020 - val_loss: 397.0616 - val_MinusLogProbMetric: 397.0616 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 260/1000
2023-09-10 02:35:54.215 
Epoch 260/1000 
	 loss: 389.5107, MinusLogProbMetric: 389.5107, val_loss: 398.4227, val_MinusLogProbMetric: 398.4227

Epoch 260: val_loss did not improve from 394.63605
196/196 - 13s - loss: 389.5107 - MinusLogProbMetric: 389.5107 - val_loss: 398.4227 - val_MinusLogProbMetric: 398.4227 - lr: 1.6667e-04 - 13s/epoch - 64ms/step
Epoch 261/1000
2023-09-10 02:36:06.154 
Epoch 261/1000 
	 loss: 389.6524, MinusLogProbMetric: 389.6524, val_loss: 395.8323, val_MinusLogProbMetric: 395.8323

Epoch 261: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.6524 - MinusLogProbMetric: 389.6524 - val_loss: 395.8323 - val_MinusLogProbMetric: 395.8323 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 262/1000
2023-09-10 02:36:16.952 
Epoch 262/1000 
	 loss: 390.6705, MinusLogProbMetric: 390.6705, val_loss: 395.8316, val_MinusLogProbMetric: 395.8316

Epoch 262: val_loss did not improve from 394.63605
196/196 - 11s - loss: 390.6705 - MinusLogProbMetric: 390.6705 - val_loss: 395.8316 - val_MinusLogProbMetric: 395.8316 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 263/1000
2023-09-10 02:36:28.703 
Epoch 263/1000 
	 loss: 389.2178, MinusLogProbMetric: 389.2178, val_loss: 397.5174, val_MinusLogProbMetric: 397.5174

Epoch 263: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.2178 - MinusLogProbMetric: 389.2178 - val_loss: 397.5174 - val_MinusLogProbMetric: 397.5174 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 264/1000
2023-09-10 02:36:39.447 
Epoch 264/1000 
	 loss: 389.7425, MinusLogProbMetric: 389.7425, val_loss: 396.2374, val_MinusLogProbMetric: 396.2374

Epoch 264: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.7425 - MinusLogProbMetric: 389.7425 - val_loss: 396.2374 - val_MinusLogProbMetric: 396.2374 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 265/1000
2023-09-10 02:36:49.949 
Epoch 265/1000 
	 loss: 389.6422, MinusLogProbMetric: 389.6422, val_loss: 397.0117, val_MinusLogProbMetric: 397.0117

Epoch 265: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.6422 - MinusLogProbMetric: 389.6422 - val_loss: 397.0117 - val_MinusLogProbMetric: 397.0117 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 266/1000
2023-09-10 02:37:02.222 
Epoch 266/1000 
	 loss: 389.5935, MinusLogProbMetric: 389.5935, val_loss: 395.7770, val_MinusLogProbMetric: 395.7770

Epoch 266: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.5935 - MinusLogProbMetric: 389.5935 - val_loss: 395.7770 - val_MinusLogProbMetric: 395.7770 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 267/1000
2023-09-10 02:37:13.134 
Epoch 267/1000 
	 loss: 389.8737, MinusLogProbMetric: 389.8737, val_loss: 395.5807, val_MinusLogProbMetric: 395.5807

Epoch 267: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.8737 - MinusLogProbMetric: 389.8737 - val_loss: 395.5807 - val_MinusLogProbMetric: 395.5807 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 268/1000
2023-09-10 02:37:25.990 
Epoch 268/1000 
	 loss: 389.4808, MinusLogProbMetric: 389.4808, val_loss: 395.0119, val_MinusLogProbMetric: 395.0119

Epoch 268: val_loss did not improve from 394.63605
196/196 - 13s - loss: 389.4808 - MinusLogProbMetric: 389.4808 - val_loss: 395.0119 - val_MinusLogProbMetric: 395.0119 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 269/1000
2023-09-10 02:37:36.698 
Epoch 269/1000 
	 loss: 389.6524, MinusLogProbMetric: 389.6524, val_loss: 396.4241, val_MinusLogProbMetric: 396.4241

Epoch 269: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.6524 - MinusLogProbMetric: 389.6524 - val_loss: 396.4241 - val_MinusLogProbMetric: 396.4241 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 270/1000
2023-09-10 02:37:47.411 
Epoch 270/1000 
	 loss: 389.4553, MinusLogProbMetric: 389.4553, val_loss: 397.7023, val_MinusLogProbMetric: 397.7023

Epoch 270: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.4553 - MinusLogProbMetric: 389.4553 - val_loss: 397.7023 - val_MinusLogProbMetric: 397.7023 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 271/1000
2023-09-10 02:37:58.569 
Epoch 271/1000 
	 loss: 389.5252, MinusLogProbMetric: 389.5252, val_loss: 395.6462, val_MinusLogProbMetric: 395.6462

Epoch 271: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.5252 - MinusLogProbMetric: 389.5252 - val_loss: 395.6462 - val_MinusLogProbMetric: 395.6462 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 272/1000
2023-09-10 02:38:09.745 
Epoch 272/1000 
	 loss: 389.7366, MinusLogProbMetric: 389.7366, val_loss: 396.2490, val_MinusLogProbMetric: 396.2490

Epoch 272: val_loss did not improve from 394.63605
196/196 - 11s - loss: 389.7366 - MinusLogProbMetric: 389.7366 - val_loss: 396.2490 - val_MinusLogProbMetric: 396.2490 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 273/1000
2023-09-10 02:38:20.174 
Epoch 273/1000 
	 loss: 389.5078, MinusLogProbMetric: 389.5078, val_loss: 398.7307, val_MinusLogProbMetric: 398.7307

Epoch 273: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.5078 - MinusLogProbMetric: 389.5078 - val_loss: 398.7307 - val_MinusLogProbMetric: 398.7307 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 274/1000
2023-09-10 02:38:29.723 
Epoch 274/1000 
	 loss: 389.6476, MinusLogProbMetric: 389.6476, val_loss: 395.0769, val_MinusLogProbMetric: 395.0769

Epoch 274: val_loss did not improve from 394.63605
196/196 - 10s - loss: 389.6476 - MinusLogProbMetric: 389.6476 - val_loss: 395.0769 - val_MinusLogProbMetric: 395.0769 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 275/1000
2023-09-10 02:38:41.922 
Epoch 275/1000 
	 loss: 389.2200, MinusLogProbMetric: 389.2200, val_loss: 397.3915, val_MinusLogProbMetric: 397.3915

Epoch 275: val_loss did not improve from 394.63605
196/196 - 12s - loss: 389.2200 - MinusLogProbMetric: 389.2200 - val_loss: 397.3915 - val_MinusLogProbMetric: 397.3915 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 276/1000
2023-09-10 02:38:52.455 
Epoch 276/1000 
	 loss: 387.0392, MinusLogProbMetric: 387.0392, val_loss: 393.7409, val_MinusLogProbMetric: 393.7409

Epoch 276: val_loss improved from 394.63605 to 393.74091, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 387.0392 - MinusLogProbMetric: 387.0392 - val_loss: 393.7409 - val_MinusLogProbMetric: 393.7409 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 277/1000
2023-09-10 02:39:04.673 
Epoch 277/1000 
	 loss: 386.8092, MinusLogProbMetric: 386.8092, val_loss: 393.7115, val_MinusLogProbMetric: 393.7115

Epoch 277: val_loss improved from 393.74091 to 393.71155, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 386.8092 - MinusLogProbMetric: 386.8092 - val_loss: 393.7115 - val_MinusLogProbMetric: 393.7115 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 278/1000
2023-09-10 02:39:16.958 
Epoch 278/1000 
	 loss: 386.9066, MinusLogProbMetric: 386.9066, val_loss: 394.3270, val_MinusLogProbMetric: 394.3270

Epoch 278: val_loss did not improve from 393.71155
196/196 - 12s - loss: 386.9066 - MinusLogProbMetric: 386.9066 - val_loss: 394.3270 - val_MinusLogProbMetric: 394.3270 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 279/1000
2023-09-10 02:39:29.224 
Epoch 279/1000 
	 loss: 387.0219, MinusLogProbMetric: 387.0219, val_loss: 393.7277, val_MinusLogProbMetric: 393.7277

Epoch 279: val_loss did not improve from 393.71155
196/196 - 12s - loss: 387.0219 - MinusLogProbMetric: 387.0219 - val_loss: 393.7277 - val_MinusLogProbMetric: 393.7277 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 280/1000
2023-09-10 02:39:41.952 
Epoch 280/1000 
	 loss: 387.0077, MinusLogProbMetric: 387.0077, val_loss: 393.9431, val_MinusLogProbMetric: 393.9431

Epoch 280: val_loss did not improve from 393.71155
196/196 - 13s - loss: 387.0077 - MinusLogProbMetric: 387.0077 - val_loss: 393.9431 - val_MinusLogProbMetric: 393.9431 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 281/1000
2023-09-10 02:39:54.436 
Epoch 281/1000 
	 loss: 387.0288, MinusLogProbMetric: 387.0288, val_loss: 393.8856, val_MinusLogProbMetric: 393.8856

Epoch 281: val_loss did not improve from 393.71155
196/196 - 12s - loss: 387.0288 - MinusLogProbMetric: 387.0288 - val_loss: 393.8856 - val_MinusLogProbMetric: 393.8856 - lr: 8.3333e-05 - 12s/epoch - 64ms/step
Epoch 282/1000
2023-09-10 02:40:05.536 
Epoch 282/1000 
	 loss: 386.8987, MinusLogProbMetric: 386.8987, val_loss: 393.6911, val_MinusLogProbMetric: 393.6911

Epoch 282: val_loss improved from 393.71155 to 393.69107, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 386.8987 - MinusLogProbMetric: 386.8987 - val_loss: 393.6911 - val_MinusLogProbMetric: 393.6911 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 283/1000
2023-09-10 02:40:17.081 
Epoch 283/1000 
	 loss: 387.1932, MinusLogProbMetric: 387.1932, val_loss: 393.9085, val_MinusLogProbMetric: 393.9085

Epoch 283: val_loss did not improve from 393.69107
196/196 - 11s - loss: 387.1932 - MinusLogProbMetric: 387.1932 - val_loss: 393.9085 - val_MinusLogProbMetric: 393.9085 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 284/1000
2023-09-10 02:40:27.914 
Epoch 284/1000 
	 loss: 387.0822, MinusLogProbMetric: 387.0822, val_loss: 393.9193, val_MinusLogProbMetric: 393.9193

Epoch 284: val_loss did not improve from 393.69107
196/196 - 11s - loss: 387.0822 - MinusLogProbMetric: 387.0822 - val_loss: 393.9193 - val_MinusLogProbMetric: 393.9193 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 285/1000
2023-09-10 02:40:40.349 
Epoch 285/1000 
	 loss: 387.1081, MinusLogProbMetric: 387.1081, val_loss: 394.6164, val_MinusLogProbMetric: 394.6164

Epoch 285: val_loss did not improve from 393.69107
196/196 - 12s - loss: 387.1081 - MinusLogProbMetric: 387.1081 - val_loss: 394.6164 - val_MinusLogProbMetric: 394.6164 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 286/1000
2023-09-10 02:40:51.137 
Epoch 286/1000 
	 loss: 386.8793, MinusLogProbMetric: 386.8793, val_loss: 394.4729, val_MinusLogProbMetric: 394.4729

Epoch 286: val_loss did not improve from 393.69107
196/196 - 11s - loss: 386.8793 - MinusLogProbMetric: 386.8793 - val_loss: 394.4729 - val_MinusLogProbMetric: 394.4729 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 287/1000
2023-09-10 02:41:02.482 
Epoch 287/1000 
	 loss: 386.9673, MinusLogProbMetric: 386.9673, val_loss: 393.6769, val_MinusLogProbMetric: 393.6769

Epoch 287: val_loss improved from 393.69107 to 393.67688, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 386.9673 - MinusLogProbMetric: 386.9673 - val_loss: 393.6769 - val_MinusLogProbMetric: 393.6769 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 288/1000
2023-09-10 02:41:13.084 
Epoch 288/1000 
	 loss: 386.9694, MinusLogProbMetric: 386.9694, val_loss: 394.0035, val_MinusLogProbMetric: 394.0035

Epoch 288: val_loss did not improve from 393.67688
196/196 - 10s - loss: 386.9694 - MinusLogProbMetric: 386.9694 - val_loss: 394.0035 - val_MinusLogProbMetric: 394.0035 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 289/1000
2023-09-10 02:41:25.311 
Epoch 289/1000 
	 loss: 386.8900, MinusLogProbMetric: 386.8900, val_loss: 394.1637, val_MinusLogProbMetric: 394.1637

Epoch 289: val_loss did not improve from 393.67688
196/196 - 12s - loss: 386.8900 - MinusLogProbMetric: 386.8900 - val_loss: 394.1637 - val_MinusLogProbMetric: 394.1637 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 290/1000
2023-09-10 02:41:36.401 
Epoch 290/1000 
	 loss: 386.9141, MinusLogProbMetric: 386.9141, val_loss: 394.0439, val_MinusLogProbMetric: 394.0439

Epoch 290: val_loss did not improve from 393.67688
196/196 - 11s - loss: 386.9141 - MinusLogProbMetric: 386.9141 - val_loss: 394.0439 - val_MinusLogProbMetric: 394.0439 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 291/1000
2023-09-10 02:41:47.808 
Epoch 291/1000 
	 loss: 386.9008, MinusLogProbMetric: 386.9008, val_loss: 393.7999, val_MinusLogProbMetric: 393.7999

Epoch 291: val_loss did not improve from 393.67688
196/196 - 11s - loss: 386.9008 - MinusLogProbMetric: 386.9008 - val_loss: 393.7999 - val_MinusLogProbMetric: 393.7999 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 292/1000
2023-09-10 02:41:59.511 
Epoch 292/1000 
	 loss: 386.8507, MinusLogProbMetric: 386.8507, val_loss: 394.4056, val_MinusLogProbMetric: 394.4056

Epoch 292: val_loss did not improve from 393.67688
196/196 - 12s - loss: 386.8507 - MinusLogProbMetric: 386.8507 - val_loss: 394.4056 - val_MinusLogProbMetric: 394.4056 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 293/1000
2023-09-10 02:42:09.739 
Epoch 293/1000 
	 loss: 386.8905, MinusLogProbMetric: 386.8905, val_loss: 394.7035, val_MinusLogProbMetric: 394.7035

Epoch 293: val_loss did not improve from 393.67688
196/196 - 10s - loss: 386.8905 - MinusLogProbMetric: 386.8905 - val_loss: 394.7035 - val_MinusLogProbMetric: 394.7035 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 294/1000
2023-09-10 02:42:21.693 
Epoch 294/1000 
	 loss: 387.0856, MinusLogProbMetric: 387.0856, val_loss: 394.7511, val_MinusLogProbMetric: 394.7511

Epoch 294: val_loss did not improve from 393.67688
196/196 - 12s - loss: 387.0856 - MinusLogProbMetric: 387.0856 - val_loss: 394.7511 - val_MinusLogProbMetric: 394.7511 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 295/1000
2023-09-10 02:42:31.392 
Epoch 295/1000 
	 loss: 386.9366, MinusLogProbMetric: 386.9366, val_loss: 393.6530, val_MinusLogProbMetric: 393.6530

Epoch 295: val_loss improved from 393.67688 to 393.65305, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 10s - loss: 386.9366 - MinusLogProbMetric: 386.9366 - val_loss: 393.6530 - val_MinusLogProbMetric: 393.6530 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 296/1000
2023-09-10 02:42:43.665 
Epoch 296/1000 
	 loss: 387.0803, MinusLogProbMetric: 387.0803, val_loss: 394.5066, val_MinusLogProbMetric: 394.5066

Epoch 296: val_loss did not improve from 393.65305
196/196 - 12s - loss: 387.0803 - MinusLogProbMetric: 387.0803 - val_loss: 394.5066 - val_MinusLogProbMetric: 394.5066 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 297/1000
2023-09-10 02:42:53.718 
Epoch 297/1000 
	 loss: 386.8978, MinusLogProbMetric: 386.8978, val_loss: 394.1525, val_MinusLogProbMetric: 394.1525

Epoch 297: val_loss did not improve from 393.65305
196/196 - 10s - loss: 386.8978 - MinusLogProbMetric: 386.8978 - val_loss: 394.1525 - val_MinusLogProbMetric: 394.1525 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 298/1000
2023-09-10 02:43:05.880 
Epoch 298/1000 
	 loss: 387.0124, MinusLogProbMetric: 387.0124, val_loss: 395.0002, val_MinusLogProbMetric: 395.0002

Epoch 298: val_loss did not improve from 393.65305
196/196 - 12s - loss: 387.0124 - MinusLogProbMetric: 387.0124 - val_loss: 395.0002 - val_MinusLogProbMetric: 395.0002 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 299/1000
2023-09-10 02:43:16.894 
Epoch 299/1000 
	 loss: 386.9904, MinusLogProbMetric: 386.9904, val_loss: 395.4513, val_MinusLogProbMetric: 395.4513

Epoch 299: val_loss did not improve from 393.65305
196/196 - 11s - loss: 386.9904 - MinusLogProbMetric: 386.9904 - val_loss: 395.4513 - val_MinusLogProbMetric: 395.4513 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 300/1000
2023-09-10 02:43:27.888 
Epoch 300/1000 
	 loss: 387.0472, MinusLogProbMetric: 387.0472, val_loss: 394.3355, val_MinusLogProbMetric: 394.3355

Epoch 300: val_loss did not improve from 393.65305
196/196 - 11s - loss: 387.0472 - MinusLogProbMetric: 387.0472 - val_loss: 394.3355 - val_MinusLogProbMetric: 394.3355 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 301/1000
2023-09-10 02:43:37.693 
Epoch 301/1000 
	 loss: 386.9798, MinusLogProbMetric: 386.9798, val_loss: 394.5476, val_MinusLogProbMetric: 394.5476

Epoch 301: val_loss did not improve from 393.65305
196/196 - 10s - loss: 386.9798 - MinusLogProbMetric: 386.9798 - val_loss: 394.5476 - val_MinusLogProbMetric: 394.5476 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 302/1000
2023-09-10 02:43:46.603 
Epoch 302/1000 
	 loss: 386.9992, MinusLogProbMetric: 386.9992, val_loss: 393.8929, val_MinusLogProbMetric: 393.8929

Epoch 302: val_loss did not improve from 393.65305
196/196 - 9s - loss: 386.9992 - MinusLogProbMetric: 386.9992 - val_loss: 393.8929 - val_MinusLogProbMetric: 393.8929 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 303/1000
2023-09-10 02:43:58.611 
Epoch 303/1000 
	 loss: 386.8813, MinusLogProbMetric: 386.8813, val_loss: 395.3879, val_MinusLogProbMetric: 395.3879

Epoch 303: val_loss did not improve from 393.65305
196/196 - 12s - loss: 386.8813 - MinusLogProbMetric: 386.8813 - val_loss: 395.3879 - val_MinusLogProbMetric: 395.3879 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 304/1000
2023-09-10 02:44:08.217 
Epoch 304/1000 
	 loss: 386.9696, MinusLogProbMetric: 386.9696, val_loss: 393.8347, val_MinusLogProbMetric: 393.8347

Epoch 304: val_loss did not improve from 393.65305
196/196 - 10s - loss: 386.9696 - MinusLogProbMetric: 386.9696 - val_loss: 393.8347 - val_MinusLogProbMetric: 393.8347 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 305/1000
2023-09-10 02:44:20.166 
Epoch 305/1000 
	 loss: 386.8790, MinusLogProbMetric: 386.8790, val_loss: 394.3794, val_MinusLogProbMetric: 394.3794

Epoch 305: val_loss did not improve from 393.65305
196/196 - 12s - loss: 386.8790 - MinusLogProbMetric: 386.8790 - val_loss: 394.3794 - val_MinusLogProbMetric: 394.3794 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 306/1000
2023-09-10 02:44:30.956 
Epoch 306/1000 
	 loss: 386.9219, MinusLogProbMetric: 386.9219, val_loss: 393.9538, val_MinusLogProbMetric: 393.9538

Epoch 306: val_loss did not improve from 393.65305
196/196 - 11s - loss: 386.9219 - MinusLogProbMetric: 386.9219 - val_loss: 393.9538 - val_MinusLogProbMetric: 393.9538 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 307/1000
2023-09-10 02:44:42.488 
Epoch 307/1000 
	 loss: 386.8862, MinusLogProbMetric: 386.8862, val_loss: 394.1087, val_MinusLogProbMetric: 394.1087

Epoch 307: val_loss did not improve from 393.65305
196/196 - 12s - loss: 386.8862 - MinusLogProbMetric: 386.8862 - val_loss: 394.1087 - val_MinusLogProbMetric: 394.1087 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 308/1000
2023-09-10 02:44:52.986 
Epoch 308/1000 
	 loss: 386.9063, MinusLogProbMetric: 386.9063, val_loss: 393.5852, val_MinusLogProbMetric: 393.5852

Epoch 308: val_loss improved from 393.65305 to 393.58521, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 386.9063 - MinusLogProbMetric: 386.9063 - val_loss: 393.5852 - val_MinusLogProbMetric: 393.5852 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 309/1000
2023-09-10 02:45:06.648 
Epoch 309/1000 
	 loss: 386.8502, MinusLogProbMetric: 386.8502, val_loss: 394.8970, val_MinusLogProbMetric: 394.8970

Epoch 309: val_loss did not improve from 393.58521
196/196 - 13s - loss: 386.8502 - MinusLogProbMetric: 386.8502 - val_loss: 394.8970 - val_MinusLogProbMetric: 394.8970 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 310/1000
2023-09-10 02:45:16.511 
Epoch 310/1000 
	 loss: 386.8170, MinusLogProbMetric: 386.8170, val_loss: 393.5613, val_MinusLogProbMetric: 393.5613

Epoch 310: val_loss improved from 393.58521 to 393.56128, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 10s - loss: 386.8170 - MinusLogProbMetric: 386.8170 - val_loss: 393.5613 - val_MinusLogProbMetric: 393.5613 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 311/1000
2023-09-10 02:45:29.034 
Epoch 311/1000 
	 loss: 387.0103, MinusLogProbMetric: 387.0103, val_loss: 393.7156, val_MinusLogProbMetric: 393.7156

Epoch 311: val_loss did not improve from 393.56128
196/196 - 12s - loss: 387.0103 - MinusLogProbMetric: 387.0103 - val_loss: 393.7156 - val_MinusLogProbMetric: 393.7156 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 312/1000
2023-09-10 02:45:39.742 
Epoch 312/1000 
	 loss: 386.8234, MinusLogProbMetric: 386.8234, val_loss: 394.0874, val_MinusLogProbMetric: 394.0874

Epoch 312: val_loss did not improve from 393.56128
196/196 - 11s - loss: 386.8234 - MinusLogProbMetric: 386.8234 - val_loss: 394.0874 - val_MinusLogProbMetric: 394.0874 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 313/1000
2023-09-10 02:45:52.057 
Epoch 313/1000 
	 loss: 386.9856, MinusLogProbMetric: 386.9856, val_loss: 394.0385, val_MinusLogProbMetric: 394.0385

Epoch 313: val_loss did not improve from 393.56128
196/196 - 12s - loss: 386.9856 - MinusLogProbMetric: 386.9856 - val_loss: 394.0385 - val_MinusLogProbMetric: 394.0385 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 314/1000
2023-09-10 02:46:03.015 
Epoch 314/1000 
	 loss: 386.7818, MinusLogProbMetric: 386.7818, val_loss: 394.0690, val_MinusLogProbMetric: 394.0690

Epoch 314: val_loss did not improve from 393.56128
196/196 - 11s - loss: 386.7818 - MinusLogProbMetric: 386.7818 - val_loss: 394.0690 - val_MinusLogProbMetric: 394.0690 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 315/1000
2023-09-10 02:46:12.919 
Epoch 315/1000 
	 loss: 386.8876, MinusLogProbMetric: 386.8876, val_loss: 394.0576, val_MinusLogProbMetric: 394.0576

Epoch 315: val_loss did not improve from 393.56128
196/196 - 10s - loss: 386.8876 - MinusLogProbMetric: 386.8876 - val_loss: 394.0576 - val_MinusLogProbMetric: 394.0576 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 316/1000
2023-09-10 02:46:24.719 
Epoch 316/1000 
	 loss: 387.0401, MinusLogProbMetric: 387.0401, val_loss: 393.5958, val_MinusLogProbMetric: 393.5958

Epoch 316: val_loss did not improve from 393.56128
196/196 - 12s - loss: 387.0401 - MinusLogProbMetric: 387.0401 - val_loss: 393.5958 - val_MinusLogProbMetric: 393.5958 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 317/1000
2023-09-10 02:46:35.043 
Epoch 317/1000 
	 loss: 386.9540, MinusLogProbMetric: 386.9540, val_loss: 394.6336, val_MinusLogProbMetric: 394.6336

Epoch 317: val_loss did not improve from 393.56128
196/196 - 10s - loss: 386.9540 - MinusLogProbMetric: 386.9540 - val_loss: 394.6336 - val_MinusLogProbMetric: 394.6336 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 318/1000
2023-09-10 02:46:46.503 
Epoch 318/1000 
	 loss: 386.7291, MinusLogProbMetric: 386.7291, val_loss: 394.3115, val_MinusLogProbMetric: 394.3115

Epoch 318: val_loss did not improve from 393.56128
196/196 - 11s - loss: 386.7291 - MinusLogProbMetric: 386.7291 - val_loss: 394.3115 - val_MinusLogProbMetric: 394.3115 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 319/1000
2023-09-10 02:46:56.641 
Epoch 319/1000 
	 loss: 386.9280, MinusLogProbMetric: 386.9280, val_loss: 393.8666, val_MinusLogProbMetric: 393.8666

Epoch 319: val_loss did not improve from 393.56128
196/196 - 10s - loss: 386.9280 - MinusLogProbMetric: 386.9280 - val_loss: 393.8666 - val_MinusLogProbMetric: 393.8666 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 320/1000
2023-09-10 02:47:09.122 
Epoch 320/1000 
	 loss: 386.6871, MinusLogProbMetric: 386.6871, val_loss: 393.9156, val_MinusLogProbMetric: 393.9156

Epoch 320: val_loss did not improve from 393.56128
196/196 - 12s - loss: 386.6871 - MinusLogProbMetric: 386.6871 - val_loss: 393.9156 - val_MinusLogProbMetric: 393.9156 - lr: 8.3333e-05 - 12s/epoch - 64ms/step
Epoch 321/1000
2023-09-10 02:47:19.508 
Epoch 321/1000 
	 loss: 386.9048, MinusLogProbMetric: 386.9048, val_loss: 393.9170, val_MinusLogProbMetric: 393.9170

Epoch 321: val_loss did not improve from 393.56128
196/196 - 10s - loss: 386.9048 - MinusLogProbMetric: 386.9048 - val_loss: 393.9170 - val_MinusLogProbMetric: 393.9170 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 322/1000
2023-09-10 02:47:31.694 
Epoch 322/1000 
	 loss: 386.8127, MinusLogProbMetric: 386.8127, val_loss: 393.8070, val_MinusLogProbMetric: 393.8070

Epoch 322: val_loss did not improve from 393.56128
196/196 - 12s - loss: 386.8127 - MinusLogProbMetric: 386.8127 - val_loss: 393.8070 - val_MinusLogProbMetric: 393.8070 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 323/1000
2023-09-10 02:47:41.965 
Epoch 323/1000 
	 loss: 386.7001, MinusLogProbMetric: 386.7001, val_loss: 395.0105, val_MinusLogProbMetric: 395.0105

Epoch 323: val_loss did not improve from 393.56128
196/196 - 10s - loss: 386.7001 - MinusLogProbMetric: 386.7001 - val_loss: 395.0105 - val_MinusLogProbMetric: 395.0105 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 324/1000
2023-09-10 02:47:55.234 
Epoch 324/1000 
	 loss: 386.7646, MinusLogProbMetric: 386.7646, val_loss: 393.9636, val_MinusLogProbMetric: 393.9636

Epoch 324: val_loss did not improve from 393.56128
196/196 - 13s - loss: 386.7646 - MinusLogProbMetric: 386.7646 - val_loss: 393.9636 - val_MinusLogProbMetric: 393.9636 - lr: 8.3333e-05 - 13s/epoch - 68ms/step
Epoch 325/1000
2023-09-10 02:48:05.523 
Epoch 325/1000 
	 loss: 386.8216, MinusLogProbMetric: 386.8216, val_loss: 393.9309, val_MinusLogProbMetric: 393.9309

Epoch 325: val_loss did not improve from 393.56128
196/196 - 10s - loss: 386.8216 - MinusLogProbMetric: 386.8216 - val_loss: 393.9309 - val_MinusLogProbMetric: 393.9309 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 326/1000
2023-09-10 02:48:18.041 
Epoch 326/1000 
	 loss: 386.7925, MinusLogProbMetric: 386.7925, val_loss: 394.4460, val_MinusLogProbMetric: 394.4460

Epoch 326: val_loss did not improve from 393.56128
196/196 - 12s - loss: 386.7925 - MinusLogProbMetric: 386.7925 - val_loss: 394.4460 - val_MinusLogProbMetric: 394.4460 - lr: 8.3333e-05 - 12s/epoch - 64ms/step
Epoch 327/1000
2023-09-10 02:48:28.029 
Epoch 327/1000 
	 loss: 386.6625, MinusLogProbMetric: 386.6625, val_loss: 394.0454, val_MinusLogProbMetric: 394.0454

Epoch 327: val_loss did not improve from 393.56128
196/196 - 10s - loss: 386.6625 - MinusLogProbMetric: 386.6625 - val_loss: 394.0454 - val_MinusLogProbMetric: 394.0454 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 328/1000
2023-09-10 02:48:40.059 
Epoch 328/1000 
	 loss: 386.5947, MinusLogProbMetric: 386.5947, val_loss: 393.5145, val_MinusLogProbMetric: 393.5145

Epoch 328: val_loss improved from 393.56128 to 393.51453, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 386.5947 - MinusLogProbMetric: 386.5947 - val_loss: 393.5145 - val_MinusLogProbMetric: 393.5145 - lr: 8.3333e-05 - 13s/epoch - 64ms/step
Epoch 329/1000
2023-09-10 02:48:51.319 
Epoch 329/1000 
	 loss: 386.7462, MinusLogProbMetric: 386.7462, val_loss: 394.0094, val_MinusLogProbMetric: 394.0094

Epoch 329: val_loss did not improve from 393.51453
196/196 - 11s - loss: 386.7462 - MinusLogProbMetric: 386.7462 - val_loss: 394.0094 - val_MinusLogProbMetric: 394.0094 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 330/1000
2023-09-10 02:49:04.064 
Epoch 330/1000 
	 loss: 386.5722, MinusLogProbMetric: 386.5722, val_loss: 394.5723, val_MinusLogProbMetric: 394.5723

Epoch 330: val_loss did not improve from 393.51453
196/196 - 13s - loss: 386.5722 - MinusLogProbMetric: 386.5722 - val_loss: 394.5723 - val_MinusLogProbMetric: 394.5723 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 331/1000
2023-09-10 02:49:14.713 
Epoch 331/1000 
	 loss: 386.7256, MinusLogProbMetric: 386.7256, val_loss: 393.4639, val_MinusLogProbMetric: 393.4639

Epoch 331: val_loss improved from 393.51453 to 393.46387, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 386.7256 - MinusLogProbMetric: 386.7256 - val_loss: 393.4639 - val_MinusLogProbMetric: 393.4639 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 332/1000
2023-09-10 02:49:26.791 
Epoch 332/1000 
	 loss: 386.8001, MinusLogProbMetric: 386.8001, val_loss: 393.7436, val_MinusLogProbMetric: 393.7436

Epoch 332: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.8001 - MinusLogProbMetric: 386.8001 - val_loss: 393.7436 - val_MinusLogProbMetric: 393.7436 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 333/1000
2023-09-10 02:49:37.242 
Epoch 333/1000 
	 loss: 386.7477, MinusLogProbMetric: 386.7477, val_loss: 393.8528, val_MinusLogProbMetric: 393.8528

Epoch 333: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.7477 - MinusLogProbMetric: 386.7477 - val_loss: 393.8528 - val_MinusLogProbMetric: 393.8528 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 334/1000
2023-09-10 02:49:48.773 
Epoch 334/1000 
	 loss: 386.6017, MinusLogProbMetric: 386.6017, val_loss: 393.9579, val_MinusLogProbMetric: 393.9579

Epoch 334: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.6017 - MinusLogProbMetric: 386.6017 - val_loss: 393.9579 - val_MinusLogProbMetric: 393.9579 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 335/1000
2023-09-10 02:50:00.209 
Epoch 335/1000 
	 loss: 386.8103, MinusLogProbMetric: 386.8103, val_loss: 394.7568, val_MinusLogProbMetric: 394.7568

Epoch 335: val_loss did not improve from 393.46387
196/196 - 11s - loss: 386.8103 - MinusLogProbMetric: 386.8103 - val_loss: 394.7568 - val_MinusLogProbMetric: 394.7568 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 336/1000
2023-09-10 02:50:11.878 
Epoch 336/1000 
	 loss: 386.6571, MinusLogProbMetric: 386.6571, val_loss: 394.1176, val_MinusLogProbMetric: 394.1176

Epoch 336: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.6571 - MinusLogProbMetric: 386.6571 - val_loss: 394.1176 - val_MinusLogProbMetric: 394.1176 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 337/1000
2023-09-10 02:50:22.037 
Epoch 337/1000 
	 loss: 386.8043, MinusLogProbMetric: 386.8043, val_loss: 397.7480, val_MinusLogProbMetric: 397.7480

Epoch 337: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.8043 - MinusLogProbMetric: 386.8043 - val_loss: 397.7480 - val_MinusLogProbMetric: 397.7480 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 338/1000
2023-09-10 02:50:33.983 
Epoch 338/1000 
	 loss: 386.6207, MinusLogProbMetric: 386.6207, val_loss: 394.1379, val_MinusLogProbMetric: 394.1379

Epoch 338: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.6207 - MinusLogProbMetric: 386.6207 - val_loss: 394.1379 - val_MinusLogProbMetric: 394.1379 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 339/1000
2023-09-10 02:50:44.713 
Epoch 339/1000 
	 loss: 386.7820, MinusLogProbMetric: 386.7820, val_loss: 394.1452, val_MinusLogProbMetric: 394.1452

Epoch 339: val_loss did not improve from 393.46387
196/196 - 11s - loss: 386.7820 - MinusLogProbMetric: 386.7820 - val_loss: 394.1452 - val_MinusLogProbMetric: 394.1452 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 340/1000
2023-09-10 02:50:56.632 
Epoch 340/1000 
	 loss: 386.6594, MinusLogProbMetric: 386.6594, val_loss: 394.8648, val_MinusLogProbMetric: 394.8648

Epoch 340: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.6594 - MinusLogProbMetric: 386.6594 - val_loss: 394.8648 - val_MinusLogProbMetric: 394.8648 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 341/1000
2023-09-10 02:51:05.976 
Epoch 341/1000 
	 loss: 386.8256, MinusLogProbMetric: 386.8256, val_loss: 395.3714, val_MinusLogProbMetric: 395.3714

Epoch 341: val_loss did not improve from 393.46387
196/196 - 9s - loss: 386.8256 - MinusLogProbMetric: 386.8256 - val_loss: 395.3714 - val_MinusLogProbMetric: 395.3714 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 342/1000
2023-09-10 02:51:17.646 
Epoch 342/1000 
	 loss: 386.7320, MinusLogProbMetric: 386.7320, val_loss: 393.9357, val_MinusLogProbMetric: 393.9357

Epoch 342: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.7320 - MinusLogProbMetric: 386.7320 - val_loss: 393.9357 - val_MinusLogProbMetric: 393.9357 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 343/1000
2023-09-10 02:51:27.343 
Epoch 343/1000 
	 loss: 386.7116, MinusLogProbMetric: 386.7116, val_loss: 394.0896, val_MinusLogProbMetric: 394.0896

Epoch 343: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.7116 - MinusLogProbMetric: 386.7116 - val_loss: 394.0896 - val_MinusLogProbMetric: 394.0896 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 344/1000
2023-09-10 02:51:38.311 
Epoch 344/1000 
	 loss: 386.7507, MinusLogProbMetric: 386.7507, val_loss: 393.5937, val_MinusLogProbMetric: 393.5937

Epoch 344: val_loss did not improve from 393.46387
196/196 - 11s - loss: 386.7507 - MinusLogProbMetric: 386.7507 - val_loss: 393.5937 - val_MinusLogProbMetric: 393.5937 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 345/1000
2023-09-10 02:51:48.251 
Epoch 345/1000 
	 loss: 386.7739, MinusLogProbMetric: 386.7739, val_loss: 397.7166, val_MinusLogProbMetric: 397.7166

Epoch 345: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.7739 - MinusLogProbMetric: 386.7739 - val_loss: 397.7166 - val_MinusLogProbMetric: 397.7166 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 346/1000
2023-09-10 02:51:59.523 
Epoch 346/1000 
	 loss: 386.8591, MinusLogProbMetric: 386.8591, val_loss: 394.0713, val_MinusLogProbMetric: 394.0713

Epoch 346: val_loss did not improve from 393.46387
196/196 - 11s - loss: 386.8591 - MinusLogProbMetric: 386.8591 - val_loss: 394.0713 - val_MinusLogProbMetric: 394.0713 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 347/1000
2023-09-10 02:52:09.957 
Epoch 347/1000 
	 loss: 386.6193, MinusLogProbMetric: 386.6193, val_loss: 395.0330, val_MinusLogProbMetric: 395.0330

Epoch 347: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.6193 - MinusLogProbMetric: 386.6193 - val_loss: 395.0330 - val_MinusLogProbMetric: 395.0330 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 348/1000
2023-09-10 02:52:20.318 
Epoch 348/1000 
	 loss: 386.6555, MinusLogProbMetric: 386.6555, val_loss: 394.2125, val_MinusLogProbMetric: 394.2125

Epoch 348: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.6555 - MinusLogProbMetric: 386.6555 - val_loss: 394.2125 - val_MinusLogProbMetric: 394.2125 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 349/1000
2023-09-10 02:52:31.649 
Epoch 349/1000 
	 loss: 386.7321, MinusLogProbMetric: 386.7321, val_loss: 393.9158, val_MinusLogProbMetric: 393.9158

Epoch 349: val_loss did not improve from 393.46387
196/196 - 11s - loss: 386.7321 - MinusLogProbMetric: 386.7321 - val_loss: 393.9158 - val_MinusLogProbMetric: 393.9158 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 350/1000
2023-09-10 02:52:41.777 
Epoch 350/1000 
	 loss: 386.8649, MinusLogProbMetric: 386.8649, val_loss: 393.9490, val_MinusLogProbMetric: 393.9490

Epoch 350: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.8649 - MinusLogProbMetric: 386.8649 - val_loss: 393.9490 - val_MinusLogProbMetric: 393.9490 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 351/1000
2023-09-10 02:52:53.674 
Epoch 351/1000 
	 loss: 386.6394, MinusLogProbMetric: 386.6394, val_loss: 395.1877, val_MinusLogProbMetric: 395.1877

Epoch 351: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.6394 - MinusLogProbMetric: 386.6394 - val_loss: 395.1877 - val_MinusLogProbMetric: 395.1877 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 352/1000
2023-09-10 02:53:03.637 
Epoch 352/1000 
	 loss: 386.6189, MinusLogProbMetric: 386.6189, val_loss: 393.9336, val_MinusLogProbMetric: 393.9336

Epoch 352: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.6189 - MinusLogProbMetric: 386.6189 - val_loss: 393.9336 - val_MinusLogProbMetric: 393.9336 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 353/1000
2023-09-10 02:53:14.665 
Epoch 353/1000 
	 loss: 386.6454, MinusLogProbMetric: 386.6454, val_loss: 394.2523, val_MinusLogProbMetric: 394.2523

Epoch 353: val_loss did not improve from 393.46387
196/196 - 11s - loss: 386.6454 - MinusLogProbMetric: 386.6454 - val_loss: 394.2523 - val_MinusLogProbMetric: 394.2523 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 354/1000
2023-09-10 02:53:23.882 
Epoch 354/1000 
	 loss: 386.9437, MinusLogProbMetric: 386.9437, val_loss: 394.8358, val_MinusLogProbMetric: 394.8358

Epoch 354: val_loss did not improve from 393.46387
196/196 - 9s - loss: 386.9437 - MinusLogProbMetric: 386.9437 - val_loss: 394.8358 - val_MinusLogProbMetric: 394.8358 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 355/1000
2023-09-10 02:53:35.645 
Epoch 355/1000 
	 loss: 386.4814, MinusLogProbMetric: 386.4814, val_loss: 393.8815, val_MinusLogProbMetric: 393.8815

Epoch 355: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.4814 - MinusLogProbMetric: 386.4814 - val_loss: 393.8815 - val_MinusLogProbMetric: 393.8815 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 356/1000
2023-09-10 02:53:45.545 
Epoch 356/1000 
	 loss: 386.3078, MinusLogProbMetric: 386.3078, val_loss: 394.8471, val_MinusLogProbMetric: 394.8471

Epoch 356: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.3078 - MinusLogProbMetric: 386.3078 - val_loss: 394.8471 - val_MinusLogProbMetric: 394.8471 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 357/1000
2023-09-10 02:53:57.502 
Epoch 357/1000 
	 loss: 386.9072, MinusLogProbMetric: 386.9072, val_loss: 394.0960, val_MinusLogProbMetric: 394.0960

Epoch 357: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.9072 - MinusLogProbMetric: 386.9072 - val_loss: 394.0960 - val_MinusLogProbMetric: 394.0960 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 358/1000
2023-09-10 02:54:07.707 
Epoch 358/1000 
	 loss: 386.3221, MinusLogProbMetric: 386.3221, val_loss: 394.0479, val_MinusLogProbMetric: 394.0479

Epoch 358: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.3221 - MinusLogProbMetric: 386.3221 - val_loss: 394.0479 - val_MinusLogProbMetric: 394.0479 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 359/1000
2023-09-10 02:54:19.428 
Epoch 359/1000 
	 loss: 386.5334, MinusLogProbMetric: 386.5334, val_loss: 393.9239, val_MinusLogProbMetric: 393.9239

Epoch 359: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.5334 - MinusLogProbMetric: 386.5334 - val_loss: 393.9239 - val_MinusLogProbMetric: 393.9239 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 360/1000
2023-09-10 02:54:28.513 
Epoch 360/1000 
	 loss: 386.5181, MinusLogProbMetric: 386.5181, val_loss: 394.3647, val_MinusLogProbMetric: 394.3647

Epoch 360: val_loss did not improve from 393.46387
196/196 - 9s - loss: 386.5181 - MinusLogProbMetric: 386.5181 - val_loss: 394.3647 - val_MinusLogProbMetric: 394.3647 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 361/1000
2023-09-10 02:54:40.502 
Epoch 361/1000 
	 loss: 386.5181, MinusLogProbMetric: 386.5181, val_loss: 394.3419, val_MinusLogProbMetric: 394.3419

Epoch 361: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.5181 - MinusLogProbMetric: 386.5181 - val_loss: 394.3419 - val_MinusLogProbMetric: 394.3419 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 362/1000
2023-09-10 02:54:49.991 
Epoch 362/1000 
	 loss: 386.4066, MinusLogProbMetric: 386.4066, val_loss: 393.6688, val_MinusLogProbMetric: 393.6688

Epoch 362: val_loss did not improve from 393.46387
196/196 - 9s - loss: 386.4066 - MinusLogProbMetric: 386.4066 - val_loss: 393.6688 - val_MinusLogProbMetric: 393.6688 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 363/1000
2023-09-10 02:55:01.789 
Epoch 363/1000 
	 loss: 386.6226, MinusLogProbMetric: 386.6226, val_loss: 394.0268, val_MinusLogProbMetric: 394.0268

Epoch 363: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.6226 - MinusLogProbMetric: 386.6226 - val_loss: 394.0268 - val_MinusLogProbMetric: 394.0268 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 364/1000
2023-09-10 02:55:11.497 
Epoch 364/1000 
	 loss: 386.6339, MinusLogProbMetric: 386.6339, val_loss: 393.7668, val_MinusLogProbMetric: 393.7668

Epoch 364: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.6339 - MinusLogProbMetric: 386.6339 - val_loss: 393.7668 - val_MinusLogProbMetric: 393.7668 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 365/1000
2023-09-10 02:55:23.420 
Epoch 365/1000 
	 loss: 386.4846, MinusLogProbMetric: 386.4846, val_loss: 393.7201, val_MinusLogProbMetric: 393.7201

Epoch 365: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.4846 - MinusLogProbMetric: 386.4846 - val_loss: 393.7201 - val_MinusLogProbMetric: 393.7201 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 366/1000
2023-09-10 02:55:32.062 
Epoch 366/1000 
	 loss: 386.5404, MinusLogProbMetric: 386.5404, val_loss: 395.8152, val_MinusLogProbMetric: 395.8152

Epoch 366: val_loss did not improve from 393.46387
196/196 - 9s - loss: 386.5404 - MinusLogProbMetric: 386.5404 - val_loss: 395.8152 - val_MinusLogProbMetric: 395.8152 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 367/1000
2023-09-10 02:55:43.984 
Epoch 367/1000 
	 loss: 386.8767, MinusLogProbMetric: 386.8767, val_loss: 393.9812, val_MinusLogProbMetric: 393.9812

Epoch 367: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.8767 - MinusLogProbMetric: 386.8767 - val_loss: 393.9812 - val_MinusLogProbMetric: 393.9812 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 368/1000
2023-09-10 02:55:53.733 
Epoch 368/1000 
	 loss: 386.6718, MinusLogProbMetric: 386.6718, val_loss: 394.2493, val_MinusLogProbMetric: 394.2493

Epoch 368: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.6718 - MinusLogProbMetric: 386.6718 - val_loss: 394.2493 - val_MinusLogProbMetric: 394.2493 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 369/1000
2023-09-10 02:56:05.477 
Epoch 369/1000 
	 loss: 386.3738, MinusLogProbMetric: 386.3738, val_loss: 394.8753, val_MinusLogProbMetric: 394.8753

Epoch 369: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.3738 - MinusLogProbMetric: 386.3738 - val_loss: 394.8753 - val_MinusLogProbMetric: 394.8753 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 370/1000
2023-09-10 02:56:15.152 
Epoch 370/1000 
	 loss: 386.6174, MinusLogProbMetric: 386.6174, val_loss: 394.0436, val_MinusLogProbMetric: 394.0436

Epoch 370: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.6174 - MinusLogProbMetric: 386.6174 - val_loss: 394.0436 - val_MinusLogProbMetric: 394.0436 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 371/1000
2023-09-10 02:56:27.265 
Epoch 371/1000 
	 loss: 386.3668, MinusLogProbMetric: 386.3668, val_loss: 394.2558, val_MinusLogProbMetric: 394.2558

Epoch 371: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.3668 - MinusLogProbMetric: 386.3668 - val_loss: 394.2558 - val_MinusLogProbMetric: 394.2558 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 372/1000
2023-09-10 02:56:36.553 
Epoch 372/1000 
	 loss: 386.4693, MinusLogProbMetric: 386.4693, val_loss: 395.4817, val_MinusLogProbMetric: 395.4817

Epoch 372: val_loss did not improve from 393.46387
196/196 - 9s - loss: 386.4693 - MinusLogProbMetric: 386.4693 - val_loss: 395.4817 - val_MinusLogProbMetric: 395.4817 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 373/1000
2023-09-10 02:56:48.810 
Epoch 373/1000 
	 loss: 386.8127, MinusLogProbMetric: 386.8127, val_loss: 394.0831, val_MinusLogProbMetric: 394.0831

Epoch 373: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.8127 - MinusLogProbMetric: 386.8127 - val_loss: 394.0831 - val_MinusLogProbMetric: 394.0831 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 374/1000
2023-09-10 02:56:59.097 
Epoch 374/1000 
	 loss: 386.4034, MinusLogProbMetric: 386.4034, val_loss: 394.1711, val_MinusLogProbMetric: 394.1711

Epoch 374: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.4034 - MinusLogProbMetric: 386.4034 - val_loss: 394.1711 - val_MinusLogProbMetric: 394.1711 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 375/1000
2023-09-10 02:57:10.698 
Epoch 375/1000 
	 loss: 386.6689, MinusLogProbMetric: 386.6689, val_loss: 394.2302, val_MinusLogProbMetric: 394.2302

Epoch 375: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.6689 - MinusLogProbMetric: 386.6689 - val_loss: 394.2302 - val_MinusLogProbMetric: 394.2302 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 376/1000
2023-09-10 02:57:20.240 
Epoch 376/1000 
	 loss: 386.4491, MinusLogProbMetric: 386.4491, val_loss: 394.4655, val_MinusLogProbMetric: 394.4655

Epoch 376: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.4491 - MinusLogProbMetric: 386.4491 - val_loss: 394.4655 - val_MinusLogProbMetric: 394.4655 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 377/1000
2023-09-10 02:57:32.282 
Epoch 377/1000 
	 loss: 386.9096, MinusLogProbMetric: 386.9096, val_loss: 394.2028, val_MinusLogProbMetric: 394.2028

Epoch 377: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.9096 - MinusLogProbMetric: 386.9096 - val_loss: 394.2028 - val_MinusLogProbMetric: 394.2028 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 378/1000
2023-09-10 02:57:42.738 
Epoch 378/1000 
	 loss: 386.3692, MinusLogProbMetric: 386.3692, val_loss: 394.3099, val_MinusLogProbMetric: 394.3099

Epoch 378: val_loss did not improve from 393.46387
196/196 - 10s - loss: 386.3692 - MinusLogProbMetric: 386.3692 - val_loss: 394.3099 - val_MinusLogProbMetric: 394.3099 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 379/1000
2023-09-10 02:57:54.518 
Epoch 379/1000 
	 loss: 386.4343, MinusLogProbMetric: 386.4343, val_loss: 394.9043, val_MinusLogProbMetric: 394.9043

Epoch 379: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.4343 - MinusLogProbMetric: 386.4343 - val_loss: 394.9043 - val_MinusLogProbMetric: 394.9043 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 380/1000
2023-09-10 02:58:05.746 
Epoch 380/1000 
	 loss: 386.6750, MinusLogProbMetric: 386.6750, val_loss: 394.5467, val_MinusLogProbMetric: 394.5467

Epoch 380: val_loss did not improve from 393.46387
196/196 - 11s - loss: 386.6750 - MinusLogProbMetric: 386.6750 - val_loss: 394.5467 - val_MinusLogProbMetric: 394.5467 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 381/1000
2023-09-10 02:58:18.257 
Epoch 381/1000 
	 loss: 386.4064, MinusLogProbMetric: 386.4064, val_loss: 394.0233, val_MinusLogProbMetric: 394.0233

Epoch 381: val_loss did not improve from 393.46387
196/196 - 12s - loss: 386.4064 - MinusLogProbMetric: 386.4064 - val_loss: 394.0233 - val_MinusLogProbMetric: 394.0233 - lr: 8.3333e-05 - 12s/epoch - 64ms/step
Epoch 382/1000
2023-09-10 02:58:28.768 
Epoch 382/1000 
	 loss: 385.2423, MinusLogProbMetric: 385.2423, val_loss: 393.2381, val_MinusLogProbMetric: 393.2381

Epoch 382: val_loss improved from 393.46387 to 393.23813, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 385.2423 - MinusLogProbMetric: 385.2423 - val_loss: 393.2381 - val_MinusLogProbMetric: 393.2381 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 383/1000
2023-09-10 02:58:40.615 
Epoch 383/1000 
	 loss: 385.1699, MinusLogProbMetric: 385.1699, val_loss: 393.2413, val_MinusLogProbMetric: 393.2413

Epoch 383: val_loss did not improve from 393.23813
196/196 - 12s - loss: 385.1699 - MinusLogProbMetric: 385.1699 - val_loss: 393.2413 - val_MinusLogProbMetric: 393.2413 - lr: 4.1667e-05 - 12s/epoch - 59ms/step
Epoch 384/1000
2023-09-10 02:58:51.203 
Epoch 384/1000 
	 loss: 385.1721, MinusLogProbMetric: 385.1721, val_loss: 393.2178, val_MinusLogProbMetric: 393.2178

Epoch 384: val_loss improved from 393.23813 to 393.21777, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 11s - loss: 385.1721 - MinusLogProbMetric: 385.1721 - val_loss: 393.2178 - val_MinusLogProbMetric: 393.2178 - lr: 4.1667e-05 - 11s/epoch - 56ms/step
Epoch 385/1000
2023-09-10 02:59:04.114 
Epoch 385/1000 
	 loss: 385.1222, MinusLogProbMetric: 385.1222, val_loss: 393.4295, val_MinusLogProbMetric: 393.4295

Epoch 385: val_loss did not improve from 393.21777
196/196 - 13s - loss: 385.1222 - MinusLogProbMetric: 385.1222 - val_loss: 393.4295 - val_MinusLogProbMetric: 393.4295 - lr: 4.1667e-05 - 13s/epoch - 64ms/step
Epoch 386/1000
2023-09-10 02:59:14.268 
Epoch 386/1000 
	 loss: 385.1274, MinusLogProbMetric: 385.1274, val_loss: 393.8735, val_MinusLogProbMetric: 393.8735

Epoch 386: val_loss did not improve from 393.21777
196/196 - 10s - loss: 385.1274 - MinusLogProbMetric: 385.1274 - val_loss: 393.8735 - val_MinusLogProbMetric: 393.8735 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 387/1000
2023-09-10 02:59:25.644 
Epoch 387/1000 
	 loss: 385.1972, MinusLogProbMetric: 385.1972, val_loss: 393.5116, val_MinusLogProbMetric: 393.5116

Epoch 387: val_loss did not improve from 393.21777
196/196 - 11s - loss: 385.1972 - MinusLogProbMetric: 385.1972 - val_loss: 393.5116 - val_MinusLogProbMetric: 393.5116 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 388/1000
2023-09-10 02:59:35.593 
Epoch 388/1000 
	 loss: 385.2544, MinusLogProbMetric: 385.2544, val_loss: 393.2193, val_MinusLogProbMetric: 393.2193

Epoch 388: val_loss did not improve from 393.21777
196/196 - 10s - loss: 385.2544 - MinusLogProbMetric: 385.2544 - val_loss: 393.2193 - val_MinusLogProbMetric: 393.2193 - lr: 4.1667e-05 - 10s/epoch - 51ms/step
Epoch 389/1000
2023-09-10 02:59:47.777 
Epoch 389/1000 
	 loss: 385.2177, MinusLogProbMetric: 385.2177, val_loss: 393.6611, val_MinusLogProbMetric: 393.6611

Epoch 389: val_loss did not improve from 393.21777
196/196 - 12s - loss: 385.2177 - MinusLogProbMetric: 385.2177 - val_loss: 393.6611 - val_MinusLogProbMetric: 393.6611 - lr: 4.1667e-05 - 12s/epoch - 62ms/step
Epoch 390/1000
2023-09-10 02:59:58.377 
Epoch 390/1000 
	 loss: 385.2335, MinusLogProbMetric: 385.2335, val_loss: 393.9131, val_MinusLogProbMetric: 393.9131

Epoch 390: val_loss did not improve from 393.21777
196/196 - 11s - loss: 385.2335 - MinusLogProbMetric: 385.2335 - val_loss: 393.9131 - val_MinusLogProbMetric: 393.9131 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 391/1000
2023-09-10 03:00:11.925 
Epoch 391/1000 
	 loss: 385.3071, MinusLogProbMetric: 385.3071, val_loss: 393.3934, val_MinusLogProbMetric: 393.3934

Epoch 391: val_loss did not improve from 393.21777
196/196 - 14s - loss: 385.3071 - MinusLogProbMetric: 385.3071 - val_loss: 393.3934 - val_MinusLogProbMetric: 393.3934 - lr: 4.1667e-05 - 14s/epoch - 69ms/step
Epoch 392/1000
2023-09-10 03:00:22.172 
Epoch 392/1000 
	 loss: 385.1048, MinusLogProbMetric: 385.1048, val_loss: 393.3590, val_MinusLogProbMetric: 393.3590

Epoch 392: val_loss did not improve from 393.21777
196/196 - 10s - loss: 385.1048 - MinusLogProbMetric: 385.1048 - val_loss: 393.3590 - val_MinusLogProbMetric: 393.3590 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 393/1000
2023-09-10 03:00:34.741 
Epoch 393/1000 
	 loss: 385.1246, MinusLogProbMetric: 385.1246, val_loss: 393.2882, val_MinusLogProbMetric: 393.2882

Epoch 393: val_loss did not improve from 393.21777
196/196 - 13s - loss: 385.1246 - MinusLogProbMetric: 385.1246 - val_loss: 393.2882 - val_MinusLogProbMetric: 393.2882 - lr: 4.1667e-05 - 13s/epoch - 64ms/step
Epoch 394/1000
2023-09-10 03:00:45.888 
Epoch 394/1000 
	 loss: 385.0467, MinusLogProbMetric: 385.0467, val_loss: 393.0682, val_MinusLogProbMetric: 393.0682

Epoch 394: val_loss improved from 393.21777 to 393.06821, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 12s - loss: 385.0467 - MinusLogProbMetric: 385.0467 - val_loss: 393.0682 - val_MinusLogProbMetric: 393.0682 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 395/1000
2023-09-10 03:00:58.219 
Epoch 395/1000 
	 loss: 385.0683, MinusLogProbMetric: 385.0683, val_loss: 393.3544, val_MinusLogProbMetric: 393.3544

Epoch 395: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.0683 - MinusLogProbMetric: 385.0683 - val_loss: 393.3544 - val_MinusLogProbMetric: 393.3544 - lr: 4.1667e-05 - 12s/epoch - 59ms/step
Epoch 396/1000
2023-09-10 03:01:08.390 
Epoch 396/1000 
	 loss: 385.1723, MinusLogProbMetric: 385.1723, val_loss: 393.3539, val_MinusLogProbMetric: 393.3539

Epoch 396: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.1723 - MinusLogProbMetric: 385.1723 - val_loss: 393.3539 - val_MinusLogProbMetric: 393.3539 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 397/1000
2023-09-10 03:01:20.168 
Epoch 397/1000 
	 loss: 385.1187, MinusLogProbMetric: 385.1187, val_loss: 393.3347, val_MinusLogProbMetric: 393.3347

Epoch 397: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.1187 - MinusLogProbMetric: 385.1187 - val_loss: 393.3347 - val_MinusLogProbMetric: 393.3347 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 398/1000
2023-09-10 03:01:30.083 
Epoch 398/1000 
	 loss: 385.0399, MinusLogProbMetric: 385.0399, val_loss: 393.3488, val_MinusLogProbMetric: 393.3488

Epoch 398: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.0399 - MinusLogProbMetric: 385.0399 - val_loss: 393.3488 - val_MinusLogProbMetric: 393.3488 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 399/1000
2023-09-10 03:01:40.915 
Epoch 399/1000 
	 loss: 385.2681, MinusLogProbMetric: 385.2681, val_loss: 393.3654, val_MinusLogProbMetric: 393.3654

Epoch 399: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.2681 - MinusLogProbMetric: 385.2681 - val_loss: 393.3654 - val_MinusLogProbMetric: 393.3654 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 400/1000
2023-09-10 03:01:51.401 
Epoch 400/1000 
	 loss: 385.1672, MinusLogProbMetric: 385.1672, val_loss: 393.4175, val_MinusLogProbMetric: 393.4175

Epoch 400: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.1672 - MinusLogProbMetric: 385.1672 - val_loss: 393.4175 - val_MinusLogProbMetric: 393.4175 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 401/1000
2023-09-10 03:02:03.216 
Epoch 401/1000 
	 loss: 385.2018, MinusLogProbMetric: 385.2018, val_loss: 393.3650, val_MinusLogProbMetric: 393.3650

Epoch 401: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.2018 - MinusLogProbMetric: 385.2018 - val_loss: 393.3650 - val_MinusLogProbMetric: 393.3650 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 402/1000
2023-09-10 03:02:13.526 
Epoch 402/1000 
	 loss: 385.1822, MinusLogProbMetric: 385.1822, val_loss: 393.0839, val_MinusLogProbMetric: 393.0839

Epoch 402: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.1822 - MinusLogProbMetric: 385.1822 - val_loss: 393.0839 - val_MinusLogProbMetric: 393.0839 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 403/1000
2023-09-10 03:02:24.624 
Epoch 403/1000 
	 loss: 385.2061, MinusLogProbMetric: 385.2061, val_loss: 393.8938, val_MinusLogProbMetric: 393.8938

Epoch 403: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.2061 - MinusLogProbMetric: 385.2061 - val_loss: 393.8938 - val_MinusLogProbMetric: 393.8938 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 404/1000
2023-09-10 03:02:35.292 
Epoch 404/1000 
	 loss: 385.1625, MinusLogProbMetric: 385.1625, val_loss: 393.4938, val_MinusLogProbMetric: 393.4938

Epoch 404: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1625 - MinusLogProbMetric: 385.1625 - val_loss: 393.4938 - val_MinusLogProbMetric: 393.4938 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 405/1000
2023-09-10 03:02:47.094 
Epoch 405/1000 
	 loss: 385.1985, MinusLogProbMetric: 385.1985, val_loss: 393.6678, val_MinusLogProbMetric: 393.6678

Epoch 405: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.1985 - MinusLogProbMetric: 385.1985 - val_loss: 393.6678 - val_MinusLogProbMetric: 393.6678 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 406/1000
2023-09-10 03:02:57.738 
Epoch 406/1000 
	 loss: 385.3770, MinusLogProbMetric: 385.3770, val_loss: 393.6372, val_MinusLogProbMetric: 393.6372

Epoch 406: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.3770 - MinusLogProbMetric: 385.3770 - val_loss: 393.6372 - val_MinusLogProbMetric: 393.6372 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 407/1000
2023-09-10 03:03:11.417 
Epoch 407/1000 
	 loss: 385.3316, MinusLogProbMetric: 385.3316, val_loss: 393.8973, val_MinusLogProbMetric: 393.8973

Epoch 407: val_loss did not improve from 393.06821
196/196 - 14s - loss: 385.3316 - MinusLogProbMetric: 385.3316 - val_loss: 393.8973 - val_MinusLogProbMetric: 393.8973 - lr: 4.1667e-05 - 14s/epoch - 70ms/step
Epoch 408/1000
2023-09-10 03:03:22.659 
Epoch 408/1000 
	 loss: 385.2097, MinusLogProbMetric: 385.2097, val_loss: 393.7338, val_MinusLogProbMetric: 393.7338

Epoch 408: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.2097 - MinusLogProbMetric: 385.2097 - val_loss: 393.7338 - val_MinusLogProbMetric: 393.7338 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 409/1000
2023-09-10 03:03:33.973 
Epoch 409/1000 
	 loss: 385.1981, MinusLogProbMetric: 385.1981, val_loss: 393.8720, val_MinusLogProbMetric: 393.8720

Epoch 409: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1981 - MinusLogProbMetric: 385.1981 - val_loss: 393.8720 - val_MinusLogProbMetric: 393.8720 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 410/1000
2023-09-10 03:03:45.607 
Epoch 410/1000 
	 loss: 385.2215, MinusLogProbMetric: 385.2215, val_loss: 393.2832, val_MinusLogProbMetric: 393.2832

Epoch 410: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.2215 - MinusLogProbMetric: 385.2215 - val_loss: 393.2832 - val_MinusLogProbMetric: 393.2832 - lr: 4.1667e-05 - 12s/epoch - 59ms/step
Epoch 411/1000
2023-09-10 03:03:57.483 
Epoch 411/1000 
	 loss: 385.3574, MinusLogProbMetric: 385.3574, val_loss: 393.5664, val_MinusLogProbMetric: 393.5664

Epoch 411: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.3574 - MinusLogProbMetric: 385.3574 - val_loss: 393.5664 - val_MinusLogProbMetric: 393.5664 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 412/1000
2023-09-10 03:04:08.450 
Epoch 412/1000 
	 loss: 385.1846, MinusLogProbMetric: 385.1846, val_loss: 393.6603, val_MinusLogProbMetric: 393.6603

Epoch 412: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1846 - MinusLogProbMetric: 385.1846 - val_loss: 393.6603 - val_MinusLogProbMetric: 393.6603 - lr: 4.1667e-05 - 11s/epoch - 56ms/step
Epoch 413/1000
2023-09-10 03:04:19.192 
Epoch 413/1000 
	 loss: 385.0654, MinusLogProbMetric: 385.0654, val_loss: 393.6342, val_MinusLogProbMetric: 393.6342

Epoch 413: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.0654 - MinusLogProbMetric: 385.0654 - val_loss: 393.6342 - val_MinusLogProbMetric: 393.6342 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 414/1000
2023-09-10 03:04:29.772 
Epoch 414/1000 
	 loss: 385.1003, MinusLogProbMetric: 385.1003, val_loss: 393.4819, val_MinusLogProbMetric: 393.4819

Epoch 414: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1003 - MinusLogProbMetric: 385.1003 - val_loss: 393.4819 - val_MinusLogProbMetric: 393.4819 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 415/1000
2023-09-10 03:04:40.957 
Epoch 415/1000 
	 loss: 385.0246, MinusLogProbMetric: 385.0246, val_loss: 393.4730, val_MinusLogProbMetric: 393.4730

Epoch 415: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.0246 - MinusLogProbMetric: 385.0246 - val_loss: 393.4730 - val_MinusLogProbMetric: 393.4730 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 416/1000
2023-09-10 03:04:51.143 
Epoch 416/1000 
	 loss: 385.0208, MinusLogProbMetric: 385.0208, val_loss: 393.7981, val_MinusLogProbMetric: 393.7981

Epoch 416: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.0208 - MinusLogProbMetric: 385.0208 - val_loss: 393.7981 - val_MinusLogProbMetric: 393.7981 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 417/1000
2023-09-10 03:05:02.929 
Epoch 417/1000 
	 loss: 385.1141, MinusLogProbMetric: 385.1141, val_loss: 393.7998, val_MinusLogProbMetric: 393.7998

Epoch 417: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.1141 - MinusLogProbMetric: 385.1141 - val_loss: 393.7998 - val_MinusLogProbMetric: 393.7998 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 418/1000
2023-09-10 03:05:12.483 
Epoch 418/1000 
	 loss: 385.0760, MinusLogProbMetric: 385.0760, val_loss: 393.1137, val_MinusLogProbMetric: 393.1137

Epoch 418: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.0760 - MinusLogProbMetric: 385.0760 - val_loss: 393.1137 - val_MinusLogProbMetric: 393.1137 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 419/1000
2023-09-10 03:05:23.129 
Epoch 419/1000 
	 loss: 384.9901, MinusLogProbMetric: 384.9901, val_loss: 393.4003, val_MinusLogProbMetric: 393.4003

Epoch 419: val_loss did not improve from 393.06821
196/196 - 11s - loss: 384.9901 - MinusLogProbMetric: 384.9901 - val_loss: 393.4003 - val_MinusLogProbMetric: 393.4003 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 420/1000
2023-09-10 03:05:33.257 
Epoch 420/1000 
	 loss: 385.2275, MinusLogProbMetric: 385.2275, val_loss: 393.1177, val_MinusLogProbMetric: 393.1177

Epoch 420: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.2275 - MinusLogProbMetric: 385.2275 - val_loss: 393.1177 - val_MinusLogProbMetric: 393.1177 - lr: 4.1667e-05 - 10s/epoch - 51ms/step
Epoch 421/1000
2023-09-10 03:05:44.662 
Epoch 421/1000 
	 loss: 384.9916, MinusLogProbMetric: 384.9916, val_loss: 393.3790, val_MinusLogProbMetric: 393.3790

Epoch 421: val_loss did not improve from 393.06821
196/196 - 11s - loss: 384.9916 - MinusLogProbMetric: 384.9916 - val_loss: 393.3790 - val_MinusLogProbMetric: 393.3790 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 422/1000
2023-09-10 03:05:55.583 
Epoch 422/1000 
	 loss: 385.0757, MinusLogProbMetric: 385.0757, val_loss: 393.8253, val_MinusLogProbMetric: 393.8253

Epoch 422: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.0757 - MinusLogProbMetric: 385.0757 - val_loss: 393.8253 - val_MinusLogProbMetric: 393.8253 - lr: 4.1667e-05 - 11s/epoch - 56ms/step
Epoch 423/1000
2023-09-10 03:06:08.056 
Epoch 423/1000 
	 loss: 385.0144, MinusLogProbMetric: 385.0144, val_loss: 393.4562, val_MinusLogProbMetric: 393.4562

Epoch 423: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.0144 - MinusLogProbMetric: 385.0144 - val_loss: 393.4562 - val_MinusLogProbMetric: 393.4562 - lr: 4.1667e-05 - 12s/epoch - 64ms/step
Epoch 424/1000
2023-09-10 03:06:18.568 
Epoch 424/1000 
	 loss: 385.1585, MinusLogProbMetric: 385.1585, val_loss: 393.4041, val_MinusLogProbMetric: 393.4041

Epoch 424: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1585 - MinusLogProbMetric: 385.1585 - val_loss: 393.4041 - val_MinusLogProbMetric: 393.4041 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 425/1000
2023-09-10 03:06:30.339 
Epoch 425/1000 
	 loss: 385.0254, MinusLogProbMetric: 385.0254, val_loss: 393.4479, val_MinusLogProbMetric: 393.4479

Epoch 425: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.0254 - MinusLogProbMetric: 385.0254 - val_loss: 393.4479 - val_MinusLogProbMetric: 393.4479 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 426/1000
2023-09-10 03:06:40.703 
Epoch 426/1000 
	 loss: 385.0053, MinusLogProbMetric: 385.0053, val_loss: 393.4338, val_MinusLogProbMetric: 393.4338

Epoch 426: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.0053 - MinusLogProbMetric: 385.0053 - val_loss: 393.4338 - val_MinusLogProbMetric: 393.4338 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 427/1000
2023-09-10 03:06:52.749 
Epoch 427/1000 
	 loss: 385.0624, MinusLogProbMetric: 385.0624, val_loss: 393.8785, val_MinusLogProbMetric: 393.8785

Epoch 427: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.0624 - MinusLogProbMetric: 385.0624 - val_loss: 393.8785 - val_MinusLogProbMetric: 393.8785 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 428/1000
2023-09-10 03:07:03.153 
Epoch 428/1000 
	 loss: 385.0154, MinusLogProbMetric: 385.0154, val_loss: 394.9394, val_MinusLogProbMetric: 394.9394

Epoch 428: val_loss did not improve from 393.06821
196/196 - 10s - loss: 385.0154 - MinusLogProbMetric: 385.0154 - val_loss: 394.9394 - val_MinusLogProbMetric: 394.9394 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 429/1000
2023-09-10 03:07:15.293 
Epoch 429/1000 
	 loss: 384.9955, MinusLogProbMetric: 384.9955, val_loss: 393.3451, val_MinusLogProbMetric: 393.3451

Epoch 429: val_loss did not improve from 393.06821
196/196 - 12s - loss: 384.9955 - MinusLogProbMetric: 384.9955 - val_loss: 393.3451 - val_MinusLogProbMetric: 393.3451 - lr: 4.1667e-05 - 12s/epoch - 62ms/step
Epoch 430/1000
2023-09-10 03:07:26.711 
Epoch 430/1000 
	 loss: 385.0145, MinusLogProbMetric: 385.0145, val_loss: 393.2571, val_MinusLogProbMetric: 393.2571

Epoch 430: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.0145 - MinusLogProbMetric: 385.0145 - val_loss: 393.2571 - val_MinusLogProbMetric: 393.2571 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 431/1000
2023-09-10 03:07:37.768 
Epoch 431/1000 
	 loss: 385.1665, MinusLogProbMetric: 385.1665, val_loss: 393.4474, val_MinusLogProbMetric: 393.4474

Epoch 431: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1665 - MinusLogProbMetric: 385.1665 - val_loss: 393.4474 - val_MinusLogProbMetric: 393.4474 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 432/1000
2023-09-10 03:07:48.535 
Epoch 432/1000 
	 loss: 385.0314, MinusLogProbMetric: 385.0314, val_loss: 393.3157, val_MinusLogProbMetric: 393.3157

Epoch 432: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.0314 - MinusLogProbMetric: 385.0314 - val_loss: 393.3157 - val_MinusLogProbMetric: 393.3157 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 433/1000
2023-09-10 03:08:00.382 
Epoch 433/1000 
	 loss: 385.0262, MinusLogProbMetric: 385.0262, val_loss: 393.5566, val_MinusLogProbMetric: 393.5566

Epoch 433: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.0262 - MinusLogProbMetric: 385.0262 - val_loss: 393.5566 - val_MinusLogProbMetric: 393.5566 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 434/1000
2023-09-10 03:08:11.690 
Epoch 434/1000 
	 loss: 385.2877, MinusLogProbMetric: 385.2877, val_loss: 393.3290, val_MinusLogProbMetric: 393.3290

Epoch 434: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.2877 - MinusLogProbMetric: 385.2877 - val_loss: 393.3290 - val_MinusLogProbMetric: 393.3290 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 435/1000
2023-09-10 03:08:22.987 
Epoch 435/1000 
	 loss: 385.1709, MinusLogProbMetric: 385.1709, val_loss: 393.8316, val_MinusLogProbMetric: 393.8316

Epoch 435: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1709 - MinusLogProbMetric: 385.1709 - val_loss: 393.8316 - val_MinusLogProbMetric: 393.8316 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 436/1000
2023-09-10 03:08:34.159 
Epoch 436/1000 
	 loss: 384.9684, MinusLogProbMetric: 384.9684, val_loss: 393.7807, val_MinusLogProbMetric: 393.7807

Epoch 436: val_loss did not improve from 393.06821
196/196 - 11s - loss: 384.9684 - MinusLogProbMetric: 384.9684 - val_loss: 393.7807 - val_MinusLogProbMetric: 393.7807 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 437/1000
2023-09-10 03:08:46.620 
Epoch 437/1000 
	 loss: 385.2042, MinusLogProbMetric: 385.2042, val_loss: 393.2984, val_MinusLogProbMetric: 393.2984

Epoch 437: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.2042 - MinusLogProbMetric: 385.2042 - val_loss: 393.2984 - val_MinusLogProbMetric: 393.2984 - lr: 4.1667e-05 - 12s/epoch - 63ms/step
Epoch 438/1000
2023-09-10 03:08:57.497 
Epoch 438/1000 
	 loss: 385.1187, MinusLogProbMetric: 385.1187, val_loss: 393.5589, val_MinusLogProbMetric: 393.5589

Epoch 438: val_loss did not improve from 393.06821
196/196 - 11s - loss: 385.1187 - MinusLogProbMetric: 385.1187 - val_loss: 393.5589 - val_MinusLogProbMetric: 393.5589 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 439/1000
2023-09-10 03:09:09.342 
Epoch 439/1000 
	 loss: 385.2108, MinusLogProbMetric: 385.2108, val_loss: 393.4259, val_MinusLogProbMetric: 393.4259

Epoch 439: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.2108 - MinusLogProbMetric: 385.2108 - val_loss: 393.4259 - val_MinusLogProbMetric: 393.4259 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-10 03:09:20.048 
Epoch 440/1000 
	 loss: 384.8603, MinusLogProbMetric: 384.8603, val_loss: 393.4844, val_MinusLogProbMetric: 393.4844

Epoch 440: val_loss did not improve from 393.06821
196/196 - 11s - loss: 384.8603 - MinusLogProbMetric: 384.8603 - val_loss: 393.4844 - val_MinusLogProbMetric: 393.4844 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 441/1000
2023-09-10 03:09:31.874 
Epoch 441/1000 
	 loss: 384.9506, MinusLogProbMetric: 384.9506, val_loss: 394.0388, val_MinusLogProbMetric: 394.0388

Epoch 441: val_loss did not improve from 393.06821
196/196 - 12s - loss: 384.9506 - MinusLogProbMetric: 384.9506 - val_loss: 394.0388 - val_MinusLogProbMetric: 394.0388 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 442/1000
2023-09-10 03:09:44.028 
Epoch 442/1000 
	 loss: 385.1792, MinusLogProbMetric: 385.1792, val_loss: 394.0655, val_MinusLogProbMetric: 394.0655

Epoch 442: val_loss did not improve from 393.06821
196/196 - 12s - loss: 385.1792 - MinusLogProbMetric: 385.1792 - val_loss: 394.0655 - val_MinusLogProbMetric: 394.0655 - lr: 4.1667e-05 - 12s/epoch - 62ms/step
Epoch 443/1000
2023-09-10 03:09:56.011 
Epoch 443/1000 
	 loss: 384.9561, MinusLogProbMetric: 384.9561, val_loss: 394.2352, val_MinusLogProbMetric: 394.2352

Epoch 443: val_loss did not improve from 393.06821
196/196 - 12s - loss: 384.9561 - MinusLogProbMetric: 384.9561 - val_loss: 394.2352 - val_MinusLogProbMetric: 394.2352 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 444/1000
2023-09-10 03:10:08.568 
Epoch 444/1000 
	 loss: 385.1147, MinusLogProbMetric: 385.1147, val_loss: 393.9154, val_MinusLogProbMetric: 393.9154

Epoch 444: val_loss did not improve from 393.06821
196/196 - 13s - loss: 385.1147 - MinusLogProbMetric: 385.1147 - val_loss: 393.9154 - val_MinusLogProbMetric: 393.9154 - lr: 4.1667e-05 - 13s/epoch - 64ms/step
Epoch 445/1000
2023-09-10 03:10:20.804 
Epoch 445/1000 
	 loss: 384.5180, MinusLogProbMetric: 384.5180, val_loss: 393.0536, val_MinusLogProbMetric: 393.0536

Epoch 445: val_loss improved from 393.06821 to 393.05359, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 13s - loss: 384.5180 - MinusLogProbMetric: 384.5180 - val_loss: 393.0536 - val_MinusLogProbMetric: 393.0536 - lr: 2.0833e-05 - 13s/epoch - 65ms/step
Epoch 446/1000
2023-09-10 03:10:31.282 
Epoch 446/1000 
	 loss: 384.4901, MinusLogProbMetric: 384.4901, val_loss: 393.1007, val_MinusLogProbMetric: 393.1007

Epoch 446: val_loss did not improve from 393.05359
196/196 - 10s - loss: 384.4901 - MinusLogProbMetric: 384.4901 - val_loss: 393.1007 - val_MinusLogProbMetric: 393.1007 - lr: 2.0833e-05 - 10s/epoch - 51ms/step
Epoch 447/1000
2023-09-10 03:10:44.384 
Epoch 447/1000 
	 loss: 384.4883, MinusLogProbMetric: 384.4883, val_loss: 393.0482, val_MinusLogProbMetric: 393.0482

Epoch 447: val_loss improved from 393.05359 to 393.04825, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 14s - loss: 384.4883 - MinusLogProbMetric: 384.4883 - val_loss: 393.0482 - val_MinusLogProbMetric: 393.0482 - lr: 2.0833e-05 - 14s/epoch - 69ms/step
Epoch 448/1000
2023-09-10 03:10:54.630 
Epoch 448/1000 
	 loss: 384.4692, MinusLogProbMetric: 384.4692, val_loss: 393.0245, val_MinusLogProbMetric: 393.0245

Epoch 448: val_loss improved from 393.04825 to 393.02448, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_330/weights/best_weights.h5
196/196 - 10s - loss: 384.4692 - MinusLogProbMetric: 384.4692 - val_loss: 393.0245 - val_MinusLogProbMetric: 393.0245 - lr: 2.0833e-05 - 10s/epoch - 53ms/step
Epoch 449/1000
2023-09-10 03:11:08.429 
Epoch 449/1000 
	 loss: 384.4657, MinusLogProbMetric: 384.4657, val_loss: 393.0518, val_MinusLogProbMetric: 393.0518

Epoch 449: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.4657 - MinusLogProbMetric: 384.4657 - val_loss: 393.0518 - val_MinusLogProbMetric: 393.0518 - lr: 2.0833e-05 - 13s/epoch - 67ms/step
Epoch 450/1000
2023-09-10 03:11:21.759 
Epoch 450/1000 
	 loss: 384.4708, MinusLogProbMetric: 384.4708, val_loss: 393.1628, val_MinusLogProbMetric: 393.1628

Epoch 450: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.4708 - MinusLogProbMetric: 384.4708 - val_loss: 393.1628 - val_MinusLogProbMetric: 393.1628 - lr: 2.0833e-05 - 13s/epoch - 68ms/step
Epoch 451/1000
2023-09-10 03:11:32.656 
Epoch 451/1000 
	 loss: 384.4734, MinusLogProbMetric: 384.4734, val_loss: 393.0825, val_MinusLogProbMetric: 393.0825

Epoch 451: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4734 - MinusLogProbMetric: 384.4734 - val_loss: 393.0825 - val_MinusLogProbMetric: 393.0825 - lr: 2.0833e-05 - 11s/epoch - 55ms/step
Epoch 452/1000
2023-09-10 03:11:43.843 
Epoch 452/1000 
	 loss: 384.4582, MinusLogProbMetric: 384.4582, val_loss: 393.2731, val_MinusLogProbMetric: 393.2731

Epoch 452: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4582 - MinusLogProbMetric: 384.4582 - val_loss: 393.2731 - val_MinusLogProbMetric: 393.2731 - lr: 2.0833e-05 - 11s/epoch - 57ms/step
Epoch 453/1000
2023-09-10 03:11:55.166 
Epoch 453/1000 
	 loss: 384.4653, MinusLogProbMetric: 384.4653, val_loss: 393.0417, val_MinusLogProbMetric: 393.0417

Epoch 453: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4653 - MinusLogProbMetric: 384.4653 - val_loss: 393.0417 - val_MinusLogProbMetric: 393.0417 - lr: 2.0833e-05 - 11s/epoch - 58ms/step
Epoch 454/1000
2023-09-10 03:12:07.546 
Epoch 454/1000 
	 loss: 384.4290, MinusLogProbMetric: 384.4290, val_loss: 393.1037, val_MinusLogProbMetric: 393.1037

Epoch 454: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4290 - MinusLogProbMetric: 384.4290 - val_loss: 393.1037 - val_MinusLogProbMetric: 393.1037 - lr: 2.0833e-05 - 12s/epoch - 63ms/step
Epoch 455/1000
2023-09-10 03:12:19.221 
Epoch 455/1000 
	 loss: 384.4745, MinusLogProbMetric: 384.4745, val_loss: 393.1658, val_MinusLogProbMetric: 393.1658

Epoch 455: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4745 - MinusLogProbMetric: 384.4745 - val_loss: 393.1658 - val_MinusLogProbMetric: 393.1658 - lr: 2.0833e-05 - 12s/epoch - 59ms/step
Epoch 456/1000
2023-09-10 03:12:30.297 
Epoch 456/1000 
	 loss: 384.4503, MinusLogProbMetric: 384.4503, val_loss: 393.1556, val_MinusLogProbMetric: 393.1556

Epoch 456: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4503 - MinusLogProbMetric: 384.4503 - val_loss: 393.1556 - val_MinusLogProbMetric: 393.1556 - lr: 2.0833e-05 - 11s/epoch - 57ms/step
Epoch 457/1000
2023-09-10 03:12:40.958 
Epoch 457/1000 
	 loss: 384.4660, MinusLogProbMetric: 384.4660, val_loss: 393.1609, val_MinusLogProbMetric: 393.1609

Epoch 457: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4660 - MinusLogProbMetric: 384.4660 - val_loss: 393.1609 - val_MinusLogProbMetric: 393.1609 - lr: 2.0833e-05 - 11s/epoch - 54ms/step
Epoch 458/1000
2023-09-10 03:12:52.241 
Epoch 458/1000 
	 loss: 384.4659, MinusLogProbMetric: 384.4659, val_loss: 393.2893, val_MinusLogProbMetric: 393.2893

Epoch 458: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4659 - MinusLogProbMetric: 384.4659 - val_loss: 393.2893 - val_MinusLogProbMetric: 393.2893 - lr: 2.0833e-05 - 11s/epoch - 58ms/step
Epoch 459/1000
2023-09-10 03:13:03.110 
Epoch 459/1000 
	 loss: 384.4774, MinusLogProbMetric: 384.4774, val_loss: 393.2384, val_MinusLogProbMetric: 393.2384

Epoch 459: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4774 - MinusLogProbMetric: 384.4774 - val_loss: 393.2384 - val_MinusLogProbMetric: 393.2384 - lr: 2.0833e-05 - 11s/epoch - 56ms/step
Epoch 460/1000
2023-09-10 03:13:15.411 
Epoch 460/1000 
	 loss: 384.4536, MinusLogProbMetric: 384.4536, val_loss: 393.1756, val_MinusLogProbMetric: 393.1756

Epoch 460: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4536 - MinusLogProbMetric: 384.4536 - val_loss: 393.1756 - val_MinusLogProbMetric: 393.1756 - lr: 2.0833e-05 - 12s/epoch - 63ms/step
Epoch 461/1000
2023-09-10 03:13:27.351 
Epoch 461/1000 
	 loss: 384.4360, MinusLogProbMetric: 384.4360, val_loss: 393.3047, val_MinusLogProbMetric: 393.3047

Epoch 461: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4360 - MinusLogProbMetric: 384.4360 - val_loss: 393.3047 - val_MinusLogProbMetric: 393.3047 - lr: 2.0833e-05 - 12s/epoch - 61ms/step
Epoch 462/1000
2023-09-10 03:13:38.418 
Epoch 462/1000 
	 loss: 384.4367, MinusLogProbMetric: 384.4367, val_loss: 393.1994, val_MinusLogProbMetric: 393.1994

Epoch 462: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4367 - MinusLogProbMetric: 384.4367 - val_loss: 393.1994 - val_MinusLogProbMetric: 393.1994 - lr: 2.0833e-05 - 11s/epoch - 56ms/step
Epoch 463/1000
2023-09-10 03:13:50.770 
Epoch 463/1000 
	 loss: 384.4629, MinusLogProbMetric: 384.4629, val_loss: 393.1484, val_MinusLogProbMetric: 393.1484

Epoch 463: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4629 - MinusLogProbMetric: 384.4629 - val_loss: 393.1484 - val_MinusLogProbMetric: 393.1484 - lr: 2.0833e-05 - 12s/epoch - 63ms/step
Epoch 464/1000
2023-09-10 03:14:03.143 
Epoch 464/1000 
	 loss: 384.5367, MinusLogProbMetric: 384.5367, val_loss: 393.0683, val_MinusLogProbMetric: 393.0683

Epoch 464: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.5367 - MinusLogProbMetric: 384.5367 - val_loss: 393.0683 - val_MinusLogProbMetric: 393.0683 - lr: 2.0833e-05 - 12s/epoch - 63ms/step
Epoch 465/1000
2023-09-10 03:14:13.937 
Epoch 465/1000 
	 loss: 384.4114, MinusLogProbMetric: 384.4114, val_loss: 393.0682, val_MinusLogProbMetric: 393.0682

Epoch 465: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4114 - MinusLogProbMetric: 384.4114 - val_loss: 393.0682 - val_MinusLogProbMetric: 393.0682 - lr: 2.0833e-05 - 11s/epoch - 55ms/step
Epoch 466/1000
2023-09-10 03:14:26.988 
Epoch 466/1000 
	 loss: 384.4409, MinusLogProbMetric: 384.4409, val_loss: 393.2033, val_MinusLogProbMetric: 393.2033

Epoch 466: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.4409 - MinusLogProbMetric: 384.4409 - val_loss: 393.2033 - val_MinusLogProbMetric: 393.2033 - lr: 2.0833e-05 - 13s/epoch - 67ms/step
Epoch 467/1000
2023-09-10 03:14:38.342 
Epoch 467/1000 
	 loss: 384.4457, MinusLogProbMetric: 384.4457, val_loss: 393.2653, val_MinusLogProbMetric: 393.2653

Epoch 467: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4457 - MinusLogProbMetric: 384.4457 - val_loss: 393.2653 - val_MinusLogProbMetric: 393.2653 - lr: 2.0833e-05 - 11s/epoch - 58ms/step
Epoch 468/1000
2023-09-10 03:14:49.993 
Epoch 468/1000 
	 loss: 384.4184, MinusLogProbMetric: 384.4184, val_loss: 393.1505, val_MinusLogProbMetric: 393.1505

Epoch 468: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4184 - MinusLogProbMetric: 384.4184 - val_loss: 393.1505 - val_MinusLogProbMetric: 393.1505 - lr: 2.0833e-05 - 12s/epoch - 59ms/step
Epoch 469/1000
2023-09-10 03:15:01.465 
Epoch 469/1000 
	 loss: 384.4464, MinusLogProbMetric: 384.4464, val_loss: 393.0882, val_MinusLogProbMetric: 393.0882

Epoch 469: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4464 - MinusLogProbMetric: 384.4464 - val_loss: 393.0882 - val_MinusLogProbMetric: 393.0882 - lr: 2.0833e-05 - 11s/epoch - 59ms/step
Epoch 470/1000
2023-09-10 03:15:13.116 
Epoch 470/1000 
	 loss: 384.4043, MinusLogProbMetric: 384.4043, val_loss: 393.2389, val_MinusLogProbMetric: 393.2389

Epoch 470: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4043 - MinusLogProbMetric: 384.4043 - val_loss: 393.2389 - val_MinusLogProbMetric: 393.2389 - lr: 2.0833e-05 - 12s/epoch - 59ms/step
Epoch 471/1000
2023-09-10 03:15:25.132 
Epoch 471/1000 
	 loss: 384.4099, MinusLogProbMetric: 384.4099, val_loss: 393.1697, val_MinusLogProbMetric: 393.1697

Epoch 471: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4099 - MinusLogProbMetric: 384.4099 - val_loss: 393.1697 - val_MinusLogProbMetric: 393.1697 - lr: 2.0833e-05 - 12s/epoch - 61ms/step
Epoch 472/1000
2023-09-10 03:15:37.864 
Epoch 472/1000 
	 loss: 384.3916, MinusLogProbMetric: 384.3916, val_loss: 393.1478, val_MinusLogProbMetric: 393.1478

Epoch 472: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.3916 - MinusLogProbMetric: 384.3916 - val_loss: 393.1478 - val_MinusLogProbMetric: 393.1478 - lr: 2.0833e-05 - 13s/epoch - 65ms/step
Epoch 473/1000
2023-09-10 03:15:49.094 
Epoch 473/1000 
	 loss: 384.4270, MinusLogProbMetric: 384.4270, val_loss: 393.1600, val_MinusLogProbMetric: 393.1600

Epoch 473: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4270 - MinusLogProbMetric: 384.4270 - val_loss: 393.1600 - val_MinusLogProbMetric: 393.1600 - lr: 2.0833e-05 - 11s/epoch - 57ms/step
Epoch 474/1000
2023-09-10 03:16:00.835 
Epoch 474/1000 
	 loss: 384.4471, MinusLogProbMetric: 384.4471, val_loss: 393.4425, val_MinusLogProbMetric: 393.4425

Epoch 474: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4471 - MinusLogProbMetric: 384.4471 - val_loss: 393.4425 - val_MinusLogProbMetric: 393.4425 - lr: 2.0833e-05 - 12s/epoch - 60ms/step
Epoch 475/1000
2023-09-10 03:16:11.413 
Epoch 475/1000 
	 loss: 384.4102, MinusLogProbMetric: 384.4102, val_loss: 393.1049, val_MinusLogProbMetric: 393.1049

Epoch 475: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4102 - MinusLogProbMetric: 384.4102 - val_loss: 393.1049 - val_MinusLogProbMetric: 393.1049 - lr: 2.0833e-05 - 11s/epoch - 54ms/step
Epoch 476/1000
2023-09-10 03:16:23.673 
Epoch 476/1000 
	 loss: 384.4028, MinusLogProbMetric: 384.4028, val_loss: 393.8305, val_MinusLogProbMetric: 393.8305

Epoch 476: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4028 - MinusLogProbMetric: 384.4028 - val_loss: 393.8305 - val_MinusLogProbMetric: 393.8305 - lr: 2.0833e-05 - 12s/epoch - 62ms/step
Epoch 477/1000
2023-09-10 03:16:34.496 
Epoch 477/1000 
	 loss: 384.4036, MinusLogProbMetric: 384.4036, val_loss: 393.4137, val_MinusLogProbMetric: 393.4137

Epoch 477: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4036 - MinusLogProbMetric: 384.4036 - val_loss: 393.4137 - val_MinusLogProbMetric: 393.4137 - lr: 2.0833e-05 - 11s/epoch - 55ms/step
Epoch 478/1000
2023-09-10 03:16:45.659 
Epoch 478/1000 
	 loss: 384.4735, MinusLogProbMetric: 384.4735, val_loss: 393.2881, val_MinusLogProbMetric: 393.2881

Epoch 478: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4735 - MinusLogProbMetric: 384.4735 - val_loss: 393.2881 - val_MinusLogProbMetric: 393.2881 - lr: 2.0833e-05 - 11s/epoch - 57ms/step
Epoch 479/1000
2023-09-10 03:16:56.563 
Epoch 479/1000 
	 loss: 384.3846, MinusLogProbMetric: 384.3846, val_loss: 393.5475, val_MinusLogProbMetric: 393.5475

Epoch 479: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.3846 - MinusLogProbMetric: 384.3846 - val_loss: 393.5475 - val_MinusLogProbMetric: 393.5475 - lr: 2.0833e-05 - 11s/epoch - 56ms/step
Epoch 480/1000
2023-09-10 03:17:07.860 
Epoch 480/1000 
	 loss: 384.4815, MinusLogProbMetric: 384.4815, val_loss: 393.3106, val_MinusLogProbMetric: 393.3106

Epoch 480: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4815 - MinusLogProbMetric: 384.4815 - val_loss: 393.3106 - val_MinusLogProbMetric: 393.3106 - lr: 2.0833e-05 - 11s/epoch - 58ms/step
Epoch 481/1000
2023-09-10 03:17:20.061 
Epoch 481/1000 
	 loss: 384.5298, MinusLogProbMetric: 384.5298, val_loss: 393.3670, val_MinusLogProbMetric: 393.3670

Epoch 481: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.5298 - MinusLogProbMetric: 384.5298 - val_loss: 393.3670 - val_MinusLogProbMetric: 393.3670 - lr: 2.0833e-05 - 12s/epoch - 62ms/step
Epoch 482/1000
2023-09-10 03:17:31.258 
Epoch 482/1000 
	 loss: 384.4356, MinusLogProbMetric: 384.4356, val_loss: 393.3053, val_MinusLogProbMetric: 393.3053

Epoch 482: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4356 - MinusLogProbMetric: 384.4356 - val_loss: 393.3053 - val_MinusLogProbMetric: 393.3053 - lr: 2.0833e-05 - 11s/epoch - 57ms/step
Epoch 483/1000
2023-09-10 03:17:44.277 
Epoch 483/1000 
	 loss: 384.4417, MinusLogProbMetric: 384.4417, val_loss: 393.2327, val_MinusLogProbMetric: 393.2327

Epoch 483: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.4417 - MinusLogProbMetric: 384.4417 - val_loss: 393.2327 - val_MinusLogProbMetric: 393.2327 - lr: 2.0833e-05 - 13s/epoch - 66ms/step
Epoch 484/1000
2023-09-10 03:17:56.096 
Epoch 484/1000 
	 loss: 384.4562, MinusLogProbMetric: 384.4562, val_loss: 393.1793, val_MinusLogProbMetric: 393.1793

Epoch 484: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4562 - MinusLogProbMetric: 384.4562 - val_loss: 393.1793 - val_MinusLogProbMetric: 393.1793 - lr: 2.0833e-05 - 12s/epoch - 60ms/step
Epoch 485/1000
2023-09-10 03:18:07.140 
Epoch 485/1000 
	 loss: 384.4541, MinusLogProbMetric: 384.4541, val_loss: 393.1798, val_MinusLogProbMetric: 393.1798

Epoch 485: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4541 - MinusLogProbMetric: 384.4541 - val_loss: 393.1798 - val_MinusLogProbMetric: 393.1798 - lr: 2.0833e-05 - 11s/epoch - 56ms/step
Epoch 486/1000
2023-09-10 03:18:18.240 
Epoch 486/1000 
	 loss: 384.4247, MinusLogProbMetric: 384.4247, val_loss: 393.3152, val_MinusLogProbMetric: 393.3152

Epoch 486: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4247 - MinusLogProbMetric: 384.4247 - val_loss: 393.3152 - val_MinusLogProbMetric: 393.3152 - lr: 2.0833e-05 - 11s/epoch - 57ms/step
Epoch 487/1000
2023-09-10 03:18:26.976 
Epoch 487/1000 
	 loss: 384.4387, MinusLogProbMetric: 384.4387, val_loss: 393.1670, val_MinusLogProbMetric: 393.1670

Epoch 487: val_loss did not improve from 393.02448
196/196 - 9s - loss: 384.4387 - MinusLogProbMetric: 384.4387 - val_loss: 393.1670 - val_MinusLogProbMetric: 393.1670 - lr: 2.0833e-05 - 9s/epoch - 45ms/step
Epoch 488/1000
2023-09-10 03:18:36.143 
Epoch 488/1000 
	 loss: 384.4051, MinusLogProbMetric: 384.4051, val_loss: 393.1276, val_MinusLogProbMetric: 393.1276

Epoch 488: val_loss did not improve from 393.02448
196/196 - 9s - loss: 384.4051 - MinusLogProbMetric: 384.4051 - val_loss: 393.1276 - val_MinusLogProbMetric: 393.1276 - lr: 2.0833e-05 - 9s/epoch - 47ms/step
Epoch 489/1000
2023-09-10 03:18:46.448 
Epoch 489/1000 
	 loss: 384.4454, MinusLogProbMetric: 384.4454, val_loss: 393.1676, val_MinusLogProbMetric: 393.1676

Epoch 489: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.4454 - MinusLogProbMetric: 384.4454 - val_loss: 393.1676 - val_MinusLogProbMetric: 393.1676 - lr: 2.0833e-05 - 10s/epoch - 53ms/step
Epoch 490/1000
2023-09-10 03:18:56.812 
Epoch 490/1000 
	 loss: 384.4865, MinusLogProbMetric: 384.4865, val_loss: 393.2987, val_MinusLogProbMetric: 393.2987

Epoch 490: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.4865 - MinusLogProbMetric: 384.4865 - val_loss: 393.2987 - val_MinusLogProbMetric: 393.2987 - lr: 2.0833e-05 - 10s/epoch - 53ms/step
Epoch 491/1000
2023-09-10 03:19:07.583 
Epoch 491/1000 
	 loss: 384.4933, MinusLogProbMetric: 384.4933, val_loss: 393.2536, val_MinusLogProbMetric: 393.2536

Epoch 491: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4933 - MinusLogProbMetric: 384.4933 - val_loss: 393.2536 - val_MinusLogProbMetric: 393.2536 - lr: 2.0833e-05 - 11s/epoch - 55ms/step
Epoch 492/1000
2023-09-10 03:19:19.436 
Epoch 492/1000 
	 loss: 384.3925, MinusLogProbMetric: 384.3925, val_loss: 393.8534, val_MinusLogProbMetric: 393.8534

Epoch 492: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.3925 - MinusLogProbMetric: 384.3925 - val_loss: 393.8534 - val_MinusLogProbMetric: 393.8534 - lr: 2.0833e-05 - 12s/epoch - 60ms/step
Epoch 493/1000
2023-09-10 03:19:30.259 
Epoch 493/1000 
	 loss: 384.4478, MinusLogProbMetric: 384.4478, val_loss: 393.3709, val_MinusLogProbMetric: 393.3709

Epoch 493: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4478 - MinusLogProbMetric: 384.4478 - val_loss: 393.3709 - val_MinusLogProbMetric: 393.3709 - lr: 2.0833e-05 - 11s/epoch - 55ms/step
Epoch 494/1000
2023-09-10 03:19:43.946 
Epoch 494/1000 
	 loss: 384.4024, MinusLogProbMetric: 384.4024, val_loss: 393.2317, val_MinusLogProbMetric: 393.2317

Epoch 494: val_loss did not improve from 393.02448
196/196 - 14s - loss: 384.4024 - MinusLogProbMetric: 384.4024 - val_loss: 393.2317 - val_MinusLogProbMetric: 393.2317 - lr: 2.0833e-05 - 14s/epoch - 70ms/step
Epoch 495/1000
2023-09-10 03:19:55.701 
Epoch 495/1000 
	 loss: 384.3782, MinusLogProbMetric: 384.3782, val_loss: 393.3632, val_MinusLogProbMetric: 393.3632

Epoch 495: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.3782 - MinusLogProbMetric: 384.3782 - val_loss: 393.3632 - val_MinusLogProbMetric: 393.3632 - lr: 2.0833e-05 - 12s/epoch - 60ms/step
Epoch 496/1000
2023-09-10 03:20:06.228 
Epoch 496/1000 
	 loss: 384.4291, MinusLogProbMetric: 384.4291, val_loss: 393.3060, val_MinusLogProbMetric: 393.3060

Epoch 496: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.4291 - MinusLogProbMetric: 384.4291 - val_loss: 393.3060 - val_MinusLogProbMetric: 393.3060 - lr: 2.0833e-05 - 11s/epoch - 54ms/step
Epoch 497/1000
2023-09-10 03:20:17.988 
Epoch 497/1000 
	 loss: 384.4411, MinusLogProbMetric: 384.4411, val_loss: 393.2956, val_MinusLogProbMetric: 393.2956

Epoch 497: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.4411 - MinusLogProbMetric: 384.4411 - val_loss: 393.2956 - val_MinusLogProbMetric: 393.2956 - lr: 2.0833e-05 - 12s/epoch - 60ms/step
Epoch 498/1000
2023-09-10 03:20:30.250 
Epoch 498/1000 
	 loss: 384.3928, MinusLogProbMetric: 384.3928, val_loss: 393.2002, val_MinusLogProbMetric: 393.2002

Epoch 498: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.3928 - MinusLogProbMetric: 384.3928 - val_loss: 393.2002 - val_MinusLogProbMetric: 393.2002 - lr: 2.0833e-05 - 12s/epoch - 63ms/step
Epoch 499/1000
2023-09-10 03:20:40.947 
Epoch 499/1000 
	 loss: 384.1792, MinusLogProbMetric: 384.1792, val_loss: 393.0975, val_MinusLogProbMetric: 393.0975

Epoch 499: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1792 - MinusLogProbMetric: 384.1792 - val_loss: 393.0975 - val_MinusLogProbMetric: 393.0975 - lr: 1.0417e-05 - 11s/epoch - 54ms/step
Epoch 500/1000
2023-09-10 03:20:55.549 
Epoch 500/1000 
	 loss: 384.1716, MinusLogProbMetric: 384.1716, val_loss: 393.0466, val_MinusLogProbMetric: 393.0466

Epoch 500: val_loss did not improve from 393.02448
196/196 - 15s - loss: 384.1716 - MinusLogProbMetric: 384.1716 - val_loss: 393.0466 - val_MinusLogProbMetric: 393.0466 - lr: 1.0417e-05 - 15s/epoch - 75ms/step
Epoch 501/1000
2023-09-10 03:21:07.928 
Epoch 501/1000 
	 loss: 384.1785, MinusLogProbMetric: 384.1785, val_loss: 393.0754, val_MinusLogProbMetric: 393.0754

Epoch 501: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1785 - MinusLogProbMetric: 384.1785 - val_loss: 393.0754 - val_MinusLogProbMetric: 393.0754 - lr: 1.0417e-05 - 12s/epoch - 63ms/step
Epoch 502/1000
2023-09-10 03:21:19.320 
Epoch 502/1000 
	 loss: 384.1723, MinusLogProbMetric: 384.1723, val_loss: 393.0971, val_MinusLogProbMetric: 393.0971

Epoch 502: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1723 - MinusLogProbMetric: 384.1723 - val_loss: 393.0971 - val_MinusLogProbMetric: 393.0971 - lr: 1.0417e-05 - 11s/epoch - 58ms/step
Epoch 503/1000
2023-09-10 03:21:30.240 
Epoch 503/1000 
	 loss: 384.1970, MinusLogProbMetric: 384.1970, val_loss: 393.3060, val_MinusLogProbMetric: 393.3060

Epoch 503: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1970 - MinusLogProbMetric: 384.1970 - val_loss: 393.3060 - val_MinusLogProbMetric: 393.3060 - lr: 1.0417e-05 - 11s/epoch - 56ms/step
Epoch 504/1000
2023-09-10 03:21:41.720 
Epoch 504/1000 
	 loss: 384.2062, MinusLogProbMetric: 384.2062, val_loss: 393.0408, val_MinusLogProbMetric: 393.0408

Epoch 504: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.2062 - MinusLogProbMetric: 384.2062 - val_loss: 393.0408 - val_MinusLogProbMetric: 393.0408 - lr: 1.0417e-05 - 11s/epoch - 59ms/step
Epoch 505/1000
2023-09-10 03:21:53.200 
Epoch 505/1000 
	 loss: 384.1801, MinusLogProbMetric: 384.1801, val_loss: 393.1032, val_MinusLogProbMetric: 393.1032

Epoch 505: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1801 - MinusLogProbMetric: 384.1801 - val_loss: 393.1032 - val_MinusLogProbMetric: 393.1032 - lr: 1.0417e-05 - 11s/epoch - 58ms/step
Epoch 506/1000
2023-09-10 03:22:04.496 
Epoch 506/1000 
	 loss: 384.1839, MinusLogProbMetric: 384.1839, val_loss: 393.0893, val_MinusLogProbMetric: 393.0893

Epoch 506: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1839 - MinusLogProbMetric: 384.1839 - val_loss: 393.0893 - val_MinusLogProbMetric: 393.0893 - lr: 1.0417e-05 - 11s/epoch - 57ms/step
Epoch 507/1000
2023-09-10 03:22:16.856 
Epoch 507/1000 
	 loss: 384.2020, MinusLogProbMetric: 384.2020, val_loss: 393.0818, val_MinusLogProbMetric: 393.0818

Epoch 507: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.2020 - MinusLogProbMetric: 384.2020 - val_loss: 393.0818 - val_MinusLogProbMetric: 393.0818 - lr: 1.0417e-05 - 12s/epoch - 63ms/step
Epoch 508/1000
2023-09-10 03:22:26.836 
Epoch 508/1000 
	 loss: 384.1850, MinusLogProbMetric: 384.1850, val_loss: 393.1164, val_MinusLogProbMetric: 393.1164

Epoch 508: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.1850 - MinusLogProbMetric: 384.1850 - val_loss: 393.1164 - val_MinusLogProbMetric: 393.1164 - lr: 1.0417e-05 - 10s/epoch - 51ms/step
Epoch 509/1000
2023-09-10 03:22:40.989 
Epoch 509/1000 
	 loss: 384.1787, MinusLogProbMetric: 384.1787, val_loss: 393.0847, val_MinusLogProbMetric: 393.0847

Epoch 509: val_loss did not improve from 393.02448
196/196 - 14s - loss: 384.1787 - MinusLogProbMetric: 384.1787 - val_loss: 393.0847 - val_MinusLogProbMetric: 393.0847 - lr: 1.0417e-05 - 14s/epoch - 72ms/step
Epoch 510/1000
2023-09-10 03:22:50.738 
Epoch 510/1000 
	 loss: 384.1809, MinusLogProbMetric: 384.1809, val_loss: 393.0939, val_MinusLogProbMetric: 393.0939

Epoch 510: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.1809 - MinusLogProbMetric: 384.1809 - val_loss: 393.0939 - val_MinusLogProbMetric: 393.0939 - lr: 1.0417e-05 - 10s/epoch - 50ms/step
Epoch 511/1000
2023-09-10 03:23:03.636 
Epoch 511/1000 
	 loss: 384.1851, MinusLogProbMetric: 384.1851, val_loss: 393.1848, val_MinusLogProbMetric: 393.1848

Epoch 511: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.1851 - MinusLogProbMetric: 384.1851 - val_loss: 393.1848 - val_MinusLogProbMetric: 393.1848 - lr: 1.0417e-05 - 13s/epoch - 66ms/step
Epoch 512/1000
2023-09-10 03:23:14.344 
Epoch 512/1000 
	 loss: 384.1723, MinusLogProbMetric: 384.1723, val_loss: 393.1916, val_MinusLogProbMetric: 393.1916

Epoch 512: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1723 - MinusLogProbMetric: 384.1723 - val_loss: 393.1916 - val_MinusLogProbMetric: 393.1916 - lr: 1.0417e-05 - 11s/epoch - 55ms/step
Epoch 513/1000
2023-09-10 03:23:26.640 
Epoch 513/1000 
	 loss: 384.1932, MinusLogProbMetric: 384.1932, val_loss: 393.3632, val_MinusLogProbMetric: 393.3632

Epoch 513: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1932 - MinusLogProbMetric: 384.1932 - val_loss: 393.3632 - val_MinusLogProbMetric: 393.3632 - lr: 1.0417e-05 - 12s/epoch - 63ms/step
Epoch 514/1000
2023-09-10 03:23:37.036 
Epoch 514/1000 
	 loss: 384.2310, MinusLogProbMetric: 384.2310, val_loss: 393.2395, val_MinusLogProbMetric: 393.2395

Epoch 514: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.2310 - MinusLogProbMetric: 384.2310 - val_loss: 393.2395 - val_MinusLogProbMetric: 393.2395 - lr: 1.0417e-05 - 10s/epoch - 53ms/step
Epoch 515/1000
2023-09-10 03:23:49.536 
Epoch 515/1000 
	 loss: 384.2056, MinusLogProbMetric: 384.2056, val_loss: 393.0479, val_MinusLogProbMetric: 393.0479

Epoch 515: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.2056 - MinusLogProbMetric: 384.2056 - val_loss: 393.0479 - val_MinusLogProbMetric: 393.0479 - lr: 1.0417e-05 - 12s/epoch - 64ms/step
Epoch 516/1000
2023-09-10 03:24:00.781 
Epoch 516/1000 
	 loss: 384.1752, MinusLogProbMetric: 384.1752, val_loss: 393.2331, val_MinusLogProbMetric: 393.2331

Epoch 516: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1752 - MinusLogProbMetric: 384.1752 - val_loss: 393.2331 - val_MinusLogProbMetric: 393.2331 - lr: 1.0417e-05 - 11s/epoch - 57ms/step
Epoch 517/1000
2023-09-10 03:24:12.777 
Epoch 517/1000 
	 loss: 384.1851, MinusLogProbMetric: 384.1851, val_loss: 393.1104, val_MinusLogProbMetric: 393.1104

Epoch 517: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1851 - MinusLogProbMetric: 384.1851 - val_loss: 393.1104 - val_MinusLogProbMetric: 393.1104 - lr: 1.0417e-05 - 12s/epoch - 61ms/step
Epoch 518/1000
2023-09-10 03:24:24.954 
Epoch 518/1000 
	 loss: 384.1716, MinusLogProbMetric: 384.1716, val_loss: 393.1627, val_MinusLogProbMetric: 393.1627

Epoch 518: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1716 - MinusLogProbMetric: 384.1716 - val_loss: 393.1627 - val_MinusLogProbMetric: 393.1627 - lr: 1.0417e-05 - 12s/epoch - 62ms/step
Epoch 519/1000
2023-09-10 03:24:35.597 
Epoch 519/1000 
	 loss: 384.1640, MinusLogProbMetric: 384.1640, val_loss: 393.1192, val_MinusLogProbMetric: 393.1192

Epoch 519: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1640 - MinusLogProbMetric: 384.1640 - val_loss: 393.1192 - val_MinusLogProbMetric: 393.1192 - lr: 1.0417e-05 - 11s/epoch - 54ms/step
Epoch 520/1000
2023-09-10 03:24:46.508 
Epoch 520/1000 
	 loss: 384.1646, MinusLogProbMetric: 384.1646, val_loss: 393.1968, val_MinusLogProbMetric: 393.1968

Epoch 520: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1646 - MinusLogProbMetric: 384.1646 - val_loss: 393.1968 - val_MinusLogProbMetric: 393.1968 - lr: 1.0417e-05 - 11s/epoch - 56ms/step
Epoch 521/1000
2023-09-10 03:24:59.292 
Epoch 521/1000 
	 loss: 384.1470, MinusLogProbMetric: 384.1470, val_loss: 393.1256, val_MinusLogProbMetric: 393.1256

Epoch 521: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.1470 - MinusLogProbMetric: 384.1470 - val_loss: 393.1256 - val_MinusLogProbMetric: 393.1256 - lr: 1.0417e-05 - 13s/epoch - 65ms/step
Epoch 522/1000
2023-09-10 03:25:09.558 
Epoch 522/1000 
	 loss: 384.1417, MinusLogProbMetric: 384.1417, val_loss: 393.1679, val_MinusLogProbMetric: 393.1679

Epoch 522: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.1417 - MinusLogProbMetric: 384.1417 - val_loss: 393.1679 - val_MinusLogProbMetric: 393.1679 - lr: 1.0417e-05 - 10s/epoch - 52ms/step
Epoch 523/1000
2023-09-10 03:25:21.944 
Epoch 523/1000 
	 loss: 384.1497, MinusLogProbMetric: 384.1497, val_loss: 393.1547, val_MinusLogProbMetric: 393.1547

Epoch 523: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1497 - MinusLogProbMetric: 384.1497 - val_loss: 393.1547 - val_MinusLogProbMetric: 393.1547 - lr: 1.0417e-05 - 12s/epoch - 63ms/step
Epoch 524/1000
2023-09-10 03:25:34.640 
Epoch 524/1000 
	 loss: 384.1460, MinusLogProbMetric: 384.1460, val_loss: 393.1207, val_MinusLogProbMetric: 393.1207

Epoch 524: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.1460 - MinusLogProbMetric: 384.1460 - val_loss: 393.1207 - val_MinusLogProbMetric: 393.1207 - lr: 1.0417e-05 - 13s/epoch - 65ms/step
Epoch 525/1000
2023-09-10 03:25:46.354 
Epoch 525/1000 
	 loss: 384.1523, MinusLogProbMetric: 384.1523, val_loss: 393.3953, val_MinusLogProbMetric: 393.3953

Epoch 525: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1523 - MinusLogProbMetric: 384.1523 - val_loss: 393.3953 - val_MinusLogProbMetric: 393.3953 - lr: 1.0417e-05 - 12s/epoch - 60ms/step
Epoch 526/1000
2023-09-10 03:25:57.998 
Epoch 526/1000 
	 loss: 384.1609, MinusLogProbMetric: 384.1609, val_loss: 393.1120, val_MinusLogProbMetric: 393.1120

Epoch 526: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1609 - MinusLogProbMetric: 384.1609 - val_loss: 393.1120 - val_MinusLogProbMetric: 393.1120 - lr: 1.0417e-05 - 12s/epoch - 59ms/step
Epoch 527/1000
2023-09-10 03:26:09.590 
Epoch 527/1000 
	 loss: 384.1483, MinusLogProbMetric: 384.1483, val_loss: 393.0964, val_MinusLogProbMetric: 393.0964

Epoch 527: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1483 - MinusLogProbMetric: 384.1483 - val_loss: 393.0964 - val_MinusLogProbMetric: 393.0964 - lr: 1.0417e-05 - 12s/epoch - 59ms/step
Epoch 528/1000
2023-09-10 03:26:22.643 
Epoch 528/1000 
	 loss: 384.1507, MinusLogProbMetric: 384.1507, val_loss: 393.1043, val_MinusLogProbMetric: 393.1043

Epoch 528: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.1507 - MinusLogProbMetric: 384.1507 - val_loss: 393.1043 - val_MinusLogProbMetric: 393.1043 - lr: 1.0417e-05 - 13s/epoch - 67ms/step
Epoch 529/1000
2023-09-10 03:26:33.133 
Epoch 529/1000 
	 loss: 384.1558, MinusLogProbMetric: 384.1558, val_loss: 393.0909, val_MinusLogProbMetric: 393.0909

Epoch 529: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.1558 - MinusLogProbMetric: 384.1558 - val_loss: 393.0909 - val_MinusLogProbMetric: 393.0909 - lr: 1.0417e-05 - 10s/epoch - 54ms/step
Epoch 530/1000
2023-09-10 03:26:45.669 
Epoch 530/1000 
	 loss: 384.1414, MinusLogProbMetric: 384.1414, val_loss: 393.1176, val_MinusLogProbMetric: 393.1176

Epoch 530: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.1414 - MinusLogProbMetric: 384.1414 - val_loss: 393.1176 - val_MinusLogProbMetric: 393.1176 - lr: 1.0417e-05 - 13s/epoch - 64ms/step
Epoch 531/1000
2023-09-10 03:26:57.191 
Epoch 531/1000 
	 loss: 384.1552, MinusLogProbMetric: 384.1552, val_loss: 393.1164, val_MinusLogProbMetric: 393.1164

Epoch 531: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1552 - MinusLogProbMetric: 384.1552 - val_loss: 393.1164 - val_MinusLogProbMetric: 393.1164 - lr: 1.0417e-05 - 12s/epoch - 59ms/step
Epoch 532/1000
2023-09-10 03:27:08.600 
Epoch 532/1000 
	 loss: 384.1457, MinusLogProbMetric: 384.1457, val_loss: 393.0294, val_MinusLogProbMetric: 393.0294

Epoch 532: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1457 - MinusLogProbMetric: 384.1457 - val_loss: 393.0294 - val_MinusLogProbMetric: 393.0294 - lr: 1.0417e-05 - 11s/epoch - 58ms/step
Epoch 533/1000
2023-09-10 03:27:20.809 
Epoch 533/1000 
	 loss: 384.1351, MinusLogProbMetric: 384.1351, val_loss: 393.1539, val_MinusLogProbMetric: 393.1539

Epoch 533: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1351 - MinusLogProbMetric: 384.1351 - val_loss: 393.1539 - val_MinusLogProbMetric: 393.1539 - lr: 1.0417e-05 - 12s/epoch - 62ms/step
Epoch 534/1000
2023-09-10 03:27:31.288 
Epoch 534/1000 
	 loss: 384.1421, MinusLogProbMetric: 384.1421, val_loss: 393.2918, val_MinusLogProbMetric: 393.2918

Epoch 534: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.1421 - MinusLogProbMetric: 384.1421 - val_loss: 393.2918 - val_MinusLogProbMetric: 393.2918 - lr: 1.0417e-05 - 10s/epoch - 53ms/step
Epoch 535/1000
2023-09-10 03:27:43.527 
Epoch 535/1000 
	 loss: 384.1564, MinusLogProbMetric: 384.1564, val_loss: 393.1344, val_MinusLogProbMetric: 393.1344

Epoch 535: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1564 - MinusLogProbMetric: 384.1564 - val_loss: 393.1344 - val_MinusLogProbMetric: 393.1344 - lr: 1.0417e-05 - 12s/epoch - 62ms/step
Epoch 536/1000
2023-09-10 03:27:53.396 
Epoch 536/1000 
	 loss: 384.1386, MinusLogProbMetric: 384.1386, val_loss: 393.1640, val_MinusLogProbMetric: 393.1640

Epoch 536: val_loss did not improve from 393.02448
196/196 - 10s - loss: 384.1386 - MinusLogProbMetric: 384.1386 - val_loss: 393.1640 - val_MinusLogProbMetric: 393.1640 - lr: 1.0417e-05 - 10s/epoch - 50ms/step
Epoch 537/1000
2023-09-10 03:28:05.472 
Epoch 537/1000 
	 loss: 384.1265, MinusLogProbMetric: 384.1265, val_loss: 393.2133, val_MinusLogProbMetric: 393.2133

Epoch 537: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1265 - MinusLogProbMetric: 384.1265 - val_loss: 393.2133 - val_MinusLogProbMetric: 393.2133 - lr: 1.0417e-05 - 12s/epoch - 62ms/step
Epoch 538/1000
2023-09-10 03:28:16.681 
Epoch 538/1000 
	 loss: 384.1229, MinusLogProbMetric: 384.1229, val_loss: 393.0404, val_MinusLogProbMetric: 393.0404

Epoch 538: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1229 - MinusLogProbMetric: 384.1229 - val_loss: 393.0404 - val_MinusLogProbMetric: 393.0404 - lr: 1.0417e-05 - 11s/epoch - 57ms/step
Epoch 539/1000
2023-09-10 03:28:28.935 
Epoch 539/1000 
	 loss: 384.1227, MinusLogProbMetric: 384.1227, val_loss: 393.0970, val_MinusLogProbMetric: 393.0970

Epoch 539: val_loss did not improve from 393.02448
196/196 - 12s - loss: 384.1227 - MinusLogProbMetric: 384.1227 - val_loss: 393.0970 - val_MinusLogProbMetric: 393.0970 - lr: 1.0417e-05 - 12s/epoch - 63ms/step
Epoch 540/1000
2023-09-10 03:28:42.122 
Epoch 540/1000 
	 loss: 384.1226, MinusLogProbMetric: 384.1226, val_loss: 393.1123, val_MinusLogProbMetric: 393.1123

Epoch 540: val_loss did not improve from 393.02448
196/196 - 13s - loss: 384.1226 - MinusLogProbMetric: 384.1226 - val_loss: 393.1123 - val_MinusLogProbMetric: 393.1123 - lr: 1.0417e-05 - 13s/epoch - 67ms/step
Epoch 541/1000
2023-09-10 03:28:53.566 
Epoch 541/1000 
	 loss: 384.1170, MinusLogProbMetric: 384.1170, val_loss: 393.1014, val_MinusLogProbMetric: 393.1014

Epoch 541: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1170 - MinusLogProbMetric: 384.1170 - val_loss: 393.1014 - val_MinusLogProbMetric: 393.1014 - lr: 1.0417e-05 - 11s/epoch - 58ms/step
Epoch 542/1000
2023-09-10 03:29:07.260 
Epoch 542/1000 
	 loss: 384.1355, MinusLogProbMetric: 384.1355, val_loss: 393.1164, val_MinusLogProbMetric: 393.1164

Epoch 542: val_loss did not improve from 393.02448
196/196 - 14s - loss: 384.1355 - MinusLogProbMetric: 384.1355 - val_loss: 393.1164 - val_MinusLogProbMetric: 393.1164 - lr: 1.0417e-05 - 14s/epoch - 70ms/step
Epoch 543/1000
2023-09-10 03:29:18.554 
Epoch 543/1000 
	 loss: 384.1412, MinusLogProbMetric: 384.1412, val_loss: 393.1836, val_MinusLogProbMetric: 393.1836

Epoch 543: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1412 - MinusLogProbMetric: 384.1412 - val_loss: 393.1836 - val_MinusLogProbMetric: 393.1836 - lr: 1.0417e-05 - 11s/epoch - 58ms/step
Epoch 544/1000
2023-09-10 03:29:29.492 
Epoch 544/1000 
	 loss: 384.1212, MinusLogProbMetric: 384.1212, val_loss: 393.1681, val_MinusLogProbMetric: 393.1681

Epoch 544: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1212 - MinusLogProbMetric: 384.1212 - val_loss: 393.1681 - val_MinusLogProbMetric: 393.1681 - lr: 1.0417e-05 - 11s/epoch - 56ms/step
Epoch 545/1000
2023-09-10 03:29:40.442 
Epoch 545/1000 
	 loss: 384.1238, MinusLogProbMetric: 384.1238, val_loss: 393.1979, val_MinusLogProbMetric: 393.1979

Epoch 545: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1238 - MinusLogProbMetric: 384.1238 - val_loss: 393.1979 - val_MinusLogProbMetric: 393.1979 - lr: 1.0417e-05 - 11s/epoch - 56ms/step
Epoch 546/1000
2023-09-10 03:29:51.215 
Epoch 546/1000 
	 loss: 384.1536, MinusLogProbMetric: 384.1536, val_loss: 393.1656, val_MinusLogProbMetric: 393.1656

Epoch 546: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1536 - MinusLogProbMetric: 384.1536 - val_loss: 393.1656 - val_MinusLogProbMetric: 393.1656 - lr: 1.0417e-05 - 11s/epoch - 55ms/step
Epoch 547/1000
2023-09-10 03:30:02.374 
Epoch 547/1000 
	 loss: 384.1615, MinusLogProbMetric: 384.1615, val_loss: 393.1600, val_MinusLogProbMetric: 393.1600

Epoch 547: val_loss did not improve from 393.02448
196/196 - 11s - loss: 384.1615 - MinusLogProbMetric: 384.1615 - val_loss: 393.1600 - val_MinusLogProbMetric: 393.1600 - lr: 1.0417e-05 - 11s/epoch - 57ms/step
Epoch 548/1000
2023-09-10 03:30:12.869 
Epoch 548/1000 
	 loss: 384.1404, MinusLogProbMetric: 384.1404, val_loss: 393.1585, val_MinusLogProbMetric: 393.1585

Epoch 548: val_loss did not improve from 393.02448
Restoring model weights from the end of the best epoch: 448.
196/196 - 11s - loss: 384.1404 - MinusLogProbMetric: 384.1404 - val_loss: 393.1585 - val_MinusLogProbMetric: 393.1585 - lr: 1.0417e-05 - 11s/epoch - 54ms/step
Epoch 548: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 1044.2886621169746 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 1077.3628017589217 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1043.8646497799782 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 1071.662372492021 seconds.
Training succeeded with seed 377.
Model trained in 6501.96 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 4366.12 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 4366.92 s.
===========
Run 330/360 done in 11182.32 s.
===========

===========
Generating train data for run 331.
===========
Train data generated in 2.45 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_331/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_331/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_331/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_331
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.437488    7.1322474   6.533019   ...  9.559031    1.9697884
   6.253516  ]
 [ 6.105814   -0.33694893  4.861082   ...  4.728712    6.8399925
   2.9518385 ]
 [ 5.5099134   8.416618    3.6192868  ... 10.13037     0.5513004
   6.6116333 ]
 ...
 [ 8.378759    5.1539607   5.2823405  ...  4.1604185   7.9323363
   6.8563857 ]
 [ 8.088472    5.184855    5.311574   ...  3.8879027   7.132432
   7.66768   ]
 [ 5.6874776   6.932827    6.1243634  ...  9.540177    3.2688973
   7.1452303 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_25 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_4 (LogProbLa  (None,)                  4191520   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,191,520
Trainable params: 4,191,520
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_4/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_4'")
self.model: <keras.engine.functional.Functional object at 0x7efbb8485750>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effed3099f0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effed3099f0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effed30a620>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7effed0c1d50>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7effed11e170>, <keras.callbacks.ModelCheckpoint object at 0x7effed2c1810>, <keras.callbacks.EarlyStopping object at 0x7effed11ec80>, <keras.callbacks.ReduceLROnPlateau object at 0x7effed309de0>, <keras.callbacks.TerminateOnNaN object at 0x7effed309d80>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_331/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 331/360 with hyperparameters:
timestamp = 2023-09-10 04:43:08.369915
ndims = 1000
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 4191520
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.43748808e+00  7.13224745e+00  6.53301907e+00  5.31066608e+00
  3.79545021e+00  6.28738737e+00  2.71391177e+00  8.88872051e+00
  9.43951797e+00  4.12179470e+00  7.81367683e+00  5.36657619e+00
  5.55121899e+00  9.56866932e+00  7.94146359e-01  9.63486314e-01
 -1.46448463e-02  7.97977352e+00  8.35143089e+00  9.09444618e+00
  9.51050758e+00  8.15759563e+00  4.87677431e+00  8.12364483e+00
 -5.86649776e-01  6.22392607e+00  1.30506945e+00  9.45408440e+00
  7.08888865e+00  3.35072994e+00  2.25734115e+00  8.41814995e+00
  4.58319330e+00  5.61194181e+00  2.26602942e-01  5.45686245e+00
  6.14353561e+00  6.25023174e+00  9.57346344e+00  6.36795044e+00
  3.20757818e+00  4.83043623e+00  7.51926565e+00  6.34396672e-01
  6.89045191e+00  6.62100124e+00  2.44563007e+00  1.28772116e+00
  3.22250342e+00  4.52788544e+00  5.89035130e+00  4.86346960e+00
  9.48264980e+00 -1.13163722e+00  3.37091446e+00  9.05362010e-01
  6.78129101e+00  1.94818664e+00  4.17912102e+00  3.18960547e+00
  1.62776482e+00  1.21974039e+00  7.33607817e+00  1.62089002e+00
  2.96397400e+00  4.52560091e+00  8.39162827e+00  1.51216686e+00
  8.25380135e+00  5.98394752e-01  9.67017937e+00  4.48699141e+00
  1.02882853e+01  5.70898390e+00  6.28753185e+00  6.97938085e-01
  2.82613039e+00  1.18152845e+00  2.21910620e+00  1.18442059e-01
  3.30913496e+00  4.37123442e+00 -6.00820422e-01  7.13190508e+00
  5.83363104e+00  2.43325353e+00  5.20436668e+00  1.77731943e+00
  6.29233789e+00  9.14511585e+00  2.47849083e+00  7.14207220e+00
  1.59640992e+00  7.87721014e+00  3.72595000e+00  1.65804911e+00
  6.26306725e+00  6.14266574e-01  9.35802937e+00 -5.55100851e-02
  6.81794071e+00  2.07937002e+00  7.28380156e+00  1.05093136e+01
  1.40520501e+00  5.19018650e+00  6.29479265e+00  5.23412371e+00
  2.19359255e+00  9.70839596e+00  4.63605547e+00  9.80713272e+00
  6.71604156e+00  2.83194685e+00  8.21691513e+00  3.91888070e+00
  8.82857418e+00  5.65095377e+00  7.74853373e+00  6.66070604e+00
  8.72240067e+00  4.82063627e+00  9.65159893e+00  7.37593651e+00
  5.52394199e+00  6.06229258e+00  6.28078938e-01  3.63155842e+00
  6.63515043e+00  3.13720345e+00  6.10160494e+00  4.59917688e+00
  1.67009079e+00  2.67929316e+00  5.87469530e+00  5.35120296e+00
  5.20565653e+00  6.30662727e+00  7.39564276e+00  4.35430813e+00
  8.88551044e+00  2.87358689e+00  4.32844305e+00  9.07120323e+00
  8.34959602e+00  6.54305315e+00  6.36145771e-01  9.69855213e+00
  6.49582243e+00  1.02082977e+01  1.42218649e+00  7.77432966e+00
  1.58041847e+00  6.40702820e+00  1.07924449e+00  8.47589207e+00
  8.23396206e+00  5.41745853e+00  3.85215545e+00  7.45270491e-01
  6.41533756e+00  4.21811962e+00  7.45381451e+00  8.68435764e+00
  9.59165764e+00  9.22718906e+00 -1.01518297e+00  4.78479671e+00
  7.09206533e+00  2.16092372e+00  5.71304035e+00  1.19908273e-01
  3.16043782e+00  9.20669734e-02  8.17029667e+00  2.31537890e+00
  3.80825901e+00  9.06393814e+00  7.17630625e+00  1.20758474e-01
  1.57467747e+00  6.56413174e+00  5.80603886e+00  1.90417314e+00
  9.26850033e+00  5.71055651e+00  5.48348093e+00  5.70006657e+00
  7.34501457e+00  3.06974077e+00  4.17449951e+00  1.88637686e+00
  1.59649813e+00  8.74714470e+00  7.68149471e+00  5.14725018e+00
  1.94792962e+00  2.93671155e+00  6.94045722e-01  4.93041849e+00
  2.29451370e+00  6.96200371e+00  2.94133329e+00  7.65987992e-01
 -2.16490626e-02  6.85447574e-01  6.85941124e+00  4.85409117e+00
  5.72059441e+00  8.98723507e+00  9.62737179e+00  2.21571255e+00
  6.79449415e+00  2.29369974e+00  5.30113637e-01  7.87245512e+00
  3.63518763e+00  4.00529575e+00  5.20808411e+00  8.23005772e+00
  6.37014103e+00  8.26017952e+00  3.29657626e+00  7.93651295e+00
  1.78429985e+00  9.56696796e+00  7.06810617e+00  2.25382471e+00
  9.54646778e+00  7.23986912e+00  2.52804947e+00  2.58364177e+00
  5.52888250e+00  1.77395463e-01  2.06791592e+00  4.35356903e+00
  3.59637356e+00  3.74388838e+00  2.40446615e+00  5.81385517e+00
  8.67110729e+00  1.17576969e+00  4.94048452e+00  9.40345764e-01
  6.09276962e+00  3.86963511e+00  6.18902493e+00  1.56115341e+00
  2.90525699e+00  4.87162495e+00  3.71526504e+00  9.40074253e+00
  7.42161226e+00  7.27192879e+00  1.00699673e+01  1.18854022e+00
  5.78801632e+00  5.48251772e+00  9.94960403e+00  2.90021896e+00
  4.43213892e+00  4.77912188e-01  3.98015082e-01  1.12766476e+01
  6.74848080e+00  7.22801781e+00  2.82795882e+00  5.88993359e+00
  6.98136806e-01  3.23450828e+00  9.72003841e+00  8.30174351e+00
  3.07273555e+00  9.91379070e+00  1.91660452e+00  9.71661282e+00
  9.90089893e+00  8.15846062e+00  7.03740978e+00  9.58544540e+00
  2.93002963e+00  8.31967926e+00  5.99808025e+00  7.28550479e-02
  3.85735941e+00  9.70761538e-01  9.23753738e+00  5.46686459e+00
  5.50278473e+00  6.01728964e+00  4.34324074e+00  1.36993062e+00
  8.45484543e+00  4.68175888e-01  5.26911163e+00  1.84141123e+00
  3.81864011e-01  7.90763950e+00  9.70255852e+00  9.84720516e+00
  9.43443680e+00  7.68962574e+00  3.80397248e+00  6.65612042e-01
  5.16863966e+00  2.47927332e+00  4.73985672e-01  1.05347097e+00
  7.32991314e+00  9.36276674e-01  7.35460091e+00  1.67862105e+00
  4.33905751e-01  1.59291720e+00  7.84084034e+00  2.43011403e+00
  4.25165033e+00  5.68983269e+00  8.60872746e+00  7.16398525e+00
  2.72054410e+00  1.94252491e+00 -1.85395658e-01  3.34451747e+00
  1.99218881e+00  3.79499388e+00  5.96836662e+00  7.37168837e+00
  2.49210262e+00  3.98509121e+00  9.37832177e-01  8.80943108e+00
  2.57825583e-01  6.98963022e+00  7.78174019e+00  7.89891291e+00
  2.61566496e+00  3.04674053e+00  6.46863794e+00  2.90103054e+00
  4.06367350e+00  2.83596921e+00  5.16630077e+00  6.22896612e-01
  7.82478142e+00  3.80227089e-01  3.55100584e+00  3.55920887e+00
  5.84608507e+00  9.32784271e+00  6.44432068e+00  6.71383977e-01
  3.80863142e+00  5.12159157e+00  5.26213694e+00  6.50915527e+00
  3.31823993e+00  1.51588440e+00  3.74508786e+00  9.63789845e+00
  2.82012701e+00  9.30117702e+00  5.18297386e+00  5.08122492e+00
  9.10340309e+00  4.14017344e+00  8.16922951e+00  3.49889684e+00
  9.15036392e+00  7.04796791e+00  6.91863298e+00  3.43821239e+00
  7.49771976e+00  6.58094883e+00  1.52206314e+00  1.66219306e+00
  8.96467304e+00  9.71891689e+00  6.03888035e+00  6.12453365e+00
  8.36337280e+00  4.72068548e+00  7.40723658e+00  4.66089344e+00
  9.60812855e+00  1.02327881e+01  8.27917576e+00  1.76802504e+00
  5.86829615e+00  4.09585905e+00 -5.26962698e-01  4.35076141e+00
  2.46013212e+00  8.68481445e+00  3.86820614e-01  9.69470692e+00
  3.67586684e+00  3.92413521e+00 -9.84535664e-02  2.63078451e+00
  4.00670385e+00  1.10941935e+01  5.17772198e-01  9.30033970e+00
  9.24112511e+00  2.92216539e+00  3.37561965e+00  2.46589732e+00
  6.14229774e+00  4.67309088e-01 -8.67828280e-02  4.08560181e+00
  3.99175465e-01  2.54151607e+00  2.21575212e+00  2.50912642e+00
  1.27955842e+00 -7.25474238e-01  8.21681261e-01  6.53614998e+00
  1.04211264e+01  9.34315395e+00  3.89995766e+00  3.41503716e+00
  6.30898190e+00  4.78263617e+00  1.00384960e+01  1.44826126e+00
  8.01760387e+00  3.30487871e+00  2.22230029e+00  6.98749399e+00
  2.56673408e+00  6.51266956e+00  5.16357517e+00  4.21222687e+00
  5.53316402e+00  2.87564898e+00  6.88569880e+00  5.24295902e+00
  3.83784485e+00  8.63262177e+00  9.42399979e+00  4.50341552e-01
  2.33270240e+00  2.46700525e+00  8.57210445e+00  9.93498421e+00
  9.70180130e+00  9.04918671e+00  2.82848668e+00  1.01604681e+01
  2.13376069e+00  1.08001816e+00  1.01585007e+01  2.37143421e+00
  6.89639854e+00  6.13785625e-01  6.39277411e+00  8.98899841e+00
  3.29311657e+00  3.45347357e+00  3.81167507e+00  7.88749123e+00
  1.59779358e+00  5.66715002e-01  4.65487051e+00  4.15191126e+00
  8.22690773e+00  2.27221990e+00  5.74325514e+00  9.80365372e+00
  6.51945877e+00  8.45271111e+00  9.52017021e+00  7.24792719e+00
  6.43911409e+00  8.51561165e+00  1.02915831e+01  4.50498724e+00
  9.14542615e-01  2.86150455e+00  2.13800192e-01  3.66317129e+00
  1.32120097e+00  6.51088238e+00  3.09616232e+00  9.20569038e+00
  9.73210716e+00  5.21707201e+00  3.67960548e+00  5.34920645e+00
  8.44879818e+00  4.15654373e+00  5.51069403e+00  2.64717555e+00
  4.56229973e+00  4.03184319e+00  2.53720236e+00  4.99534702e+00
  2.31029892e+00  3.48865128e+00  8.25072670e+00  7.54355812e+00
  2.20225477e+00  1.13970642e+01  8.49588680e+00  7.10883319e-01
  2.74363828e+00  4.99293470e+00  1.34385705e-01  3.21501279e+00
  8.21650314e+00  6.79964018e+00  6.27488852e+00  7.14794111e+00
  1.90239477e+00  3.45294881e+00  7.35099411e+00  9.33995914e+00
  6.05294037e+00  2.90113711e+00 -1.24432337e+00  6.42705727e+00
  5.68964370e-02  3.37960458e+00  4.96043348e+00  9.90640545e+00
  1.23383534e+00  4.00741386e+00  6.40055537e-03  3.24708557e+00
  6.32790136e+00  2.19222999e+00  2.08447242e+00  1.32372677e+00
  5.92049932e+00  6.88256168e+00  7.01928997e+00  1.04399967e+01
 -2.88216442e-01  6.52927542e+00  6.16809750e+00  6.00324678e+00
  9.71869183e+00  1.13557257e-01  7.11323690e+00  7.71879911e+00
  5.03887224e+00  3.76561260e+00  8.05337811e+00  3.14987302e-01
  5.12668896e+00  5.27989054e+00  6.75082159e+00  1.43525863e+00
  2.57989788e+00  4.62727022e+00  6.04563522e+00  9.48542213e+00
  7.09511852e+00  1.17622685e+00  9.15441227e+00  9.80256653e+00
  5.09900427e+00  9.44795132e+00  5.51893759e+00  1.03330717e+01
  8.30469704e+00  1.07898369e+01  1.01827803e+01 -5.05745411e-04
  1.73885703e+00  3.52059174e+00  9.45347977e+00  3.41492081e+00
  1.14690316e+00  9.65928459e+00  4.69807243e+00  9.03562832e+00
  1.17234612e+00  6.69798565e+00  4.43081808e+00  8.74517798e-01
  6.92903471e+00  2.09807229e+00 -7.14968681e-01  5.73539436e-01
  6.28464758e-01  8.92654991e+00  8.03050327e+00  9.02817154e+00
  7.40084696e+00  5.17232370e+00  3.25738239e+00  1.01524630e+01
  3.55576420e+00  3.88637328e+00  4.20779133e+00  8.97262955e+00
  1.70729637e+00  3.30006480e+00  5.26616716e+00  9.60324168e-01
  6.40397358e+00  4.05875492e+00  2.62214065e+00  2.05707121e+00
  4.09347248e+00  3.94071198e+00  5.06777287e+00  3.40968561e+00
  8.99762726e+00  1.47003901e+00  8.83282781e-01  3.52675414e+00
  5.27389050e+00  6.61437607e+00  5.19436264e+00  9.38774395e+00
  3.59817815e+00  7.51900101e+00  6.17228937e+00  8.14072514e+00
  1.00964031e+01  8.67543316e+00  7.67522526e+00  6.90801048e+00
  3.51598859e+00  5.34878731e-01  6.36672795e-01  2.41127205e+00
  3.82626390e+00  5.18385172e+00  5.83661032e+00  9.15472126e+00
  8.23223293e-01  2.42483902e+00  5.41429329e+00  8.00633621e+00
  7.98597336e+00  9.41291142e+00  9.83840275e+00  4.71966314e+00
  4.63481140e+00  4.06945586e-01  6.68186712e+00  6.24139881e+00
  8.50881863e+00  7.10938215e-01  4.35715389e+00  5.98537350e+00
  2.39591932e+00  1.52024806e+00  9.15522194e+00  1.84586793e-01
  3.84848523e+00  1.13246572e+00  4.45568275e+00  9.84170437e+00
  4.21756744e+00  6.01763248e+00  7.27610350e-01  3.31445408e+00
  4.36259508e+00  4.26714516e+00  6.67291355e+00  3.47573233e+00
  6.96841526e+00  6.61320925e+00  4.78718519e+00  3.85241342e+00
  5.65875959e+00  9.63071108e-01  8.21956635e+00  7.05007601e+00
  7.35808372e+00  5.60682201e+00  8.74726832e-01  4.78749466e+00
  4.08274555e+00  3.05295515e+00 -2.82806456e-02  7.37880754e+00
  1.13245630e+00  6.21132517e+00  7.19738770e+00  6.62598848e+00
  8.44676971e+00  7.01955557e-01  8.75954437e+00  1.91597685e-01
  6.34029531e+00  4.09656525e+00  4.70814228e+00  3.66343403e+00
  1.92009354e+00 -2.97656119e-01  4.93795109e+00  7.03719902e+00
  3.54990387e+00  2.22650814e+00  1.47342825e+00  1.87733543e+00
  9.82225418e-01  1.97523093e+00  2.90856576e+00 -1.95377409e-01
  7.63740540e-01  8.23801708e+00  1.92524207e+00  4.57951069e+00
  8.07519722e+00  4.80337429e+00  1.63165092e+00  2.09296656e+00
  4.45628262e+00  5.24322176e+00  3.30323172e+00  7.77983236e+00
  7.60303879e+00  8.98269558e+00  3.17642242e-01  9.00031185e+00
  3.89518857e+00  8.87557316e+00  6.54464340e+00  9.40222740e+00
  7.76669884e+00  3.63010335e+00  4.89937687e+00  3.79815769e+00
  3.43109441e+00  2.11776972e+00  4.50608540e+00  6.73585749e+00
  2.77784801e+00  4.75118494e+00  1.41163933e+00  1.43678403e+00
  4.72844005e-01  1.01116915e+01  4.33705822e-02  1.87914848e+00
  6.03755856e+00  1.65911603e+00  9.08522511e+00  7.11956310e+00
  8.27528858e+00  4.67179298e+00  1.46821272e+00  5.57443333e+00
  9.03736591e+00  7.08154297e+00  2.92699647e+00  9.28951740e+00
  3.66812515e+00  1.79973990e-02  2.40762663e+00  1.92846382e+00
  8.69157314e+00  4.33280611e+00  4.23879671e+00  3.11560988e+00
  9.60638237e+00  1.10599823e+01  9.74016571e+00  3.66849303e+00
  9.42271328e+00  8.38017178e+00  6.39697123e+00  3.64649916e+00
  1.97412837e+00  2.19269991e+00  9.55885601e+00  2.80885458e+00
  4.91888142e+00  5.15744495e+00  8.31021786e+00  8.34845829e+00
  1.55545843e+00  3.92147779e+00  8.22108078e+00  7.88888502e+00
  1.22066307e+00  1.52498245e+00  3.15602779e+00  9.93907928e-01
  4.50527048e+00  1.36449265e+00  5.00522995e+00  2.42850351e+00
  5.87198400e+00 -1.04476917e+00  9.73143959e+00  9.51038170e+00
  4.31158495e+00  3.61805153e+00  1.88797522e+00  5.04972935e+00
  4.03085709e-01  4.60245562e+00  3.75540328e+00  4.01810455e+00
  8.59900475e+00  7.06478453e+00  9.62819099e+00  3.01856041e+00
  9.00697613e+00  8.57353497e+00  4.79125214e+00  6.26140499e+00
  2.85231853e+00  1.06102486e+01  1.06103802e+00  2.18488646e+00
  3.15353966e+00  4.29014683e+00  7.35634613e+00  5.12752581e+00
  4.86164331e+00  6.53155148e-01  5.14040470e+00  5.27053058e-01
  1.85232019e+00  9.85549164e+00  2.36561966e+00  8.83290672e+00
  8.07797718e+00  2.24759030e+00  5.88459301e+00  1.65719461e+00
  7.13856363e+00  6.36659193e+00  8.30550766e+00  4.64638376e+00
  8.86743259e+00 -1.78816348e-01  2.12690020e+00  7.22018147e+00
  4.37131548e+00  1.50182629e+00  1.44224501e+00  8.23597240e+00
  2.87912059e+00  8.82868195e+00  6.72185993e+00  4.10417318e+00
  3.72402120e+00  4.76707935e+00  8.69713497e+00  8.02846813e+00
 -5.91852479e-02  6.92536926e+00  9.99452686e+00  7.10508966e+00
  1.77003264e+00  5.62554789e+00  1.03404069e+00  4.70238781e+00
  9.31285954e+00  8.93695068e+00  2.82111669e+00  3.46559119e+00
  6.18987942e+00  9.39866257e+00  5.47782779e-01  2.72644186e+00
  8.94318962e+00  4.69057751e+00  1.03748589e+01  2.52786398e+00
  5.76243114e+00  3.48165631e+00  3.81163502e+00  3.76940107e+00
  4.03297091e+00  4.00298834e+00  8.04087162e+00  7.70173693e+00
  7.10223532e+00  3.21729660e+00  5.74228382e+00  6.87862539e+00
  7.01803017e+00  3.45543861e+00  7.26741600e+00  7.03988886e+00
  1.35023844e+00  8.91982746e+00  4.43680811e+00  5.25290489e+00
  3.51280975e+00  6.24143553e+00  6.52131414e+00  4.72280169e+00
  8.25355721e+00  6.25390244e+00  5.13515329e+00  4.87421942e+00
  7.67947769e+00  3.34088635e+00  2.31048179e+00  4.33013082e-01
  8.68751335e+00  9.47573662e+00  1.55903900e+00  3.07618022e+00
  1.50216174e+00  1.19446433e+00  9.29029846e+00  1.65662837e+00
  9.56382942e+00  9.47769403e-01  8.08623123e+00  5.85028315e+00
  4.43489981e+00  3.51404214e+00  7.59146261e+00  3.24519110e+00
  6.24453449e+00  3.84153080e+00  4.75549126e+00  8.96583271e+00
  5.54600143e+00  7.46122551e+00  6.96567345e+00  4.11713839e-01
  7.67649698e+00  2.08050108e+00  9.21236324e+00  1.41680741e+00
  3.03086996e+00  1.13182259e+00  4.03754902e+00  8.78156567e+00
  2.95456624e+00  1.61442590e+00  3.30749226e+00  8.14694023e+00
  1.37203860e+00  1.63373399e+00  6.45686090e-01  7.07791662e+00
  3.06980824e+00  4.66480160e+00  7.18863678e+00  3.41025472e+00
  7.26521921e+00  7.07599974e+00  2.82888842e+00  1.03278141e+01
  1.74131536e+00  2.78822184e+00  1.28855526e+00  3.68360829e+00
  5.39412928e+00  5.52329063e+00  8.01896572e+00  8.91389751e+00
  2.46595716e+00  6.16491985e+00  1.14002132e+00  3.73238707e+00
  3.28532362e+00  2.97972035e+00  4.97999954e+00  7.17574263e+00
  7.50538170e-01  1.02770720e+01  7.28148460e+00  2.06288123e+00
  9.35947418e+00  5.11205769e+00  9.92250729e+00  1.66801298e+00
  3.66859484e+00  3.06588221e+00  3.05286908e+00  5.87349463e+00
  9.89076328e+00  8.08929062e+00  6.18565559e+00  5.57329512e+00
  9.22900391e+00  3.96593451e+00  8.75203419e+00  8.35547829e+00
  2.17680025e+00  7.65000153e+00  1.08980224e-01  3.05595231e+00
  2.58785725e+00  5.23494005e+00  7.61446953e+00  4.45858717e-01
  4.63132048e+00  9.55903053e+00  1.96978843e+00  6.25351620e+00]
Epoch 1/1000
2023-09-10 04:44:47.545 
Epoch 1/1000 
	 loss: 1629.7311, MinusLogProbMetric: 1629.7311, val_loss: 643.6135, val_MinusLogProbMetric: 643.6135

Epoch 1: val_loss improved from inf to 643.61353, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 100s - loss: 1629.7311 - MinusLogProbMetric: 1629.7311 - val_loss: 643.6135 - val_MinusLogProbMetric: 643.6135 - lr: 0.0010 - 100s/epoch - 509ms/step
Epoch 2/1000
2023-09-10 04:45:08.168 
Epoch 2/1000 
	 loss: 558.9319, MinusLogProbMetric: 558.9319, val_loss: 524.9188, val_MinusLogProbMetric: 524.9188

Epoch 2: val_loss improved from 643.61353 to 524.91882, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 21s - loss: 558.9319 - MinusLogProbMetric: 558.9319 - val_loss: 524.9188 - val_MinusLogProbMetric: 524.9188 - lr: 0.0010 - 21s/epoch - 105ms/step
Epoch 3/1000
2023-09-10 04:45:27.825 
Epoch 3/1000 
	 loss: 511.0765, MinusLogProbMetric: 511.0765, val_loss: 492.5440, val_MinusLogProbMetric: 492.5440

Epoch 3: val_loss improved from 524.91882 to 492.54398, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 511.0765 - MinusLogProbMetric: 511.0765 - val_loss: 492.5440 - val_MinusLogProbMetric: 492.5440 - lr: 0.0010 - 19s/epoch - 98ms/step
Epoch 4/1000
2023-09-10 04:45:47.212 
Epoch 4/1000 
	 loss: 491.9456, MinusLogProbMetric: 491.9456, val_loss: 475.4568, val_MinusLogProbMetric: 475.4568

Epoch 4: val_loss improved from 492.54398 to 475.45685, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 491.9456 - MinusLogProbMetric: 491.9456 - val_loss: 475.4568 - val_MinusLogProbMetric: 475.4568 - lr: 0.0010 - 19s/epoch - 99ms/step
Epoch 5/1000
2023-09-10 04:46:05.915 
Epoch 5/1000 
	 loss: 484.0453, MinusLogProbMetric: 484.0453, val_loss: 477.6664, val_MinusLogProbMetric: 477.6664

Epoch 5: val_loss did not improve from 475.45685
196/196 - 18s - loss: 484.0453 - MinusLogProbMetric: 484.0453 - val_loss: 477.6664 - val_MinusLogProbMetric: 477.6664 - lr: 0.0010 - 18s/epoch - 92ms/step
Epoch 6/1000
2023-09-10 04:46:25.626 
Epoch 6/1000 
	 loss: 474.7757, MinusLogProbMetric: 474.7757, val_loss: 461.7959, val_MinusLogProbMetric: 461.7959

Epoch 6: val_loss improved from 475.45685 to 461.79593, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 474.7757 - MinusLogProbMetric: 474.7757 - val_loss: 461.7959 - val_MinusLogProbMetric: 461.7959 - lr: 0.0010 - 20s/epoch - 103ms/step
Epoch 7/1000
2023-09-10 04:46:45.733 
Epoch 7/1000 
	 loss: 462.4690, MinusLogProbMetric: 462.4690, val_loss: 456.8075, val_MinusLogProbMetric: 456.8075

Epoch 7: val_loss improved from 461.79593 to 456.80753, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 462.4690 - MinusLogProbMetric: 462.4690 - val_loss: 456.8075 - val_MinusLogProbMetric: 456.8075 - lr: 0.0010 - 20s/epoch - 104ms/step
Epoch 8/1000
2023-09-10 04:47:05.093 
Epoch 8/1000 
	 loss: 462.0472, MinusLogProbMetric: 462.0472, val_loss: 456.2197, val_MinusLogProbMetric: 456.2197

Epoch 8: val_loss improved from 456.80753 to 456.21970, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 462.0472 - MinusLogProbMetric: 462.0472 - val_loss: 456.2197 - val_MinusLogProbMetric: 456.2197 - lr: 0.0010 - 19s/epoch - 99ms/step
Epoch 9/1000
2023-09-10 04:47:23.936 
Epoch 9/1000 
	 loss: 453.1959, MinusLogProbMetric: 453.1959, val_loss: 452.0308, val_MinusLogProbMetric: 452.0308

Epoch 9: val_loss improved from 456.21970 to 452.03076, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 453.1959 - MinusLogProbMetric: 453.1959 - val_loss: 452.0308 - val_MinusLogProbMetric: 452.0308 - lr: 0.0010 - 19s/epoch - 96ms/step
Epoch 10/1000
2023-09-10 04:47:42.305 
Epoch 10/1000 
	 loss: 453.0383, MinusLogProbMetric: 453.0383, val_loss: 452.1135, val_MinusLogProbMetric: 452.1135

Epoch 10: val_loss did not improve from 452.03076
196/196 - 18s - loss: 453.0383 - MinusLogProbMetric: 453.0383 - val_loss: 452.1135 - val_MinusLogProbMetric: 452.1135 - lr: 0.0010 - 18s/epoch - 90ms/step
Epoch 11/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 174: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-10 04:47:58.106 
Epoch 11/1000 
	 loss: nan, MinusLogProbMetric: 876624569042972628143530729013248.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 11: val_loss did not improve from 452.03076
196/196 - 16s - loss: nan - MinusLogProbMetric: 876624569042972628143530729013248.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 16s/epoch - 81ms/step
The loss history contains NaN values.
Training failed: trying again with seed 326159 and lr 0.0003333333333333333.
===========
Generating train data for run 331.
===========
Train data generated in 2.15 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_331/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 377}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_331/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_331/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_331
self.data_kwargs: {'seed': 377}
self.x_data: [[ 5.437488    7.1322474   6.533019   ...  9.559031    1.9697884
   6.253516  ]
 [ 6.105814   -0.33694893  4.861082   ...  4.728712    6.8399925
   2.9518385 ]
 [ 5.5099134   8.416618    3.6192868  ... 10.13037     0.5513004
   6.6116333 ]
 ...
 [ 8.378759    5.1539607   5.2823405  ...  4.1604185   7.9323363
   6.8563857 ]
 [ 8.088472    5.184855    5.311574   ...  3.8879027   7.132432
   7.66768   ]
 [ 5.6874776   6.932827    6.1243634  ...  9.540177    3.2688973
   7.1452303 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_36 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_5 (LogProbLa  (None,)                  4191520   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,191,520
Trainable params: 4,191,520
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_5/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_5'")
self.model: <keras.engine.functional.Functional object at 0x7effb1117970>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effec01cbe0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effec01cbe0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effb1137c40>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7effc1ef44f0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7effc1ef49d0>, <keras.callbacks.ModelCheckpoint object at 0x7effc1ef4a90>, <keras.callbacks.EarlyStopping object at 0x7effc1ef4d00>, <keras.callbacks.ReduceLROnPlateau object at 0x7effc1ef4d30>, <keras.callbacks.TerminateOnNaN object at 0x7effc1ef4970>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[8.229488 , 4.495837 , 5.2408857, ..., 2.4850268, 8.645066 ,
        6.947819 ],
       [6.4597087, 8.5036125, 6.4417224, ..., 9.769764 , 1.7685618,
        5.715251 ],
       [8.184484 , 4.6048226, 5.1865025, ..., 2.5379913, 8.714117 ,
        6.813641 ],
       ...,
       [8.467587 , 5.268347 , 5.1986547, ..., 3.5898209, 8.35342  ,
        6.779558 ],
       [8.0343275, 5.003659 , 5.2459483, ..., 3.075615 , 8.72342  ,
        6.6362123],
       [5.2588263, 7.861301 , 6.1851134, ..., 9.199393 , 2.3736775,
        6.457649 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 331/360 with hyperparameters:
timestamp = 2023-09-10 04:48:06.799799
ndims = 1000
seed_train = 377
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 4191520
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 5.43748808e+00  7.13224745e+00  6.53301907e+00  5.31066608e+00
  3.79545021e+00  6.28738737e+00  2.71391177e+00  8.88872051e+00
  9.43951797e+00  4.12179470e+00  7.81367683e+00  5.36657619e+00
  5.55121899e+00  9.56866932e+00  7.94146359e-01  9.63486314e-01
 -1.46448463e-02  7.97977352e+00  8.35143089e+00  9.09444618e+00
  9.51050758e+00  8.15759563e+00  4.87677431e+00  8.12364483e+00
 -5.86649776e-01  6.22392607e+00  1.30506945e+00  9.45408440e+00
  7.08888865e+00  3.35072994e+00  2.25734115e+00  8.41814995e+00
  4.58319330e+00  5.61194181e+00  2.26602942e-01  5.45686245e+00
  6.14353561e+00  6.25023174e+00  9.57346344e+00  6.36795044e+00
  3.20757818e+00  4.83043623e+00  7.51926565e+00  6.34396672e-01
  6.89045191e+00  6.62100124e+00  2.44563007e+00  1.28772116e+00
  3.22250342e+00  4.52788544e+00  5.89035130e+00  4.86346960e+00
  9.48264980e+00 -1.13163722e+00  3.37091446e+00  9.05362010e-01
  6.78129101e+00  1.94818664e+00  4.17912102e+00  3.18960547e+00
  1.62776482e+00  1.21974039e+00  7.33607817e+00  1.62089002e+00
  2.96397400e+00  4.52560091e+00  8.39162827e+00  1.51216686e+00
  8.25380135e+00  5.98394752e-01  9.67017937e+00  4.48699141e+00
  1.02882853e+01  5.70898390e+00  6.28753185e+00  6.97938085e-01
  2.82613039e+00  1.18152845e+00  2.21910620e+00  1.18442059e-01
  3.30913496e+00  4.37123442e+00 -6.00820422e-01  7.13190508e+00
  5.83363104e+00  2.43325353e+00  5.20436668e+00  1.77731943e+00
  6.29233789e+00  9.14511585e+00  2.47849083e+00  7.14207220e+00
  1.59640992e+00  7.87721014e+00  3.72595000e+00  1.65804911e+00
  6.26306725e+00  6.14266574e-01  9.35802937e+00 -5.55100851e-02
  6.81794071e+00  2.07937002e+00  7.28380156e+00  1.05093136e+01
  1.40520501e+00  5.19018650e+00  6.29479265e+00  5.23412371e+00
  2.19359255e+00  9.70839596e+00  4.63605547e+00  9.80713272e+00
  6.71604156e+00  2.83194685e+00  8.21691513e+00  3.91888070e+00
  8.82857418e+00  5.65095377e+00  7.74853373e+00  6.66070604e+00
  8.72240067e+00  4.82063627e+00  9.65159893e+00  7.37593651e+00
  5.52394199e+00  6.06229258e+00  6.28078938e-01  3.63155842e+00
  6.63515043e+00  3.13720345e+00  6.10160494e+00  4.59917688e+00
  1.67009079e+00  2.67929316e+00  5.87469530e+00  5.35120296e+00
  5.20565653e+00  6.30662727e+00  7.39564276e+00  4.35430813e+00
  8.88551044e+00  2.87358689e+00  4.32844305e+00  9.07120323e+00
  8.34959602e+00  6.54305315e+00  6.36145771e-01  9.69855213e+00
  6.49582243e+00  1.02082977e+01  1.42218649e+00  7.77432966e+00
  1.58041847e+00  6.40702820e+00  1.07924449e+00  8.47589207e+00
  8.23396206e+00  5.41745853e+00  3.85215545e+00  7.45270491e-01
  6.41533756e+00  4.21811962e+00  7.45381451e+00  8.68435764e+00
  9.59165764e+00  9.22718906e+00 -1.01518297e+00  4.78479671e+00
  7.09206533e+00  2.16092372e+00  5.71304035e+00  1.19908273e-01
  3.16043782e+00  9.20669734e-02  8.17029667e+00  2.31537890e+00
  3.80825901e+00  9.06393814e+00  7.17630625e+00  1.20758474e-01
  1.57467747e+00  6.56413174e+00  5.80603886e+00  1.90417314e+00
  9.26850033e+00  5.71055651e+00  5.48348093e+00  5.70006657e+00
  7.34501457e+00  3.06974077e+00  4.17449951e+00  1.88637686e+00
  1.59649813e+00  8.74714470e+00  7.68149471e+00  5.14725018e+00
  1.94792962e+00  2.93671155e+00  6.94045722e-01  4.93041849e+00
  2.29451370e+00  6.96200371e+00  2.94133329e+00  7.65987992e-01
 -2.16490626e-02  6.85447574e-01  6.85941124e+00  4.85409117e+00
  5.72059441e+00  8.98723507e+00  9.62737179e+00  2.21571255e+00
  6.79449415e+00  2.29369974e+00  5.30113637e-01  7.87245512e+00
  3.63518763e+00  4.00529575e+00  5.20808411e+00  8.23005772e+00
  6.37014103e+00  8.26017952e+00  3.29657626e+00  7.93651295e+00
  1.78429985e+00  9.56696796e+00  7.06810617e+00  2.25382471e+00
  9.54646778e+00  7.23986912e+00  2.52804947e+00  2.58364177e+00
  5.52888250e+00  1.77395463e-01  2.06791592e+00  4.35356903e+00
  3.59637356e+00  3.74388838e+00  2.40446615e+00  5.81385517e+00
  8.67110729e+00  1.17576969e+00  4.94048452e+00  9.40345764e-01
  6.09276962e+00  3.86963511e+00  6.18902493e+00  1.56115341e+00
  2.90525699e+00  4.87162495e+00  3.71526504e+00  9.40074253e+00
  7.42161226e+00  7.27192879e+00  1.00699673e+01  1.18854022e+00
  5.78801632e+00  5.48251772e+00  9.94960403e+00  2.90021896e+00
  4.43213892e+00  4.77912188e-01  3.98015082e-01  1.12766476e+01
  6.74848080e+00  7.22801781e+00  2.82795882e+00  5.88993359e+00
  6.98136806e-01  3.23450828e+00  9.72003841e+00  8.30174351e+00
  3.07273555e+00  9.91379070e+00  1.91660452e+00  9.71661282e+00
  9.90089893e+00  8.15846062e+00  7.03740978e+00  9.58544540e+00
  2.93002963e+00  8.31967926e+00  5.99808025e+00  7.28550479e-02
  3.85735941e+00  9.70761538e-01  9.23753738e+00  5.46686459e+00
  5.50278473e+00  6.01728964e+00  4.34324074e+00  1.36993062e+00
  8.45484543e+00  4.68175888e-01  5.26911163e+00  1.84141123e+00
  3.81864011e-01  7.90763950e+00  9.70255852e+00  9.84720516e+00
  9.43443680e+00  7.68962574e+00  3.80397248e+00  6.65612042e-01
  5.16863966e+00  2.47927332e+00  4.73985672e-01  1.05347097e+00
  7.32991314e+00  9.36276674e-01  7.35460091e+00  1.67862105e+00
  4.33905751e-01  1.59291720e+00  7.84084034e+00  2.43011403e+00
  4.25165033e+00  5.68983269e+00  8.60872746e+00  7.16398525e+00
  2.72054410e+00  1.94252491e+00 -1.85395658e-01  3.34451747e+00
  1.99218881e+00  3.79499388e+00  5.96836662e+00  7.37168837e+00
  2.49210262e+00  3.98509121e+00  9.37832177e-01  8.80943108e+00
  2.57825583e-01  6.98963022e+00  7.78174019e+00  7.89891291e+00
  2.61566496e+00  3.04674053e+00  6.46863794e+00  2.90103054e+00
  4.06367350e+00  2.83596921e+00  5.16630077e+00  6.22896612e-01
  7.82478142e+00  3.80227089e-01  3.55100584e+00  3.55920887e+00
  5.84608507e+00  9.32784271e+00  6.44432068e+00  6.71383977e-01
  3.80863142e+00  5.12159157e+00  5.26213694e+00  6.50915527e+00
  3.31823993e+00  1.51588440e+00  3.74508786e+00  9.63789845e+00
  2.82012701e+00  9.30117702e+00  5.18297386e+00  5.08122492e+00
  9.10340309e+00  4.14017344e+00  8.16922951e+00  3.49889684e+00
  9.15036392e+00  7.04796791e+00  6.91863298e+00  3.43821239e+00
  7.49771976e+00  6.58094883e+00  1.52206314e+00  1.66219306e+00
  8.96467304e+00  9.71891689e+00  6.03888035e+00  6.12453365e+00
  8.36337280e+00  4.72068548e+00  7.40723658e+00  4.66089344e+00
  9.60812855e+00  1.02327881e+01  8.27917576e+00  1.76802504e+00
  5.86829615e+00  4.09585905e+00 -5.26962698e-01  4.35076141e+00
  2.46013212e+00  8.68481445e+00  3.86820614e-01  9.69470692e+00
  3.67586684e+00  3.92413521e+00 -9.84535664e-02  2.63078451e+00
  4.00670385e+00  1.10941935e+01  5.17772198e-01  9.30033970e+00
  9.24112511e+00  2.92216539e+00  3.37561965e+00  2.46589732e+00
  6.14229774e+00  4.67309088e-01 -8.67828280e-02  4.08560181e+00
  3.99175465e-01  2.54151607e+00  2.21575212e+00  2.50912642e+00
  1.27955842e+00 -7.25474238e-01  8.21681261e-01  6.53614998e+00
  1.04211264e+01  9.34315395e+00  3.89995766e+00  3.41503716e+00
  6.30898190e+00  4.78263617e+00  1.00384960e+01  1.44826126e+00
  8.01760387e+00  3.30487871e+00  2.22230029e+00  6.98749399e+00
  2.56673408e+00  6.51266956e+00  5.16357517e+00  4.21222687e+00
  5.53316402e+00  2.87564898e+00  6.88569880e+00  5.24295902e+00
  3.83784485e+00  8.63262177e+00  9.42399979e+00  4.50341552e-01
  2.33270240e+00  2.46700525e+00  8.57210445e+00  9.93498421e+00
  9.70180130e+00  9.04918671e+00  2.82848668e+00  1.01604681e+01
  2.13376069e+00  1.08001816e+00  1.01585007e+01  2.37143421e+00
  6.89639854e+00  6.13785625e-01  6.39277411e+00  8.98899841e+00
  3.29311657e+00  3.45347357e+00  3.81167507e+00  7.88749123e+00
  1.59779358e+00  5.66715002e-01  4.65487051e+00  4.15191126e+00
  8.22690773e+00  2.27221990e+00  5.74325514e+00  9.80365372e+00
  6.51945877e+00  8.45271111e+00  9.52017021e+00  7.24792719e+00
  6.43911409e+00  8.51561165e+00  1.02915831e+01  4.50498724e+00
  9.14542615e-01  2.86150455e+00  2.13800192e-01  3.66317129e+00
  1.32120097e+00  6.51088238e+00  3.09616232e+00  9.20569038e+00
  9.73210716e+00  5.21707201e+00  3.67960548e+00  5.34920645e+00
  8.44879818e+00  4.15654373e+00  5.51069403e+00  2.64717555e+00
  4.56229973e+00  4.03184319e+00  2.53720236e+00  4.99534702e+00
  2.31029892e+00  3.48865128e+00  8.25072670e+00  7.54355812e+00
  2.20225477e+00  1.13970642e+01  8.49588680e+00  7.10883319e-01
  2.74363828e+00  4.99293470e+00  1.34385705e-01  3.21501279e+00
  8.21650314e+00  6.79964018e+00  6.27488852e+00  7.14794111e+00
  1.90239477e+00  3.45294881e+00  7.35099411e+00  9.33995914e+00
  6.05294037e+00  2.90113711e+00 -1.24432337e+00  6.42705727e+00
  5.68964370e-02  3.37960458e+00  4.96043348e+00  9.90640545e+00
  1.23383534e+00  4.00741386e+00  6.40055537e-03  3.24708557e+00
  6.32790136e+00  2.19222999e+00  2.08447242e+00  1.32372677e+00
  5.92049932e+00  6.88256168e+00  7.01928997e+00  1.04399967e+01
 -2.88216442e-01  6.52927542e+00  6.16809750e+00  6.00324678e+00
  9.71869183e+00  1.13557257e-01  7.11323690e+00  7.71879911e+00
  5.03887224e+00  3.76561260e+00  8.05337811e+00  3.14987302e-01
  5.12668896e+00  5.27989054e+00  6.75082159e+00  1.43525863e+00
  2.57989788e+00  4.62727022e+00  6.04563522e+00  9.48542213e+00
  7.09511852e+00  1.17622685e+00  9.15441227e+00  9.80256653e+00
  5.09900427e+00  9.44795132e+00  5.51893759e+00  1.03330717e+01
  8.30469704e+00  1.07898369e+01  1.01827803e+01 -5.05745411e-04
  1.73885703e+00  3.52059174e+00  9.45347977e+00  3.41492081e+00
  1.14690316e+00  9.65928459e+00  4.69807243e+00  9.03562832e+00
  1.17234612e+00  6.69798565e+00  4.43081808e+00  8.74517798e-01
  6.92903471e+00  2.09807229e+00 -7.14968681e-01  5.73539436e-01
  6.28464758e-01  8.92654991e+00  8.03050327e+00  9.02817154e+00
  7.40084696e+00  5.17232370e+00  3.25738239e+00  1.01524630e+01
  3.55576420e+00  3.88637328e+00  4.20779133e+00  8.97262955e+00
  1.70729637e+00  3.30006480e+00  5.26616716e+00  9.60324168e-01
  6.40397358e+00  4.05875492e+00  2.62214065e+00  2.05707121e+00
  4.09347248e+00  3.94071198e+00  5.06777287e+00  3.40968561e+00
  8.99762726e+00  1.47003901e+00  8.83282781e-01  3.52675414e+00
  5.27389050e+00  6.61437607e+00  5.19436264e+00  9.38774395e+00
  3.59817815e+00  7.51900101e+00  6.17228937e+00  8.14072514e+00
  1.00964031e+01  8.67543316e+00  7.67522526e+00  6.90801048e+00
  3.51598859e+00  5.34878731e-01  6.36672795e-01  2.41127205e+00
  3.82626390e+00  5.18385172e+00  5.83661032e+00  9.15472126e+00
  8.23223293e-01  2.42483902e+00  5.41429329e+00  8.00633621e+00
  7.98597336e+00  9.41291142e+00  9.83840275e+00  4.71966314e+00
  4.63481140e+00  4.06945586e-01  6.68186712e+00  6.24139881e+00
  8.50881863e+00  7.10938215e-01  4.35715389e+00  5.98537350e+00
  2.39591932e+00  1.52024806e+00  9.15522194e+00  1.84586793e-01
  3.84848523e+00  1.13246572e+00  4.45568275e+00  9.84170437e+00
  4.21756744e+00  6.01763248e+00  7.27610350e-01  3.31445408e+00
  4.36259508e+00  4.26714516e+00  6.67291355e+00  3.47573233e+00
  6.96841526e+00  6.61320925e+00  4.78718519e+00  3.85241342e+00
  5.65875959e+00  9.63071108e-01  8.21956635e+00  7.05007601e+00
  7.35808372e+00  5.60682201e+00  8.74726832e-01  4.78749466e+00
  4.08274555e+00  3.05295515e+00 -2.82806456e-02  7.37880754e+00
  1.13245630e+00  6.21132517e+00  7.19738770e+00  6.62598848e+00
  8.44676971e+00  7.01955557e-01  8.75954437e+00  1.91597685e-01
  6.34029531e+00  4.09656525e+00  4.70814228e+00  3.66343403e+00
  1.92009354e+00 -2.97656119e-01  4.93795109e+00  7.03719902e+00
  3.54990387e+00  2.22650814e+00  1.47342825e+00  1.87733543e+00
  9.82225418e-01  1.97523093e+00  2.90856576e+00 -1.95377409e-01
  7.63740540e-01  8.23801708e+00  1.92524207e+00  4.57951069e+00
  8.07519722e+00  4.80337429e+00  1.63165092e+00  2.09296656e+00
  4.45628262e+00  5.24322176e+00  3.30323172e+00  7.77983236e+00
  7.60303879e+00  8.98269558e+00  3.17642242e-01  9.00031185e+00
  3.89518857e+00  8.87557316e+00  6.54464340e+00  9.40222740e+00
  7.76669884e+00  3.63010335e+00  4.89937687e+00  3.79815769e+00
  3.43109441e+00  2.11776972e+00  4.50608540e+00  6.73585749e+00
  2.77784801e+00  4.75118494e+00  1.41163933e+00  1.43678403e+00
  4.72844005e-01  1.01116915e+01  4.33705822e-02  1.87914848e+00
  6.03755856e+00  1.65911603e+00  9.08522511e+00  7.11956310e+00
  8.27528858e+00  4.67179298e+00  1.46821272e+00  5.57443333e+00
  9.03736591e+00  7.08154297e+00  2.92699647e+00  9.28951740e+00
  3.66812515e+00  1.79973990e-02  2.40762663e+00  1.92846382e+00
  8.69157314e+00  4.33280611e+00  4.23879671e+00  3.11560988e+00
  9.60638237e+00  1.10599823e+01  9.74016571e+00  3.66849303e+00
  9.42271328e+00  8.38017178e+00  6.39697123e+00  3.64649916e+00
  1.97412837e+00  2.19269991e+00  9.55885601e+00  2.80885458e+00
  4.91888142e+00  5.15744495e+00  8.31021786e+00  8.34845829e+00
  1.55545843e+00  3.92147779e+00  8.22108078e+00  7.88888502e+00
  1.22066307e+00  1.52498245e+00  3.15602779e+00  9.93907928e-01
  4.50527048e+00  1.36449265e+00  5.00522995e+00  2.42850351e+00
  5.87198400e+00 -1.04476917e+00  9.73143959e+00  9.51038170e+00
  4.31158495e+00  3.61805153e+00  1.88797522e+00  5.04972935e+00
  4.03085709e-01  4.60245562e+00  3.75540328e+00  4.01810455e+00
  8.59900475e+00  7.06478453e+00  9.62819099e+00  3.01856041e+00
  9.00697613e+00  8.57353497e+00  4.79125214e+00  6.26140499e+00
  2.85231853e+00  1.06102486e+01  1.06103802e+00  2.18488646e+00
  3.15353966e+00  4.29014683e+00  7.35634613e+00  5.12752581e+00
  4.86164331e+00  6.53155148e-01  5.14040470e+00  5.27053058e-01
  1.85232019e+00  9.85549164e+00  2.36561966e+00  8.83290672e+00
  8.07797718e+00  2.24759030e+00  5.88459301e+00  1.65719461e+00
  7.13856363e+00  6.36659193e+00  8.30550766e+00  4.64638376e+00
  8.86743259e+00 -1.78816348e-01  2.12690020e+00  7.22018147e+00
  4.37131548e+00  1.50182629e+00  1.44224501e+00  8.23597240e+00
  2.87912059e+00  8.82868195e+00  6.72185993e+00  4.10417318e+00
  3.72402120e+00  4.76707935e+00  8.69713497e+00  8.02846813e+00
 -5.91852479e-02  6.92536926e+00  9.99452686e+00  7.10508966e+00
  1.77003264e+00  5.62554789e+00  1.03404069e+00  4.70238781e+00
  9.31285954e+00  8.93695068e+00  2.82111669e+00  3.46559119e+00
  6.18987942e+00  9.39866257e+00  5.47782779e-01  2.72644186e+00
  8.94318962e+00  4.69057751e+00  1.03748589e+01  2.52786398e+00
  5.76243114e+00  3.48165631e+00  3.81163502e+00  3.76940107e+00
  4.03297091e+00  4.00298834e+00  8.04087162e+00  7.70173693e+00
  7.10223532e+00  3.21729660e+00  5.74228382e+00  6.87862539e+00
  7.01803017e+00  3.45543861e+00  7.26741600e+00  7.03988886e+00
  1.35023844e+00  8.91982746e+00  4.43680811e+00  5.25290489e+00
  3.51280975e+00  6.24143553e+00  6.52131414e+00  4.72280169e+00
  8.25355721e+00  6.25390244e+00  5.13515329e+00  4.87421942e+00
  7.67947769e+00  3.34088635e+00  2.31048179e+00  4.33013082e-01
  8.68751335e+00  9.47573662e+00  1.55903900e+00  3.07618022e+00
  1.50216174e+00  1.19446433e+00  9.29029846e+00  1.65662837e+00
  9.56382942e+00  9.47769403e-01  8.08623123e+00  5.85028315e+00
  4.43489981e+00  3.51404214e+00  7.59146261e+00  3.24519110e+00
  6.24453449e+00  3.84153080e+00  4.75549126e+00  8.96583271e+00
  5.54600143e+00  7.46122551e+00  6.96567345e+00  4.11713839e-01
  7.67649698e+00  2.08050108e+00  9.21236324e+00  1.41680741e+00
  3.03086996e+00  1.13182259e+00  4.03754902e+00  8.78156567e+00
  2.95456624e+00  1.61442590e+00  3.30749226e+00  8.14694023e+00
  1.37203860e+00  1.63373399e+00  6.45686090e-01  7.07791662e+00
  3.06980824e+00  4.66480160e+00  7.18863678e+00  3.41025472e+00
  7.26521921e+00  7.07599974e+00  2.82888842e+00  1.03278141e+01
  1.74131536e+00  2.78822184e+00  1.28855526e+00  3.68360829e+00
  5.39412928e+00  5.52329063e+00  8.01896572e+00  8.91389751e+00
  2.46595716e+00  6.16491985e+00  1.14002132e+00  3.73238707e+00
  3.28532362e+00  2.97972035e+00  4.97999954e+00  7.17574263e+00
  7.50538170e-01  1.02770720e+01  7.28148460e+00  2.06288123e+00
  9.35947418e+00  5.11205769e+00  9.92250729e+00  1.66801298e+00
  3.66859484e+00  3.06588221e+00  3.05286908e+00  5.87349463e+00
  9.89076328e+00  8.08929062e+00  6.18565559e+00  5.57329512e+00
  9.22900391e+00  3.96593451e+00  8.75203419e+00  8.35547829e+00
  2.17680025e+00  7.65000153e+00  1.08980224e-01  3.05595231e+00
  2.58785725e+00  5.23494005e+00  7.61446953e+00  4.45858717e-01
  4.63132048e+00  9.55903053e+00  1.96978843e+00  6.25351620e+00]
Epoch 1/1000
2023-09-10 04:49:43.122 
Epoch 1/1000 
	 loss: 461.7395, MinusLogProbMetric: 461.7395, val_loss: 429.6302, val_MinusLogProbMetric: 429.6302

Epoch 1: val_loss improved from inf to 429.63016, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 97s - loss: 461.7395 - MinusLogProbMetric: 461.7395 - val_loss: 429.6302 - val_MinusLogProbMetric: 429.6302 - lr: 3.3333e-04 - 97s/epoch - 494ms/step
Epoch 2/1000
2023-09-10 04:50:01.861 
Epoch 2/1000 
	 loss: 428.3376, MinusLogProbMetric: 428.3376, val_loss: 431.9609, val_MinusLogProbMetric: 431.9609

Epoch 2: val_loss did not improve from 429.63016
196/196 - 18s - loss: 428.3376 - MinusLogProbMetric: 428.3376 - val_loss: 431.9609 - val_MinusLogProbMetric: 431.9609 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 3/1000
2023-09-10 04:50:19.980 
Epoch 3/1000 
	 loss: 426.5037, MinusLogProbMetric: 426.5037, val_loss: 427.7093, val_MinusLogProbMetric: 427.7093

Epoch 3: val_loss improved from 429.63016 to 427.70929, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 426.5037 - MinusLogProbMetric: 426.5037 - val_loss: 427.7093 - val_MinusLogProbMetric: 427.7093 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 4/1000
2023-09-10 04:50:39.215 
Epoch 4/1000 
	 loss: 425.8387, MinusLogProbMetric: 425.8387, val_loss: 424.7581, val_MinusLogProbMetric: 424.7581

Epoch 4: val_loss improved from 427.70929 to 424.75806, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 425.8387 - MinusLogProbMetric: 425.8387 - val_loss: 424.7581 - val_MinusLogProbMetric: 424.7581 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 5/1000
2023-09-10 04:50:59.382 
Epoch 5/1000 
	 loss: 423.6577, MinusLogProbMetric: 423.6577, val_loss: 423.6461, val_MinusLogProbMetric: 423.6461

Epoch 5: val_loss improved from 424.75806 to 423.64609, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 423.6577 - MinusLogProbMetric: 423.6577 - val_loss: 423.6461 - val_MinusLogProbMetric: 423.6461 - lr: 3.3333e-04 - 20s/epoch - 103ms/step
Epoch 6/1000
2023-09-10 04:51:18.266 
Epoch 6/1000 
	 loss: 423.3388, MinusLogProbMetric: 423.3388, val_loss: 424.0532, val_MinusLogProbMetric: 424.0532

Epoch 6: val_loss did not improve from 423.64609
196/196 - 18s - loss: 423.3388 - MinusLogProbMetric: 423.3388 - val_loss: 424.0532 - val_MinusLogProbMetric: 424.0532 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 7/1000
2023-09-10 04:51:37.925 
Epoch 7/1000 
	 loss: 422.1426, MinusLogProbMetric: 422.1426, val_loss: 420.1562, val_MinusLogProbMetric: 420.1562

Epoch 7: val_loss improved from 423.64609 to 420.15622, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 21s - loss: 422.1426 - MinusLogProbMetric: 422.1426 - val_loss: 420.1562 - val_MinusLogProbMetric: 420.1562 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 8/1000
2023-09-10 04:51:57.448 
Epoch 8/1000 
	 loss: 421.4213, MinusLogProbMetric: 421.4213, val_loss: 437.6767, val_MinusLogProbMetric: 437.6767

Epoch 8: val_loss did not improve from 420.15622
196/196 - 19s - loss: 421.4213 - MinusLogProbMetric: 421.4213 - val_loss: 437.6767 - val_MinusLogProbMetric: 437.6767 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 9/1000
2023-09-10 04:52:15.764 
Epoch 9/1000 
	 loss: 422.2211, MinusLogProbMetric: 422.2211, val_loss: 420.6847, val_MinusLogProbMetric: 420.6847

Epoch 9: val_loss did not improve from 420.15622
196/196 - 18s - loss: 422.2211 - MinusLogProbMetric: 422.2211 - val_loss: 420.6847 - val_MinusLogProbMetric: 420.6847 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 10/1000
2023-09-10 04:52:33.356 
Epoch 10/1000 
	 loss: 418.8781, MinusLogProbMetric: 418.8781, val_loss: 420.8319, val_MinusLogProbMetric: 420.8319

Epoch 10: val_loss did not improve from 420.15622
196/196 - 18s - loss: 418.8781 - MinusLogProbMetric: 418.8781 - val_loss: 420.8319 - val_MinusLogProbMetric: 420.8319 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 11/1000
2023-09-10 04:52:51.128 
Epoch 11/1000 
	 loss: 419.9349, MinusLogProbMetric: 419.9349, val_loss: 419.8981, val_MinusLogProbMetric: 419.8981

Epoch 11: val_loss improved from 420.15622 to 419.89810, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 18s - loss: 419.9349 - MinusLogProbMetric: 419.9349 - val_loss: 419.8981 - val_MinusLogProbMetric: 419.8981 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 12/1000
2023-09-10 04:53:10.741 
Epoch 12/1000 
	 loss: 417.7433, MinusLogProbMetric: 417.7433, val_loss: 418.4573, val_MinusLogProbMetric: 418.4573

Epoch 12: val_loss improved from 419.89810 to 418.45728, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 417.7433 - MinusLogProbMetric: 417.7433 - val_loss: 418.4573 - val_MinusLogProbMetric: 418.4573 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 13/1000
2023-09-10 04:53:29.962 
Epoch 13/1000 
	 loss: 417.7784, MinusLogProbMetric: 417.7784, val_loss: 416.9294, val_MinusLogProbMetric: 416.9294

Epoch 13: val_loss improved from 418.45728 to 416.92941, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 417.7784 - MinusLogProbMetric: 417.7784 - val_loss: 416.9294 - val_MinusLogProbMetric: 416.9294 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 14/1000
2023-09-10 04:53:47.948 
Epoch 14/1000 
	 loss: 417.2448, MinusLogProbMetric: 417.2448, val_loss: 427.1468, val_MinusLogProbMetric: 427.1468

Epoch 14: val_loss did not improve from 416.92941
196/196 - 18s - loss: 417.2448 - MinusLogProbMetric: 417.2448 - val_loss: 427.1468 - val_MinusLogProbMetric: 427.1468 - lr: 3.3333e-04 - 18s/epoch - 89ms/step
Epoch 15/1000
2023-09-10 04:54:07.164 
Epoch 15/1000 
	 loss: 416.9887, MinusLogProbMetric: 416.9887, val_loss: 417.8848, val_MinusLogProbMetric: 417.8848

Epoch 15: val_loss did not improve from 416.92941
196/196 - 19s - loss: 416.9887 - MinusLogProbMetric: 416.9887 - val_loss: 417.8848 - val_MinusLogProbMetric: 417.8848 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 16/1000
2023-09-10 04:54:24.784 
Epoch 16/1000 
	 loss: 415.8507, MinusLogProbMetric: 415.8507, val_loss: 414.5053, val_MinusLogProbMetric: 414.5053

Epoch 16: val_loss improved from 416.92941 to 414.50531, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 415.8507 - MinusLogProbMetric: 415.8507 - val_loss: 414.5053 - val_MinusLogProbMetric: 414.5053 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 17/1000
2023-09-10 04:54:44.748 
Epoch 17/1000 
	 loss: 415.7902, MinusLogProbMetric: 415.7902, val_loss: 441.1122, val_MinusLogProbMetric: 441.1122

Epoch 17: val_loss did not improve from 414.50531
196/196 - 18s - loss: 415.7902 - MinusLogProbMetric: 415.7902 - val_loss: 441.1122 - val_MinusLogProbMetric: 441.1122 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 18/1000
2023-09-10 04:55:03.354 
Epoch 18/1000 
	 loss: 421.4769, MinusLogProbMetric: 421.4769, val_loss: 424.6313, val_MinusLogProbMetric: 424.6313

Epoch 18: val_loss did not improve from 414.50531
196/196 - 19s - loss: 421.4769 - MinusLogProbMetric: 421.4769 - val_loss: 424.6313 - val_MinusLogProbMetric: 424.6313 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 19/1000
2023-09-10 04:55:23.000 
Epoch 19/1000 
	 loss: 415.1295, MinusLogProbMetric: 415.1295, val_loss: 415.0343, val_MinusLogProbMetric: 415.0343

Epoch 19: val_loss did not improve from 414.50531
196/196 - 20s - loss: 415.1295 - MinusLogProbMetric: 415.1295 - val_loss: 415.0343 - val_MinusLogProbMetric: 415.0343 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 20/1000
2023-09-10 04:55:42.942 
Epoch 20/1000 
	 loss: 414.7896, MinusLogProbMetric: 414.7896, val_loss: 415.5195, val_MinusLogProbMetric: 415.5195

Epoch 20: val_loss did not improve from 414.50531
196/196 - 20s - loss: 414.7896 - MinusLogProbMetric: 414.7896 - val_loss: 415.5195 - val_MinusLogProbMetric: 415.5195 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 21/1000
2023-09-10 04:56:02.242 
Epoch 21/1000 
	 loss: 413.8745, MinusLogProbMetric: 413.8745, val_loss: 414.3985, val_MinusLogProbMetric: 414.3985

Epoch 21: val_loss improved from 414.50531 to 414.39850, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 413.8745 - MinusLogProbMetric: 413.8745 - val_loss: 414.3985 - val_MinusLogProbMetric: 414.3985 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 22/1000
2023-09-10 04:56:21.129 
Epoch 22/1000 
	 loss: 413.1439, MinusLogProbMetric: 413.1439, val_loss: 413.8447, val_MinusLogProbMetric: 413.8447

Epoch 22: val_loss improved from 414.39850 to 413.84470, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 413.1439 - MinusLogProbMetric: 413.1439 - val_loss: 413.8447 - val_MinusLogProbMetric: 413.8447 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 23/1000
2023-09-10 04:56:41.767 
Epoch 23/1000 
	 loss: 413.2422, MinusLogProbMetric: 413.2422, val_loss: 423.0899, val_MinusLogProbMetric: 423.0899

Epoch 23: val_loss did not improve from 413.84470
196/196 - 20s - loss: 413.2422 - MinusLogProbMetric: 413.2422 - val_loss: 423.0899 - val_MinusLogProbMetric: 423.0899 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 24/1000
2023-09-10 04:57:02.569 
Epoch 24/1000 
	 loss: 413.0244, MinusLogProbMetric: 413.0244, val_loss: 415.1224, val_MinusLogProbMetric: 415.1224

Epoch 24: val_loss did not improve from 413.84470
196/196 - 21s - loss: 413.0244 - MinusLogProbMetric: 413.0244 - val_loss: 415.1224 - val_MinusLogProbMetric: 415.1224 - lr: 3.3333e-04 - 21s/epoch - 106ms/step
Epoch 25/1000
2023-09-10 04:57:21.509 
Epoch 25/1000 
	 loss: 509.7639, MinusLogProbMetric: 509.7639, val_loss: 428.8068, val_MinusLogProbMetric: 428.8068

Epoch 25: val_loss did not improve from 413.84470
196/196 - 19s - loss: 509.7639 - MinusLogProbMetric: 509.7639 - val_loss: 428.8068 - val_MinusLogProbMetric: 428.8068 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 26/1000
2023-09-10 04:57:40.477 
Epoch 26/1000 
	 loss: 420.4035, MinusLogProbMetric: 420.4035, val_loss: 418.3550, val_MinusLogProbMetric: 418.3550

Epoch 26: val_loss did not improve from 413.84470
196/196 - 19s - loss: 420.4035 - MinusLogProbMetric: 420.4035 - val_loss: 418.3550 - val_MinusLogProbMetric: 418.3550 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 27/1000
2023-09-10 04:58:00.379 
Epoch 27/1000 
	 loss: 415.6017, MinusLogProbMetric: 415.6017, val_loss: 419.5384, val_MinusLogProbMetric: 419.5384

Epoch 27: val_loss did not improve from 413.84470
196/196 - 20s - loss: 415.6017 - MinusLogProbMetric: 415.6017 - val_loss: 419.5384 - val_MinusLogProbMetric: 419.5384 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 28/1000
2023-09-10 04:58:18.147 
Epoch 28/1000 
	 loss: 413.6732, MinusLogProbMetric: 413.6732, val_loss: 420.2473, val_MinusLogProbMetric: 420.2473

Epoch 28: val_loss did not improve from 413.84470
196/196 - 18s - loss: 413.6732 - MinusLogProbMetric: 413.6732 - val_loss: 420.2473 - val_MinusLogProbMetric: 420.2473 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 29/1000
2023-09-10 04:58:36.425 
Epoch 29/1000 
	 loss: 412.8575, MinusLogProbMetric: 412.8575, val_loss: 415.5869, val_MinusLogProbMetric: 415.5869

Epoch 29: val_loss did not improve from 413.84470
196/196 - 18s - loss: 412.8575 - MinusLogProbMetric: 412.8575 - val_loss: 415.5869 - val_MinusLogProbMetric: 415.5869 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 30/1000
2023-09-10 04:58:55.852 
Epoch 30/1000 
	 loss: 412.5633, MinusLogProbMetric: 412.5633, val_loss: 411.9010, val_MinusLogProbMetric: 411.9010

Epoch 30: val_loss improved from 413.84470 to 411.90100, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 412.5633 - MinusLogProbMetric: 412.5633 - val_loss: 411.9010 - val_MinusLogProbMetric: 411.9010 - lr: 3.3333e-04 - 20s/epoch - 103ms/step
Epoch 31/1000
2023-09-10 04:59:16.995 
Epoch 31/1000 
	 loss: 412.3469, MinusLogProbMetric: 412.3469, val_loss: 412.6197, val_MinusLogProbMetric: 412.6197

Epoch 31: val_loss did not improve from 411.90100
196/196 - 20s - loss: 412.3469 - MinusLogProbMetric: 412.3469 - val_loss: 412.6197 - val_MinusLogProbMetric: 412.6197 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 32/1000
2023-09-10 04:59:36.241 
Epoch 32/1000 
	 loss: 411.6385, MinusLogProbMetric: 411.6385, val_loss: 410.4085, val_MinusLogProbMetric: 410.4085

Epoch 32: val_loss improved from 411.90100 to 410.40854, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 411.6385 - MinusLogProbMetric: 411.6385 - val_loss: 410.4085 - val_MinusLogProbMetric: 410.4085 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 33/1000
2023-09-10 04:59:56.902 
Epoch 33/1000 
	 loss: 410.3894, MinusLogProbMetric: 410.3894, val_loss: 409.8883, val_MinusLogProbMetric: 409.8883

Epoch 33: val_loss improved from 410.40854 to 409.88831, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 21s - loss: 410.3894 - MinusLogProbMetric: 410.3894 - val_loss: 409.8883 - val_MinusLogProbMetric: 409.8883 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 34/1000
2023-09-10 05:00:16.489 
Epoch 34/1000 
	 loss: 411.1010, MinusLogProbMetric: 411.1010, val_loss: 436.0455, val_MinusLogProbMetric: 436.0455

Epoch 34: val_loss did not improve from 409.88831
196/196 - 19s - loss: 411.1010 - MinusLogProbMetric: 411.1010 - val_loss: 436.0455 - val_MinusLogProbMetric: 436.0455 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 35/1000
2023-09-10 05:00:36.311 
Epoch 35/1000 
	 loss: 410.3540, MinusLogProbMetric: 410.3540, val_loss: 426.4143, val_MinusLogProbMetric: 426.4143

Epoch 35: val_loss did not improve from 409.88831
196/196 - 20s - loss: 410.3540 - MinusLogProbMetric: 410.3540 - val_loss: 426.4143 - val_MinusLogProbMetric: 426.4143 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 36/1000
2023-09-10 05:00:54.368 
Epoch 36/1000 
	 loss: 409.9814, MinusLogProbMetric: 409.9814, val_loss: 410.6936, val_MinusLogProbMetric: 410.6936

Epoch 36: val_loss did not improve from 409.88831
196/196 - 18s - loss: 409.9814 - MinusLogProbMetric: 409.9814 - val_loss: 410.6936 - val_MinusLogProbMetric: 410.6936 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 37/1000
2023-09-10 05:01:12.902 
Epoch 37/1000 
	 loss: 409.3297, MinusLogProbMetric: 409.3297, val_loss: 411.8746, val_MinusLogProbMetric: 411.8746

Epoch 37: val_loss did not improve from 409.88831
196/196 - 19s - loss: 409.3297 - MinusLogProbMetric: 409.3297 - val_loss: 411.8746 - val_MinusLogProbMetric: 411.8746 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 38/1000
2023-09-10 05:01:32.144 
Epoch 38/1000 
	 loss: 408.5807, MinusLogProbMetric: 408.5807, val_loss: 408.9535, val_MinusLogProbMetric: 408.9535

Epoch 38: val_loss improved from 409.88831 to 408.95346, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 408.5807 - MinusLogProbMetric: 408.5807 - val_loss: 408.9535 - val_MinusLogProbMetric: 408.9535 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 39/1000
2023-09-10 05:01:51.700 
Epoch 39/1000 
	 loss: 408.8208, MinusLogProbMetric: 408.8208, val_loss: 408.0190, val_MinusLogProbMetric: 408.0190

Epoch 39: val_loss improved from 408.95346 to 408.01901, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 408.8208 - MinusLogProbMetric: 408.8208 - val_loss: 408.0190 - val_MinusLogProbMetric: 408.0190 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 40/1000
2023-09-10 05:02:11.153 
Epoch 40/1000 
	 loss: 409.9846, MinusLogProbMetric: 409.9846, val_loss: 449.3004, val_MinusLogProbMetric: 449.3004

Epoch 40: val_loss did not improve from 408.01901
196/196 - 19s - loss: 409.9846 - MinusLogProbMetric: 409.9846 - val_loss: 449.3004 - val_MinusLogProbMetric: 449.3004 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 41/1000
2023-09-10 05:02:29.461 
Epoch 41/1000 
	 loss: 409.6862, MinusLogProbMetric: 409.6862, val_loss: 408.8872, val_MinusLogProbMetric: 408.8872

Epoch 41: val_loss did not improve from 408.01901
196/196 - 18s - loss: 409.6862 - MinusLogProbMetric: 409.6862 - val_loss: 408.8872 - val_MinusLogProbMetric: 408.8872 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 42/1000
2023-09-10 05:02:47.366 
Epoch 42/1000 
	 loss: 407.9382, MinusLogProbMetric: 407.9382, val_loss: 408.1371, val_MinusLogProbMetric: 408.1371

Epoch 42: val_loss did not improve from 408.01901
196/196 - 18s - loss: 407.9382 - MinusLogProbMetric: 407.9382 - val_loss: 408.1371 - val_MinusLogProbMetric: 408.1371 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 43/1000
2023-09-10 05:03:06.897 
Epoch 43/1000 
	 loss: 407.8271, MinusLogProbMetric: 407.8271, val_loss: 408.1076, val_MinusLogProbMetric: 408.1076

Epoch 43: val_loss did not improve from 408.01901
196/196 - 20s - loss: 407.8271 - MinusLogProbMetric: 407.8271 - val_loss: 408.1076 - val_MinusLogProbMetric: 408.1076 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 44/1000
2023-09-10 05:03:25.439 
Epoch 44/1000 
	 loss: 407.5112, MinusLogProbMetric: 407.5112, val_loss: 408.4137, val_MinusLogProbMetric: 408.4137

Epoch 44: val_loss did not improve from 408.01901
196/196 - 19s - loss: 407.5112 - MinusLogProbMetric: 407.5112 - val_loss: 408.4137 - val_MinusLogProbMetric: 408.4137 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 45/1000
2023-09-10 05:03:44.075 
Epoch 45/1000 
	 loss: 407.5336, MinusLogProbMetric: 407.5336, val_loss: 407.8358, val_MinusLogProbMetric: 407.8358

Epoch 45: val_loss improved from 408.01901 to 407.83585, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 407.5336 - MinusLogProbMetric: 407.5336 - val_loss: 407.8358 - val_MinusLogProbMetric: 407.8358 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 46/1000
2023-09-10 05:04:03.612 
Epoch 46/1000 
	 loss: 407.0784, MinusLogProbMetric: 407.0784, val_loss: 406.6237, val_MinusLogProbMetric: 406.6237

Epoch 46: val_loss improved from 407.83585 to 406.62372, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 407.0784 - MinusLogProbMetric: 407.0784 - val_loss: 406.6237 - val_MinusLogProbMetric: 406.6237 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 47/1000
2023-09-10 05:04:23.847 
Epoch 47/1000 
	 loss: 407.2547, MinusLogProbMetric: 407.2547, val_loss: 413.7237, val_MinusLogProbMetric: 413.7237

Epoch 47: val_loss did not improve from 406.62372
196/196 - 19s - loss: 407.2547 - MinusLogProbMetric: 407.2547 - val_loss: 413.7237 - val_MinusLogProbMetric: 413.7237 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 48/1000
2023-09-10 05:04:41.030 
Epoch 48/1000 
	 loss: 406.5999, MinusLogProbMetric: 406.5999, val_loss: 407.2790, val_MinusLogProbMetric: 407.2790

Epoch 48: val_loss did not improve from 406.62372
196/196 - 17s - loss: 406.5999 - MinusLogProbMetric: 406.5999 - val_loss: 407.2790 - val_MinusLogProbMetric: 407.2790 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 49/1000
2023-09-10 05:05:00.202 
Epoch 49/1000 
	 loss: 406.9734, MinusLogProbMetric: 406.9734, val_loss: 411.6257, val_MinusLogProbMetric: 411.6257

Epoch 49: val_loss did not improve from 406.62372
196/196 - 19s - loss: 406.9734 - MinusLogProbMetric: 406.9734 - val_loss: 411.6257 - val_MinusLogProbMetric: 411.6257 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 50/1000
2023-09-10 05:05:19.581 
Epoch 50/1000 
	 loss: 406.4353, MinusLogProbMetric: 406.4353, val_loss: 407.0868, val_MinusLogProbMetric: 407.0868

Epoch 50: val_loss did not improve from 406.62372
196/196 - 19s - loss: 406.4353 - MinusLogProbMetric: 406.4353 - val_loss: 407.0868 - val_MinusLogProbMetric: 407.0868 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 51/1000
2023-09-10 05:05:39.169 
Epoch 51/1000 
	 loss: 406.3708, MinusLogProbMetric: 406.3708, val_loss: 407.1804, val_MinusLogProbMetric: 407.1804

Epoch 51: val_loss did not improve from 406.62372
196/196 - 20s - loss: 406.3708 - MinusLogProbMetric: 406.3708 - val_loss: 407.1804 - val_MinusLogProbMetric: 407.1804 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 52/1000
2023-09-10 05:05:58.132 
Epoch 52/1000 
	 loss: 406.3231, MinusLogProbMetric: 406.3231, val_loss: 407.8143, val_MinusLogProbMetric: 407.8143

Epoch 52: val_loss did not improve from 406.62372
196/196 - 19s - loss: 406.3231 - MinusLogProbMetric: 406.3231 - val_loss: 407.8143 - val_MinusLogProbMetric: 407.8143 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 53/1000
2023-09-10 05:06:17.689 
Epoch 53/1000 
	 loss: 406.0640, MinusLogProbMetric: 406.0640, val_loss: 404.7222, val_MinusLogProbMetric: 404.7222

Epoch 53: val_loss improved from 406.62372 to 404.72223, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 406.0640 - MinusLogProbMetric: 406.0640 - val_loss: 404.7222 - val_MinusLogProbMetric: 404.7222 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 54/1000
2023-09-10 05:06:37.442 
Epoch 54/1000 
	 loss: 412.2885, MinusLogProbMetric: 412.2885, val_loss: 406.0817, val_MinusLogProbMetric: 406.0817

Epoch 54: val_loss did not improve from 404.72223
196/196 - 19s - loss: 412.2885 - MinusLogProbMetric: 412.2885 - val_loss: 406.0817 - val_MinusLogProbMetric: 406.0817 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 55/1000
2023-09-10 05:06:56.839 
Epoch 55/1000 
	 loss: 406.1154, MinusLogProbMetric: 406.1154, val_loss: 405.7037, val_MinusLogProbMetric: 405.7037

Epoch 55: val_loss did not improve from 404.72223
196/196 - 19s - loss: 406.1154 - MinusLogProbMetric: 406.1154 - val_loss: 405.7037 - val_MinusLogProbMetric: 405.7037 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 56/1000
2023-09-10 05:07:15.978 
Epoch 56/1000 
	 loss: 407.8187, MinusLogProbMetric: 407.8187, val_loss: 406.0325, val_MinusLogProbMetric: 406.0325

Epoch 56: val_loss did not improve from 404.72223
196/196 - 19s - loss: 407.8187 - MinusLogProbMetric: 407.8187 - val_loss: 406.0325 - val_MinusLogProbMetric: 406.0325 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 57/1000
2023-09-10 05:07:34.741 
Epoch 57/1000 
	 loss: 405.8531, MinusLogProbMetric: 405.8531, val_loss: 408.9564, val_MinusLogProbMetric: 408.9564

Epoch 57: val_loss did not improve from 404.72223
196/196 - 19s - loss: 405.8531 - MinusLogProbMetric: 405.8531 - val_loss: 408.9564 - val_MinusLogProbMetric: 408.9564 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 58/1000
2023-09-10 05:07:55.195 
Epoch 58/1000 
	 loss: 404.5295, MinusLogProbMetric: 404.5295, val_loss: 409.1071, val_MinusLogProbMetric: 409.1071

Epoch 58: val_loss did not improve from 404.72223
196/196 - 20s - loss: 404.5295 - MinusLogProbMetric: 404.5295 - val_loss: 409.1071 - val_MinusLogProbMetric: 409.1071 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 59/1000
2023-09-10 05:08:15.225 
Epoch 59/1000 
	 loss: 405.1357, MinusLogProbMetric: 405.1357, val_loss: 404.7058, val_MinusLogProbMetric: 404.7058

Epoch 59: val_loss improved from 404.72223 to 404.70581, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 21s - loss: 405.1357 - MinusLogProbMetric: 405.1357 - val_loss: 404.7058 - val_MinusLogProbMetric: 404.7058 - lr: 3.3333e-04 - 21s/epoch - 107ms/step
Epoch 60/1000
2023-09-10 05:08:33.595 
Epoch 60/1000 
	 loss: 404.9370, MinusLogProbMetric: 404.9370, val_loss: 418.4264, val_MinusLogProbMetric: 418.4264

Epoch 60: val_loss did not improve from 404.70581
196/196 - 17s - loss: 404.9370 - MinusLogProbMetric: 404.9370 - val_loss: 418.4264 - val_MinusLogProbMetric: 418.4264 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 61/1000
2023-09-10 05:08:51.547 
Epoch 61/1000 
	 loss: 404.8029, MinusLogProbMetric: 404.8029, val_loss: 410.1053, val_MinusLogProbMetric: 410.1053

Epoch 61: val_loss did not improve from 404.70581
196/196 - 18s - loss: 404.8029 - MinusLogProbMetric: 404.8029 - val_loss: 410.1053 - val_MinusLogProbMetric: 410.1053 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 62/1000
2023-09-10 05:09:09.811 
Epoch 62/1000 
	 loss: 405.1380, MinusLogProbMetric: 405.1380, val_loss: 447.7148, val_MinusLogProbMetric: 447.7148

Epoch 62: val_loss did not improve from 404.70581
196/196 - 18s - loss: 405.1380 - MinusLogProbMetric: 405.1380 - val_loss: 447.7148 - val_MinusLogProbMetric: 447.7148 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 63/1000
2023-09-10 05:09:28.002 
Epoch 63/1000 
	 loss: 408.0094, MinusLogProbMetric: 408.0094, val_loss: 406.4411, val_MinusLogProbMetric: 406.4411

Epoch 63: val_loss did not improve from 404.70581
196/196 - 18s - loss: 408.0094 - MinusLogProbMetric: 408.0094 - val_loss: 406.4411 - val_MinusLogProbMetric: 406.4411 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 64/1000
2023-09-10 05:09:46.914 
Epoch 64/1000 
	 loss: 404.1236, MinusLogProbMetric: 404.1236, val_loss: 404.1195, val_MinusLogProbMetric: 404.1195

Epoch 64: val_loss improved from 404.70581 to 404.11954, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 404.1236 - MinusLogProbMetric: 404.1236 - val_loss: 404.1195 - val_MinusLogProbMetric: 404.1195 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 65/1000
2023-09-10 05:10:06.563 
Epoch 65/1000 
	 loss: 404.2342, MinusLogProbMetric: 404.2342, val_loss: 404.0424, val_MinusLogProbMetric: 404.0424

Epoch 65: val_loss improved from 404.11954 to 404.04239, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 404.2342 - MinusLogProbMetric: 404.2342 - val_loss: 404.0424 - val_MinusLogProbMetric: 404.0424 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 66/1000
2023-09-10 05:10:26.860 
Epoch 66/1000 
	 loss: 404.2675, MinusLogProbMetric: 404.2675, val_loss: 404.5130, val_MinusLogProbMetric: 404.5130

Epoch 66: val_loss did not improve from 404.04239
196/196 - 20s - loss: 404.2675 - MinusLogProbMetric: 404.2675 - val_loss: 404.5130 - val_MinusLogProbMetric: 404.5130 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 67/1000
2023-09-10 05:10:46.161 
Epoch 67/1000 
	 loss: 405.1815, MinusLogProbMetric: 405.1815, val_loss: 404.5658, val_MinusLogProbMetric: 404.5658

Epoch 67: val_loss did not improve from 404.04239
196/196 - 19s - loss: 405.1815 - MinusLogProbMetric: 405.1815 - val_loss: 404.5658 - val_MinusLogProbMetric: 404.5658 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 68/1000
2023-09-10 05:11:05.266 
Epoch 68/1000 
	 loss: 403.7388, MinusLogProbMetric: 403.7388, val_loss: 404.8152, val_MinusLogProbMetric: 404.8152

Epoch 68: val_loss did not improve from 404.04239
196/196 - 19s - loss: 403.7388 - MinusLogProbMetric: 403.7388 - val_loss: 404.8152 - val_MinusLogProbMetric: 404.8152 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 69/1000
2023-09-10 05:11:22.544 
Epoch 69/1000 
	 loss: 403.4601, MinusLogProbMetric: 403.4601, val_loss: 404.8209, val_MinusLogProbMetric: 404.8209

Epoch 69: val_loss did not improve from 404.04239
196/196 - 17s - loss: 403.4601 - MinusLogProbMetric: 403.4601 - val_loss: 404.8209 - val_MinusLogProbMetric: 404.8209 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 70/1000
2023-09-10 05:11:41.970 
Epoch 70/1000 
	 loss: 405.2842, MinusLogProbMetric: 405.2842, val_loss: 404.6323, val_MinusLogProbMetric: 404.6323

Epoch 70: val_loss did not improve from 404.04239
196/196 - 19s - loss: 405.2842 - MinusLogProbMetric: 405.2842 - val_loss: 404.6323 - val_MinusLogProbMetric: 404.6323 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 71/1000
2023-09-10 05:12:00.982 
Epoch 71/1000 
	 loss: 405.8255, MinusLogProbMetric: 405.8255, val_loss: 405.9597, val_MinusLogProbMetric: 405.9597

Epoch 71: val_loss did not improve from 404.04239
196/196 - 19s - loss: 405.8255 - MinusLogProbMetric: 405.8255 - val_loss: 405.9597 - val_MinusLogProbMetric: 405.9597 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 72/1000
2023-09-10 05:12:20.508 
Epoch 72/1000 
	 loss: 403.0485, MinusLogProbMetric: 403.0485, val_loss: 404.4217, val_MinusLogProbMetric: 404.4217

Epoch 72: val_loss did not improve from 404.04239
196/196 - 20s - loss: 403.0485 - MinusLogProbMetric: 403.0485 - val_loss: 404.4217 - val_MinusLogProbMetric: 404.4217 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 73/1000
2023-09-10 05:12:39.711 
Epoch 73/1000 
	 loss: 403.9268, MinusLogProbMetric: 403.9268, val_loss: 406.0897, val_MinusLogProbMetric: 406.0897

Epoch 73: val_loss did not improve from 404.04239
196/196 - 19s - loss: 403.9268 - MinusLogProbMetric: 403.9268 - val_loss: 406.0897 - val_MinusLogProbMetric: 406.0897 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 74/1000
2023-09-10 05:12:58.409 
Epoch 74/1000 
	 loss: 402.8268, MinusLogProbMetric: 402.8268, val_loss: 402.8920, val_MinusLogProbMetric: 402.8920

Epoch 74: val_loss improved from 404.04239 to 402.89203, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 20s - loss: 402.8268 - MinusLogProbMetric: 402.8268 - val_loss: 402.8920 - val_MinusLogProbMetric: 402.8920 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 75/1000
2023-09-10 05:13:18.989 
Epoch 75/1000 
	 loss: 403.8634, MinusLogProbMetric: 403.8634, val_loss: 404.0349, val_MinusLogProbMetric: 404.0349

Epoch 75: val_loss did not improve from 402.89203
196/196 - 20s - loss: 403.8634 - MinusLogProbMetric: 403.8634 - val_loss: 404.0349 - val_MinusLogProbMetric: 404.0349 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 76/1000
2023-09-10 05:13:37.511 
Epoch 76/1000 
	 loss: 403.4283, MinusLogProbMetric: 403.4283, val_loss: 403.5151, val_MinusLogProbMetric: 403.5151

Epoch 76: val_loss did not improve from 402.89203
196/196 - 19s - loss: 403.4283 - MinusLogProbMetric: 403.4283 - val_loss: 403.5151 - val_MinusLogProbMetric: 403.5151 - lr: 3.3333e-04 - 19s/epoch - 94ms/step
Epoch 77/1000
2023-09-10 05:13:57.029 
Epoch 77/1000 
	 loss: 403.0312, MinusLogProbMetric: 403.0312, val_loss: 403.4184, val_MinusLogProbMetric: 403.4184

Epoch 77: val_loss did not improve from 402.89203
196/196 - 20s - loss: 403.0312 - MinusLogProbMetric: 403.0312 - val_loss: 403.4184 - val_MinusLogProbMetric: 403.4184 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 78/1000
2023-09-10 05:14:16.848 
Epoch 78/1000 
	 loss: 402.5912, MinusLogProbMetric: 402.5912, val_loss: 405.3977, val_MinusLogProbMetric: 405.3977

Epoch 78: val_loss did not improve from 402.89203
196/196 - 20s - loss: 402.5912 - MinusLogProbMetric: 402.5912 - val_loss: 405.3977 - val_MinusLogProbMetric: 405.3977 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 79/1000
2023-09-10 05:14:35.279 
Epoch 79/1000 
	 loss: 402.7939, MinusLogProbMetric: 402.7939, val_loss: 404.0805, val_MinusLogProbMetric: 404.0805

Epoch 79: val_loss did not improve from 402.89203
196/196 - 18s - loss: 402.7939 - MinusLogProbMetric: 402.7939 - val_loss: 404.0805 - val_MinusLogProbMetric: 404.0805 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 80/1000
2023-09-10 05:14:53.599 
Epoch 80/1000 
	 loss: 403.1144, MinusLogProbMetric: 403.1144, val_loss: 434.0495, val_MinusLogProbMetric: 434.0495

Epoch 80: val_loss did not improve from 402.89203
196/196 - 18s - loss: 403.1144 - MinusLogProbMetric: 403.1144 - val_loss: 434.0495 - val_MinusLogProbMetric: 434.0495 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 81/1000
2023-09-10 05:15:11.241 
Epoch 81/1000 
	 loss: 403.2716, MinusLogProbMetric: 403.2716, val_loss: 408.6967, val_MinusLogProbMetric: 408.6967

Epoch 81: val_loss did not improve from 402.89203
196/196 - 18s - loss: 403.2716 - MinusLogProbMetric: 403.2716 - val_loss: 408.6967 - val_MinusLogProbMetric: 408.6967 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 82/1000
2023-09-10 05:15:31.702 
Epoch 82/1000 
	 loss: 402.7504, MinusLogProbMetric: 402.7504, val_loss: 403.2990, val_MinusLogProbMetric: 403.2990

Epoch 82: val_loss did not improve from 402.89203
196/196 - 20s - loss: 402.7504 - MinusLogProbMetric: 402.7504 - val_loss: 403.2990 - val_MinusLogProbMetric: 403.2990 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 83/1000
2023-09-10 05:15:50.108 
Epoch 83/1000 
	 loss: 402.7908, MinusLogProbMetric: 402.7908, val_loss: 404.2233, val_MinusLogProbMetric: 404.2233

Epoch 83: val_loss did not improve from 402.89203
196/196 - 18s - loss: 402.7908 - MinusLogProbMetric: 402.7908 - val_loss: 404.2233 - val_MinusLogProbMetric: 404.2233 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 84/1000
2023-09-10 05:16:08.519 
Epoch 84/1000 
	 loss: 402.1895, MinusLogProbMetric: 402.1895, val_loss: 406.7063, val_MinusLogProbMetric: 406.7063

Epoch 84: val_loss did not improve from 402.89203
196/196 - 18s - loss: 402.1895 - MinusLogProbMetric: 402.1895 - val_loss: 406.7063 - val_MinusLogProbMetric: 406.7063 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 85/1000
2023-09-10 05:16:28.138 
Epoch 85/1000 
	 loss: 402.2006, MinusLogProbMetric: 402.2006, val_loss: 403.0532, val_MinusLogProbMetric: 403.0532

Epoch 85: val_loss did not improve from 402.89203
196/196 - 20s - loss: 402.2006 - MinusLogProbMetric: 402.2006 - val_loss: 403.0532 - val_MinusLogProbMetric: 403.0532 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 86/1000
2023-09-10 05:16:47.487 
Epoch 86/1000 
	 loss: 402.7314, MinusLogProbMetric: 402.7314, val_loss: 402.9648, val_MinusLogProbMetric: 402.9648

Epoch 86: val_loss did not improve from 402.89203
196/196 - 19s - loss: 402.7314 - MinusLogProbMetric: 402.7314 - val_loss: 402.9648 - val_MinusLogProbMetric: 402.9648 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 87/1000
2023-09-10 05:17:07.049 
Epoch 87/1000 
	 loss: 610.2144, MinusLogProbMetric: 610.2144, val_loss: 871.4386, val_MinusLogProbMetric: 871.4386

Epoch 87: val_loss did not improve from 402.89203
196/196 - 20s - loss: 610.2144 - MinusLogProbMetric: 610.2144 - val_loss: 871.4386 - val_MinusLogProbMetric: 871.4386 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 88/1000
2023-09-10 05:17:27.352 
Epoch 88/1000 
	 loss: 495.5676, MinusLogProbMetric: 495.5676, val_loss: 432.7101, val_MinusLogProbMetric: 432.7101

Epoch 88: val_loss did not improve from 402.89203
196/196 - 20s - loss: 495.5676 - MinusLogProbMetric: 495.5676 - val_loss: 432.7101 - val_MinusLogProbMetric: 432.7101 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 89/1000
2023-09-10 05:17:46.144 
Epoch 89/1000 
	 loss: 424.9102, MinusLogProbMetric: 424.9102, val_loss: 422.2460, val_MinusLogProbMetric: 422.2460

Epoch 89: val_loss did not improve from 402.89203
196/196 - 19s - loss: 424.9102 - MinusLogProbMetric: 424.9102 - val_loss: 422.2460 - val_MinusLogProbMetric: 422.2460 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 90/1000
2023-09-10 05:18:03.878 
Epoch 90/1000 
	 loss: 417.8024, MinusLogProbMetric: 417.8024, val_loss: 416.7474, val_MinusLogProbMetric: 416.7474

Epoch 90: val_loss did not improve from 402.89203
196/196 - 18s - loss: 417.8024 - MinusLogProbMetric: 417.8024 - val_loss: 416.7474 - val_MinusLogProbMetric: 416.7474 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 91/1000
2023-09-10 05:18:24.569 
Epoch 91/1000 
	 loss: 414.1471, MinusLogProbMetric: 414.1471, val_loss: 414.5153, val_MinusLogProbMetric: 414.5153

Epoch 91: val_loss did not improve from 402.89203
196/196 - 21s - loss: 414.1471 - MinusLogProbMetric: 414.1471 - val_loss: 414.5153 - val_MinusLogProbMetric: 414.5153 - lr: 3.3333e-04 - 21s/epoch - 106ms/step
Epoch 92/1000
2023-09-10 05:18:44.355 
Epoch 92/1000 
	 loss: 411.9059, MinusLogProbMetric: 411.9059, val_loss: 413.3078, val_MinusLogProbMetric: 413.3078

Epoch 92: val_loss did not improve from 402.89203
196/196 - 20s - loss: 411.9059 - MinusLogProbMetric: 411.9059 - val_loss: 413.3078 - val_MinusLogProbMetric: 413.3078 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 93/1000
2023-09-10 05:19:03.909 
Epoch 93/1000 
	 loss: 410.2981, MinusLogProbMetric: 410.2981, val_loss: 410.3419, val_MinusLogProbMetric: 410.3419

Epoch 93: val_loss did not improve from 402.89203
196/196 - 20s - loss: 410.2981 - MinusLogProbMetric: 410.2981 - val_loss: 410.3419 - val_MinusLogProbMetric: 410.3419 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 94/1000
2023-09-10 05:19:22.555 
Epoch 94/1000 
	 loss: 409.2466, MinusLogProbMetric: 409.2466, val_loss: 409.9969, val_MinusLogProbMetric: 409.9969

Epoch 94: val_loss did not improve from 402.89203
196/196 - 19s - loss: 409.2466 - MinusLogProbMetric: 409.2466 - val_loss: 409.9969 - val_MinusLogProbMetric: 409.9969 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 95/1000
2023-09-10 05:19:42.010 
Epoch 95/1000 
	 loss: 407.9962, MinusLogProbMetric: 407.9962, val_loss: 409.5383, val_MinusLogProbMetric: 409.5383

Epoch 95: val_loss did not improve from 402.89203
196/196 - 19s - loss: 407.9962 - MinusLogProbMetric: 407.9962 - val_loss: 409.5383 - val_MinusLogProbMetric: 409.5383 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 96/1000
2023-09-10 05:20:02.785 
Epoch 96/1000 
	 loss: 407.4357, MinusLogProbMetric: 407.4357, val_loss: 409.9617, val_MinusLogProbMetric: 409.9617

Epoch 96: val_loss did not improve from 402.89203
196/196 - 21s - loss: 407.4357 - MinusLogProbMetric: 407.4357 - val_loss: 409.9617 - val_MinusLogProbMetric: 409.9617 - lr: 3.3333e-04 - 21s/epoch - 106ms/step
Epoch 97/1000
2023-09-10 05:20:22.656 
Epoch 97/1000 
	 loss: 406.7369, MinusLogProbMetric: 406.7369, val_loss: 408.1508, val_MinusLogProbMetric: 408.1508

Epoch 97: val_loss did not improve from 402.89203
196/196 - 20s - loss: 406.7369 - MinusLogProbMetric: 406.7369 - val_loss: 408.1508 - val_MinusLogProbMetric: 408.1508 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 98/1000
2023-09-10 05:20:42.288 
Epoch 98/1000 
	 loss: 406.3519, MinusLogProbMetric: 406.3519, val_loss: 405.9233, val_MinusLogProbMetric: 405.9233

Epoch 98: val_loss did not improve from 402.89203
196/196 - 20s - loss: 406.3519 - MinusLogProbMetric: 406.3519 - val_loss: 405.9233 - val_MinusLogProbMetric: 405.9233 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 99/1000
2023-09-10 05:21:02.365 
Epoch 99/1000 
	 loss: 405.9718, MinusLogProbMetric: 405.9718, val_loss: 405.4562, val_MinusLogProbMetric: 405.4562

Epoch 99: val_loss did not improve from 402.89203
196/196 - 20s - loss: 405.9718 - MinusLogProbMetric: 405.9718 - val_loss: 405.4562 - val_MinusLogProbMetric: 405.4562 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 100/1000
2023-09-10 05:21:22.213 
Epoch 100/1000 
	 loss: 405.7599, MinusLogProbMetric: 405.7599, val_loss: 405.8190, val_MinusLogProbMetric: 405.8190

Epoch 100: val_loss did not improve from 402.89203
196/196 - 20s - loss: 405.7599 - MinusLogProbMetric: 405.7599 - val_loss: 405.8190 - val_MinusLogProbMetric: 405.8190 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 101/1000
2023-09-10 05:21:41.376 
Epoch 101/1000 
	 loss: 404.8732, MinusLogProbMetric: 404.8732, val_loss: 407.2206, val_MinusLogProbMetric: 407.2206

Epoch 101: val_loss did not improve from 402.89203
196/196 - 19s - loss: 404.8732 - MinusLogProbMetric: 404.8732 - val_loss: 407.2206 - val_MinusLogProbMetric: 407.2206 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 102/1000
2023-09-10 05:22:00.981 
Epoch 102/1000 
	 loss: 404.8148, MinusLogProbMetric: 404.8148, val_loss: 404.4288, val_MinusLogProbMetric: 404.4288

Epoch 102: val_loss did not improve from 402.89203
196/196 - 20s - loss: 404.8148 - MinusLogProbMetric: 404.8148 - val_loss: 404.4288 - val_MinusLogProbMetric: 404.4288 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 103/1000
2023-09-10 05:22:20.368 
Epoch 103/1000 
	 loss: 404.1452, MinusLogProbMetric: 404.1452, val_loss: 404.1268, val_MinusLogProbMetric: 404.1268

Epoch 103: val_loss did not improve from 402.89203
196/196 - 19s - loss: 404.1452 - MinusLogProbMetric: 404.1452 - val_loss: 404.1268 - val_MinusLogProbMetric: 404.1268 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 104/1000
2023-09-10 05:22:39.590 
Epoch 104/1000 
	 loss: 404.2939, MinusLogProbMetric: 404.2939, val_loss: 406.5368, val_MinusLogProbMetric: 406.5368

Epoch 104: val_loss did not improve from 402.89203
196/196 - 19s - loss: 404.2939 - MinusLogProbMetric: 404.2939 - val_loss: 406.5368 - val_MinusLogProbMetric: 406.5368 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 105/1000
2023-09-10 05:22:58.280 
Epoch 105/1000 
	 loss: 403.7605, MinusLogProbMetric: 403.7605, val_loss: 404.6936, val_MinusLogProbMetric: 404.6936

Epoch 105: val_loss did not improve from 402.89203
196/196 - 19s - loss: 403.7605 - MinusLogProbMetric: 403.7605 - val_loss: 404.6936 - val_MinusLogProbMetric: 404.6936 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 106/1000
2023-09-10 05:23:16.738 
Epoch 106/1000 
	 loss: 403.9952, MinusLogProbMetric: 403.9952, val_loss: 404.0977, val_MinusLogProbMetric: 404.0977

Epoch 106: val_loss did not improve from 402.89203
196/196 - 18s - loss: 403.9952 - MinusLogProbMetric: 403.9952 - val_loss: 404.0977 - val_MinusLogProbMetric: 404.0977 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 107/1000
2023-09-10 05:23:36.548 
Epoch 107/1000 
	 loss: 403.1804, MinusLogProbMetric: 403.1804, val_loss: 404.8339, val_MinusLogProbMetric: 404.8339

Epoch 107: val_loss did not improve from 402.89203
196/196 - 20s - loss: 403.1804 - MinusLogProbMetric: 403.1804 - val_loss: 404.8339 - val_MinusLogProbMetric: 404.8339 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 108/1000
2023-09-10 05:23:55.554 
Epoch 108/1000 
	 loss: 403.2859, MinusLogProbMetric: 403.2859, val_loss: 404.4085, val_MinusLogProbMetric: 404.4085

Epoch 108: val_loss did not improve from 402.89203
196/196 - 19s - loss: 403.2859 - MinusLogProbMetric: 403.2859 - val_loss: 404.4085 - val_MinusLogProbMetric: 404.4085 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 109/1000
2023-09-10 05:24:15.727 
Epoch 109/1000 
	 loss: 402.7900, MinusLogProbMetric: 402.7900, val_loss: 407.7653, val_MinusLogProbMetric: 407.7653

Epoch 109: val_loss did not improve from 402.89203
196/196 - 20s - loss: 402.7900 - MinusLogProbMetric: 402.7900 - val_loss: 407.7653 - val_MinusLogProbMetric: 407.7653 - lr: 3.3333e-04 - 20s/epoch - 103ms/step
Epoch 110/1000
2023-09-10 05:24:34.673 
Epoch 110/1000 
	 loss: 403.2275, MinusLogProbMetric: 403.2275, val_loss: 403.1947, val_MinusLogProbMetric: 403.1947

Epoch 110: val_loss did not improve from 402.89203
196/196 - 19s - loss: 403.2275 - MinusLogProbMetric: 403.2275 - val_loss: 403.1947 - val_MinusLogProbMetric: 403.1947 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 111/1000
2023-09-10 05:24:54.546 
Epoch 111/1000 
	 loss: 402.8158, MinusLogProbMetric: 402.8158, val_loss: 404.4288, val_MinusLogProbMetric: 404.4288

Epoch 111: val_loss did not improve from 402.89203
196/196 - 20s - loss: 402.8158 - MinusLogProbMetric: 402.8158 - val_loss: 404.4288 - val_MinusLogProbMetric: 404.4288 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 112/1000
2023-09-10 05:25:14.293 
Epoch 112/1000 
	 loss: 403.2455, MinusLogProbMetric: 403.2455, val_loss: 402.4860, val_MinusLogProbMetric: 402.4860

Epoch 112: val_loss improved from 402.89203 to 402.48599, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 21s - loss: 403.2455 - MinusLogProbMetric: 403.2455 - val_loss: 402.4860 - val_MinusLogProbMetric: 402.4860 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 113/1000
2023-09-10 05:25:22.799 
Epoch 113/1000 
	 loss: 402.3606, MinusLogProbMetric: 402.3606, val_loss: 404.8177, val_MinusLogProbMetric: 404.8177

Epoch 113: val_loss did not improve from 402.48599
196/196 - 8s - loss: 402.3606 - MinusLogProbMetric: 402.3606 - val_loss: 404.8177 - val_MinusLogProbMetric: 404.8177 - lr: 3.3333e-04 - 8s/epoch - 39ms/step
Epoch 114/1000
2023-09-10 05:25:32.622 
Epoch 114/1000 
	 loss: 402.2368, MinusLogProbMetric: 402.2368, val_loss: 405.0113, val_MinusLogProbMetric: 405.0113

Epoch 114: val_loss did not improve from 402.48599
196/196 - 10s - loss: 402.2368 - MinusLogProbMetric: 402.2368 - val_loss: 405.0113 - val_MinusLogProbMetric: 405.0113 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 115/1000
2023-09-10 05:25:44.184 
Epoch 115/1000 
	 loss: 402.0500, MinusLogProbMetric: 402.0500, val_loss: 403.2867, val_MinusLogProbMetric: 403.2867

Epoch 115: val_loss did not improve from 402.48599
196/196 - 12s - loss: 402.0500 - MinusLogProbMetric: 402.0500 - val_loss: 403.2867 - val_MinusLogProbMetric: 403.2867 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 116/1000
2023-09-10 05:25:58.250 
Epoch 116/1000 
	 loss: 401.8286, MinusLogProbMetric: 401.8286, val_loss: 403.6062, val_MinusLogProbMetric: 403.6062

Epoch 116: val_loss did not improve from 402.48599
196/196 - 14s - loss: 401.8286 - MinusLogProbMetric: 401.8286 - val_loss: 403.6062 - val_MinusLogProbMetric: 403.6062 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 117/1000
2023-09-10 05:26:12.285 
Epoch 117/1000 
	 loss: 402.2375, MinusLogProbMetric: 402.2375, val_loss: 402.3155, val_MinusLogProbMetric: 402.3155

Epoch 117: val_loss improved from 402.48599 to 402.31546, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 402.2375 - MinusLogProbMetric: 402.2375 - val_loss: 402.3155 - val_MinusLogProbMetric: 402.3155 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 118/1000
2023-09-10 05:26:25.889 
Epoch 118/1000 
	 loss: 401.4932, MinusLogProbMetric: 401.4932, val_loss: 404.2418, val_MinusLogProbMetric: 404.2418

Epoch 118: val_loss did not improve from 402.31546
196/196 - 13s - loss: 401.4932 - MinusLogProbMetric: 401.4932 - val_loss: 404.2418 - val_MinusLogProbMetric: 404.2418 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 119/1000
2023-09-10 05:26:39.531 
Epoch 119/1000 
	 loss: 401.6980, MinusLogProbMetric: 401.6980, val_loss: 402.5063, val_MinusLogProbMetric: 402.5063

Epoch 119: val_loss did not improve from 402.31546
196/196 - 14s - loss: 401.6980 - MinusLogProbMetric: 401.6980 - val_loss: 402.5063 - val_MinusLogProbMetric: 402.5063 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 120/1000
2023-09-10 05:26:51.971 
Epoch 120/1000 
	 loss: 401.3051, MinusLogProbMetric: 401.3051, val_loss: 403.4550, val_MinusLogProbMetric: 403.4550

Epoch 120: val_loss did not improve from 402.31546
196/196 - 12s - loss: 401.3051 - MinusLogProbMetric: 401.3051 - val_loss: 403.4550 - val_MinusLogProbMetric: 403.4550 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 121/1000
2023-09-10 05:27:04.898 
Epoch 121/1000 
	 loss: 401.7070, MinusLogProbMetric: 401.7070, val_loss: 405.9686, val_MinusLogProbMetric: 405.9686

Epoch 121: val_loss did not improve from 402.31546
196/196 - 13s - loss: 401.7070 - MinusLogProbMetric: 401.7070 - val_loss: 405.9686 - val_MinusLogProbMetric: 405.9686 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 122/1000
2023-09-10 05:27:17.941 
Epoch 122/1000 
	 loss: 401.9340, MinusLogProbMetric: 401.9340, val_loss: 401.4248, val_MinusLogProbMetric: 401.4248

Epoch 122: val_loss improved from 402.31546 to 401.42480, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 13s - loss: 401.9340 - MinusLogProbMetric: 401.9340 - val_loss: 401.4248 - val_MinusLogProbMetric: 401.4248 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 123/1000
2023-09-10 05:27:32.102 
Epoch 123/1000 
	 loss: 401.3311, MinusLogProbMetric: 401.3311, val_loss: 402.0797, val_MinusLogProbMetric: 402.0797

Epoch 123: val_loss did not improve from 401.42480
196/196 - 14s - loss: 401.3311 - MinusLogProbMetric: 401.3311 - val_loss: 402.0797 - val_MinusLogProbMetric: 402.0797 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 124/1000
2023-09-10 05:27:45.978 
Epoch 124/1000 
	 loss: 400.9184, MinusLogProbMetric: 400.9184, val_loss: 401.2895, val_MinusLogProbMetric: 401.2895

Epoch 124: val_loss improved from 401.42480 to 401.28946, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 400.9184 - MinusLogProbMetric: 400.9184 - val_loss: 401.2895 - val_MinusLogProbMetric: 401.2895 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 125/1000
2023-09-10 05:28:00.720 
Epoch 125/1000 
	 loss: 401.0128, MinusLogProbMetric: 401.0128, val_loss: 403.3868, val_MinusLogProbMetric: 403.3868

Epoch 125: val_loss did not improve from 401.28946
196/196 - 14s - loss: 401.0128 - MinusLogProbMetric: 401.0128 - val_loss: 403.3868 - val_MinusLogProbMetric: 403.3868 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 126/1000
2023-09-10 05:28:16.316 
Epoch 126/1000 
	 loss: 401.1117, MinusLogProbMetric: 401.1117, val_loss: 402.8591, val_MinusLogProbMetric: 402.8591

Epoch 126: val_loss did not improve from 401.28946
196/196 - 16s - loss: 401.1117 - MinusLogProbMetric: 401.1117 - val_loss: 402.8591 - val_MinusLogProbMetric: 402.8591 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 127/1000
2023-09-10 05:28:30.598 
Epoch 127/1000 
	 loss: 401.3314, MinusLogProbMetric: 401.3314, val_loss: 405.4276, val_MinusLogProbMetric: 405.4276

Epoch 127: val_loss did not improve from 401.28946
196/196 - 14s - loss: 401.3314 - MinusLogProbMetric: 401.3314 - val_loss: 405.4276 - val_MinusLogProbMetric: 405.4276 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 128/1000
2023-09-10 05:28:44.746 
Epoch 128/1000 
	 loss: 400.4240, MinusLogProbMetric: 400.4240, val_loss: 403.5192, val_MinusLogProbMetric: 403.5192

Epoch 128: val_loss did not improve from 401.28946
196/196 - 14s - loss: 400.4240 - MinusLogProbMetric: 400.4240 - val_loss: 403.5192 - val_MinusLogProbMetric: 403.5192 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 129/1000
2023-09-10 05:28:59.144 
Epoch 129/1000 
	 loss: 400.8181, MinusLogProbMetric: 400.8181, val_loss: 402.1251, val_MinusLogProbMetric: 402.1251

Epoch 129: val_loss did not improve from 401.28946
196/196 - 14s - loss: 400.8181 - MinusLogProbMetric: 400.8181 - val_loss: 402.1251 - val_MinusLogProbMetric: 402.1251 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 130/1000
2023-09-10 05:29:13.893 
Epoch 130/1000 
	 loss: 400.4895, MinusLogProbMetric: 400.4895, val_loss: 403.6026, val_MinusLogProbMetric: 403.6026

Epoch 130: val_loss did not improve from 401.28946
196/196 - 15s - loss: 400.4895 - MinusLogProbMetric: 400.4895 - val_loss: 403.6026 - val_MinusLogProbMetric: 403.6026 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 131/1000
2023-09-10 05:29:29.564 
Epoch 131/1000 
	 loss: 400.3615, MinusLogProbMetric: 400.3615, val_loss: 402.1425, val_MinusLogProbMetric: 402.1425

Epoch 131: val_loss did not improve from 401.28946
196/196 - 16s - loss: 400.3615 - MinusLogProbMetric: 400.3615 - val_loss: 402.1425 - val_MinusLogProbMetric: 402.1425 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 132/1000
2023-09-10 05:29:43.866 
Epoch 132/1000 
	 loss: 400.6084, MinusLogProbMetric: 400.6084, val_loss: 401.9235, val_MinusLogProbMetric: 401.9235

Epoch 132: val_loss did not improve from 401.28946
196/196 - 14s - loss: 400.6084 - MinusLogProbMetric: 400.6084 - val_loss: 401.9235 - val_MinusLogProbMetric: 401.9235 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 133/1000
2023-09-10 05:29:59.350 
Epoch 133/1000 
	 loss: 400.4987, MinusLogProbMetric: 400.4987, val_loss: 401.7489, val_MinusLogProbMetric: 401.7489

Epoch 133: val_loss did not improve from 401.28946
196/196 - 15s - loss: 400.4987 - MinusLogProbMetric: 400.4987 - val_loss: 401.7489 - val_MinusLogProbMetric: 401.7489 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 134/1000
2023-09-10 05:30:13.663 
Epoch 134/1000 
	 loss: 400.4194, MinusLogProbMetric: 400.4194, val_loss: 405.4452, val_MinusLogProbMetric: 405.4452

Epoch 134: val_loss did not improve from 401.28946
196/196 - 14s - loss: 400.4194 - MinusLogProbMetric: 400.4194 - val_loss: 405.4452 - val_MinusLogProbMetric: 405.4452 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 135/1000
2023-09-10 05:30:26.928 
Epoch 135/1000 
	 loss: 400.2093, MinusLogProbMetric: 400.2093, val_loss: 401.3316, val_MinusLogProbMetric: 401.3316

Epoch 135: val_loss did not improve from 401.28946
196/196 - 13s - loss: 400.2093 - MinusLogProbMetric: 400.2093 - val_loss: 401.3316 - val_MinusLogProbMetric: 401.3316 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 136/1000
2023-09-10 05:30:39.993 
Epoch 136/1000 
	 loss: 400.2687, MinusLogProbMetric: 400.2687, val_loss: 403.6796, val_MinusLogProbMetric: 403.6796

Epoch 136: val_loss did not improve from 401.28946
196/196 - 13s - loss: 400.2687 - MinusLogProbMetric: 400.2687 - val_loss: 403.6796 - val_MinusLogProbMetric: 403.6796 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 137/1000
2023-09-10 05:30:52.422 
Epoch 137/1000 
	 loss: 399.8696, MinusLogProbMetric: 399.8696, val_loss: 401.7744, val_MinusLogProbMetric: 401.7744

Epoch 137: val_loss did not improve from 401.28946
196/196 - 12s - loss: 399.8696 - MinusLogProbMetric: 399.8696 - val_loss: 401.7744 - val_MinusLogProbMetric: 401.7744 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 138/1000
2023-09-10 05:31:07.711 
Epoch 138/1000 
	 loss: 400.3506, MinusLogProbMetric: 400.3506, val_loss: 400.8459, val_MinusLogProbMetric: 400.8459

Epoch 138: val_loss improved from 401.28946 to 400.84589, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 400.3506 - MinusLogProbMetric: 400.3506 - val_loss: 400.8459 - val_MinusLogProbMetric: 400.8459 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 139/1000
2023-09-10 05:31:25.297 
Epoch 139/1000 
	 loss: 399.8823, MinusLogProbMetric: 399.8823, val_loss: 400.4409, val_MinusLogProbMetric: 400.4409

Epoch 139: val_loss improved from 400.84589 to 400.44095, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 18s - loss: 399.8823 - MinusLogProbMetric: 399.8823 - val_loss: 400.4409 - val_MinusLogProbMetric: 400.4409 - lr: 3.3333e-04 - 18s/epoch - 89ms/step
Epoch 140/1000
2023-09-10 05:31:42.491 
Epoch 140/1000 
	 loss: 399.8611, MinusLogProbMetric: 399.8611, val_loss: 400.1365, val_MinusLogProbMetric: 400.1365

Epoch 140: val_loss improved from 400.44095 to 400.13647, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 17s - loss: 399.8611 - MinusLogProbMetric: 399.8611 - val_loss: 400.1365 - val_MinusLogProbMetric: 400.1365 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 141/1000
2023-09-10 05:32:00.205 
Epoch 141/1000 
	 loss: 399.8574, MinusLogProbMetric: 399.8574, val_loss: 400.6382, val_MinusLogProbMetric: 400.6382

Epoch 141: val_loss did not improve from 400.13647
196/196 - 17s - loss: 399.8574 - MinusLogProbMetric: 399.8574 - val_loss: 400.6382 - val_MinusLogProbMetric: 400.6382 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 142/1000
2023-09-10 05:32:14.354 
Epoch 142/1000 
	 loss: 399.9844, MinusLogProbMetric: 399.9844, val_loss: 401.6706, val_MinusLogProbMetric: 401.6706

Epoch 142: val_loss did not improve from 400.13647
196/196 - 14s - loss: 399.9844 - MinusLogProbMetric: 399.9844 - val_loss: 401.6706 - val_MinusLogProbMetric: 401.6706 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 143/1000
2023-09-10 05:32:29.445 
Epoch 143/1000 
	 loss: 399.8782, MinusLogProbMetric: 399.8782, val_loss: 402.6938, val_MinusLogProbMetric: 402.6938

Epoch 143: val_loss did not improve from 400.13647
196/196 - 15s - loss: 399.8782 - MinusLogProbMetric: 399.8782 - val_loss: 402.6938 - val_MinusLogProbMetric: 402.6938 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 144/1000
2023-09-10 05:32:44.047 
Epoch 144/1000 
	 loss: 399.4247, MinusLogProbMetric: 399.4247, val_loss: 403.0259, val_MinusLogProbMetric: 403.0259

Epoch 144: val_loss did not improve from 400.13647
196/196 - 15s - loss: 399.4247 - MinusLogProbMetric: 399.4247 - val_loss: 403.0259 - val_MinusLogProbMetric: 403.0259 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 145/1000
2023-09-10 05:32:58.320 
Epoch 145/1000 
	 loss: 399.6792, MinusLogProbMetric: 399.6792, val_loss: 405.4055, val_MinusLogProbMetric: 405.4055

Epoch 145: val_loss did not improve from 400.13647
196/196 - 14s - loss: 399.6792 - MinusLogProbMetric: 399.6792 - val_loss: 405.4055 - val_MinusLogProbMetric: 405.4055 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 146/1000
2023-09-10 05:33:13.320 
Epoch 146/1000 
	 loss: 399.4733, MinusLogProbMetric: 399.4733, val_loss: 401.5827, val_MinusLogProbMetric: 401.5827

Epoch 146: val_loss did not improve from 400.13647
196/196 - 15s - loss: 399.4733 - MinusLogProbMetric: 399.4733 - val_loss: 401.5827 - val_MinusLogProbMetric: 401.5827 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 147/1000
2023-09-10 05:33:26.757 
Epoch 147/1000 
	 loss: 399.3183, MinusLogProbMetric: 399.3183, val_loss: 400.4633, val_MinusLogProbMetric: 400.4633

Epoch 147: val_loss did not improve from 400.13647
196/196 - 13s - loss: 399.3183 - MinusLogProbMetric: 399.3183 - val_loss: 400.4633 - val_MinusLogProbMetric: 400.4633 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 148/1000
2023-09-10 05:33:42.002 
Epoch 148/1000 
	 loss: 399.4630, MinusLogProbMetric: 399.4630, val_loss: 401.2655, val_MinusLogProbMetric: 401.2655

Epoch 148: val_loss did not improve from 400.13647
196/196 - 15s - loss: 399.4630 - MinusLogProbMetric: 399.4630 - val_loss: 401.2655 - val_MinusLogProbMetric: 401.2655 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 149/1000
2023-09-10 05:33:57.137 
Epoch 149/1000 
	 loss: 399.5118, MinusLogProbMetric: 399.5118, val_loss: 403.5705, val_MinusLogProbMetric: 403.5705

Epoch 149: val_loss did not improve from 400.13647
196/196 - 15s - loss: 399.5118 - MinusLogProbMetric: 399.5118 - val_loss: 403.5705 - val_MinusLogProbMetric: 403.5705 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 150/1000
2023-09-10 05:34:12.707 
Epoch 150/1000 
	 loss: 399.6362, MinusLogProbMetric: 399.6362, val_loss: 399.6976, val_MinusLogProbMetric: 399.6976

Epoch 150: val_loss improved from 400.13647 to 399.69757, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 399.6362 - MinusLogProbMetric: 399.6362 - val_loss: 399.6976 - val_MinusLogProbMetric: 399.6976 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 151/1000
2023-09-10 05:34:28.671 
Epoch 151/1000 
	 loss: 399.3094, MinusLogProbMetric: 399.3094, val_loss: 402.0689, val_MinusLogProbMetric: 402.0689

Epoch 151: val_loss did not improve from 399.69757
196/196 - 15s - loss: 399.3094 - MinusLogProbMetric: 399.3094 - val_loss: 402.0689 - val_MinusLogProbMetric: 402.0689 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 152/1000
2023-09-10 05:34:43.568 
Epoch 152/1000 
	 loss: 399.4272, MinusLogProbMetric: 399.4272, val_loss: 399.8228, val_MinusLogProbMetric: 399.8228

Epoch 152: val_loss did not improve from 399.69757
196/196 - 15s - loss: 399.4272 - MinusLogProbMetric: 399.4272 - val_loss: 399.8228 - val_MinusLogProbMetric: 399.8228 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 153/1000
2023-09-10 05:34:59.085 
Epoch 153/1000 
	 loss: 399.3402, MinusLogProbMetric: 399.3402, val_loss: 401.6576, val_MinusLogProbMetric: 401.6576

Epoch 153: val_loss did not improve from 399.69757
196/196 - 16s - loss: 399.3402 - MinusLogProbMetric: 399.3402 - val_loss: 401.6576 - val_MinusLogProbMetric: 401.6576 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 154/1000
2023-09-10 05:35:14.160 
Epoch 154/1000 
	 loss: 399.3871, MinusLogProbMetric: 399.3871, val_loss: 401.5143, val_MinusLogProbMetric: 401.5143

Epoch 154: val_loss did not improve from 399.69757
196/196 - 15s - loss: 399.3871 - MinusLogProbMetric: 399.3871 - val_loss: 401.5143 - val_MinusLogProbMetric: 401.5143 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 155/1000
2023-09-10 05:35:29.706 
Epoch 155/1000 
	 loss: 399.7574, MinusLogProbMetric: 399.7574, val_loss: 401.2577, val_MinusLogProbMetric: 401.2577

Epoch 155: val_loss did not improve from 399.69757
196/196 - 16s - loss: 399.7574 - MinusLogProbMetric: 399.7574 - val_loss: 401.2577 - val_MinusLogProbMetric: 401.2577 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 156/1000
2023-09-10 05:35:43.028 
Epoch 156/1000 
	 loss: 399.1557, MinusLogProbMetric: 399.1557, val_loss: 400.2137, val_MinusLogProbMetric: 400.2137

Epoch 156: val_loss did not improve from 399.69757
196/196 - 13s - loss: 399.1557 - MinusLogProbMetric: 399.1557 - val_loss: 400.2137 - val_MinusLogProbMetric: 400.2137 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 157/1000
2023-09-10 05:35:58.128 
Epoch 157/1000 
	 loss: 398.9939, MinusLogProbMetric: 398.9939, val_loss: 402.9328, val_MinusLogProbMetric: 402.9328

Epoch 157: val_loss did not improve from 399.69757
196/196 - 15s - loss: 398.9939 - MinusLogProbMetric: 398.9939 - val_loss: 402.9328 - val_MinusLogProbMetric: 402.9328 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 158/1000
2023-09-10 05:36:14.054 
Epoch 158/1000 
	 loss: 398.8782, MinusLogProbMetric: 398.8782, val_loss: 402.2663, val_MinusLogProbMetric: 402.2663

Epoch 158: val_loss did not improve from 399.69757
196/196 - 16s - loss: 398.8782 - MinusLogProbMetric: 398.8782 - val_loss: 402.2663 - val_MinusLogProbMetric: 402.2663 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 159/1000
2023-09-10 05:36:26.467 
Epoch 159/1000 
	 loss: 398.8414, MinusLogProbMetric: 398.8414, val_loss: 399.6993, val_MinusLogProbMetric: 399.6993

Epoch 159: val_loss did not improve from 399.69757
196/196 - 12s - loss: 398.8414 - MinusLogProbMetric: 398.8414 - val_loss: 399.6993 - val_MinusLogProbMetric: 399.6993 - lr: 3.3333e-04 - 12s/epoch - 63ms/step
Epoch 160/1000
2023-09-10 05:36:41.040 
Epoch 160/1000 
	 loss: 399.2297, MinusLogProbMetric: 399.2297, val_loss: 402.2867, val_MinusLogProbMetric: 402.2867

Epoch 160: val_loss did not improve from 399.69757
196/196 - 15s - loss: 399.2297 - MinusLogProbMetric: 399.2297 - val_loss: 402.2867 - val_MinusLogProbMetric: 402.2867 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 161/1000
2023-09-10 05:36:56.514 
Epoch 161/1000 
	 loss: 399.4668, MinusLogProbMetric: 399.4668, val_loss: 400.3647, val_MinusLogProbMetric: 400.3647

Epoch 161: val_loss did not improve from 399.69757
196/196 - 15s - loss: 399.4668 - MinusLogProbMetric: 399.4668 - val_loss: 400.3647 - val_MinusLogProbMetric: 400.3647 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 162/1000
2023-09-10 05:37:11.890 
Epoch 162/1000 
	 loss: 398.7183, MinusLogProbMetric: 398.7183, val_loss: 399.6823, val_MinusLogProbMetric: 399.6823

Epoch 162: val_loss improved from 399.69757 to 399.68234, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 398.7183 - MinusLogProbMetric: 398.7183 - val_loss: 399.6823 - val_MinusLogProbMetric: 399.6823 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 163/1000
2023-09-10 05:37:27.008 
Epoch 163/1000 
	 loss: 399.2774, MinusLogProbMetric: 399.2774, val_loss: 400.0381, val_MinusLogProbMetric: 400.0381

Epoch 163: val_loss did not improve from 399.68234
196/196 - 15s - loss: 399.2774 - MinusLogProbMetric: 399.2774 - val_loss: 400.0381 - val_MinusLogProbMetric: 400.0381 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 164/1000
2023-09-10 05:37:41.972 
Epoch 164/1000 
	 loss: 398.6495, MinusLogProbMetric: 398.6495, val_loss: 401.7675, val_MinusLogProbMetric: 401.7675

Epoch 164: val_loss did not improve from 399.68234
196/196 - 15s - loss: 398.6495 - MinusLogProbMetric: 398.6495 - val_loss: 401.7675 - val_MinusLogProbMetric: 401.7675 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 165/1000
2023-09-10 05:37:57.431 
Epoch 165/1000 
	 loss: 398.6715, MinusLogProbMetric: 398.6715, val_loss: 401.3316, val_MinusLogProbMetric: 401.3316

Epoch 165: val_loss did not improve from 399.68234
196/196 - 15s - loss: 398.6715 - MinusLogProbMetric: 398.6715 - val_loss: 401.3316 - val_MinusLogProbMetric: 401.3316 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 166/1000
2023-09-10 05:38:14.591 
Epoch 166/1000 
	 loss: 398.7767, MinusLogProbMetric: 398.7767, val_loss: 402.6618, val_MinusLogProbMetric: 402.6618

Epoch 166: val_loss did not improve from 399.68234
196/196 - 17s - loss: 398.7767 - MinusLogProbMetric: 398.7767 - val_loss: 402.6618 - val_MinusLogProbMetric: 402.6618 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 167/1000
2023-09-10 05:38:32.350 
Epoch 167/1000 
	 loss: 398.6969, MinusLogProbMetric: 398.6969, val_loss: 399.7305, val_MinusLogProbMetric: 399.7305

Epoch 167: val_loss did not improve from 399.68234
196/196 - 18s - loss: 398.6969 - MinusLogProbMetric: 398.6969 - val_loss: 399.7305 - val_MinusLogProbMetric: 399.7305 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 168/1000
2023-09-10 05:38:48.781 
Epoch 168/1000 
	 loss: 398.6877, MinusLogProbMetric: 398.6877, val_loss: 400.6842, val_MinusLogProbMetric: 400.6842

Epoch 168: val_loss did not improve from 399.68234
196/196 - 16s - loss: 398.6877 - MinusLogProbMetric: 398.6877 - val_loss: 400.6842 - val_MinusLogProbMetric: 400.6842 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 169/1000
2023-09-10 05:39:03.133 
Epoch 169/1000 
	 loss: 398.4395, MinusLogProbMetric: 398.4395, val_loss: 425.6988, val_MinusLogProbMetric: 425.6988

Epoch 169: val_loss did not improve from 399.68234
196/196 - 14s - loss: 398.4395 - MinusLogProbMetric: 398.4395 - val_loss: 425.6988 - val_MinusLogProbMetric: 425.6988 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 170/1000
2023-09-10 05:39:17.978 
Epoch 170/1000 
	 loss: 398.8535, MinusLogProbMetric: 398.8535, val_loss: 407.0153, val_MinusLogProbMetric: 407.0153

Epoch 170: val_loss did not improve from 399.68234
196/196 - 15s - loss: 398.8535 - MinusLogProbMetric: 398.8535 - val_loss: 407.0153 - val_MinusLogProbMetric: 407.0153 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 171/1000
2023-09-10 05:39:32.189 
Epoch 171/1000 
	 loss: 398.5036, MinusLogProbMetric: 398.5036, val_loss: 400.9185, val_MinusLogProbMetric: 400.9185

Epoch 171: val_loss did not improve from 399.68234
196/196 - 14s - loss: 398.5036 - MinusLogProbMetric: 398.5036 - val_loss: 400.9185 - val_MinusLogProbMetric: 400.9185 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 172/1000
2023-09-10 05:39:48.169 
Epoch 172/1000 
	 loss: 398.5857, MinusLogProbMetric: 398.5857, val_loss: 401.9417, val_MinusLogProbMetric: 401.9417

Epoch 172: val_loss did not improve from 399.68234
196/196 - 16s - loss: 398.5857 - MinusLogProbMetric: 398.5857 - val_loss: 401.9417 - val_MinusLogProbMetric: 401.9417 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 173/1000
2023-09-10 05:40:02.044 
Epoch 173/1000 
	 loss: 398.3840, MinusLogProbMetric: 398.3840, val_loss: 400.1084, val_MinusLogProbMetric: 400.1084

Epoch 173: val_loss did not improve from 399.68234
196/196 - 14s - loss: 398.3840 - MinusLogProbMetric: 398.3840 - val_loss: 400.1084 - val_MinusLogProbMetric: 400.1084 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 174/1000
2023-09-10 05:40:16.491 
Epoch 174/1000 
	 loss: 398.2295, MinusLogProbMetric: 398.2295, val_loss: 399.5328, val_MinusLogProbMetric: 399.5328

Epoch 174: val_loss improved from 399.68234 to 399.53281, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 398.2295 - MinusLogProbMetric: 398.2295 - val_loss: 399.5328 - val_MinusLogProbMetric: 399.5328 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 175/1000
2023-09-10 05:40:31.177 
Epoch 175/1000 
	 loss: 400.1303, MinusLogProbMetric: 400.1303, val_loss: 399.7261, val_MinusLogProbMetric: 399.7261

Epoch 175: val_loss did not improve from 399.53281
196/196 - 14s - loss: 400.1303 - MinusLogProbMetric: 400.1303 - val_loss: 399.7261 - val_MinusLogProbMetric: 399.7261 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 176/1000
2023-09-10 05:40:46.390 
Epoch 176/1000 
	 loss: 398.3051, MinusLogProbMetric: 398.3051, val_loss: 401.3966, val_MinusLogProbMetric: 401.3966

Epoch 176: val_loss did not improve from 399.53281
196/196 - 15s - loss: 398.3051 - MinusLogProbMetric: 398.3051 - val_loss: 401.3966 - val_MinusLogProbMetric: 401.3966 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 177/1000
2023-09-10 05:41:01.041 
Epoch 177/1000 
	 loss: 398.1392, MinusLogProbMetric: 398.1392, val_loss: 398.5014, val_MinusLogProbMetric: 398.5014

Epoch 177: val_loss improved from 399.53281 to 398.50137, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 398.1392 - MinusLogProbMetric: 398.1392 - val_loss: 398.5014 - val_MinusLogProbMetric: 398.5014 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 178/1000
2023-09-10 05:41:15.129 
Epoch 178/1000 
	 loss: 398.1302, MinusLogProbMetric: 398.1302, val_loss: 400.5846, val_MinusLogProbMetric: 400.5846

Epoch 178: val_loss did not improve from 398.50137
196/196 - 14s - loss: 398.1302 - MinusLogProbMetric: 398.1302 - val_loss: 400.5846 - val_MinusLogProbMetric: 400.5846 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 179/1000
2023-09-10 05:41:30.356 
Epoch 179/1000 
	 loss: 398.2109, MinusLogProbMetric: 398.2109, val_loss: 399.9664, val_MinusLogProbMetric: 399.9664

Epoch 179: val_loss did not improve from 398.50137
196/196 - 15s - loss: 398.2109 - MinusLogProbMetric: 398.2109 - val_loss: 399.9664 - val_MinusLogProbMetric: 399.9664 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 180/1000
2023-09-10 05:41:44.709 
Epoch 180/1000 
	 loss: 397.9913, MinusLogProbMetric: 397.9913, val_loss: 401.7909, val_MinusLogProbMetric: 401.7909

Epoch 180: val_loss did not improve from 398.50137
196/196 - 14s - loss: 397.9913 - MinusLogProbMetric: 397.9913 - val_loss: 401.7909 - val_MinusLogProbMetric: 401.7909 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 181/1000
2023-09-10 05:42:00.724 
Epoch 181/1000 
	 loss: 398.4322, MinusLogProbMetric: 398.4322, val_loss: 401.4198, val_MinusLogProbMetric: 401.4198

Epoch 181: val_loss did not improve from 398.50137
196/196 - 16s - loss: 398.4322 - MinusLogProbMetric: 398.4322 - val_loss: 401.4198 - val_MinusLogProbMetric: 401.4198 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 182/1000
2023-09-10 05:42:16.086 
Epoch 182/1000 
	 loss: 398.0368, MinusLogProbMetric: 398.0368, val_loss: 401.6517, val_MinusLogProbMetric: 401.6517

Epoch 182: val_loss did not improve from 398.50137
196/196 - 15s - loss: 398.0368 - MinusLogProbMetric: 398.0368 - val_loss: 401.6517 - val_MinusLogProbMetric: 401.6517 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 183/1000
2023-09-10 05:42:31.355 
Epoch 183/1000 
	 loss: 398.7555, MinusLogProbMetric: 398.7555, val_loss: 400.3539, val_MinusLogProbMetric: 400.3539

Epoch 183: val_loss did not improve from 398.50137
196/196 - 15s - loss: 398.7555 - MinusLogProbMetric: 398.7555 - val_loss: 400.3539 - val_MinusLogProbMetric: 400.3539 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 184/1000
2023-09-10 05:42:46.787 
Epoch 184/1000 
	 loss: 397.9016, MinusLogProbMetric: 397.9016, val_loss: 398.2479, val_MinusLogProbMetric: 398.2479

Epoch 184: val_loss improved from 398.50137 to 398.24786, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 397.9016 - MinusLogProbMetric: 397.9016 - val_loss: 398.2479 - val_MinusLogProbMetric: 398.2479 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 185/1000
2023-09-10 05:43:01.916 
Epoch 185/1000 
	 loss: 397.8574, MinusLogProbMetric: 397.8574, val_loss: 402.1811, val_MinusLogProbMetric: 402.1811

Epoch 185: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.8574 - MinusLogProbMetric: 397.8574 - val_loss: 402.1811 - val_MinusLogProbMetric: 402.1811 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 186/1000
2023-09-10 05:43:16.268 
Epoch 186/1000 
	 loss: 398.0306, MinusLogProbMetric: 398.0306, val_loss: 398.8799, val_MinusLogProbMetric: 398.8799

Epoch 186: val_loss did not improve from 398.24786
196/196 - 14s - loss: 398.0306 - MinusLogProbMetric: 398.0306 - val_loss: 398.8799 - val_MinusLogProbMetric: 398.8799 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 187/1000
2023-09-10 05:43:32.423 
Epoch 187/1000 
	 loss: 397.6228, MinusLogProbMetric: 397.6228, val_loss: 400.4712, val_MinusLogProbMetric: 400.4712

Epoch 187: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.6228 - MinusLogProbMetric: 397.6228 - val_loss: 400.4712 - val_MinusLogProbMetric: 400.4712 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 188/1000
2023-09-10 05:43:46.098 
Epoch 188/1000 
	 loss: 398.6375, MinusLogProbMetric: 398.6375, val_loss: 398.7781, val_MinusLogProbMetric: 398.7781

Epoch 188: val_loss did not improve from 398.24786
196/196 - 14s - loss: 398.6375 - MinusLogProbMetric: 398.6375 - val_loss: 398.7781 - val_MinusLogProbMetric: 398.7781 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 189/1000
2023-09-10 05:44:01.693 
Epoch 189/1000 
	 loss: 398.1712, MinusLogProbMetric: 398.1712, val_loss: 398.2969, val_MinusLogProbMetric: 398.2969

Epoch 189: val_loss did not improve from 398.24786
196/196 - 16s - loss: 398.1712 - MinusLogProbMetric: 398.1712 - val_loss: 398.2969 - val_MinusLogProbMetric: 398.2969 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 190/1000
2023-09-10 05:44:17.947 
Epoch 190/1000 
	 loss: 397.6979, MinusLogProbMetric: 397.6979, val_loss: 399.6595, val_MinusLogProbMetric: 399.6595

Epoch 190: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.6979 - MinusLogProbMetric: 397.6979 - val_loss: 399.6595 - val_MinusLogProbMetric: 399.6595 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 191/1000
2023-09-10 05:44:33.414 
Epoch 191/1000 
	 loss: 398.0089, MinusLogProbMetric: 398.0089, val_loss: 401.5974, val_MinusLogProbMetric: 401.5974

Epoch 191: val_loss did not improve from 398.24786
196/196 - 15s - loss: 398.0089 - MinusLogProbMetric: 398.0089 - val_loss: 401.5974 - val_MinusLogProbMetric: 401.5974 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 192/1000
2023-09-10 05:44:49.849 
Epoch 192/1000 
	 loss: 397.5476, MinusLogProbMetric: 397.5476, val_loss: 399.9961, val_MinusLogProbMetric: 399.9961

Epoch 192: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.5476 - MinusLogProbMetric: 397.5476 - val_loss: 399.9961 - val_MinusLogProbMetric: 399.9961 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 193/1000
2023-09-10 05:45:03.416 
Epoch 193/1000 
	 loss: 398.5623, MinusLogProbMetric: 398.5623, val_loss: 398.5468, val_MinusLogProbMetric: 398.5468

Epoch 193: val_loss did not improve from 398.24786
196/196 - 14s - loss: 398.5623 - MinusLogProbMetric: 398.5623 - val_loss: 398.5468 - val_MinusLogProbMetric: 398.5468 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 194/1000
2023-09-10 05:45:18.827 
Epoch 194/1000 
	 loss: 397.3752, MinusLogProbMetric: 397.3752, val_loss: 399.7353, val_MinusLogProbMetric: 399.7353

Epoch 194: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.3752 - MinusLogProbMetric: 397.3752 - val_loss: 399.7353 - val_MinusLogProbMetric: 399.7353 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 195/1000
2023-09-10 05:45:33.836 
Epoch 195/1000 
	 loss: 397.6750, MinusLogProbMetric: 397.6750, val_loss: 400.8102, val_MinusLogProbMetric: 400.8102

Epoch 195: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.6750 - MinusLogProbMetric: 397.6750 - val_loss: 400.8102 - val_MinusLogProbMetric: 400.8102 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 196/1000
2023-09-10 05:45:48.807 
Epoch 196/1000 
	 loss: 398.5013, MinusLogProbMetric: 398.5013, val_loss: 399.0726, val_MinusLogProbMetric: 399.0726

Epoch 196: val_loss did not improve from 398.24786
196/196 - 15s - loss: 398.5013 - MinusLogProbMetric: 398.5013 - val_loss: 399.0726 - val_MinusLogProbMetric: 399.0726 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 197/1000
2023-09-10 05:46:03.145 
Epoch 197/1000 
	 loss: 397.6161, MinusLogProbMetric: 397.6161, val_loss: 399.4106, val_MinusLogProbMetric: 399.4106

Epoch 197: val_loss did not improve from 398.24786
196/196 - 14s - loss: 397.6161 - MinusLogProbMetric: 397.6161 - val_loss: 399.4106 - val_MinusLogProbMetric: 399.4106 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 198/1000
2023-09-10 05:46:18.461 
Epoch 198/1000 
	 loss: 397.4313, MinusLogProbMetric: 397.4313, val_loss: 404.3766, val_MinusLogProbMetric: 404.3766

Epoch 198: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.4313 - MinusLogProbMetric: 397.4313 - val_loss: 404.3766 - val_MinusLogProbMetric: 404.3766 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 199/1000
2023-09-10 05:46:33.111 
Epoch 199/1000 
	 loss: 397.5081, MinusLogProbMetric: 397.5081, val_loss: 398.9545, val_MinusLogProbMetric: 398.9545

Epoch 199: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.5081 - MinusLogProbMetric: 397.5081 - val_loss: 398.9545 - val_MinusLogProbMetric: 398.9545 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 200/1000
2023-09-10 05:46:46.814 
Epoch 200/1000 
	 loss: 397.4706, MinusLogProbMetric: 397.4706, val_loss: 402.8312, val_MinusLogProbMetric: 402.8312

Epoch 200: val_loss did not improve from 398.24786
196/196 - 14s - loss: 397.4706 - MinusLogProbMetric: 397.4706 - val_loss: 402.8312 - val_MinusLogProbMetric: 402.8312 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 201/1000
2023-09-10 05:47:01.442 
Epoch 201/1000 
	 loss: 397.7500, MinusLogProbMetric: 397.7500, val_loss: 407.6471, val_MinusLogProbMetric: 407.6471

Epoch 201: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.7500 - MinusLogProbMetric: 397.7500 - val_loss: 407.6471 - val_MinusLogProbMetric: 407.6471 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 202/1000
2023-09-10 05:47:15.412 
Epoch 202/1000 
	 loss: 397.5576, MinusLogProbMetric: 397.5576, val_loss: 400.0764, val_MinusLogProbMetric: 400.0764

Epoch 202: val_loss did not improve from 398.24786
196/196 - 14s - loss: 397.5576 - MinusLogProbMetric: 397.5576 - val_loss: 400.0764 - val_MinusLogProbMetric: 400.0764 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 203/1000
2023-09-10 05:47:30.609 
Epoch 203/1000 
	 loss: 397.7136, MinusLogProbMetric: 397.7136, val_loss: 398.3353, val_MinusLogProbMetric: 398.3353

Epoch 203: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.7136 - MinusLogProbMetric: 397.7136 - val_loss: 398.3353 - val_MinusLogProbMetric: 398.3353 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 204/1000
2023-09-10 05:47:46.938 
Epoch 204/1000 
	 loss: 397.2328, MinusLogProbMetric: 397.2328, val_loss: 400.2343, val_MinusLogProbMetric: 400.2343

Epoch 204: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.2328 - MinusLogProbMetric: 397.2328 - val_loss: 400.2343 - val_MinusLogProbMetric: 400.2343 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 205/1000
2023-09-10 05:48:03.116 
Epoch 205/1000 
	 loss: 397.4696, MinusLogProbMetric: 397.4696, val_loss: 400.4600, val_MinusLogProbMetric: 400.4600

Epoch 205: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.4696 - MinusLogProbMetric: 397.4696 - val_loss: 400.4600 - val_MinusLogProbMetric: 400.4600 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 206/1000
2023-09-10 05:48:19.721 
Epoch 206/1000 
	 loss: 397.3219, MinusLogProbMetric: 397.3219, val_loss: 398.4201, val_MinusLogProbMetric: 398.4201

Epoch 206: val_loss did not improve from 398.24786
196/196 - 17s - loss: 397.3219 - MinusLogProbMetric: 397.3219 - val_loss: 398.4201 - val_MinusLogProbMetric: 398.4201 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 207/1000
2023-09-10 05:48:34.408 
Epoch 207/1000 
	 loss: 397.2587, MinusLogProbMetric: 397.2587, val_loss: 403.3847, val_MinusLogProbMetric: 403.3847

Epoch 207: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.2587 - MinusLogProbMetric: 397.2587 - val_loss: 403.3847 - val_MinusLogProbMetric: 403.3847 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 208/1000
2023-09-10 05:48:50.477 
Epoch 208/1000 
	 loss: 397.1546, MinusLogProbMetric: 397.1546, val_loss: 401.5568, val_MinusLogProbMetric: 401.5568

Epoch 208: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.1546 - MinusLogProbMetric: 397.1546 - val_loss: 401.5568 - val_MinusLogProbMetric: 401.5568 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 209/1000
2023-09-10 05:49:04.589 
Epoch 209/1000 
	 loss: 397.8025, MinusLogProbMetric: 397.8025, val_loss: 399.4437, val_MinusLogProbMetric: 399.4437

Epoch 209: val_loss did not improve from 398.24786
196/196 - 14s - loss: 397.8025 - MinusLogProbMetric: 397.8025 - val_loss: 399.4437 - val_MinusLogProbMetric: 399.4437 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 210/1000
2023-09-10 05:49:21.044 
Epoch 210/1000 
	 loss: 397.1498, MinusLogProbMetric: 397.1498, val_loss: 398.9760, val_MinusLogProbMetric: 398.9760

Epoch 210: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.1498 - MinusLogProbMetric: 397.1498 - val_loss: 398.9760 - val_MinusLogProbMetric: 398.9760 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 211/1000
2023-09-10 05:49:36.380 
Epoch 211/1000 
	 loss: 397.6774, MinusLogProbMetric: 397.6774, val_loss: 398.3379, val_MinusLogProbMetric: 398.3379

Epoch 211: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.6774 - MinusLogProbMetric: 397.6774 - val_loss: 398.3379 - val_MinusLogProbMetric: 398.3379 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 212/1000
2023-09-10 05:49:53.097 
Epoch 212/1000 
	 loss: 398.8666, MinusLogProbMetric: 398.8666, val_loss: 399.1363, val_MinusLogProbMetric: 399.1363

Epoch 212: val_loss did not improve from 398.24786
196/196 - 17s - loss: 398.8666 - MinusLogProbMetric: 398.8666 - val_loss: 399.1363 - val_MinusLogProbMetric: 399.1363 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 213/1000
2023-09-10 05:50:08.591 
Epoch 213/1000 
	 loss: 396.9449, MinusLogProbMetric: 396.9449, val_loss: 398.8757, val_MinusLogProbMetric: 398.8757

Epoch 213: val_loss did not improve from 398.24786
196/196 - 15s - loss: 396.9449 - MinusLogProbMetric: 396.9449 - val_loss: 398.8757 - val_MinusLogProbMetric: 398.8757 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 214/1000
2023-09-10 05:50:25.283 
Epoch 214/1000 
	 loss: 397.1801, MinusLogProbMetric: 397.1801, val_loss: 404.4488, val_MinusLogProbMetric: 404.4488

Epoch 214: val_loss did not improve from 398.24786
196/196 - 17s - loss: 397.1801 - MinusLogProbMetric: 397.1801 - val_loss: 404.4488 - val_MinusLogProbMetric: 404.4488 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 215/1000
2023-09-10 05:50:41.709 
Epoch 215/1000 
	 loss: 396.6932, MinusLogProbMetric: 396.6932, val_loss: 400.3576, val_MinusLogProbMetric: 400.3576

Epoch 215: val_loss did not improve from 398.24786
196/196 - 16s - loss: 396.6932 - MinusLogProbMetric: 396.6932 - val_loss: 400.3576 - val_MinusLogProbMetric: 400.3576 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 216/1000
2023-09-10 05:50:57.686 
Epoch 216/1000 
	 loss: 397.1223, MinusLogProbMetric: 397.1223, val_loss: 399.6799, val_MinusLogProbMetric: 399.6799

Epoch 216: val_loss did not improve from 398.24786
196/196 - 16s - loss: 397.1223 - MinusLogProbMetric: 397.1223 - val_loss: 399.6799 - val_MinusLogProbMetric: 399.6799 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 217/1000
2023-09-10 05:51:11.140 
Epoch 217/1000 
	 loss: 396.9059, MinusLogProbMetric: 396.9059, val_loss: 400.4396, val_MinusLogProbMetric: 400.4396

Epoch 217: val_loss did not improve from 398.24786
196/196 - 13s - loss: 396.9059 - MinusLogProbMetric: 396.9059 - val_loss: 400.4396 - val_MinusLogProbMetric: 400.4396 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 218/1000
2023-09-10 05:51:26.218 
Epoch 218/1000 
	 loss: 397.1554, MinusLogProbMetric: 397.1554, val_loss: 400.5454, val_MinusLogProbMetric: 400.5454

Epoch 218: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.1554 - MinusLogProbMetric: 397.1554 - val_loss: 400.5454 - val_MinusLogProbMetric: 400.5454 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 219/1000
2023-09-10 05:51:41.046 
Epoch 219/1000 
	 loss: 397.0394, MinusLogProbMetric: 397.0394, val_loss: 399.8781, val_MinusLogProbMetric: 399.8781

Epoch 219: val_loss did not improve from 398.24786
196/196 - 15s - loss: 397.0394 - MinusLogProbMetric: 397.0394 - val_loss: 399.8781 - val_MinusLogProbMetric: 399.8781 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 220/1000
2023-09-10 05:51:56.139 
Epoch 220/1000 
	 loss: 397.8297, MinusLogProbMetric: 397.8297, val_loss: 397.6285, val_MinusLogProbMetric: 397.6285

Epoch 220: val_loss improved from 398.24786 to 397.62851, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 397.8297 - MinusLogProbMetric: 397.8297 - val_loss: 397.6285 - val_MinusLogProbMetric: 397.6285 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 221/1000
2023-09-10 05:52:10.874 
Epoch 221/1000 
	 loss: 396.5319, MinusLogProbMetric: 396.5319, val_loss: 398.4230, val_MinusLogProbMetric: 398.4230

Epoch 221: val_loss did not improve from 397.62851
196/196 - 14s - loss: 396.5319 - MinusLogProbMetric: 396.5319 - val_loss: 398.4230 - val_MinusLogProbMetric: 398.4230 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 222/1000
2023-09-10 05:52:25.927 
Epoch 222/1000 
	 loss: 396.9032, MinusLogProbMetric: 396.9032, val_loss: 397.9358, val_MinusLogProbMetric: 397.9358

Epoch 222: val_loss did not improve from 397.62851
196/196 - 15s - loss: 396.9032 - MinusLogProbMetric: 396.9032 - val_loss: 397.9358 - val_MinusLogProbMetric: 397.9358 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 223/1000
2023-09-10 05:52:41.140 
Epoch 223/1000 
	 loss: 397.3690, MinusLogProbMetric: 397.3690, val_loss: 398.5912, val_MinusLogProbMetric: 398.5912

Epoch 223: val_loss did not improve from 397.62851
196/196 - 15s - loss: 397.3690 - MinusLogProbMetric: 397.3690 - val_loss: 398.5912 - val_MinusLogProbMetric: 398.5912 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 224/1000
2023-09-10 05:52:55.949 
Epoch 224/1000 
	 loss: 397.3910, MinusLogProbMetric: 397.3910, val_loss: 397.8638, val_MinusLogProbMetric: 397.8638

Epoch 224: val_loss did not improve from 397.62851
196/196 - 15s - loss: 397.3910 - MinusLogProbMetric: 397.3910 - val_loss: 397.8638 - val_MinusLogProbMetric: 397.8638 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 225/1000
2023-09-10 05:53:09.167 
Epoch 225/1000 
	 loss: 396.8840, MinusLogProbMetric: 396.8840, val_loss: 397.3295, val_MinusLogProbMetric: 397.3295

Epoch 225: val_loss improved from 397.62851 to 397.32947, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 396.8840 - MinusLogProbMetric: 396.8840 - val_loss: 397.3295 - val_MinusLogProbMetric: 397.3295 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 226/1000
2023-09-10 05:53:24.534 
Epoch 226/1000 
	 loss: 396.9721, MinusLogProbMetric: 396.9721, val_loss: 400.3489, val_MinusLogProbMetric: 400.3489

Epoch 226: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.9721 - MinusLogProbMetric: 396.9721 - val_loss: 400.3489 - val_MinusLogProbMetric: 400.3489 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 227/1000
2023-09-10 05:53:38.401 
Epoch 227/1000 
	 loss: 396.7023, MinusLogProbMetric: 396.7023, val_loss: 399.6161, val_MinusLogProbMetric: 399.6161

Epoch 227: val_loss did not improve from 397.32947
196/196 - 14s - loss: 396.7023 - MinusLogProbMetric: 396.7023 - val_loss: 399.6161 - val_MinusLogProbMetric: 399.6161 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 228/1000
2023-09-10 05:53:53.320 
Epoch 228/1000 
	 loss: 396.7865, MinusLogProbMetric: 396.7865, val_loss: 398.3075, val_MinusLogProbMetric: 398.3075

Epoch 228: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.7865 - MinusLogProbMetric: 396.7865 - val_loss: 398.3075 - val_MinusLogProbMetric: 398.3075 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 229/1000
2023-09-10 05:54:07.989 
Epoch 229/1000 
	 loss: 396.9113, MinusLogProbMetric: 396.9113, val_loss: 399.2003, val_MinusLogProbMetric: 399.2003

Epoch 229: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.9113 - MinusLogProbMetric: 396.9113 - val_loss: 399.2003 - val_MinusLogProbMetric: 399.2003 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 230/1000
2023-09-10 05:54:23.502 
Epoch 230/1000 
	 loss: 396.7685, MinusLogProbMetric: 396.7685, val_loss: 399.5436, val_MinusLogProbMetric: 399.5436

Epoch 230: val_loss did not improve from 397.32947
196/196 - 16s - loss: 396.7685 - MinusLogProbMetric: 396.7685 - val_loss: 399.5436 - val_MinusLogProbMetric: 399.5436 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 231/1000
2023-09-10 05:54:37.818 
Epoch 231/1000 
	 loss: 397.1846, MinusLogProbMetric: 397.1846, val_loss: 399.1754, val_MinusLogProbMetric: 399.1754

Epoch 231: val_loss did not improve from 397.32947
196/196 - 14s - loss: 397.1846 - MinusLogProbMetric: 397.1846 - val_loss: 399.1754 - val_MinusLogProbMetric: 399.1754 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 232/1000
2023-09-10 05:54:50.684 
Epoch 232/1000 
	 loss: 397.6554, MinusLogProbMetric: 397.6554, val_loss: 401.1541, val_MinusLogProbMetric: 401.1541

Epoch 232: val_loss did not improve from 397.32947
196/196 - 13s - loss: 397.6554 - MinusLogProbMetric: 397.6554 - val_loss: 401.1541 - val_MinusLogProbMetric: 401.1541 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 233/1000
2023-09-10 05:55:04.724 
Epoch 233/1000 
	 loss: 396.2962, MinusLogProbMetric: 396.2962, val_loss: 398.9000, val_MinusLogProbMetric: 398.9000

Epoch 233: val_loss did not improve from 397.32947
196/196 - 14s - loss: 396.2962 - MinusLogProbMetric: 396.2962 - val_loss: 398.9000 - val_MinusLogProbMetric: 398.9000 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 234/1000
2023-09-10 05:55:20.225 
Epoch 234/1000 
	 loss: 396.9420, MinusLogProbMetric: 396.9420, val_loss: 399.8209, val_MinusLogProbMetric: 399.8209

Epoch 234: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.9420 - MinusLogProbMetric: 396.9420 - val_loss: 399.8209 - val_MinusLogProbMetric: 399.8209 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 235/1000
2023-09-10 05:55:34.688 
Epoch 235/1000 
	 loss: 396.5064, MinusLogProbMetric: 396.5064, val_loss: 403.0445, val_MinusLogProbMetric: 403.0445

Epoch 235: val_loss did not improve from 397.32947
196/196 - 14s - loss: 396.5064 - MinusLogProbMetric: 396.5064 - val_loss: 403.0445 - val_MinusLogProbMetric: 403.0445 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 236/1000
2023-09-10 05:55:50.633 
Epoch 236/1000 
	 loss: 396.9991, MinusLogProbMetric: 396.9991, val_loss: 402.0985, val_MinusLogProbMetric: 402.0985

Epoch 236: val_loss did not improve from 397.32947
196/196 - 16s - loss: 396.9991 - MinusLogProbMetric: 396.9991 - val_loss: 402.0985 - val_MinusLogProbMetric: 402.0985 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 237/1000
2023-09-10 05:56:05.101 
Epoch 237/1000 
	 loss: 396.1145, MinusLogProbMetric: 396.1145, val_loss: 398.7491, val_MinusLogProbMetric: 398.7491

Epoch 237: val_loss did not improve from 397.32947
196/196 - 14s - loss: 396.1145 - MinusLogProbMetric: 396.1145 - val_loss: 398.7491 - val_MinusLogProbMetric: 398.7491 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 238/1000
2023-09-10 05:56:20.727 
Epoch 238/1000 
	 loss: 396.7565, MinusLogProbMetric: 396.7565, val_loss: 397.8331, val_MinusLogProbMetric: 397.8331

Epoch 238: val_loss did not improve from 397.32947
196/196 - 16s - loss: 396.7565 - MinusLogProbMetric: 396.7565 - val_loss: 397.8331 - val_MinusLogProbMetric: 397.8331 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 239/1000
2023-09-10 05:56:34.734 
Epoch 239/1000 
	 loss: 396.8788, MinusLogProbMetric: 396.8788, val_loss: 398.2067, val_MinusLogProbMetric: 398.2067

Epoch 239: val_loss did not improve from 397.32947
196/196 - 14s - loss: 396.8788 - MinusLogProbMetric: 396.8788 - val_loss: 398.2067 - val_MinusLogProbMetric: 398.2067 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 240/1000
2023-09-10 05:56:51.495 
Epoch 240/1000 
	 loss: 396.3558, MinusLogProbMetric: 396.3558, val_loss: 415.0750, val_MinusLogProbMetric: 415.0750

Epoch 240: val_loss did not improve from 397.32947
196/196 - 17s - loss: 396.3558 - MinusLogProbMetric: 396.3558 - val_loss: 415.0750 - val_MinusLogProbMetric: 415.0750 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 241/1000
2023-09-10 05:57:06.844 
Epoch 241/1000 
	 loss: 399.9833, MinusLogProbMetric: 399.9833, val_loss: 399.3461, val_MinusLogProbMetric: 399.3461

Epoch 241: val_loss did not improve from 397.32947
196/196 - 15s - loss: 399.9833 - MinusLogProbMetric: 399.9833 - val_loss: 399.3461 - val_MinusLogProbMetric: 399.3461 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 242/1000
2023-09-10 05:57:23.660 
Epoch 242/1000 
	 loss: 396.1049, MinusLogProbMetric: 396.1049, val_loss: 397.5303, val_MinusLogProbMetric: 397.5303

Epoch 242: val_loss did not improve from 397.32947
196/196 - 17s - loss: 396.1049 - MinusLogProbMetric: 396.1049 - val_loss: 397.5303 - val_MinusLogProbMetric: 397.5303 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 243/1000
2023-09-10 05:57:39.403 
Epoch 243/1000 
	 loss: 396.4306, MinusLogProbMetric: 396.4306, val_loss: 398.9906, val_MinusLogProbMetric: 398.9906

Epoch 243: val_loss did not improve from 397.32947
196/196 - 16s - loss: 396.4306 - MinusLogProbMetric: 396.4306 - val_loss: 398.9906 - val_MinusLogProbMetric: 398.9906 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 244/1000
2023-09-10 05:57:56.049 
Epoch 244/1000 
	 loss: 396.4105, MinusLogProbMetric: 396.4105, val_loss: 399.6466, val_MinusLogProbMetric: 399.6466

Epoch 244: val_loss did not improve from 397.32947
196/196 - 17s - loss: 396.4105 - MinusLogProbMetric: 396.4105 - val_loss: 399.6466 - val_MinusLogProbMetric: 399.6466 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 245/1000
2023-09-10 05:58:11.496 
Epoch 245/1000 
	 loss: 396.4569, MinusLogProbMetric: 396.4569, val_loss: 399.6894, val_MinusLogProbMetric: 399.6894

Epoch 245: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.4569 - MinusLogProbMetric: 396.4569 - val_loss: 399.6894 - val_MinusLogProbMetric: 399.6894 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 246/1000
2023-09-10 05:58:26.622 
Epoch 246/1000 
	 loss: 396.2747, MinusLogProbMetric: 396.2747, val_loss: 397.8340, val_MinusLogProbMetric: 397.8340

Epoch 246: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.2747 - MinusLogProbMetric: 396.2747 - val_loss: 397.8340 - val_MinusLogProbMetric: 397.8340 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 247/1000
2023-09-10 05:58:40.796 
Epoch 247/1000 
	 loss: 395.9570, MinusLogProbMetric: 395.9570, val_loss: 398.3344, val_MinusLogProbMetric: 398.3344

Epoch 247: val_loss did not improve from 397.32947
196/196 - 14s - loss: 395.9570 - MinusLogProbMetric: 395.9570 - val_loss: 398.3344 - val_MinusLogProbMetric: 398.3344 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 248/1000
2023-09-10 05:58:56.733 
Epoch 248/1000 
	 loss: 397.2407, MinusLogProbMetric: 397.2407, val_loss: 398.8953, val_MinusLogProbMetric: 398.8953

Epoch 248: val_loss did not improve from 397.32947
196/196 - 16s - loss: 397.2407 - MinusLogProbMetric: 397.2407 - val_loss: 398.8953 - val_MinusLogProbMetric: 398.8953 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 249/1000
2023-09-10 05:59:12.469 
Epoch 249/1000 
	 loss: 396.6161, MinusLogProbMetric: 396.6161, val_loss: 400.2388, val_MinusLogProbMetric: 400.2388

Epoch 249: val_loss did not improve from 397.32947
196/196 - 16s - loss: 396.6161 - MinusLogProbMetric: 396.6161 - val_loss: 400.2388 - val_MinusLogProbMetric: 400.2388 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 250/1000
2023-09-10 05:59:26.983 
Epoch 250/1000 
	 loss: 396.2803, MinusLogProbMetric: 396.2803, val_loss: 397.4159, val_MinusLogProbMetric: 397.4159

Epoch 250: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.2803 - MinusLogProbMetric: 396.2803 - val_loss: 397.4159 - val_MinusLogProbMetric: 397.4159 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 251/1000
2023-09-10 05:59:42.058 
Epoch 251/1000 
	 loss: 396.0117, MinusLogProbMetric: 396.0117, val_loss: 398.2276, val_MinusLogProbMetric: 398.2276

Epoch 251: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.0117 - MinusLogProbMetric: 396.0117 - val_loss: 398.2276 - val_MinusLogProbMetric: 398.2276 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 252/1000
2023-09-10 05:59:55.486 
Epoch 252/1000 
	 loss: 395.9133, MinusLogProbMetric: 395.9133, val_loss: 399.7431, val_MinusLogProbMetric: 399.7431

Epoch 252: val_loss did not improve from 397.32947
196/196 - 13s - loss: 395.9133 - MinusLogProbMetric: 395.9133 - val_loss: 399.7431 - val_MinusLogProbMetric: 399.7431 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 253/1000
2023-09-10 06:00:09.838 
Epoch 253/1000 
	 loss: 407.4179, MinusLogProbMetric: 407.4179, val_loss: 398.7493, val_MinusLogProbMetric: 398.7493

Epoch 253: val_loss did not improve from 397.32947
196/196 - 14s - loss: 407.4179 - MinusLogProbMetric: 407.4179 - val_loss: 398.7493 - val_MinusLogProbMetric: 398.7493 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 254/1000
2023-09-10 06:00:23.775 
Epoch 254/1000 
	 loss: 396.0460, MinusLogProbMetric: 396.0460, val_loss: 398.6808, val_MinusLogProbMetric: 398.6808

Epoch 254: val_loss did not improve from 397.32947
196/196 - 14s - loss: 396.0460 - MinusLogProbMetric: 396.0460 - val_loss: 398.6808 - val_MinusLogProbMetric: 398.6808 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 255/1000
2023-09-10 06:00:38.691 
Epoch 255/1000 
	 loss: 396.6298, MinusLogProbMetric: 396.6298, val_loss: 397.9267, val_MinusLogProbMetric: 397.9267

Epoch 255: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.6298 - MinusLogProbMetric: 396.6298 - val_loss: 397.9267 - val_MinusLogProbMetric: 397.9267 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 256/1000
2023-09-10 06:00:53.272 
Epoch 256/1000 
	 loss: 396.2150, MinusLogProbMetric: 396.2150, val_loss: 401.4666, val_MinusLogProbMetric: 401.4666

Epoch 256: val_loss did not improve from 397.32947
196/196 - 15s - loss: 396.2150 - MinusLogProbMetric: 396.2150 - val_loss: 401.4666 - val_MinusLogProbMetric: 401.4666 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 257/1000
2023-09-10 06:01:07.404 
Epoch 257/1000 
	 loss: 395.9207, MinusLogProbMetric: 395.9207, val_loss: 400.9188, val_MinusLogProbMetric: 400.9188

Epoch 257: val_loss did not improve from 397.32947
196/196 - 14s - loss: 395.9207 - MinusLogProbMetric: 395.9207 - val_loss: 400.9188 - val_MinusLogProbMetric: 400.9188 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 258/1000
2023-09-10 06:01:21.881 
Epoch 258/1000 
	 loss: 395.8435, MinusLogProbMetric: 395.8435, val_loss: 399.6414, val_MinusLogProbMetric: 399.6414

Epoch 258: val_loss did not improve from 397.32947
196/196 - 14s - loss: 395.8435 - MinusLogProbMetric: 395.8435 - val_loss: 399.6414 - val_MinusLogProbMetric: 399.6414 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 259/1000
2023-09-10 06:01:36.445 
Epoch 259/1000 
	 loss: 395.7653, MinusLogProbMetric: 395.7653, val_loss: 397.6474, val_MinusLogProbMetric: 397.6474

Epoch 259: val_loss did not improve from 397.32947
196/196 - 15s - loss: 395.7653 - MinusLogProbMetric: 395.7653 - val_loss: 397.6474 - val_MinusLogProbMetric: 397.6474 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 260/1000
2023-09-10 06:01:51.151 
Epoch 260/1000 
	 loss: 395.9359, MinusLogProbMetric: 395.9359, val_loss: 397.3073, val_MinusLogProbMetric: 397.3073

Epoch 260: val_loss improved from 397.32947 to 397.30728, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 395.9359 - MinusLogProbMetric: 395.9359 - val_loss: 397.3073 - val_MinusLogProbMetric: 397.3073 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 261/1000
2023-09-10 06:02:05.847 
Epoch 261/1000 
	 loss: 395.7728, MinusLogProbMetric: 395.7728, val_loss: 398.6369, val_MinusLogProbMetric: 398.6369

Epoch 261: val_loss did not improve from 397.30728
196/196 - 14s - loss: 395.7728 - MinusLogProbMetric: 395.7728 - val_loss: 398.6369 - val_MinusLogProbMetric: 398.6369 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 262/1000
2023-09-10 06:02:19.220 
Epoch 262/1000 
	 loss: 396.1034, MinusLogProbMetric: 396.1034, val_loss: 398.5848, val_MinusLogProbMetric: 398.5848

Epoch 262: val_loss did not improve from 397.30728
196/196 - 13s - loss: 396.1034 - MinusLogProbMetric: 396.1034 - val_loss: 398.5848 - val_MinusLogProbMetric: 398.5848 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 263/1000
2023-09-10 06:02:34.531 
Epoch 263/1000 
	 loss: 396.8894, MinusLogProbMetric: 396.8894, val_loss: 399.1000, val_MinusLogProbMetric: 399.1000

Epoch 263: val_loss did not improve from 397.30728
196/196 - 15s - loss: 396.8894 - MinusLogProbMetric: 396.8894 - val_loss: 399.1000 - val_MinusLogProbMetric: 399.1000 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 264/1000
2023-09-10 06:02:50.943 
Epoch 264/1000 
	 loss: 396.2964, MinusLogProbMetric: 396.2964, val_loss: 398.2731, val_MinusLogProbMetric: 398.2731

Epoch 264: val_loss did not improve from 397.30728
196/196 - 16s - loss: 396.2964 - MinusLogProbMetric: 396.2964 - val_loss: 398.2731 - val_MinusLogProbMetric: 398.2731 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 265/1000
2023-09-10 06:03:09.167 
Epoch 265/1000 
	 loss: 396.4525, MinusLogProbMetric: 396.4525, val_loss: 402.1451, val_MinusLogProbMetric: 402.1451

Epoch 265: val_loss did not improve from 397.30728
196/196 - 18s - loss: 396.4525 - MinusLogProbMetric: 396.4525 - val_loss: 402.1451 - val_MinusLogProbMetric: 402.1451 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 266/1000
2023-09-10 06:03:24.540 
Epoch 266/1000 
	 loss: 396.1203, MinusLogProbMetric: 396.1203, val_loss: 398.8300, val_MinusLogProbMetric: 398.8300

Epoch 266: val_loss did not improve from 397.30728
196/196 - 15s - loss: 396.1203 - MinusLogProbMetric: 396.1203 - val_loss: 398.8300 - val_MinusLogProbMetric: 398.8300 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 267/1000
2023-09-10 06:03:40.811 
Epoch 267/1000 
	 loss: 395.8732, MinusLogProbMetric: 395.8732, val_loss: 398.9807, val_MinusLogProbMetric: 398.9807

Epoch 267: val_loss did not improve from 397.30728
196/196 - 16s - loss: 395.8732 - MinusLogProbMetric: 395.8732 - val_loss: 398.9807 - val_MinusLogProbMetric: 398.9807 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 268/1000
2023-09-10 06:03:55.914 
Epoch 268/1000 
	 loss: 396.5696, MinusLogProbMetric: 396.5696, val_loss: 397.4730, val_MinusLogProbMetric: 397.4730

Epoch 268: val_loss did not improve from 397.30728
196/196 - 15s - loss: 396.5696 - MinusLogProbMetric: 396.5696 - val_loss: 397.4730 - val_MinusLogProbMetric: 397.4730 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 269/1000
2023-09-10 06:04:13.035 
Epoch 269/1000 
	 loss: 396.4725, MinusLogProbMetric: 396.4725, val_loss: 399.1704, val_MinusLogProbMetric: 399.1704

Epoch 269: val_loss did not improve from 397.30728
196/196 - 17s - loss: 396.4725 - MinusLogProbMetric: 396.4725 - val_loss: 399.1704 - val_MinusLogProbMetric: 399.1704 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 270/1000
2023-09-10 06:04:29.000 
Epoch 270/1000 
	 loss: 395.9480, MinusLogProbMetric: 395.9480, val_loss: 400.5962, val_MinusLogProbMetric: 400.5962

Epoch 270: val_loss did not improve from 397.30728
196/196 - 16s - loss: 395.9480 - MinusLogProbMetric: 395.9480 - val_loss: 400.5962 - val_MinusLogProbMetric: 400.5962 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 271/1000
2023-09-10 06:04:44.172 
Epoch 271/1000 
	 loss: 395.9330, MinusLogProbMetric: 395.9330, val_loss: 398.0128, val_MinusLogProbMetric: 398.0128

Epoch 271: val_loss did not improve from 397.30728
196/196 - 15s - loss: 395.9330 - MinusLogProbMetric: 395.9330 - val_loss: 398.0128 - val_MinusLogProbMetric: 398.0128 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 272/1000
2023-09-10 06:04:59.407 
Epoch 272/1000 
	 loss: 395.5144, MinusLogProbMetric: 395.5144, val_loss: 397.8998, val_MinusLogProbMetric: 397.8998

Epoch 272: val_loss did not improve from 397.30728
196/196 - 15s - loss: 395.5144 - MinusLogProbMetric: 395.5144 - val_loss: 397.8998 - val_MinusLogProbMetric: 397.8998 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 273/1000
2023-09-10 06:05:14.278 
Epoch 273/1000 
	 loss: 395.8499, MinusLogProbMetric: 395.8499, val_loss: 398.2507, val_MinusLogProbMetric: 398.2507

Epoch 273: val_loss did not improve from 397.30728
196/196 - 15s - loss: 395.8499 - MinusLogProbMetric: 395.8499 - val_loss: 398.2507 - val_MinusLogProbMetric: 398.2507 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 274/1000
2023-09-10 06:05:30.173 
Epoch 274/1000 
	 loss: 396.0731, MinusLogProbMetric: 396.0731, val_loss: 397.4601, val_MinusLogProbMetric: 397.4601

Epoch 274: val_loss did not improve from 397.30728
196/196 - 16s - loss: 396.0731 - MinusLogProbMetric: 396.0731 - val_loss: 397.4601 - val_MinusLogProbMetric: 397.4601 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 275/1000
2023-09-10 06:05:46.965 
Epoch 275/1000 
	 loss: 396.8829, MinusLogProbMetric: 396.8829, val_loss: 396.4027, val_MinusLogProbMetric: 396.4027

Epoch 275: val_loss improved from 397.30728 to 396.40268, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 17s - loss: 396.8829 - MinusLogProbMetric: 396.8829 - val_loss: 396.4027 - val_MinusLogProbMetric: 396.4027 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 276/1000
2023-09-10 06:06:08.129 
Epoch 276/1000 
	 loss: 395.9703, MinusLogProbMetric: 395.9703, val_loss: 399.1785, val_MinusLogProbMetric: 399.1785

Epoch 276: val_loss did not improve from 396.40268
196/196 - 21s - loss: 395.9703 - MinusLogProbMetric: 395.9703 - val_loss: 399.1785 - val_MinusLogProbMetric: 399.1785 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 277/1000
2023-09-10 06:06:23.523 
Epoch 277/1000 
	 loss: 395.7648, MinusLogProbMetric: 395.7648, val_loss: 398.9018, val_MinusLogProbMetric: 398.9018

Epoch 277: val_loss did not improve from 396.40268
196/196 - 15s - loss: 395.7648 - MinusLogProbMetric: 395.7648 - val_loss: 398.9018 - val_MinusLogProbMetric: 398.9018 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 278/1000
2023-09-10 06:06:37.281 
Epoch 278/1000 
	 loss: 395.8217, MinusLogProbMetric: 395.8217, val_loss: 397.6486, val_MinusLogProbMetric: 397.6486

Epoch 278: val_loss did not improve from 396.40268
196/196 - 14s - loss: 395.8217 - MinusLogProbMetric: 395.8217 - val_loss: 397.6486 - val_MinusLogProbMetric: 397.6486 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 279/1000
2023-09-10 06:06:50.967 
Epoch 279/1000 
	 loss: 395.4542, MinusLogProbMetric: 395.4542, val_loss: 397.3833, val_MinusLogProbMetric: 397.3833

Epoch 279: val_loss did not improve from 396.40268
196/196 - 14s - loss: 395.4542 - MinusLogProbMetric: 395.4542 - val_loss: 397.3833 - val_MinusLogProbMetric: 397.3833 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 280/1000
2023-09-10 06:07:03.692 
Epoch 280/1000 
	 loss: 871.4116, MinusLogProbMetric: 871.4116, val_loss: 512.0829, val_MinusLogProbMetric: 512.0829

Epoch 280: val_loss did not improve from 396.40268
196/196 - 13s - loss: 871.4116 - MinusLogProbMetric: 871.4116 - val_loss: 512.0829 - val_MinusLogProbMetric: 512.0829 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 281/1000
2023-09-10 06:07:17.614 
Epoch 281/1000 
	 loss: 457.2213, MinusLogProbMetric: 457.2213, val_loss: 437.0385, val_MinusLogProbMetric: 437.0385

Epoch 281: val_loss did not improve from 396.40268
196/196 - 14s - loss: 457.2213 - MinusLogProbMetric: 457.2213 - val_loss: 437.0385 - val_MinusLogProbMetric: 437.0385 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 282/1000
2023-09-10 06:07:32.987 
Epoch 282/1000 
	 loss: 429.9770, MinusLogProbMetric: 429.9770, val_loss: 426.1256, val_MinusLogProbMetric: 426.1256

Epoch 282: val_loss did not improve from 396.40268
196/196 - 15s - loss: 429.9770 - MinusLogProbMetric: 429.9770 - val_loss: 426.1256 - val_MinusLogProbMetric: 426.1256 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 283/1000
2023-09-10 06:07:49.859 
Epoch 283/1000 
	 loss: 421.8811, MinusLogProbMetric: 421.8811, val_loss: 420.5842, val_MinusLogProbMetric: 420.5842

Epoch 283: val_loss did not improve from 396.40268
196/196 - 17s - loss: 421.8811 - MinusLogProbMetric: 421.8811 - val_loss: 420.5842 - val_MinusLogProbMetric: 420.5842 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 284/1000
2023-09-10 06:08:06.310 
Epoch 284/1000 
	 loss: 417.4022, MinusLogProbMetric: 417.4022, val_loss: 418.8461, val_MinusLogProbMetric: 418.8461

Epoch 284: val_loss did not improve from 396.40268
196/196 - 16s - loss: 417.4022 - MinusLogProbMetric: 417.4022 - val_loss: 418.8461 - val_MinusLogProbMetric: 418.8461 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 285/1000
2023-09-10 06:08:24.199 
Epoch 285/1000 
	 loss: 414.3494, MinusLogProbMetric: 414.3494, val_loss: 416.8707, val_MinusLogProbMetric: 416.8707

Epoch 285: val_loss did not improve from 396.40268
196/196 - 18s - loss: 414.3494 - MinusLogProbMetric: 414.3494 - val_loss: 416.8707 - val_MinusLogProbMetric: 416.8707 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 286/1000
2023-09-10 06:08:40.740 
Epoch 286/1000 
	 loss: 412.1278, MinusLogProbMetric: 412.1278, val_loss: 413.1690, val_MinusLogProbMetric: 413.1690

Epoch 286: val_loss did not improve from 396.40268
196/196 - 17s - loss: 412.1278 - MinusLogProbMetric: 412.1278 - val_loss: 413.1690 - val_MinusLogProbMetric: 413.1690 - lr: 3.3333e-04 - 17s/epoch - 84ms/step
Epoch 287/1000
2023-09-10 06:08:57.515 
Epoch 287/1000 
	 loss: 410.3294, MinusLogProbMetric: 410.3294, val_loss: 410.8572, val_MinusLogProbMetric: 410.8572

Epoch 287: val_loss did not improve from 396.40268
196/196 - 17s - loss: 410.3294 - MinusLogProbMetric: 410.3294 - val_loss: 410.8572 - val_MinusLogProbMetric: 410.8572 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 288/1000
2023-09-10 06:09:13.103 
Epoch 288/1000 
	 loss: 408.9265, MinusLogProbMetric: 408.9265, val_loss: 410.1512, val_MinusLogProbMetric: 410.1512

Epoch 288: val_loss did not improve from 396.40268
196/196 - 16s - loss: 408.9265 - MinusLogProbMetric: 408.9265 - val_loss: 410.1512 - val_MinusLogProbMetric: 410.1512 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 289/1000
2023-09-10 06:09:27.869 
Epoch 289/1000 
	 loss: 407.6698, MinusLogProbMetric: 407.6698, val_loss: 408.2330, val_MinusLogProbMetric: 408.2330

Epoch 289: val_loss did not improve from 396.40268
196/196 - 15s - loss: 407.6698 - MinusLogProbMetric: 407.6698 - val_loss: 408.2330 - val_MinusLogProbMetric: 408.2330 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 290/1000
2023-09-10 06:09:43.387 
Epoch 290/1000 
	 loss: 406.3946, MinusLogProbMetric: 406.3946, val_loss: 408.1592, val_MinusLogProbMetric: 408.1592

Epoch 290: val_loss did not improve from 396.40268
196/196 - 16s - loss: 406.3946 - MinusLogProbMetric: 406.3946 - val_loss: 408.1592 - val_MinusLogProbMetric: 408.1592 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 291/1000
2023-09-10 06:09:58.440 
Epoch 291/1000 
	 loss: 405.6266, MinusLogProbMetric: 405.6266, val_loss: 406.9921, val_MinusLogProbMetric: 406.9921

Epoch 291: val_loss did not improve from 396.40268
196/196 - 15s - loss: 405.6266 - MinusLogProbMetric: 405.6266 - val_loss: 406.9921 - val_MinusLogProbMetric: 406.9921 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 292/1000
2023-09-10 06:10:14.578 
Epoch 292/1000 
	 loss: 404.9170, MinusLogProbMetric: 404.9170, val_loss: 407.5821, val_MinusLogProbMetric: 407.5821

Epoch 292: val_loss did not improve from 396.40268
196/196 - 16s - loss: 404.9170 - MinusLogProbMetric: 404.9170 - val_loss: 407.5821 - val_MinusLogProbMetric: 407.5821 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 293/1000
2023-09-10 06:10:31.292 
Epoch 293/1000 
	 loss: 404.4830, MinusLogProbMetric: 404.4830, val_loss: 407.0860, val_MinusLogProbMetric: 407.0860

Epoch 293: val_loss did not improve from 396.40268
196/196 - 17s - loss: 404.4830 - MinusLogProbMetric: 404.4830 - val_loss: 407.0860 - val_MinusLogProbMetric: 407.0860 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 294/1000
2023-09-10 06:10:46.134 
Epoch 294/1000 
	 loss: 403.8150, MinusLogProbMetric: 403.8150, val_loss: 406.9141, val_MinusLogProbMetric: 406.9141

Epoch 294: val_loss did not improve from 396.40268
196/196 - 15s - loss: 403.8150 - MinusLogProbMetric: 403.8150 - val_loss: 406.9141 - val_MinusLogProbMetric: 406.9141 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 295/1000
2023-09-10 06:11:01.288 
Epoch 295/1000 
	 loss: 403.3770, MinusLogProbMetric: 403.3770, val_loss: 404.6230, val_MinusLogProbMetric: 404.6230

Epoch 295: val_loss did not improve from 396.40268
196/196 - 15s - loss: 403.3770 - MinusLogProbMetric: 403.3770 - val_loss: 404.6230 - val_MinusLogProbMetric: 404.6230 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 296/1000
2023-09-10 06:11:14.839 
Epoch 296/1000 
	 loss: 402.7183, MinusLogProbMetric: 402.7183, val_loss: 403.9747, val_MinusLogProbMetric: 403.9747

Epoch 296: val_loss did not improve from 396.40268
196/196 - 14s - loss: 402.7183 - MinusLogProbMetric: 402.7183 - val_loss: 403.9747 - val_MinusLogProbMetric: 403.9747 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 297/1000
2023-09-10 06:11:29.123 
Epoch 297/1000 
	 loss: 402.2599, MinusLogProbMetric: 402.2599, val_loss: 403.5770, val_MinusLogProbMetric: 403.5770

Epoch 297: val_loss did not improve from 396.40268
196/196 - 14s - loss: 402.2599 - MinusLogProbMetric: 402.2599 - val_loss: 403.5770 - val_MinusLogProbMetric: 403.5770 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 298/1000
2023-09-10 06:11:43.602 
Epoch 298/1000 
	 loss: 402.1120, MinusLogProbMetric: 402.1120, val_loss: 402.8727, val_MinusLogProbMetric: 402.8727

Epoch 298: val_loss did not improve from 396.40268
196/196 - 14s - loss: 402.1120 - MinusLogProbMetric: 402.1120 - val_loss: 402.8727 - val_MinusLogProbMetric: 402.8727 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 299/1000
2023-09-10 06:11:58.248 
Epoch 299/1000 
	 loss: 401.7766, MinusLogProbMetric: 401.7766, val_loss: 402.4548, val_MinusLogProbMetric: 402.4548

Epoch 299: val_loss did not improve from 396.40268
196/196 - 15s - loss: 401.7766 - MinusLogProbMetric: 401.7766 - val_loss: 402.4548 - val_MinusLogProbMetric: 402.4548 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 300/1000
2023-09-10 06:12:12.215 
Epoch 300/1000 
	 loss: 401.2256, MinusLogProbMetric: 401.2256, val_loss: 403.7984, val_MinusLogProbMetric: 403.7984

Epoch 300: val_loss did not improve from 396.40268
196/196 - 14s - loss: 401.2256 - MinusLogProbMetric: 401.2256 - val_loss: 403.7984 - val_MinusLogProbMetric: 403.7984 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 301/1000
2023-09-10 06:12:27.463 
Epoch 301/1000 
	 loss: 401.0398, MinusLogProbMetric: 401.0398, val_loss: 403.5482, val_MinusLogProbMetric: 403.5482

Epoch 301: val_loss did not improve from 396.40268
196/196 - 15s - loss: 401.0398 - MinusLogProbMetric: 401.0398 - val_loss: 403.5482 - val_MinusLogProbMetric: 403.5482 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 302/1000
2023-09-10 06:12:43.181 
Epoch 302/1000 
	 loss: 400.9025, MinusLogProbMetric: 400.9025, val_loss: 402.6449, val_MinusLogProbMetric: 402.6449

Epoch 302: val_loss did not improve from 396.40268
196/196 - 16s - loss: 400.9025 - MinusLogProbMetric: 400.9025 - val_loss: 402.6449 - val_MinusLogProbMetric: 402.6449 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 303/1000
2023-09-10 06:12:57.706 
Epoch 303/1000 
	 loss: 400.7473, MinusLogProbMetric: 400.7473, val_loss: 402.8496, val_MinusLogProbMetric: 402.8496

Epoch 303: val_loss did not improve from 396.40268
196/196 - 15s - loss: 400.7473 - MinusLogProbMetric: 400.7473 - val_loss: 402.8496 - val_MinusLogProbMetric: 402.8496 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 304/1000
2023-09-10 06:13:11.354 
Epoch 304/1000 
	 loss: 400.2460, MinusLogProbMetric: 400.2460, val_loss: 402.2088, val_MinusLogProbMetric: 402.2088

Epoch 304: val_loss did not improve from 396.40268
196/196 - 14s - loss: 400.2460 - MinusLogProbMetric: 400.2460 - val_loss: 402.2088 - val_MinusLogProbMetric: 402.2088 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 305/1000
2023-09-10 06:13:24.861 
Epoch 305/1000 
	 loss: 400.3010, MinusLogProbMetric: 400.3010, val_loss: 403.4837, val_MinusLogProbMetric: 403.4837

Epoch 305: val_loss did not improve from 396.40268
196/196 - 13s - loss: 400.3010 - MinusLogProbMetric: 400.3010 - val_loss: 403.4837 - val_MinusLogProbMetric: 403.4837 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 306/1000
2023-09-10 06:13:39.709 
Epoch 306/1000 
	 loss: 400.0633, MinusLogProbMetric: 400.0633, val_loss: 402.9062, val_MinusLogProbMetric: 402.9062

Epoch 306: val_loss did not improve from 396.40268
196/196 - 15s - loss: 400.0633 - MinusLogProbMetric: 400.0633 - val_loss: 402.9062 - val_MinusLogProbMetric: 402.9062 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 307/1000
2023-09-10 06:13:57.399 
Epoch 307/1000 
	 loss: 399.7291, MinusLogProbMetric: 399.7291, val_loss: 402.8358, val_MinusLogProbMetric: 402.8358

Epoch 307: val_loss did not improve from 396.40268
196/196 - 18s - loss: 399.7291 - MinusLogProbMetric: 399.7291 - val_loss: 402.8358 - val_MinusLogProbMetric: 402.8358 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 308/1000
2023-09-10 06:14:13.602 
Epoch 308/1000 
	 loss: 399.5363, MinusLogProbMetric: 399.5363, val_loss: 400.7730, val_MinusLogProbMetric: 400.7730

Epoch 308: val_loss did not improve from 396.40268
196/196 - 16s - loss: 399.5363 - MinusLogProbMetric: 399.5363 - val_loss: 400.7730 - val_MinusLogProbMetric: 400.7730 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 309/1000
2023-09-10 06:14:30.413 
Epoch 309/1000 
	 loss: 399.4221, MinusLogProbMetric: 399.4221, val_loss: 404.5091, val_MinusLogProbMetric: 404.5091

Epoch 309: val_loss did not improve from 396.40268
196/196 - 17s - loss: 399.4221 - MinusLogProbMetric: 399.4221 - val_loss: 404.5091 - val_MinusLogProbMetric: 404.5091 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 310/1000
2023-09-10 06:14:46.871 
Epoch 310/1000 
	 loss: 399.3732, MinusLogProbMetric: 399.3732, val_loss: 400.4876, val_MinusLogProbMetric: 400.4876

Epoch 310: val_loss did not improve from 396.40268
196/196 - 16s - loss: 399.3732 - MinusLogProbMetric: 399.3732 - val_loss: 400.4876 - val_MinusLogProbMetric: 400.4876 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 311/1000
2023-09-10 06:15:03.256 
Epoch 311/1000 
	 loss: 399.2543, MinusLogProbMetric: 399.2543, val_loss: 400.3525, val_MinusLogProbMetric: 400.3525

Epoch 311: val_loss did not improve from 396.40268
196/196 - 16s - loss: 399.2543 - MinusLogProbMetric: 399.2543 - val_loss: 400.3525 - val_MinusLogProbMetric: 400.3525 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 312/1000
2023-09-10 06:15:19.128 
Epoch 312/1000 
	 loss: 399.1247, MinusLogProbMetric: 399.1247, val_loss: 400.5271, val_MinusLogProbMetric: 400.5271

Epoch 312: val_loss did not improve from 396.40268
196/196 - 16s - loss: 399.1247 - MinusLogProbMetric: 399.1247 - val_loss: 400.5271 - val_MinusLogProbMetric: 400.5271 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 313/1000
2023-09-10 06:15:33.608 
Epoch 313/1000 
	 loss: 398.8757, MinusLogProbMetric: 398.8757, val_loss: 400.8766, val_MinusLogProbMetric: 400.8766

Epoch 313: val_loss did not improve from 396.40268
196/196 - 14s - loss: 398.8757 - MinusLogProbMetric: 398.8757 - val_loss: 400.8766 - val_MinusLogProbMetric: 400.8766 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 314/1000
2023-09-10 06:15:48.796 
Epoch 314/1000 
	 loss: 398.8885, MinusLogProbMetric: 398.8885, val_loss: 400.6519, val_MinusLogProbMetric: 400.6519

Epoch 314: val_loss did not improve from 396.40268
196/196 - 15s - loss: 398.8885 - MinusLogProbMetric: 398.8885 - val_loss: 400.6519 - val_MinusLogProbMetric: 400.6519 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 315/1000
2023-09-10 06:16:04.015 
Epoch 315/1000 
	 loss: 398.5165, MinusLogProbMetric: 398.5165, val_loss: 400.1419, val_MinusLogProbMetric: 400.1419

Epoch 315: val_loss did not improve from 396.40268
196/196 - 15s - loss: 398.5165 - MinusLogProbMetric: 398.5165 - val_loss: 400.1419 - val_MinusLogProbMetric: 400.1419 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 316/1000
2023-09-10 06:16:18.765 
Epoch 316/1000 
	 loss: 398.6241, MinusLogProbMetric: 398.6241, val_loss: 408.1171, val_MinusLogProbMetric: 408.1171

Epoch 316: val_loss did not improve from 396.40268
196/196 - 15s - loss: 398.6241 - MinusLogProbMetric: 398.6241 - val_loss: 408.1171 - val_MinusLogProbMetric: 408.1171 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 317/1000
2023-09-10 06:16:33.854 
Epoch 317/1000 
	 loss: 398.3808, MinusLogProbMetric: 398.3808, val_loss: 401.7355, val_MinusLogProbMetric: 401.7355

Epoch 317: val_loss did not improve from 396.40268
196/196 - 15s - loss: 398.3808 - MinusLogProbMetric: 398.3808 - val_loss: 401.7355 - val_MinusLogProbMetric: 401.7355 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 318/1000
2023-09-10 06:16:51.139 
Epoch 318/1000 
	 loss: 398.5614, MinusLogProbMetric: 398.5614, val_loss: 399.8294, val_MinusLogProbMetric: 399.8294

Epoch 318: val_loss did not improve from 396.40268
196/196 - 17s - loss: 398.5614 - MinusLogProbMetric: 398.5614 - val_loss: 399.8294 - val_MinusLogProbMetric: 399.8294 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 319/1000
2023-09-10 06:17:08.556 
Epoch 319/1000 
	 loss: 398.3377, MinusLogProbMetric: 398.3377, val_loss: 400.5075, val_MinusLogProbMetric: 400.5075

Epoch 319: val_loss did not improve from 396.40268
196/196 - 17s - loss: 398.3377 - MinusLogProbMetric: 398.3377 - val_loss: 400.5075 - val_MinusLogProbMetric: 400.5075 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 320/1000
2023-09-10 06:17:24.463 
Epoch 320/1000 
	 loss: 397.8857, MinusLogProbMetric: 397.8857, val_loss: 402.8371, val_MinusLogProbMetric: 402.8371

Epoch 320: val_loss did not improve from 396.40268
196/196 - 16s - loss: 397.8857 - MinusLogProbMetric: 397.8857 - val_loss: 402.8371 - val_MinusLogProbMetric: 402.8371 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 321/1000
2023-09-10 06:17:41.000 
Epoch 321/1000 
	 loss: 398.0192, MinusLogProbMetric: 398.0192, val_loss: 399.5046, val_MinusLogProbMetric: 399.5046

Epoch 321: val_loss did not improve from 396.40268
196/196 - 17s - loss: 398.0192 - MinusLogProbMetric: 398.0192 - val_loss: 399.5046 - val_MinusLogProbMetric: 399.5046 - lr: 3.3333e-04 - 17s/epoch - 84ms/step
Epoch 322/1000
2023-09-10 06:17:58.743 
Epoch 322/1000 
	 loss: 398.1724, MinusLogProbMetric: 398.1724, val_loss: 399.3162, val_MinusLogProbMetric: 399.3162

Epoch 322: val_loss did not improve from 396.40268
196/196 - 18s - loss: 398.1724 - MinusLogProbMetric: 398.1724 - val_loss: 399.3162 - val_MinusLogProbMetric: 399.3162 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 323/1000
2023-09-10 06:18:12.986 
Epoch 323/1000 
	 loss: 397.7301, MinusLogProbMetric: 397.7301, val_loss: 399.0169, val_MinusLogProbMetric: 399.0169

Epoch 323: val_loss did not improve from 396.40268
196/196 - 14s - loss: 397.7301 - MinusLogProbMetric: 397.7301 - val_loss: 399.0169 - val_MinusLogProbMetric: 399.0169 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 324/1000
2023-09-10 06:18:29.505 
Epoch 324/1000 
	 loss: 397.6006, MinusLogProbMetric: 397.6006, val_loss: 399.4737, val_MinusLogProbMetric: 399.4737

Epoch 324: val_loss did not improve from 396.40268
196/196 - 17s - loss: 397.6006 - MinusLogProbMetric: 397.6006 - val_loss: 399.4737 - val_MinusLogProbMetric: 399.4737 - lr: 3.3333e-04 - 17s/epoch - 84ms/step
Epoch 325/1000
2023-09-10 06:18:45.241 
Epoch 325/1000 
	 loss: 397.8217, MinusLogProbMetric: 397.8217, val_loss: 400.0280, val_MinusLogProbMetric: 400.0280

Epoch 325: val_loss did not improve from 396.40268
196/196 - 16s - loss: 397.8217 - MinusLogProbMetric: 397.8217 - val_loss: 400.0280 - val_MinusLogProbMetric: 400.0280 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 326/1000
2023-09-10 06:19:01.688 
Epoch 326/1000 
	 loss: 394.6532, MinusLogProbMetric: 394.6532, val_loss: 396.5494, val_MinusLogProbMetric: 396.5494

Epoch 326: val_loss did not improve from 396.40268
196/196 - 16s - loss: 394.6532 - MinusLogProbMetric: 394.6532 - val_loss: 396.5494 - val_MinusLogProbMetric: 396.5494 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 327/1000
2023-09-10 06:19:17.087 
Epoch 327/1000 
	 loss: 394.4859, MinusLogProbMetric: 394.4859, val_loss: 396.5603, val_MinusLogProbMetric: 396.5603

Epoch 327: val_loss did not improve from 396.40268
196/196 - 15s - loss: 394.4859 - MinusLogProbMetric: 394.4859 - val_loss: 396.5603 - val_MinusLogProbMetric: 396.5603 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 328/1000
2023-09-10 06:19:33.171 
Epoch 328/1000 
	 loss: 394.6200, MinusLogProbMetric: 394.6200, val_loss: 396.6933, val_MinusLogProbMetric: 396.6933

Epoch 328: val_loss did not improve from 396.40268
196/196 - 16s - loss: 394.6200 - MinusLogProbMetric: 394.6200 - val_loss: 396.6933 - val_MinusLogProbMetric: 396.6933 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 329/1000
2023-09-10 06:19:49.590 
Epoch 329/1000 
	 loss: 394.4267, MinusLogProbMetric: 394.4267, val_loss: 396.2908, val_MinusLogProbMetric: 396.2908

Epoch 329: val_loss improved from 396.40268 to 396.29080, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 17s - loss: 394.4267 - MinusLogProbMetric: 394.4267 - val_loss: 396.2908 - val_MinusLogProbMetric: 396.2908 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 330/1000
2023-09-10 06:20:05.782 
Epoch 330/1000 
	 loss: 394.6385, MinusLogProbMetric: 394.6385, val_loss: 397.0309, val_MinusLogProbMetric: 397.0309

Epoch 330: val_loss did not improve from 396.29080
196/196 - 16s - loss: 394.6385 - MinusLogProbMetric: 394.6385 - val_loss: 397.0309 - val_MinusLogProbMetric: 397.0309 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 331/1000
2023-09-10 06:20:20.116 
Epoch 331/1000 
	 loss: 394.4884, MinusLogProbMetric: 394.4884, val_loss: 396.6974, val_MinusLogProbMetric: 396.6974

Epoch 331: val_loss did not improve from 396.29080
196/196 - 14s - loss: 394.4884 - MinusLogProbMetric: 394.4884 - val_loss: 396.6974 - val_MinusLogProbMetric: 396.6974 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 332/1000
2023-09-10 06:20:37.197 
Epoch 332/1000 
	 loss: 394.7471, MinusLogProbMetric: 394.7471, val_loss: 397.4426, val_MinusLogProbMetric: 397.4426

Epoch 332: val_loss did not improve from 396.29080
196/196 - 17s - loss: 394.7471 - MinusLogProbMetric: 394.7471 - val_loss: 397.4426 - val_MinusLogProbMetric: 397.4426 - lr: 1.6667e-04 - 17s/epoch - 87ms/step
Epoch 333/1000
2023-09-10 06:20:51.625 
Epoch 333/1000 
	 loss: 394.5044, MinusLogProbMetric: 394.5044, val_loss: 398.4506, val_MinusLogProbMetric: 398.4506

Epoch 333: val_loss did not improve from 396.29080
196/196 - 14s - loss: 394.5044 - MinusLogProbMetric: 394.5044 - val_loss: 398.4506 - val_MinusLogProbMetric: 398.4506 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 334/1000
2023-09-10 06:21:06.043 
Epoch 334/1000 
	 loss: 394.3078, MinusLogProbMetric: 394.3078, val_loss: 396.8932, val_MinusLogProbMetric: 396.8932

Epoch 334: val_loss did not improve from 396.29080
196/196 - 14s - loss: 394.3078 - MinusLogProbMetric: 394.3078 - val_loss: 396.8932 - val_MinusLogProbMetric: 396.8932 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 335/1000
2023-09-10 06:21:21.347 
Epoch 335/1000 
	 loss: 394.5262, MinusLogProbMetric: 394.5262, val_loss: 396.3344, val_MinusLogProbMetric: 396.3344

Epoch 335: val_loss did not improve from 396.29080
196/196 - 15s - loss: 394.5262 - MinusLogProbMetric: 394.5262 - val_loss: 396.3344 - val_MinusLogProbMetric: 396.3344 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 336/1000
2023-09-10 06:21:36.387 
Epoch 336/1000 
	 loss: 394.3212, MinusLogProbMetric: 394.3212, val_loss: 396.7146, val_MinusLogProbMetric: 396.7146

Epoch 336: val_loss did not improve from 396.29080
196/196 - 15s - loss: 394.3212 - MinusLogProbMetric: 394.3212 - val_loss: 396.7146 - val_MinusLogProbMetric: 396.7146 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 337/1000
2023-09-10 06:21:51.282 
Epoch 337/1000 
	 loss: 394.3766, MinusLogProbMetric: 394.3766, val_loss: 397.2092, val_MinusLogProbMetric: 397.2092

Epoch 337: val_loss did not improve from 396.29080
196/196 - 15s - loss: 394.3766 - MinusLogProbMetric: 394.3766 - val_loss: 397.2092 - val_MinusLogProbMetric: 397.2092 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 338/1000
2023-09-10 06:22:05.180 
Epoch 338/1000 
	 loss: 394.2715, MinusLogProbMetric: 394.2715, val_loss: 396.2225, val_MinusLogProbMetric: 396.2225

Epoch 338: val_loss improved from 396.29080 to 396.22250, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 394.2715 - MinusLogProbMetric: 394.2715 - val_loss: 396.2225 - val_MinusLogProbMetric: 396.2225 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 339/1000
2023-09-10 06:22:20.541 
Epoch 339/1000 
	 loss: 394.1233, MinusLogProbMetric: 394.1233, val_loss: 397.8747, val_MinusLogProbMetric: 397.8747

Epoch 339: val_loss did not improve from 396.22250
196/196 - 15s - loss: 394.1233 - MinusLogProbMetric: 394.1233 - val_loss: 397.8747 - val_MinusLogProbMetric: 397.8747 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 340/1000
2023-09-10 06:22:35.722 
Epoch 340/1000 
	 loss: 394.2344, MinusLogProbMetric: 394.2344, val_loss: 396.2839, val_MinusLogProbMetric: 396.2839

Epoch 340: val_loss did not improve from 396.22250
196/196 - 15s - loss: 394.2344 - MinusLogProbMetric: 394.2344 - val_loss: 396.2839 - val_MinusLogProbMetric: 396.2839 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 341/1000
2023-09-10 06:22:49.617 
Epoch 341/1000 
	 loss: 394.2085, MinusLogProbMetric: 394.2085, val_loss: 396.8989, val_MinusLogProbMetric: 396.8989

Epoch 341: val_loss did not improve from 396.22250
196/196 - 14s - loss: 394.2085 - MinusLogProbMetric: 394.2085 - val_loss: 396.8989 - val_MinusLogProbMetric: 396.8989 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 342/1000
2023-09-10 06:23:03.365 
Epoch 342/1000 
	 loss: 394.2516, MinusLogProbMetric: 394.2516, val_loss: 396.8749, val_MinusLogProbMetric: 396.8749

Epoch 342: val_loss did not improve from 396.22250
196/196 - 14s - loss: 394.2516 - MinusLogProbMetric: 394.2516 - val_loss: 396.8749 - val_MinusLogProbMetric: 396.8749 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 343/1000
2023-09-10 06:23:17.268 
Epoch 343/1000 
	 loss: 394.0597, MinusLogProbMetric: 394.0597, val_loss: 396.9675, val_MinusLogProbMetric: 396.9675

Epoch 343: val_loss did not improve from 396.22250
196/196 - 14s - loss: 394.0597 - MinusLogProbMetric: 394.0597 - val_loss: 396.9675 - val_MinusLogProbMetric: 396.9675 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 344/1000
2023-09-10 06:23:31.885 
Epoch 344/1000 
	 loss: 394.1802, MinusLogProbMetric: 394.1802, val_loss: 395.5652, val_MinusLogProbMetric: 395.5652

Epoch 344: val_loss improved from 396.22250 to 395.56525, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 394.1802 - MinusLogProbMetric: 394.1802 - val_loss: 395.5652 - val_MinusLogProbMetric: 395.5652 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 345/1000
2023-09-10 06:23:45.908 
Epoch 345/1000 
	 loss: 393.7677, MinusLogProbMetric: 393.7677, val_loss: 396.4439, val_MinusLogProbMetric: 396.4439

Epoch 345: val_loss did not improve from 395.56525
196/196 - 13s - loss: 393.7677 - MinusLogProbMetric: 393.7677 - val_loss: 396.4439 - val_MinusLogProbMetric: 396.4439 - lr: 1.6667e-04 - 13s/epoch - 69ms/step
Epoch 346/1000
2023-09-10 06:24:01.843 
Epoch 346/1000 
	 loss: 394.0465, MinusLogProbMetric: 394.0465, val_loss: 396.9899, val_MinusLogProbMetric: 396.9899

Epoch 346: val_loss did not improve from 395.56525
196/196 - 16s - loss: 394.0465 - MinusLogProbMetric: 394.0465 - val_loss: 396.9899 - val_MinusLogProbMetric: 396.9899 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 347/1000
2023-09-10 06:24:18.594 
Epoch 347/1000 
	 loss: 393.9009, MinusLogProbMetric: 393.9009, val_loss: 396.3065, val_MinusLogProbMetric: 396.3065

Epoch 347: val_loss did not improve from 395.56525
196/196 - 17s - loss: 393.9009 - MinusLogProbMetric: 393.9009 - val_loss: 396.3065 - val_MinusLogProbMetric: 396.3065 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 348/1000
2023-09-10 06:24:35.001 
Epoch 348/1000 
	 loss: 393.9810, MinusLogProbMetric: 393.9810, val_loss: 395.3899, val_MinusLogProbMetric: 395.3899

Epoch 348: val_loss improved from 395.56525 to 395.38992, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 17s - loss: 393.9810 - MinusLogProbMetric: 393.9810 - val_loss: 395.3899 - val_MinusLogProbMetric: 395.3899 - lr: 1.6667e-04 - 17s/epoch - 87ms/step
Epoch 349/1000
2023-09-10 06:24:49.921 
Epoch 349/1000 
	 loss: 393.5914, MinusLogProbMetric: 393.5914, val_loss: 395.5878, val_MinusLogProbMetric: 395.5878

Epoch 349: val_loss did not improve from 395.38992
196/196 - 14s - loss: 393.5914 - MinusLogProbMetric: 393.5914 - val_loss: 395.5878 - val_MinusLogProbMetric: 395.5878 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 350/1000
2023-09-10 06:25:04.408 
Epoch 350/1000 
	 loss: 394.0309, MinusLogProbMetric: 394.0309, val_loss: 396.6442, val_MinusLogProbMetric: 396.6442

Epoch 350: val_loss did not improve from 395.38992
196/196 - 14s - loss: 394.0309 - MinusLogProbMetric: 394.0309 - val_loss: 396.6442 - val_MinusLogProbMetric: 396.6442 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 351/1000
2023-09-10 06:25:18.615 
Epoch 351/1000 
	 loss: 393.9541, MinusLogProbMetric: 393.9541, val_loss: 396.0036, val_MinusLogProbMetric: 396.0036

Epoch 351: val_loss did not improve from 395.38992
196/196 - 14s - loss: 393.9541 - MinusLogProbMetric: 393.9541 - val_loss: 396.0036 - val_MinusLogProbMetric: 396.0036 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 352/1000
2023-09-10 06:25:32.745 
Epoch 352/1000 
	 loss: 393.8461, MinusLogProbMetric: 393.8461, val_loss: 396.1251, val_MinusLogProbMetric: 396.1251

Epoch 352: val_loss did not improve from 395.38992
196/196 - 14s - loss: 393.8461 - MinusLogProbMetric: 393.8461 - val_loss: 396.1251 - val_MinusLogProbMetric: 396.1251 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 353/1000
2023-09-10 06:25:46.144 
Epoch 353/1000 
	 loss: 393.5865, MinusLogProbMetric: 393.5865, val_loss: 395.8240, val_MinusLogProbMetric: 395.8240

Epoch 353: val_loss did not improve from 395.38992
196/196 - 13s - loss: 393.5865 - MinusLogProbMetric: 393.5865 - val_loss: 395.8240 - val_MinusLogProbMetric: 395.8240 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 354/1000
2023-09-10 06:26:00.396 
Epoch 354/1000 
	 loss: 393.8194, MinusLogProbMetric: 393.8194, val_loss: 395.7397, val_MinusLogProbMetric: 395.7397

Epoch 354: val_loss did not improve from 395.38992
196/196 - 14s - loss: 393.8194 - MinusLogProbMetric: 393.8194 - val_loss: 395.7397 - val_MinusLogProbMetric: 395.7397 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 355/1000
2023-09-10 06:26:14.659 
Epoch 355/1000 
	 loss: 393.6419, MinusLogProbMetric: 393.6419, val_loss: 398.1076, val_MinusLogProbMetric: 398.1076

Epoch 355: val_loss did not improve from 395.38992
196/196 - 14s - loss: 393.6419 - MinusLogProbMetric: 393.6419 - val_loss: 398.1076 - val_MinusLogProbMetric: 398.1076 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 356/1000
2023-09-10 06:26:29.878 
Epoch 356/1000 
	 loss: 393.7946, MinusLogProbMetric: 393.7946, val_loss: 395.8280, val_MinusLogProbMetric: 395.8280

Epoch 356: val_loss did not improve from 395.38992
196/196 - 15s - loss: 393.7946 - MinusLogProbMetric: 393.7946 - val_loss: 395.8280 - val_MinusLogProbMetric: 395.8280 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 357/1000
2023-09-10 06:26:42.909 
Epoch 357/1000 
	 loss: 393.4803, MinusLogProbMetric: 393.4803, val_loss: 395.3256, val_MinusLogProbMetric: 395.3256

Epoch 357: val_loss improved from 395.38992 to 395.32556, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 393.4803 - MinusLogProbMetric: 393.4803 - val_loss: 395.3256 - val_MinusLogProbMetric: 395.3256 - lr: 1.6667e-04 - 14s/epoch - 69ms/step
Epoch 358/1000
2023-09-10 06:26:56.762 
Epoch 358/1000 
	 loss: 393.6560, MinusLogProbMetric: 393.6560, val_loss: 395.7466, val_MinusLogProbMetric: 395.7466

Epoch 358: val_loss did not improve from 395.32556
196/196 - 13s - loss: 393.6560 - MinusLogProbMetric: 393.6560 - val_loss: 395.7466 - val_MinusLogProbMetric: 395.7466 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 359/1000
2023-09-10 06:27:10.906 
Epoch 359/1000 
	 loss: 393.6418, MinusLogProbMetric: 393.6418, val_loss: 395.4172, val_MinusLogProbMetric: 395.4172

Epoch 359: val_loss did not improve from 395.32556
196/196 - 14s - loss: 393.6418 - MinusLogProbMetric: 393.6418 - val_loss: 395.4172 - val_MinusLogProbMetric: 395.4172 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 360/1000
2023-09-10 06:27:26.099 
Epoch 360/1000 
	 loss: 393.4706, MinusLogProbMetric: 393.4706, val_loss: 395.2762, val_MinusLogProbMetric: 395.2762

Epoch 360: val_loss improved from 395.32556 to 395.27621, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 393.4706 - MinusLogProbMetric: 393.4706 - val_loss: 395.2762 - val_MinusLogProbMetric: 395.2762 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 361/1000
2023-09-10 06:27:39.917 
Epoch 361/1000 
	 loss: 393.7226, MinusLogProbMetric: 393.7226, val_loss: 395.2278, val_MinusLogProbMetric: 395.2278

Epoch 361: val_loss improved from 395.27621 to 395.22784, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 393.7226 - MinusLogProbMetric: 393.7226 - val_loss: 395.2278 - val_MinusLogProbMetric: 395.2278 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 362/1000
2023-09-10 06:27:58.191 
Epoch 362/1000 
	 loss: 393.6104, MinusLogProbMetric: 393.6104, val_loss: 396.3003, val_MinusLogProbMetric: 396.3003

Epoch 362: val_loss did not improve from 395.22784
196/196 - 18s - loss: 393.6104 - MinusLogProbMetric: 393.6104 - val_loss: 396.3003 - val_MinusLogProbMetric: 396.3003 - lr: 1.6667e-04 - 18s/epoch - 91ms/step
Epoch 363/1000
2023-09-10 06:28:15.601 
Epoch 363/1000 
	 loss: 393.5918, MinusLogProbMetric: 393.5918, val_loss: 395.3560, val_MinusLogProbMetric: 395.3560

Epoch 363: val_loss did not improve from 395.22784
196/196 - 17s - loss: 393.5918 - MinusLogProbMetric: 393.5918 - val_loss: 395.3560 - val_MinusLogProbMetric: 395.3560 - lr: 1.6667e-04 - 17s/epoch - 89ms/step
Epoch 364/1000
2023-09-10 06:28:29.767 
Epoch 364/1000 
	 loss: 393.8952, MinusLogProbMetric: 393.8952, val_loss: 395.3618, val_MinusLogProbMetric: 395.3618

Epoch 364: val_loss did not improve from 395.22784
196/196 - 14s - loss: 393.8952 - MinusLogProbMetric: 393.8952 - val_loss: 395.3618 - val_MinusLogProbMetric: 395.3618 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 365/1000
2023-09-10 06:28:44.724 
Epoch 365/1000 
	 loss: 393.3616, MinusLogProbMetric: 393.3616, val_loss: 395.0137, val_MinusLogProbMetric: 395.0137

Epoch 365: val_loss improved from 395.22784 to 395.01373, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 393.3616 - MinusLogProbMetric: 393.3616 - val_loss: 395.0137 - val_MinusLogProbMetric: 395.0137 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 366/1000
2023-09-10 06:28:59.308 
Epoch 366/1000 
	 loss: 393.5561, MinusLogProbMetric: 393.5561, val_loss: 396.0319, val_MinusLogProbMetric: 396.0319

Epoch 366: val_loss did not improve from 395.01373
196/196 - 14s - loss: 393.5561 - MinusLogProbMetric: 393.5561 - val_loss: 396.0319 - val_MinusLogProbMetric: 396.0319 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 367/1000
2023-09-10 06:29:14.766 
Epoch 367/1000 
	 loss: 393.3424, MinusLogProbMetric: 393.3424, val_loss: 395.9872, val_MinusLogProbMetric: 395.9872

Epoch 367: val_loss did not improve from 395.01373
196/196 - 15s - loss: 393.3424 - MinusLogProbMetric: 393.3424 - val_loss: 395.9872 - val_MinusLogProbMetric: 395.9872 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 368/1000
2023-09-10 06:29:29.335 
Epoch 368/1000 
	 loss: 393.3890, MinusLogProbMetric: 393.3890, val_loss: 395.9162, val_MinusLogProbMetric: 395.9162

Epoch 368: val_loss did not improve from 395.01373
196/196 - 15s - loss: 393.3890 - MinusLogProbMetric: 393.3890 - val_loss: 395.9162 - val_MinusLogProbMetric: 395.9162 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 369/1000
2023-09-10 06:29:44.392 
Epoch 369/1000 
	 loss: 393.3801, MinusLogProbMetric: 393.3801, val_loss: 395.5754, val_MinusLogProbMetric: 395.5754

Epoch 369: val_loss did not improve from 395.01373
196/196 - 15s - loss: 393.3801 - MinusLogProbMetric: 393.3801 - val_loss: 395.5754 - val_MinusLogProbMetric: 395.5754 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 370/1000
2023-09-10 06:29:58.070 
Epoch 370/1000 
	 loss: 393.4606, MinusLogProbMetric: 393.4606, val_loss: 396.1991, val_MinusLogProbMetric: 396.1991

Epoch 370: val_loss did not improve from 395.01373
196/196 - 14s - loss: 393.4606 - MinusLogProbMetric: 393.4606 - val_loss: 396.1991 - val_MinusLogProbMetric: 396.1991 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 371/1000
2023-09-10 06:30:12.221 
Epoch 371/1000 
	 loss: 393.2150, MinusLogProbMetric: 393.2150, val_loss: 397.6138, val_MinusLogProbMetric: 397.6138

Epoch 371: val_loss did not improve from 395.01373
196/196 - 14s - loss: 393.2150 - MinusLogProbMetric: 393.2150 - val_loss: 397.6138 - val_MinusLogProbMetric: 397.6138 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 372/1000
2023-09-10 06:30:25.425 
Epoch 372/1000 
	 loss: 393.3324, MinusLogProbMetric: 393.3324, val_loss: 395.4804, val_MinusLogProbMetric: 395.4804

Epoch 372: val_loss did not improve from 395.01373
196/196 - 13s - loss: 393.3324 - MinusLogProbMetric: 393.3324 - val_loss: 395.4804 - val_MinusLogProbMetric: 395.4804 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 373/1000
2023-09-10 06:30:37.214 
Epoch 373/1000 
	 loss: 393.4242, MinusLogProbMetric: 393.4242, val_loss: 395.8558, val_MinusLogProbMetric: 395.8558

Epoch 373: val_loss did not improve from 395.01373
196/196 - 12s - loss: 393.4242 - MinusLogProbMetric: 393.4242 - val_loss: 395.8558 - val_MinusLogProbMetric: 395.8558 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 374/1000
2023-09-10 06:30:52.037 
Epoch 374/1000 
	 loss: 393.3535, MinusLogProbMetric: 393.3535, val_loss: 396.6592, val_MinusLogProbMetric: 396.6592

Epoch 374: val_loss did not improve from 395.01373
196/196 - 15s - loss: 393.3535 - MinusLogProbMetric: 393.3535 - val_loss: 396.6592 - val_MinusLogProbMetric: 396.6592 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 375/1000
2023-09-10 06:31:07.893 
Epoch 375/1000 
	 loss: 393.4655, MinusLogProbMetric: 393.4655, val_loss: 394.8804, val_MinusLogProbMetric: 394.8804

Epoch 375: val_loss improved from 395.01373 to 394.88037, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 393.4655 - MinusLogProbMetric: 393.4655 - val_loss: 394.8804 - val_MinusLogProbMetric: 394.8804 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 376/1000
2023-09-10 06:31:24.001 
Epoch 376/1000 
	 loss: 392.8931, MinusLogProbMetric: 392.8931, val_loss: 397.5275, val_MinusLogProbMetric: 397.5275

Epoch 376: val_loss did not improve from 394.88037
196/196 - 16s - loss: 392.8931 - MinusLogProbMetric: 392.8931 - val_loss: 397.5275 - val_MinusLogProbMetric: 397.5275 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 377/1000
2023-09-10 06:31:39.141 
Epoch 377/1000 
	 loss: 393.2345, MinusLogProbMetric: 393.2345, val_loss: 395.3921, val_MinusLogProbMetric: 395.3921

Epoch 377: val_loss did not improve from 394.88037
196/196 - 15s - loss: 393.2345 - MinusLogProbMetric: 393.2345 - val_loss: 395.3921 - val_MinusLogProbMetric: 395.3921 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 378/1000
2023-09-10 06:31:54.466 
Epoch 378/1000 
	 loss: 393.3261, MinusLogProbMetric: 393.3261, val_loss: 396.0085, val_MinusLogProbMetric: 396.0085

Epoch 378: val_loss did not improve from 394.88037
196/196 - 15s - loss: 393.3261 - MinusLogProbMetric: 393.3261 - val_loss: 396.0085 - val_MinusLogProbMetric: 396.0085 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 379/1000
2023-09-10 06:32:08.160 
Epoch 379/1000 
	 loss: 393.1440, MinusLogProbMetric: 393.1440, val_loss: 399.9281, val_MinusLogProbMetric: 399.9281

Epoch 379: val_loss did not improve from 394.88037
196/196 - 14s - loss: 393.1440 - MinusLogProbMetric: 393.1440 - val_loss: 399.9281 - val_MinusLogProbMetric: 399.9281 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 380/1000
2023-09-10 06:32:23.104 
Epoch 380/1000 
	 loss: 393.1712, MinusLogProbMetric: 393.1712, val_loss: 396.1276, val_MinusLogProbMetric: 396.1276

Epoch 380: val_loss did not improve from 394.88037
196/196 - 15s - loss: 393.1712 - MinusLogProbMetric: 393.1712 - val_loss: 396.1276 - val_MinusLogProbMetric: 396.1276 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 381/1000
2023-09-10 06:32:38.842 
Epoch 381/1000 
	 loss: 393.0152, MinusLogProbMetric: 393.0152, val_loss: 395.2375, val_MinusLogProbMetric: 395.2375

Epoch 381: val_loss did not improve from 394.88037
196/196 - 16s - loss: 393.0152 - MinusLogProbMetric: 393.0152 - val_loss: 395.2375 - val_MinusLogProbMetric: 395.2375 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 382/1000
2023-09-10 06:32:55.239 
Epoch 382/1000 
	 loss: 393.1029, MinusLogProbMetric: 393.1029, val_loss: 394.8702, val_MinusLogProbMetric: 394.8702

Epoch 382: val_loss improved from 394.88037 to 394.87018, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 17s - loss: 393.1029 - MinusLogProbMetric: 393.1029 - val_loss: 394.8702 - val_MinusLogProbMetric: 394.8702 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 383/1000
2023-09-10 06:33:12.516 
Epoch 383/1000 
	 loss: 393.0330, MinusLogProbMetric: 393.0330, val_loss: 395.6932, val_MinusLogProbMetric: 395.6932

Epoch 383: val_loss did not improve from 394.87018
196/196 - 17s - loss: 393.0330 - MinusLogProbMetric: 393.0330 - val_loss: 395.6932 - val_MinusLogProbMetric: 395.6932 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 384/1000
2023-09-10 06:33:28.812 
Epoch 384/1000 
	 loss: 393.2348, MinusLogProbMetric: 393.2348, val_loss: 395.4939, val_MinusLogProbMetric: 395.4939

Epoch 384: val_loss did not improve from 394.87018
196/196 - 16s - loss: 393.2348 - MinusLogProbMetric: 393.2348 - val_loss: 395.4939 - val_MinusLogProbMetric: 395.4939 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 385/1000
2023-09-10 06:33:44.381 
Epoch 385/1000 
	 loss: 393.1341, MinusLogProbMetric: 393.1341, val_loss: 395.3085, val_MinusLogProbMetric: 395.3085

Epoch 385: val_loss did not improve from 394.87018
196/196 - 16s - loss: 393.1341 - MinusLogProbMetric: 393.1341 - val_loss: 395.3085 - val_MinusLogProbMetric: 395.3085 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 386/1000
2023-09-10 06:33:59.898 
Epoch 386/1000 
	 loss: 392.8913, MinusLogProbMetric: 392.8913, val_loss: 395.0983, val_MinusLogProbMetric: 395.0983

Epoch 386: val_loss did not improve from 394.87018
196/196 - 16s - loss: 392.8913 - MinusLogProbMetric: 392.8913 - val_loss: 395.0983 - val_MinusLogProbMetric: 395.0983 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 387/1000
2023-09-10 06:34:13.857 
Epoch 387/1000 
	 loss: 393.1635, MinusLogProbMetric: 393.1635, val_loss: 396.9261, val_MinusLogProbMetric: 396.9261

Epoch 387: val_loss did not improve from 394.87018
196/196 - 14s - loss: 393.1635 - MinusLogProbMetric: 393.1635 - val_loss: 396.9261 - val_MinusLogProbMetric: 396.9261 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 388/1000
2023-09-10 06:34:28.488 
Epoch 388/1000 
	 loss: 393.1424, MinusLogProbMetric: 393.1424, val_loss: 394.7194, val_MinusLogProbMetric: 394.7194

Epoch 388: val_loss improved from 394.87018 to 394.71939, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 393.1424 - MinusLogProbMetric: 393.1424 - val_loss: 394.7194 - val_MinusLogProbMetric: 394.7194 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 389/1000
2023-09-10 06:34:42.129 
Epoch 389/1000 
	 loss: 393.0834, MinusLogProbMetric: 393.0834, val_loss: 394.8749, val_MinusLogProbMetric: 394.8749

Epoch 389: val_loss did not improve from 394.71939
196/196 - 13s - loss: 393.0834 - MinusLogProbMetric: 393.0834 - val_loss: 394.8749 - val_MinusLogProbMetric: 394.8749 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 390/1000
2023-09-10 06:34:54.174 
Epoch 390/1000 
	 loss: 392.9046, MinusLogProbMetric: 392.9046, val_loss: 396.8190, val_MinusLogProbMetric: 396.8190

Epoch 390: val_loss did not improve from 394.71939
196/196 - 12s - loss: 392.9046 - MinusLogProbMetric: 392.9046 - val_loss: 396.8190 - val_MinusLogProbMetric: 396.8190 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 391/1000
2023-09-10 06:35:09.329 
Epoch 391/1000 
	 loss: 392.7313, MinusLogProbMetric: 392.7313, val_loss: 394.8973, val_MinusLogProbMetric: 394.8973

Epoch 391: val_loss did not improve from 394.71939
196/196 - 15s - loss: 392.7313 - MinusLogProbMetric: 392.7313 - val_loss: 394.8973 - val_MinusLogProbMetric: 394.8973 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 392/1000
2023-09-10 06:35:24.293 
Epoch 392/1000 
	 loss: 393.0272, MinusLogProbMetric: 393.0272, val_loss: 394.7351, val_MinusLogProbMetric: 394.7351

Epoch 392: val_loss did not improve from 394.71939
196/196 - 15s - loss: 393.0272 - MinusLogProbMetric: 393.0272 - val_loss: 394.7351 - val_MinusLogProbMetric: 394.7351 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 393/1000
2023-09-10 06:35:37.300 
Epoch 393/1000 
	 loss: 393.1468, MinusLogProbMetric: 393.1468, val_loss: 394.4872, val_MinusLogProbMetric: 394.4872

Epoch 393: val_loss improved from 394.71939 to 394.48724, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 13s - loss: 393.1468 - MinusLogProbMetric: 393.1468 - val_loss: 394.4872 - val_MinusLogProbMetric: 394.4872 - lr: 1.6667e-04 - 13s/epoch - 69ms/step
Epoch 394/1000
2023-09-10 06:35:51.395 
Epoch 394/1000 
	 loss: 392.8517, MinusLogProbMetric: 392.8517, val_loss: 395.0305, val_MinusLogProbMetric: 395.0305

Epoch 394: val_loss did not improve from 394.48724
196/196 - 14s - loss: 392.8517 - MinusLogProbMetric: 392.8517 - val_loss: 395.0305 - val_MinusLogProbMetric: 395.0305 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 395/1000
2023-09-10 06:36:05.991 
Epoch 395/1000 
	 loss: 393.1937, MinusLogProbMetric: 393.1937, val_loss: 395.2664, val_MinusLogProbMetric: 395.2664

Epoch 395: val_loss did not improve from 394.48724
196/196 - 15s - loss: 393.1937 - MinusLogProbMetric: 393.1937 - val_loss: 395.2664 - val_MinusLogProbMetric: 395.2664 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 396/1000
2023-09-10 06:36:21.059 
Epoch 396/1000 
	 loss: 392.6931, MinusLogProbMetric: 392.6931, val_loss: 395.5197, val_MinusLogProbMetric: 395.5197

Epoch 396: val_loss did not improve from 394.48724
196/196 - 15s - loss: 392.6931 - MinusLogProbMetric: 392.6931 - val_loss: 395.5197 - val_MinusLogProbMetric: 395.5197 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 397/1000
2023-09-10 06:36:34.796 
Epoch 397/1000 
	 loss: 392.9167, MinusLogProbMetric: 392.9167, val_loss: 396.6237, val_MinusLogProbMetric: 396.6237

Epoch 397: val_loss did not improve from 394.48724
196/196 - 14s - loss: 392.9167 - MinusLogProbMetric: 392.9167 - val_loss: 396.6237 - val_MinusLogProbMetric: 396.6237 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 398/1000
2023-09-10 06:36:49.936 
Epoch 398/1000 
	 loss: 393.0298, MinusLogProbMetric: 393.0298, val_loss: 396.4176, val_MinusLogProbMetric: 396.4176

Epoch 398: val_loss did not improve from 394.48724
196/196 - 15s - loss: 393.0298 - MinusLogProbMetric: 393.0298 - val_loss: 396.4176 - val_MinusLogProbMetric: 396.4176 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 399/1000
2023-09-10 06:37:04.978 
Epoch 399/1000 
	 loss: 392.8609, MinusLogProbMetric: 392.8609, val_loss: 397.0542, val_MinusLogProbMetric: 397.0542

Epoch 399: val_loss did not improve from 394.48724
196/196 - 15s - loss: 392.8609 - MinusLogProbMetric: 392.8609 - val_loss: 397.0542 - val_MinusLogProbMetric: 397.0542 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 400/1000
2023-09-10 06:37:22.969 
Epoch 400/1000 
	 loss: 393.2423, MinusLogProbMetric: 393.2423, val_loss: 394.6611, val_MinusLogProbMetric: 394.6611

Epoch 400: val_loss did not improve from 394.48724
196/196 - 18s - loss: 393.2423 - MinusLogProbMetric: 393.2423 - val_loss: 394.6611 - val_MinusLogProbMetric: 394.6611 - lr: 1.6667e-04 - 18s/epoch - 92ms/step
Epoch 401/1000
2023-09-10 06:37:39.621 
Epoch 401/1000 
	 loss: 392.5543, MinusLogProbMetric: 392.5543, val_loss: 395.0517, val_MinusLogProbMetric: 395.0517

Epoch 401: val_loss did not improve from 394.48724
196/196 - 17s - loss: 392.5543 - MinusLogProbMetric: 392.5543 - val_loss: 395.0517 - val_MinusLogProbMetric: 395.0517 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 402/1000
2023-09-10 06:37:54.526 
Epoch 402/1000 
	 loss: 392.8251, MinusLogProbMetric: 392.8251, val_loss: 395.6388, val_MinusLogProbMetric: 395.6388

Epoch 402: val_loss did not improve from 394.48724
196/196 - 15s - loss: 392.8251 - MinusLogProbMetric: 392.8251 - val_loss: 395.6388 - val_MinusLogProbMetric: 395.6388 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 403/1000
2023-09-10 06:38:09.902 
Epoch 403/1000 
	 loss: 393.0666, MinusLogProbMetric: 393.0666, val_loss: 394.4084, val_MinusLogProbMetric: 394.4084

Epoch 403: val_loss improved from 394.48724 to 394.40839, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 393.0666 - MinusLogProbMetric: 393.0666 - val_loss: 394.4084 - val_MinusLogProbMetric: 394.4084 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 404/1000
2023-09-10 06:38:25.886 
Epoch 404/1000 
	 loss: 392.5210, MinusLogProbMetric: 392.5210, val_loss: 395.3414, val_MinusLogProbMetric: 395.3414

Epoch 404: val_loss did not improve from 394.40839
196/196 - 15s - loss: 392.5210 - MinusLogProbMetric: 392.5210 - val_loss: 395.3414 - val_MinusLogProbMetric: 395.3414 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 405/1000
2023-09-10 06:38:43.861 
Epoch 405/1000 
	 loss: 392.7460, MinusLogProbMetric: 392.7460, val_loss: 394.8626, val_MinusLogProbMetric: 394.8626

Epoch 405: val_loss did not improve from 394.40839
196/196 - 18s - loss: 392.7460 - MinusLogProbMetric: 392.7460 - val_loss: 394.8626 - val_MinusLogProbMetric: 394.8626 - lr: 1.6667e-04 - 18s/epoch - 92ms/step
Epoch 406/1000
2023-09-10 06:38:58.955 
Epoch 406/1000 
	 loss: 392.8564, MinusLogProbMetric: 392.8564, val_loss: 395.5937, val_MinusLogProbMetric: 395.5937

Epoch 406: val_loss did not improve from 394.40839
196/196 - 15s - loss: 392.8564 - MinusLogProbMetric: 392.8564 - val_loss: 395.5937 - val_MinusLogProbMetric: 395.5937 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 407/1000
2023-09-10 06:39:14.489 
Epoch 407/1000 
	 loss: 392.7124, MinusLogProbMetric: 392.7124, val_loss: 396.8291, val_MinusLogProbMetric: 396.8291

Epoch 407: val_loss did not improve from 394.40839
196/196 - 16s - loss: 392.7124 - MinusLogProbMetric: 392.7124 - val_loss: 396.8291 - val_MinusLogProbMetric: 396.8291 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 408/1000
2023-09-10 06:39:30.409 
Epoch 408/1000 
	 loss: 392.7464, MinusLogProbMetric: 392.7464, val_loss: 394.5812, val_MinusLogProbMetric: 394.5812

Epoch 408: val_loss did not improve from 394.40839
196/196 - 16s - loss: 392.7464 - MinusLogProbMetric: 392.7464 - val_loss: 394.5812 - val_MinusLogProbMetric: 394.5812 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 409/1000
2023-09-10 06:39:45.881 
Epoch 409/1000 
	 loss: 392.5737, MinusLogProbMetric: 392.5737, val_loss: 395.2677, val_MinusLogProbMetric: 395.2677

Epoch 409: val_loss did not improve from 394.40839
196/196 - 15s - loss: 392.5737 - MinusLogProbMetric: 392.5737 - val_loss: 395.2677 - val_MinusLogProbMetric: 395.2677 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 410/1000
2023-09-10 06:40:01.007 
Epoch 410/1000 
	 loss: 392.6801, MinusLogProbMetric: 392.6801, val_loss: 394.5223, val_MinusLogProbMetric: 394.5223

Epoch 410: val_loss did not improve from 394.40839
196/196 - 15s - loss: 392.6801 - MinusLogProbMetric: 392.6801 - val_loss: 394.5223 - val_MinusLogProbMetric: 394.5223 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 411/1000
2023-09-10 06:40:17.587 
Epoch 411/1000 
	 loss: 392.4473, MinusLogProbMetric: 392.4473, val_loss: 395.0368, val_MinusLogProbMetric: 395.0368

Epoch 411: val_loss did not improve from 394.40839
196/196 - 17s - loss: 392.4473 - MinusLogProbMetric: 392.4473 - val_loss: 395.0368 - val_MinusLogProbMetric: 395.0368 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 412/1000
2023-09-10 06:40:33.593 
Epoch 412/1000 
	 loss: 392.7780, MinusLogProbMetric: 392.7780, val_loss: 394.8806, val_MinusLogProbMetric: 394.8806

Epoch 412: val_loss did not improve from 394.40839
196/196 - 16s - loss: 392.7780 - MinusLogProbMetric: 392.7780 - val_loss: 394.8806 - val_MinusLogProbMetric: 394.8806 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 413/1000
2023-09-10 06:40:49.424 
Epoch 413/1000 
	 loss: 392.4646, MinusLogProbMetric: 392.4646, val_loss: 394.5636, val_MinusLogProbMetric: 394.5636

Epoch 413: val_loss did not improve from 394.40839
196/196 - 16s - loss: 392.4646 - MinusLogProbMetric: 392.4646 - val_loss: 394.5636 - val_MinusLogProbMetric: 394.5636 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 414/1000
2023-09-10 06:41:03.997 
Epoch 414/1000 
	 loss: 392.4787, MinusLogProbMetric: 392.4787, val_loss: 394.8135, val_MinusLogProbMetric: 394.8135

Epoch 414: val_loss did not improve from 394.40839
196/196 - 15s - loss: 392.4787 - MinusLogProbMetric: 392.4787 - val_loss: 394.8135 - val_MinusLogProbMetric: 394.8135 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 415/1000
2023-09-10 06:41:19.834 
Epoch 415/1000 
	 loss: 393.0262, MinusLogProbMetric: 393.0262, val_loss: 394.3617, val_MinusLogProbMetric: 394.3617

Epoch 415: val_loss improved from 394.40839 to 394.36169, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 393.0262 - MinusLogProbMetric: 393.0262 - val_loss: 394.3617 - val_MinusLogProbMetric: 394.3617 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 416/1000
2023-09-10 06:41:34.146 
Epoch 416/1000 
	 loss: 392.5360, MinusLogProbMetric: 392.5360, val_loss: 394.9797, val_MinusLogProbMetric: 394.9797

Epoch 416: val_loss did not improve from 394.36169
196/196 - 14s - loss: 392.5360 - MinusLogProbMetric: 392.5360 - val_loss: 394.9797 - val_MinusLogProbMetric: 394.9797 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 417/1000
2023-09-10 06:41:50.334 
Epoch 417/1000 
	 loss: 392.4829, MinusLogProbMetric: 392.4829, val_loss: 394.6179, val_MinusLogProbMetric: 394.6179

Epoch 417: val_loss did not improve from 394.36169
196/196 - 16s - loss: 392.4829 - MinusLogProbMetric: 392.4829 - val_loss: 394.6179 - val_MinusLogProbMetric: 394.6179 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 418/1000
2023-09-10 06:42:04.687 
Epoch 418/1000 
	 loss: 392.4789, MinusLogProbMetric: 392.4789, val_loss: 396.2502, val_MinusLogProbMetric: 396.2502

Epoch 418: val_loss did not improve from 394.36169
196/196 - 14s - loss: 392.4789 - MinusLogProbMetric: 392.4789 - val_loss: 396.2502 - val_MinusLogProbMetric: 396.2502 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 419/1000
2023-09-10 06:42:19.844 
Epoch 419/1000 
	 loss: 392.6614, MinusLogProbMetric: 392.6614, val_loss: 394.6507, val_MinusLogProbMetric: 394.6507

Epoch 419: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.6614 - MinusLogProbMetric: 392.6614 - val_loss: 394.6507 - val_MinusLogProbMetric: 394.6507 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 420/1000
2023-09-10 06:42:34.947 
Epoch 420/1000 
	 loss: 392.6871, MinusLogProbMetric: 392.6871, val_loss: 396.1712, val_MinusLogProbMetric: 396.1712

Epoch 420: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.6871 - MinusLogProbMetric: 392.6871 - val_loss: 396.1712 - val_MinusLogProbMetric: 396.1712 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 421/1000
2023-09-10 06:42:50.895 
Epoch 421/1000 
	 loss: 392.4970, MinusLogProbMetric: 392.4970, val_loss: 395.2297, val_MinusLogProbMetric: 395.2297

Epoch 421: val_loss did not improve from 394.36169
196/196 - 16s - loss: 392.4970 - MinusLogProbMetric: 392.4970 - val_loss: 395.2297 - val_MinusLogProbMetric: 395.2297 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 422/1000
2023-09-10 06:43:06.104 
Epoch 422/1000 
	 loss: 392.5807, MinusLogProbMetric: 392.5807, val_loss: 396.8368, val_MinusLogProbMetric: 396.8368

Epoch 422: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.5807 - MinusLogProbMetric: 392.5807 - val_loss: 396.8368 - val_MinusLogProbMetric: 396.8368 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 423/1000
2023-09-10 06:43:20.644 
Epoch 423/1000 
	 loss: 392.5906, MinusLogProbMetric: 392.5906, val_loss: 397.9122, val_MinusLogProbMetric: 397.9122

Epoch 423: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.5906 - MinusLogProbMetric: 392.5906 - val_loss: 397.9122 - val_MinusLogProbMetric: 397.9122 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 424/1000
2023-09-10 06:43:39.779 
Epoch 424/1000 
	 loss: 392.5312, MinusLogProbMetric: 392.5312, val_loss: 394.3865, val_MinusLogProbMetric: 394.3865

Epoch 424: val_loss did not improve from 394.36169
196/196 - 19s - loss: 392.5312 - MinusLogProbMetric: 392.5312 - val_loss: 394.3865 - val_MinusLogProbMetric: 394.3865 - lr: 1.6667e-04 - 19s/epoch - 98ms/step
Epoch 425/1000
2023-09-10 06:43:54.887 
Epoch 425/1000 
	 loss: 392.7313, MinusLogProbMetric: 392.7313, val_loss: 396.8759, val_MinusLogProbMetric: 396.8759

Epoch 425: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.7313 - MinusLogProbMetric: 392.7313 - val_loss: 396.8759 - val_MinusLogProbMetric: 396.8759 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 426/1000
2023-09-10 06:44:10.429 
Epoch 426/1000 
	 loss: 392.2600, MinusLogProbMetric: 392.2600, val_loss: 394.7832, val_MinusLogProbMetric: 394.7832

Epoch 426: val_loss did not improve from 394.36169
196/196 - 16s - loss: 392.2600 - MinusLogProbMetric: 392.2600 - val_loss: 394.7832 - val_MinusLogProbMetric: 394.7832 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 427/1000
2023-09-10 06:44:25.347 
Epoch 427/1000 
	 loss: 392.7568, MinusLogProbMetric: 392.7568, val_loss: 395.3997, val_MinusLogProbMetric: 395.3997

Epoch 427: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.7568 - MinusLogProbMetric: 392.7568 - val_loss: 395.3997 - val_MinusLogProbMetric: 395.3997 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 428/1000
2023-09-10 06:44:40.492 
Epoch 428/1000 
	 loss: 392.4702, MinusLogProbMetric: 392.4702, val_loss: 394.5837, val_MinusLogProbMetric: 394.5837

Epoch 428: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.4702 - MinusLogProbMetric: 392.4702 - val_loss: 394.5837 - val_MinusLogProbMetric: 394.5837 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 429/1000
2023-09-10 06:44:54.409 
Epoch 429/1000 
	 loss: 392.4166, MinusLogProbMetric: 392.4166, val_loss: 395.0032, val_MinusLogProbMetric: 395.0032

Epoch 429: val_loss did not improve from 394.36169
196/196 - 14s - loss: 392.4166 - MinusLogProbMetric: 392.4166 - val_loss: 395.0032 - val_MinusLogProbMetric: 395.0032 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 430/1000
2023-09-10 06:45:07.268 
Epoch 430/1000 
	 loss: 392.2518, MinusLogProbMetric: 392.2518, val_loss: 397.0270, val_MinusLogProbMetric: 397.0270

Epoch 430: val_loss did not improve from 394.36169
196/196 - 13s - loss: 392.2518 - MinusLogProbMetric: 392.2518 - val_loss: 397.0270 - val_MinusLogProbMetric: 397.0270 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 431/1000
2023-09-10 06:45:21.456 
Epoch 431/1000 
	 loss: 392.9768, MinusLogProbMetric: 392.9768, val_loss: 394.6752, val_MinusLogProbMetric: 394.6752

Epoch 431: val_loss did not improve from 394.36169
196/196 - 14s - loss: 392.9768 - MinusLogProbMetric: 392.9768 - val_loss: 394.6752 - val_MinusLogProbMetric: 394.6752 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 432/1000
2023-09-10 06:45:36.359 
Epoch 432/1000 
	 loss: 392.4778, MinusLogProbMetric: 392.4778, val_loss: 394.7873, val_MinusLogProbMetric: 394.7873

Epoch 432: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.4778 - MinusLogProbMetric: 392.4778 - val_loss: 394.7873 - val_MinusLogProbMetric: 394.7873 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 433/1000
2023-09-10 06:45:53.693 
Epoch 433/1000 
	 loss: 392.3190, MinusLogProbMetric: 392.3190, val_loss: 394.8988, val_MinusLogProbMetric: 394.8988

Epoch 433: val_loss did not improve from 394.36169
196/196 - 17s - loss: 392.3190 - MinusLogProbMetric: 392.3190 - val_loss: 394.8988 - val_MinusLogProbMetric: 394.8988 - lr: 1.6667e-04 - 17s/epoch - 88ms/step
Epoch 434/1000
2023-09-10 06:46:12.227 
Epoch 434/1000 
	 loss: 392.4470, MinusLogProbMetric: 392.4470, val_loss: 394.7576, val_MinusLogProbMetric: 394.7576

Epoch 434: val_loss did not improve from 394.36169
196/196 - 19s - loss: 392.4470 - MinusLogProbMetric: 392.4470 - val_loss: 394.7576 - val_MinusLogProbMetric: 394.7576 - lr: 1.6667e-04 - 19s/epoch - 95ms/step
Epoch 435/1000
2023-09-10 06:46:28.618 
Epoch 435/1000 
	 loss: 392.5253, MinusLogProbMetric: 392.5253, val_loss: 395.2805, val_MinusLogProbMetric: 395.2805

Epoch 435: val_loss did not improve from 394.36169
196/196 - 16s - loss: 392.5253 - MinusLogProbMetric: 392.5253 - val_loss: 395.2805 - val_MinusLogProbMetric: 395.2805 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 436/1000
2023-09-10 06:46:43.100 
Epoch 436/1000 
	 loss: 392.0644, MinusLogProbMetric: 392.0644, val_loss: 395.5377, val_MinusLogProbMetric: 395.5377

Epoch 436: val_loss did not improve from 394.36169
196/196 - 14s - loss: 392.0644 - MinusLogProbMetric: 392.0644 - val_loss: 395.5377 - val_MinusLogProbMetric: 395.5377 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 437/1000
2023-09-10 06:46:57.620 
Epoch 437/1000 
	 loss: 392.7404, MinusLogProbMetric: 392.7404, val_loss: 395.6204, val_MinusLogProbMetric: 395.6204

Epoch 437: val_loss did not improve from 394.36169
196/196 - 15s - loss: 392.7404 - MinusLogProbMetric: 392.7404 - val_loss: 395.6204 - val_MinusLogProbMetric: 395.6204 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 438/1000
2023-09-10 06:47:11.606 
Epoch 438/1000 
	 loss: 392.1877, MinusLogProbMetric: 392.1877, val_loss: 393.8134, val_MinusLogProbMetric: 393.8134

Epoch 438: val_loss improved from 394.36169 to 393.81345, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 392.1877 - MinusLogProbMetric: 392.1877 - val_loss: 393.8134 - val_MinusLogProbMetric: 393.8134 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 439/1000
2023-09-10 06:47:27.872 
Epoch 439/1000 
	 loss: 392.2566, MinusLogProbMetric: 392.2566, val_loss: 395.0168, val_MinusLogProbMetric: 395.0168

Epoch 439: val_loss did not improve from 393.81345
196/196 - 16s - loss: 392.2566 - MinusLogProbMetric: 392.2566 - val_loss: 395.0168 - val_MinusLogProbMetric: 395.0168 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 440/1000
2023-09-10 06:47:45.000 
Epoch 440/1000 
	 loss: 391.9485, MinusLogProbMetric: 391.9485, val_loss: 394.8101, val_MinusLogProbMetric: 394.8101

Epoch 440: val_loss did not improve from 393.81345
196/196 - 17s - loss: 391.9485 - MinusLogProbMetric: 391.9485 - val_loss: 394.8101 - val_MinusLogProbMetric: 394.8101 - lr: 1.6667e-04 - 17s/epoch - 87ms/step
Epoch 441/1000
2023-09-10 06:48:03.223 
Epoch 441/1000 
	 loss: 392.2173, MinusLogProbMetric: 392.2173, val_loss: 394.3772, val_MinusLogProbMetric: 394.3772

Epoch 441: val_loss did not improve from 393.81345
196/196 - 18s - loss: 392.2173 - MinusLogProbMetric: 392.2173 - val_loss: 394.3772 - val_MinusLogProbMetric: 394.3772 - lr: 1.6667e-04 - 18s/epoch - 93ms/step
Epoch 442/1000
2023-09-10 06:48:19.495 
Epoch 442/1000 
	 loss: 392.4089, MinusLogProbMetric: 392.4089, val_loss: 394.9755, val_MinusLogProbMetric: 394.9755

Epoch 442: val_loss did not improve from 393.81345
196/196 - 16s - loss: 392.4089 - MinusLogProbMetric: 392.4089 - val_loss: 394.9755 - val_MinusLogProbMetric: 394.9755 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 443/1000
2023-09-10 06:48:37.211 
Epoch 443/1000 
	 loss: 392.3407, MinusLogProbMetric: 392.3407, val_loss: 394.4690, val_MinusLogProbMetric: 394.4690

Epoch 443: val_loss did not improve from 393.81345
196/196 - 18s - loss: 392.3407 - MinusLogProbMetric: 392.3407 - val_loss: 394.4690 - val_MinusLogProbMetric: 394.4690 - lr: 1.6667e-04 - 18s/epoch - 90ms/step
Epoch 444/1000
2023-09-10 06:48:54.070 
Epoch 444/1000 
	 loss: 392.1753, MinusLogProbMetric: 392.1753, val_loss: 394.8064, val_MinusLogProbMetric: 394.8064

Epoch 444: val_loss did not improve from 393.81345
196/196 - 17s - loss: 392.1753 - MinusLogProbMetric: 392.1753 - val_loss: 394.8064 - val_MinusLogProbMetric: 394.8064 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 445/1000
2023-09-10 06:49:09.800 
Epoch 445/1000 
	 loss: 392.4626, MinusLogProbMetric: 392.4626, val_loss: 394.1552, val_MinusLogProbMetric: 394.1552

Epoch 445: val_loss did not improve from 393.81345
196/196 - 16s - loss: 392.4626 - MinusLogProbMetric: 392.4626 - val_loss: 394.1552 - val_MinusLogProbMetric: 394.1552 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 446/1000
2023-09-10 06:49:26.406 
Epoch 446/1000 
	 loss: 392.3511, MinusLogProbMetric: 392.3511, val_loss: 396.3032, val_MinusLogProbMetric: 396.3032

Epoch 446: val_loss did not improve from 393.81345
196/196 - 17s - loss: 392.3511 - MinusLogProbMetric: 392.3511 - val_loss: 396.3032 - val_MinusLogProbMetric: 396.3032 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 447/1000
2023-09-10 06:49:43.280 
Epoch 447/1000 
	 loss: 392.4432, MinusLogProbMetric: 392.4432, val_loss: 395.5870, val_MinusLogProbMetric: 395.5870

Epoch 447: val_loss did not improve from 393.81345
196/196 - 17s - loss: 392.4432 - MinusLogProbMetric: 392.4432 - val_loss: 395.5870 - val_MinusLogProbMetric: 395.5870 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 448/1000
2023-09-10 06:49:58.967 
Epoch 448/1000 
	 loss: 392.3916, MinusLogProbMetric: 392.3916, val_loss: 395.0832, val_MinusLogProbMetric: 395.0832

Epoch 448: val_loss did not improve from 393.81345
196/196 - 16s - loss: 392.3916 - MinusLogProbMetric: 392.3916 - val_loss: 395.0832 - val_MinusLogProbMetric: 395.0832 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 449/1000
2023-09-10 06:50:15.657 
Epoch 449/1000 
	 loss: 392.0861, MinusLogProbMetric: 392.0861, val_loss: 399.0165, val_MinusLogProbMetric: 399.0165

Epoch 449: val_loss did not improve from 393.81345
196/196 - 17s - loss: 392.0861 - MinusLogProbMetric: 392.0861 - val_loss: 399.0165 - val_MinusLogProbMetric: 399.0165 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 450/1000
2023-09-10 06:50:30.103 
Epoch 450/1000 
	 loss: 392.3747, MinusLogProbMetric: 392.3747, val_loss: 394.7533, val_MinusLogProbMetric: 394.7533

Epoch 450: val_loss did not improve from 393.81345
196/196 - 14s - loss: 392.3747 - MinusLogProbMetric: 392.3747 - val_loss: 394.7533 - val_MinusLogProbMetric: 394.7533 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 451/1000
2023-09-10 06:50:45.380 
Epoch 451/1000 
	 loss: 392.1435, MinusLogProbMetric: 392.1435, val_loss: 395.3707, val_MinusLogProbMetric: 395.3707

Epoch 451: val_loss did not improve from 393.81345
196/196 - 15s - loss: 392.1435 - MinusLogProbMetric: 392.1435 - val_loss: 395.3707 - val_MinusLogProbMetric: 395.3707 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 452/1000
2023-09-10 06:51:00.617 
Epoch 452/1000 
	 loss: 392.3922, MinusLogProbMetric: 392.3922, val_loss: 394.5811, val_MinusLogProbMetric: 394.5811

Epoch 452: val_loss did not improve from 393.81345
196/196 - 15s - loss: 392.3922 - MinusLogProbMetric: 392.3922 - val_loss: 394.5811 - val_MinusLogProbMetric: 394.5811 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 453/1000
2023-09-10 06:51:15.069 
Epoch 453/1000 
	 loss: 391.8121, MinusLogProbMetric: 391.8121, val_loss: 394.6431, val_MinusLogProbMetric: 394.6431

Epoch 453: val_loss did not improve from 393.81345
196/196 - 14s - loss: 391.8121 - MinusLogProbMetric: 391.8121 - val_loss: 394.6431 - val_MinusLogProbMetric: 394.6431 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 454/1000
2023-09-10 06:51:29.960 
Epoch 454/1000 
	 loss: 391.9873, MinusLogProbMetric: 391.9873, val_loss: 394.5780, val_MinusLogProbMetric: 394.5780

Epoch 454: val_loss did not improve from 393.81345
196/196 - 15s - loss: 391.9873 - MinusLogProbMetric: 391.9873 - val_loss: 394.5780 - val_MinusLogProbMetric: 394.5780 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 455/1000
2023-09-10 06:51:45.964 
Epoch 455/1000 
	 loss: 392.4178, MinusLogProbMetric: 392.4178, val_loss: 395.0029, val_MinusLogProbMetric: 395.0029

Epoch 455: val_loss did not improve from 393.81345
196/196 - 16s - loss: 392.4178 - MinusLogProbMetric: 392.4178 - val_loss: 395.0029 - val_MinusLogProbMetric: 395.0029 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 456/1000
2023-09-10 06:52:00.729 
Epoch 456/1000 
	 loss: 392.0624, MinusLogProbMetric: 392.0624, val_loss: 394.8044, val_MinusLogProbMetric: 394.8044

Epoch 456: val_loss did not improve from 393.81345
196/196 - 15s - loss: 392.0624 - MinusLogProbMetric: 392.0624 - val_loss: 394.8044 - val_MinusLogProbMetric: 394.8044 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 457/1000
2023-09-10 06:52:14.646 
Epoch 457/1000 
	 loss: 392.2962, MinusLogProbMetric: 392.2962, val_loss: 394.4492, val_MinusLogProbMetric: 394.4492

Epoch 457: val_loss did not improve from 393.81345
196/196 - 14s - loss: 392.2962 - MinusLogProbMetric: 392.2962 - val_loss: 394.4492 - val_MinusLogProbMetric: 394.4492 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 458/1000
2023-09-10 06:52:29.756 
Epoch 458/1000 
	 loss: 392.0974, MinusLogProbMetric: 392.0974, val_loss: 394.8869, val_MinusLogProbMetric: 394.8869

Epoch 458: val_loss did not improve from 393.81345
196/196 - 15s - loss: 392.0974 - MinusLogProbMetric: 392.0974 - val_loss: 394.8869 - val_MinusLogProbMetric: 394.8869 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 459/1000
2023-09-10 06:52:44.514 
Epoch 459/1000 
	 loss: 391.7606, MinusLogProbMetric: 391.7606, val_loss: 395.6846, val_MinusLogProbMetric: 395.6846

Epoch 459: val_loss did not improve from 393.81345
196/196 - 15s - loss: 391.7606 - MinusLogProbMetric: 391.7606 - val_loss: 395.6846 - val_MinusLogProbMetric: 395.6846 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 460/1000
2023-09-10 06:52:59.187 
Epoch 460/1000 
	 loss: 392.1476, MinusLogProbMetric: 392.1476, val_loss: 394.5053, val_MinusLogProbMetric: 394.5053

Epoch 460: val_loss did not improve from 393.81345
196/196 - 15s - loss: 392.1476 - MinusLogProbMetric: 392.1476 - val_loss: 394.5053 - val_MinusLogProbMetric: 394.5053 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 461/1000
2023-09-10 06:53:14.749 
Epoch 461/1000 
	 loss: 392.3686, MinusLogProbMetric: 392.3686, val_loss: 394.7948, val_MinusLogProbMetric: 394.7948

Epoch 461: val_loss did not improve from 393.81345
196/196 - 16s - loss: 392.3686 - MinusLogProbMetric: 392.3686 - val_loss: 394.7948 - val_MinusLogProbMetric: 394.7948 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 462/1000
2023-09-10 06:53:29.648 
Epoch 462/1000 
	 loss: 391.7953, MinusLogProbMetric: 391.7953, val_loss: 395.6988, val_MinusLogProbMetric: 395.6988

Epoch 462: val_loss did not improve from 393.81345
196/196 - 15s - loss: 391.7953 - MinusLogProbMetric: 391.7953 - val_loss: 395.6988 - val_MinusLogProbMetric: 395.6988 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 463/1000
2023-09-10 06:53:44.657 
Epoch 463/1000 
	 loss: 392.0819, MinusLogProbMetric: 392.0819, val_loss: 394.6180, val_MinusLogProbMetric: 394.6180

Epoch 463: val_loss did not improve from 393.81345
196/196 - 15s - loss: 392.0819 - MinusLogProbMetric: 392.0819 - val_loss: 394.6180 - val_MinusLogProbMetric: 394.6180 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 464/1000
2023-09-10 06:54:00.874 
Epoch 464/1000 
	 loss: 392.0007, MinusLogProbMetric: 392.0007, val_loss: 394.3913, val_MinusLogProbMetric: 394.3913

Epoch 464: val_loss did not improve from 393.81345
196/196 - 16s - loss: 392.0007 - MinusLogProbMetric: 392.0007 - val_loss: 394.3913 - val_MinusLogProbMetric: 394.3913 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 465/1000
2023-09-10 06:54:15.376 
Epoch 465/1000 
	 loss: 391.9410, MinusLogProbMetric: 391.9410, val_loss: 393.7502, val_MinusLogProbMetric: 393.7502

Epoch 465: val_loss improved from 393.81345 to 393.75021, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 391.9410 - MinusLogProbMetric: 391.9410 - val_loss: 393.7502 - val_MinusLogProbMetric: 393.7502 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 466/1000
2023-09-10 06:54:29.732 
Epoch 466/1000 
	 loss: 392.2841, MinusLogProbMetric: 392.2841, val_loss: 394.8448, val_MinusLogProbMetric: 394.8448

Epoch 466: val_loss did not improve from 393.75021
196/196 - 14s - loss: 392.2841 - MinusLogProbMetric: 392.2841 - val_loss: 394.8448 - val_MinusLogProbMetric: 394.8448 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 467/1000
2023-09-10 06:54:45.676 
Epoch 467/1000 
	 loss: 391.9878, MinusLogProbMetric: 391.9878, val_loss: 395.1865, val_MinusLogProbMetric: 395.1865

Epoch 467: val_loss did not improve from 393.75021
196/196 - 16s - loss: 391.9878 - MinusLogProbMetric: 391.9878 - val_loss: 395.1865 - val_MinusLogProbMetric: 395.1865 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 468/1000
2023-09-10 06:55:00.960 
Epoch 468/1000 
	 loss: 392.1776, MinusLogProbMetric: 392.1776, val_loss: 394.7070, val_MinusLogProbMetric: 394.7070

Epoch 468: val_loss did not improve from 393.75021
196/196 - 15s - loss: 392.1776 - MinusLogProbMetric: 392.1776 - val_loss: 394.7070 - val_MinusLogProbMetric: 394.7070 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 469/1000
2023-09-10 06:55:16.744 
Epoch 469/1000 
	 loss: 392.1939, MinusLogProbMetric: 392.1939, val_loss: 394.2128, val_MinusLogProbMetric: 394.2128

Epoch 469: val_loss did not improve from 393.75021
196/196 - 16s - loss: 392.1939 - MinusLogProbMetric: 392.1939 - val_loss: 394.2128 - val_MinusLogProbMetric: 394.2128 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 470/1000
2023-09-10 06:55:30.840 
Epoch 470/1000 
	 loss: 392.1244, MinusLogProbMetric: 392.1244, val_loss: 394.4562, val_MinusLogProbMetric: 394.4562

Epoch 470: val_loss did not improve from 393.75021
196/196 - 14s - loss: 392.1244 - MinusLogProbMetric: 392.1244 - val_loss: 394.4562 - val_MinusLogProbMetric: 394.4562 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 471/1000
2023-09-10 06:55:45.445 
Epoch 471/1000 
	 loss: 392.0316, MinusLogProbMetric: 392.0316, val_loss: 394.1518, val_MinusLogProbMetric: 394.1518

Epoch 471: val_loss did not improve from 393.75021
196/196 - 15s - loss: 392.0316 - MinusLogProbMetric: 392.0316 - val_loss: 394.1518 - val_MinusLogProbMetric: 394.1518 - lr: 1.6667e-04 - 15s/epoch - 74ms/step
Epoch 472/1000
2023-09-10 06:55:59.935 
Epoch 472/1000 
	 loss: 391.9339, MinusLogProbMetric: 391.9339, val_loss: 397.4480, val_MinusLogProbMetric: 397.4480

Epoch 472: val_loss did not improve from 393.75021
196/196 - 14s - loss: 391.9339 - MinusLogProbMetric: 391.9339 - val_loss: 397.4480 - val_MinusLogProbMetric: 397.4480 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 473/1000
2023-09-10 06:56:15.146 
Epoch 473/1000 
	 loss: 392.1613, MinusLogProbMetric: 392.1613, val_loss: 394.6574, val_MinusLogProbMetric: 394.6574

Epoch 473: val_loss did not improve from 393.75021
196/196 - 15s - loss: 392.1613 - MinusLogProbMetric: 392.1613 - val_loss: 394.6574 - val_MinusLogProbMetric: 394.6574 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 474/1000
2023-09-10 06:56:28.554 
Epoch 474/1000 
	 loss: 391.6723, MinusLogProbMetric: 391.6723, val_loss: 394.9956, val_MinusLogProbMetric: 394.9956

Epoch 474: val_loss did not improve from 393.75021
196/196 - 13s - loss: 391.6723 - MinusLogProbMetric: 391.6723 - val_loss: 394.9956 - val_MinusLogProbMetric: 394.9956 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 475/1000
2023-09-10 06:56:43.847 
Epoch 475/1000 
	 loss: 391.8419, MinusLogProbMetric: 391.8419, val_loss: 407.8098, val_MinusLogProbMetric: 407.8098

Epoch 475: val_loss did not improve from 393.75021
196/196 - 15s - loss: 391.8419 - MinusLogProbMetric: 391.8419 - val_loss: 407.8098 - val_MinusLogProbMetric: 407.8098 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 476/1000
2023-09-10 06:56:58.076 
Epoch 476/1000 
	 loss: 392.6097, MinusLogProbMetric: 392.6097, val_loss: 395.5188, val_MinusLogProbMetric: 395.5188

Epoch 476: val_loss did not improve from 393.75021
196/196 - 14s - loss: 392.6097 - MinusLogProbMetric: 392.6097 - val_loss: 395.5188 - val_MinusLogProbMetric: 395.5188 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 477/1000
2023-09-10 06:57:12.535 
Epoch 477/1000 
	 loss: 391.7715, MinusLogProbMetric: 391.7715, val_loss: 395.4280, val_MinusLogProbMetric: 395.4280

Epoch 477: val_loss did not improve from 393.75021
196/196 - 14s - loss: 391.7715 - MinusLogProbMetric: 391.7715 - val_loss: 395.4280 - val_MinusLogProbMetric: 395.4280 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 478/1000
2023-09-10 06:57:28.099 
Epoch 478/1000 
	 loss: 392.2920, MinusLogProbMetric: 392.2920, val_loss: 395.5998, val_MinusLogProbMetric: 395.5998

Epoch 478: val_loss did not improve from 393.75021
196/196 - 16s - loss: 392.2920 - MinusLogProbMetric: 392.2920 - val_loss: 395.5998 - val_MinusLogProbMetric: 395.5998 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 479/1000
2023-09-10 06:57:41.857 
Epoch 479/1000 
	 loss: 391.6252, MinusLogProbMetric: 391.6252, val_loss: 394.7785, val_MinusLogProbMetric: 394.7785

Epoch 479: val_loss did not improve from 393.75021
196/196 - 14s - loss: 391.6252 - MinusLogProbMetric: 391.6252 - val_loss: 394.7785 - val_MinusLogProbMetric: 394.7785 - lr: 1.6667e-04 - 14s/epoch - 70ms/step
Epoch 480/1000
2023-09-10 06:57:56.777 
Epoch 480/1000 
	 loss: 392.2997, MinusLogProbMetric: 392.2997, val_loss: 393.7070, val_MinusLogProbMetric: 393.7070

Epoch 480: val_loss improved from 393.75021 to 393.70700, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 392.2997 - MinusLogProbMetric: 392.2997 - val_loss: 393.7070 - val_MinusLogProbMetric: 393.7070 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 481/1000
2023-09-10 06:58:11.281 
Epoch 481/1000 
	 loss: 391.8696, MinusLogProbMetric: 391.8696, val_loss: 395.9595, val_MinusLogProbMetric: 395.9595

Epoch 481: val_loss did not improve from 393.70700
196/196 - 14s - loss: 391.8696 - MinusLogProbMetric: 391.8696 - val_loss: 395.9595 - val_MinusLogProbMetric: 395.9595 - lr: 1.6667e-04 - 14s/epoch - 71ms/step
Epoch 482/1000
2023-09-10 06:58:28.496 
Epoch 482/1000 
	 loss: 392.0909, MinusLogProbMetric: 392.0909, val_loss: 396.3008, val_MinusLogProbMetric: 396.3008

Epoch 482: val_loss did not improve from 393.70700
196/196 - 17s - loss: 392.0909 - MinusLogProbMetric: 392.0909 - val_loss: 396.3008 - val_MinusLogProbMetric: 396.3008 - lr: 1.6667e-04 - 17s/epoch - 88ms/step
Epoch 483/1000
2023-09-10 06:58:43.916 
Epoch 483/1000 
	 loss: 392.0469, MinusLogProbMetric: 392.0469, val_loss: 393.9796, val_MinusLogProbMetric: 393.9796

Epoch 483: val_loss did not improve from 393.70700
196/196 - 15s - loss: 392.0469 - MinusLogProbMetric: 392.0469 - val_loss: 393.9796 - val_MinusLogProbMetric: 393.9796 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 484/1000
2023-09-10 06:59:00.725 
Epoch 484/1000 
	 loss: 391.7030, MinusLogProbMetric: 391.7030, val_loss: 394.3562, val_MinusLogProbMetric: 394.3562

Epoch 484: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.7030 - MinusLogProbMetric: 391.7030 - val_loss: 394.3562 - val_MinusLogProbMetric: 394.3562 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 485/1000
2023-09-10 06:59:16.401 
Epoch 485/1000 
	 loss: 392.3798, MinusLogProbMetric: 392.3798, val_loss: 394.9928, val_MinusLogProbMetric: 394.9928

Epoch 485: val_loss did not improve from 393.70700
196/196 - 16s - loss: 392.3798 - MinusLogProbMetric: 392.3798 - val_loss: 394.9928 - val_MinusLogProbMetric: 394.9928 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 486/1000
2023-09-10 06:59:31.869 
Epoch 486/1000 
	 loss: 391.8800, MinusLogProbMetric: 391.8800, val_loss: 395.3649, val_MinusLogProbMetric: 395.3649

Epoch 486: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.8800 - MinusLogProbMetric: 391.8800 - val_loss: 395.3649 - val_MinusLogProbMetric: 395.3649 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 487/1000
2023-09-10 06:59:46.695 
Epoch 487/1000 
	 loss: 392.0872, MinusLogProbMetric: 392.0872, val_loss: 395.1864, val_MinusLogProbMetric: 395.1864

Epoch 487: val_loss did not improve from 393.70700
196/196 - 15s - loss: 392.0872 - MinusLogProbMetric: 392.0872 - val_loss: 395.1864 - val_MinusLogProbMetric: 395.1864 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 488/1000
2023-09-10 07:00:02.850 
Epoch 488/1000 
	 loss: 391.6474, MinusLogProbMetric: 391.6474, val_loss: 394.2807, val_MinusLogProbMetric: 394.2807

Epoch 488: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.6474 - MinusLogProbMetric: 391.6474 - val_loss: 394.2807 - val_MinusLogProbMetric: 394.2807 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 489/1000
2023-09-10 07:00:19.407 
Epoch 489/1000 
	 loss: 391.8873, MinusLogProbMetric: 391.8873, val_loss: 393.7686, val_MinusLogProbMetric: 393.7686

Epoch 489: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.8873 - MinusLogProbMetric: 391.8873 - val_loss: 393.7686 - val_MinusLogProbMetric: 393.7686 - lr: 1.6667e-04 - 17s/epoch - 84ms/step
Epoch 490/1000
2023-09-10 07:00:35.859 
Epoch 490/1000 
	 loss: 391.8785, MinusLogProbMetric: 391.8785, val_loss: 395.6132, val_MinusLogProbMetric: 395.6132

Epoch 490: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.8785 - MinusLogProbMetric: 391.8785 - val_loss: 395.6132 - val_MinusLogProbMetric: 395.6132 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 491/1000
2023-09-10 07:00:51.277 
Epoch 491/1000 
	 loss: 391.9876, MinusLogProbMetric: 391.9876, val_loss: 395.2402, val_MinusLogProbMetric: 395.2402

Epoch 491: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.9876 - MinusLogProbMetric: 391.9876 - val_loss: 395.2402 - val_MinusLogProbMetric: 395.2402 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 492/1000
2023-09-10 07:01:07.771 
Epoch 492/1000 
	 loss: 391.7729, MinusLogProbMetric: 391.7729, val_loss: 394.0398, val_MinusLogProbMetric: 394.0398

Epoch 492: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.7729 - MinusLogProbMetric: 391.7729 - val_loss: 394.0398 - val_MinusLogProbMetric: 394.0398 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 493/1000
2023-09-10 07:01:22.784 
Epoch 493/1000 
	 loss: 391.7701, MinusLogProbMetric: 391.7701, val_loss: 396.9714, val_MinusLogProbMetric: 396.9714

Epoch 493: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.7701 - MinusLogProbMetric: 391.7701 - val_loss: 396.9714 - val_MinusLogProbMetric: 396.9714 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 494/1000
2023-09-10 07:01:38.536 
Epoch 494/1000 
	 loss: 391.9710, MinusLogProbMetric: 391.9710, val_loss: 395.7572, val_MinusLogProbMetric: 395.7572

Epoch 494: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.9710 - MinusLogProbMetric: 391.9710 - val_loss: 395.7572 - val_MinusLogProbMetric: 395.7572 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 495/1000
2023-09-10 07:01:54.255 
Epoch 495/1000 
	 loss: 391.9667, MinusLogProbMetric: 391.9667, val_loss: 394.9413, val_MinusLogProbMetric: 394.9413

Epoch 495: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.9667 - MinusLogProbMetric: 391.9667 - val_loss: 394.9413 - val_MinusLogProbMetric: 394.9413 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 496/1000
2023-09-10 07:02:10.659 
Epoch 496/1000 
	 loss: 391.6853, MinusLogProbMetric: 391.6853, val_loss: 393.8335, val_MinusLogProbMetric: 393.8335

Epoch 496: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.6853 - MinusLogProbMetric: 391.6853 - val_loss: 393.8335 - val_MinusLogProbMetric: 393.8335 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 497/1000
2023-09-10 07:02:25.524 
Epoch 497/1000 
	 loss: 391.8282, MinusLogProbMetric: 391.8282, val_loss: 394.6053, val_MinusLogProbMetric: 394.6053

Epoch 497: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.8282 - MinusLogProbMetric: 391.8282 - val_loss: 394.6053 - val_MinusLogProbMetric: 394.6053 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 498/1000
2023-09-10 07:02:42.153 
Epoch 498/1000 
	 loss: 392.0152, MinusLogProbMetric: 392.0152, val_loss: 395.4648, val_MinusLogProbMetric: 395.4648

Epoch 498: val_loss did not improve from 393.70700
196/196 - 17s - loss: 392.0152 - MinusLogProbMetric: 392.0152 - val_loss: 395.4648 - val_MinusLogProbMetric: 395.4648 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 499/1000
2023-09-10 07:02:58.326 
Epoch 499/1000 
	 loss: 391.7780, MinusLogProbMetric: 391.7780, val_loss: 394.0854, val_MinusLogProbMetric: 394.0854

Epoch 499: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.7780 - MinusLogProbMetric: 391.7780 - val_loss: 394.0854 - val_MinusLogProbMetric: 394.0854 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 500/1000
2023-09-10 07:03:14.029 
Epoch 500/1000 
	 loss: 391.6395, MinusLogProbMetric: 391.6395, val_loss: 395.2599, val_MinusLogProbMetric: 395.2599

Epoch 500: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.6395 - MinusLogProbMetric: 391.6395 - val_loss: 395.2599 - val_MinusLogProbMetric: 395.2599 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 501/1000
2023-09-10 07:03:29.125 
Epoch 501/1000 
	 loss: 391.6011, MinusLogProbMetric: 391.6011, val_loss: 393.8469, val_MinusLogProbMetric: 393.8469

Epoch 501: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.6011 - MinusLogProbMetric: 391.6011 - val_loss: 393.8469 - val_MinusLogProbMetric: 393.8469 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 502/1000
2023-09-10 07:03:46.207 
Epoch 502/1000 
	 loss: 391.8638, MinusLogProbMetric: 391.8638, val_loss: 393.7348, val_MinusLogProbMetric: 393.7348

Epoch 502: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.8638 - MinusLogProbMetric: 391.8638 - val_loss: 393.7348 - val_MinusLogProbMetric: 393.7348 - lr: 1.6667e-04 - 17s/epoch - 87ms/step
Epoch 503/1000
2023-09-10 07:04:00.927 
Epoch 503/1000 
	 loss: 392.0067, MinusLogProbMetric: 392.0067, val_loss: 394.1766, val_MinusLogProbMetric: 394.1766

Epoch 503: val_loss did not improve from 393.70700
196/196 - 15s - loss: 392.0067 - MinusLogProbMetric: 392.0067 - val_loss: 394.1766 - val_MinusLogProbMetric: 394.1766 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 504/1000
2023-09-10 07:04:16.355 
Epoch 504/1000 
	 loss: 391.9020, MinusLogProbMetric: 391.9020, val_loss: 394.2154, val_MinusLogProbMetric: 394.2154

Epoch 504: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.9020 - MinusLogProbMetric: 391.9020 - val_loss: 394.2154 - val_MinusLogProbMetric: 394.2154 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 505/1000
2023-09-10 07:04:31.784 
Epoch 505/1000 
	 loss: 391.4117, MinusLogProbMetric: 391.4117, val_loss: 393.7574, val_MinusLogProbMetric: 393.7574

Epoch 505: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.4117 - MinusLogProbMetric: 391.4117 - val_loss: 393.7574 - val_MinusLogProbMetric: 393.7574 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 506/1000
2023-09-10 07:04:47.525 
Epoch 506/1000 
	 loss: 392.2366, MinusLogProbMetric: 392.2366, val_loss: 394.5073, val_MinusLogProbMetric: 394.5073

Epoch 506: val_loss did not improve from 393.70700
196/196 - 16s - loss: 392.2366 - MinusLogProbMetric: 392.2366 - val_loss: 394.5073 - val_MinusLogProbMetric: 394.5073 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 507/1000
2023-09-10 07:05:02.893 
Epoch 507/1000 
	 loss: 391.7261, MinusLogProbMetric: 391.7261, val_loss: 394.7291, val_MinusLogProbMetric: 394.7291

Epoch 507: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.7261 - MinusLogProbMetric: 391.7261 - val_loss: 394.7291 - val_MinusLogProbMetric: 394.7291 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 508/1000
2023-09-10 07:05:17.383 
Epoch 508/1000 
	 loss: 391.7218, MinusLogProbMetric: 391.7218, val_loss: 393.7709, val_MinusLogProbMetric: 393.7709

Epoch 508: val_loss did not improve from 393.70700
196/196 - 14s - loss: 391.7218 - MinusLogProbMetric: 391.7218 - val_loss: 393.7709 - val_MinusLogProbMetric: 393.7709 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 509/1000
2023-09-10 07:05:32.506 
Epoch 509/1000 
	 loss: 391.4583, MinusLogProbMetric: 391.4583, val_loss: 394.0730, val_MinusLogProbMetric: 394.0730

Epoch 509: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.4583 - MinusLogProbMetric: 391.4583 - val_loss: 394.0730 - val_MinusLogProbMetric: 394.0730 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 510/1000
2023-09-10 07:05:48.757 
Epoch 510/1000 
	 loss: 391.6484, MinusLogProbMetric: 391.6484, val_loss: 395.5930, val_MinusLogProbMetric: 395.5930

Epoch 510: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.6484 - MinusLogProbMetric: 391.6484 - val_loss: 395.5930 - val_MinusLogProbMetric: 395.5930 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 511/1000
2023-09-10 07:06:04.092 
Epoch 511/1000 
	 loss: 392.5598, MinusLogProbMetric: 392.5598, val_loss: 398.1842, val_MinusLogProbMetric: 398.1842

Epoch 511: val_loss did not improve from 393.70700
196/196 - 15s - loss: 392.5598 - MinusLogProbMetric: 392.5598 - val_loss: 398.1842 - val_MinusLogProbMetric: 398.1842 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 512/1000
2023-09-10 07:06:20.883 
Epoch 512/1000 
	 loss: 391.8947, MinusLogProbMetric: 391.8947, val_loss: 394.5088, val_MinusLogProbMetric: 394.5088

Epoch 512: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.8947 - MinusLogProbMetric: 391.8947 - val_loss: 394.5088 - val_MinusLogProbMetric: 394.5088 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 513/1000
2023-09-10 07:06:37.621 
Epoch 513/1000 
	 loss: 391.7186, MinusLogProbMetric: 391.7186, val_loss: 394.1340, val_MinusLogProbMetric: 394.1340

Epoch 513: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.7186 - MinusLogProbMetric: 391.7186 - val_loss: 394.1340 - val_MinusLogProbMetric: 394.1340 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 514/1000
2023-09-10 07:06:55.264 
Epoch 514/1000 
	 loss: 391.5067, MinusLogProbMetric: 391.5067, val_loss: 394.5066, val_MinusLogProbMetric: 394.5066

Epoch 514: val_loss did not improve from 393.70700
196/196 - 18s - loss: 391.5067 - MinusLogProbMetric: 391.5067 - val_loss: 394.5066 - val_MinusLogProbMetric: 394.5066 - lr: 1.6667e-04 - 18s/epoch - 90ms/step
Epoch 515/1000
2023-09-10 07:07:11.029 
Epoch 515/1000 
	 loss: 391.5903, MinusLogProbMetric: 391.5903, val_loss: 394.3908, val_MinusLogProbMetric: 394.3908

Epoch 515: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.5903 - MinusLogProbMetric: 391.5903 - val_loss: 394.3908 - val_MinusLogProbMetric: 394.3908 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 516/1000
2023-09-10 07:07:27.294 
Epoch 516/1000 
	 loss: 391.7110, MinusLogProbMetric: 391.7110, val_loss: 403.4558, val_MinusLogProbMetric: 403.4558

Epoch 516: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.7110 - MinusLogProbMetric: 391.7110 - val_loss: 403.4558 - val_MinusLogProbMetric: 403.4558 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 517/1000
2023-09-10 07:07:43.571 
Epoch 517/1000 
	 loss: 392.2994, MinusLogProbMetric: 392.2994, val_loss: 398.7775, val_MinusLogProbMetric: 398.7775

Epoch 517: val_loss did not improve from 393.70700
196/196 - 16s - loss: 392.2994 - MinusLogProbMetric: 392.2994 - val_loss: 398.7775 - val_MinusLogProbMetric: 398.7775 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 518/1000
2023-09-10 07:08:00.844 
Epoch 518/1000 
	 loss: 391.7829, MinusLogProbMetric: 391.7829, val_loss: 394.2911, val_MinusLogProbMetric: 394.2911

Epoch 518: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.7829 - MinusLogProbMetric: 391.7829 - val_loss: 394.2911 - val_MinusLogProbMetric: 394.2911 - lr: 1.6667e-04 - 17s/epoch - 88ms/step
Epoch 519/1000
2023-09-10 07:08:17.029 
Epoch 519/1000 
	 loss: 391.3188, MinusLogProbMetric: 391.3188, val_loss: 393.9335, val_MinusLogProbMetric: 393.9335

Epoch 519: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.3188 - MinusLogProbMetric: 391.3188 - val_loss: 393.9335 - val_MinusLogProbMetric: 393.9335 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 520/1000
2023-09-10 07:08:33.665 
Epoch 520/1000 
	 loss: 391.7623, MinusLogProbMetric: 391.7623, val_loss: 393.9483, val_MinusLogProbMetric: 393.9483

Epoch 520: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.7623 - MinusLogProbMetric: 391.7623 - val_loss: 393.9483 - val_MinusLogProbMetric: 393.9483 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 521/1000
2023-09-10 07:08:49.526 
Epoch 521/1000 
	 loss: 391.4380, MinusLogProbMetric: 391.4380, val_loss: 393.9477, val_MinusLogProbMetric: 393.9477

Epoch 521: val_loss did not improve from 393.70700
196/196 - 16s - loss: 391.4380 - MinusLogProbMetric: 391.4380 - val_loss: 393.9477 - val_MinusLogProbMetric: 393.9477 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 522/1000
2023-09-10 07:09:06.283 
Epoch 522/1000 
	 loss: 391.9822, MinusLogProbMetric: 391.9822, val_loss: 395.5378, val_MinusLogProbMetric: 395.5378

Epoch 522: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.9822 - MinusLogProbMetric: 391.9822 - val_loss: 395.5378 - val_MinusLogProbMetric: 395.5378 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 523/1000
2023-09-10 07:09:23.152 
Epoch 523/1000 
	 loss: 391.4670, MinusLogProbMetric: 391.4670, val_loss: 395.1407, val_MinusLogProbMetric: 395.1407

Epoch 523: val_loss did not improve from 393.70700
196/196 - 17s - loss: 391.4670 - MinusLogProbMetric: 391.4670 - val_loss: 395.1407 - val_MinusLogProbMetric: 395.1407 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 524/1000
2023-09-10 07:09:40.688 
Epoch 524/1000 
	 loss: 391.7523, MinusLogProbMetric: 391.7523, val_loss: 394.1449, val_MinusLogProbMetric: 394.1449

Epoch 524: val_loss did not improve from 393.70700
196/196 - 18s - loss: 391.7523 - MinusLogProbMetric: 391.7523 - val_loss: 394.1449 - val_MinusLogProbMetric: 394.1449 - lr: 1.6667e-04 - 18s/epoch - 89ms/step
Epoch 525/1000
2023-09-10 07:09:55.870 
Epoch 525/1000 
	 loss: 391.5295, MinusLogProbMetric: 391.5295, val_loss: 394.6595, val_MinusLogProbMetric: 394.6595

Epoch 525: val_loss did not improve from 393.70700
196/196 - 15s - loss: 391.5295 - MinusLogProbMetric: 391.5295 - val_loss: 394.6595 - val_MinusLogProbMetric: 394.6595 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 526/1000
2023-09-10 07:10:08.796 
Epoch 526/1000 
	 loss: 391.3964, MinusLogProbMetric: 391.3964, val_loss: 395.0791, val_MinusLogProbMetric: 395.0791

Epoch 526: val_loss did not improve from 393.70700
196/196 - 13s - loss: 391.3964 - MinusLogProbMetric: 391.3964 - val_loss: 395.0791 - val_MinusLogProbMetric: 395.0791 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 527/1000
2023-09-10 07:10:23.512 
Epoch 527/1000 
	 loss: 392.0492, MinusLogProbMetric: 392.0492, val_loss: 394.8640, val_MinusLogProbMetric: 394.8640

Epoch 527: val_loss did not improve from 393.70700
196/196 - 15s - loss: 392.0492 - MinusLogProbMetric: 392.0492 - val_loss: 394.8640 - val_MinusLogProbMetric: 394.8640 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 528/1000
2023-09-10 07:10:37.622 
Epoch 528/1000 
	 loss: 391.8620, MinusLogProbMetric: 391.8620, val_loss: 404.8582, val_MinusLogProbMetric: 404.8582

Epoch 528: val_loss did not improve from 393.70700
196/196 - 14s - loss: 391.8620 - MinusLogProbMetric: 391.8620 - val_loss: 404.8582 - val_MinusLogProbMetric: 404.8582 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 529/1000
2023-09-10 07:10:49.629 
Epoch 529/1000 
	 loss: 391.6477, MinusLogProbMetric: 391.6477, val_loss: 393.7798, val_MinusLogProbMetric: 393.7798

Epoch 529: val_loss did not improve from 393.70700
196/196 - 12s - loss: 391.6477 - MinusLogProbMetric: 391.6477 - val_loss: 393.7798 - val_MinusLogProbMetric: 393.7798 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 530/1000
2023-09-10 07:11:04.116 
Epoch 530/1000 
	 loss: 391.5334, MinusLogProbMetric: 391.5334, val_loss: 393.7459, val_MinusLogProbMetric: 393.7459

Epoch 530: val_loss did not improve from 393.70700
196/196 - 14s - loss: 391.5334 - MinusLogProbMetric: 391.5334 - val_loss: 393.7459 - val_MinusLogProbMetric: 393.7459 - lr: 1.6667e-04 - 14s/epoch - 74ms/step
Epoch 531/1000
2023-09-10 07:11:17.782 
Epoch 531/1000 
	 loss: 389.6524, MinusLogProbMetric: 389.6524, val_loss: 392.7089, val_MinusLogProbMetric: 392.7089

Epoch 531: val_loss improved from 393.70700 to 392.70886, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 389.6524 - MinusLogProbMetric: 389.6524 - val_loss: 392.7089 - val_MinusLogProbMetric: 392.7089 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 532/1000
2023-09-10 07:11:31.438 
Epoch 532/1000 
	 loss: 389.5231, MinusLogProbMetric: 389.5231, val_loss: 392.8930, val_MinusLogProbMetric: 392.8930

Epoch 532: val_loss did not improve from 392.70886
196/196 - 13s - loss: 389.5231 - MinusLogProbMetric: 389.5231 - val_loss: 392.8930 - val_MinusLogProbMetric: 392.8930 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 533/1000
2023-09-10 07:11:45.417 
Epoch 533/1000 
	 loss: 389.4703, MinusLogProbMetric: 389.4703, val_loss: 393.1928, val_MinusLogProbMetric: 393.1928

Epoch 533: val_loss did not improve from 392.70886
196/196 - 14s - loss: 389.4703 - MinusLogProbMetric: 389.4703 - val_loss: 393.1928 - val_MinusLogProbMetric: 393.1928 - lr: 8.3333e-05 - 14s/epoch - 71ms/step
Epoch 534/1000
2023-09-10 07:11:57.783 
Epoch 534/1000 
	 loss: 389.4369, MinusLogProbMetric: 389.4369, val_loss: 392.4374, val_MinusLogProbMetric: 392.4374

Epoch 534: val_loss improved from 392.70886 to 392.43741, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 13s - loss: 389.4369 - MinusLogProbMetric: 389.4369 - val_loss: 392.4374 - val_MinusLogProbMetric: 392.4374 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 535/1000
2023-09-10 07:12:11.799 
Epoch 535/1000 
	 loss: 389.4725, MinusLogProbMetric: 389.4725, val_loss: 392.6101, val_MinusLogProbMetric: 392.6101

Epoch 535: val_loss did not improve from 392.43741
196/196 - 14s - loss: 389.4725 - MinusLogProbMetric: 389.4725 - val_loss: 392.6101 - val_MinusLogProbMetric: 392.6101 - lr: 8.3333e-05 - 14s/epoch - 69ms/step
Epoch 536/1000
2023-09-10 07:12:24.559 
Epoch 536/1000 
	 loss: 389.5466, MinusLogProbMetric: 389.5466, val_loss: 392.9689, val_MinusLogProbMetric: 392.9689

Epoch 536: val_loss did not improve from 392.43741
196/196 - 13s - loss: 389.5466 - MinusLogProbMetric: 389.5466 - val_loss: 392.9689 - val_MinusLogProbMetric: 392.9689 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 537/1000
2023-09-10 07:12:38.084 
Epoch 537/1000 
	 loss: 389.5536, MinusLogProbMetric: 389.5536, val_loss: 392.8170, val_MinusLogProbMetric: 392.8170

Epoch 537: val_loss did not improve from 392.43741
196/196 - 14s - loss: 389.5536 - MinusLogProbMetric: 389.5536 - val_loss: 392.8170 - val_MinusLogProbMetric: 392.8170 - lr: 8.3333e-05 - 14s/epoch - 69ms/step
Epoch 538/1000
2023-09-10 07:12:51.810 
Epoch 538/1000 
	 loss: 389.5121, MinusLogProbMetric: 389.5121, val_loss: 393.5041, val_MinusLogProbMetric: 393.5041

Epoch 538: val_loss did not improve from 392.43741
196/196 - 14s - loss: 389.5121 - MinusLogProbMetric: 389.5121 - val_loss: 393.5041 - val_MinusLogProbMetric: 393.5041 - lr: 8.3333e-05 - 14s/epoch - 70ms/step
Epoch 539/1000
2023-09-10 07:13:04.843 
Epoch 539/1000 
	 loss: 389.6643, MinusLogProbMetric: 389.6643, val_loss: 392.3799, val_MinusLogProbMetric: 392.3799

Epoch 539: val_loss improved from 392.43741 to 392.37985, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 389.6643 - MinusLogProbMetric: 389.6643 - val_loss: 392.3799 - val_MinusLogProbMetric: 392.3799 - lr: 8.3333e-05 - 14s/epoch - 69ms/step
Epoch 540/1000
2023-09-10 07:13:19.591 
Epoch 540/1000 
	 loss: 389.9610, MinusLogProbMetric: 389.9610, val_loss: 393.9331, val_MinusLogProbMetric: 393.9331

Epoch 540: val_loss did not improve from 392.37985
196/196 - 14s - loss: 389.9610 - MinusLogProbMetric: 389.9610 - val_loss: 393.9331 - val_MinusLogProbMetric: 393.9331 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 541/1000
2023-09-10 07:13:31.971 
Epoch 541/1000 
	 loss: 389.5144, MinusLogProbMetric: 389.5144, val_loss: 392.3812, val_MinusLogProbMetric: 392.3812

Epoch 541: val_loss did not improve from 392.37985
196/196 - 12s - loss: 389.5144 - MinusLogProbMetric: 389.5144 - val_loss: 392.3812 - val_MinusLogProbMetric: 392.3812 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 542/1000
2023-09-10 07:13:45.151 
Epoch 542/1000 
	 loss: 389.5887, MinusLogProbMetric: 389.5887, val_loss: 393.3094, val_MinusLogProbMetric: 393.3094

Epoch 542: val_loss did not improve from 392.37985
196/196 - 13s - loss: 389.5887 - MinusLogProbMetric: 389.5887 - val_loss: 393.3094 - val_MinusLogProbMetric: 393.3094 - lr: 8.3333e-05 - 13s/epoch - 67ms/step
Epoch 543/1000
2023-09-10 07:14:00.545 
Epoch 543/1000 
	 loss: 389.6277, MinusLogProbMetric: 389.6277, val_loss: 392.3846, val_MinusLogProbMetric: 392.3846

Epoch 543: val_loss did not improve from 392.37985
196/196 - 15s - loss: 389.6277 - MinusLogProbMetric: 389.6277 - val_loss: 392.3846 - val_MinusLogProbMetric: 392.3846 - lr: 8.3333e-05 - 15s/epoch - 79ms/step
Epoch 544/1000
2023-09-10 07:14:14.854 
Epoch 544/1000 
	 loss: 389.5444, MinusLogProbMetric: 389.5444, val_loss: 392.5125, val_MinusLogProbMetric: 392.5125

Epoch 544: val_loss did not improve from 392.37985
196/196 - 14s - loss: 389.5444 - MinusLogProbMetric: 389.5444 - val_loss: 392.5125 - val_MinusLogProbMetric: 392.5125 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 545/1000
2023-09-10 07:14:26.920 
Epoch 545/1000 
	 loss: 389.5446, MinusLogProbMetric: 389.5446, val_loss: 393.0323, val_MinusLogProbMetric: 393.0323

Epoch 545: val_loss did not improve from 392.37985
196/196 - 12s - loss: 389.5446 - MinusLogProbMetric: 389.5446 - val_loss: 393.0323 - val_MinusLogProbMetric: 393.0323 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 546/1000
2023-09-10 07:14:40.491 
Epoch 546/1000 
	 loss: 389.4792, MinusLogProbMetric: 389.4792, val_loss: 392.8983, val_MinusLogProbMetric: 392.8983

Epoch 546: val_loss did not improve from 392.37985
196/196 - 14s - loss: 389.4792 - MinusLogProbMetric: 389.4792 - val_loss: 392.8983 - val_MinusLogProbMetric: 392.8983 - lr: 8.3333e-05 - 14s/epoch - 69ms/step
Epoch 547/1000
2023-09-10 07:14:53.625 
Epoch 547/1000 
	 loss: 389.5038, MinusLogProbMetric: 389.5038, val_loss: 393.5321, val_MinusLogProbMetric: 393.5321

Epoch 547: val_loss did not improve from 392.37985
196/196 - 13s - loss: 389.5038 - MinusLogProbMetric: 389.5038 - val_loss: 393.5321 - val_MinusLogProbMetric: 393.5321 - lr: 8.3333e-05 - 13s/epoch - 67ms/step
Epoch 548/1000
2023-09-10 07:15:07.197 
Epoch 548/1000 
	 loss: 389.8752, MinusLogProbMetric: 389.8752, val_loss: 392.7201, val_MinusLogProbMetric: 392.7201

Epoch 548: val_loss did not improve from 392.37985
196/196 - 14s - loss: 389.8752 - MinusLogProbMetric: 389.8752 - val_loss: 392.7201 - val_MinusLogProbMetric: 392.7201 - lr: 8.3333e-05 - 14s/epoch - 69ms/step
Epoch 549/1000
2023-09-10 07:15:22.181 
Epoch 549/1000 
	 loss: 389.6317, MinusLogProbMetric: 389.6317, val_loss: 392.8846, val_MinusLogProbMetric: 392.8846

Epoch 549: val_loss did not improve from 392.37985
196/196 - 15s - loss: 389.6317 - MinusLogProbMetric: 389.6317 - val_loss: 392.8846 - val_MinusLogProbMetric: 392.8846 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 550/1000
2023-09-10 07:15:36.490 
Epoch 550/1000 
	 loss: 390.1427, MinusLogProbMetric: 390.1427, val_loss: 392.4761, val_MinusLogProbMetric: 392.4761

Epoch 550: val_loss did not improve from 392.37985
196/196 - 14s - loss: 390.1427 - MinusLogProbMetric: 390.1427 - val_loss: 392.4761 - val_MinusLogProbMetric: 392.4761 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 551/1000
2023-09-10 07:15:50.768 
Epoch 551/1000 
	 loss: 389.7479, MinusLogProbMetric: 389.7479, val_loss: 393.5325, val_MinusLogProbMetric: 393.5325

Epoch 551: val_loss did not improve from 392.37985
196/196 - 14s - loss: 389.7479 - MinusLogProbMetric: 389.7479 - val_loss: 393.5325 - val_MinusLogProbMetric: 393.5325 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 552/1000
2023-09-10 07:16:05.207 
Epoch 552/1000 
	 loss: 389.6510, MinusLogProbMetric: 389.6510, val_loss: 393.7814, val_MinusLogProbMetric: 393.7814

Epoch 552: val_loss did not improve from 392.37985
196/196 - 14s - loss: 389.6510 - MinusLogProbMetric: 389.6510 - val_loss: 393.7814 - val_MinusLogProbMetric: 393.7814 - lr: 8.3333e-05 - 14s/epoch - 74ms/step
Epoch 553/1000
2023-09-10 07:16:20.153 
Epoch 553/1000 
	 loss: 389.7561, MinusLogProbMetric: 389.7561, val_loss: 392.9421, val_MinusLogProbMetric: 392.9421

Epoch 553: val_loss did not improve from 392.37985
196/196 - 15s - loss: 389.7561 - MinusLogProbMetric: 389.7561 - val_loss: 392.9421 - val_MinusLogProbMetric: 392.9421 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 554/1000
2023-09-10 07:16:35.113 
Epoch 554/1000 
	 loss: 389.4792, MinusLogProbMetric: 389.4792, val_loss: 392.7607, val_MinusLogProbMetric: 392.7607

Epoch 554: val_loss did not improve from 392.37985
196/196 - 15s - loss: 389.4792 - MinusLogProbMetric: 389.4792 - val_loss: 392.7607 - val_MinusLogProbMetric: 392.7607 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 555/1000
2023-09-10 07:16:51.645 
Epoch 555/1000 
	 loss: 389.7828, MinusLogProbMetric: 389.7828, val_loss: 393.7601, val_MinusLogProbMetric: 393.7601

Epoch 555: val_loss did not improve from 392.37985
196/196 - 17s - loss: 389.7828 - MinusLogProbMetric: 389.7828 - val_loss: 393.7601 - val_MinusLogProbMetric: 393.7601 - lr: 8.3333e-05 - 17s/epoch - 84ms/step
Epoch 556/1000
2023-09-10 07:17:06.630 
Epoch 556/1000 
	 loss: 389.5070, MinusLogProbMetric: 389.5070, val_loss: 392.8014, val_MinusLogProbMetric: 392.8014

Epoch 556: val_loss did not improve from 392.37985
196/196 - 15s - loss: 389.5070 - MinusLogProbMetric: 389.5070 - val_loss: 392.8014 - val_MinusLogProbMetric: 392.8014 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 557/1000
2023-09-10 07:17:21.220 
Epoch 557/1000 
	 loss: 389.7015, MinusLogProbMetric: 389.7015, val_loss: 393.5497, val_MinusLogProbMetric: 393.5497

Epoch 557: val_loss did not improve from 392.37985
196/196 - 15s - loss: 389.7015 - MinusLogProbMetric: 389.7015 - val_loss: 393.5497 - val_MinusLogProbMetric: 393.5497 - lr: 8.3333e-05 - 15s/epoch - 74ms/step
Epoch 558/1000
2023-09-10 07:17:37.359 
Epoch 558/1000 
	 loss: 390.2199, MinusLogProbMetric: 390.2199, val_loss: 392.7476, val_MinusLogProbMetric: 392.7476

Epoch 558: val_loss did not improve from 392.37985
196/196 - 16s - loss: 390.2199 - MinusLogProbMetric: 390.2199 - val_loss: 392.7476 - val_MinusLogProbMetric: 392.7476 - lr: 8.3333e-05 - 16s/epoch - 82ms/step
Epoch 559/1000
2023-09-10 07:17:52.817 
Epoch 559/1000 
	 loss: 389.4552, MinusLogProbMetric: 389.4552, val_loss: 393.3169, val_MinusLogProbMetric: 393.3169

Epoch 559: val_loss did not improve from 392.37985
196/196 - 15s - loss: 389.4552 - MinusLogProbMetric: 389.4552 - val_loss: 393.3169 - val_MinusLogProbMetric: 393.3169 - lr: 8.3333e-05 - 15s/epoch - 79ms/step
Epoch 560/1000
2023-09-10 07:18:08.418 
Epoch 560/1000 
	 loss: 389.3738, MinusLogProbMetric: 389.3738, val_loss: 393.4874, val_MinusLogProbMetric: 393.4874

Epoch 560: val_loss did not improve from 392.37985
196/196 - 16s - loss: 389.3738 - MinusLogProbMetric: 389.3738 - val_loss: 393.4874 - val_MinusLogProbMetric: 393.4874 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 561/1000
2023-09-10 07:18:24.682 
Epoch 561/1000 
	 loss: 389.7525, MinusLogProbMetric: 389.7525, val_loss: 392.7727, val_MinusLogProbMetric: 392.7727

Epoch 561: val_loss did not improve from 392.37985
196/196 - 16s - loss: 389.7525 - MinusLogProbMetric: 389.7525 - val_loss: 392.7727 - val_MinusLogProbMetric: 392.7727 - lr: 8.3333e-05 - 16s/epoch - 83ms/step
Epoch 562/1000
2023-09-10 07:18:38.687 
Epoch 562/1000 
	 loss: 389.4780, MinusLogProbMetric: 389.4780, val_loss: 392.1360, val_MinusLogProbMetric: 392.1360

Epoch 562: val_loss improved from 392.37985 to 392.13605, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 389.4780 - MinusLogProbMetric: 389.4780 - val_loss: 392.1360 - val_MinusLogProbMetric: 392.1360 - lr: 8.3333e-05 - 14s/epoch - 74ms/step
Epoch 563/1000
2023-09-10 07:18:53.992 
Epoch 563/1000 
	 loss: 389.7487, MinusLogProbMetric: 389.7487, val_loss: 392.5408, val_MinusLogProbMetric: 392.5408

Epoch 563: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.7487 - MinusLogProbMetric: 389.7487 - val_loss: 392.5408 - val_MinusLogProbMetric: 392.5408 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 564/1000
2023-09-10 07:19:09.332 
Epoch 564/1000 
	 loss: 389.6227, MinusLogProbMetric: 389.6227, val_loss: 395.1667, val_MinusLogProbMetric: 395.1667

Epoch 564: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.6227 - MinusLogProbMetric: 389.6227 - val_loss: 395.1667 - val_MinusLogProbMetric: 395.1667 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 565/1000
2023-09-10 07:19:24.629 
Epoch 565/1000 
	 loss: 389.8091, MinusLogProbMetric: 389.8091, val_loss: 392.2813, val_MinusLogProbMetric: 392.2813

Epoch 565: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.8091 - MinusLogProbMetric: 389.8091 - val_loss: 392.2813 - val_MinusLogProbMetric: 392.2813 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 566/1000
2023-09-10 07:19:39.340 
Epoch 566/1000 
	 loss: 389.5609, MinusLogProbMetric: 389.5609, val_loss: 393.7081, val_MinusLogProbMetric: 393.7081

Epoch 566: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.5609 - MinusLogProbMetric: 389.5609 - val_loss: 393.7081 - val_MinusLogProbMetric: 393.7081 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 567/1000
2023-09-10 07:19:54.372 
Epoch 567/1000 
	 loss: 389.6317, MinusLogProbMetric: 389.6317, val_loss: 392.6053, val_MinusLogProbMetric: 392.6053

Epoch 567: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.6317 - MinusLogProbMetric: 389.6317 - val_loss: 392.6053 - val_MinusLogProbMetric: 392.6053 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 568/1000
2023-09-10 07:20:09.969 
Epoch 568/1000 
	 loss: 389.4805, MinusLogProbMetric: 389.4805, val_loss: 392.8556, val_MinusLogProbMetric: 392.8556

Epoch 568: val_loss did not improve from 392.13605
196/196 - 16s - loss: 389.4805 - MinusLogProbMetric: 389.4805 - val_loss: 392.8556 - val_MinusLogProbMetric: 392.8556 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 569/1000
2023-09-10 07:20:26.067 
Epoch 569/1000 
	 loss: 389.5738, MinusLogProbMetric: 389.5738, val_loss: 392.9629, val_MinusLogProbMetric: 392.9629

Epoch 569: val_loss did not improve from 392.13605
196/196 - 16s - loss: 389.5738 - MinusLogProbMetric: 389.5738 - val_loss: 392.9629 - val_MinusLogProbMetric: 392.9629 - lr: 8.3333e-05 - 16s/epoch - 82ms/step
Epoch 570/1000
2023-09-10 07:20:42.461 
Epoch 570/1000 
	 loss: 389.6949, MinusLogProbMetric: 389.6949, val_loss: 393.1877, val_MinusLogProbMetric: 393.1877

Epoch 570: val_loss did not improve from 392.13605
196/196 - 16s - loss: 389.6949 - MinusLogProbMetric: 389.6949 - val_loss: 393.1877 - val_MinusLogProbMetric: 393.1877 - lr: 8.3333e-05 - 16s/epoch - 84ms/step
Epoch 571/1000
2023-09-10 07:20:59.006 
Epoch 571/1000 
	 loss: 389.4342, MinusLogProbMetric: 389.4342, val_loss: 392.2731, val_MinusLogProbMetric: 392.2731

Epoch 571: val_loss did not improve from 392.13605
196/196 - 17s - loss: 389.4342 - MinusLogProbMetric: 389.4342 - val_loss: 392.2731 - val_MinusLogProbMetric: 392.2731 - lr: 8.3333e-05 - 17s/epoch - 84ms/step
Epoch 572/1000
2023-09-10 07:21:13.804 
Epoch 572/1000 
	 loss: 389.3523, MinusLogProbMetric: 389.3523, val_loss: 392.8364, val_MinusLogProbMetric: 392.8364

Epoch 572: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.3523 - MinusLogProbMetric: 389.3523 - val_loss: 392.8364 - val_MinusLogProbMetric: 392.8364 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 573/1000
2023-09-10 07:21:29.592 
Epoch 573/1000 
	 loss: 389.6372, MinusLogProbMetric: 389.6372, val_loss: 392.3236, val_MinusLogProbMetric: 392.3236

Epoch 573: val_loss did not improve from 392.13605
196/196 - 16s - loss: 389.6372 - MinusLogProbMetric: 389.6372 - val_loss: 392.3236 - val_MinusLogProbMetric: 392.3236 - lr: 8.3333e-05 - 16s/epoch - 81ms/step
Epoch 574/1000
2023-09-10 07:21:48.090 
Epoch 574/1000 
	 loss: 389.6159, MinusLogProbMetric: 389.6159, val_loss: 392.5105, val_MinusLogProbMetric: 392.5105

Epoch 574: val_loss did not improve from 392.13605
196/196 - 18s - loss: 389.6159 - MinusLogProbMetric: 389.6159 - val_loss: 392.5105 - val_MinusLogProbMetric: 392.5105 - lr: 8.3333e-05 - 18s/epoch - 94ms/step
Epoch 575/1000
2023-09-10 07:22:06.732 
Epoch 575/1000 
	 loss: 390.1966, MinusLogProbMetric: 390.1966, val_loss: 393.1842, val_MinusLogProbMetric: 393.1842

Epoch 575: val_loss did not improve from 392.13605
196/196 - 19s - loss: 390.1966 - MinusLogProbMetric: 390.1966 - val_loss: 393.1842 - val_MinusLogProbMetric: 393.1842 - lr: 8.3333e-05 - 19s/epoch - 95ms/step
Epoch 576/1000
2023-09-10 07:22:21.577 
Epoch 576/1000 
	 loss: 389.3078, MinusLogProbMetric: 389.3078, val_loss: 393.8770, val_MinusLogProbMetric: 393.8770

Epoch 576: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.3078 - MinusLogProbMetric: 389.3078 - val_loss: 393.8770 - val_MinusLogProbMetric: 393.8770 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 577/1000
2023-09-10 07:22:37.615 
Epoch 577/1000 
	 loss: 389.4073, MinusLogProbMetric: 389.4073, val_loss: 392.7688, val_MinusLogProbMetric: 392.7688

Epoch 577: val_loss did not improve from 392.13605
196/196 - 16s - loss: 389.4073 - MinusLogProbMetric: 389.4073 - val_loss: 392.7688 - val_MinusLogProbMetric: 392.7688 - lr: 8.3333e-05 - 16s/epoch - 82ms/step
Epoch 578/1000
2023-09-10 07:22:52.993 
Epoch 578/1000 
	 loss: 389.2855, MinusLogProbMetric: 389.2855, val_loss: 393.4676, val_MinusLogProbMetric: 393.4676

Epoch 578: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.2855 - MinusLogProbMetric: 389.2855 - val_loss: 393.4676 - val_MinusLogProbMetric: 393.4676 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 579/1000
2023-09-10 07:23:07.616 
Epoch 579/1000 
	 loss: 389.3468, MinusLogProbMetric: 389.3468, val_loss: 392.8252, val_MinusLogProbMetric: 392.8252

Epoch 579: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.3468 - MinusLogProbMetric: 389.3468 - val_loss: 392.8252 - val_MinusLogProbMetric: 392.8252 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 580/1000
2023-09-10 07:23:22.823 
Epoch 580/1000 
	 loss: 389.7047, MinusLogProbMetric: 389.7047, val_loss: 392.9191, val_MinusLogProbMetric: 392.9191

Epoch 580: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.7047 - MinusLogProbMetric: 389.7047 - val_loss: 392.9191 - val_MinusLogProbMetric: 392.9191 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 581/1000
2023-09-10 07:23:38.647 
Epoch 581/1000 
	 loss: 389.5480, MinusLogProbMetric: 389.5480, val_loss: 392.9536, val_MinusLogProbMetric: 392.9536

Epoch 581: val_loss did not improve from 392.13605
196/196 - 16s - loss: 389.5480 - MinusLogProbMetric: 389.5480 - val_loss: 392.9536 - val_MinusLogProbMetric: 392.9536 - lr: 8.3333e-05 - 16s/epoch - 81ms/step
Epoch 582/1000
2023-09-10 07:23:54.011 
Epoch 582/1000 
	 loss: 389.2849, MinusLogProbMetric: 389.2849, val_loss: 392.1899, val_MinusLogProbMetric: 392.1899

Epoch 582: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.2849 - MinusLogProbMetric: 389.2849 - val_loss: 392.1899 - val_MinusLogProbMetric: 392.1899 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 583/1000
2023-09-10 07:24:08.829 
Epoch 583/1000 
	 loss: 389.3857, MinusLogProbMetric: 389.3857, val_loss: 393.1498, val_MinusLogProbMetric: 393.1498

Epoch 583: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.3857 - MinusLogProbMetric: 389.3857 - val_loss: 393.1498 - val_MinusLogProbMetric: 393.1498 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 584/1000
2023-09-10 07:24:24.214 
Epoch 584/1000 
	 loss: 389.8289, MinusLogProbMetric: 389.8289, val_loss: 395.2208, val_MinusLogProbMetric: 395.2208

Epoch 584: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.8289 - MinusLogProbMetric: 389.8289 - val_loss: 395.2208 - val_MinusLogProbMetric: 395.2208 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 585/1000
2023-09-10 07:24:39.978 
Epoch 585/1000 
	 loss: 389.6654, MinusLogProbMetric: 389.6654, val_loss: 392.9436, val_MinusLogProbMetric: 392.9436

Epoch 585: val_loss did not improve from 392.13605
196/196 - 16s - loss: 389.6654 - MinusLogProbMetric: 389.6654 - val_loss: 392.9436 - val_MinusLogProbMetric: 392.9436 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 586/1000
2023-09-10 07:24:54.389 
Epoch 586/1000 
	 loss: 389.4820, MinusLogProbMetric: 389.4820, val_loss: 392.3002, val_MinusLogProbMetric: 392.3002

Epoch 586: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.4820 - MinusLogProbMetric: 389.4820 - val_loss: 392.3002 - val_MinusLogProbMetric: 392.3002 - lr: 8.3333e-05 - 14s/epoch - 74ms/step
Epoch 587/1000
2023-09-10 07:25:09.165 
Epoch 587/1000 
	 loss: 389.3955, MinusLogProbMetric: 389.3955, val_loss: 393.3392, val_MinusLogProbMetric: 393.3392

Epoch 587: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.3955 - MinusLogProbMetric: 389.3955 - val_loss: 393.3392 - val_MinusLogProbMetric: 393.3392 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 588/1000
2023-09-10 07:25:24.256 
Epoch 588/1000 
	 loss: 389.5401, MinusLogProbMetric: 389.5401, val_loss: 392.5285, val_MinusLogProbMetric: 392.5285

Epoch 588: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.5401 - MinusLogProbMetric: 389.5401 - val_loss: 392.5285 - val_MinusLogProbMetric: 392.5285 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 589/1000
2023-09-10 07:25:41.225 
Epoch 589/1000 
	 loss: 389.1793, MinusLogProbMetric: 389.1793, val_loss: 392.9064, val_MinusLogProbMetric: 392.9064

Epoch 589: val_loss did not improve from 392.13605
196/196 - 17s - loss: 389.1793 - MinusLogProbMetric: 389.1793 - val_loss: 392.9064 - val_MinusLogProbMetric: 392.9064 - lr: 8.3333e-05 - 17s/epoch - 87ms/step
Epoch 590/1000
2023-09-10 07:25:59.467 
Epoch 590/1000 
	 loss: 389.4606, MinusLogProbMetric: 389.4606, val_loss: 392.8728, val_MinusLogProbMetric: 392.8728

Epoch 590: val_loss did not improve from 392.13605
196/196 - 18s - loss: 389.4606 - MinusLogProbMetric: 389.4606 - val_loss: 392.8728 - val_MinusLogProbMetric: 392.8728 - lr: 8.3333e-05 - 18s/epoch - 93ms/step
Epoch 591/1000
2023-09-10 07:26:16.655 
Epoch 591/1000 
	 loss: 389.3940, MinusLogProbMetric: 389.3940, val_loss: 393.1851, val_MinusLogProbMetric: 393.1851

Epoch 591: val_loss did not improve from 392.13605
196/196 - 17s - loss: 389.3940 - MinusLogProbMetric: 389.3940 - val_loss: 393.1851 - val_MinusLogProbMetric: 393.1851 - lr: 8.3333e-05 - 17s/epoch - 88ms/step
Epoch 592/1000
2023-09-10 07:26:31.533 
Epoch 592/1000 
	 loss: 389.2841, MinusLogProbMetric: 389.2841, val_loss: 392.7275, val_MinusLogProbMetric: 392.7275

Epoch 592: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.2841 - MinusLogProbMetric: 389.2841 - val_loss: 392.7275 - val_MinusLogProbMetric: 392.7275 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 593/1000
2023-09-10 07:26:46.491 
Epoch 593/1000 
	 loss: 389.5856, MinusLogProbMetric: 389.5856, val_loss: 392.6370, val_MinusLogProbMetric: 392.6370

Epoch 593: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.5856 - MinusLogProbMetric: 389.5856 - val_loss: 392.6370 - val_MinusLogProbMetric: 392.6370 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 594/1000
2023-09-10 07:27:01.258 
Epoch 594/1000 
	 loss: 389.9416, MinusLogProbMetric: 389.9416, val_loss: 394.0473, val_MinusLogProbMetric: 394.0473

Epoch 594: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.9416 - MinusLogProbMetric: 389.9416 - val_loss: 394.0473 - val_MinusLogProbMetric: 394.0473 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 595/1000
2023-09-10 07:27:15.712 
Epoch 595/1000 
	 loss: 389.3181, MinusLogProbMetric: 389.3181, val_loss: 392.6678, val_MinusLogProbMetric: 392.6678

Epoch 595: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.3181 - MinusLogProbMetric: 389.3181 - val_loss: 392.6678 - val_MinusLogProbMetric: 392.6678 - lr: 8.3333e-05 - 14s/epoch - 74ms/step
Epoch 596/1000
2023-09-10 07:27:28.726 
Epoch 596/1000 
	 loss: 389.2742, MinusLogProbMetric: 389.2742, val_loss: 393.4761, val_MinusLogProbMetric: 393.4761

Epoch 596: val_loss did not improve from 392.13605
196/196 - 13s - loss: 389.2742 - MinusLogProbMetric: 389.2742 - val_loss: 393.4761 - val_MinusLogProbMetric: 393.4761 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 597/1000
2023-09-10 07:27:43.610 
Epoch 597/1000 
	 loss: 389.3771, MinusLogProbMetric: 389.3771, val_loss: 392.8797, val_MinusLogProbMetric: 392.8797

Epoch 597: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.3771 - MinusLogProbMetric: 389.3771 - val_loss: 392.8797 - val_MinusLogProbMetric: 392.8797 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 598/1000
2023-09-10 07:27:57.456 
Epoch 598/1000 
	 loss: 389.5866, MinusLogProbMetric: 389.5866, val_loss: 392.7237, val_MinusLogProbMetric: 392.7237

Epoch 598: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.5866 - MinusLogProbMetric: 389.5866 - val_loss: 392.7237 - val_MinusLogProbMetric: 392.7237 - lr: 8.3333e-05 - 14s/epoch - 71ms/step
Epoch 599/1000
2023-09-10 07:28:10.404 
Epoch 599/1000 
	 loss: 389.3967, MinusLogProbMetric: 389.3967, val_loss: 392.6697, val_MinusLogProbMetric: 392.6697

Epoch 599: val_loss did not improve from 392.13605
196/196 - 13s - loss: 389.3967 - MinusLogProbMetric: 389.3967 - val_loss: 392.6697 - val_MinusLogProbMetric: 392.6697 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 600/1000
2023-09-10 07:28:24.483 
Epoch 600/1000 
	 loss: 389.4258, MinusLogProbMetric: 389.4258, val_loss: 394.0465, val_MinusLogProbMetric: 394.0465

Epoch 600: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.4258 - MinusLogProbMetric: 389.4258 - val_loss: 394.0465 - val_MinusLogProbMetric: 394.0465 - lr: 8.3333e-05 - 14s/epoch - 72ms/step
Epoch 601/1000
2023-09-10 07:28:37.630 
Epoch 601/1000 
	 loss: 389.5785, MinusLogProbMetric: 389.5785, val_loss: 393.0497, val_MinusLogProbMetric: 393.0497

Epoch 601: val_loss did not improve from 392.13605
196/196 - 13s - loss: 389.5785 - MinusLogProbMetric: 389.5785 - val_loss: 393.0497 - val_MinusLogProbMetric: 393.0497 - lr: 8.3333e-05 - 13s/epoch - 67ms/step
Epoch 602/1000
2023-09-10 07:28:50.685 
Epoch 602/1000 
	 loss: 389.7864, MinusLogProbMetric: 389.7864, val_loss: 392.4012, val_MinusLogProbMetric: 392.4012

Epoch 602: val_loss did not improve from 392.13605
196/196 - 13s - loss: 389.7864 - MinusLogProbMetric: 389.7864 - val_loss: 392.4012 - val_MinusLogProbMetric: 392.4012 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 603/1000
2023-09-10 07:29:04.564 
Epoch 603/1000 
	 loss: 389.3368, MinusLogProbMetric: 389.3368, val_loss: 393.7782, val_MinusLogProbMetric: 393.7782

Epoch 603: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.3368 - MinusLogProbMetric: 389.3368 - val_loss: 393.7782 - val_MinusLogProbMetric: 393.7782 - lr: 8.3333e-05 - 14s/epoch - 71ms/step
Epoch 604/1000
2023-09-10 07:29:19.679 
Epoch 604/1000 
	 loss: 389.3196, MinusLogProbMetric: 389.3196, val_loss: 392.5089, val_MinusLogProbMetric: 392.5089

Epoch 604: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.3196 - MinusLogProbMetric: 389.3196 - val_loss: 392.5089 - val_MinusLogProbMetric: 392.5089 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 605/1000
2023-09-10 07:29:33.915 
Epoch 605/1000 
	 loss: 389.4223, MinusLogProbMetric: 389.4223, val_loss: 393.3573, val_MinusLogProbMetric: 393.3573

Epoch 605: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.4223 - MinusLogProbMetric: 389.4223 - val_loss: 393.3573 - val_MinusLogProbMetric: 393.3573 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 606/1000
2023-09-10 07:29:48.931 
Epoch 606/1000 
	 loss: 389.5706, MinusLogProbMetric: 389.5706, val_loss: 392.8531, val_MinusLogProbMetric: 392.8531

Epoch 606: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.5706 - MinusLogProbMetric: 389.5706 - val_loss: 392.8531 - val_MinusLogProbMetric: 392.8531 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 607/1000
2023-09-10 07:30:03.688 
Epoch 607/1000 
	 loss: 389.4437, MinusLogProbMetric: 389.4437, val_loss: 393.8615, val_MinusLogProbMetric: 393.8615

Epoch 607: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.4437 - MinusLogProbMetric: 389.4437 - val_loss: 393.8615 - val_MinusLogProbMetric: 393.8615 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 608/1000
2023-09-10 07:30:21.012 
Epoch 608/1000 
	 loss: 389.7296, MinusLogProbMetric: 389.7296, val_loss: 392.6065, val_MinusLogProbMetric: 392.6065

Epoch 608: val_loss did not improve from 392.13605
196/196 - 17s - loss: 389.7296 - MinusLogProbMetric: 389.7296 - val_loss: 392.6065 - val_MinusLogProbMetric: 392.6065 - lr: 8.3333e-05 - 17s/epoch - 88ms/step
Epoch 609/1000
2023-09-10 07:30:35.677 
Epoch 609/1000 
	 loss: 389.4937, MinusLogProbMetric: 389.4937, val_loss: 392.9879, val_MinusLogProbMetric: 392.9879

Epoch 609: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.4937 - MinusLogProbMetric: 389.4937 - val_loss: 392.9879 - val_MinusLogProbMetric: 392.9879 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 610/1000
2023-09-10 07:30:49.784 
Epoch 610/1000 
	 loss: 389.8912, MinusLogProbMetric: 389.8912, val_loss: 392.8498, val_MinusLogProbMetric: 392.8498

Epoch 610: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.8912 - MinusLogProbMetric: 389.8912 - val_loss: 392.8498 - val_MinusLogProbMetric: 392.8498 - lr: 8.3333e-05 - 14s/epoch - 72ms/step
Epoch 611/1000
2023-09-10 07:31:05.284 
Epoch 611/1000 
	 loss: 389.8020, MinusLogProbMetric: 389.8020, val_loss: 393.2804, val_MinusLogProbMetric: 393.2804

Epoch 611: val_loss did not improve from 392.13605
196/196 - 15s - loss: 389.8020 - MinusLogProbMetric: 389.8020 - val_loss: 393.2804 - val_MinusLogProbMetric: 393.2804 - lr: 8.3333e-05 - 15s/epoch - 79ms/step
Epoch 612/1000
2023-09-10 07:31:19.448 
Epoch 612/1000 
	 loss: 389.4614, MinusLogProbMetric: 389.4614, val_loss: 393.4379, val_MinusLogProbMetric: 393.4379

Epoch 612: val_loss did not improve from 392.13605
196/196 - 14s - loss: 389.4614 - MinusLogProbMetric: 389.4614 - val_loss: 393.4379 - val_MinusLogProbMetric: 393.4379 - lr: 8.3333e-05 - 14s/epoch - 72ms/step
Epoch 613/1000
2023-09-10 07:31:34.028 
Epoch 613/1000 
	 loss: 388.5762, MinusLogProbMetric: 388.5762, val_loss: 392.4069, val_MinusLogProbMetric: 392.4069

Epoch 613: val_loss did not improve from 392.13605
196/196 - 15s - loss: 388.5762 - MinusLogProbMetric: 388.5762 - val_loss: 392.4069 - val_MinusLogProbMetric: 392.4069 - lr: 4.1667e-05 - 15s/epoch - 74ms/step
Epoch 614/1000
2023-09-10 07:31:49.665 
Epoch 614/1000 
	 loss: 388.5949, MinusLogProbMetric: 388.5949, val_loss: 392.3514, val_MinusLogProbMetric: 392.3514

Epoch 614: val_loss did not improve from 392.13605
196/196 - 16s - loss: 388.5949 - MinusLogProbMetric: 388.5949 - val_loss: 392.3514 - val_MinusLogProbMetric: 392.3514 - lr: 4.1667e-05 - 16s/epoch - 80ms/step
Epoch 615/1000
2023-09-10 07:32:04.260 
Epoch 615/1000 
	 loss: 388.5059, MinusLogProbMetric: 388.5059, val_loss: 392.1862, val_MinusLogProbMetric: 392.1862

Epoch 615: val_loss did not improve from 392.13605
196/196 - 15s - loss: 388.5059 - MinusLogProbMetric: 388.5059 - val_loss: 392.1862 - val_MinusLogProbMetric: 392.1862 - lr: 4.1667e-05 - 15s/epoch - 74ms/step
Epoch 616/1000
2023-09-10 07:32:17.257 
Epoch 616/1000 
	 loss: 388.4951, MinusLogProbMetric: 388.4951, val_loss: 392.0734, val_MinusLogProbMetric: 392.0734

Epoch 616: val_loss improved from 392.13605 to 392.07343, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 388.4951 - MinusLogProbMetric: 388.4951 - val_loss: 392.0734 - val_MinusLogProbMetric: 392.0734 - lr: 4.1667e-05 - 14s/epoch - 71ms/step
Epoch 617/1000
2023-09-10 07:32:31.578 
Epoch 617/1000 
	 loss: 388.5358, MinusLogProbMetric: 388.5358, val_loss: 391.9670, val_MinusLogProbMetric: 391.9670

Epoch 617: val_loss improved from 392.07343 to 391.96704, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 388.5358 - MinusLogProbMetric: 388.5358 - val_loss: 391.9670 - val_MinusLogProbMetric: 391.9670 - lr: 4.1667e-05 - 14s/epoch - 71ms/step
Epoch 618/1000
2023-09-10 07:32:46.144 
Epoch 618/1000 
	 loss: 388.5053, MinusLogProbMetric: 388.5053, val_loss: 392.8177, val_MinusLogProbMetric: 392.8177

Epoch 618: val_loss did not improve from 391.96704
196/196 - 14s - loss: 388.5053 - MinusLogProbMetric: 388.5053 - val_loss: 392.8177 - val_MinusLogProbMetric: 392.8177 - lr: 4.1667e-05 - 14s/epoch - 72ms/step
Epoch 619/1000
2023-09-10 07:33:01.123 
Epoch 619/1000 
	 loss: 388.5128, MinusLogProbMetric: 388.5128, val_loss: 391.9373, val_MinusLogProbMetric: 391.9373

Epoch 619: val_loss improved from 391.96704 to 391.93729, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 16s - loss: 388.5128 - MinusLogProbMetric: 388.5128 - val_loss: 391.9373 - val_MinusLogProbMetric: 391.9373 - lr: 4.1667e-05 - 16s/epoch - 79ms/step
Epoch 620/1000
2023-09-10 07:33:15.438 
Epoch 620/1000 
	 loss: 388.4825, MinusLogProbMetric: 388.4825, val_loss: 392.0022, val_MinusLogProbMetric: 392.0022

Epoch 620: val_loss did not improve from 391.93729
196/196 - 14s - loss: 388.4825 - MinusLogProbMetric: 388.4825 - val_loss: 392.0022 - val_MinusLogProbMetric: 392.0022 - lr: 4.1667e-05 - 14s/epoch - 70ms/step
Epoch 621/1000
2023-09-10 07:33:29.600 
Epoch 621/1000 
	 loss: 388.4297, MinusLogProbMetric: 388.4297, val_loss: 391.7535, val_MinusLogProbMetric: 391.7535

Epoch 621: val_loss improved from 391.93729 to 391.75354, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 388.4297 - MinusLogProbMetric: 388.4297 - val_loss: 391.7535 - val_MinusLogProbMetric: 391.7535 - lr: 4.1667e-05 - 15s/epoch - 75ms/step
Epoch 622/1000
2023-09-10 07:33:43.845 
Epoch 622/1000 
	 loss: 388.4048, MinusLogProbMetric: 388.4048, val_loss: 391.8726, val_MinusLogProbMetric: 391.8726

Epoch 622: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4048 - MinusLogProbMetric: 388.4048 - val_loss: 391.8726 - val_MinusLogProbMetric: 391.8726 - lr: 4.1667e-05 - 14s/epoch - 70ms/step
Epoch 623/1000
2023-09-10 07:33:58.896 
Epoch 623/1000 
	 loss: 388.4073, MinusLogProbMetric: 388.4073, val_loss: 392.1751, val_MinusLogProbMetric: 392.1751

Epoch 623: val_loss did not improve from 391.75354
196/196 - 15s - loss: 388.4073 - MinusLogProbMetric: 388.4073 - val_loss: 392.1751 - val_MinusLogProbMetric: 392.1751 - lr: 4.1667e-05 - 15s/epoch - 77ms/step
Epoch 624/1000
2023-09-10 07:34:12.582 
Epoch 624/1000 
	 loss: 388.4261, MinusLogProbMetric: 388.4261, val_loss: 392.1012, val_MinusLogProbMetric: 392.1012

Epoch 624: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4261 - MinusLogProbMetric: 388.4261 - val_loss: 392.1012 - val_MinusLogProbMetric: 392.1012 - lr: 4.1667e-05 - 14s/epoch - 70ms/step
Epoch 625/1000
2023-09-10 07:34:28.845 
Epoch 625/1000 
	 loss: 388.3495, MinusLogProbMetric: 388.3495, val_loss: 391.9477, val_MinusLogProbMetric: 391.9477

Epoch 625: val_loss did not improve from 391.75354
196/196 - 16s - loss: 388.3495 - MinusLogProbMetric: 388.3495 - val_loss: 391.9477 - val_MinusLogProbMetric: 391.9477 - lr: 4.1667e-05 - 16s/epoch - 83ms/step
Epoch 626/1000
2023-09-10 07:34:42.869 
Epoch 626/1000 
	 loss: 388.4207, MinusLogProbMetric: 388.4207, val_loss: 392.0125, val_MinusLogProbMetric: 392.0125

Epoch 626: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4207 - MinusLogProbMetric: 388.4207 - val_loss: 392.0125 - val_MinusLogProbMetric: 392.0125 - lr: 4.1667e-05 - 14s/epoch - 72ms/step
Epoch 627/1000
2023-09-10 07:34:56.247 
Epoch 627/1000 
	 loss: 388.3383, MinusLogProbMetric: 388.3383, val_loss: 392.6324, val_MinusLogProbMetric: 392.6324

Epoch 627: val_loss did not improve from 391.75354
196/196 - 13s - loss: 388.3383 - MinusLogProbMetric: 388.3383 - val_loss: 392.6324 - val_MinusLogProbMetric: 392.6324 - lr: 4.1667e-05 - 13s/epoch - 68ms/step
Epoch 628/1000
2023-09-10 07:35:10.654 
Epoch 628/1000 
	 loss: 388.4130, MinusLogProbMetric: 388.4130, val_loss: 392.2662, val_MinusLogProbMetric: 392.2662

Epoch 628: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4130 - MinusLogProbMetric: 388.4130 - val_loss: 392.2662 - val_MinusLogProbMetric: 392.2662 - lr: 4.1667e-05 - 14s/epoch - 74ms/step
Epoch 629/1000
2023-09-10 07:35:25.177 
Epoch 629/1000 
	 loss: 388.4337, MinusLogProbMetric: 388.4337, val_loss: 392.1042, val_MinusLogProbMetric: 392.1042

Epoch 629: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4337 - MinusLogProbMetric: 388.4337 - val_loss: 392.1042 - val_MinusLogProbMetric: 392.1042 - lr: 4.1667e-05 - 14s/epoch - 74ms/step
Epoch 630/1000
2023-09-10 07:35:40.574 
Epoch 630/1000 
	 loss: 388.4587, MinusLogProbMetric: 388.4587, val_loss: 392.0919, val_MinusLogProbMetric: 392.0919

Epoch 630: val_loss did not improve from 391.75354
196/196 - 15s - loss: 388.4587 - MinusLogProbMetric: 388.4587 - val_loss: 392.0919 - val_MinusLogProbMetric: 392.0919 - lr: 4.1667e-05 - 15s/epoch - 79ms/step
Epoch 631/1000
2023-09-10 07:35:54.597 
Epoch 631/1000 
	 loss: 388.4313, MinusLogProbMetric: 388.4313, val_loss: 392.2252, val_MinusLogProbMetric: 392.2252

Epoch 631: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4313 - MinusLogProbMetric: 388.4313 - val_loss: 392.2252 - val_MinusLogProbMetric: 392.2252 - lr: 4.1667e-05 - 14s/epoch - 72ms/step
Epoch 632/1000
2023-09-10 07:36:08.621 
Epoch 632/1000 
	 loss: 388.4154, MinusLogProbMetric: 388.4154, val_loss: 392.2467, val_MinusLogProbMetric: 392.2467

Epoch 632: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4154 - MinusLogProbMetric: 388.4154 - val_loss: 392.2467 - val_MinusLogProbMetric: 392.2467 - lr: 4.1667e-05 - 14s/epoch - 71ms/step
Epoch 633/1000
2023-09-10 07:36:22.935 
Epoch 633/1000 
	 loss: 388.5548, MinusLogProbMetric: 388.5548, val_loss: 391.9562, val_MinusLogProbMetric: 391.9562

Epoch 633: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.5548 - MinusLogProbMetric: 388.5548 - val_loss: 391.9562 - val_MinusLogProbMetric: 391.9562 - lr: 4.1667e-05 - 14s/epoch - 73ms/step
Epoch 634/1000
2023-09-10 07:36:36.638 
Epoch 634/1000 
	 loss: 388.4821, MinusLogProbMetric: 388.4821, val_loss: 391.9303, val_MinusLogProbMetric: 391.9303

Epoch 634: val_loss did not improve from 391.75354
196/196 - 14s - loss: 388.4821 - MinusLogProbMetric: 388.4821 - val_loss: 391.9303 - val_MinusLogProbMetric: 391.9303 - lr: 4.1667e-05 - 14s/epoch - 70ms/step
Epoch 635/1000
2023-09-10 07:36:49.703 
Epoch 635/1000 
	 loss: 388.4453, MinusLogProbMetric: 388.4453, val_loss: 391.7498, val_MinusLogProbMetric: 391.7498

Epoch 635: val_loss improved from 391.75354 to 391.74976, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 14s - loss: 388.4453 - MinusLogProbMetric: 388.4453 - val_loss: 391.7498 - val_MinusLogProbMetric: 391.7498 - lr: 4.1667e-05 - 14s/epoch - 69ms/step
Epoch 636/1000
2023-09-10 07:37:04.652 
Epoch 636/1000 
	 loss: 388.4406, MinusLogProbMetric: 388.4406, val_loss: 391.9846, val_MinusLogProbMetric: 391.9846

Epoch 636: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.4406 - MinusLogProbMetric: 388.4406 - val_loss: 391.9846 - val_MinusLogProbMetric: 391.9846 - lr: 4.1667e-05 - 14s/epoch - 74ms/step
Epoch 637/1000
2023-09-10 07:37:18.851 
Epoch 637/1000 
	 loss: 388.3796, MinusLogProbMetric: 388.3796, val_loss: 392.3799, val_MinusLogProbMetric: 392.3799

Epoch 637: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.3796 - MinusLogProbMetric: 388.3796 - val_loss: 392.3799 - val_MinusLogProbMetric: 392.3799 - lr: 4.1667e-05 - 14s/epoch - 72ms/step
Epoch 638/1000
2023-09-10 07:37:32.174 
Epoch 638/1000 
	 loss: 388.4017, MinusLogProbMetric: 388.4017, val_loss: 392.2971, val_MinusLogProbMetric: 392.2971

Epoch 638: val_loss did not improve from 391.74976
196/196 - 13s - loss: 388.4017 - MinusLogProbMetric: 388.4017 - val_loss: 392.2971 - val_MinusLogProbMetric: 392.2971 - lr: 4.1667e-05 - 13s/epoch - 68ms/step
Epoch 639/1000
2023-09-10 07:37:46.056 
Epoch 639/1000 
	 loss: 388.3788, MinusLogProbMetric: 388.3788, val_loss: 392.5092, val_MinusLogProbMetric: 392.5092

Epoch 639: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.3788 - MinusLogProbMetric: 388.3788 - val_loss: 392.5092 - val_MinusLogProbMetric: 392.5092 - lr: 4.1667e-05 - 14s/epoch - 71ms/step
Epoch 640/1000
2023-09-10 07:37:58.926 
Epoch 640/1000 
	 loss: 388.4555, MinusLogProbMetric: 388.4555, val_loss: 392.0756, val_MinusLogProbMetric: 392.0756

Epoch 640: val_loss did not improve from 391.74976
196/196 - 13s - loss: 388.4555 - MinusLogProbMetric: 388.4555 - val_loss: 392.0756 - val_MinusLogProbMetric: 392.0756 - lr: 4.1667e-05 - 13s/epoch - 66ms/step
Epoch 641/1000
2023-09-10 07:38:13.332 
Epoch 641/1000 
	 loss: 388.4003, MinusLogProbMetric: 388.4003, val_loss: 392.1291, val_MinusLogProbMetric: 392.1291

Epoch 641: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.4003 - MinusLogProbMetric: 388.4003 - val_loss: 392.1291 - val_MinusLogProbMetric: 392.1291 - lr: 4.1667e-05 - 14s/epoch - 73ms/step
Epoch 642/1000
2023-09-10 07:38:28.760 
Epoch 642/1000 
	 loss: 388.3499, MinusLogProbMetric: 388.3499, val_loss: 392.1785, val_MinusLogProbMetric: 392.1785

Epoch 642: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.3499 - MinusLogProbMetric: 388.3499 - val_loss: 392.1785 - val_MinusLogProbMetric: 392.1785 - lr: 4.1667e-05 - 15s/epoch - 79ms/step
Epoch 643/1000
2023-09-10 07:38:43.164 
Epoch 643/1000 
	 loss: 388.4231, MinusLogProbMetric: 388.4231, val_loss: 392.3250, val_MinusLogProbMetric: 392.3250

Epoch 643: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.4231 - MinusLogProbMetric: 388.4231 - val_loss: 392.3250 - val_MinusLogProbMetric: 392.3250 - lr: 4.1667e-05 - 14s/epoch - 73ms/step
Epoch 644/1000
2023-09-10 07:38:57.523 
Epoch 644/1000 
	 loss: 388.4919, MinusLogProbMetric: 388.4919, val_loss: 391.8801, val_MinusLogProbMetric: 391.8801

Epoch 644: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.4919 - MinusLogProbMetric: 388.4919 - val_loss: 391.8801 - val_MinusLogProbMetric: 391.8801 - lr: 4.1667e-05 - 14s/epoch - 73ms/step
Epoch 645/1000
2023-09-10 07:39:12.189 
Epoch 645/1000 
	 loss: 388.3795, MinusLogProbMetric: 388.3795, val_loss: 392.8540, val_MinusLogProbMetric: 392.8540

Epoch 645: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.3795 - MinusLogProbMetric: 388.3795 - val_loss: 392.8540 - val_MinusLogProbMetric: 392.8540 - lr: 4.1667e-05 - 15s/epoch - 75ms/step
Epoch 646/1000
2023-09-10 07:39:25.856 
Epoch 646/1000 
	 loss: 388.3996, MinusLogProbMetric: 388.3996, val_loss: 392.2189, val_MinusLogProbMetric: 392.2189

Epoch 646: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.3996 - MinusLogProbMetric: 388.3996 - val_loss: 392.2189 - val_MinusLogProbMetric: 392.2189 - lr: 4.1667e-05 - 14s/epoch - 70ms/step
Epoch 647/1000
2023-09-10 07:39:38.212 
Epoch 647/1000 
	 loss: 388.3963, MinusLogProbMetric: 388.3963, val_loss: 392.4581, val_MinusLogProbMetric: 392.4581

Epoch 647: val_loss did not improve from 391.74976
196/196 - 12s - loss: 388.3963 - MinusLogProbMetric: 388.3963 - val_loss: 392.4581 - val_MinusLogProbMetric: 392.4581 - lr: 4.1667e-05 - 12s/epoch - 63ms/step
Epoch 648/1000
2023-09-10 07:39:51.991 
Epoch 648/1000 
	 loss: 388.3544, MinusLogProbMetric: 388.3544, val_loss: 391.9276, val_MinusLogProbMetric: 391.9276

Epoch 648: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.3544 - MinusLogProbMetric: 388.3544 - val_loss: 391.9276 - val_MinusLogProbMetric: 391.9276 - lr: 4.1667e-05 - 14s/epoch - 70ms/step
Epoch 649/1000
2023-09-10 07:40:05.068 
Epoch 649/1000 
	 loss: 388.4581, MinusLogProbMetric: 388.4581, val_loss: 392.0163, val_MinusLogProbMetric: 392.0163

Epoch 649: val_loss did not improve from 391.74976
196/196 - 13s - loss: 388.4581 - MinusLogProbMetric: 388.4581 - val_loss: 392.0163 - val_MinusLogProbMetric: 392.0163 - lr: 4.1667e-05 - 13s/epoch - 67ms/step
Epoch 650/1000
2023-09-10 07:40:20.181 
Epoch 650/1000 
	 loss: 388.2863, MinusLogProbMetric: 388.2863, val_loss: 392.1938, val_MinusLogProbMetric: 392.1938

Epoch 650: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.2863 - MinusLogProbMetric: 388.2863 - val_loss: 392.1938 - val_MinusLogProbMetric: 392.1938 - lr: 4.1667e-05 - 15s/epoch - 77ms/step
Epoch 651/1000
2023-09-10 07:40:36.755 
Epoch 651/1000 
	 loss: 388.3296, MinusLogProbMetric: 388.3296, val_loss: 392.0712, val_MinusLogProbMetric: 392.0712

Epoch 651: val_loss did not improve from 391.74976
196/196 - 17s - loss: 388.3296 - MinusLogProbMetric: 388.3296 - val_loss: 392.0712 - val_MinusLogProbMetric: 392.0712 - lr: 4.1667e-05 - 17s/epoch - 85ms/step
Epoch 652/1000
2023-09-10 07:40:51.574 
Epoch 652/1000 
	 loss: 388.3566, MinusLogProbMetric: 388.3566, val_loss: 392.2622, val_MinusLogProbMetric: 392.2622

Epoch 652: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.3566 - MinusLogProbMetric: 388.3566 - val_loss: 392.2622 - val_MinusLogProbMetric: 392.2622 - lr: 4.1667e-05 - 15s/epoch - 76ms/step
Epoch 653/1000
2023-09-10 07:41:06.871 
Epoch 653/1000 
	 loss: 388.4337, MinusLogProbMetric: 388.4337, val_loss: 392.4782, val_MinusLogProbMetric: 392.4782

Epoch 653: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.4337 - MinusLogProbMetric: 388.4337 - val_loss: 392.4782 - val_MinusLogProbMetric: 392.4782 - lr: 4.1667e-05 - 15s/epoch - 78ms/step
Epoch 654/1000
2023-09-10 07:41:21.955 
Epoch 654/1000 
	 loss: 388.5420, MinusLogProbMetric: 388.5420, val_loss: 392.1117, val_MinusLogProbMetric: 392.1117

Epoch 654: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.5420 - MinusLogProbMetric: 388.5420 - val_loss: 392.1117 - val_MinusLogProbMetric: 392.1117 - lr: 4.1667e-05 - 15s/epoch - 77ms/step
Epoch 655/1000
2023-09-10 07:41:37.904 
Epoch 655/1000 
	 loss: 388.4446, MinusLogProbMetric: 388.4446, val_loss: 392.3005, val_MinusLogProbMetric: 392.3005

Epoch 655: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.4446 - MinusLogProbMetric: 388.4446 - val_loss: 392.3005 - val_MinusLogProbMetric: 392.3005 - lr: 4.1667e-05 - 16s/epoch - 81ms/step
Epoch 656/1000
2023-09-10 07:41:55.502 
Epoch 656/1000 
	 loss: 388.4806, MinusLogProbMetric: 388.4806, val_loss: 391.9834, val_MinusLogProbMetric: 391.9834

Epoch 656: val_loss did not improve from 391.74976
196/196 - 18s - loss: 388.4806 - MinusLogProbMetric: 388.4806 - val_loss: 391.9834 - val_MinusLogProbMetric: 391.9834 - lr: 4.1667e-05 - 18s/epoch - 90ms/step
Epoch 657/1000
2023-09-10 07:42:11.913 
Epoch 657/1000 
	 loss: 388.4532, MinusLogProbMetric: 388.4532, val_loss: 392.0388, val_MinusLogProbMetric: 392.0388

Epoch 657: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.4532 - MinusLogProbMetric: 388.4532 - val_loss: 392.0388 - val_MinusLogProbMetric: 392.0388 - lr: 4.1667e-05 - 16s/epoch - 84ms/step
Epoch 658/1000
2023-09-10 07:42:26.784 
Epoch 658/1000 
	 loss: 388.5708, MinusLogProbMetric: 388.5708, val_loss: 392.9245, val_MinusLogProbMetric: 392.9245

Epoch 658: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.5708 - MinusLogProbMetric: 388.5708 - val_loss: 392.9245 - val_MinusLogProbMetric: 392.9245 - lr: 4.1667e-05 - 15s/epoch - 76ms/step
Epoch 659/1000
2023-09-10 07:42:42.923 
Epoch 659/1000 
	 loss: 388.5522, MinusLogProbMetric: 388.5522, val_loss: 392.2895, val_MinusLogProbMetric: 392.2895

Epoch 659: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.5522 - MinusLogProbMetric: 388.5522 - val_loss: 392.2895 - val_MinusLogProbMetric: 392.2895 - lr: 4.1667e-05 - 16s/epoch - 82ms/step
Epoch 660/1000
2023-09-10 07:42:58.836 
Epoch 660/1000 
	 loss: 388.5139, MinusLogProbMetric: 388.5139, val_loss: 392.4804, val_MinusLogProbMetric: 392.4804

Epoch 660: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.5139 - MinusLogProbMetric: 388.5139 - val_loss: 392.4804 - val_MinusLogProbMetric: 392.4804 - lr: 4.1667e-05 - 16s/epoch - 81ms/step
Epoch 661/1000
2023-09-10 07:43:15.400 
Epoch 661/1000 
	 loss: 388.4610, MinusLogProbMetric: 388.4610, val_loss: 392.3673, val_MinusLogProbMetric: 392.3673

Epoch 661: val_loss did not improve from 391.74976
196/196 - 17s - loss: 388.4610 - MinusLogProbMetric: 388.4610 - val_loss: 392.3673 - val_MinusLogProbMetric: 392.3673 - lr: 4.1667e-05 - 17s/epoch - 84ms/step
Epoch 662/1000
2023-09-10 07:43:32.251 
Epoch 662/1000 
	 loss: 388.3692, MinusLogProbMetric: 388.3692, val_loss: 392.2905, val_MinusLogProbMetric: 392.2905

Epoch 662: val_loss did not improve from 391.74976
196/196 - 17s - loss: 388.3692 - MinusLogProbMetric: 388.3692 - val_loss: 392.2905 - val_MinusLogProbMetric: 392.2905 - lr: 4.1667e-05 - 17s/epoch - 86ms/step
Epoch 663/1000
2023-09-10 07:43:47.940 
Epoch 663/1000 
	 loss: 388.4404, MinusLogProbMetric: 388.4404, val_loss: 392.2702, val_MinusLogProbMetric: 392.2702

Epoch 663: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.4404 - MinusLogProbMetric: 388.4404 - val_loss: 392.2702 - val_MinusLogProbMetric: 392.2702 - lr: 4.1667e-05 - 16s/epoch - 80ms/step
Epoch 664/1000
2023-09-10 07:44:02.977 
Epoch 664/1000 
	 loss: 388.3169, MinusLogProbMetric: 388.3169, val_loss: 391.9610, val_MinusLogProbMetric: 391.9610

Epoch 664: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.3169 - MinusLogProbMetric: 388.3169 - val_loss: 391.9610 - val_MinusLogProbMetric: 391.9610 - lr: 4.1667e-05 - 15s/epoch - 77ms/step
Epoch 665/1000
2023-09-10 07:44:18.007 
Epoch 665/1000 
	 loss: 388.3856, MinusLogProbMetric: 388.3856, val_loss: 392.5800, val_MinusLogProbMetric: 392.5800

Epoch 665: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.3856 - MinusLogProbMetric: 388.3856 - val_loss: 392.5800 - val_MinusLogProbMetric: 392.5800 - lr: 4.1667e-05 - 15s/epoch - 77ms/step
Epoch 666/1000
2023-09-10 07:44:33.677 
Epoch 666/1000 
	 loss: 388.5818, MinusLogProbMetric: 388.5818, val_loss: 392.6363, val_MinusLogProbMetric: 392.6363

Epoch 666: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.5818 - MinusLogProbMetric: 388.5818 - val_loss: 392.6363 - val_MinusLogProbMetric: 392.6363 - lr: 4.1667e-05 - 16s/epoch - 80ms/step
Epoch 667/1000
2023-09-10 07:44:51.578 
Epoch 667/1000 
	 loss: 388.3511, MinusLogProbMetric: 388.3511, val_loss: 392.5638, val_MinusLogProbMetric: 392.5638

Epoch 667: val_loss did not improve from 391.74976
196/196 - 18s - loss: 388.3511 - MinusLogProbMetric: 388.3511 - val_loss: 392.5638 - val_MinusLogProbMetric: 392.5638 - lr: 4.1667e-05 - 18s/epoch - 91ms/step
Epoch 668/1000
2023-09-10 07:45:07.773 
Epoch 668/1000 
	 loss: 388.3950, MinusLogProbMetric: 388.3950, val_loss: 392.6595, val_MinusLogProbMetric: 392.6595

Epoch 668: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.3950 - MinusLogProbMetric: 388.3950 - val_loss: 392.6595 - val_MinusLogProbMetric: 392.6595 - lr: 4.1667e-05 - 16s/epoch - 83ms/step
Epoch 669/1000
2023-09-10 07:45:23.243 
Epoch 669/1000 
	 loss: 388.4745, MinusLogProbMetric: 388.4745, val_loss: 392.9111, val_MinusLogProbMetric: 392.9111

Epoch 669: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.4745 - MinusLogProbMetric: 388.4745 - val_loss: 392.9111 - val_MinusLogProbMetric: 392.9111 - lr: 4.1667e-05 - 15s/epoch - 79ms/step
Epoch 670/1000
2023-09-10 07:45:38.573 
Epoch 670/1000 
	 loss: 388.7927, MinusLogProbMetric: 388.7927, val_loss: 391.9144, val_MinusLogProbMetric: 391.9144

Epoch 670: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.7927 - MinusLogProbMetric: 388.7927 - val_loss: 391.9144 - val_MinusLogProbMetric: 391.9144 - lr: 4.1667e-05 - 15s/epoch - 78ms/step
Epoch 671/1000
2023-09-10 07:45:54.626 
Epoch 671/1000 
	 loss: 388.3792, MinusLogProbMetric: 388.3792, val_loss: 391.8868, val_MinusLogProbMetric: 391.8868

Epoch 671: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.3792 - MinusLogProbMetric: 388.3792 - val_loss: 391.8868 - val_MinusLogProbMetric: 391.8868 - lr: 4.1667e-05 - 16s/epoch - 82ms/step
Epoch 672/1000
2023-09-10 07:46:09.850 
Epoch 672/1000 
	 loss: 388.3268, MinusLogProbMetric: 388.3268, val_loss: 392.3611, val_MinusLogProbMetric: 392.3611

Epoch 672: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.3268 - MinusLogProbMetric: 388.3268 - val_loss: 392.3611 - val_MinusLogProbMetric: 392.3611 - lr: 4.1667e-05 - 15s/epoch - 78ms/step
Epoch 673/1000
2023-09-10 07:46:23.905 
Epoch 673/1000 
	 loss: 388.3084, MinusLogProbMetric: 388.3084, val_loss: 392.2567, val_MinusLogProbMetric: 392.2567

Epoch 673: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.3084 - MinusLogProbMetric: 388.3084 - val_loss: 392.2567 - val_MinusLogProbMetric: 392.2567 - lr: 4.1667e-05 - 14s/epoch - 72ms/step
Epoch 674/1000
2023-09-10 07:46:38.030 
Epoch 674/1000 
	 loss: 388.3386, MinusLogProbMetric: 388.3386, val_loss: 391.7546, val_MinusLogProbMetric: 391.7546

Epoch 674: val_loss did not improve from 391.74976
196/196 - 14s - loss: 388.3386 - MinusLogProbMetric: 388.3386 - val_loss: 391.7546 - val_MinusLogProbMetric: 391.7546 - lr: 4.1667e-05 - 14s/epoch - 72ms/step
Epoch 675/1000
2023-09-10 07:46:52.992 
Epoch 675/1000 
	 loss: 388.2938, MinusLogProbMetric: 388.2938, val_loss: 392.3108, val_MinusLogProbMetric: 392.3108

Epoch 675: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.2938 - MinusLogProbMetric: 388.2938 - val_loss: 392.3108 - val_MinusLogProbMetric: 392.3108 - lr: 4.1667e-05 - 15s/epoch - 76ms/step
Epoch 676/1000
2023-09-10 07:47:08.852 
Epoch 676/1000 
	 loss: 388.5193, MinusLogProbMetric: 388.5193, val_loss: 392.1231, val_MinusLogProbMetric: 392.1231

Epoch 676: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.5193 - MinusLogProbMetric: 388.5193 - val_loss: 392.1231 - val_MinusLogProbMetric: 392.1231 - lr: 4.1667e-05 - 16s/epoch - 81ms/step
Epoch 677/1000
2023-09-10 07:47:26.704 
Epoch 677/1000 
	 loss: 388.2691, MinusLogProbMetric: 388.2691, val_loss: 392.1133, val_MinusLogProbMetric: 392.1133

Epoch 677: val_loss did not improve from 391.74976
196/196 - 18s - loss: 388.2691 - MinusLogProbMetric: 388.2691 - val_loss: 392.1133 - val_MinusLogProbMetric: 392.1133 - lr: 4.1667e-05 - 18s/epoch - 91ms/step
Epoch 678/1000
2023-09-10 07:47:42.148 
Epoch 678/1000 
	 loss: 388.2443, MinusLogProbMetric: 388.2443, val_loss: 392.6001, val_MinusLogProbMetric: 392.6001

Epoch 678: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.2443 - MinusLogProbMetric: 388.2443 - val_loss: 392.6001 - val_MinusLogProbMetric: 392.6001 - lr: 4.1667e-05 - 15s/epoch - 79ms/step
Epoch 679/1000
2023-09-10 07:47:58.226 
Epoch 679/1000 
	 loss: 388.3059, MinusLogProbMetric: 388.3059, val_loss: 391.9759, val_MinusLogProbMetric: 391.9759

Epoch 679: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.3059 - MinusLogProbMetric: 388.3059 - val_loss: 391.9759 - val_MinusLogProbMetric: 391.9759 - lr: 4.1667e-05 - 16s/epoch - 82ms/step
Epoch 680/1000
2023-09-10 07:48:13.265 
Epoch 680/1000 
	 loss: 388.3037, MinusLogProbMetric: 388.3037, val_loss: 392.0233, val_MinusLogProbMetric: 392.0233

Epoch 680: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.3037 - MinusLogProbMetric: 388.3037 - val_loss: 392.0233 - val_MinusLogProbMetric: 392.0233 - lr: 4.1667e-05 - 15s/epoch - 77ms/step
Epoch 681/1000
2023-09-10 07:48:29.507 
Epoch 681/1000 
	 loss: 388.2173, MinusLogProbMetric: 388.2173, val_loss: 391.9859, val_MinusLogProbMetric: 391.9859

Epoch 681: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.2173 - MinusLogProbMetric: 388.2173 - val_loss: 391.9859 - val_MinusLogProbMetric: 391.9859 - lr: 4.1667e-05 - 16s/epoch - 83ms/step
Epoch 682/1000
2023-09-10 07:48:45.112 
Epoch 682/1000 
	 loss: 388.3987, MinusLogProbMetric: 388.3987, val_loss: 392.3043, val_MinusLogProbMetric: 392.3043

Epoch 682: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.3987 - MinusLogProbMetric: 388.3987 - val_loss: 392.3043 - val_MinusLogProbMetric: 392.3043 - lr: 4.1667e-05 - 16s/epoch - 79ms/step
Epoch 683/1000
2023-09-10 07:49:00.645 
Epoch 683/1000 
	 loss: 388.2970, MinusLogProbMetric: 388.2970, val_loss: 392.5142, val_MinusLogProbMetric: 392.5142

Epoch 683: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.2970 - MinusLogProbMetric: 388.2970 - val_loss: 392.5142 - val_MinusLogProbMetric: 392.5142 - lr: 4.1667e-05 - 16s/epoch - 79ms/step
Epoch 684/1000
2023-09-10 07:49:15.829 
Epoch 684/1000 
	 loss: 388.2896, MinusLogProbMetric: 388.2896, val_loss: 392.0405, val_MinusLogProbMetric: 392.0405

Epoch 684: val_loss did not improve from 391.74976
196/196 - 15s - loss: 388.2896 - MinusLogProbMetric: 388.2896 - val_loss: 392.0405 - val_MinusLogProbMetric: 392.0405 - lr: 4.1667e-05 - 15s/epoch - 77ms/step
Epoch 685/1000
2023-09-10 07:49:31.590 
Epoch 685/1000 
	 loss: 388.3129, MinusLogProbMetric: 388.3129, val_loss: 392.3823, val_MinusLogProbMetric: 392.3823

Epoch 685: val_loss did not improve from 391.74976
196/196 - 16s - loss: 388.3129 - MinusLogProbMetric: 388.3129 - val_loss: 392.3823 - val_MinusLogProbMetric: 392.3823 - lr: 4.1667e-05 - 16s/epoch - 80ms/step
Epoch 686/1000
2023-09-10 07:49:46.336 
Epoch 686/1000 
	 loss: 387.9216, MinusLogProbMetric: 387.9216, val_loss: 391.9443, val_MinusLogProbMetric: 391.9443

Epoch 686: val_loss did not improve from 391.74976
196/196 - 15s - loss: 387.9216 - MinusLogProbMetric: 387.9216 - val_loss: 391.9443 - val_MinusLogProbMetric: 391.9443 - lr: 2.0833e-05 - 15s/epoch - 75ms/step
Epoch 687/1000
2023-09-10 07:50:01.225 
Epoch 687/1000 
	 loss: 387.9108, MinusLogProbMetric: 387.9108, val_loss: 391.6246, val_MinusLogProbMetric: 391.6246

Epoch 687: val_loss improved from 391.74976 to 391.62463, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 15s - loss: 387.9108 - MinusLogProbMetric: 387.9108 - val_loss: 391.6246 - val_MinusLogProbMetric: 391.6246 - lr: 2.0833e-05 - 15s/epoch - 79ms/step
Epoch 688/1000
2023-09-10 07:50:14.853 
Epoch 688/1000 
	 loss: 387.8916, MinusLogProbMetric: 387.8916, val_loss: 391.8554, val_MinusLogProbMetric: 391.8554

Epoch 688: val_loss did not improve from 391.62463
196/196 - 13s - loss: 387.8916 - MinusLogProbMetric: 387.8916 - val_loss: 391.8554 - val_MinusLogProbMetric: 391.8554 - lr: 2.0833e-05 - 13s/epoch - 67ms/step
Epoch 689/1000
2023-09-10 07:50:29.852 
Epoch 689/1000 
	 loss: 387.9021, MinusLogProbMetric: 387.9021, val_loss: 391.8544, val_MinusLogProbMetric: 391.8544

Epoch 689: val_loss did not improve from 391.62463
196/196 - 15s - loss: 387.9021 - MinusLogProbMetric: 387.9021 - val_loss: 391.8544 - val_MinusLogProbMetric: 391.8544 - lr: 2.0833e-05 - 15s/epoch - 77ms/step
Epoch 690/1000
2023-09-10 07:50:46.687 
Epoch 690/1000 
	 loss: 387.9203, MinusLogProbMetric: 387.9203, val_loss: 391.9158, val_MinusLogProbMetric: 391.9158

Epoch 690: val_loss did not improve from 391.62463
196/196 - 17s - loss: 387.9203 - MinusLogProbMetric: 387.9203 - val_loss: 391.9158 - val_MinusLogProbMetric: 391.9158 - lr: 2.0833e-05 - 17s/epoch - 86ms/step
Epoch 691/1000
2023-09-10 07:51:02.163 
Epoch 691/1000 
	 loss: 387.9402, MinusLogProbMetric: 387.9402, val_loss: 391.9680, val_MinusLogProbMetric: 391.9680

Epoch 691: val_loss did not improve from 391.62463
196/196 - 15s - loss: 387.9402 - MinusLogProbMetric: 387.9402 - val_loss: 391.9680 - val_MinusLogProbMetric: 391.9680 - lr: 2.0833e-05 - 15s/epoch - 79ms/step
Epoch 692/1000
2023-09-10 07:51:20.615 
Epoch 692/1000 
	 loss: 387.9329, MinusLogProbMetric: 387.9329, val_loss: 391.5879, val_MinusLogProbMetric: 391.5879

Epoch 692: val_loss improved from 391.62463 to 391.58792, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 387.9329 - MinusLogProbMetric: 387.9329 - val_loss: 391.5879 - val_MinusLogProbMetric: 391.5879 - lr: 2.0833e-05 - 19s/epoch - 97ms/step
Epoch 693/1000
2023-09-10 07:51:36.813 
Epoch 693/1000 
	 loss: 387.9232, MinusLogProbMetric: 387.9232, val_loss: 391.7540, val_MinusLogProbMetric: 391.7540

Epoch 693: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9232 - MinusLogProbMetric: 387.9232 - val_loss: 391.7540 - val_MinusLogProbMetric: 391.7540 - lr: 2.0833e-05 - 16s/epoch - 79ms/step
Epoch 694/1000
2023-09-10 07:51:53.939 
Epoch 694/1000 
	 loss: 387.9286, MinusLogProbMetric: 387.9286, val_loss: 391.7092, val_MinusLogProbMetric: 391.7092

Epoch 694: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.9286 - MinusLogProbMetric: 387.9286 - val_loss: 391.7092 - val_MinusLogProbMetric: 391.7092 - lr: 2.0833e-05 - 17s/epoch - 87ms/step
Epoch 695/1000
2023-09-10 07:52:10.160 
Epoch 695/1000 
	 loss: 387.9650, MinusLogProbMetric: 387.9650, val_loss: 392.1777, val_MinusLogProbMetric: 392.1777

Epoch 695: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9650 - MinusLogProbMetric: 387.9650 - val_loss: 392.1777 - val_MinusLogProbMetric: 392.1777 - lr: 2.0833e-05 - 16s/epoch - 83ms/step
Epoch 696/1000
2023-09-10 07:52:26.429 
Epoch 696/1000 
	 loss: 387.9562, MinusLogProbMetric: 387.9562, val_loss: 391.9438, val_MinusLogProbMetric: 391.9438

Epoch 696: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9562 - MinusLogProbMetric: 387.9562 - val_loss: 391.9438 - val_MinusLogProbMetric: 391.9438 - lr: 2.0833e-05 - 16s/epoch - 83ms/step
Epoch 697/1000
2023-09-10 07:52:43.058 
Epoch 697/1000 
	 loss: 387.9660, MinusLogProbMetric: 387.9660, val_loss: 391.8619, val_MinusLogProbMetric: 391.8619

Epoch 697: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.9660 - MinusLogProbMetric: 387.9660 - val_loss: 391.8619 - val_MinusLogProbMetric: 391.8619 - lr: 2.0833e-05 - 17s/epoch - 85ms/step
Epoch 698/1000
2023-09-10 07:52:58.883 
Epoch 698/1000 
	 loss: 387.9279, MinusLogProbMetric: 387.9279, val_loss: 391.7558, val_MinusLogProbMetric: 391.7558

Epoch 698: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9279 - MinusLogProbMetric: 387.9279 - val_loss: 391.7558 - val_MinusLogProbMetric: 391.7558 - lr: 2.0833e-05 - 16s/epoch - 81ms/step
Epoch 699/1000
2023-09-10 07:53:14.780 
Epoch 699/1000 
	 loss: 387.9302, MinusLogProbMetric: 387.9302, val_loss: 392.6578, val_MinusLogProbMetric: 392.6578

Epoch 699: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9302 - MinusLogProbMetric: 387.9302 - val_loss: 392.6578 - val_MinusLogProbMetric: 392.6578 - lr: 2.0833e-05 - 16s/epoch - 81ms/step
Epoch 700/1000
2023-09-10 07:53:29.660 
Epoch 700/1000 
	 loss: 387.9563, MinusLogProbMetric: 387.9563, val_loss: 392.0587, val_MinusLogProbMetric: 392.0587

Epoch 700: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.9563 - MinusLogProbMetric: 387.9563 - val_loss: 392.0587 - val_MinusLogProbMetric: 392.0587 - lr: 2.0833e-05 - 15s/epoch - 76ms/step
Epoch 701/1000
2023-09-10 07:53:46.207 
Epoch 701/1000 
	 loss: 387.9201, MinusLogProbMetric: 387.9201, val_loss: 391.8423, val_MinusLogProbMetric: 391.8423

Epoch 701: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.9201 - MinusLogProbMetric: 387.9201 - val_loss: 391.8423 - val_MinusLogProbMetric: 391.8423 - lr: 2.0833e-05 - 17s/epoch - 84ms/step
Epoch 702/1000
2023-09-10 07:54:04.109 
Epoch 702/1000 
	 loss: 387.8963, MinusLogProbMetric: 387.8963, val_loss: 392.1370, val_MinusLogProbMetric: 392.1370

Epoch 702: val_loss did not improve from 391.58792
196/196 - 18s - loss: 387.8963 - MinusLogProbMetric: 387.8963 - val_loss: 392.1370 - val_MinusLogProbMetric: 392.1370 - lr: 2.0833e-05 - 18s/epoch - 91ms/step
Epoch 703/1000
2023-09-10 07:54:20.505 
Epoch 703/1000 
	 loss: 387.9321, MinusLogProbMetric: 387.9321, val_loss: 391.8548, val_MinusLogProbMetric: 391.8548

Epoch 703: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9321 - MinusLogProbMetric: 387.9321 - val_loss: 391.8548 - val_MinusLogProbMetric: 391.8548 - lr: 2.0833e-05 - 16s/epoch - 84ms/step
Epoch 704/1000
2023-09-10 07:54:35.155 
Epoch 704/1000 
	 loss: 387.9170, MinusLogProbMetric: 387.9170, val_loss: 392.0763, val_MinusLogProbMetric: 392.0763

Epoch 704: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.9170 - MinusLogProbMetric: 387.9170 - val_loss: 392.0763 - val_MinusLogProbMetric: 392.0763 - lr: 2.0833e-05 - 15s/epoch - 75ms/step
Epoch 705/1000
2023-09-10 07:54:50.954 
Epoch 705/1000 
	 loss: 387.9052, MinusLogProbMetric: 387.9052, val_loss: 391.8925, val_MinusLogProbMetric: 391.8925

Epoch 705: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9052 - MinusLogProbMetric: 387.9052 - val_loss: 391.8925 - val_MinusLogProbMetric: 391.8925 - lr: 2.0833e-05 - 16s/epoch - 80ms/step
Epoch 706/1000
2023-09-10 07:55:06.586 
Epoch 706/1000 
	 loss: 387.9110, MinusLogProbMetric: 387.9110, val_loss: 391.8982, val_MinusLogProbMetric: 391.8982

Epoch 706: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.9110 - MinusLogProbMetric: 387.9110 - val_loss: 391.8982 - val_MinusLogProbMetric: 391.8982 - lr: 2.0833e-05 - 16s/epoch - 80ms/step
Epoch 707/1000
2023-09-10 07:55:22.038 
Epoch 707/1000 
	 loss: 387.9116, MinusLogProbMetric: 387.9116, val_loss: 392.1190, val_MinusLogProbMetric: 392.1190

Epoch 707: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.9116 - MinusLogProbMetric: 387.9116 - val_loss: 392.1190 - val_MinusLogProbMetric: 392.1190 - lr: 2.0833e-05 - 15s/epoch - 79ms/step
Epoch 708/1000
2023-09-10 07:55:37.347 
Epoch 708/1000 
	 loss: 387.8852, MinusLogProbMetric: 387.8852, val_loss: 391.9902, val_MinusLogProbMetric: 391.9902

Epoch 708: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8852 - MinusLogProbMetric: 387.8852 - val_loss: 391.9902 - val_MinusLogProbMetric: 391.9902 - lr: 2.0833e-05 - 15s/epoch - 78ms/step
Epoch 709/1000
2023-09-10 07:55:53.691 
Epoch 709/1000 
	 loss: 387.8751, MinusLogProbMetric: 387.8751, val_loss: 391.8829, val_MinusLogProbMetric: 391.8829

Epoch 709: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.8751 - MinusLogProbMetric: 387.8751 - val_loss: 391.8829 - val_MinusLogProbMetric: 391.8829 - lr: 2.0833e-05 - 16s/epoch - 83ms/step
Epoch 710/1000
2023-09-10 07:56:11.435 
Epoch 710/1000 
	 loss: 387.8594, MinusLogProbMetric: 387.8594, val_loss: 392.0463, val_MinusLogProbMetric: 392.0463

Epoch 710: val_loss did not improve from 391.58792
196/196 - 18s - loss: 387.8594 - MinusLogProbMetric: 387.8594 - val_loss: 392.0463 - val_MinusLogProbMetric: 392.0463 - lr: 2.0833e-05 - 18s/epoch - 91ms/step
Epoch 711/1000
2023-09-10 07:56:26.610 
Epoch 711/1000 
	 loss: 387.8677, MinusLogProbMetric: 387.8677, val_loss: 392.1536, val_MinusLogProbMetric: 392.1536

Epoch 711: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8677 - MinusLogProbMetric: 387.8677 - val_loss: 392.1536 - val_MinusLogProbMetric: 392.1536 - lr: 2.0833e-05 - 15s/epoch - 77ms/step
Epoch 712/1000
2023-09-10 07:56:41.554 
Epoch 712/1000 
	 loss: 387.8614, MinusLogProbMetric: 387.8614, val_loss: 392.2514, val_MinusLogProbMetric: 392.2514

Epoch 712: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8614 - MinusLogProbMetric: 387.8614 - val_loss: 392.2514 - val_MinusLogProbMetric: 392.2514 - lr: 2.0833e-05 - 15s/epoch - 76ms/step
Epoch 713/1000
2023-09-10 07:56:55.795 
Epoch 713/1000 
	 loss: 387.8877, MinusLogProbMetric: 387.8877, val_loss: 392.0608, val_MinusLogProbMetric: 392.0608

Epoch 713: val_loss did not improve from 391.58792
196/196 - 14s - loss: 387.8877 - MinusLogProbMetric: 387.8877 - val_loss: 392.0608 - val_MinusLogProbMetric: 392.0608 - lr: 2.0833e-05 - 14s/epoch - 73ms/step
Epoch 714/1000
2023-09-10 07:57:10.109 
Epoch 714/1000 
	 loss: 387.8774, MinusLogProbMetric: 387.8774, val_loss: 392.0657, val_MinusLogProbMetric: 392.0657

Epoch 714: val_loss did not improve from 391.58792
196/196 - 14s - loss: 387.8774 - MinusLogProbMetric: 387.8774 - val_loss: 392.0657 - val_MinusLogProbMetric: 392.0657 - lr: 2.0833e-05 - 14s/epoch - 73ms/step
Epoch 715/1000
2023-09-10 07:57:25.009 
Epoch 715/1000 
	 loss: 387.8744, MinusLogProbMetric: 387.8744, val_loss: 392.1630, val_MinusLogProbMetric: 392.1630

Epoch 715: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8744 - MinusLogProbMetric: 387.8744 - val_loss: 392.1630 - val_MinusLogProbMetric: 392.1630 - lr: 2.0833e-05 - 15s/epoch - 76ms/step
Epoch 716/1000
2023-09-10 07:57:39.681 
Epoch 716/1000 
	 loss: 387.9083, MinusLogProbMetric: 387.9083, val_loss: 391.9508, val_MinusLogProbMetric: 391.9508

Epoch 716: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.9083 - MinusLogProbMetric: 387.9083 - val_loss: 391.9508 - val_MinusLogProbMetric: 391.9508 - lr: 2.0833e-05 - 15s/epoch - 75ms/step
Epoch 717/1000
2023-09-10 07:57:54.805 
Epoch 717/1000 
	 loss: 387.8748, MinusLogProbMetric: 387.8748, val_loss: 391.6887, val_MinusLogProbMetric: 391.6887

Epoch 717: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8748 - MinusLogProbMetric: 387.8748 - val_loss: 391.6887 - val_MinusLogProbMetric: 391.6887 - lr: 2.0833e-05 - 15s/epoch - 77ms/step
Epoch 718/1000
2023-09-10 07:58:09.664 
Epoch 718/1000 
	 loss: 387.8744, MinusLogProbMetric: 387.8744, val_loss: 391.8167, val_MinusLogProbMetric: 391.8167

Epoch 718: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8744 - MinusLogProbMetric: 387.8744 - val_loss: 391.8167 - val_MinusLogProbMetric: 391.8167 - lr: 2.0833e-05 - 15s/epoch - 76ms/step
Epoch 719/1000
2023-09-10 07:58:25.052 
Epoch 719/1000 
	 loss: 387.8423, MinusLogProbMetric: 387.8423, val_loss: 392.2875, val_MinusLogProbMetric: 392.2875

Epoch 719: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8423 - MinusLogProbMetric: 387.8423 - val_loss: 392.2875 - val_MinusLogProbMetric: 392.2875 - lr: 2.0833e-05 - 15s/epoch - 78ms/step
Epoch 720/1000
2023-09-10 07:58:37.869 
Epoch 720/1000 
	 loss: 387.9187, MinusLogProbMetric: 387.9187, val_loss: 391.9555, val_MinusLogProbMetric: 391.9555

Epoch 720: val_loss did not improve from 391.58792
196/196 - 13s - loss: 387.9187 - MinusLogProbMetric: 387.9187 - val_loss: 391.9555 - val_MinusLogProbMetric: 391.9555 - lr: 2.0833e-05 - 13s/epoch - 65ms/step
Epoch 721/1000
2023-09-10 07:58:51.507 
Epoch 721/1000 
	 loss: 387.8541, MinusLogProbMetric: 387.8541, val_loss: 391.8863, val_MinusLogProbMetric: 391.8863

Epoch 721: val_loss did not improve from 391.58792
196/196 - 14s - loss: 387.8541 - MinusLogProbMetric: 387.8541 - val_loss: 391.8863 - val_MinusLogProbMetric: 391.8863 - lr: 2.0833e-05 - 14s/epoch - 70ms/step
Epoch 722/1000
2023-09-10 07:59:06.867 
Epoch 722/1000 
	 loss: 387.8828, MinusLogProbMetric: 387.8828, val_loss: 391.8170, val_MinusLogProbMetric: 391.8170

Epoch 722: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8828 - MinusLogProbMetric: 387.8828 - val_loss: 391.8170 - val_MinusLogProbMetric: 391.8170 - lr: 2.0833e-05 - 15s/epoch - 78ms/step
Epoch 723/1000
2023-09-10 07:59:22.676 
Epoch 723/1000 
	 loss: 387.8611, MinusLogProbMetric: 387.8611, val_loss: 391.7272, val_MinusLogProbMetric: 391.7272

Epoch 723: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.8611 - MinusLogProbMetric: 387.8611 - val_loss: 391.7272 - val_MinusLogProbMetric: 391.7272 - lr: 2.0833e-05 - 16s/epoch - 81ms/step
Epoch 724/1000
2023-09-10 07:59:40.795 
Epoch 724/1000 
	 loss: 387.9317, MinusLogProbMetric: 387.9317, val_loss: 391.9434, val_MinusLogProbMetric: 391.9434

Epoch 724: val_loss did not improve from 391.58792
196/196 - 18s - loss: 387.9317 - MinusLogProbMetric: 387.9317 - val_loss: 391.9434 - val_MinusLogProbMetric: 391.9434 - lr: 2.0833e-05 - 18s/epoch - 92ms/step
Epoch 725/1000
2023-09-10 07:59:57.410 
Epoch 725/1000 
	 loss: 387.8462, MinusLogProbMetric: 387.8462, val_loss: 391.9613, val_MinusLogProbMetric: 391.9613

Epoch 725: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.8462 - MinusLogProbMetric: 387.8462 - val_loss: 391.9613 - val_MinusLogProbMetric: 391.9613 - lr: 2.0833e-05 - 17s/epoch - 85ms/step
Epoch 726/1000
2023-09-10 08:00:13.557 
Epoch 726/1000 
	 loss: 387.8672, MinusLogProbMetric: 387.8672, val_loss: 391.6453, val_MinusLogProbMetric: 391.6453

Epoch 726: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.8672 - MinusLogProbMetric: 387.8672 - val_loss: 391.6453 - val_MinusLogProbMetric: 391.6453 - lr: 2.0833e-05 - 16s/epoch - 82ms/step
Epoch 727/1000
2023-09-10 08:00:30.127 
Epoch 727/1000 
	 loss: 387.8241, MinusLogProbMetric: 387.8241, val_loss: 392.3834, val_MinusLogProbMetric: 392.3834

Epoch 727: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.8241 - MinusLogProbMetric: 387.8241 - val_loss: 392.3834 - val_MinusLogProbMetric: 392.3834 - lr: 2.0833e-05 - 17s/epoch - 84ms/step
Epoch 728/1000
2023-09-10 08:00:44.665 
Epoch 728/1000 
	 loss: 387.8486, MinusLogProbMetric: 387.8486, val_loss: 392.0642, val_MinusLogProbMetric: 392.0642

Epoch 728: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8486 - MinusLogProbMetric: 387.8486 - val_loss: 392.0642 - val_MinusLogProbMetric: 392.0642 - lr: 2.0833e-05 - 15s/epoch - 74ms/step
Epoch 729/1000
2023-09-10 08:01:00.604 
Epoch 729/1000 
	 loss: 387.8228, MinusLogProbMetric: 387.8228, val_loss: 391.8596, val_MinusLogProbMetric: 391.8596

Epoch 729: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.8228 - MinusLogProbMetric: 387.8228 - val_loss: 391.8596 - val_MinusLogProbMetric: 391.8596 - lr: 2.0833e-05 - 16s/epoch - 81ms/step
Epoch 730/1000
2023-09-10 08:01:15.969 
Epoch 730/1000 
	 loss: 387.8412, MinusLogProbMetric: 387.8412, val_loss: 391.8151, val_MinusLogProbMetric: 391.8151

Epoch 730: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8412 - MinusLogProbMetric: 387.8412 - val_loss: 391.8151 - val_MinusLogProbMetric: 391.8151 - lr: 2.0833e-05 - 15s/epoch - 78ms/step
Epoch 731/1000
2023-09-10 08:01:30.347 
Epoch 731/1000 
	 loss: 387.8481, MinusLogProbMetric: 387.8481, val_loss: 391.9462, val_MinusLogProbMetric: 391.9462

Epoch 731: val_loss did not improve from 391.58792
196/196 - 14s - loss: 387.8481 - MinusLogProbMetric: 387.8481 - val_loss: 391.9462 - val_MinusLogProbMetric: 391.9462 - lr: 2.0833e-05 - 14s/epoch - 73ms/step
Epoch 732/1000
2023-09-10 08:01:45.542 
Epoch 732/1000 
	 loss: 387.8432, MinusLogProbMetric: 387.8432, val_loss: 391.8390, val_MinusLogProbMetric: 391.8390

Epoch 732: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8432 - MinusLogProbMetric: 387.8432 - val_loss: 391.8390 - val_MinusLogProbMetric: 391.8390 - lr: 2.0833e-05 - 15s/epoch - 77ms/step
Epoch 733/1000
2023-09-10 08:02:02.495 
Epoch 733/1000 
	 loss: 387.8257, MinusLogProbMetric: 387.8257, val_loss: 391.8288, val_MinusLogProbMetric: 391.8288

Epoch 733: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.8257 - MinusLogProbMetric: 387.8257 - val_loss: 391.8288 - val_MinusLogProbMetric: 391.8288 - lr: 2.0833e-05 - 17s/epoch - 86ms/step
Epoch 734/1000
2023-09-10 08:02:19.622 
Epoch 734/1000 
	 loss: 387.8345, MinusLogProbMetric: 387.8345, val_loss: 391.6159, val_MinusLogProbMetric: 391.6159

Epoch 734: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.8345 - MinusLogProbMetric: 387.8345 - val_loss: 391.6159 - val_MinusLogProbMetric: 391.6159 - lr: 2.0833e-05 - 17s/epoch - 87ms/step
Epoch 735/1000
2023-09-10 08:02:35.597 
Epoch 735/1000 
	 loss: 387.8566, MinusLogProbMetric: 387.8566, val_loss: 391.9022, val_MinusLogProbMetric: 391.9022

Epoch 735: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.8566 - MinusLogProbMetric: 387.8566 - val_loss: 391.9022 - val_MinusLogProbMetric: 391.9022 - lr: 2.0833e-05 - 16s/epoch - 82ms/step
Epoch 736/1000
2023-09-10 08:02:51.895 
Epoch 736/1000 
	 loss: 387.8348, MinusLogProbMetric: 387.8348, val_loss: 391.9492, val_MinusLogProbMetric: 391.9492

Epoch 736: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.8348 - MinusLogProbMetric: 387.8348 - val_loss: 391.9492 - val_MinusLogProbMetric: 391.9492 - lr: 2.0833e-05 - 16s/epoch - 83ms/step
Epoch 737/1000
2023-09-10 08:03:09.201 
Epoch 737/1000 
	 loss: 387.8540, MinusLogProbMetric: 387.8540, val_loss: 391.7071, val_MinusLogProbMetric: 391.7071

Epoch 737: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.8540 - MinusLogProbMetric: 387.8540 - val_loss: 391.7071 - val_MinusLogProbMetric: 391.7071 - lr: 2.0833e-05 - 17s/epoch - 88ms/step
Epoch 738/1000
2023-09-10 08:03:26.355 
Epoch 738/1000 
	 loss: 387.8549, MinusLogProbMetric: 387.8549, val_loss: 391.9734, val_MinusLogProbMetric: 391.9734

Epoch 738: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.8549 - MinusLogProbMetric: 387.8549 - val_loss: 391.9734 - val_MinusLogProbMetric: 391.9734 - lr: 2.0833e-05 - 17s/epoch - 87ms/step
Epoch 739/1000
2023-09-10 08:03:41.370 
Epoch 739/1000 
	 loss: 387.8711, MinusLogProbMetric: 387.8711, val_loss: 392.0741, val_MinusLogProbMetric: 392.0741

Epoch 739: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8711 - MinusLogProbMetric: 387.8711 - val_loss: 392.0741 - val_MinusLogProbMetric: 392.0741 - lr: 2.0833e-05 - 15s/epoch - 77ms/step
Epoch 740/1000
2023-09-10 08:03:56.549 
Epoch 740/1000 
	 loss: 387.8976, MinusLogProbMetric: 387.8976, val_loss: 392.2615, val_MinusLogProbMetric: 392.2615

Epoch 740: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.8976 - MinusLogProbMetric: 387.8976 - val_loss: 392.2615 - val_MinusLogProbMetric: 392.2615 - lr: 2.0833e-05 - 15s/epoch - 77ms/step
Epoch 741/1000
2023-09-10 08:04:12.533 
Epoch 741/1000 
	 loss: 387.8734, MinusLogProbMetric: 387.8734, val_loss: 391.9743, val_MinusLogProbMetric: 391.9743

Epoch 741: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.8734 - MinusLogProbMetric: 387.8734 - val_loss: 391.9743 - val_MinusLogProbMetric: 391.9743 - lr: 2.0833e-05 - 16s/epoch - 82ms/step
Epoch 742/1000
2023-09-10 08:04:26.569 
Epoch 742/1000 
	 loss: 387.8914, MinusLogProbMetric: 387.8914, val_loss: 391.8138, val_MinusLogProbMetric: 391.8138

Epoch 742: val_loss did not improve from 391.58792
196/196 - 14s - loss: 387.8914 - MinusLogProbMetric: 387.8914 - val_loss: 391.8138 - val_MinusLogProbMetric: 391.8138 - lr: 2.0833e-05 - 14s/epoch - 72ms/step
Epoch 743/1000
2023-09-10 08:04:43.839 
Epoch 743/1000 
	 loss: 387.7130, MinusLogProbMetric: 387.7130, val_loss: 391.7364, val_MinusLogProbMetric: 391.7364

Epoch 743: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.7130 - MinusLogProbMetric: 387.7130 - val_loss: 391.7364 - val_MinusLogProbMetric: 391.7364 - lr: 1.0417e-05 - 17s/epoch - 88ms/step
Epoch 744/1000
2023-09-10 08:04:59.236 
Epoch 744/1000 
	 loss: 387.7010, MinusLogProbMetric: 387.7010, val_loss: 391.9213, val_MinusLogProbMetric: 391.9213

Epoch 744: val_loss did not improve from 391.58792
196/196 - 15s - loss: 387.7010 - MinusLogProbMetric: 387.7010 - val_loss: 391.9213 - val_MinusLogProbMetric: 391.9213 - lr: 1.0417e-05 - 15s/epoch - 79ms/step
Epoch 745/1000
2023-09-10 08:05:13.279 
Epoch 745/1000 
	 loss: 387.7037, MinusLogProbMetric: 387.7037, val_loss: 391.7640, val_MinusLogProbMetric: 391.7640

Epoch 745: val_loss did not improve from 391.58792
196/196 - 14s - loss: 387.7037 - MinusLogProbMetric: 387.7037 - val_loss: 391.7640 - val_MinusLogProbMetric: 391.7640 - lr: 1.0417e-05 - 14s/epoch - 72ms/step
Epoch 746/1000
2023-09-10 08:05:32.012 
Epoch 746/1000 
	 loss: 387.7094, MinusLogProbMetric: 387.7094, val_loss: 391.8283, val_MinusLogProbMetric: 391.8283

Epoch 746: val_loss did not improve from 391.58792
196/196 - 19s - loss: 387.7094 - MinusLogProbMetric: 387.7094 - val_loss: 391.8283 - val_MinusLogProbMetric: 391.8283 - lr: 1.0417e-05 - 19s/epoch - 96ms/step
Epoch 747/1000
2023-09-10 08:05:52.054 
Epoch 747/1000 
	 loss: 387.7195, MinusLogProbMetric: 387.7195, val_loss: 392.0963, val_MinusLogProbMetric: 392.0963

Epoch 747: val_loss did not improve from 391.58792
196/196 - 20s - loss: 387.7195 - MinusLogProbMetric: 387.7195 - val_loss: 392.0963 - val_MinusLogProbMetric: 392.0963 - lr: 1.0417e-05 - 20s/epoch - 102ms/step
Epoch 748/1000
2023-09-10 08:06:10.665 
Epoch 748/1000 
	 loss: 387.6988, MinusLogProbMetric: 387.6988, val_loss: 391.7350, val_MinusLogProbMetric: 391.7350

Epoch 748: val_loss did not improve from 391.58792
196/196 - 19s - loss: 387.6988 - MinusLogProbMetric: 387.6988 - val_loss: 391.7350 - val_MinusLogProbMetric: 391.7350 - lr: 1.0417e-05 - 19s/epoch - 95ms/step
Epoch 749/1000
2023-09-10 08:06:28.865 
Epoch 749/1000 
	 loss: 387.7016, MinusLogProbMetric: 387.7016, val_loss: 391.8350, val_MinusLogProbMetric: 391.8350

Epoch 749: val_loss did not improve from 391.58792
196/196 - 18s - loss: 387.7016 - MinusLogProbMetric: 387.7016 - val_loss: 391.8350 - val_MinusLogProbMetric: 391.8350 - lr: 1.0417e-05 - 18s/epoch - 93ms/step
Epoch 750/1000
2023-09-10 08:06:46.646 
Epoch 750/1000 
	 loss: 387.7091, MinusLogProbMetric: 387.7091, val_loss: 391.6681, val_MinusLogProbMetric: 391.6681

Epoch 750: val_loss did not improve from 391.58792
196/196 - 18s - loss: 387.7091 - MinusLogProbMetric: 387.7091 - val_loss: 391.6681 - val_MinusLogProbMetric: 391.6681 - lr: 1.0417e-05 - 18s/epoch - 91ms/step
Epoch 751/1000
2023-09-10 08:07:04.135 
Epoch 751/1000 
	 loss: 387.7237, MinusLogProbMetric: 387.7237, val_loss: 391.8607, val_MinusLogProbMetric: 391.8607

Epoch 751: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.7237 - MinusLogProbMetric: 387.7237 - val_loss: 391.8607 - val_MinusLogProbMetric: 391.8607 - lr: 1.0417e-05 - 17s/epoch - 89ms/step
Epoch 752/1000
2023-09-10 08:07:20.061 
Epoch 752/1000 
	 loss: 387.7478, MinusLogProbMetric: 387.7478, val_loss: 391.9888, val_MinusLogProbMetric: 391.9888

Epoch 752: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.7478 - MinusLogProbMetric: 387.7478 - val_loss: 391.9888 - val_MinusLogProbMetric: 391.9888 - lr: 1.0417e-05 - 16s/epoch - 81ms/step
Epoch 753/1000
2023-09-10 08:07:38.593 
Epoch 753/1000 
	 loss: 387.7290, MinusLogProbMetric: 387.7290, val_loss: 391.9841, val_MinusLogProbMetric: 391.9841

Epoch 753: val_loss did not improve from 391.58792
196/196 - 19s - loss: 387.7290 - MinusLogProbMetric: 387.7290 - val_loss: 391.9841 - val_MinusLogProbMetric: 391.9841 - lr: 1.0417e-05 - 19s/epoch - 95ms/step
Epoch 754/1000
2023-09-10 08:07:55.509 
Epoch 754/1000 
	 loss: 387.7492, MinusLogProbMetric: 387.7492, val_loss: 391.9390, val_MinusLogProbMetric: 391.9390

Epoch 754: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.7492 - MinusLogProbMetric: 387.7492 - val_loss: 391.9390 - val_MinusLogProbMetric: 391.9390 - lr: 1.0417e-05 - 17s/epoch - 86ms/step
Epoch 755/1000
2023-09-10 08:08:11.580 
Epoch 755/1000 
	 loss: 387.7018, MinusLogProbMetric: 387.7018, val_loss: 391.6697, val_MinusLogProbMetric: 391.6697

Epoch 755: val_loss did not improve from 391.58792
196/196 - 16s - loss: 387.7018 - MinusLogProbMetric: 387.7018 - val_loss: 391.6697 - val_MinusLogProbMetric: 391.6697 - lr: 1.0417e-05 - 16s/epoch - 82ms/step
Epoch 756/1000
2023-09-10 08:08:28.218 
Epoch 756/1000 
	 loss: 387.6986, MinusLogProbMetric: 387.6986, val_loss: 392.0172, val_MinusLogProbMetric: 392.0172

Epoch 756: val_loss did not improve from 391.58792
196/196 - 17s - loss: 387.6986 - MinusLogProbMetric: 387.6986 - val_loss: 392.0172 - val_MinusLogProbMetric: 392.0172 - lr: 1.0417e-05 - 17s/epoch - 85ms/step
Epoch 757/1000
2023-09-10 08:08:47.045 
Epoch 757/1000 
	 loss: 387.7347, MinusLogProbMetric: 387.7347, val_loss: 391.5464, val_MinusLogProbMetric: 391.5464

Epoch 757: val_loss improved from 391.58792 to 391.54639, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_331/weights/best_weights.h5
196/196 - 19s - loss: 387.7347 - MinusLogProbMetric: 387.7347 - val_loss: 391.5464 - val_MinusLogProbMetric: 391.5464 - lr: 1.0417e-05 - 19s/epoch - 99ms/step
Epoch 758/1000
2023-09-10 08:09:04.508 
Epoch 758/1000 
	 loss: 387.7013, MinusLogProbMetric: 387.7013, val_loss: 391.6191, val_MinusLogProbMetric: 391.6191

Epoch 758: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.7013 - MinusLogProbMetric: 387.7013 - val_loss: 391.6191 - val_MinusLogProbMetric: 391.6191 - lr: 1.0417e-05 - 17s/epoch - 86ms/step
Epoch 759/1000
2023-09-10 08:09:20.322 
Epoch 759/1000 
	 loss: 387.6865, MinusLogProbMetric: 387.6865, val_loss: 391.8889, val_MinusLogProbMetric: 391.8889

Epoch 759: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6865 - MinusLogProbMetric: 387.6865 - val_loss: 391.8889 - val_MinusLogProbMetric: 391.8889 - lr: 1.0417e-05 - 16s/epoch - 81ms/step
Epoch 760/1000
2023-09-10 08:09:35.186 
Epoch 760/1000 
	 loss: 387.7112, MinusLogProbMetric: 387.7112, val_loss: 391.7661, val_MinusLogProbMetric: 391.7661

Epoch 760: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7112 - MinusLogProbMetric: 387.7112 - val_loss: 391.7661 - val_MinusLogProbMetric: 391.7661 - lr: 1.0417e-05 - 15s/epoch - 76ms/step
Epoch 761/1000
2023-09-10 08:09:49.896 
Epoch 761/1000 
	 loss: 387.7262, MinusLogProbMetric: 387.7262, val_loss: 391.7246, val_MinusLogProbMetric: 391.7246

Epoch 761: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7262 - MinusLogProbMetric: 387.7262 - val_loss: 391.7246 - val_MinusLogProbMetric: 391.7246 - lr: 1.0417e-05 - 15s/epoch - 75ms/step
Epoch 762/1000
2023-09-10 08:10:03.526 
Epoch 762/1000 
	 loss: 387.7288, MinusLogProbMetric: 387.7288, val_loss: 392.2271, val_MinusLogProbMetric: 392.2271

Epoch 762: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7288 - MinusLogProbMetric: 387.7288 - val_loss: 392.2271 - val_MinusLogProbMetric: 392.2271 - lr: 1.0417e-05 - 14s/epoch - 70ms/step
Epoch 763/1000
2023-09-10 08:10:18.098 
Epoch 763/1000 
	 loss: 387.7332, MinusLogProbMetric: 387.7332, val_loss: 392.0437, val_MinusLogProbMetric: 392.0437

Epoch 763: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7332 - MinusLogProbMetric: 387.7332 - val_loss: 392.0437 - val_MinusLogProbMetric: 392.0437 - lr: 1.0417e-05 - 15s/epoch - 74ms/step
Epoch 764/1000
2023-09-10 08:10:35.185 
Epoch 764/1000 
	 loss: 387.7408, MinusLogProbMetric: 387.7408, val_loss: 391.9859, val_MinusLogProbMetric: 391.9859

Epoch 764: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.7408 - MinusLogProbMetric: 387.7408 - val_loss: 391.9859 - val_MinusLogProbMetric: 391.9859 - lr: 1.0417e-05 - 17s/epoch - 87ms/step
Epoch 765/1000
2023-09-10 08:10:49.646 
Epoch 765/1000 
	 loss: 387.7142, MinusLogProbMetric: 387.7142, val_loss: 391.9896, val_MinusLogProbMetric: 391.9896

Epoch 765: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7142 - MinusLogProbMetric: 387.7142 - val_loss: 391.9896 - val_MinusLogProbMetric: 391.9896 - lr: 1.0417e-05 - 14s/epoch - 74ms/step
Epoch 766/1000
2023-09-10 08:11:02.293 
Epoch 766/1000 
	 loss: 387.6985, MinusLogProbMetric: 387.6985, val_loss: 391.9267, val_MinusLogProbMetric: 391.9267

Epoch 766: val_loss did not improve from 391.54639
196/196 - 13s - loss: 387.6985 - MinusLogProbMetric: 387.6985 - val_loss: 391.9267 - val_MinusLogProbMetric: 391.9267 - lr: 1.0417e-05 - 13s/epoch - 65ms/step
Epoch 767/1000
2023-09-10 08:11:16.463 
Epoch 767/1000 
	 loss: 387.7126, MinusLogProbMetric: 387.7126, val_loss: 391.9412, val_MinusLogProbMetric: 391.9412

Epoch 767: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7126 - MinusLogProbMetric: 387.7126 - val_loss: 391.9412 - val_MinusLogProbMetric: 391.9412 - lr: 1.0417e-05 - 14s/epoch - 72ms/step
Epoch 768/1000
2023-09-10 08:11:31.282 
Epoch 768/1000 
	 loss: 387.7242, MinusLogProbMetric: 387.7242, val_loss: 392.0908, val_MinusLogProbMetric: 392.0908

Epoch 768: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7242 - MinusLogProbMetric: 387.7242 - val_loss: 392.0908 - val_MinusLogProbMetric: 392.0908 - lr: 1.0417e-05 - 15s/epoch - 76ms/step
Epoch 769/1000
2023-09-10 08:11:46.167 
Epoch 769/1000 
	 loss: 387.7479, MinusLogProbMetric: 387.7479, val_loss: 391.8500, val_MinusLogProbMetric: 391.8500

Epoch 769: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7479 - MinusLogProbMetric: 387.7479 - val_loss: 391.8500 - val_MinusLogProbMetric: 391.8500 - lr: 1.0417e-05 - 15s/epoch - 76ms/step
Epoch 770/1000
2023-09-10 08:11:59.603 
Epoch 770/1000 
	 loss: 387.7206, MinusLogProbMetric: 387.7206, val_loss: 392.2406, val_MinusLogProbMetric: 392.2406

Epoch 770: val_loss did not improve from 391.54639
196/196 - 13s - loss: 387.7206 - MinusLogProbMetric: 387.7206 - val_loss: 392.2406 - val_MinusLogProbMetric: 392.2406 - lr: 1.0417e-05 - 13s/epoch - 68ms/step
Epoch 771/1000
2023-09-10 08:12:15.174 
Epoch 771/1000 
	 loss: 387.7237, MinusLogProbMetric: 387.7237, val_loss: 392.1128, val_MinusLogProbMetric: 392.1128

Epoch 771: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7237 - MinusLogProbMetric: 387.7237 - val_loss: 392.1128 - val_MinusLogProbMetric: 392.1128 - lr: 1.0417e-05 - 16s/epoch - 79ms/step
Epoch 772/1000
2023-09-10 08:12:31.558 
Epoch 772/1000 
	 loss: 387.7174, MinusLogProbMetric: 387.7174, val_loss: 392.0958, val_MinusLogProbMetric: 392.0958

Epoch 772: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7174 - MinusLogProbMetric: 387.7174 - val_loss: 392.0958 - val_MinusLogProbMetric: 392.0958 - lr: 1.0417e-05 - 16s/epoch - 84ms/step
Epoch 773/1000
2023-09-10 08:12:49.964 
Epoch 773/1000 
	 loss: 387.7032, MinusLogProbMetric: 387.7032, val_loss: 391.9352, val_MinusLogProbMetric: 391.9352

Epoch 773: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.7032 - MinusLogProbMetric: 387.7032 - val_loss: 391.9352 - val_MinusLogProbMetric: 391.9352 - lr: 1.0417e-05 - 18s/epoch - 94ms/step
Epoch 774/1000
2023-09-10 08:13:04.648 
Epoch 774/1000 
	 loss: 387.7090, MinusLogProbMetric: 387.7090, val_loss: 392.0027, val_MinusLogProbMetric: 392.0027

Epoch 774: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7090 - MinusLogProbMetric: 387.7090 - val_loss: 392.0027 - val_MinusLogProbMetric: 392.0027 - lr: 1.0417e-05 - 15s/epoch - 75ms/step
Epoch 775/1000
2023-09-10 08:13:18.732 
Epoch 775/1000 
	 loss: 387.7202, MinusLogProbMetric: 387.7202, val_loss: 391.9616, val_MinusLogProbMetric: 391.9616

Epoch 775: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7202 - MinusLogProbMetric: 387.7202 - val_loss: 391.9616 - val_MinusLogProbMetric: 391.9616 - lr: 1.0417e-05 - 14s/epoch - 72ms/step
Epoch 776/1000
2023-09-10 08:13:35.101 
Epoch 776/1000 
	 loss: 387.7078, MinusLogProbMetric: 387.7078, val_loss: 391.9476, val_MinusLogProbMetric: 391.9476

Epoch 776: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7078 - MinusLogProbMetric: 387.7078 - val_loss: 391.9476 - val_MinusLogProbMetric: 391.9476 - lr: 1.0417e-05 - 16s/epoch - 84ms/step
Epoch 777/1000
2023-09-10 08:13:48.434 
Epoch 777/1000 
	 loss: 387.7085, MinusLogProbMetric: 387.7085, val_loss: 391.8299, val_MinusLogProbMetric: 391.8299

Epoch 777: val_loss did not improve from 391.54639
196/196 - 13s - loss: 387.7085 - MinusLogProbMetric: 387.7085 - val_loss: 391.8299 - val_MinusLogProbMetric: 391.8299 - lr: 1.0417e-05 - 13s/epoch - 68ms/step
Epoch 778/1000
2023-09-10 08:14:01.903 
Epoch 778/1000 
	 loss: 387.7046, MinusLogProbMetric: 387.7046, val_loss: 391.9253, val_MinusLogProbMetric: 391.9253

Epoch 778: val_loss did not improve from 391.54639
196/196 - 13s - loss: 387.7046 - MinusLogProbMetric: 387.7046 - val_loss: 391.9253 - val_MinusLogProbMetric: 391.9253 - lr: 1.0417e-05 - 13s/epoch - 69ms/step
Epoch 779/1000
2023-09-10 08:14:15.484 
Epoch 779/1000 
	 loss: 387.7042, MinusLogProbMetric: 387.7042, val_loss: 392.0537, val_MinusLogProbMetric: 392.0537

Epoch 779: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7042 - MinusLogProbMetric: 387.7042 - val_loss: 392.0537 - val_MinusLogProbMetric: 392.0537 - lr: 1.0417e-05 - 14s/epoch - 69ms/step
Epoch 780/1000
2023-09-10 08:14:30.580 
Epoch 780/1000 
	 loss: 387.7130, MinusLogProbMetric: 387.7130, val_loss: 391.8953, val_MinusLogProbMetric: 391.8953

Epoch 780: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7130 - MinusLogProbMetric: 387.7130 - val_loss: 391.8953 - val_MinusLogProbMetric: 391.8953 - lr: 1.0417e-05 - 15s/epoch - 77ms/step
Epoch 781/1000
2023-09-10 08:14:44.766 
Epoch 781/1000 
	 loss: 387.7192, MinusLogProbMetric: 387.7192, val_loss: 392.0987, val_MinusLogProbMetric: 392.0987

Epoch 781: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7192 - MinusLogProbMetric: 387.7192 - val_loss: 392.0987 - val_MinusLogProbMetric: 392.0987 - lr: 1.0417e-05 - 14s/epoch - 72ms/step
Epoch 782/1000
2023-09-10 08:14:59.191 
Epoch 782/1000 
	 loss: 387.7057, MinusLogProbMetric: 387.7057, val_loss: 391.6223, val_MinusLogProbMetric: 391.6223

Epoch 782: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7057 - MinusLogProbMetric: 387.7057 - val_loss: 391.6223 - val_MinusLogProbMetric: 391.6223 - lr: 1.0417e-05 - 14s/epoch - 74ms/step
Epoch 783/1000
2023-09-10 08:15:14.516 
Epoch 783/1000 
	 loss: 387.7308, MinusLogProbMetric: 387.7308, val_loss: 391.8700, val_MinusLogProbMetric: 391.8700

Epoch 783: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7308 - MinusLogProbMetric: 387.7308 - val_loss: 391.8700 - val_MinusLogProbMetric: 391.8700 - lr: 1.0417e-05 - 15s/epoch - 78ms/step
Epoch 784/1000
2023-09-10 08:15:30.989 
Epoch 784/1000 
	 loss: 387.7014, MinusLogProbMetric: 387.7014, val_loss: 392.0301, val_MinusLogProbMetric: 392.0301

Epoch 784: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7014 - MinusLogProbMetric: 387.7014 - val_loss: 392.0301 - val_MinusLogProbMetric: 392.0301 - lr: 1.0417e-05 - 16s/epoch - 84ms/step
Epoch 785/1000
2023-09-10 08:15:45.049 
Epoch 785/1000 
	 loss: 387.7047, MinusLogProbMetric: 387.7047, val_loss: 391.9703, val_MinusLogProbMetric: 391.9703

Epoch 785: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.7047 - MinusLogProbMetric: 387.7047 - val_loss: 391.9703 - val_MinusLogProbMetric: 391.9703 - lr: 1.0417e-05 - 14s/epoch - 72ms/step
Epoch 786/1000
2023-09-10 08:15:59.609 
Epoch 786/1000 
	 loss: 387.7083, MinusLogProbMetric: 387.7083, val_loss: 391.8072, val_MinusLogProbMetric: 391.8072

Epoch 786: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7083 - MinusLogProbMetric: 387.7083 - val_loss: 391.8072 - val_MinusLogProbMetric: 391.8072 - lr: 1.0417e-05 - 15s/epoch - 74ms/step
Epoch 787/1000
2023-09-10 08:16:13.737 
Epoch 787/1000 
	 loss: 387.6905, MinusLogProbMetric: 387.6905, val_loss: 392.0585, val_MinusLogProbMetric: 392.0585

Epoch 787: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.6905 - MinusLogProbMetric: 387.6905 - val_loss: 392.0585 - val_MinusLogProbMetric: 392.0585 - lr: 1.0417e-05 - 14s/epoch - 72ms/step
Epoch 788/1000
2023-09-10 08:16:33.838 
Epoch 788/1000 
	 loss: 387.6970, MinusLogProbMetric: 387.6970, val_loss: 392.1234, val_MinusLogProbMetric: 392.1234

Epoch 788: val_loss did not improve from 391.54639
196/196 - 20s - loss: 387.6970 - MinusLogProbMetric: 387.6970 - val_loss: 392.1234 - val_MinusLogProbMetric: 392.1234 - lr: 1.0417e-05 - 20s/epoch - 103ms/step
Epoch 789/1000
2023-09-10 08:16:50.177 
Epoch 789/1000 
	 loss: 387.7250, MinusLogProbMetric: 387.7250, val_loss: 391.9461, val_MinusLogProbMetric: 391.9461

Epoch 789: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7250 - MinusLogProbMetric: 387.7250 - val_loss: 391.9461 - val_MinusLogProbMetric: 391.9461 - lr: 1.0417e-05 - 16s/epoch - 83ms/step
Epoch 790/1000
2023-09-10 08:17:05.931 
Epoch 790/1000 
	 loss: 387.6972, MinusLogProbMetric: 387.6972, val_loss: 392.1373, val_MinusLogProbMetric: 392.1373

Epoch 790: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6972 - MinusLogProbMetric: 387.6972 - val_loss: 392.1373 - val_MinusLogProbMetric: 392.1373 - lr: 1.0417e-05 - 16s/epoch - 80ms/step
Epoch 791/1000
2023-09-10 08:17:21.216 
Epoch 791/1000 
	 loss: 387.7061, MinusLogProbMetric: 387.7061, val_loss: 392.0523, val_MinusLogProbMetric: 392.0523

Epoch 791: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7061 - MinusLogProbMetric: 387.7061 - val_loss: 392.0523 - val_MinusLogProbMetric: 392.0523 - lr: 1.0417e-05 - 15s/epoch - 78ms/step
Epoch 792/1000
2023-09-10 08:17:37.426 
Epoch 792/1000 
	 loss: 387.7025, MinusLogProbMetric: 387.7025, val_loss: 392.0769, val_MinusLogProbMetric: 392.0769

Epoch 792: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7025 - MinusLogProbMetric: 387.7025 - val_loss: 392.0769 - val_MinusLogProbMetric: 392.0769 - lr: 1.0417e-05 - 16s/epoch - 83ms/step
Epoch 793/1000
2023-09-10 08:17:55.689 
Epoch 793/1000 
	 loss: 387.7030, MinusLogProbMetric: 387.7030, val_loss: 392.1325, val_MinusLogProbMetric: 392.1325

Epoch 793: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.7030 - MinusLogProbMetric: 387.7030 - val_loss: 392.1325 - val_MinusLogProbMetric: 392.1325 - lr: 1.0417e-05 - 18s/epoch - 93ms/step
Epoch 794/1000
2023-09-10 08:18:14.158 
Epoch 794/1000 
	 loss: 387.7046, MinusLogProbMetric: 387.7046, val_loss: 392.0321, val_MinusLogProbMetric: 392.0321

Epoch 794: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.7046 - MinusLogProbMetric: 387.7046 - val_loss: 392.0321 - val_MinusLogProbMetric: 392.0321 - lr: 1.0417e-05 - 18s/epoch - 94ms/step
Epoch 795/1000
2023-09-10 08:18:33.281 
Epoch 795/1000 
	 loss: 387.7035, MinusLogProbMetric: 387.7035, val_loss: 391.7794, val_MinusLogProbMetric: 391.7794

Epoch 795: val_loss did not improve from 391.54639
196/196 - 19s - loss: 387.7035 - MinusLogProbMetric: 387.7035 - val_loss: 391.7794 - val_MinusLogProbMetric: 391.7794 - lr: 1.0417e-05 - 19s/epoch - 98ms/step
Epoch 796/1000
2023-09-10 08:18:50.804 
Epoch 796/1000 
	 loss: 387.7170, MinusLogProbMetric: 387.7170, val_loss: 392.1451, val_MinusLogProbMetric: 392.1451

Epoch 796: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.7170 - MinusLogProbMetric: 387.7170 - val_loss: 392.1451 - val_MinusLogProbMetric: 392.1451 - lr: 1.0417e-05 - 18s/epoch - 89ms/step
Epoch 797/1000
2023-09-10 08:19:10.430 
Epoch 797/1000 
	 loss: 387.7080, MinusLogProbMetric: 387.7080, val_loss: 391.9845, val_MinusLogProbMetric: 391.9845

Epoch 797: val_loss did not improve from 391.54639
196/196 - 20s - loss: 387.7080 - MinusLogProbMetric: 387.7080 - val_loss: 391.9845 - val_MinusLogProbMetric: 391.9845 - lr: 1.0417e-05 - 20s/epoch - 100ms/step
Epoch 798/1000
2023-09-10 08:19:28.916 
Epoch 798/1000 
	 loss: 387.7079, MinusLogProbMetric: 387.7079, val_loss: 392.0053, val_MinusLogProbMetric: 392.0053

Epoch 798: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.7079 - MinusLogProbMetric: 387.7079 - val_loss: 392.0053 - val_MinusLogProbMetric: 392.0053 - lr: 1.0417e-05 - 18s/epoch - 94ms/step
Epoch 799/1000
2023-09-10 08:19:46.065 
Epoch 799/1000 
	 loss: 387.7214, MinusLogProbMetric: 387.7214, val_loss: 391.8654, val_MinusLogProbMetric: 391.8654

Epoch 799: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.7214 - MinusLogProbMetric: 387.7214 - val_loss: 391.8654 - val_MinusLogProbMetric: 391.8654 - lr: 1.0417e-05 - 17s/epoch - 87ms/step
Epoch 800/1000
2023-09-10 08:20:03.469 
Epoch 800/1000 
	 loss: 387.7065, MinusLogProbMetric: 387.7065, val_loss: 391.9568, val_MinusLogProbMetric: 391.9568

Epoch 800: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.7065 - MinusLogProbMetric: 387.7065 - val_loss: 391.9568 - val_MinusLogProbMetric: 391.9568 - lr: 1.0417e-05 - 17s/epoch - 89ms/step
Epoch 801/1000
2023-09-10 08:20:22.740 
Epoch 801/1000 
	 loss: 387.7079, MinusLogProbMetric: 387.7079, val_loss: 391.8490, val_MinusLogProbMetric: 391.8490

Epoch 801: val_loss did not improve from 391.54639
196/196 - 19s - loss: 387.7079 - MinusLogProbMetric: 387.7079 - val_loss: 391.8490 - val_MinusLogProbMetric: 391.8490 - lr: 1.0417e-05 - 19s/epoch - 98ms/step
Epoch 802/1000
2023-09-10 08:20:39.579 
Epoch 802/1000 
	 loss: 387.7183, MinusLogProbMetric: 387.7183, val_loss: 391.8955, val_MinusLogProbMetric: 391.8955

Epoch 802: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.7183 - MinusLogProbMetric: 387.7183 - val_loss: 391.8955 - val_MinusLogProbMetric: 391.8955 - lr: 1.0417e-05 - 17s/epoch - 86ms/step
Epoch 803/1000
2023-09-10 08:20:54.676 
Epoch 803/1000 
	 loss: 387.7244, MinusLogProbMetric: 387.7244, val_loss: 391.7987, val_MinusLogProbMetric: 391.7987

Epoch 803: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7244 - MinusLogProbMetric: 387.7244 - val_loss: 391.7987 - val_MinusLogProbMetric: 391.7987 - lr: 1.0417e-05 - 15s/epoch - 77ms/step
Epoch 804/1000
2023-09-10 08:21:10.492 
Epoch 804/1000 
	 loss: 387.7218, MinusLogProbMetric: 387.7218, val_loss: 391.8503, val_MinusLogProbMetric: 391.8503

Epoch 804: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7218 - MinusLogProbMetric: 387.7218 - val_loss: 391.8503 - val_MinusLogProbMetric: 391.8503 - lr: 1.0417e-05 - 16s/epoch - 81ms/step
Epoch 805/1000
2023-09-10 08:21:27.123 
Epoch 805/1000 
	 loss: 387.7464, MinusLogProbMetric: 387.7464, val_loss: 391.7173, val_MinusLogProbMetric: 391.7173

Epoch 805: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.7464 - MinusLogProbMetric: 387.7464 - val_loss: 391.7173 - val_MinusLogProbMetric: 391.7173 - lr: 1.0417e-05 - 17s/epoch - 85ms/step
Epoch 806/1000
2023-09-10 08:21:43.009 
Epoch 806/1000 
	 loss: 387.7191, MinusLogProbMetric: 387.7191, val_loss: 391.9759, val_MinusLogProbMetric: 391.9759

Epoch 806: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.7191 - MinusLogProbMetric: 387.7191 - val_loss: 391.9759 - val_MinusLogProbMetric: 391.9759 - lr: 1.0417e-05 - 16s/epoch - 81ms/step
Epoch 807/1000
2023-09-10 08:21:58.018 
Epoch 807/1000 
	 loss: 387.7190, MinusLogProbMetric: 387.7190, val_loss: 391.8318, val_MinusLogProbMetric: 391.8318

Epoch 807: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.7190 - MinusLogProbMetric: 387.7190 - val_loss: 391.8318 - val_MinusLogProbMetric: 391.8318 - lr: 1.0417e-05 - 15s/epoch - 76ms/step
Epoch 808/1000
2023-09-10 08:22:12.084 
Epoch 808/1000 
	 loss: 387.6196, MinusLogProbMetric: 387.6196, val_loss: 391.8447, val_MinusLogProbMetric: 391.8447

Epoch 808: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.6196 - MinusLogProbMetric: 387.6196 - val_loss: 391.8447 - val_MinusLogProbMetric: 391.8447 - lr: 5.2083e-06 - 14s/epoch - 72ms/step
Epoch 809/1000
2023-09-10 08:22:27.623 
Epoch 809/1000 
	 loss: 387.6335, MinusLogProbMetric: 387.6335, val_loss: 391.7645, val_MinusLogProbMetric: 391.7645

Epoch 809: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6335 - MinusLogProbMetric: 387.6335 - val_loss: 391.7645 - val_MinusLogProbMetric: 391.7645 - lr: 5.2083e-06 - 16s/epoch - 79ms/step
Epoch 810/1000
2023-09-10 08:22:46.089 
Epoch 810/1000 
	 loss: 387.6088, MinusLogProbMetric: 387.6088, val_loss: 391.8130, val_MinusLogProbMetric: 391.8130

Epoch 810: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.6088 - MinusLogProbMetric: 387.6088 - val_loss: 391.8130 - val_MinusLogProbMetric: 391.8130 - lr: 5.2083e-06 - 18s/epoch - 94ms/step
Epoch 811/1000
2023-09-10 08:23:01.795 
Epoch 811/1000 
	 loss: 387.6034, MinusLogProbMetric: 387.6034, val_loss: 391.7569, val_MinusLogProbMetric: 391.7569

Epoch 811: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6034 - MinusLogProbMetric: 387.6034 - val_loss: 391.7569 - val_MinusLogProbMetric: 391.7569 - lr: 5.2083e-06 - 16s/epoch - 80ms/step
Epoch 812/1000
2023-09-10 08:23:19.955 
Epoch 812/1000 
	 loss: 387.5990, MinusLogProbMetric: 387.5990, val_loss: 391.8953, val_MinusLogProbMetric: 391.8953

Epoch 812: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.5990 - MinusLogProbMetric: 387.5990 - val_loss: 391.8953 - val_MinusLogProbMetric: 391.8953 - lr: 5.2083e-06 - 18s/epoch - 93ms/step
Epoch 813/1000
2023-09-10 08:23:38.933 
Epoch 813/1000 
	 loss: 387.5954, MinusLogProbMetric: 387.5954, val_loss: 391.8029, val_MinusLogProbMetric: 391.8029

Epoch 813: val_loss did not improve from 391.54639
196/196 - 19s - loss: 387.5954 - MinusLogProbMetric: 387.5954 - val_loss: 391.8029 - val_MinusLogProbMetric: 391.8029 - lr: 5.2083e-06 - 19s/epoch - 97ms/step
Epoch 814/1000
2023-09-10 08:23:55.191 
Epoch 814/1000 
	 loss: 387.5986, MinusLogProbMetric: 387.5986, val_loss: 391.8777, val_MinusLogProbMetric: 391.8777

Epoch 814: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.5986 - MinusLogProbMetric: 387.5986 - val_loss: 391.8777 - val_MinusLogProbMetric: 391.8777 - lr: 5.2083e-06 - 16s/epoch - 83ms/step
Epoch 815/1000
2023-09-10 08:24:11.422 
Epoch 815/1000 
	 loss: 387.6003, MinusLogProbMetric: 387.6003, val_loss: 392.0267, val_MinusLogProbMetric: 392.0267

Epoch 815: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6003 - MinusLogProbMetric: 387.6003 - val_loss: 392.0267 - val_MinusLogProbMetric: 392.0267 - lr: 5.2083e-06 - 16s/epoch - 83ms/step
Epoch 816/1000
2023-09-10 08:24:25.966 
Epoch 816/1000 
	 loss: 387.5997, MinusLogProbMetric: 387.5997, val_loss: 391.8651, val_MinusLogProbMetric: 391.8651

Epoch 816: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.5997 - MinusLogProbMetric: 387.5997 - val_loss: 391.8651 - val_MinusLogProbMetric: 391.8651 - lr: 5.2083e-06 - 15s/epoch - 74ms/step
Epoch 817/1000
2023-09-10 08:24:41.502 
Epoch 817/1000 
	 loss: 387.6003, MinusLogProbMetric: 387.6003, val_loss: 391.8235, val_MinusLogProbMetric: 391.8235

Epoch 817: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6003 - MinusLogProbMetric: 387.6003 - val_loss: 391.8235 - val_MinusLogProbMetric: 391.8235 - lr: 5.2083e-06 - 16s/epoch - 79ms/step
Epoch 818/1000
2023-09-10 08:24:58.314 
Epoch 818/1000 
	 loss: 387.5955, MinusLogProbMetric: 387.5955, val_loss: 391.8295, val_MinusLogProbMetric: 391.8295

Epoch 818: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.5955 - MinusLogProbMetric: 387.5955 - val_loss: 391.8295 - val_MinusLogProbMetric: 391.8295 - lr: 5.2083e-06 - 17s/epoch - 86ms/step
Epoch 819/1000
2023-09-10 08:25:12.785 
Epoch 819/1000 
	 loss: 387.6076, MinusLogProbMetric: 387.6076, val_loss: 391.6856, val_MinusLogProbMetric: 391.6856

Epoch 819: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.6076 - MinusLogProbMetric: 387.6076 - val_loss: 391.6856 - val_MinusLogProbMetric: 391.6856 - lr: 5.2083e-06 - 14s/epoch - 74ms/step
Epoch 820/1000
2023-09-10 08:25:29.601 
Epoch 820/1000 
	 loss: 387.6001, MinusLogProbMetric: 387.6001, val_loss: 391.8780, val_MinusLogProbMetric: 391.8780

Epoch 820: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.6001 - MinusLogProbMetric: 387.6001 - val_loss: 391.8780 - val_MinusLogProbMetric: 391.8780 - lr: 5.2083e-06 - 17s/epoch - 86ms/step
Epoch 821/1000
2023-09-10 08:25:44.512 
Epoch 821/1000 
	 loss: 387.6038, MinusLogProbMetric: 387.6038, val_loss: 391.8166, val_MinusLogProbMetric: 391.8166

Epoch 821: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.6038 - MinusLogProbMetric: 387.6038 - val_loss: 391.8166 - val_MinusLogProbMetric: 391.8166 - lr: 5.2083e-06 - 15s/epoch - 76ms/step
Epoch 822/1000
2023-09-10 08:25:59.392 
Epoch 822/1000 
	 loss: 387.5954, MinusLogProbMetric: 387.5954, val_loss: 391.6783, val_MinusLogProbMetric: 391.6783

Epoch 822: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.5954 - MinusLogProbMetric: 387.5954 - val_loss: 391.6783 - val_MinusLogProbMetric: 391.6783 - lr: 5.2083e-06 - 15s/epoch - 76ms/step
Epoch 823/1000
2023-09-10 08:26:16.240 
Epoch 823/1000 
	 loss: 387.6017, MinusLogProbMetric: 387.6017, val_loss: 391.7500, val_MinusLogProbMetric: 391.7500

Epoch 823: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.6017 - MinusLogProbMetric: 387.6017 - val_loss: 391.7500 - val_MinusLogProbMetric: 391.7500 - lr: 5.2083e-06 - 17s/epoch - 86ms/step
Epoch 824/1000
2023-09-10 08:26:30.824 
Epoch 824/1000 
	 loss: 387.6025, MinusLogProbMetric: 387.6025, val_loss: 391.7131, val_MinusLogProbMetric: 391.7131

Epoch 824: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.6025 - MinusLogProbMetric: 387.6025 - val_loss: 391.7131 - val_MinusLogProbMetric: 391.7131 - lr: 5.2083e-06 - 15s/epoch - 74ms/step
Epoch 825/1000
2023-09-10 08:26:46.686 
Epoch 825/1000 
	 loss: 387.5950, MinusLogProbMetric: 387.5950, val_loss: 391.7764, val_MinusLogProbMetric: 391.7764

Epoch 825: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.5950 - MinusLogProbMetric: 387.5950 - val_loss: 391.7764 - val_MinusLogProbMetric: 391.7764 - lr: 5.2083e-06 - 16s/epoch - 81ms/step
Epoch 826/1000
2023-09-10 08:27:02.517 
Epoch 826/1000 
	 loss: 387.5964, MinusLogProbMetric: 387.5964, val_loss: 391.9824, val_MinusLogProbMetric: 391.9824

Epoch 826: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.5964 - MinusLogProbMetric: 387.5964 - val_loss: 391.9824 - val_MinusLogProbMetric: 391.9824 - lr: 5.2083e-06 - 16s/epoch - 81ms/step
Epoch 827/1000
2023-09-10 08:27:19.342 
Epoch 827/1000 
	 loss: 387.5980, MinusLogProbMetric: 387.5980, val_loss: 391.9282, val_MinusLogProbMetric: 391.9282

Epoch 827: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.5980 - MinusLogProbMetric: 387.5980 - val_loss: 391.9282 - val_MinusLogProbMetric: 391.9282 - lr: 5.2083e-06 - 17s/epoch - 86ms/step
Epoch 828/1000
2023-09-10 08:27:35.317 
Epoch 828/1000 
	 loss: 387.6011, MinusLogProbMetric: 387.6011, val_loss: 391.9507, val_MinusLogProbMetric: 391.9507

Epoch 828: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6011 - MinusLogProbMetric: 387.6011 - val_loss: 391.9507 - val_MinusLogProbMetric: 391.9507 - lr: 5.2083e-06 - 16s/epoch - 82ms/step
Epoch 829/1000
2023-09-10 08:27:52.433 
Epoch 829/1000 
	 loss: 387.6068, MinusLogProbMetric: 387.6068, val_loss: 391.8635, val_MinusLogProbMetric: 391.8635

Epoch 829: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.6068 - MinusLogProbMetric: 387.6068 - val_loss: 391.8635 - val_MinusLogProbMetric: 391.8635 - lr: 5.2083e-06 - 17s/epoch - 87ms/step
Epoch 830/1000
2023-09-10 08:28:10.510 
Epoch 830/1000 
	 loss: 387.6030, MinusLogProbMetric: 387.6030, val_loss: 391.9159, val_MinusLogProbMetric: 391.9159

Epoch 830: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.6030 - MinusLogProbMetric: 387.6030 - val_loss: 391.9159 - val_MinusLogProbMetric: 391.9159 - lr: 5.2083e-06 - 18s/epoch - 92ms/step
Epoch 831/1000
2023-09-10 08:28:27.139 
Epoch 831/1000 
	 loss: 387.5997, MinusLogProbMetric: 387.5997, val_loss: 391.8730, val_MinusLogProbMetric: 391.8730

Epoch 831: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.5997 - MinusLogProbMetric: 387.5997 - val_loss: 391.8730 - val_MinusLogProbMetric: 391.8730 - lr: 5.2083e-06 - 17s/epoch - 85ms/step
Epoch 832/1000
2023-09-10 08:28:43.825 
Epoch 832/1000 
	 loss: 387.6107, MinusLogProbMetric: 387.6107, val_loss: 391.8684, val_MinusLogProbMetric: 391.8684

Epoch 832: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.6107 - MinusLogProbMetric: 387.6107 - val_loss: 391.8684 - val_MinusLogProbMetric: 391.8684 - lr: 5.2083e-06 - 17s/epoch - 85ms/step
Epoch 833/1000
2023-09-10 08:29:00.231 
Epoch 833/1000 
	 loss: 387.6196, MinusLogProbMetric: 387.6196, val_loss: 391.9558, val_MinusLogProbMetric: 391.9558

Epoch 833: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6196 - MinusLogProbMetric: 387.6196 - val_loss: 391.9558 - val_MinusLogProbMetric: 391.9558 - lr: 5.2083e-06 - 16s/epoch - 84ms/step
Epoch 834/1000
2023-09-10 08:29:18.170 
Epoch 834/1000 
	 loss: 387.6111, MinusLogProbMetric: 387.6111, val_loss: 391.6032, val_MinusLogProbMetric: 391.6032

Epoch 834: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.6111 - MinusLogProbMetric: 387.6111 - val_loss: 391.6032 - val_MinusLogProbMetric: 391.6032 - lr: 5.2083e-06 - 18s/epoch - 91ms/step
Epoch 835/1000
2023-09-10 08:29:37.183 
Epoch 835/1000 
	 loss: 387.6071, MinusLogProbMetric: 387.6071, val_loss: 391.8382, val_MinusLogProbMetric: 391.8382

Epoch 835: val_loss did not improve from 391.54639
196/196 - 19s - loss: 387.6071 - MinusLogProbMetric: 387.6071 - val_loss: 391.8382 - val_MinusLogProbMetric: 391.8382 - lr: 5.2083e-06 - 19s/epoch - 97ms/step
Epoch 836/1000
2023-09-10 08:29:55.208 
Epoch 836/1000 
	 loss: 387.6025, MinusLogProbMetric: 387.6025, val_loss: 391.8307, val_MinusLogProbMetric: 391.8307

Epoch 836: val_loss did not improve from 391.54639
196/196 - 18s - loss: 387.6025 - MinusLogProbMetric: 387.6025 - val_loss: 391.8307 - val_MinusLogProbMetric: 391.8307 - lr: 5.2083e-06 - 18s/epoch - 92ms/step
Epoch 837/1000
2023-09-10 08:30:12.604 
Epoch 837/1000 
	 loss: 387.6039, MinusLogProbMetric: 387.6039, val_loss: 391.8854, val_MinusLogProbMetric: 391.8854

Epoch 837: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.6039 - MinusLogProbMetric: 387.6039 - val_loss: 391.8854 - val_MinusLogProbMetric: 391.8854 - lr: 5.2083e-06 - 17s/epoch - 89ms/step
Epoch 838/1000
2023-09-10 08:30:31.135 
Epoch 838/1000 
	 loss: 387.6094, MinusLogProbMetric: 387.6094, val_loss: 391.8685, val_MinusLogProbMetric: 391.8685

Epoch 838: val_loss did not improve from 391.54639
196/196 - 19s - loss: 387.6094 - MinusLogProbMetric: 387.6094 - val_loss: 391.8685 - val_MinusLogProbMetric: 391.8685 - lr: 5.2083e-06 - 19s/epoch - 95ms/step
Epoch 839/1000
2023-09-10 08:30:46.392 
Epoch 839/1000 
	 loss: 387.6067, MinusLogProbMetric: 387.6067, val_loss: 391.9382, val_MinusLogProbMetric: 391.9382

Epoch 839: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.6067 - MinusLogProbMetric: 387.6067 - val_loss: 391.9382 - val_MinusLogProbMetric: 391.9382 - lr: 5.2083e-06 - 15s/epoch - 78ms/step
Epoch 840/1000
2023-09-10 08:31:00.962 
Epoch 840/1000 
	 loss: 387.6181, MinusLogProbMetric: 387.6181, val_loss: 391.8082, val_MinusLogProbMetric: 391.8082

Epoch 840: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.6181 - MinusLogProbMetric: 387.6181 - val_loss: 391.8082 - val_MinusLogProbMetric: 391.8082 - lr: 5.2083e-06 - 15s/epoch - 74ms/step
Epoch 841/1000
2023-09-10 08:31:16.971 
Epoch 841/1000 
	 loss: 387.6027, MinusLogProbMetric: 387.6027, val_loss: 391.9141, val_MinusLogProbMetric: 391.9141

Epoch 841: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.6027 - MinusLogProbMetric: 387.6027 - val_loss: 391.9141 - val_MinusLogProbMetric: 391.9141 - lr: 5.2083e-06 - 16s/epoch - 82ms/step
Epoch 842/1000
2023-09-10 08:31:32.065 
Epoch 842/1000 
	 loss: 387.6038, MinusLogProbMetric: 387.6038, val_loss: 391.7705, val_MinusLogProbMetric: 391.7705

Epoch 842: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.6038 - MinusLogProbMetric: 387.6038 - val_loss: 391.7705 - val_MinusLogProbMetric: 391.7705 - lr: 5.2083e-06 - 15s/epoch - 77ms/step
Epoch 843/1000
2023-09-10 08:31:47.002 
Epoch 843/1000 
	 loss: 387.6032, MinusLogProbMetric: 387.6032, val_loss: 391.9441, val_MinusLogProbMetric: 391.9441

Epoch 843: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.6032 - MinusLogProbMetric: 387.6032 - val_loss: 391.9441 - val_MinusLogProbMetric: 391.9441 - lr: 5.2083e-06 - 15s/epoch - 76ms/step
Epoch 844/1000
2023-09-10 08:32:01.638 
Epoch 844/1000 
	 loss: 387.6101, MinusLogProbMetric: 387.6101, val_loss: 391.8084, val_MinusLogProbMetric: 391.8084

Epoch 844: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.6101 - MinusLogProbMetric: 387.6101 - val_loss: 391.8084 - val_MinusLogProbMetric: 391.8084 - lr: 5.2083e-06 - 15s/epoch - 75ms/step
Epoch 845/1000
2023-09-10 08:32:15.961 
Epoch 845/1000 
	 loss: 387.6087, MinusLogProbMetric: 387.6087, val_loss: 391.8208, val_MinusLogProbMetric: 391.8208

Epoch 845: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.6087 - MinusLogProbMetric: 387.6087 - val_loss: 391.8208 - val_MinusLogProbMetric: 391.8208 - lr: 5.2083e-06 - 14s/epoch - 73ms/step
Epoch 846/1000
2023-09-10 08:32:32.990 
Epoch 846/1000 
	 loss: 387.5974, MinusLogProbMetric: 387.5974, val_loss: 391.9015, val_MinusLogProbMetric: 391.9015

Epoch 846: val_loss did not improve from 391.54639
196/196 - 17s - loss: 387.5974 - MinusLogProbMetric: 387.5974 - val_loss: 391.9015 - val_MinusLogProbMetric: 391.9015 - lr: 5.2083e-06 - 17s/epoch - 87ms/step
Epoch 847/1000
2023-09-10 08:32:47.331 
Epoch 847/1000 
	 loss: 387.6019, MinusLogProbMetric: 387.6019, val_loss: 391.6645, val_MinusLogProbMetric: 391.6645

Epoch 847: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.6019 - MinusLogProbMetric: 387.6019 - val_loss: 391.6645 - val_MinusLogProbMetric: 391.6645 - lr: 5.2083e-06 - 14s/epoch - 73ms/step
Epoch 848/1000
2023-09-10 08:33:01.284 
Epoch 848/1000 
	 loss: 387.5966, MinusLogProbMetric: 387.5966, val_loss: 391.7794, val_MinusLogProbMetric: 391.7794

Epoch 848: val_loss did not improve from 391.54639
196/196 - 14s - loss: 387.5966 - MinusLogProbMetric: 387.5966 - val_loss: 391.7794 - val_MinusLogProbMetric: 391.7794 - lr: 5.2083e-06 - 14s/epoch - 71ms/step
Epoch 849/1000
2023-09-10 08:33:16.094 
Epoch 849/1000 
	 loss: 387.5950, MinusLogProbMetric: 387.5950, val_loss: 391.6422, val_MinusLogProbMetric: 391.6422

Epoch 849: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.5950 - MinusLogProbMetric: 387.5950 - val_loss: 391.6422 - val_MinusLogProbMetric: 391.6422 - lr: 5.2083e-06 - 15s/epoch - 75ms/step
Epoch 850/1000
2023-09-10 08:33:30.754 
Epoch 850/1000 
	 loss: 387.5850, MinusLogProbMetric: 387.5850, val_loss: 391.8951, val_MinusLogProbMetric: 391.8951

Epoch 850: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.5850 - MinusLogProbMetric: 387.5850 - val_loss: 391.8951 - val_MinusLogProbMetric: 391.8951 - lr: 5.2083e-06 - 15s/epoch - 75ms/step
Epoch 851/1000
2023-09-10 08:33:43.857 
Epoch 851/1000 
	 loss: 387.5887, MinusLogProbMetric: 387.5887, val_loss: 391.9162, val_MinusLogProbMetric: 391.9162

Epoch 851: val_loss did not improve from 391.54639
196/196 - 13s - loss: 387.5887 - MinusLogProbMetric: 387.5887 - val_loss: 391.9162 - val_MinusLogProbMetric: 391.9162 - lr: 5.2083e-06 - 13s/epoch - 67ms/step
Epoch 852/1000
2023-09-10 08:33:58.832 
Epoch 852/1000 
	 loss: 387.5893, MinusLogProbMetric: 387.5893, val_loss: 391.8298, val_MinusLogProbMetric: 391.8298

Epoch 852: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.5893 - MinusLogProbMetric: 387.5893 - val_loss: 391.8298 - val_MinusLogProbMetric: 391.8298 - lr: 5.2083e-06 - 15s/epoch - 76ms/step
Epoch 853/1000
2023-09-10 08:34:14.665 
Epoch 853/1000 
	 loss: 387.5801, MinusLogProbMetric: 387.5801, val_loss: 391.8213, val_MinusLogProbMetric: 391.8213

Epoch 853: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.5801 - MinusLogProbMetric: 387.5801 - val_loss: 391.8213 - val_MinusLogProbMetric: 391.8213 - lr: 5.2083e-06 - 16s/epoch - 81ms/step
Epoch 854/1000
2023-09-10 08:34:30.718 
Epoch 854/1000 
	 loss: 387.5807, MinusLogProbMetric: 387.5807, val_loss: 391.7896, val_MinusLogProbMetric: 391.7896

Epoch 854: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.5807 - MinusLogProbMetric: 387.5807 - val_loss: 391.7896 - val_MinusLogProbMetric: 391.7896 - lr: 5.2083e-06 - 16s/epoch - 82ms/step
Epoch 855/1000
2023-09-10 08:34:45.882 
Epoch 855/1000 
	 loss: 387.5790, MinusLogProbMetric: 387.5790, val_loss: 391.7868, val_MinusLogProbMetric: 391.7868

Epoch 855: val_loss did not improve from 391.54639
196/196 - 15s - loss: 387.5790 - MinusLogProbMetric: 387.5790 - val_loss: 391.7868 - val_MinusLogProbMetric: 391.7868 - lr: 5.2083e-06 - 15s/epoch - 77ms/step
Epoch 856/1000
2023-09-10 08:35:01.842 
Epoch 856/1000 
	 loss: 387.5821, MinusLogProbMetric: 387.5821, val_loss: 392.0786, val_MinusLogProbMetric: 392.0786

Epoch 856: val_loss did not improve from 391.54639
196/196 - 16s - loss: 387.5821 - MinusLogProbMetric: 387.5821 - val_loss: 392.0786 - val_MinusLogProbMetric: 392.0786 - lr: 5.2083e-06 - 16s/epoch - 81ms/step
Epoch 857/1000
2023-09-10 08:35:17.959 
Epoch 857/1000 
	 loss: 387.5766, MinusLogProbMetric: 387.5766, val_loss: 391.7395, val_MinusLogProbMetric: 391.7395

Epoch 857: val_loss did not improve from 391.54639
Restoring model weights from the end of the best epoch: 757.
196/196 - 16s - loss: 387.5766 - MinusLogProbMetric: 387.5766 - val_loss: 391.7395 - val_MinusLogProbMetric: 391.7395 - lr: 5.2083e-06 - 16s/epoch - 83ms/step
Epoch 857: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 1775.6960382930702 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 1752.735068715061 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 1774.2715125780087 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 1741.5395886489423 seconds.
Training succeeded with seed 377.
Model trained in 13631.38 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 7326.71 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 7327.42 s.
===========
Run 331/360 done in 21265.83 s.
===========

Directory ../../results/MAFN_new/run_332/ already exists.
Skipping it.
===========
Run 332/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_333/ already exists.
Skipping it.
===========
Run 333/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_334/ already exists.
Skipping it.
===========
Run 334/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_335/ already exists.
Skipping it.
===========
Run 335/360 already exists. Skipping it.
===========

===========
Generating train data for run 336.
===========
Train data generated in 2.37 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_336/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_336/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_336/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_336
self.data_kwargs: {'seed': 440}
self.x_data: [[ 5.975928    0.18705393  4.579732   ...  5.052782    6.363114
   3.5951567 ]
 [ 8.245443    4.908681    5.163151   ...  2.2962263   8.159441
   6.519855  ]
 [ 5.979998    0.06695901  4.8433633  ...  4.708263    6.650848
   7.1221867 ]
 ...
 [ 8.616862    3.848415    5.171632   ...  3.7576704   8.165923
   7.0578055 ]
 [ 8.209467    4.7939653   5.2042055  ...  3.0320504   8.283145
   7.183658  ]
 [ 6.448749   -0.35270444  4.789608   ...  4.7734337   6.228376
   4.513551  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_47 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_6 (LogProbLa  (None,)                  9018400   
 yer)                                                            
                                                                 
=================================================================
Total params: 9,018,400
Trainable params: 9,018,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_6/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_6'")
self.model: <keras.engine.functional.Functional object at 0x7effb0cd1870>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7efb1c613fa0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7efb1c613fa0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effc208cb80>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7efb1c6dbe20>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7efb1c6a4340>, <keras.callbacks.ModelCheckpoint object at 0x7efb1c6a4400>, <keras.callbacks.EarlyStopping object at 0x7efb1c6a4670>, <keras.callbacks.ReduceLROnPlateau object at 0x7efb1c6a46a0>, <keras.callbacks.TerminateOnNaN object at 0x7efb1c6a42e0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_336/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 336/360 with hyperparameters:
timestamp = 2023-09-10 10:37:32.965885
ndims = 1000
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 9018400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.9759278e+00  1.8705393e-01  4.5797319e+00  7.3813486e+00
  4.9839023e-01  9.1128473e+00  5.1425128e+00  1.0601972e+00
  1.8690022e+00  9.7343407e+00  6.0127983e+00  1.2467406e+00
  2.1360984e+00  5.5741024e+00  8.1917816e-01  3.7718730e+00
  5.1906404e+00  3.0766895e+00  6.0415301e+00  7.3736296e+00
  2.8012948e+00  7.5884948e+00  7.1015620e+00  1.0307134e+01
  6.5797253e+00  7.9973593e+00  3.9854233e+00  1.8046517e+00
  9.7217255e+00  1.0974171e+00  5.1221895e+00  8.3442938e-01
  9.2890491e+00  9.2900143e+00  7.2703452e+00  3.3996055e+00
  2.9350464e+00  2.6254275e+00  1.3082062e+00  5.2701192e+00
  1.3725662e+00  3.2777114e+00  6.2085199e+00  7.2575483e+00
  5.7510644e-02  4.4865317e+00  6.2462301e+00  8.9988785e+00
  4.7538991e+00  9.9086142e+00  2.3183393e+00  4.7639337e-01
  4.5737805e+00  2.5859902e+00  8.1949062e+00  2.6238203e+00
  3.0378006e+00  7.9298201e+00  8.4647675e+00  4.9066219e+00
  6.4023814e+00  3.9823089e+00 -4.2869711e-01  1.5175290e-02
  6.1451683e+00 -2.2587168e-01 -9.5339119e-02  8.5243511e+00
  9.1139994e+00 -1.0624671e-01 -6.7571568e-01  9.4670458e+00
  2.6047506e+00  9.5776010e-01  6.6801319e+00  9.6847260e-01
  3.1678288e+00  9.7247944e+00  6.2540312e+00  6.3839302e+00
  3.4341021e+00  7.7830091e+00  1.6556205e+00  9.9951563e+00
  8.6061764e+00  6.2981930e+00  1.2968564e+00  8.2717495e+00
  9.2503586e+00  5.0443635e+00  4.8242106e+00  1.5439949e+00
  7.4578109e+00  9.9600182e+00  1.0782404e+00  7.4997787e+00
 -6.1716002e-01  1.0503052e+01  6.2509499e+00  5.6324120e+00
  2.8450089e+00  8.2806787e+00  2.7606368e+00  8.2886658e+00
  1.0619202e+01  7.7074742e+00  4.5604439e+00  1.0194874e+00
  4.4170108e+00  4.2977200e+00  1.7771544e+00  4.3124924e+00
  3.5204492e+00  7.5383079e-01  4.9013953e+00  1.8483464e+00
  5.2527041e+00  2.9501736e-01  9.0906477e+00  6.7014809e+00
  5.4151597e+00  8.2172470e+00  9.6032486e+00  1.1688474e+00
  7.4652319e+00  9.9523344e+00  1.0106757e+01  5.6442394e+00
  1.2893100e+00  6.2976708e+00 -6.0980135e-01  2.0239670e+00
  9.4813910e+00  9.1562080e-01  6.0650496e+00  3.3473954e+00
  9.4390936e+00  6.5065956e+00  2.8910985e+00  7.6608114e+00
  1.1822252e+00  2.8502061e+00  2.2126217e+00  7.5678649e+00
  1.3060629e+00  4.1730914e+00  2.7150269e+00  4.2508979e+00
  3.1311915e+00  8.0161762e+00  1.1140229e+00  6.6955643e+00
  2.3109643e+00  2.5608201e+00  9.0579319e+00  8.9470587e+00
  1.9467136e+00  7.7616472e+00  1.1755015e+00  6.9813056e+00
  7.1541829e+00  1.1629101e+00  4.0641637e+00  8.5495291e+00
  1.0037423e+00  3.7546790e-01  5.4117308e+00  3.8483400e+00
  7.5943928e+00  1.0048924e+01  3.0955133e+00  3.7507610e+00
  4.7484083e+00  5.6718163e+00  9.9414043e+00  6.6468272e+00
  5.5795021e+00  2.8773146e+00  9.3531322e+00  1.8336586e+00
  8.0805283e+00  9.5689878e+00  7.0799055e+00  4.9151144e+00
  2.3026161e+00  3.8051813e+00  7.9677577e+00  6.0892525e+00
  9.0358343e+00  8.3774691e+00  8.6793871e+00  8.7717085e+00
  2.5660608e+00  4.4672542e+00  3.7499821e+00  6.0084786e+00
  6.4533715e+00  2.9849510e+00  6.0209244e-01  4.3385081e+00
  3.7030458e+00  9.5341787e+00  9.2192812e+00  7.2649994e+00
  6.9098902e+00  2.3594141e+00  5.7481446e+00  8.3444004e+00
  1.5395805e+00  8.0469885e+00  7.2350705e-01  7.6298466e+00
  7.5203185e+00  6.8629438e-01  6.1138077e+00  5.6196861e+00
  1.5752215e+00  1.0186056e+00  7.5847526e+00  4.9043198e+00
  1.0365025e+01  1.0957176e+01  1.0342247e+01  2.2840269e+00
  8.8948154e+00  2.1656735e+00  4.4965944e+00  6.3290133e+00
  1.9084119e+00  6.1508875e+00  7.1696973e-01  1.0796700e+00
  1.2289739e+00  3.7995231e+00  4.2479050e-01  4.0374312e+00
  6.2082539e+00  3.8042982e+00  1.1126742e+00 -2.8491318e-02
  2.3989291e+00  1.5484333e+00  9.0736609e+00  2.2606084e+00
  7.8717704e+00  5.8197365e+00  5.3839073e+00  4.4864936e+00
  9.7097330e+00  5.1985941e+00  7.8766909e+00  4.8876739e+00
  3.9949443e+00  7.6952267e+00  6.1897888e+00  1.1930196e+00
  4.7831144e+00  7.5184402e+00  7.9867325e+00  9.8890352e+00
  2.8126411e+00  6.6819544e+00  2.9722786e+00  4.3866873e+00
  9.6697216e+00  9.3694468e+00  8.5144243e+00  4.4165196e+00
  8.8433590e+00  4.9158731e+00  4.2708116e+00  6.1693680e-01
  6.9947834e+00  4.8547955e+00  8.8329058e+00  7.1928735e+00
  8.0629263e+00  3.3316441e+00  8.6988659e+00  5.4551535e+00
  5.0940285e+00  7.1205068e+00 -7.6878732e-01  1.4425153e+00
  2.9650118e+00  9.9633141e+00  1.3754138e+00  3.5696523e+00
  1.2369231e+00  3.2220390e+00  4.1846347e+00  9.2791929e+00
  7.7624817e+00  3.6623871e+00  7.8092593e-01  7.3296189e+00
  5.7747946e+00  2.3126864e-01  9.6106710e+00  9.5668274e-01
  8.3702803e+00  2.9747019e+00  4.3602333e+00  7.8842506e+00
  6.2896223e+00  8.5025053e+00  6.1606364e+00  1.0106425e+00
  8.6921835e+00  7.3920555e+00  7.1117039e+00  1.2270844e+00
  4.3614955e+00  2.5761406e+00  8.1967859e+00  6.2408938e+00
  9.4475508e+00  9.6550465e+00  8.4041348e+00  1.0130975e+01
  5.6460967e+00  4.0990400e-01 -8.8367611e-03  3.5952890e+00
  9.2217665e+00  8.4936142e+00  9.9719982e+00  6.2442482e-01
  1.5329283e+00  8.9031639e+00  2.9812365e+00  4.6210904e+00
  9.6318512e+00  3.3671608e+00  6.6170344e+00  4.0481849e+00
  7.8299704e+00  4.1430693e+00  2.1972313e+00  2.7806988e+00
  2.4690957e+00  6.2265091e+00  8.0078650e+00  8.5526848e+00
  7.8363638e+00  6.6496010e+00  1.7129709e+00  3.3299735e+00
  4.1951280e+00  7.1778541e+00  2.9357438e+00  3.2394106e+00
  4.3329515e+00  7.8274932e+00  5.8496819e+00  4.6137288e-01
  7.5736916e-01  3.1835232e+00  7.2212210e+00  7.3863716e+00
  7.1284332e+00  7.4827847e+00  2.6439285e+00  5.7008662e+00
  5.0590334e+00  8.0088997e+00  9.6267881e+00  2.4991486e+00
  8.2448721e+00  6.5369444e+00  6.2472978e+00  7.7897358e+00
  9.4234190e+00  9.6731400e-01  1.6939137e+00  7.3830414e+00
  1.0644419e+00  5.3757925e+00  4.4202948e+00  1.9308488e+00
  8.0857773e+00 -3.4219015e-01  8.6868877e+00  4.4470925e+00
  4.9024949e+00  5.6183209e+00  6.1064873e+00  3.4613369e+00
  1.2080189e+00  3.4117126e+00  4.1149378e-02  6.4430194e+00
  1.9570980e+00  9.7712898e+00  9.6677971e+00  6.8640056e+00
  6.0994020e+00  1.0187636e+01  8.8685141e+00  8.2290039e+00
  3.1689963e+00  3.6186795e+00  2.5079422e+00  3.3114364e+00
  9.9208021e+00  9.1239557e+00  1.3143113e+00  6.8661511e-01
  8.9672060e+00  5.2539353e+00  1.7683913e+00  6.8201876e+00
  6.3931870e+00  1.2865118e+00  3.4232042e+00  1.2203555e+00
  2.0503523e+00  8.4730494e-01  1.9659302e+00  6.6408830e+00
  3.0317956e-01  8.8737220e-01  2.3188889e-01  3.0580165e+00
  3.1296854e+00  2.1522398e+00  7.4903617e+00  9.1460247e+00
  5.0951142e+00  8.5311861e+00  3.9055674e+00 -2.2732937e-01
  4.0364518e+00  2.6478162e+00  5.1365023e+00  7.4299526e+00
  4.6355362e+00  8.9175758e+00  8.7688503e+00  5.5298843e+00
  4.4609528e+00  1.2880317e+00  4.0175514e+00  6.7396054e+00
  3.7963538e+00  1.2283164e+00  9.0873432e+00  7.1056828e+00
  5.5581961e+00  8.0034761e+00  8.3522511e+00  4.6975536e+00
  8.0432367e+00  8.6975918e+00  9.9233341e-01  6.2826734e+00
  5.9927521e+00  5.0778217e+00  8.8290005e+00  2.5841575e+00
  9.9096069e+00  8.9677849e+00  4.5229397e+00  8.1403732e+00
  6.6729965e+00  6.2468095e+00  3.7025385e+00  2.1858666e+00
  7.0194511e+00  8.6221571e+00 -2.3119065e-01  6.4518013e+00
  4.6490231e+00  9.1139078e+00  2.6489720e+00  4.4286499e+00
  4.7887325e+00  1.6389720e+00  8.0717764e+00  8.0382366e+00
  1.3237777e+00  2.9469595e+00  6.6192156e-01  9.5147648e+00
  6.1208944e+00  9.9296083e+00  5.8978138e+00  6.4843559e+00
  4.2908926e+00  3.5816567e+00  3.7703094e+00  7.1296864e+00
  3.3137634e+00  9.1458826e+00  1.0168221e+01  4.6002930e-01
  1.9140388e+00  7.9359615e-01  5.7083476e-01  2.0637333e+00
  4.4295535e+00  8.4761515e+00  2.1790206e+00  4.8846216e+00
  1.1725900e+01  6.4370713e+00  7.5755668e+00  5.3716149e+00
  9.8037472e+00  6.0171165e+00 -1.0524909e+00  2.8919909e+00
  3.9641018e+00  5.4104433e+00  7.7196703e+00  4.5299621e+00
  7.0386343e+00  8.1372356e+00  2.8667083e+00  9.8477182e+00
  6.2275105e+00  8.9304132e+00  5.8799353e+00  7.2770109e+00
  7.7765956e+00  9.1447611e+00  1.3774345e+00  4.7782230e+00
  4.5103283e+00  9.6529636e+00  1.0817671e+00  9.6128826e+00
  8.8991022e+00  7.8995752e-01  5.2336302e+00  7.1597772e+00
  6.9343681e+00  9.0601816e+00  8.0068483e+00  3.5910506e+00
  5.0274186e+00  7.0993495e+00  3.2836149e+00  1.3527107e+00
  3.3847008e+00  3.9555850e+00  8.4203587e+00  5.7436528e+00
  4.4528852e+00  8.3769274e+00  8.4812574e+00  9.8149929e+00
  8.4825897e+00  4.3883948e+00  1.1693200e+00  8.5065060e+00
  1.7731776e+00  3.4153044e+00  9.9896975e+00  8.2860680e+00
  6.3954239e+00  7.1741295e+00  6.7204058e-01  5.1233587e+00
  6.6728873e+00  3.4099829e+00  3.0468628e+00  2.3115411e+00
  4.1901307e+00  4.4959798e+00  5.7105017e+00  7.4096904e+00
  2.9691739e+00  2.5698562e+00  3.1576818e-01 -5.9249759e-02
  2.4639745e+00  7.8125792e+00  7.1327791e+00  7.7584710e+00
  6.2746820e+00  8.4847488e+00  6.9726362e+00  1.0046572e+01
  8.4835949e+00  6.7527709e+00  5.9673371e+00  4.3935239e-01
  1.1263874e+01  1.3709677e+00  7.3908615e+00  7.9875464e+00
  3.9839177e+00  2.2393181e+00  8.4422034e-01  6.9838266e+00
  4.5242758e+00  7.4394574e+00  9.1695070e+00  1.5673304e+00
  9.3064995e+00  3.2363920e+00  3.0193369e+00  9.7506819e+00
  9.7927599e+00  2.1529837e+00  5.8980074e+00  1.1057787e+00
  6.5593362e+00  8.3812113e+00  5.5978317e+00  3.2321651e+00
  3.8758488e+00  4.0856094e+00  7.0214200e+00  8.6556015e+00
  9.3241930e+00  2.9402196e-02  1.4503651e+00  4.8388457e-01
  2.0156007e+00  4.3253636e+00  5.0806727e+00  6.2870202e+00
  8.3587704e+00  9.1714058e+00  1.1041972e+01  6.7473054e+00
  8.3084793e+00  7.5109200e+00  3.7499793e+00  7.7249527e+00
  3.9467406e-01  6.4965940e-01  2.9256980e+00  4.6755557e+00
  6.6328969e+00  1.9519567e-01  7.0285888e+00  8.4598532e+00
  1.9452683e+00  4.4380093e+00  4.9697065e+00  4.4265666e+00
  7.9045653e+00  9.4661942e+00  8.0525227e+00  8.8097310e-01
  6.8595657e+00  1.7693057e+00  2.4858186e+00  1.4309098e+00
  1.8431244e+00  4.7576222e+00  6.7128339e+00  4.3999271e+00
  9.4328070e+00  2.1000056e+00  7.5769453e+00  8.7397270e+00
  5.8346295e+00  4.8793106e+00  4.7135677e+00  4.4952607e+00
  5.7733207e+00  3.9166284e+00  4.1439590e+00  6.8955579e+00
  6.8403614e-01  2.0110247e+00  9.0629015e+00  8.0548077e+00
  2.7293277e+00  4.2169027e+00  9.2188635e+00  9.0293961e+00
  6.1455669e+00  2.1301951e+00  5.6030965e-01  4.4237075e+00
  7.3219604e+00  8.5027437e+00  8.5191278e+00  4.1766196e-01
  2.4718022e+00  3.2887347e+00  1.7133644e+00  7.1094151e+00
  7.3223224e+00  4.3398414e+00  9.8931112e+00  1.3441966e+00
  9.0235968e+00  1.2211851e+00  2.6455071e+00  7.5472803e+00
  1.1029721e+00  4.7136912e+00  2.8467078e+00  7.3037176e+00
  9.4062443e+00  7.6552663e+00  8.4975100e+00  6.3747257e-02
  2.3440433e+00  5.1499615e+00  3.5230517e+00  1.9831378e+00
  3.5230274e+00  9.6046629e+00  3.3157225e+00  4.3171234e+00
  1.3997978e+00  7.7749600e+00  3.3477159e+00  1.9058161e+00
  2.5061352e+00  9.0734358e+00  2.0535131e+00  8.7670698e+00
  7.5356512e+00  1.0142322e+01 -3.0124056e-01  2.2794275e+00
  7.4697652e+00  1.9831645e+00  2.1713405e+00  2.2061615e+00
  1.5869830e+00  4.8229289e+00  1.4017915e+00  3.4431477e+00
  4.9791493e+00  7.0362866e-01  4.3548961e+00  6.2790900e-01
  5.3626833e+00  9.2004957e+00  7.4519486e+00  9.5844626e-01
  5.9674959e+00  8.2974005e+00  2.5478227e+00  7.6181903e+00
  8.8209562e+00  7.9951472e+00  2.8410530e-01  4.9098748e-01
  2.0705619e+00  2.6533947e+00  5.7332134e+00  2.9440532e+00
  7.7568593e+00  3.6492581e+00  2.4384577e+00  2.8873272e+00
  9.4621639e+00  9.1508560e+00  2.0058784e+00  6.5649538e+00
  2.7415826e+00  8.4922266e+00  4.9448359e-01  7.5271797e+00
 -1.5808821e-01  9.7426481e+00  6.3803730e+00  8.4051380e+00
  5.7340975e+00  4.6641579e+00  6.2364306e+00  5.1810746e+00
  5.3571901e+00  8.9868603e+00  1.8257052e+00  8.8656920e-01
  4.3585706e+00  3.5430098e+00  7.3958582e-01  8.3649902e+00
  7.7803888e+00  5.7408032e+00  9.7680950e+00  6.9590604e-01
  7.2661672e+00  2.1069894e+00  3.6764739e+00  3.4602623e+00
  7.6012840e+00  2.0565724e-01  8.5318031e+00  7.2798491e+00
  1.4081079e+00  8.3596611e+00  7.2540979e+00  9.5279789e+00
  7.3339424e+00  5.2405219e+00  8.5954704e+00  2.9429979e+00
  5.2126360e+00  3.8612814e+00  9.0659313e+00  1.9871573e+00
  3.8985163e-01  3.2772667e+00  4.5025587e+00  1.2284964e-02
  6.7665458e+00  9.5286417e+00  7.1374736e+00  6.0702968e+00
  9.5389080e+00  9.5242043e+00  8.4405804e+00  6.5415311e+00
  4.7715144e+00  1.9164640e-01  6.2476826e+00  9.6162710e+00
  8.1386156e+00  3.4102411e+00  1.4985125e+00  7.9778295e+00
  7.4183102e+00  9.5704803e+00  7.8087254e+00  6.9231396e+00
  1.3841813e+00  4.7959905e+00  2.9273345e+00  5.1850367e+00
  3.0295143e+00  8.6389799e+00  9.0257702e+00  3.6582994e+00
  5.9157324e+00  4.1758962e+00  9.3391609e+00  1.7730776e+00
  7.6125379e+00  1.0046360e+01  2.1057978e+00  1.7478250e+00
  7.1132212e+00  7.9645081e+00  5.2505498e+00  6.4574647e+00
  3.2315047e+00  4.3446302e+00  1.2056727e+00  2.9674428e+00
  2.7837610e+00  4.7524495e+00  9.8256521e+00  1.5932522e+00
  4.8396316e+00  5.9174523e+00  9.4890871e+00  1.2948707e+00
  9.0378551e+00  1.3124785e+00  5.4293876e+00  4.4993534e+00
  2.0538125e+00  3.5617321e+00  5.4850354e+00  8.2304430e+00
  9.7063475e+00  4.5277615e+00  8.3297014e+00  6.6988935e+00
  3.0370085e+00  2.5210819e+00  4.3796597e+00  5.5016708e+00
  1.9651670e+00  2.4778838e+00  5.8789811e+00  3.1068649e+00
  8.4105711e+00  2.6629505e+00 -3.3057988e-01  9.0704960e-01
  9.3188791e+00  1.0806879e+00 -8.1481934e-03  9.1659679e+00
  2.1467557e+00  7.2326632e+00  8.2058630e+00  5.8045855e+00
  8.4636183e+00  6.8212204e+00  5.0721443e-01  5.9133248e+00
  7.4281392e+00  7.8691220e+00 -6.8311334e-02  7.2124262e+00
  8.6880360e+00  6.6583366e+00  5.0127316e+00  4.6381230e+00
  5.9561200e+00  6.8466635e+00  9.5994196e+00  6.0355244e+00
  8.7480297e+00  7.6578970e+00  1.2954912e+00  4.2609344e+00
  2.7702582e+00  3.0329621e+00  3.6327574e+00  3.4195125e+00
  5.5413127e+00  5.8191652e+00  2.7070973e+00  1.6614884e+00
  3.8416210e-01  6.2802663e+00  2.0622129e+00 -6.8790317e-01
  9.2128534e+00  4.7458625e+00  9.4553316e-01  8.3560362e+00
  9.9401188e+00  3.5302291e+00  4.7089720e-01  1.3786711e+00
  5.3229847e+00  9.2913418e+00  1.6849303e+00  8.2535496e+00
 -2.5821114e-01  4.1421123e+00  6.4032269e+00  6.6551906e-01
  5.3515515e+00  9.1520185e+00  1.5094744e+00  7.4785428e+00
  6.0626564e+00  1.8558639e+00  4.4214793e-02  7.5862879e-01
  4.2469244e+00  8.8614159e+00  6.5688152e+00  7.3740344e+00
  4.8993049e+00  5.7953315e+00  9.2521513e-01  8.7253218e+00
  7.7945423e+00  9.9947720e+00  3.9001837e+00  2.8082497e+00
  2.2034130e+00  9.5151176e+00  7.4653130e+00  5.4289103e-01
  5.5686536e+00  4.1999950e+00  1.3804873e+00  1.5220041e+00
  9.6445208e+00  3.1844208e+00  8.2594252e+00  5.8706766e-01
  3.8130655e+00  9.4813788e-01  1.4116070e-01  5.6962514e+00
  2.8564551e+00  7.0057955e+00  6.3632298e+00  1.4823904e+00
  9.5153828e+00  7.8791199e+00  2.7109826e+00  5.3147154e+00
  7.3835139e+00  3.6906118e+00  4.5995116e+00  4.1400166e+00
  6.1948090e+00  8.8411551e+00  1.6546024e+00  8.7375402e+00
  5.7898629e-01  6.4826312e+00  4.3135948e+00  7.4583459e+00
  6.8681207e+00  5.0527821e+00  6.3631139e+00  3.5951567e+00]
Epoch 1/1000
2023-09-10 10:39:07.349 
Epoch 1/1000 
	 loss: 1481.6477, MinusLogProbMetric: 1481.6477, val_loss: 589.9567, val_MinusLogProbMetric: 589.9567

Epoch 1: val_loss improved from inf to 589.95673, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 94s - loss: 1481.6477 - MinusLogProbMetric: 1481.6477 - val_loss: 589.9567 - val_MinusLogProbMetric: 589.9567 - lr: 0.0010 - 94s/epoch - 482ms/step
Epoch 2/1000
2023-09-10 10:39:23.169 
Epoch 2/1000 
	 loss: 563.3990, MinusLogProbMetric: 563.3990, val_loss: 520.4138, val_MinusLogProbMetric: 520.4138

Epoch 2: val_loss improved from 589.95673 to 520.41382, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 563.3990 - MinusLogProbMetric: 563.3990 - val_loss: 520.4138 - val_MinusLogProbMetric: 520.4138 - lr: 0.0010 - 16s/epoch - 80ms/step
Epoch 3/1000
2023-09-10 10:39:40.107 
Epoch 3/1000 
	 loss: 522.5123, MinusLogProbMetric: 522.5123, val_loss: 513.5709, val_MinusLogProbMetric: 513.5709

Epoch 3: val_loss improved from 520.41382 to 513.57086, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 522.5123 - MinusLogProbMetric: 522.5123 - val_loss: 513.5709 - val_MinusLogProbMetric: 513.5709 - lr: 0.0010 - 17s/epoch - 86ms/step
Epoch 4/1000
2023-09-10 10:39:57.775 
Epoch 4/1000 
	 loss: 522.1628, MinusLogProbMetric: 522.1628, val_loss: 497.9836, val_MinusLogProbMetric: 497.9836

Epoch 4: val_loss improved from 513.57086 to 497.98358, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 18s - loss: 522.1628 - MinusLogProbMetric: 522.1628 - val_loss: 497.9836 - val_MinusLogProbMetric: 497.9836 - lr: 0.0010 - 18s/epoch - 91ms/step
Epoch 5/1000
2023-09-10 10:40:14.986 
Epoch 5/1000 
	 loss: 484.8287, MinusLogProbMetric: 484.8287, val_loss: 504.1241, val_MinusLogProbMetric: 504.1241

Epoch 5: val_loss did not improve from 497.98358
196/196 - 16s - loss: 484.8287 - MinusLogProbMetric: 484.8287 - val_loss: 504.1241 - val_MinusLogProbMetric: 504.1241 - lr: 0.0010 - 16s/epoch - 83ms/step
Epoch 6/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 92: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-10 10:40:23.441 
Epoch 6/1000 
	 loss: nan, MinusLogProbMetric: 71938792.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 6: val_loss did not improve from 497.98358
196/196 - 8s - loss: nan - MinusLogProbMetric: 71938792.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 8s/epoch - 43ms/step
The loss history contains NaN values.
Training failed: trying again with seed 978294 and lr 0.0003333333333333333.
===========
Generating train data for run 336.
===========
Train data generated in 2.33 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_336/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_336/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_336/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_336
self.data_kwargs: {'seed': 440}
self.x_data: [[ 5.975928    0.18705393  4.579732   ...  5.052782    6.363114
   3.5951567 ]
 [ 8.245443    4.908681    5.163151   ...  2.2962263   8.159441
   6.519855  ]
 [ 5.979998    0.06695901  4.8433633  ...  4.708263    6.650848
   7.1221867 ]
 ...
 [ 8.616862    3.848415    5.171632   ...  3.7576704   8.165923
   7.0578055 ]
 [ 8.209467    4.7939653   5.2042055  ...  3.0320504   8.283145
   7.183658  ]
 [ 6.448749   -0.35270444  4.789608   ...  4.7734337   6.228376
   4.513551  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_58 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_7 (LogProbLa  (None,)                  9018400   
 yer)                                                            
                                                                 
=================================================================
Total params: 9,018,400
Trainable params: 9,018,400
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_7/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_7'")
self.model: <keras.engine.functional.Functional object at 0x7effb141a050>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effb14ceef0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effb14ceef0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effca863970>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7efb043eacb0>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7efb24068460>, <keras.callbacks.ModelCheckpoint object at 0x7effca863a30>, <keras.callbacks.EarlyStopping object at 0x7efb78402560>, <keras.callbacks.ReduceLROnPlateau object at 0x7effca863af0>, <keras.callbacks.TerminateOnNaN object at 0x7effca862740>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 336/360 with hyperparameters:
timestamp = 2023-09-10 10:40:31.539652
ndims = 1000
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 9018400
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 5.9759278e+00  1.8705393e-01  4.5797319e+00  7.3813486e+00
  4.9839023e-01  9.1128473e+00  5.1425128e+00  1.0601972e+00
  1.8690022e+00  9.7343407e+00  6.0127983e+00  1.2467406e+00
  2.1360984e+00  5.5741024e+00  8.1917816e-01  3.7718730e+00
  5.1906404e+00  3.0766895e+00  6.0415301e+00  7.3736296e+00
  2.8012948e+00  7.5884948e+00  7.1015620e+00  1.0307134e+01
  6.5797253e+00  7.9973593e+00  3.9854233e+00  1.8046517e+00
  9.7217255e+00  1.0974171e+00  5.1221895e+00  8.3442938e-01
  9.2890491e+00  9.2900143e+00  7.2703452e+00  3.3996055e+00
  2.9350464e+00  2.6254275e+00  1.3082062e+00  5.2701192e+00
  1.3725662e+00  3.2777114e+00  6.2085199e+00  7.2575483e+00
  5.7510644e-02  4.4865317e+00  6.2462301e+00  8.9988785e+00
  4.7538991e+00  9.9086142e+00  2.3183393e+00  4.7639337e-01
  4.5737805e+00  2.5859902e+00  8.1949062e+00  2.6238203e+00
  3.0378006e+00  7.9298201e+00  8.4647675e+00  4.9066219e+00
  6.4023814e+00  3.9823089e+00 -4.2869711e-01  1.5175290e-02
  6.1451683e+00 -2.2587168e-01 -9.5339119e-02  8.5243511e+00
  9.1139994e+00 -1.0624671e-01 -6.7571568e-01  9.4670458e+00
  2.6047506e+00  9.5776010e-01  6.6801319e+00  9.6847260e-01
  3.1678288e+00  9.7247944e+00  6.2540312e+00  6.3839302e+00
  3.4341021e+00  7.7830091e+00  1.6556205e+00  9.9951563e+00
  8.6061764e+00  6.2981930e+00  1.2968564e+00  8.2717495e+00
  9.2503586e+00  5.0443635e+00  4.8242106e+00  1.5439949e+00
  7.4578109e+00  9.9600182e+00  1.0782404e+00  7.4997787e+00
 -6.1716002e-01  1.0503052e+01  6.2509499e+00  5.6324120e+00
  2.8450089e+00  8.2806787e+00  2.7606368e+00  8.2886658e+00
  1.0619202e+01  7.7074742e+00  4.5604439e+00  1.0194874e+00
  4.4170108e+00  4.2977200e+00  1.7771544e+00  4.3124924e+00
  3.5204492e+00  7.5383079e-01  4.9013953e+00  1.8483464e+00
  5.2527041e+00  2.9501736e-01  9.0906477e+00  6.7014809e+00
  5.4151597e+00  8.2172470e+00  9.6032486e+00  1.1688474e+00
  7.4652319e+00  9.9523344e+00  1.0106757e+01  5.6442394e+00
  1.2893100e+00  6.2976708e+00 -6.0980135e-01  2.0239670e+00
  9.4813910e+00  9.1562080e-01  6.0650496e+00  3.3473954e+00
  9.4390936e+00  6.5065956e+00  2.8910985e+00  7.6608114e+00
  1.1822252e+00  2.8502061e+00  2.2126217e+00  7.5678649e+00
  1.3060629e+00  4.1730914e+00  2.7150269e+00  4.2508979e+00
  3.1311915e+00  8.0161762e+00  1.1140229e+00  6.6955643e+00
  2.3109643e+00  2.5608201e+00  9.0579319e+00  8.9470587e+00
  1.9467136e+00  7.7616472e+00  1.1755015e+00  6.9813056e+00
  7.1541829e+00  1.1629101e+00  4.0641637e+00  8.5495291e+00
  1.0037423e+00  3.7546790e-01  5.4117308e+00  3.8483400e+00
  7.5943928e+00  1.0048924e+01  3.0955133e+00  3.7507610e+00
  4.7484083e+00  5.6718163e+00  9.9414043e+00  6.6468272e+00
  5.5795021e+00  2.8773146e+00  9.3531322e+00  1.8336586e+00
  8.0805283e+00  9.5689878e+00  7.0799055e+00  4.9151144e+00
  2.3026161e+00  3.8051813e+00  7.9677577e+00  6.0892525e+00
  9.0358343e+00  8.3774691e+00  8.6793871e+00  8.7717085e+00
  2.5660608e+00  4.4672542e+00  3.7499821e+00  6.0084786e+00
  6.4533715e+00  2.9849510e+00  6.0209244e-01  4.3385081e+00
  3.7030458e+00  9.5341787e+00  9.2192812e+00  7.2649994e+00
  6.9098902e+00  2.3594141e+00  5.7481446e+00  8.3444004e+00
  1.5395805e+00  8.0469885e+00  7.2350705e-01  7.6298466e+00
  7.5203185e+00  6.8629438e-01  6.1138077e+00  5.6196861e+00
  1.5752215e+00  1.0186056e+00  7.5847526e+00  4.9043198e+00
  1.0365025e+01  1.0957176e+01  1.0342247e+01  2.2840269e+00
  8.8948154e+00  2.1656735e+00  4.4965944e+00  6.3290133e+00
  1.9084119e+00  6.1508875e+00  7.1696973e-01  1.0796700e+00
  1.2289739e+00  3.7995231e+00  4.2479050e-01  4.0374312e+00
  6.2082539e+00  3.8042982e+00  1.1126742e+00 -2.8491318e-02
  2.3989291e+00  1.5484333e+00  9.0736609e+00  2.2606084e+00
  7.8717704e+00  5.8197365e+00  5.3839073e+00  4.4864936e+00
  9.7097330e+00  5.1985941e+00  7.8766909e+00  4.8876739e+00
  3.9949443e+00  7.6952267e+00  6.1897888e+00  1.1930196e+00
  4.7831144e+00  7.5184402e+00  7.9867325e+00  9.8890352e+00
  2.8126411e+00  6.6819544e+00  2.9722786e+00  4.3866873e+00
  9.6697216e+00  9.3694468e+00  8.5144243e+00  4.4165196e+00
  8.8433590e+00  4.9158731e+00  4.2708116e+00  6.1693680e-01
  6.9947834e+00  4.8547955e+00  8.8329058e+00  7.1928735e+00
  8.0629263e+00  3.3316441e+00  8.6988659e+00  5.4551535e+00
  5.0940285e+00  7.1205068e+00 -7.6878732e-01  1.4425153e+00
  2.9650118e+00  9.9633141e+00  1.3754138e+00  3.5696523e+00
  1.2369231e+00  3.2220390e+00  4.1846347e+00  9.2791929e+00
  7.7624817e+00  3.6623871e+00  7.8092593e-01  7.3296189e+00
  5.7747946e+00  2.3126864e-01  9.6106710e+00  9.5668274e-01
  8.3702803e+00  2.9747019e+00  4.3602333e+00  7.8842506e+00
  6.2896223e+00  8.5025053e+00  6.1606364e+00  1.0106425e+00
  8.6921835e+00  7.3920555e+00  7.1117039e+00  1.2270844e+00
  4.3614955e+00  2.5761406e+00  8.1967859e+00  6.2408938e+00
  9.4475508e+00  9.6550465e+00  8.4041348e+00  1.0130975e+01
  5.6460967e+00  4.0990400e-01 -8.8367611e-03  3.5952890e+00
  9.2217665e+00  8.4936142e+00  9.9719982e+00  6.2442482e-01
  1.5329283e+00  8.9031639e+00  2.9812365e+00  4.6210904e+00
  9.6318512e+00  3.3671608e+00  6.6170344e+00  4.0481849e+00
  7.8299704e+00  4.1430693e+00  2.1972313e+00  2.7806988e+00
  2.4690957e+00  6.2265091e+00  8.0078650e+00  8.5526848e+00
  7.8363638e+00  6.6496010e+00  1.7129709e+00  3.3299735e+00
  4.1951280e+00  7.1778541e+00  2.9357438e+00  3.2394106e+00
  4.3329515e+00  7.8274932e+00  5.8496819e+00  4.6137288e-01
  7.5736916e-01  3.1835232e+00  7.2212210e+00  7.3863716e+00
  7.1284332e+00  7.4827847e+00  2.6439285e+00  5.7008662e+00
  5.0590334e+00  8.0088997e+00  9.6267881e+00  2.4991486e+00
  8.2448721e+00  6.5369444e+00  6.2472978e+00  7.7897358e+00
  9.4234190e+00  9.6731400e-01  1.6939137e+00  7.3830414e+00
  1.0644419e+00  5.3757925e+00  4.4202948e+00  1.9308488e+00
  8.0857773e+00 -3.4219015e-01  8.6868877e+00  4.4470925e+00
  4.9024949e+00  5.6183209e+00  6.1064873e+00  3.4613369e+00
  1.2080189e+00  3.4117126e+00  4.1149378e-02  6.4430194e+00
  1.9570980e+00  9.7712898e+00  9.6677971e+00  6.8640056e+00
  6.0994020e+00  1.0187636e+01  8.8685141e+00  8.2290039e+00
  3.1689963e+00  3.6186795e+00  2.5079422e+00  3.3114364e+00
  9.9208021e+00  9.1239557e+00  1.3143113e+00  6.8661511e-01
  8.9672060e+00  5.2539353e+00  1.7683913e+00  6.8201876e+00
  6.3931870e+00  1.2865118e+00  3.4232042e+00  1.2203555e+00
  2.0503523e+00  8.4730494e-01  1.9659302e+00  6.6408830e+00
  3.0317956e-01  8.8737220e-01  2.3188889e-01  3.0580165e+00
  3.1296854e+00  2.1522398e+00  7.4903617e+00  9.1460247e+00
  5.0951142e+00  8.5311861e+00  3.9055674e+00 -2.2732937e-01
  4.0364518e+00  2.6478162e+00  5.1365023e+00  7.4299526e+00
  4.6355362e+00  8.9175758e+00  8.7688503e+00  5.5298843e+00
  4.4609528e+00  1.2880317e+00  4.0175514e+00  6.7396054e+00
  3.7963538e+00  1.2283164e+00  9.0873432e+00  7.1056828e+00
  5.5581961e+00  8.0034761e+00  8.3522511e+00  4.6975536e+00
  8.0432367e+00  8.6975918e+00  9.9233341e-01  6.2826734e+00
  5.9927521e+00  5.0778217e+00  8.8290005e+00  2.5841575e+00
  9.9096069e+00  8.9677849e+00  4.5229397e+00  8.1403732e+00
  6.6729965e+00  6.2468095e+00  3.7025385e+00  2.1858666e+00
  7.0194511e+00  8.6221571e+00 -2.3119065e-01  6.4518013e+00
  4.6490231e+00  9.1139078e+00  2.6489720e+00  4.4286499e+00
  4.7887325e+00  1.6389720e+00  8.0717764e+00  8.0382366e+00
  1.3237777e+00  2.9469595e+00  6.6192156e-01  9.5147648e+00
  6.1208944e+00  9.9296083e+00  5.8978138e+00  6.4843559e+00
  4.2908926e+00  3.5816567e+00  3.7703094e+00  7.1296864e+00
  3.3137634e+00  9.1458826e+00  1.0168221e+01  4.6002930e-01
  1.9140388e+00  7.9359615e-01  5.7083476e-01  2.0637333e+00
  4.4295535e+00  8.4761515e+00  2.1790206e+00  4.8846216e+00
  1.1725900e+01  6.4370713e+00  7.5755668e+00  5.3716149e+00
  9.8037472e+00  6.0171165e+00 -1.0524909e+00  2.8919909e+00
  3.9641018e+00  5.4104433e+00  7.7196703e+00  4.5299621e+00
  7.0386343e+00  8.1372356e+00  2.8667083e+00  9.8477182e+00
  6.2275105e+00  8.9304132e+00  5.8799353e+00  7.2770109e+00
  7.7765956e+00  9.1447611e+00  1.3774345e+00  4.7782230e+00
  4.5103283e+00  9.6529636e+00  1.0817671e+00  9.6128826e+00
  8.8991022e+00  7.8995752e-01  5.2336302e+00  7.1597772e+00
  6.9343681e+00  9.0601816e+00  8.0068483e+00  3.5910506e+00
  5.0274186e+00  7.0993495e+00  3.2836149e+00  1.3527107e+00
  3.3847008e+00  3.9555850e+00  8.4203587e+00  5.7436528e+00
  4.4528852e+00  8.3769274e+00  8.4812574e+00  9.8149929e+00
  8.4825897e+00  4.3883948e+00  1.1693200e+00  8.5065060e+00
  1.7731776e+00  3.4153044e+00  9.9896975e+00  8.2860680e+00
  6.3954239e+00  7.1741295e+00  6.7204058e-01  5.1233587e+00
  6.6728873e+00  3.4099829e+00  3.0468628e+00  2.3115411e+00
  4.1901307e+00  4.4959798e+00  5.7105017e+00  7.4096904e+00
  2.9691739e+00  2.5698562e+00  3.1576818e-01 -5.9249759e-02
  2.4639745e+00  7.8125792e+00  7.1327791e+00  7.7584710e+00
  6.2746820e+00  8.4847488e+00  6.9726362e+00  1.0046572e+01
  8.4835949e+00  6.7527709e+00  5.9673371e+00  4.3935239e-01
  1.1263874e+01  1.3709677e+00  7.3908615e+00  7.9875464e+00
  3.9839177e+00  2.2393181e+00  8.4422034e-01  6.9838266e+00
  4.5242758e+00  7.4394574e+00  9.1695070e+00  1.5673304e+00
  9.3064995e+00  3.2363920e+00  3.0193369e+00  9.7506819e+00
  9.7927599e+00  2.1529837e+00  5.8980074e+00  1.1057787e+00
  6.5593362e+00  8.3812113e+00  5.5978317e+00  3.2321651e+00
  3.8758488e+00  4.0856094e+00  7.0214200e+00  8.6556015e+00
  9.3241930e+00  2.9402196e-02  1.4503651e+00  4.8388457e-01
  2.0156007e+00  4.3253636e+00  5.0806727e+00  6.2870202e+00
  8.3587704e+00  9.1714058e+00  1.1041972e+01  6.7473054e+00
  8.3084793e+00  7.5109200e+00  3.7499793e+00  7.7249527e+00
  3.9467406e-01  6.4965940e-01  2.9256980e+00  4.6755557e+00
  6.6328969e+00  1.9519567e-01  7.0285888e+00  8.4598532e+00
  1.9452683e+00  4.4380093e+00  4.9697065e+00  4.4265666e+00
  7.9045653e+00  9.4661942e+00  8.0525227e+00  8.8097310e-01
  6.8595657e+00  1.7693057e+00  2.4858186e+00  1.4309098e+00
  1.8431244e+00  4.7576222e+00  6.7128339e+00  4.3999271e+00
  9.4328070e+00  2.1000056e+00  7.5769453e+00  8.7397270e+00
  5.8346295e+00  4.8793106e+00  4.7135677e+00  4.4952607e+00
  5.7733207e+00  3.9166284e+00  4.1439590e+00  6.8955579e+00
  6.8403614e-01  2.0110247e+00  9.0629015e+00  8.0548077e+00
  2.7293277e+00  4.2169027e+00  9.2188635e+00  9.0293961e+00
  6.1455669e+00  2.1301951e+00  5.6030965e-01  4.4237075e+00
  7.3219604e+00  8.5027437e+00  8.5191278e+00  4.1766196e-01
  2.4718022e+00  3.2887347e+00  1.7133644e+00  7.1094151e+00
  7.3223224e+00  4.3398414e+00  9.8931112e+00  1.3441966e+00
  9.0235968e+00  1.2211851e+00  2.6455071e+00  7.5472803e+00
  1.1029721e+00  4.7136912e+00  2.8467078e+00  7.3037176e+00
  9.4062443e+00  7.6552663e+00  8.4975100e+00  6.3747257e-02
  2.3440433e+00  5.1499615e+00  3.5230517e+00  1.9831378e+00
  3.5230274e+00  9.6046629e+00  3.3157225e+00  4.3171234e+00
  1.3997978e+00  7.7749600e+00  3.3477159e+00  1.9058161e+00
  2.5061352e+00  9.0734358e+00  2.0535131e+00  8.7670698e+00
  7.5356512e+00  1.0142322e+01 -3.0124056e-01  2.2794275e+00
  7.4697652e+00  1.9831645e+00  2.1713405e+00  2.2061615e+00
  1.5869830e+00  4.8229289e+00  1.4017915e+00  3.4431477e+00
  4.9791493e+00  7.0362866e-01  4.3548961e+00  6.2790900e-01
  5.3626833e+00  9.2004957e+00  7.4519486e+00  9.5844626e-01
  5.9674959e+00  8.2974005e+00  2.5478227e+00  7.6181903e+00
  8.8209562e+00  7.9951472e+00  2.8410530e-01  4.9098748e-01
  2.0705619e+00  2.6533947e+00  5.7332134e+00  2.9440532e+00
  7.7568593e+00  3.6492581e+00  2.4384577e+00  2.8873272e+00
  9.4621639e+00  9.1508560e+00  2.0058784e+00  6.5649538e+00
  2.7415826e+00  8.4922266e+00  4.9448359e-01  7.5271797e+00
 -1.5808821e-01  9.7426481e+00  6.3803730e+00  8.4051380e+00
  5.7340975e+00  4.6641579e+00  6.2364306e+00  5.1810746e+00
  5.3571901e+00  8.9868603e+00  1.8257052e+00  8.8656920e-01
  4.3585706e+00  3.5430098e+00  7.3958582e-01  8.3649902e+00
  7.7803888e+00  5.7408032e+00  9.7680950e+00  6.9590604e-01
  7.2661672e+00  2.1069894e+00  3.6764739e+00  3.4602623e+00
  7.6012840e+00  2.0565724e-01  8.5318031e+00  7.2798491e+00
  1.4081079e+00  8.3596611e+00  7.2540979e+00  9.5279789e+00
  7.3339424e+00  5.2405219e+00  8.5954704e+00  2.9429979e+00
  5.2126360e+00  3.8612814e+00  9.0659313e+00  1.9871573e+00
  3.8985163e-01  3.2772667e+00  4.5025587e+00  1.2284964e-02
  6.7665458e+00  9.5286417e+00  7.1374736e+00  6.0702968e+00
  9.5389080e+00  9.5242043e+00  8.4405804e+00  6.5415311e+00
  4.7715144e+00  1.9164640e-01  6.2476826e+00  9.6162710e+00
  8.1386156e+00  3.4102411e+00  1.4985125e+00  7.9778295e+00
  7.4183102e+00  9.5704803e+00  7.8087254e+00  6.9231396e+00
  1.3841813e+00  4.7959905e+00  2.9273345e+00  5.1850367e+00
  3.0295143e+00  8.6389799e+00  9.0257702e+00  3.6582994e+00
  5.9157324e+00  4.1758962e+00  9.3391609e+00  1.7730776e+00
  7.6125379e+00  1.0046360e+01  2.1057978e+00  1.7478250e+00
  7.1132212e+00  7.9645081e+00  5.2505498e+00  6.4574647e+00
  3.2315047e+00  4.3446302e+00  1.2056727e+00  2.9674428e+00
  2.7837610e+00  4.7524495e+00  9.8256521e+00  1.5932522e+00
  4.8396316e+00  5.9174523e+00  9.4890871e+00  1.2948707e+00
  9.0378551e+00  1.3124785e+00  5.4293876e+00  4.4993534e+00
  2.0538125e+00  3.5617321e+00  5.4850354e+00  8.2304430e+00
  9.7063475e+00  4.5277615e+00  8.3297014e+00  6.6988935e+00
  3.0370085e+00  2.5210819e+00  4.3796597e+00  5.5016708e+00
  1.9651670e+00  2.4778838e+00  5.8789811e+00  3.1068649e+00
  8.4105711e+00  2.6629505e+00 -3.3057988e-01  9.0704960e-01
  9.3188791e+00  1.0806879e+00 -8.1481934e-03  9.1659679e+00
  2.1467557e+00  7.2326632e+00  8.2058630e+00  5.8045855e+00
  8.4636183e+00  6.8212204e+00  5.0721443e-01  5.9133248e+00
  7.4281392e+00  7.8691220e+00 -6.8311334e-02  7.2124262e+00
  8.6880360e+00  6.6583366e+00  5.0127316e+00  4.6381230e+00
  5.9561200e+00  6.8466635e+00  9.5994196e+00  6.0355244e+00
  8.7480297e+00  7.6578970e+00  1.2954912e+00  4.2609344e+00
  2.7702582e+00  3.0329621e+00  3.6327574e+00  3.4195125e+00
  5.5413127e+00  5.8191652e+00  2.7070973e+00  1.6614884e+00
  3.8416210e-01  6.2802663e+00  2.0622129e+00 -6.8790317e-01
  9.2128534e+00  4.7458625e+00  9.4553316e-01  8.3560362e+00
  9.9401188e+00  3.5302291e+00  4.7089720e-01  1.3786711e+00
  5.3229847e+00  9.2913418e+00  1.6849303e+00  8.2535496e+00
 -2.5821114e-01  4.1421123e+00  6.4032269e+00  6.6551906e-01
  5.3515515e+00  9.1520185e+00  1.5094744e+00  7.4785428e+00
  6.0626564e+00  1.8558639e+00  4.4214793e-02  7.5862879e-01
  4.2469244e+00  8.8614159e+00  6.5688152e+00  7.3740344e+00
  4.8993049e+00  5.7953315e+00  9.2521513e-01  8.7253218e+00
  7.7945423e+00  9.9947720e+00  3.9001837e+00  2.8082497e+00
  2.2034130e+00  9.5151176e+00  7.4653130e+00  5.4289103e-01
  5.5686536e+00  4.1999950e+00  1.3804873e+00  1.5220041e+00
  9.6445208e+00  3.1844208e+00  8.2594252e+00  5.8706766e-01
  3.8130655e+00  9.4813788e-01  1.4116070e-01  5.6962514e+00
  2.8564551e+00  7.0057955e+00  6.3632298e+00  1.4823904e+00
  9.5153828e+00  7.8791199e+00  2.7109826e+00  5.3147154e+00
  7.3835139e+00  3.6906118e+00  4.5995116e+00  4.1400166e+00
  6.1948090e+00  8.8411551e+00  1.6546024e+00  8.7375402e+00
  5.7898629e-01  6.4826312e+00  4.3135948e+00  7.4583459e+00
  6.8681207e+00  5.0527821e+00  6.3631139e+00  3.5951567e+00]
Epoch 1/1000
2023-09-10 10:42:09.500 
Epoch 1/1000 
	 loss: 525.2611, MinusLogProbMetric: 525.2611, val_loss: 453.2751, val_MinusLogProbMetric: 453.2751

Epoch 1: val_loss improved from inf to 453.27505, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 98s - loss: 525.2611 - MinusLogProbMetric: 525.2611 - val_loss: 453.2751 - val_MinusLogProbMetric: 453.2751 - lr: 3.3333e-04 - 98s/epoch - 501ms/step
Epoch 2/1000
2023-09-10 10:42:25.810 
Epoch 2/1000 
	 loss: 449.5223, MinusLogProbMetric: 449.5223, val_loss: 455.8709, val_MinusLogProbMetric: 455.8709

Epoch 2: val_loss did not improve from 453.27505
196/196 - 15s - loss: 449.5223 - MinusLogProbMetric: 449.5223 - val_loss: 455.8709 - val_MinusLogProbMetric: 455.8709 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 3/1000
2023-09-10 10:42:39.362 
Epoch 3/1000 
	 loss: 446.3402, MinusLogProbMetric: 446.3402, val_loss: 443.0156, val_MinusLogProbMetric: 443.0156

Epoch 3: val_loss improved from 453.27505 to 443.01559, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 14s - loss: 446.3402 - MinusLogProbMetric: 446.3402 - val_loss: 443.0156 - val_MinusLogProbMetric: 443.0156 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 4/1000
2023-09-10 10:42:55.370 
Epoch 4/1000 
	 loss: 441.9224, MinusLogProbMetric: 441.9224, val_loss: 439.1690, val_MinusLogProbMetric: 439.1690

Epoch 4: val_loss improved from 443.01559 to 439.16904, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 441.9224 - MinusLogProbMetric: 441.9224 - val_loss: 439.1690 - val_MinusLogProbMetric: 439.1690 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 5/1000
2023-09-10 10:43:11.379 
Epoch 5/1000 
	 loss: 439.6662, MinusLogProbMetric: 439.6662, val_loss: 437.9366, val_MinusLogProbMetric: 437.9366

Epoch 5: val_loss improved from 439.16904 to 437.93665, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 439.6662 - MinusLogProbMetric: 439.6662 - val_loss: 437.9366 - val_MinusLogProbMetric: 437.9366 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 6/1000
2023-09-10 10:43:27.329 
Epoch 6/1000 
	 loss: 436.7569, MinusLogProbMetric: 436.7569, val_loss: 434.4668, val_MinusLogProbMetric: 434.4668

Epoch 6: val_loss improved from 437.93665 to 434.46680, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 436.7569 - MinusLogProbMetric: 436.7569 - val_loss: 434.4668 - val_MinusLogProbMetric: 434.4668 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 7/1000
2023-09-10 10:43:43.709 
Epoch 7/1000 
	 loss: 433.4504, MinusLogProbMetric: 433.4504, val_loss: 432.2355, val_MinusLogProbMetric: 432.2355

Epoch 7: val_loss improved from 434.46680 to 432.23550, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 433.4504 - MinusLogProbMetric: 433.4504 - val_loss: 432.2355 - val_MinusLogProbMetric: 432.2355 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 8/1000
2023-09-10 10:44:01.892 
Epoch 8/1000 
	 loss: 432.8033, MinusLogProbMetric: 432.8033, val_loss: 431.2786, val_MinusLogProbMetric: 431.2786

Epoch 8: val_loss improved from 432.23550 to 431.27859, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 18s - loss: 432.8033 - MinusLogProbMetric: 432.8033 - val_loss: 431.2786 - val_MinusLogProbMetric: 431.2786 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 9/1000
2023-09-10 10:44:18.616 
Epoch 9/1000 
	 loss: 431.1764, MinusLogProbMetric: 431.1764, val_loss: 437.7187, val_MinusLogProbMetric: 437.7187

Epoch 9: val_loss did not improve from 431.27859
196/196 - 16s - loss: 431.1764 - MinusLogProbMetric: 431.1764 - val_loss: 437.7187 - val_MinusLogProbMetric: 437.7187 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 10/1000
2023-09-10 10:44:36.324 
Epoch 10/1000 
	 loss: 429.0256, MinusLogProbMetric: 429.0256, val_loss: 439.9857, val_MinusLogProbMetric: 439.9857

Epoch 10: val_loss did not improve from 431.27859
196/196 - 18s - loss: 429.0256 - MinusLogProbMetric: 429.0256 - val_loss: 439.9857 - val_MinusLogProbMetric: 439.9857 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 11/1000
2023-09-10 10:44:54.638 
Epoch 11/1000 
	 loss: 428.8456, MinusLogProbMetric: 428.8456, val_loss: 424.5096, val_MinusLogProbMetric: 424.5096

Epoch 11: val_loss improved from 431.27859 to 424.50955, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 19s - loss: 428.8456 - MinusLogProbMetric: 428.8456 - val_loss: 424.5096 - val_MinusLogProbMetric: 424.5096 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 12/1000
2023-09-10 10:45:11.588 
Epoch 12/1000 
	 loss: 425.7872, MinusLogProbMetric: 425.7872, val_loss: 424.6506, val_MinusLogProbMetric: 424.6506

Epoch 12: val_loss did not improve from 424.50955
196/196 - 16s - loss: 425.7872 - MinusLogProbMetric: 425.7872 - val_loss: 424.6506 - val_MinusLogProbMetric: 424.6506 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 13/1000
2023-09-10 10:45:27.859 
Epoch 13/1000 
	 loss: 427.5864, MinusLogProbMetric: 427.5864, val_loss: 426.2587, val_MinusLogProbMetric: 426.2587

Epoch 13: val_loss did not improve from 424.50955
196/196 - 16s - loss: 427.5864 - MinusLogProbMetric: 427.5864 - val_loss: 426.2587 - val_MinusLogProbMetric: 426.2587 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 14/1000
2023-09-10 10:45:43.410 
Epoch 14/1000 
	 loss: 424.4213, MinusLogProbMetric: 424.4213, val_loss: 430.4204, val_MinusLogProbMetric: 430.4204

Epoch 14: val_loss did not improve from 424.50955
196/196 - 16s - loss: 424.4213 - MinusLogProbMetric: 424.4213 - val_loss: 430.4204 - val_MinusLogProbMetric: 430.4204 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 15/1000
2023-09-10 10:45:58.632 
Epoch 15/1000 
	 loss: 424.3741, MinusLogProbMetric: 424.3741, val_loss: 421.4315, val_MinusLogProbMetric: 421.4315

Epoch 15: val_loss improved from 424.50955 to 421.43146, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 424.3741 - MinusLogProbMetric: 424.3741 - val_loss: 421.4315 - val_MinusLogProbMetric: 421.4315 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 16/1000
2023-09-10 10:46:14.963 
Epoch 16/1000 
	 loss: 420.5500, MinusLogProbMetric: 420.5500, val_loss: 421.7037, val_MinusLogProbMetric: 421.7037

Epoch 16: val_loss did not improve from 421.43146
196/196 - 16s - loss: 420.5500 - MinusLogProbMetric: 420.5500 - val_loss: 421.7037 - val_MinusLogProbMetric: 421.7037 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 17/1000
2023-09-10 10:46:29.308 
Epoch 17/1000 
	 loss: 420.9890, MinusLogProbMetric: 420.9890, val_loss: 420.3903, val_MinusLogProbMetric: 420.3903

Epoch 17: val_loss improved from 421.43146 to 420.39032, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 420.9890 - MinusLogProbMetric: 420.9890 - val_loss: 420.3903 - val_MinusLogProbMetric: 420.3903 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 18/1000
2023-09-10 10:46:44.496 
Epoch 18/1000 
	 loss: 418.6736, MinusLogProbMetric: 418.6736, val_loss: 421.1554, val_MinusLogProbMetric: 421.1554

Epoch 18: val_loss did not improve from 420.39032
196/196 - 14s - loss: 418.6736 - MinusLogProbMetric: 418.6736 - val_loss: 421.1554 - val_MinusLogProbMetric: 421.1554 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 19/1000
2023-09-10 10:46:59.378 
Epoch 19/1000 
	 loss: 419.4128, MinusLogProbMetric: 419.4128, val_loss: 435.4946, val_MinusLogProbMetric: 435.4946

Epoch 19: val_loss did not improve from 420.39032
196/196 - 15s - loss: 419.4128 - MinusLogProbMetric: 419.4128 - val_loss: 435.4946 - val_MinusLogProbMetric: 435.4946 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 20/1000
2023-09-10 10:47:14.783 
Epoch 20/1000 
	 loss: 419.4234, MinusLogProbMetric: 419.4234, val_loss: 418.0692, val_MinusLogProbMetric: 418.0692

Epoch 20: val_loss improved from 420.39032 to 418.06921, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 419.4234 - MinusLogProbMetric: 419.4234 - val_loss: 418.0692 - val_MinusLogProbMetric: 418.0692 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 21/1000
2023-09-10 10:47:31.249 
Epoch 21/1000 
	 loss: 418.3948, MinusLogProbMetric: 418.3948, val_loss: 421.2950, val_MinusLogProbMetric: 421.2950

Epoch 21: val_loss did not improve from 418.06921
196/196 - 16s - loss: 418.3948 - MinusLogProbMetric: 418.3948 - val_loss: 421.2950 - val_MinusLogProbMetric: 421.2950 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 22/1000
2023-09-10 10:47:48.312 
Epoch 22/1000 
	 loss: 422.4800, MinusLogProbMetric: 422.4800, val_loss: 415.7807, val_MinusLogProbMetric: 415.7807

Epoch 22: val_loss improved from 418.06921 to 415.78067, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 18s - loss: 422.4800 - MinusLogProbMetric: 422.4800 - val_loss: 415.7807 - val_MinusLogProbMetric: 415.7807 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 23/1000
2023-09-10 10:48:06.048 
Epoch 23/1000 
	 loss: 417.6069, MinusLogProbMetric: 417.6069, val_loss: 416.4879, val_MinusLogProbMetric: 416.4879

Epoch 23: val_loss did not improve from 415.78067
196/196 - 17s - loss: 417.6069 - MinusLogProbMetric: 417.6069 - val_loss: 416.4879 - val_MinusLogProbMetric: 416.4879 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 24/1000
2023-09-10 10:48:22.521 
Epoch 24/1000 
	 loss: 415.2310, MinusLogProbMetric: 415.2310, val_loss: 416.4576, val_MinusLogProbMetric: 416.4576

Epoch 24: val_loss did not improve from 415.78067
196/196 - 16s - loss: 415.2310 - MinusLogProbMetric: 415.2310 - val_loss: 416.4576 - val_MinusLogProbMetric: 416.4576 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 25/1000
2023-09-10 10:48:39.006 
Epoch 25/1000 
	 loss: 415.3195, MinusLogProbMetric: 415.3195, val_loss: 416.8178, val_MinusLogProbMetric: 416.8178

Epoch 25: val_loss did not improve from 415.78067
196/196 - 16s - loss: 415.3195 - MinusLogProbMetric: 415.3195 - val_loss: 416.8178 - val_MinusLogProbMetric: 416.8178 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 26/1000
2023-09-10 10:48:58.420 
Epoch 26/1000 
	 loss: 415.8641, MinusLogProbMetric: 415.8641, val_loss: 415.9957, val_MinusLogProbMetric: 415.9957

Epoch 26: val_loss did not improve from 415.78067
196/196 - 19s - loss: 415.8641 - MinusLogProbMetric: 415.8641 - val_loss: 415.9957 - val_MinusLogProbMetric: 415.9957 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 27/1000
2023-09-10 10:49:14.021 
Epoch 27/1000 
	 loss: 415.4189, MinusLogProbMetric: 415.4189, val_loss: 415.9894, val_MinusLogProbMetric: 415.9894

Epoch 27: val_loss did not improve from 415.78067
196/196 - 16s - loss: 415.4189 - MinusLogProbMetric: 415.4189 - val_loss: 415.9894 - val_MinusLogProbMetric: 415.9894 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 28/1000
2023-09-10 10:49:29.948 
Epoch 28/1000 
	 loss: 415.0332, MinusLogProbMetric: 415.0332, val_loss: 416.3121, val_MinusLogProbMetric: 416.3121

Epoch 28: val_loss did not improve from 415.78067
196/196 - 16s - loss: 415.0332 - MinusLogProbMetric: 415.0332 - val_loss: 416.3121 - val_MinusLogProbMetric: 416.3121 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 29/1000
2023-09-10 10:49:45.609 
Epoch 29/1000 
	 loss: 415.1126, MinusLogProbMetric: 415.1126, val_loss: 434.7291, val_MinusLogProbMetric: 434.7291

Epoch 29: val_loss did not improve from 415.78067
196/196 - 16s - loss: 415.1126 - MinusLogProbMetric: 415.1126 - val_loss: 434.7291 - val_MinusLogProbMetric: 434.7291 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 30/1000
2023-09-10 10:50:00.882 
Epoch 30/1000 
	 loss: 413.8994, MinusLogProbMetric: 413.8994, val_loss: 414.5172, val_MinusLogProbMetric: 414.5172

Epoch 30: val_loss improved from 415.78067 to 414.51724, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 413.8994 - MinusLogProbMetric: 413.8994 - val_loss: 414.5172 - val_MinusLogProbMetric: 414.5172 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 31/1000
2023-09-10 10:50:16.023 
Epoch 31/1000 
	 loss: 413.0200, MinusLogProbMetric: 413.0200, val_loss: 413.8057, val_MinusLogProbMetric: 413.8057

Epoch 31: val_loss improved from 414.51724 to 413.80569, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 15s - loss: 413.0200 - MinusLogProbMetric: 413.0200 - val_loss: 413.8057 - val_MinusLogProbMetric: 413.8057 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 32/1000
2023-09-10 10:50:32.860 
Epoch 32/1000 
	 loss: 411.6360, MinusLogProbMetric: 411.6360, val_loss: 413.5443, val_MinusLogProbMetric: 413.5443

Epoch 32: val_loss improved from 413.80569 to 413.54428, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 411.6360 - MinusLogProbMetric: 411.6360 - val_loss: 413.5443 - val_MinusLogProbMetric: 413.5443 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 33/1000
2023-09-10 10:50:50.211 
Epoch 33/1000 
	 loss: 413.0595, MinusLogProbMetric: 413.0595, val_loss: 413.4861, val_MinusLogProbMetric: 413.4861

Epoch 33: val_loss improved from 413.54428 to 413.48615, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 413.0595 - MinusLogProbMetric: 413.0595 - val_loss: 413.4861 - val_MinusLogProbMetric: 413.4861 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 34/1000
2023-09-10 10:51:06.009 
Epoch 34/1000 
	 loss: 412.2312, MinusLogProbMetric: 412.2312, val_loss: 415.2086, val_MinusLogProbMetric: 415.2086

Epoch 34: val_loss did not improve from 413.48615
196/196 - 15s - loss: 412.2312 - MinusLogProbMetric: 412.2312 - val_loss: 415.2086 - val_MinusLogProbMetric: 415.2086 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 35/1000
2023-09-10 10:51:21.272 
Epoch 35/1000 
	 loss: 414.0807, MinusLogProbMetric: 414.0807, val_loss: 411.4864, val_MinusLogProbMetric: 411.4864

Epoch 35: val_loss improved from 413.48615 to 411.48639, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 414.0807 - MinusLogProbMetric: 414.0807 - val_loss: 411.4864 - val_MinusLogProbMetric: 411.4864 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 36/1000
2023-09-10 10:51:37.820 
Epoch 36/1000 
	 loss: 412.4301, MinusLogProbMetric: 412.4301, val_loss: 411.2523, val_MinusLogProbMetric: 411.2523

Epoch 36: val_loss improved from 411.48639 to 411.25232, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 412.4301 - MinusLogProbMetric: 412.4301 - val_loss: 411.2523 - val_MinusLogProbMetric: 411.2523 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 37/1000
2023-09-10 10:51:53.109 
Epoch 37/1000 
	 loss: 410.2952, MinusLogProbMetric: 410.2952, val_loss: 413.6633, val_MinusLogProbMetric: 413.6633

Epoch 37: val_loss did not improve from 411.25232
196/196 - 15s - loss: 410.2952 - MinusLogProbMetric: 410.2952 - val_loss: 413.6633 - val_MinusLogProbMetric: 413.6633 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 38/1000
2023-09-10 10:52:08.663 
Epoch 38/1000 
	 loss: 412.8207, MinusLogProbMetric: 412.8207, val_loss: 414.4518, val_MinusLogProbMetric: 414.4518

Epoch 38: val_loss did not improve from 411.25232
196/196 - 16s - loss: 412.8207 - MinusLogProbMetric: 412.8207 - val_loss: 414.4518 - val_MinusLogProbMetric: 414.4518 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 39/1000
2023-09-10 10:52:24.281 
Epoch 39/1000 
	 loss: 410.4457, MinusLogProbMetric: 410.4457, val_loss: 408.7691, val_MinusLogProbMetric: 408.7691

Epoch 39: val_loss improved from 411.25232 to 408.76913, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 410.4457 - MinusLogProbMetric: 410.4457 - val_loss: 408.7691 - val_MinusLogProbMetric: 408.7691 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 40/1000
2023-09-10 10:52:40.042 
Epoch 40/1000 
	 loss: 410.4280, MinusLogProbMetric: 410.4280, val_loss: 409.8653, val_MinusLogProbMetric: 409.8653

Epoch 40: val_loss did not improve from 408.76913
196/196 - 15s - loss: 410.4280 - MinusLogProbMetric: 410.4280 - val_loss: 409.8653 - val_MinusLogProbMetric: 409.8653 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 41/1000
2023-09-10 10:52:54.338 
Epoch 41/1000 
	 loss: 410.5886, MinusLogProbMetric: 410.5886, val_loss: 412.6962, val_MinusLogProbMetric: 412.6962

Epoch 41: val_loss did not improve from 408.76913
196/196 - 14s - loss: 410.5886 - MinusLogProbMetric: 410.5886 - val_loss: 412.6962 - val_MinusLogProbMetric: 412.6962 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 42/1000
2023-09-10 10:53:08.424 
Epoch 42/1000 
	 loss: 408.9424, MinusLogProbMetric: 408.9424, val_loss: 412.7027, val_MinusLogProbMetric: 412.7027

Epoch 42: val_loss did not improve from 408.76913
196/196 - 14s - loss: 408.9424 - MinusLogProbMetric: 408.9424 - val_loss: 412.7027 - val_MinusLogProbMetric: 412.7027 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 43/1000
2023-09-10 10:53:22.529 
Epoch 43/1000 
	 loss: 409.6611, MinusLogProbMetric: 409.6611, val_loss: 410.4801, val_MinusLogProbMetric: 410.4801

Epoch 43: val_loss did not improve from 408.76913
196/196 - 14s - loss: 409.6611 - MinusLogProbMetric: 409.6611 - val_loss: 410.4801 - val_MinusLogProbMetric: 410.4801 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 44/1000
2023-09-10 10:53:35.872 
Epoch 44/1000 
	 loss: 411.3907, MinusLogProbMetric: 411.3907, val_loss: 410.8256, val_MinusLogProbMetric: 410.8256

Epoch 44: val_loss did not improve from 408.76913
196/196 - 13s - loss: 411.3907 - MinusLogProbMetric: 411.3907 - val_loss: 410.8256 - val_MinusLogProbMetric: 410.8256 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 45/1000
2023-09-10 10:53:50.186 
Epoch 45/1000 
	 loss: 408.8942, MinusLogProbMetric: 408.8942, val_loss: 408.9352, val_MinusLogProbMetric: 408.9352

Epoch 45: val_loss did not improve from 408.76913
196/196 - 14s - loss: 408.8942 - MinusLogProbMetric: 408.8942 - val_loss: 408.9352 - val_MinusLogProbMetric: 408.9352 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 46/1000
2023-09-10 10:54:03.821 
Epoch 46/1000 
	 loss: 409.4090, MinusLogProbMetric: 409.4090, val_loss: 420.9030, val_MinusLogProbMetric: 420.9030

Epoch 46: val_loss did not improve from 408.76913
196/196 - 14s - loss: 409.4090 - MinusLogProbMetric: 409.4090 - val_loss: 420.9030 - val_MinusLogProbMetric: 420.9030 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 47/1000
2023-09-10 10:54:17.286 
Epoch 47/1000 
	 loss: 409.1519, MinusLogProbMetric: 409.1519, val_loss: 417.5771, val_MinusLogProbMetric: 417.5771

Epoch 47: val_loss did not improve from 408.76913
196/196 - 13s - loss: 409.1519 - MinusLogProbMetric: 409.1519 - val_loss: 417.5771 - val_MinusLogProbMetric: 417.5771 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 48/1000
2023-09-10 10:54:30.969 
Epoch 48/1000 
	 loss: 407.7123, MinusLogProbMetric: 407.7123, val_loss: 411.9988, val_MinusLogProbMetric: 411.9988

Epoch 48: val_loss did not improve from 408.76913
196/196 - 14s - loss: 407.7123 - MinusLogProbMetric: 407.7123 - val_loss: 411.9988 - val_MinusLogProbMetric: 411.9988 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 49/1000
2023-09-10 10:54:44.521 
Epoch 49/1000 
	 loss: 415.7434, MinusLogProbMetric: 415.7434, val_loss: 409.9641, val_MinusLogProbMetric: 409.9641

Epoch 49: val_loss did not improve from 408.76913
196/196 - 14s - loss: 415.7434 - MinusLogProbMetric: 415.7434 - val_loss: 409.9641 - val_MinusLogProbMetric: 409.9641 - lr: 3.3333e-04 - 14s/epoch - 69ms/step
Epoch 50/1000
2023-09-10 10:54:59.294 
Epoch 50/1000 
	 loss: 407.3951, MinusLogProbMetric: 407.3951, val_loss: 410.5009, val_MinusLogProbMetric: 410.5009

Epoch 50: val_loss did not improve from 408.76913
196/196 - 15s - loss: 407.3951 - MinusLogProbMetric: 407.3951 - val_loss: 410.5009 - val_MinusLogProbMetric: 410.5009 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 51/1000
2023-09-10 10:55:13.282 
Epoch 51/1000 
	 loss: 407.3524, MinusLogProbMetric: 407.3524, val_loss: 410.2487, val_MinusLogProbMetric: 410.2487

Epoch 51: val_loss did not improve from 408.76913
196/196 - 14s - loss: 407.3524 - MinusLogProbMetric: 407.3524 - val_loss: 410.2487 - val_MinusLogProbMetric: 410.2487 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 52/1000
2023-09-10 10:55:27.919 
Epoch 52/1000 
	 loss: 406.8790, MinusLogProbMetric: 406.8790, val_loss: 407.8833, val_MinusLogProbMetric: 407.8833

Epoch 52: val_loss improved from 408.76913 to 407.88333, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 15s - loss: 406.8790 - MinusLogProbMetric: 406.8790 - val_loss: 407.8833 - val_MinusLogProbMetric: 407.8833 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 53/1000
2023-09-10 10:55:42.385 
Epoch 53/1000 
	 loss: 408.4733, MinusLogProbMetric: 408.4733, val_loss: 409.4267, val_MinusLogProbMetric: 409.4267

Epoch 53: val_loss did not improve from 407.88333
196/196 - 14s - loss: 408.4733 - MinusLogProbMetric: 408.4733 - val_loss: 409.4267 - val_MinusLogProbMetric: 409.4267 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 54/1000
2023-09-10 10:55:55.194 
Epoch 54/1000 
	 loss: 406.5668, MinusLogProbMetric: 406.5668, val_loss: 412.8644, val_MinusLogProbMetric: 412.8644

Epoch 54: val_loss did not improve from 407.88333
196/196 - 13s - loss: 406.5668 - MinusLogProbMetric: 406.5668 - val_loss: 412.8644 - val_MinusLogProbMetric: 412.8644 - lr: 3.3333e-04 - 13s/epoch - 65ms/step
Epoch 55/1000
2023-09-10 10:56:08.891 
Epoch 55/1000 
	 loss: 406.7061, MinusLogProbMetric: 406.7061, val_loss: 408.7409, val_MinusLogProbMetric: 408.7409

Epoch 55: val_loss did not improve from 407.88333
196/196 - 14s - loss: 406.7061 - MinusLogProbMetric: 406.7061 - val_loss: 408.7409 - val_MinusLogProbMetric: 408.7409 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 56/1000
2023-09-10 10:56:22.332 
Epoch 56/1000 
	 loss: 406.0020, MinusLogProbMetric: 406.0020, val_loss: 410.3440, val_MinusLogProbMetric: 410.3440

Epoch 56: val_loss did not improve from 407.88333
196/196 - 13s - loss: 406.0020 - MinusLogProbMetric: 406.0020 - val_loss: 410.3440 - val_MinusLogProbMetric: 410.3440 - lr: 3.3333e-04 - 13s/epoch - 69ms/step
Epoch 57/1000
2023-09-10 10:56:36.584 
Epoch 57/1000 
	 loss: 406.7729, MinusLogProbMetric: 406.7729, val_loss: 414.2817, val_MinusLogProbMetric: 414.2817

Epoch 57: val_loss did not improve from 407.88333
196/196 - 14s - loss: 406.7729 - MinusLogProbMetric: 406.7729 - val_loss: 414.2817 - val_MinusLogProbMetric: 414.2817 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 58/1000
2023-09-10 10:56:51.400 
Epoch 58/1000 
	 loss: 405.8021, MinusLogProbMetric: 405.8021, val_loss: 419.9155, val_MinusLogProbMetric: 419.9155

Epoch 58: val_loss did not improve from 407.88333
196/196 - 15s - loss: 405.8021 - MinusLogProbMetric: 405.8021 - val_loss: 419.9155 - val_MinusLogProbMetric: 419.9155 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 59/1000
2023-09-10 10:57:08.120 
Epoch 59/1000 
	 loss: 405.1979, MinusLogProbMetric: 405.1979, val_loss: 414.2313, val_MinusLogProbMetric: 414.2313

Epoch 59: val_loss did not improve from 407.88333
196/196 - 17s - loss: 405.1979 - MinusLogProbMetric: 405.1979 - val_loss: 414.2313 - val_MinusLogProbMetric: 414.2313 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 60/1000
2023-09-10 10:57:25.796 
Epoch 60/1000 
	 loss: 405.4062, MinusLogProbMetric: 405.4062, val_loss: 417.2362, val_MinusLogProbMetric: 417.2362

Epoch 60: val_loss did not improve from 407.88333
196/196 - 18s - loss: 405.4062 - MinusLogProbMetric: 405.4062 - val_loss: 417.2362 - val_MinusLogProbMetric: 417.2362 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 61/1000
2023-09-10 10:57:42.680 
Epoch 61/1000 
	 loss: 405.5609, MinusLogProbMetric: 405.5609, val_loss: 410.5789, val_MinusLogProbMetric: 410.5789

Epoch 61: val_loss did not improve from 407.88333
196/196 - 17s - loss: 405.5609 - MinusLogProbMetric: 405.5609 - val_loss: 410.5789 - val_MinusLogProbMetric: 410.5789 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 62/1000
2023-09-10 10:57:59.357 
Epoch 62/1000 
	 loss: 405.9717, MinusLogProbMetric: 405.9717, val_loss: 411.0328, val_MinusLogProbMetric: 411.0328

Epoch 62: val_loss did not improve from 407.88333
196/196 - 17s - loss: 405.9717 - MinusLogProbMetric: 405.9717 - val_loss: 411.0328 - val_MinusLogProbMetric: 411.0328 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 63/1000
2023-09-10 10:58:14.780 
Epoch 63/1000 
	 loss: 405.4812, MinusLogProbMetric: 405.4812, val_loss: 408.5344, val_MinusLogProbMetric: 408.5344

Epoch 63: val_loss did not improve from 407.88333
196/196 - 15s - loss: 405.4812 - MinusLogProbMetric: 405.4812 - val_loss: 408.5344 - val_MinusLogProbMetric: 408.5344 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 64/1000
2023-09-10 10:58:30.235 
Epoch 64/1000 
	 loss: 404.4945, MinusLogProbMetric: 404.4945, val_loss: 406.3592, val_MinusLogProbMetric: 406.3592

Epoch 64: val_loss improved from 407.88333 to 406.35919, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 404.4945 - MinusLogProbMetric: 404.4945 - val_loss: 406.3592 - val_MinusLogProbMetric: 406.3592 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 65/1000
2023-09-10 10:58:46.540 
Epoch 65/1000 
	 loss: 406.7645, MinusLogProbMetric: 406.7645, val_loss: 427.9136, val_MinusLogProbMetric: 427.9136

Epoch 65: val_loss did not improve from 406.35919
196/196 - 16s - loss: 406.7645 - MinusLogProbMetric: 406.7645 - val_loss: 427.9136 - val_MinusLogProbMetric: 427.9136 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 66/1000
2023-09-10 10:59:02.801 
Epoch 66/1000 
	 loss: 405.8271, MinusLogProbMetric: 405.8271, val_loss: 405.8940, val_MinusLogProbMetric: 405.8940

Epoch 66: val_loss improved from 406.35919 to 405.89401, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 405.8271 - MinusLogProbMetric: 405.8271 - val_loss: 405.8940 - val_MinusLogProbMetric: 405.8940 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 67/1000
2023-09-10 10:59:18.953 
Epoch 67/1000 
	 loss: 404.4846, MinusLogProbMetric: 404.4846, val_loss: 406.7158, val_MinusLogProbMetric: 406.7158

Epoch 67: val_loss did not improve from 405.89401
196/196 - 16s - loss: 404.4846 - MinusLogProbMetric: 404.4846 - val_loss: 406.7158 - val_MinusLogProbMetric: 406.7158 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 68/1000
2023-09-10 10:59:36.391 
Epoch 68/1000 
	 loss: 404.0854, MinusLogProbMetric: 404.0854, val_loss: 406.7327, val_MinusLogProbMetric: 406.7327

Epoch 68: val_loss did not improve from 405.89401
196/196 - 17s - loss: 404.0854 - MinusLogProbMetric: 404.0854 - val_loss: 406.7327 - val_MinusLogProbMetric: 406.7327 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 69/1000
2023-09-10 10:59:53.704 
Epoch 69/1000 
	 loss: 405.3621, MinusLogProbMetric: 405.3621, val_loss: 407.3508, val_MinusLogProbMetric: 407.3508

Epoch 69: val_loss did not improve from 405.89401
196/196 - 17s - loss: 405.3621 - MinusLogProbMetric: 405.3621 - val_loss: 407.3508 - val_MinusLogProbMetric: 407.3508 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 70/1000
2023-09-10 11:00:10.622 
Epoch 70/1000 
	 loss: 403.5387, MinusLogProbMetric: 403.5387, val_loss: 407.3218, val_MinusLogProbMetric: 407.3218

Epoch 70: val_loss did not improve from 405.89401
196/196 - 17s - loss: 403.5387 - MinusLogProbMetric: 403.5387 - val_loss: 407.3218 - val_MinusLogProbMetric: 407.3218 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 71/1000
2023-09-10 11:00:27.140 
Epoch 71/1000 
	 loss: 404.1572, MinusLogProbMetric: 404.1572, val_loss: 411.6506, val_MinusLogProbMetric: 411.6506

Epoch 71: val_loss did not improve from 405.89401
196/196 - 17s - loss: 404.1572 - MinusLogProbMetric: 404.1572 - val_loss: 411.6506 - val_MinusLogProbMetric: 411.6506 - lr: 3.3333e-04 - 17s/epoch - 84ms/step
Epoch 72/1000
2023-09-10 11:00:43.358 
Epoch 72/1000 
	 loss: 403.5235, MinusLogProbMetric: 403.5235, val_loss: 407.0923, val_MinusLogProbMetric: 407.0923

Epoch 72: val_loss did not improve from 405.89401
196/196 - 16s - loss: 403.5235 - MinusLogProbMetric: 403.5235 - val_loss: 407.0923 - val_MinusLogProbMetric: 407.0923 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 73/1000
2023-09-10 11:00:59.630 
Epoch 73/1000 
	 loss: 404.2332, MinusLogProbMetric: 404.2332, val_loss: 404.7467, val_MinusLogProbMetric: 404.7467

Epoch 73: val_loss improved from 405.89401 to 404.74673, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 404.2332 - MinusLogProbMetric: 404.2332 - val_loss: 404.7467 - val_MinusLogProbMetric: 404.7467 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 74/1000
2023-09-10 11:01:16.737 
Epoch 74/1000 
	 loss: 404.1403, MinusLogProbMetric: 404.1403, val_loss: 406.4955, val_MinusLogProbMetric: 406.4955

Epoch 74: val_loss did not improve from 404.74673
196/196 - 16s - loss: 404.1403 - MinusLogProbMetric: 404.1403 - val_loss: 406.4955 - val_MinusLogProbMetric: 406.4955 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 75/1000
2023-09-10 11:01:33.953 
Epoch 75/1000 
	 loss: 403.6869, MinusLogProbMetric: 403.6869, val_loss: 404.2956, val_MinusLogProbMetric: 404.2956

Epoch 75: val_loss improved from 404.74673 to 404.29559, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 18s - loss: 403.6869 - MinusLogProbMetric: 403.6869 - val_loss: 404.2956 - val_MinusLogProbMetric: 404.2956 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 76/1000
2023-09-10 11:01:49.323 
Epoch 76/1000 
	 loss: 405.3176, MinusLogProbMetric: 405.3176, val_loss: 406.4856, val_MinusLogProbMetric: 406.4856

Epoch 76: val_loss did not improve from 404.29559
196/196 - 15s - loss: 405.3176 - MinusLogProbMetric: 405.3176 - val_loss: 406.4856 - val_MinusLogProbMetric: 406.4856 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 77/1000
2023-09-10 11:02:08.729 
Epoch 77/1000 
	 loss: 402.8838, MinusLogProbMetric: 402.8838, val_loss: 406.4294, val_MinusLogProbMetric: 406.4294

Epoch 77: val_loss did not improve from 404.29559
196/196 - 19s - loss: 402.8838 - MinusLogProbMetric: 402.8838 - val_loss: 406.4294 - val_MinusLogProbMetric: 406.4294 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 78/1000
2023-09-10 11:02:24.083 
Epoch 78/1000 
	 loss: 402.8778, MinusLogProbMetric: 402.8778, val_loss: 406.2210, val_MinusLogProbMetric: 406.2210

Epoch 78: val_loss did not improve from 404.29559
196/196 - 15s - loss: 402.8778 - MinusLogProbMetric: 402.8778 - val_loss: 406.2210 - val_MinusLogProbMetric: 406.2210 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 79/1000
2023-09-10 11:02:39.444 
Epoch 79/1000 
	 loss: 404.3466, MinusLogProbMetric: 404.3466, val_loss: 405.5248, val_MinusLogProbMetric: 405.5248

Epoch 79: val_loss did not improve from 404.29559
196/196 - 15s - loss: 404.3466 - MinusLogProbMetric: 404.3466 - val_loss: 405.5248 - val_MinusLogProbMetric: 405.5248 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 80/1000
2023-09-10 11:02:55.629 
Epoch 80/1000 
	 loss: 402.7130, MinusLogProbMetric: 402.7130, val_loss: 405.7996, val_MinusLogProbMetric: 405.7996

Epoch 80: val_loss did not improve from 404.29559
196/196 - 16s - loss: 402.7130 - MinusLogProbMetric: 402.7130 - val_loss: 405.7996 - val_MinusLogProbMetric: 405.7996 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 81/1000
2023-09-10 11:03:12.748 
Epoch 81/1000 
	 loss: 403.1169, MinusLogProbMetric: 403.1169, val_loss: 410.2723, val_MinusLogProbMetric: 410.2723

Epoch 81: val_loss did not improve from 404.29559
196/196 - 17s - loss: 403.1169 - MinusLogProbMetric: 403.1169 - val_loss: 410.2723 - val_MinusLogProbMetric: 410.2723 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 82/1000
2023-09-10 11:03:29.679 
Epoch 82/1000 
	 loss: 402.3244, MinusLogProbMetric: 402.3244, val_loss: 406.2959, val_MinusLogProbMetric: 406.2959

Epoch 82: val_loss did not improve from 404.29559
196/196 - 17s - loss: 402.3244 - MinusLogProbMetric: 402.3244 - val_loss: 406.2959 - val_MinusLogProbMetric: 406.2959 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 83/1000
2023-09-10 11:03:47.020 
Epoch 83/1000 
	 loss: 402.3894, MinusLogProbMetric: 402.3894, val_loss: 405.0921, val_MinusLogProbMetric: 405.0921

Epoch 83: val_loss did not improve from 404.29559
196/196 - 17s - loss: 402.3894 - MinusLogProbMetric: 402.3894 - val_loss: 405.0921 - val_MinusLogProbMetric: 405.0921 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 84/1000
2023-09-10 11:04:03.470 
Epoch 84/1000 
	 loss: 403.3191, MinusLogProbMetric: 403.3191, val_loss: 407.7802, val_MinusLogProbMetric: 407.7802

Epoch 84: val_loss did not improve from 404.29559
196/196 - 16s - loss: 403.3191 - MinusLogProbMetric: 403.3191 - val_loss: 407.7802 - val_MinusLogProbMetric: 407.7802 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 85/1000
2023-09-10 11:04:20.893 
Epoch 85/1000 
	 loss: 402.3442, MinusLogProbMetric: 402.3442, val_loss: 406.9421, val_MinusLogProbMetric: 406.9421

Epoch 85: val_loss did not improve from 404.29559
196/196 - 17s - loss: 402.3442 - MinusLogProbMetric: 402.3442 - val_loss: 406.9421 - val_MinusLogProbMetric: 406.9421 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 86/1000
2023-09-10 11:04:37.558 
Epoch 86/1000 
	 loss: 402.7859, MinusLogProbMetric: 402.7859, val_loss: 407.3849, val_MinusLogProbMetric: 407.3849

Epoch 86: val_loss did not improve from 404.29559
196/196 - 17s - loss: 402.7859 - MinusLogProbMetric: 402.7859 - val_loss: 407.3849 - val_MinusLogProbMetric: 407.3849 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 87/1000
2023-09-10 11:04:53.314 
Epoch 87/1000 
	 loss: 401.8560, MinusLogProbMetric: 401.8560, val_loss: 412.4859, val_MinusLogProbMetric: 412.4859

Epoch 87: val_loss did not improve from 404.29559
196/196 - 16s - loss: 401.8560 - MinusLogProbMetric: 401.8560 - val_loss: 412.4859 - val_MinusLogProbMetric: 412.4859 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 88/1000
2023-09-10 11:05:08.204 
Epoch 88/1000 
	 loss: 402.3705, MinusLogProbMetric: 402.3705, val_loss: 403.4152, val_MinusLogProbMetric: 403.4152

Epoch 88: val_loss improved from 404.29559 to 403.41516, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 402.3705 - MinusLogProbMetric: 402.3705 - val_loss: 403.4152 - val_MinusLogProbMetric: 403.4152 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 89/1000
2023-09-10 11:05:25.725 
Epoch 89/1000 
	 loss: 405.1956, MinusLogProbMetric: 405.1956, val_loss: 406.2354, val_MinusLogProbMetric: 406.2354

Epoch 89: val_loss did not improve from 403.41516
196/196 - 17s - loss: 405.1956 - MinusLogProbMetric: 405.1956 - val_loss: 406.2354 - val_MinusLogProbMetric: 406.2354 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 90/1000
2023-09-10 11:05:41.343 
Epoch 90/1000 
	 loss: 401.7310, MinusLogProbMetric: 401.7310, val_loss: 404.8846, val_MinusLogProbMetric: 404.8846

Epoch 90: val_loss did not improve from 403.41516
196/196 - 16s - loss: 401.7310 - MinusLogProbMetric: 401.7310 - val_loss: 404.8846 - val_MinusLogProbMetric: 404.8846 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 91/1000
2023-09-10 11:05:58.986 
Epoch 91/1000 
	 loss: 404.0178, MinusLogProbMetric: 404.0178, val_loss: 406.4047, val_MinusLogProbMetric: 406.4047

Epoch 91: val_loss did not improve from 403.41516
196/196 - 18s - loss: 404.0178 - MinusLogProbMetric: 404.0178 - val_loss: 406.4047 - val_MinusLogProbMetric: 406.4047 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 92/1000
2023-09-10 11:06:15.300 
Epoch 92/1000 
	 loss: 401.2939, MinusLogProbMetric: 401.2939, val_loss: 407.3156, val_MinusLogProbMetric: 407.3156

Epoch 92: val_loss did not improve from 403.41516
196/196 - 16s - loss: 401.2939 - MinusLogProbMetric: 401.2939 - val_loss: 407.3156 - val_MinusLogProbMetric: 407.3156 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 93/1000
2023-09-10 11:06:31.604 
Epoch 93/1000 
	 loss: 401.3430, MinusLogProbMetric: 401.3430, val_loss: 404.4913, val_MinusLogProbMetric: 404.4913

Epoch 93: val_loss did not improve from 403.41516
196/196 - 16s - loss: 401.3430 - MinusLogProbMetric: 401.3430 - val_loss: 404.4913 - val_MinusLogProbMetric: 404.4913 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 94/1000
2023-09-10 11:06:47.181 
Epoch 94/1000 
	 loss: 401.8970, MinusLogProbMetric: 401.8970, val_loss: 407.7059, val_MinusLogProbMetric: 407.7059

Epoch 94: val_loss did not improve from 403.41516
196/196 - 16s - loss: 401.8970 - MinusLogProbMetric: 401.8970 - val_loss: 407.7059 - val_MinusLogProbMetric: 407.7059 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 95/1000
2023-09-10 11:07:02.874 
Epoch 95/1000 
	 loss: 401.3768, MinusLogProbMetric: 401.3768, val_loss: 405.6653, val_MinusLogProbMetric: 405.6653

Epoch 95: val_loss did not improve from 403.41516
196/196 - 16s - loss: 401.3768 - MinusLogProbMetric: 401.3768 - val_loss: 405.6653 - val_MinusLogProbMetric: 405.6653 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 96/1000
2023-09-10 11:07:18.545 
Epoch 96/1000 
	 loss: 401.1651, MinusLogProbMetric: 401.1651, val_loss: 404.4481, val_MinusLogProbMetric: 404.4481

Epoch 96: val_loss did not improve from 403.41516
196/196 - 16s - loss: 401.1651 - MinusLogProbMetric: 401.1651 - val_loss: 404.4481 - val_MinusLogProbMetric: 404.4481 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 97/1000
2023-09-10 11:07:36.000 
Epoch 97/1000 
	 loss: 401.1006, MinusLogProbMetric: 401.1006, val_loss: 408.9671, val_MinusLogProbMetric: 408.9671

Epoch 97: val_loss did not improve from 403.41516
196/196 - 17s - loss: 401.1006 - MinusLogProbMetric: 401.1006 - val_loss: 408.9671 - val_MinusLogProbMetric: 408.9671 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 98/1000
2023-09-10 11:07:52.785 
Epoch 98/1000 
	 loss: 403.2592, MinusLogProbMetric: 403.2592, val_loss: 405.4569, val_MinusLogProbMetric: 405.4569

Epoch 98: val_loss did not improve from 403.41516
196/196 - 17s - loss: 403.2592 - MinusLogProbMetric: 403.2592 - val_loss: 405.4569 - val_MinusLogProbMetric: 405.4569 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 99/1000
2023-09-10 11:08:09.707 
Epoch 99/1000 
	 loss: 400.5048, MinusLogProbMetric: 400.5048, val_loss: 411.6405, val_MinusLogProbMetric: 411.6405

Epoch 99: val_loss did not improve from 403.41516
196/196 - 17s - loss: 400.5048 - MinusLogProbMetric: 400.5048 - val_loss: 411.6405 - val_MinusLogProbMetric: 411.6405 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 100/1000
2023-09-10 11:08:26.607 
Epoch 100/1000 
	 loss: 400.8467, MinusLogProbMetric: 400.8467, val_loss: 405.3605, val_MinusLogProbMetric: 405.3605

Epoch 100: val_loss did not improve from 403.41516
196/196 - 17s - loss: 400.8467 - MinusLogProbMetric: 400.8467 - val_loss: 405.3605 - val_MinusLogProbMetric: 405.3605 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 101/1000
2023-09-10 11:08:42.540 
Epoch 101/1000 
	 loss: 400.5455, MinusLogProbMetric: 400.5455, val_loss: 406.7652, val_MinusLogProbMetric: 406.7652

Epoch 101: val_loss did not improve from 403.41516
196/196 - 16s - loss: 400.5455 - MinusLogProbMetric: 400.5455 - val_loss: 406.7652 - val_MinusLogProbMetric: 406.7652 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 102/1000
2023-09-10 11:08:57.797 
Epoch 102/1000 
	 loss: 400.8785, MinusLogProbMetric: 400.8785, val_loss: 404.9202, val_MinusLogProbMetric: 404.9202

Epoch 102: val_loss did not improve from 403.41516
196/196 - 15s - loss: 400.8785 - MinusLogProbMetric: 400.8785 - val_loss: 404.9202 - val_MinusLogProbMetric: 404.9202 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 103/1000
2023-09-10 11:09:12.993 
Epoch 103/1000 
	 loss: 400.5569, MinusLogProbMetric: 400.5569, val_loss: 405.8837, val_MinusLogProbMetric: 405.8837

Epoch 103: val_loss did not improve from 403.41516
196/196 - 15s - loss: 400.5569 - MinusLogProbMetric: 400.5569 - val_loss: 405.8837 - val_MinusLogProbMetric: 405.8837 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 104/1000
2023-09-10 11:09:26.744 
Epoch 104/1000 
	 loss: 400.6059, MinusLogProbMetric: 400.6059, val_loss: 403.8922, val_MinusLogProbMetric: 403.8922

Epoch 104: val_loss did not improve from 403.41516
196/196 - 14s - loss: 400.6059 - MinusLogProbMetric: 400.6059 - val_loss: 403.8922 - val_MinusLogProbMetric: 403.8922 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 105/1000
2023-09-10 11:09:41.086 
Epoch 105/1000 
	 loss: 401.1752, MinusLogProbMetric: 401.1752, val_loss: 405.1297, val_MinusLogProbMetric: 405.1297

Epoch 105: val_loss did not improve from 403.41516
196/196 - 14s - loss: 401.1752 - MinusLogProbMetric: 401.1752 - val_loss: 405.1297 - val_MinusLogProbMetric: 405.1297 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 106/1000
2023-09-10 11:09:56.023 
Epoch 106/1000 
	 loss: 400.3723, MinusLogProbMetric: 400.3723, val_loss: 405.2339, val_MinusLogProbMetric: 405.2339

Epoch 106: val_loss did not improve from 403.41516
196/196 - 15s - loss: 400.3723 - MinusLogProbMetric: 400.3723 - val_loss: 405.2339 - val_MinusLogProbMetric: 405.2339 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 107/1000
2023-09-10 11:10:11.830 
Epoch 107/1000 
	 loss: 400.4106, MinusLogProbMetric: 400.4106, val_loss: 406.1296, val_MinusLogProbMetric: 406.1296

Epoch 107: val_loss did not improve from 403.41516
196/196 - 16s - loss: 400.4106 - MinusLogProbMetric: 400.4106 - val_loss: 406.1296 - val_MinusLogProbMetric: 406.1296 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 108/1000
2023-09-10 11:10:27.118 
Epoch 108/1000 
	 loss: 399.9374, MinusLogProbMetric: 399.9374, val_loss: 408.3565, val_MinusLogProbMetric: 408.3565

Epoch 108: val_loss did not improve from 403.41516
196/196 - 15s - loss: 399.9374 - MinusLogProbMetric: 399.9374 - val_loss: 408.3565 - val_MinusLogProbMetric: 408.3565 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 109/1000
2023-09-10 11:10:41.524 
Epoch 109/1000 
	 loss: 401.3847, MinusLogProbMetric: 401.3847, val_loss: 404.8942, val_MinusLogProbMetric: 404.8942

Epoch 109: val_loss did not improve from 403.41516
196/196 - 14s - loss: 401.3847 - MinusLogProbMetric: 401.3847 - val_loss: 404.8942 - val_MinusLogProbMetric: 404.8942 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 110/1000
2023-09-10 11:10:56.640 
Epoch 110/1000 
	 loss: 399.8611, MinusLogProbMetric: 399.8611, val_loss: 405.5870, val_MinusLogProbMetric: 405.5870

Epoch 110: val_loss did not improve from 403.41516
196/196 - 15s - loss: 399.8611 - MinusLogProbMetric: 399.8611 - val_loss: 405.5870 - val_MinusLogProbMetric: 405.5870 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 111/1000
2023-09-10 11:11:10.675 
Epoch 111/1000 
	 loss: 400.3033, MinusLogProbMetric: 400.3033, val_loss: 402.9787, val_MinusLogProbMetric: 402.9787

Epoch 111: val_loss improved from 403.41516 to 402.97873, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 15s - loss: 400.3033 - MinusLogProbMetric: 400.3033 - val_loss: 402.9787 - val_MinusLogProbMetric: 402.9787 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 112/1000
2023-09-10 11:11:26.255 
Epoch 112/1000 
	 loss: 400.2186, MinusLogProbMetric: 400.2186, val_loss: 404.2916, val_MinusLogProbMetric: 404.2916

Epoch 112: val_loss did not improve from 402.97873
196/196 - 15s - loss: 400.2186 - MinusLogProbMetric: 400.2186 - val_loss: 404.2916 - val_MinusLogProbMetric: 404.2916 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 113/1000
2023-09-10 11:11:39.906 
Epoch 113/1000 
	 loss: 399.7433, MinusLogProbMetric: 399.7433, val_loss: 403.9300, val_MinusLogProbMetric: 403.9300

Epoch 113: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.7433 - MinusLogProbMetric: 399.7433 - val_loss: 403.9300 - val_MinusLogProbMetric: 403.9300 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 114/1000
2023-09-10 11:11:54.419 
Epoch 114/1000 
	 loss: 400.3163, MinusLogProbMetric: 400.3163, val_loss: 405.1739, val_MinusLogProbMetric: 405.1739

Epoch 114: val_loss did not improve from 402.97873
196/196 - 14s - loss: 400.3163 - MinusLogProbMetric: 400.3163 - val_loss: 405.1739 - val_MinusLogProbMetric: 405.1739 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 115/1000
2023-09-10 11:12:09.018 
Epoch 115/1000 
	 loss: 399.4775, MinusLogProbMetric: 399.4775, val_loss: 403.9666, val_MinusLogProbMetric: 403.9666

Epoch 115: val_loss did not improve from 402.97873
196/196 - 15s - loss: 399.4775 - MinusLogProbMetric: 399.4775 - val_loss: 403.9666 - val_MinusLogProbMetric: 403.9666 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 116/1000
2023-09-10 11:12:24.604 
Epoch 116/1000 
	 loss: 402.9240, MinusLogProbMetric: 402.9240, val_loss: 403.7660, val_MinusLogProbMetric: 403.7660

Epoch 116: val_loss did not improve from 402.97873
196/196 - 16s - loss: 402.9240 - MinusLogProbMetric: 402.9240 - val_loss: 403.7660 - val_MinusLogProbMetric: 403.7660 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 117/1000
2023-09-10 11:12:40.526 
Epoch 117/1000 
	 loss: 398.9962, MinusLogProbMetric: 398.9962, val_loss: 405.5807, val_MinusLogProbMetric: 405.5807

Epoch 117: val_loss did not improve from 402.97873
196/196 - 16s - loss: 398.9962 - MinusLogProbMetric: 398.9962 - val_loss: 405.5807 - val_MinusLogProbMetric: 405.5807 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 118/1000
2023-09-10 11:12:53.652 
Epoch 118/1000 
	 loss: 399.7652, MinusLogProbMetric: 399.7652, val_loss: 403.6225, val_MinusLogProbMetric: 403.6225

Epoch 118: val_loss did not improve from 402.97873
196/196 - 13s - loss: 399.7652 - MinusLogProbMetric: 399.7652 - val_loss: 403.6225 - val_MinusLogProbMetric: 403.6225 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 119/1000
2023-09-10 11:13:07.892 
Epoch 119/1000 
	 loss: 399.7836, MinusLogProbMetric: 399.7836, val_loss: 404.7277, val_MinusLogProbMetric: 404.7277

Epoch 119: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.7836 - MinusLogProbMetric: 399.7836 - val_loss: 404.7277 - val_MinusLogProbMetric: 404.7277 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 120/1000
2023-09-10 11:13:21.860 
Epoch 120/1000 
	 loss: 399.3568, MinusLogProbMetric: 399.3568, val_loss: 404.0042, val_MinusLogProbMetric: 404.0042

Epoch 120: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.3568 - MinusLogProbMetric: 399.3568 - val_loss: 404.0042 - val_MinusLogProbMetric: 404.0042 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 121/1000
2023-09-10 11:13:35.963 
Epoch 121/1000 
	 loss: 399.6425, MinusLogProbMetric: 399.6425, val_loss: 404.4277, val_MinusLogProbMetric: 404.4277

Epoch 121: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.6425 - MinusLogProbMetric: 399.6425 - val_loss: 404.4277 - val_MinusLogProbMetric: 404.4277 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 122/1000
2023-09-10 11:13:49.292 
Epoch 122/1000 
	 loss: 399.5382, MinusLogProbMetric: 399.5382, val_loss: 410.9415, val_MinusLogProbMetric: 410.9415

Epoch 122: val_loss did not improve from 402.97873
196/196 - 13s - loss: 399.5382 - MinusLogProbMetric: 399.5382 - val_loss: 410.9415 - val_MinusLogProbMetric: 410.9415 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 123/1000
2023-09-10 11:14:04.473 
Epoch 123/1000 
	 loss: 400.1814, MinusLogProbMetric: 400.1814, val_loss: 403.7303, val_MinusLogProbMetric: 403.7303

Epoch 123: val_loss did not improve from 402.97873
196/196 - 15s - loss: 400.1814 - MinusLogProbMetric: 400.1814 - val_loss: 403.7303 - val_MinusLogProbMetric: 403.7303 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 124/1000
2023-09-10 11:14:18.716 
Epoch 124/1000 
	 loss: 398.6284, MinusLogProbMetric: 398.6284, val_loss: 403.6928, val_MinusLogProbMetric: 403.6928

Epoch 124: val_loss did not improve from 402.97873
196/196 - 14s - loss: 398.6284 - MinusLogProbMetric: 398.6284 - val_loss: 403.6928 - val_MinusLogProbMetric: 403.6928 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 125/1000
2023-09-10 11:14:32.992 
Epoch 125/1000 
	 loss: 399.3836, MinusLogProbMetric: 399.3836, val_loss: 404.6214, val_MinusLogProbMetric: 404.6214

Epoch 125: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.3836 - MinusLogProbMetric: 399.3836 - val_loss: 404.6214 - val_MinusLogProbMetric: 404.6214 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 126/1000
2023-09-10 11:14:46.393 
Epoch 126/1000 
	 loss: 398.7569, MinusLogProbMetric: 398.7569, val_loss: 404.7740, val_MinusLogProbMetric: 404.7740

Epoch 126: val_loss did not improve from 402.97873
196/196 - 13s - loss: 398.7569 - MinusLogProbMetric: 398.7569 - val_loss: 404.7740 - val_MinusLogProbMetric: 404.7740 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 127/1000
2023-09-10 11:15:00.611 
Epoch 127/1000 
	 loss: 398.6896, MinusLogProbMetric: 398.6896, val_loss: 404.9693, val_MinusLogProbMetric: 404.9693

Epoch 127: val_loss did not improve from 402.97873
196/196 - 14s - loss: 398.6896 - MinusLogProbMetric: 398.6896 - val_loss: 404.9693 - val_MinusLogProbMetric: 404.9693 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 128/1000
2023-09-10 11:15:14.938 
Epoch 128/1000 
	 loss: 399.8823, MinusLogProbMetric: 399.8823, val_loss: 403.9535, val_MinusLogProbMetric: 403.9535

Epoch 128: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.8823 - MinusLogProbMetric: 399.8823 - val_loss: 403.9535 - val_MinusLogProbMetric: 403.9535 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 129/1000
2023-09-10 11:15:28.701 
Epoch 129/1000 
	 loss: 399.0184, MinusLogProbMetric: 399.0184, val_loss: 404.5896, val_MinusLogProbMetric: 404.5896

Epoch 129: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.0184 - MinusLogProbMetric: 399.0184 - val_loss: 404.5896 - val_MinusLogProbMetric: 404.5896 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 130/1000
2023-09-10 11:15:41.608 
Epoch 130/1000 
	 loss: 398.7473, MinusLogProbMetric: 398.7473, val_loss: 404.2593, val_MinusLogProbMetric: 404.2593

Epoch 130: val_loss did not improve from 402.97873
196/196 - 13s - loss: 398.7473 - MinusLogProbMetric: 398.7473 - val_loss: 404.2593 - val_MinusLogProbMetric: 404.2593 - lr: 3.3333e-04 - 13s/epoch - 66ms/step
Epoch 131/1000
2023-09-10 11:15:55.745 
Epoch 131/1000 
	 loss: 399.7968, MinusLogProbMetric: 399.7968, val_loss: 404.2157, val_MinusLogProbMetric: 404.2157

Epoch 131: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.7968 - MinusLogProbMetric: 399.7968 - val_loss: 404.2157 - val_MinusLogProbMetric: 404.2157 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 132/1000
2023-09-10 11:16:10.597 
Epoch 132/1000 
	 loss: 398.2496, MinusLogProbMetric: 398.2496, val_loss: 404.0373, val_MinusLogProbMetric: 404.0373

Epoch 132: val_loss did not improve from 402.97873
196/196 - 15s - loss: 398.2496 - MinusLogProbMetric: 398.2496 - val_loss: 404.0373 - val_MinusLogProbMetric: 404.0373 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 133/1000
2023-09-10 11:16:24.766 
Epoch 133/1000 
	 loss: 399.7282, MinusLogProbMetric: 399.7282, val_loss: 418.0236, val_MinusLogProbMetric: 418.0236

Epoch 133: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.7282 - MinusLogProbMetric: 399.7282 - val_loss: 418.0236 - val_MinusLogProbMetric: 418.0236 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 134/1000
2023-09-10 11:16:38.881 
Epoch 134/1000 
	 loss: 399.9166, MinusLogProbMetric: 399.9166, val_loss: 403.5800, val_MinusLogProbMetric: 403.5800

Epoch 134: val_loss did not improve from 402.97873
196/196 - 14s - loss: 399.9166 - MinusLogProbMetric: 399.9166 - val_loss: 403.5800 - val_MinusLogProbMetric: 403.5800 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 135/1000
2023-09-10 11:16:54.465 
Epoch 135/1000 
	 loss: 398.2185, MinusLogProbMetric: 398.2185, val_loss: 406.8624, val_MinusLogProbMetric: 406.8624

Epoch 135: val_loss did not improve from 402.97873
196/196 - 16s - loss: 398.2185 - MinusLogProbMetric: 398.2185 - val_loss: 406.8624 - val_MinusLogProbMetric: 406.8624 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 136/1000
2023-09-10 11:17:07.691 
Epoch 136/1000 
	 loss: 398.1284, MinusLogProbMetric: 398.1284, val_loss: 404.5924, val_MinusLogProbMetric: 404.5924

Epoch 136: val_loss did not improve from 402.97873
196/196 - 13s - loss: 398.1284 - MinusLogProbMetric: 398.1284 - val_loss: 404.5924 - val_MinusLogProbMetric: 404.5924 - lr: 3.3333e-04 - 13s/epoch - 67ms/step
Epoch 137/1000
2023-09-10 11:17:21.631 
Epoch 137/1000 
	 loss: 398.8206, MinusLogProbMetric: 398.8206, val_loss: 404.5927, val_MinusLogProbMetric: 404.5927

Epoch 137: val_loss did not improve from 402.97873
196/196 - 14s - loss: 398.8206 - MinusLogProbMetric: 398.8206 - val_loss: 404.5927 - val_MinusLogProbMetric: 404.5927 - lr: 3.3333e-04 - 14s/epoch - 71ms/step
Epoch 138/1000
2023-09-10 11:17:36.453 
Epoch 138/1000 
	 loss: 398.4255, MinusLogProbMetric: 398.4255, val_loss: 405.2155, val_MinusLogProbMetric: 405.2155

Epoch 138: val_loss did not improve from 402.97873
196/196 - 15s - loss: 398.4255 - MinusLogProbMetric: 398.4255 - val_loss: 405.2155 - val_MinusLogProbMetric: 405.2155 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 139/1000
2023-09-10 11:17:50.704 
Epoch 139/1000 
	 loss: 398.4494, MinusLogProbMetric: 398.4494, val_loss: 403.7942, val_MinusLogProbMetric: 403.7942

Epoch 139: val_loss did not improve from 402.97873
196/196 - 14s - loss: 398.4494 - MinusLogProbMetric: 398.4494 - val_loss: 403.7942 - val_MinusLogProbMetric: 403.7942 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 140/1000
2023-09-10 11:18:04.020 
Epoch 140/1000 
	 loss: 398.8702, MinusLogProbMetric: 398.8702, val_loss: 410.8217, val_MinusLogProbMetric: 410.8217

Epoch 140: val_loss did not improve from 402.97873
196/196 - 13s - loss: 398.8702 - MinusLogProbMetric: 398.8702 - val_loss: 410.8217 - val_MinusLogProbMetric: 410.8217 - lr: 3.3333e-04 - 13s/epoch - 68ms/step
Epoch 141/1000
2023-09-10 11:18:17.708 
Epoch 141/1000 
	 loss: 398.1091, MinusLogProbMetric: 398.1091, val_loss: 404.4551, val_MinusLogProbMetric: 404.4551

Epoch 141: val_loss did not improve from 402.97873
196/196 - 14s - loss: 398.1091 - MinusLogProbMetric: 398.1091 - val_loss: 404.4551 - val_MinusLogProbMetric: 404.4551 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 142/1000
2023-09-10 11:18:33.578 
Epoch 142/1000 
	 loss: 397.8084, MinusLogProbMetric: 397.8084, val_loss: 402.8857, val_MinusLogProbMetric: 402.8857

Epoch 142: val_loss improved from 402.97873 to 402.88574, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 397.8084 - MinusLogProbMetric: 397.8084 - val_loss: 402.8857 - val_MinusLogProbMetric: 402.8857 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 143/1000
2023-09-10 11:18:50.502 
Epoch 143/1000 
	 loss: 397.6260, MinusLogProbMetric: 397.6260, val_loss: 408.8217, val_MinusLogProbMetric: 408.8217

Epoch 143: val_loss did not improve from 402.88574
196/196 - 16s - loss: 397.6260 - MinusLogProbMetric: 397.6260 - val_loss: 408.8217 - val_MinusLogProbMetric: 408.8217 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 144/1000
2023-09-10 11:19:08.039 
Epoch 144/1000 
	 loss: 397.8978, MinusLogProbMetric: 397.8978, val_loss: 404.0679, val_MinusLogProbMetric: 404.0679

Epoch 144: val_loss did not improve from 402.88574
196/196 - 18s - loss: 397.8978 - MinusLogProbMetric: 397.8978 - val_loss: 404.0679 - val_MinusLogProbMetric: 404.0679 - lr: 3.3333e-04 - 18s/epoch - 89ms/step
Epoch 145/1000
2023-09-10 11:19:22.925 
Epoch 145/1000 
	 loss: 397.9948, MinusLogProbMetric: 397.9948, val_loss: 405.0294, val_MinusLogProbMetric: 405.0294

Epoch 145: val_loss did not improve from 402.88574
196/196 - 15s - loss: 397.9948 - MinusLogProbMetric: 397.9948 - val_loss: 405.0294 - val_MinusLogProbMetric: 405.0294 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 146/1000
2023-09-10 11:19:41.868 
Epoch 146/1000 
	 loss: 397.2452, MinusLogProbMetric: 397.2452, val_loss: 413.1414, val_MinusLogProbMetric: 413.1414

Epoch 146: val_loss did not improve from 402.88574
196/196 - 19s - loss: 397.2452 - MinusLogProbMetric: 397.2452 - val_loss: 413.1414 - val_MinusLogProbMetric: 413.1414 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 147/1000
2023-09-10 11:19:57.394 
Epoch 147/1000 
	 loss: 399.2348, MinusLogProbMetric: 399.2348, val_loss: 405.1553, val_MinusLogProbMetric: 405.1553

Epoch 147: val_loss did not improve from 402.88574
196/196 - 16s - loss: 399.2348 - MinusLogProbMetric: 399.2348 - val_loss: 405.1553 - val_MinusLogProbMetric: 405.1553 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 148/1000
2023-09-10 11:20:14.085 
Epoch 148/1000 
	 loss: 397.4059, MinusLogProbMetric: 397.4059, val_loss: 405.3202, val_MinusLogProbMetric: 405.3202

Epoch 148: val_loss did not improve from 402.88574
196/196 - 17s - loss: 397.4059 - MinusLogProbMetric: 397.4059 - val_loss: 405.3202 - val_MinusLogProbMetric: 405.3202 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 149/1000
2023-09-10 11:20:31.659 
Epoch 149/1000 
	 loss: 398.2809, MinusLogProbMetric: 398.2809, val_loss: 413.6857, val_MinusLogProbMetric: 413.6857

Epoch 149: val_loss did not improve from 402.88574
196/196 - 18s - loss: 398.2809 - MinusLogProbMetric: 398.2809 - val_loss: 413.6857 - val_MinusLogProbMetric: 413.6857 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 150/1000
2023-09-10 11:20:47.176 
Epoch 150/1000 
	 loss: 397.1735, MinusLogProbMetric: 397.1735, val_loss: 404.0959, val_MinusLogProbMetric: 404.0959

Epoch 150: val_loss did not improve from 402.88574
196/196 - 16s - loss: 397.1735 - MinusLogProbMetric: 397.1735 - val_loss: 404.0959 - val_MinusLogProbMetric: 404.0959 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 151/1000
2023-09-10 11:21:03.278 
Epoch 151/1000 
	 loss: 396.9643, MinusLogProbMetric: 396.9643, val_loss: 405.2982, val_MinusLogProbMetric: 405.2982

Epoch 151: val_loss did not improve from 402.88574
196/196 - 16s - loss: 396.9643 - MinusLogProbMetric: 396.9643 - val_loss: 405.2982 - val_MinusLogProbMetric: 405.2982 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 152/1000
2023-09-10 11:21:18.881 
Epoch 152/1000 
	 loss: 397.4238, MinusLogProbMetric: 397.4238, val_loss: 402.3323, val_MinusLogProbMetric: 402.3323

Epoch 152: val_loss improved from 402.88574 to 402.33231, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 16s - loss: 397.4238 - MinusLogProbMetric: 397.4238 - val_loss: 402.3323 - val_MinusLogProbMetric: 402.3323 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 153/1000
2023-09-10 11:21:33.766 
Epoch 153/1000 
	 loss: 397.9201, MinusLogProbMetric: 397.9201, val_loss: 406.5086, val_MinusLogProbMetric: 406.5086

Epoch 153: val_loss did not improve from 402.33231
196/196 - 14s - loss: 397.9201 - MinusLogProbMetric: 397.9201 - val_loss: 406.5086 - val_MinusLogProbMetric: 406.5086 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 154/1000
2023-09-10 11:21:50.172 
Epoch 154/1000 
	 loss: 397.4578, MinusLogProbMetric: 397.4578, val_loss: 402.8698, val_MinusLogProbMetric: 402.8698

Epoch 154: val_loss did not improve from 402.33231
196/196 - 16s - loss: 397.4578 - MinusLogProbMetric: 397.4578 - val_loss: 402.8698 - val_MinusLogProbMetric: 402.8698 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 155/1000
2023-09-10 11:22:04.535 
Epoch 155/1000 
	 loss: 397.2086, MinusLogProbMetric: 397.2086, val_loss: 402.2140, val_MinusLogProbMetric: 402.2140

Epoch 155: val_loss improved from 402.33231 to 402.21396, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 15s - loss: 397.2086 - MinusLogProbMetric: 397.2086 - val_loss: 402.2140 - val_MinusLogProbMetric: 402.2140 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 156/1000
2023-09-10 11:22:21.575 
Epoch 156/1000 
	 loss: 397.0735, MinusLogProbMetric: 397.0735, val_loss: 406.4071, val_MinusLogProbMetric: 406.4071

Epoch 156: val_loss did not improve from 402.21396
196/196 - 16s - loss: 397.0735 - MinusLogProbMetric: 397.0735 - val_loss: 406.4071 - val_MinusLogProbMetric: 406.4071 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 157/1000
2023-09-10 11:22:37.968 
Epoch 157/1000 
	 loss: 397.8423, MinusLogProbMetric: 397.8423, val_loss: 402.6739, val_MinusLogProbMetric: 402.6739

Epoch 157: val_loss did not improve from 402.21396
196/196 - 16s - loss: 397.8423 - MinusLogProbMetric: 397.8423 - val_loss: 402.6739 - val_MinusLogProbMetric: 402.6739 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 158/1000
2023-09-10 11:22:53.204 
Epoch 158/1000 
	 loss: 397.3165, MinusLogProbMetric: 397.3165, val_loss: 407.7241, val_MinusLogProbMetric: 407.7241

Epoch 158: val_loss did not improve from 402.21396
196/196 - 15s - loss: 397.3165 - MinusLogProbMetric: 397.3165 - val_loss: 407.7241 - val_MinusLogProbMetric: 407.7241 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 159/1000
2023-09-10 11:23:08.565 
Epoch 159/1000 
	 loss: 397.1073, MinusLogProbMetric: 397.1073, val_loss: 406.6316, val_MinusLogProbMetric: 406.6316

Epoch 159: val_loss did not improve from 402.21396
196/196 - 15s - loss: 397.1073 - MinusLogProbMetric: 397.1073 - val_loss: 406.6316 - val_MinusLogProbMetric: 406.6316 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 160/1000
2023-09-10 11:23:26.731 
Epoch 160/1000 
	 loss: 396.6915, MinusLogProbMetric: 396.6915, val_loss: 405.0839, val_MinusLogProbMetric: 405.0839

Epoch 160: val_loss did not improve from 402.21396
196/196 - 18s - loss: 396.6915 - MinusLogProbMetric: 396.6915 - val_loss: 405.0839 - val_MinusLogProbMetric: 405.0839 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 161/1000
2023-09-10 11:23:46.474 
Epoch 161/1000 
	 loss: 396.4274, MinusLogProbMetric: 396.4274, val_loss: 402.9683, val_MinusLogProbMetric: 402.9683

Epoch 161: val_loss did not improve from 402.21396
196/196 - 20s - loss: 396.4274 - MinusLogProbMetric: 396.4274 - val_loss: 402.9683 - val_MinusLogProbMetric: 402.9683 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 162/1000
2023-09-10 11:24:03.660 
Epoch 162/1000 
	 loss: 396.7436, MinusLogProbMetric: 396.7436, val_loss: 406.3999, val_MinusLogProbMetric: 406.3999

Epoch 162: val_loss did not improve from 402.21396
196/196 - 17s - loss: 396.7436 - MinusLogProbMetric: 396.7436 - val_loss: 406.3999 - val_MinusLogProbMetric: 406.3999 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 163/1000
2023-09-10 11:24:19.509 
Epoch 163/1000 
	 loss: 397.2496, MinusLogProbMetric: 397.2496, val_loss: 405.7823, val_MinusLogProbMetric: 405.7823

Epoch 163: val_loss did not improve from 402.21396
196/196 - 16s - loss: 397.2496 - MinusLogProbMetric: 397.2496 - val_loss: 405.7823 - val_MinusLogProbMetric: 405.7823 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 164/1000
2023-09-10 11:24:35.600 
Epoch 164/1000 
	 loss: 396.6028, MinusLogProbMetric: 396.6028, val_loss: 404.0532, val_MinusLogProbMetric: 404.0532

Epoch 164: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.6028 - MinusLogProbMetric: 396.6028 - val_loss: 404.0532 - val_MinusLogProbMetric: 404.0532 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 165/1000
2023-09-10 11:24:51.647 
Epoch 165/1000 
	 loss: 396.6873, MinusLogProbMetric: 396.6873, val_loss: 404.4842, val_MinusLogProbMetric: 404.4842

Epoch 165: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.6873 - MinusLogProbMetric: 396.6873 - val_loss: 404.4842 - val_MinusLogProbMetric: 404.4842 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 166/1000
2023-09-10 11:25:07.879 
Epoch 166/1000 
	 loss: 396.5031, MinusLogProbMetric: 396.5031, val_loss: 407.4086, val_MinusLogProbMetric: 407.4086

Epoch 166: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.5031 - MinusLogProbMetric: 396.5031 - val_loss: 407.4086 - val_MinusLogProbMetric: 407.4086 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 167/1000
2023-09-10 11:25:25.357 
Epoch 167/1000 
	 loss: 396.6400, MinusLogProbMetric: 396.6400, val_loss: 405.1306, val_MinusLogProbMetric: 405.1306

Epoch 167: val_loss did not improve from 402.21396
196/196 - 17s - loss: 396.6400 - MinusLogProbMetric: 396.6400 - val_loss: 405.1306 - val_MinusLogProbMetric: 405.1306 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 168/1000
2023-09-10 11:25:42.383 
Epoch 168/1000 
	 loss: 396.2209, MinusLogProbMetric: 396.2209, val_loss: 403.1046, val_MinusLogProbMetric: 403.1046

Epoch 168: val_loss did not improve from 402.21396
196/196 - 17s - loss: 396.2209 - MinusLogProbMetric: 396.2209 - val_loss: 403.1046 - val_MinusLogProbMetric: 403.1046 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 169/1000
2023-09-10 11:26:00.536 
Epoch 169/1000 
	 loss: 395.9207, MinusLogProbMetric: 395.9207, val_loss: 407.7063, val_MinusLogProbMetric: 407.7063

Epoch 169: val_loss did not improve from 402.21396
196/196 - 18s - loss: 395.9207 - MinusLogProbMetric: 395.9207 - val_loss: 407.7063 - val_MinusLogProbMetric: 407.7063 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 170/1000
2023-09-10 11:26:16.155 
Epoch 170/1000 
	 loss: 396.7789, MinusLogProbMetric: 396.7789, val_loss: 403.6340, val_MinusLogProbMetric: 403.6340

Epoch 170: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.7789 - MinusLogProbMetric: 396.7789 - val_loss: 403.6340 - val_MinusLogProbMetric: 403.6340 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 171/1000
2023-09-10 11:26:33.573 
Epoch 171/1000 
	 loss: 396.1268, MinusLogProbMetric: 396.1268, val_loss: 403.4294, val_MinusLogProbMetric: 403.4294

Epoch 171: val_loss did not improve from 402.21396
196/196 - 17s - loss: 396.1268 - MinusLogProbMetric: 396.1268 - val_loss: 403.4294 - val_MinusLogProbMetric: 403.4294 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 172/1000
2023-09-10 11:26:50.158 
Epoch 172/1000 
	 loss: 396.7264, MinusLogProbMetric: 396.7264, val_loss: 416.0422, val_MinusLogProbMetric: 416.0422

Epoch 172: val_loss did not improve from 402.21396
196/196 - 17s - loss: 396.7264 - MinusLogProbMetric: 396.7264 - val_loss: 416.0422 - val_MinusLogProbMetric: 416.0422 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 173/1000
2023-09-10 11:27:04.530 
Epoch 173/1000 
	 loss: 396.2093, MinusLogProbMetric: 396.2093, val_loss: 404.2811, val_MinusLogProbMetric: 404.2811

Epoch 173: val_loss did not improve from 402.21396
196/196 - 14s - loss: 396.2093 - MinusLogProbMetric: 396.2093 - val_loss: 404.2811 - val_MinusLogProbMetric: 404.2811 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 174/1000
2023-09-10 11:27:19.380 
Epoch 174/1000 
	 loss: 397.4668, MinusLogProbMetric: 397.4668, val_loss: 407.5219, val_MinusLogProbMetric: 407.5219

Epoch 174: val_loss did not improve from 402.21396
196/196 - 15s - loss: 397.4668 - MinusLogProbMetric: 397.4668 - val_loss: 407.5219 - val_MinusLogProbMetric: 407.5219 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 175/1000
2023-09-10 11:27:33.515 
Epoch 175/1000 
	 loss: 395.8891, MinusLogProbMetric: 395.8891, val_loss: 403.7504, val_MinusLogProbMetric: 403.7504

Epoch 175: val_loss did not improve from 402.21396
196/196 - 14s - loss: 395.8891 - MinusLogProbMetric: 395.8891 - val_loss: 403.7504 - val_MinusLogProbMetric: 403.7504 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 176/1000
2023-09-10 11:27:49.699 
Epoch 176/1000 
	 loss: 395.7775, MinusLogProbMetric: 395.7775, val_loss: 406.4664, val_MinusLogProbMetric: 406.4664

Epoch 176: val_loss did not improve from 402.21396
196/196 - 16s - loss: 395.7775 - MinusLogProbMetric: 395.7775 - val_loss: 406.4664 - val_MinusLogProbMetric: 406.4664 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 177/1000
2023-09-10 11:28:07.033 
Epoch 177/1000 
	 loss: 395.7393, MinusLogProbMetric: 395.7393, val_loss: 405.0762, val_MinusLogProbMetric: 405.0762

Epoch 177: val_loss did not improve from 402.21396
196/196 - 17s - loss: 395.7393 - MinusLogProbMetric: 395.7393 - val_loss: 405.0762 - val_MinusLogProbMetric: 405.0762 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 178/1000
2023-09-10 11:28:22.704 
Epoch 178/1000 
	 loss: 395.8540, MinusLogProbMetric: 395.8540, val_loss: 404.0449, val_MinusLogProbMetric: 404.0449

Epoch 178: val_loss did not improve from 402.21396
196/196 - 16s - loss: 395.8540 - MinusLogProbMetric: 395.8540 - val_loss: 404.0449 - val_MinusLogProbMetric: 404.0449 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 179/1000
2023-09-10 11:28:38.483 
Epoch 179/1000 
	 loss: 396.5571, MinusLogProbMetric: 396.5571, val_loss: 402.9562, val_MinusLogProbMetric: 402.9562

Epoch 179: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.5571 - MinusLogProbMetric: 396.5571 - val_loss: 402.9562 - val_MinusLogProbMetric: 402.9562 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 180/1000
2023-09-10 11:28:54.654 
Epoch 180/1000 
	 loss: 396.1053, MinusLogProbMetric: 396.1053, val_loss: 407.7576, val_MinusLogProbMetric: 407.7576

Epoch 180: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.1053 - MinusLogProbMetric: 396.1053 - val_loss: 407.7576 - val_MinusLogProbMetric: 407.7576 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 181/1000
2023-09-10 11:29:13.150 
Epoch 181/1000 
	 loss: 395.9429, MinusLogProbMetric: 395.9429, val_loss: 405.3667, val_MinusLogProbMetric: 405.3667

Epoch 181: val_loss did not improve from 402.21396
196/196 - 18s - loss: 395.9429 - MinusLogProbMetric: 395.9429 - val_loss: 405.3667 - val_MinusLogProbMetric: 405.3667 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 182/1000
2023-09-10 11:29:28.401 
Epoch 182/1000 
	 loss: 395.6213, MinusLogProbMetric: 395.6213, val_loss: 411.4636, val_MinusLogProbMetric: 411.4636

Epoch 182: val_loss did not improve from 402.21396
196/196 - 15s - loss: 395.6213 - MinusLogProbMetric: 395.6213 - val_loss: 411.4636 - val_MinusLogProbMetric: 411.4636 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 183/1000
2023-09-10 11:29:42.689 
Epoch 183/1000 
	 loss: 395.8661, MinusLogProbMetric: 395.8661, val_loss: 405.2236, val_MinusLogProbMetric: 405.2236

Epoch 183: val_loss did not improve from 402.21396
196/196 - 14s - loss: 395.8661 - MinusLogProbMetric: 395.8661 - val_loss: 405.2236 - val_MinusLogProbMetric: 405.2236 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 184/1000
2023-09-10 11:29:58.893 
Epoch 184/1000 
	 loss: 395.9596, MinusLogProbMetric: 395.9596, val_loss: 404.9205, val_MinusLogProbMetric: 404.9205

Epoch 184: val_loss did not improve from 402.21396
196/196 - 16s - loss: 395.9596 - MinusLogProbMetric: 395.9596 - val_loss: 404.9205 - val_MinusLogProbMetric: 404.9205 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 185/1000
2023-09-10 11:30:14.009 
Epoch 185/1000 
	 loss: 395.2868, MinusLogProbMetric: 395.2868, val_loss: 404.3223, val_MinusLogProbMetric: 404.3223

Epoch 185: val_loss did not improve from 402.21396
196/196 - 15s - loss: 395.2868 - MinusLogProbMetric: 395.2868 - val_loss: 404.3223 - val_MinusLogProbMetric: 404.3223 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 186/1000
2023-09-10 11:30:29.970 
Epoch 186/1000 
	 loss: 396.2805, MinusLogProbMetric: 396.2805, val_loss: 402.2531, val_MinusLogProbMetric: 402.2531

Epoch 186: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.2805 - MinusLogProbMetric: 396.2805 - val_loss: 402.2531 - val_MinusLogProbMetric: 402.2531 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 187/1000
2023-09-10 11:30:44.907 
Epoch 187/1000 
	 loss: 395.3247, MinusLogProbMetric: 395.3247, val_loss: 403.4109, val_MinusLogProbMetric: 403.4109

Epoch 187: val_loss did not improve from 402.21396
196/196 - 15s - loss: 395.3247 - MinusLogProbMetric: 395.3247 - val_loss: 403.4109 - val_MinusLogProbMetric: 403.4109 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 188/1000
2023-09-10 11:30:59.297 
Epoch 188/1000 
	 loss: 395.3489, MinusLogProbMetric: 395.3489, val_loss: 425.4694, val_MinusLogProbMetric: 425.4694

Epoch 188: val_loss did not improve from 402.21396
196/196 - 14s - loss: 395.3489 - MinusLogProbMetric: 395.3489 - val_loss: 425.4694 - val_MinusLogProbMetric: 425.4694 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 189/1000
2023-09-10 11:31:14.352 
Epoch 189/1000 
	 loss: 395.7006, MinusLogProbMetric: 395.7006, val_loss: 403.7679, val_MinusLogProbMetric: 403.7679

Epoch 189: val_loss did not improve from 402.21396
196/196 - 15s - loss: 395.7006 - MinusLogProbMetric: 395.7006 - val_loss: 403.7679 - val_MinusLogProbMetric: 403.7679 - lr: 3.3333e-04 - 15s/epoch - 77ms/step
Epoch 190/1000
2023-09-10 11:31:28.016 
Epoch 190/1000 
	 loss: 395.3725, MinusLogProbMetric: 395.3725, val_loss: 405.7106, val_MinusLogProbMetric: 405.7106

Epoch 190: val_loss did not improve from 402.21396
196/196 - 14s - loss: 395.3725 - MinusLogProbMetric: 395.3725 - val_loss: 405.7106 - val_MinusLogProbMetric: 405.7106 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 191/1000
2023-09-10 11:31:43.730 
Epoch 191/1000 
	 loss: 394.7412, MinusLogProbMetric: 394.7412, val_loss: 405.4368, val_MinusLogProbMetric: 405.4368

Epoch 191: val_loss did not improve from 402.21396
196/196 - 16s - loss: 394.7412 - MinusLogProbMetric: 394.7412 - val_loss: 405.4368 - val_MinusLogProbMetric: 405.4368 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 192/1000
2023-09-10 11:31:58.275 
Epoch 192/1000 
	 loss: 394.9544, MinusLogProbMetric: 394.9544, val_loss: 402.7871, val_MinusLogProbMetric: 402.7871

Epoch 192: val_loss did not improve from 402.21396
196/196 - 15s - loss: 394.9544 - MinusLogProbMetric: 394.9544 - val_loss: 402.7871 - val_MinusLogProbMetric: 402.7871 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 193/1000
2023-09-10 11:32:13.915 
Epoch 193/1000 
	 loss: 396.7067, MinusLogProbMetric: 396.7067, val_loss: 403.9512, val_MinusLogProbMetric: 403.9512

Epoch 193: val_loss did not improve from 402.21396
196/196 - 16s - loss: 396.7067 - MinusLogProbMetric: 396.7067 - val_loss: 403.9512 - val_MinusLogProbMetric: 403.9512 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 194/1000
2023-09-10 11:32:30.248 
Epoch 194/1000 
	 loss: 395.1543, MinusLogProbMetric: 395.1543, val_loss: 404.4442, val_MinusLogProbMetric: 404.4442

Epoch 194: val_loss did not improve from 402.21396
196/196 - 16s - loss: 395.1543 - MinusLogProbMetric: 395.1543 - val_loss: 404.4442 - val_MinusLogProbMetric: 404.4442 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 195/1000
2023-09-10 11:32:45.635 
Epoch 195/1000 
	 loss: 394.4642, MinusLogProbMetric: 394.4642, val_loss: 403.8151, val_MinusLogProbMetric: 403.8151

Epoch 195: val_loss did not improve from 402.21396
196/196 - 15s - loss: 394.4642 - MinusLogProbMetric: 394.4642 - val_loss: 403.8151 - val_MinusLogProbMetric: 403.8151 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 196/1000
2023-09-10 11:32:59.727 
Epoch 196/1000 
	 loss: 395.0498, MinusLogProbMetric: 395.0498, val_loss: 403.5886, val_MinusLogProbMetric: 403.5886

Epoch 196: val_loss did not improve from 402.21396
196/196 - 14s - loss: 395.0498 - MinusLogProbMetric: 395.0498 - val_loss: 403.5886 - val_MinusLogProbMetric: 403.5886 - lr: 3.3333e-04 - 14s/epoch - 72ms/step
Epoch 197/1000
2023-09-10 11:33:14.070 
Epoch 197/1000 
	 loss: 394.8964, MinusLogProbMetric: 394.8964, val_loss: 404.6741, val_MinusLogProbMetric: 404.6741

Epoch 197: val_loss did not improve from 402.21396
196/196 - 14s - loss: 394.8964 - MinusLogProbMetric: 394.8964 - val_loss: 404.6741 - val_MinusLogProbMetric: 404.6741 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 198/1000
2023-09-10 11:33:28.765 
Epoch 198/1000 
	 loss: 394.5396, MinusLogProbMetric: 394.5396, val_loss: 410.3173, val_MinusLogProbMetric: 410.3173

Epoch 198: val_loss did not improve from 402.21396
196/196 - 15s - loss: 394.5396 - MinusLogProbMetric: 394.5396 - val_loss: 410.3173 - val_MinusLogProbMetric: 410.3173 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 199/1000
2023-09-10 11:33:44.031 
Epoch 199/1000 
	 loss: 395.1581, MinusLogProbMetric: 395.1581, val_loss: 404.0120, val_MinusLogProbMetric: 404.0120

Epoch 199: val_loss did not improve from 402.21396
196/196 - 15s - loss: 395.1581 - MinusLogProbMetric: 395.1581 - val_loss: 404.0120 - val_MinusLogProbMetric: 404.0120 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 200/1000
2023-09-10 11:33:59.757 
Epoch 200/1000 
	 loss: 394.5278, MinusLogProbMetric: 394.5278, val_loss: 404.2082, val_MinusLogProbMetric: 404.2082

Epoch 200: val_loss did not improve from 402.21396
196/196 - 16s - loss: 394.5278 - MinusLogProbMetric: 394.5278 - val_loss: 404.2082 - val_MinusLogProbMetric: 404.2082 - lr: 3.3333e-04 - 16s/epoch - 80ms/step
Epoch 201/1000
2023-09-10 11:34:13.392 
Epoch 201/1000 
	 loss: 394.5382, MinusLogProbMetric: 394.5382, val_loss: 406.5210, val_MinusLogProbMetric: 406.5210

Epoch 201: val_loss did not improve from 402.21396
196/196 - 14s - loss: 394.5382 - MinusLogProbMetric: 394.5382 - val_loss: 406.5210 - val_MinusLogProbMetric: 406.5210 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 202/1000
2023-09-10 11:34:27.828 
Epoch 202/1000 
	 loss: 394.5242, MinusLogProbMetric: 394.5242, val_loss: 405.1218, val_MinusLogProbMetric: 405.1218

Epoch 202: val_loss did not improve from 402.21396
196/196 - 14s - loss: 394.5242 - MinusLogProbMetric: 394.5242 - val_loss: 405.1218 - val_MinusLogProbMetric: 405.1218 - lr: 3.3333e-04 - 14s/epoch - 74ms/step
Epoch 203/1000
2023-09-10 11:34:42.484 
Epoch 203/1000 
	 loss: 395.1438, MinusLogProbMetric: 395.1438, val_loss: 403.4510, val_MinusLogProbMetric: 403.4510

Epoch 203: val_loss did not improve from 402.21396
196/196 - 15s - loss: 395.1438 - MinusLogProbMetric: 395.1438 - val_loss: 403.4510 - val_MinusLogProbMetric: 403.4510 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 204/1000
2023-09-10 11:34:58.006 
Epoch 204/1000 
	 loss: 394.2458, MinusLogProbMetric: 394.2458, val_loss: 404.3475, val_MinusLogProbMetric: 404.3475

Epoch 204: val_loss did not improve from 402.21396
196/196 - 16s - loss: 394.2458 - MinusLogProbMetric: 394.2458 - val_loss: 404.3475 - val_MinusLogProbMetric: 404.3475 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 205/1000
2023-09-10 11:35:12.584 
Epoch 205/1000 
	 loss: 394.4363, MinusLogProbMetric: 394.4363, val_loss: 409.0285, val_MinusLogProbMetric: 409.0285

Epoch 205: val_loss did not improve from 402.21396
196/196 - 15s - loss: 394.4363 - MinusLogProbMetric: 394.4363 - val_loss: 409.0285 - val_MinusLogProbMetric: 409.0285 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 206/1000
2023-09-10 11:35:26.354 
Epoch 206/1000 
	 loss: 388.8964, MinusLogProbMetric: 388.8964, val_loss: 399.6258, val_MinusLogProbMetric: 399.6258

Epoch 206: val_loss improved from 402.21396 to 399.62579, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 15s - loss: 388.8964 - MinusLogProbMetric: 388.8964 - val_loss: 399.6258 - val_MinusLogProbMetric: 399.6258 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 207/1000
2023-09-10 11:35:40.478 
Epoch 207/1000 
	 loss: 388.7101, MinusLogProbMetric: 388.7101, val_loss: 400.4909, val_MinusLogProbMetric: 400.4909

Epoch 207: val_loss did not improve from 399.62579
196/196 - 13s - loss: 388.7101 - MinusLogProbMetric: 388.7101 - val_loss: 400.4909 - val_MinusLogProbMetric: 400.4909 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 208/1000
2023-09-10 11:35:54.841 
Epoch 208/1000 
	 loss: 389.0925, MinusLogProbMetric: 389.0925, val_loss: 400.1211, val_MinusLogProbMetric: 400.1211

Epoch 208: val_loss did not improve from 399.62579
196/196 - 14s - loss: 389.0925 - MinusLogProbMetric: 389.0925 - val_loss: 400.1211 - val_MinusLogProbMetric: 400.1211 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 209/1000
2023-09-10 11:36:11.271 
Epoch 209/1000 
	 loss: 389.1108, MinusLogProbMetric: 389.1108, val_loss: 401.5685, val_MinusLogProbMetric: 401.5685

Epoch 209: val_loss did not improve from 399.62579
196/196 - 16s - loss: 389.1108 - MinusLogProbMetric: 389.1108 - val_loss: 401.5685 - val_MinusLogProbMetric: 401.5685 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 210/1000
2023-09-10 11:36:25.366 
Epoch 210/1000 
	 loss: 389.1303, MinusLogProbMetric: 389.1303, val_loss: 400.8437, val_MinusLogProbMetric: 400.8437

Epoch 210: val_loss did not improve from 399.62579
196/196 - 14s - loss: 389.1303 - MinusLogProbMetric: 389.1303 - val_loss: 400.8437 - val_MinusLogProbMetric: 400.8437 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 211/1000
2023-09-10 11:36:40.448 
Epoch 211/1000 
	 loss: 389.0936, MinusLogProbMetric: 389.0936, val_loss: 400.5684, val_MinusLogProbMetric: 400.5684

Epoch 211: val_loss did not improve from 399.62579
196/196 - 15s - loss: 389.0936 - MinusLogProbMetric: 389.0936 - val_loss: 400.5684 - val_MinusLogProbMetric: 400.5684 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 212/1000
2023-09-10 11:36:56.275 
Epoch 212/1000 
	 loss: 388.9625, MinusLogProbMetric: 388.9625, val_loss: 400.7153, val_MinusLogProbMetric: 400.7153

Epoch 212: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.9625 - MinusLogProbMetric: 388.9625 - val_loss: 400.7153 - val_MinusLogProbMetric: 400.7153 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 213/1000
2023-09-10 11:37:12.432 
Epoch 213/1000 
	 loss: 389.0871, MinusLogProbMetric: 389.0871, val_loss: 402.7296, val_MinusLogProbMetric: 402.7296

Epoch 213: val_loss did not improve from 399.62579
196/196 - 16s - loss: 389.0871 - MinusLogProbMetric: 389.0871 - val_loss: 402.7296 - val_MinusLogProbMetric: 402.7296 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 214/1000
2023-09-10 11:37:28.986 
Epoch 214/1000 
	 loss: 388.8797, MinusLogProbMetric: 388.8797, val_loss: 399.9687, val_MinusLogProbMetric: 399.9687

Epoch 214: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.8797 - MinusLogProbMetric: 388.8797 - val_loss: 399.9687 - val_MinusLogProbMetric: 399.9687 - lr: 1.6667e-04 - 17s/epoch - 84ms/step
Epoch 215/1000
2023-09-10 11:37:45.810 
Epoch 215/1000 
	 loss: 388.9215, MinusLogProbMetric: 388.9215, val_loss: 400.5079, val_MinusLogProbMetric: 400.5079

Epoch 215: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.9215 - MinusLogProbMetric: 388.9215 - val_loss: 400.5079 - val_MinusLogProbMetric: 400.5079 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 216/1000
2023-09-10 11:38:01.520 
Epoch 216/1000 
	 loss: 389.0677, MinusLogProbMetric: 389.0677, val_loss: 400.6067, val_MinusLogProbMetric: 400.6067

Epoch 216: val_loss did not improve from 399.62579
196/196 - 16s - loss: 389.0677 - MinusLogProbMetric: 389.0677 - val_loss: 400.6067 - val_MinusLogProbMetric: 400.6067 - lr: 1.6667e-04 - 16s/epoch - 80ms/step
Epoch 217/1000
2023-09-10 11:38:17.307 
Epoch 217/1000 
	 loss: 388.7903, MinusLogProbMetric: 388.7903, val_loss: 399.9512, val_MinusLogProbMetric: 399.9512

Epoch 217: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.7903 - MinusLogProbMetric: 388.7903 - val_loss: 399.9512 - val_MinusLogProbMetric: 399.9512 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 218/1000
2023-09-10 11:38:35.137 
Epoch 218/1000 
	 loss: 388.8001, MinusLogProbMetric: 388.8001, val_loss: 401.1594, val_MinusLogProbMetric: 401.1594

Epoch 218: val_loss did not improve from 399.62579
196/196 - 18s - loss: 388.8001 - MinusLogProbMetric: 388.8001 - val_loss: 401.1594 - val_MinusLogProbMetric: 401.1594 - lr: 1.6667e-04 - 18s/epoch - 91ms/step
Epoch 219/1000
2023-09-10 11:38:51.875 
Epoch 219/1000 
	 loss: 388.7578, MinusLogProbMetric: 388.7578, val_loss: 399.9320, val_MinusLogProbMetric: 399.9320

Epoch 219: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.7578 - MinusLogProbMetric: 388.7578 - val_loss: 399.9320 - val_MinusLogProbMetric: 399.9320 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 220/1000
2023-09-10 11:39:07.418 
Epoch 220/1000 
	 loss: 388.6427, MinusLogProbMetric: 388.6427, val_loss: 400.3125, val_MinusLogProbMetric: 400.3125

Epoch 220: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.6427 - MinusLogProbMetric: 388.6427 - val_loss: 400.3125 - val_MinusLogProbMetric: 400.3125 - lr: 1.6667e-04 - 16s/epoch - 79ms/step
Epoch 221/1000
2023-09-10 11:39:23.432 
Epoch 221/1000 
	 loss: 388.7374, MinusLogProbMetric: 388.7374, val_loss: 400.4131, val_MinusLogProbMetric: 400.4131

Epoch 221: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.7374 - MinusLogProbMetric: 388.7374 - val_loss: 400.4131 - val_MinusLogProbMetric: 400.4131 - lr: 1.6667e-04 - 16s/epoch - 82ms/step
Epoch 222/1000
2023-09-10 11:39:40.254 
Epoch 222/1000 
	 loss: 388.9749, MinusLogProbMetric: 388.9749, val_loss: 403.6543, val_MinusLogProbMetric: 403.6543

Epoch 222: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.9749 - MinusLogProbMetric: 388.9749 - val_loss: 403.6543 - val_MinusLogProbMetric: 403.6543 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 223/1000
2023-09-10 11:39:56.661 
Epoch 223/1000 
	 loss: 388.6317, MinusLogProbMetric: 388.6317, val_loss: 400.2331, val_MinusLogProbMetric: 400.2331

Epoch 223: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.6317 - MinusLogProbMetric: 388.6317 - val_loss: 400.2331 - val_MinusLogProbMetric: 400.2331 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 224/1000
2023-09-10 11:40:11.946 
Epoch 224/1000 
	 loss: 388.7598, MinusLogProbMetric: 388.7598, val_loss: 401.4149, val_MinusLogProbMetric: 401.4149

Epoch 224: val_loss did not improve from 399.62579
196/196 - 15s - loss: 388.7598 - MinusLogProbMetric: 388.7598 - val_loss: 401.4149 - val_MinusLogProbMetric: 401.4149 - lr: 1.6667e-04 - 15s/epoch - 78ms/step
Epoch 225/1000
2023-09-10 11:40:28.221 
Epoch 225/1000 
	 loss: 388.6261, MinusLogProbMetric: 388.6261, val_loss: 400.0611, val_MinusLogProbMetric: 400.0611

Epoch 225: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.6261 - MinusLogProbMetric: 388.6261 - val_loss: 400.0611 - val_MinusLogProbMetric: 400.0611 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 226/1000
2023-09-10 11:40:41.642 
Epoch 226/1000 
	 loss: 388.5255, MinusLogProbMetric: 388.5255, val_loss: 399.9812, val_MinusLogProbMetric: 399.9812

Epoch 226: val_loss did not improve from 399.62579
196/196 - 13s - loss: 388.5255 - MinusLogProbMetric: 388.5255 - val_loss: 399.9812 - val_MinusLogProbMetric: 399.9812 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 227/1000
2023-09-10 11:40:57.123 
Epoch 227/1000 
	 loss: 388.6504, MinusLogProbMetric: 388.6504, val_loss: 401.1631, val_MinusLogProbMetric: 401.1631

Epoch 227: val_loss did not improve from 399.62579
196/196 - 15s - loss: 388.6504 - MinusLogProbMetric: 388.6504 - val_loss: 401.1631 - val_MinusLogProbMetric: 401.1631 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 228/1000
2023-09-10 11:41:12.593 
Epoch 228/1000 
	 loss: 388.7433, MinusLogProbMetric: 388.7433, val_loss: 400.8723, val_MinusLogProbMetric: 400.8723

Epoch 228: val_loss did not improve from 399.62579
196/196 - 15s - loss: 388.7433 - MinusLogProbMetric: 388.7433 - val_loss: 400.8723 - val_MinusLogProbMetric: 400.8723 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 229/1000
2023-09-10 11:41:28.807 
Epoch 229/1000 
	 loss: 388.7321, MinusLogProbMetric: 388.7321, val_loss: 402.4192, val_MinusLogProbMetric: 402.4192

Epoch 229: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.7321 - MinusLogProbMetric: 388.7321 - val_loss: 402.4192 - val_MinusLogProbMetric: 402.4192 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 230/1000
2023-09-10 11:41:43.033 
Epoch 230/1000 
	 loss: 388.4830, MinusLogProbMetric: 388.4830, val_loss: 402.7988, val_MinusLogProbMetric: 402.7988

Epoch 230: val_loss did not improve from 399.62579
196/196 - 14s - loss: 388.4830 - MinusLogProbMetric: 388.4830 - val_loss: 402.7988 - val_MinusLogProbMetric: 402.7988 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 231/1000
2023-09-10 11:41:56.584 
Epoch 231/1000 
	 loss: 388.4914, MinusLogProbMetric: 388.4914, val_loss: 400.6269, val_MinusLogProbMetric: 400.6269

Epoch 231: val_loss did not improve from 399.62579
196/196 - 14s - loss: 388.4914 - MinusLogProbMetric: 388.4914 - val_loss: 400.6269 - val_MinusLogProbMetric: 400.6269 - lr: 1.6667e-04 - 14s/epoch - 69ms/step
Epoch 232/1000
2023-09-10 11:42:13.271 
Epoch 232/1000 
	 loss: 388.5341, MinusLogProbMetric: 388.5341, val_loss: 399.8985, val_MinusLogProbMetric: 399.8985

Epoch 232: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.5341 - MinusLogProbMetric: 388.5341 - val_loss: 399.8985 - val_MinusLogProbMetric: 399.8985 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 233/1000
2023-09-10 11:42:27.927 
Epoch 233/1000 
	 loss: 388.4563, MinusLogProbMetric: 388.4563, val_loss: 403.1584, val_MinusLogProbMetric: 403.1584

Epoch 233: val_loss did not improve from 399.62579
196/196 - 15s - loss: 388.4563 - MinusLogProbMetric: 388.4563 - val_loss: 403.1584 - val_MinusLogProbMetric: 403.1584 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 234/1000
2023-09-10 11:42:43.734 
Epoch 234/1000 
	 loss: 388.5400, MinusLogProbMetric: 388.5400, val_loss: 400.4930, val_MinusLogProbMetric: 400.4930

Epoch 234: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.5400 - MinusLogProbMetric: 388.5400 - val_loss: 400.4930 - val_MinusLogProbMetric: 400.4930 - lr: 1.6667e-04 - 16s/epoch - 81ms/step
Epoch 235/1000
2023-09-10 11:43:00.043 
Epoch 235/1000 
	 loss: 388.3214, MinusLogProbMetric: 388.3214, val_loss: 400.9872, val_MinusLogProbMetric: 400.9872

Epoch 235: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.3214 - MinusLogProbMetric: 388.3214 - val_loss: 400.9872 - val_MinusLogProbMetric: 400.9872 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 236/1000
2023-09-10 11:43:16.872 
Epoch 236/1000 
	 loss: 388.5385, MinusLogProbMetric: 388.5385, val_loss: 400.4356, val_MinusLogProbMetric: 400.4356

Epoch 236: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.5385 - MinusLogProbMetric: 388.5385 - val_loss: 400.4356 - val_MinusLogProbMetric: 400.4356 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 237/1000
2023-09-10 11:43:33.557 
Epoch 237/1000 
	 loss: 388.3663, MinusLogProbMetric: 388.3663, val_loss: 400.4296, val_MinusLogProbMetric: 400.4296

Epoch 237: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.3663 - MinusLogProbMetric: 388.3663 - val_loss: 400.4296 - val_MinusLogProbMetric: 400.4296 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 238/1000
2023-09-10 11:43:51.045 
Epoch 238/1000 
	 loss: 388.6333, MinusLogProbMetric: 388.6333, val_loss: 401.1927, val_MinusLogProbMetric: 401.1927

Epoch 238: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.6333 - MinusLogProbMetric: 388.6333 - val_loss: 401.1927 - val_MinusLogProbMetric: 401.1927 - lr: 1.6667e-04 - 17s/epoch - 89ms/step
Epoch 239/1000
2023-09-10 11:44:07.620 
Epoch 239/1000 
	 loss: 388.2612, MinusLogProbMetric: 388.2612, val_loss: 401.4710, val_MinusLogProbMetric: 401.4710

Epoch 239: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.2612 - MinusLogProbMetric: 388.2612 - val_loss: 401.4710 - val_MinusLogProbMetric: 401.4710 - lr: 1.6667e-04 - 17s/epoch - 84ms/step
Epoch 240/1000
2023-09-10 11:44:24.454 
Epoch 240/1000 
	 loss: 388.2908, MinusLogProbMetric: 388.2908, val_loss: 401.3972, val_MinusLogProbMetric: 401.3972

Epoch 240: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.2908 - MinusLogProbMetric: 388.2908 - val_loss: 401.3972 - val_MinusLogProbMetric: 401.3972 - lr: 1.6667e-04 - 17s/epoch - 86ms/step
Epoch 241/1000
2023-09-10 11:44:42.378 
Epoch 241/1000 
	 loss: 388.5016, MinusLogProbMetric: 388.5016, val_loss: 405.5439, val_MinusLogProbMetric: 405.5439

Epoch 241: val_loss did not improve from 399.62579
196/196 - 18s - loss: 388.5016 - MinusLogProbMetric: 388.5016 - val_loss: 405.5439 - val_MinusLogProbMetric: 405.5439 - lr: 1.6667e-04 - 18s/epoch - 91ms/step
Epoch 242/1000
2023-09-10 11:44:57.800 
Epoch 242/1000 
	 loss: 388.3858, MinusLogProbMetric: 388.3858, val_loss: 402.7093, val_MinusLogProbMetric: 402.7093

Epoch 242: val_loss did not improve from 399.62579
196/196 - 15s - loss: 388.3858 - MinusLogProbMetric: 388.3858 - val_loss: 402.7093 - val_MinusLogProbMetric: 402.7093 - lr: 1.6667e-04 - 15s/epoch - 79ms/step
Epoch 243/1000
2023-09-10 11:45:14.045 
Epoch 243/1000 
	 loss: 388.2926, MinusLogProbMetric: 388.2926, val_loss: 400.9138, val_MinusLogProbMetric: 400.9138

Epoch 243: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.2926 - MinusLogProbMetric: 388.2926 - val_loss: 400.9138 - val_MinusLogProbMetric: 400.9138 - lr: 1.6667e-04 - 16s/epoch - 83ms/step
Epoch 244/1000
2023-09-10 11:45:31.023 
Epoch 244/1000 
	 loss: 388.3315, MinusLogProbMetric: 388.3315, val_loss: 401.0450, val_MinusLogProbMetric: 401.0450

Epoch 244: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.3315 - MinusLogProbMetric: 388.3315 - val_loss: 401.0450 - val_MinusLogProbMetric: 401.0450 - lr: 1.6667e-04 - 17s/epoch - 87ms/step
Epoch 245/1000
2023-09-10 11:45:47.451 
Epoch 245/1000 
	 loss: 389.2823, MinusLogProbMetric: 389.2823, val_loss: 400.2056, val_MinusLogProbMetric: 400.2056

Epoch 245: val_loss did not improve from 399.62579
196/196 - 16s - loss: 389.2823 - MinusLogProbMetric: 389.2823 - val_loss: 400.2056 - val_MinusLogProbMetric: 400.2056 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 246/1000
2023-09-10 11:46:05.189 
Epoch 246/1000 
	 loss: 388.0122, MinusLogProbMetric: 388.0122, val_loss: 400.1265, val_MinusLogProbMetric: 400.1265

Epoch 246: val_loss did not improve from 399.62579
196/196 - 18s - loss: 388.0122 - MinusLogProbMetric: 388.0122 - val_loss: 400.1265 - val_MinusLogProbMetric: 400.1265 - lr: 1.6667e-04 - 18s/epoch - 90ms/step
Epoch 247/1000
2023-09-10 11:46:21.559 
Epoch 247/1000 
	 loss: 388.8426, MinusLogProbMetric: 388.8426, val_loss: 399.8152, val_MinusLogProbMetric: 399.8152

Epoch 247: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.8426 - MinusLogProbMetric: 388.8426 - val_loss: 399.8152 - val_MinusLogProbMetric: 399.8152 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 248/1000
2023-09-10 11:46:38.149 
Epoch 248/1000 
	 loss: 388.0215, MinusLogProbMetric: 388.0215, val_loss: 400.9783, val_MinusLogProbMetric: 400.9783

Epoch 248: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.0215 - MinusLogProbMetric: 388.0215 - val_loss: 400.9783 - val_MinusLogProbMetric: 400.9783 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 249/1000
2023-09-10 11:46:54.880 
Epoch 249/1000 
	 loss: 388.3342, MinusLogProbMetric: 388.3342, val_loss: 402.0883, val_MinusLogProbMetric: 402.0883

Epoch 249: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.3342 - MinusLogProbMetric: 388.3342 - val_loss: 402.0883 - val_MinusLogProbMetric: 402.0883 - lr: 1.6667e-04 - 17s/epoch - 85ms/step
Epoch 250/1000
2023-09-10 11:47:09.759 
Epoch 250/1000 
	 loss: 387.9351, MinusLogProbMetric: 387.9351, val_loss: 401.9516, val_MinusLogProbMetric: 401.9516

Epoch 250: val_loss did not improve from 399.62579
196/196 - 15s - loss: 387.9351 - MinusLogProbMetric: 387.9351 - val_loss: 401.9516 - val_MinusLogProbMetric: 401.9516 - lr: 1.6667e-04 - 15s/epoch - 76ms/step
Epoch 251/1000
2023-09-10 11:47:26.257 
Epoch 251/1000 
	 loss: 388.2094, MinusLogProbMetric: 388.2094, val_loss: 403.1200, val_MinusLogProbMetric: 403.1200

Epoch 251: val_loss did not improve from 399.62579
196/196 - 16s - loss: 388.2094 - MinusLogProbMetric: 388.2094 - val_loss: 403.1200 - val_MinusLogProbMetric: 403.1200 - lr: 1.6667e-04 - 16s/epoch - 84ms/step
Epoch 252/1000
2023-09-10 11:47:41.442 
Epoch 252/1000 
	 loss: 388.1492, MinusLogProbMetric: 388.1492, val_loss: 401.2868, val_MinusLogProbMetric: 401.2868

Epoch 252: val_loss did not improve from 399.62579
196/196 - 15s - loss: 388.1492 - MinusLogProbMetric: 388.1492 - val_loss: 401.2868 - val_MinusLogProbMetric: 401.2868 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 253/1000
2023-09-10 11:47:57.953 
Epoch 253/1000 
	 loss: 388.1772, MinusLogProbMetric: 388.1772, val_loss: 400.8018, val_MinusLogProbMetric: 400.8018

Epoch 253: val_loss did not improve from 399.62579
196/196 - 17s - loss: 388.1772 - MinusLogProbMetric: 388.1772 - val_loss: 400.8018 - val_MinusLogProbMetric: 400.8018 - lr: 1.6667e-04 - 17s/epoch - 84ms/step
Epoch 254/1000
2023-09-10 11:48:12.746 
Epoch 254/1000 
	 loss: 387.9155, MinusLogProbMetric: 387.9155, val_loss: 403.4298, val_MinusLogProbMetric: 403.4298

Epoch 254: val_loss did not improve from 399.62579
196/196 - 15s - loss: 387.9155 - MinusLogProbMetric: 387.9155 - val_loss: 403.4298 - val_MinusLogProbMetric: 403.4298 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 255/1000
2023-09-10 11:48:27.108 
Epoch 255/1000 
	 loss: 388.0505, MinusLogProbMetric: 388.0505, val_loss: 402.2278, val_MinusLogProbMetric: 402.2278

Epoch 255: val_loss did not improve from 399.62579
196/196 - 14s - loss: 388.0505 - MinusLogProbMetric: 388.0505 - val_loss: 402.2278 - val_MinusLogProbMetric: 402.2278 - lr: 1.6667e-04 - 14s/epoch - 73ms/step
Epoch 256/1000
2023-09-10 11:48:42.186 
Epoch 256/1000 
	 loss: 387.8350, MinusLogProbMetric: 387.8350, val_loss: 401.1698, val_MinusLogProbMetric: 401.1698

Epoch 256: val_loss did not improve from 399.62579
196/196 - 15s - loss: 387.8350 - MinusLogProbMetric: 387.8350 - val_loss: 401.1698 - val_MinusLogProbMetric: 401.1698 - lr: 1.6667e-04 - 15s/epoch - 77ms/step
Epoch 257/1000
2023-09-10 11:48:58.517 
Epoch 257/1000 
	 loss: 384.9505, MinusLogProbMetric: 384.9505, val_loss: 398.7796, val_MinusLogProbMetric: 398.7796

Epoch 257: val_loss improved from 399.62579 to 398.77960, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 17s - loss: 384.9505 - MinusLogProbMetric: 384.9505 - val_loss: 398.7796 - val_MinusLogProbMetric: 398.7796 - lr: 8.3333e-05 - 17s/epoch - 86ms/step
Epoch 258/1000
2023-09-10 11:49:14.844 
Epoch 258/1000 
	 loss: 384.7485, MinusLogProbMetric: 384.7485, val_loss: 399.4442, val_MinusLogProbMetric: 399.4442

Epoch 258: val_loss did not improve from 398.77960
196/196 - 16s - loss: 384.7485 - MinusLogProbMetric: 384.7485 - val_loss: 399.4442 - val_MinusLogProbMetric: 399.4442 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 259/1000
2023-09-10 11:49:30.692 
Epoch 259/1000 
	 loss: 384.8766, MinusLogProbMetric: 384.8766, val_loss: 398.8881, val_MinusLogProbMetric: 398.8881

Epoch 259: val_loss did not improve from 398.77960
196/196 - 16s - loss: 384.8766 - MinusLogProbMetric: 384.8766 - val_loss: 398.8881 - val_MinusLogProbMetric: 398.8881 - lr: 8.3333e-05 - 16s/epoch - 81ms/step
Epoch 260/1000
2023-09-10 11:49:47.976 
Epoch 260/1000 
	 loss: 384.9382, MinusLogProbMetric: 384.9382, val_loss: 399.0319, val_MinusLogProbMetric: 399.0319

Epoch 260: val_loss did not improve from 398.77960
196/196 - 17s - loss: 384.9382 - MinusLogProbMetric: 384.9382 - val_loss: 399.0319 - val_MinusLogProbMetric: 399.0319 - lr: 8.3333e-05 - 17s/epoch - 88ms/step
Epoch 261/1000
2023-09-10 11:50:03.722 
Epoch 261/1000 
	 loss: 385.0334, MinusLogProbMetric: 385.0334, val_loss: 399.1379, val_MinusLogProbMetric: 399.1379

Epoch 261: val_loss did not improve from 398.77960
196/196 - 16s - loss: 385.0334 - MinusLogProbMetric: 385.0334 - val_loss: 399.1379 - val_MinusLogProbMetric: 399.1379 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 262/1000
2023-09-10 11:50:19.511 
Epoch 262/1000 
	 loss: 384.9879, MinusLogProbMetric: 384.9879, val_loss: 399.5782, val_MinusLogProbMetric: 399.5782

Epoch 262: val_loss did not improve from 398.77960
196/196 - 16s - loss: 384.9879 - MinusLogProbMetric: 384.9879 - val_loss: 399.5782 - val_MinusLogProbMetric: 399.5782 - lr: 8.3333e-05 - 16s/epoch - 81ms/step
Epoch 263/1000
2023-09-10 11:50:34.529 
Epoch 263/1000 
	 loss: 384.9563, MinusLogProbMetric: 384.9563, val_loss: 399.1725, val_MinusLogProbMetric: 399.1725

Epoch 263: val_loss did not improve from 398.77960
196/196 - 15s - loss: 384.9563 - MinusLogProbMetric: 384.9563 - val_loss: 399.1725 - val_MinusLogProbMetric: 399.1725 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 264/1000
2023-09-10 11:50:52.250 
Epoch 264/1000 
	 loss: 385.0754, MinusLogProbMetric: 385.0754, val_loss: 400.0720, val_MinusLogProbMetric: 400.0720

Epoch 264: val_loss did not improve from 398.77960
196/196 - 18s - loss: 385.0754 - MinusLogProbMetric: 385.0754 - val_loss: 400.0720 - val_MinusLogProbMetric: 400.0720 - lr: 8.3333e-05 - 18s/epoch - 90ms/step
Epoch 265/1000
2023-09-10 11:51:07.149 
Epoch 265/1000 
	 loss: 385.1743, MinusLogProbMetric: 385.1743, val_loss: 399.2575, val_MinusLogProbMetric: 399.2575

Epoch 265: val_loss did not improve from 398.77960
196/196 - 15s - loss: 385.1743 - MinusLogProbMetric: 385.1743 - val_loss: 399.2575 - val_MinusLogProbMetric: 399.2575 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 266/1000
2023-09-10 11:51:21.703 
Epoch 266/1000 
	 loss: 384.7947, MinusLogProbMetric: 384.7947, val_loss: 399.1469, val_MinusLogProbMetric: 399.1469

Epoch 266: val_loss did not improve from 398.77960
196/196 - 15s - loss: 384.7947 - MinusLogProbMetric: 384.7947 - val_loss: 399.1469 - val_MinusLogProbMetric: 399.1469 - lr: 8.3333e-05 - 15s/epoch - 74ms/step
Epoch 267/1000
2023-09-10 11:51:35.560 
Epoch 267/1000 
	 loss: 384.9060, MinusLogProbMetric: 384.9060, val_loss: 399.4661, val_MinusLogProbMetric: 399.4661

Epoch 267: val_loss did not improve from 398.77960
196/196 - 14s - loss: 384.9060 - MinusLogProbMetric: 384.9060 - val_loss: 399.4661 - val_MinusLogProbMetric: 399.4661 - lr: 8.3333e-05 - 14s/epoch - 71ms/step
Epoch 268/1000
2023-09-10 11:51:49.539 
Epoch 268/1000 
	 loss: 385.0667, MinusLogProbMetric: 385.0667, val_loss: 398.9462, val_MinusLogProbMetric: 398.9462

Epoch 268: val_loss did not improve from 398.77960
196/196 - 14s - loss: 385.0667 - MinusLogProbMetric: 385.0667 - val_loss: 398.9462 - val_MinusLogProbMetric: 398.9462 - lr: 8.3333e-05 - 14s/epoch - 71ms/step
Epoch 269/1000
2023-09-10 11:52:04.399 
Epoch 269/1000 
	 loss: 384.7561, MinusLogProbMetric: 384.7561, val_loss: 398.6030, val_MinusLogProbMetric: 398.6030

Epoch 269: val_loss improved from 398.77960 to 398.60297, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_336/weights/best_weights.h5
196/196 - 15s - loss: 384.7561 - MinusLogProbMetric: 384.7561 - val_loss: 398.6030 - val_MinusLogProbMetric: 398.6030 - lr: 8.3333e-05 - 15s/epoch - 79ms/step
Epoch 270/1000
2023-09-10 11:52:19.134 
Epoch 270/1000 
	 loss: 384.9852, MinusLogProbMetric: 384.9852, val_loss: 398.7943, val_MinusLogProbMetric: 398.7943

Epoch 270: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.9852 - MinusLogProbMetric: 384.9852 - val_loss: 398.7943 - val_MinusLogProbMetric: 398.7943 - lr: 8.3333e-05 - 14s/epoch - 72ms/step
Epoch 271/1000
2023-09-10 11:52:33.497 
Epoch 271/1000 
	 loss: 384.9937, MinusLogProbMetric: 384.9937, val_loss: 400.1094, val_MinusLogProbMetric: 400.1094

Epoch 271: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.9937 - MinusLogProbMetric: 384.9937 - val_loss: 400.1094 - val_MinusLogProbMetric: 400.1094 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 272/1000
2023-09-10 11:52:48.734 
Epoch 272/1000 
	 loss: 385.0188, MinusLogProbMetric: 385.0188, val_loss: 399.5982, val_MinusLogProbMetric: 399.5982

Epoch 272: val_loss did not improve from 398.60297
196/196 - 15s - loss: 385.0188 - MinusLogProbMetric: 385.0188 - val_loss: 399.5982 - val_MinusLogProbMetric: 399.5982 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 273/1000
2023-09-10 11:53:04.505 
Epoch 273/1000 
	 loss: 384.8037, MinusLogProbMetric: 384.8037, val_loss: 399.1885, val_MinusLogProbMetric: 399.1885

Epoch 273: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.8037 - MinusLogProbMetric: 384.8037 - val_loss: 399.1885 - val_MinusLogProbMetric: 399.1885 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 274/1000
2023-09-10 11:53:20.953 
Epoch 274/1000 
	 loss: 384.7739, MinusLogProbMetric: 384.7739, val_loss: 399.1957, val_MinusLogProbMetric: 399.1957

Epoch 274: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.7739 - MinusLogProbMetric: 384.7739 - val_loss: 399.1957 - val_MinusLogProbMetric: 399.1957 - lr: 8.3333e-05 - 16s/epoch - 84ms/step
Epoch 275/1000
2023-09-10 11:53:35.407 
Epoch 275/1000 
	 loss: 384.8976, MinusLogProbMetric: 384.8976, val_loss: 399.1164, val_MinusLogProbMetric: 399.1164

Epoch 275: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.8976 - MinusLogProbMetric: 384.8976 - val_loss: 399.1164 - val_MinusLogProbMetric: 399.1164 - lr: 8.3333e-05 - 14s/epoch - 74ms/step
Epoch 276/1000
2023-09-10 11:53:49.534 
Epoch 276/1000 
	 loss: 384.6594, MinusLogProbMetric: 384.6594, val_loss: 398.9331, val_MinusLogProbMetric: 398.9331

Epoch 276: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.6594 - MinusLogProbMetric: 384.6594 - val_loss: 398.9331 - val_MinusLogProbMetric: 398.9331 - lr: 8.3333e-05 - 14s/epoch - 72ms/step
Epoch 277/1000
2023-09-10 11:54:04.747 
Epoch 277/1000 
	 loss: 384.8239, MinusLogProbMetric: 384.8239, val_loss: 400.7328, val_MinusLogProbMetric: 400.7328

Epoch 277: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.8239 - MinusLogProbMetric: 384.8239 - val_loss: 400.7328 - val_MinusLogProbMetric: 400.7328 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 278/1000
2023-09-10 11:54:19.012 
Epoch 278/1000 
	 loss: 384.8366, MinusLogProbMetric: 384.8366, val_loss: 400.1768, val_MinusLogProbMetric: 400.1768

Epoch 278: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.8366 - MinusLogProbMetric: 384.8366 - val_loss: 400.1768 - val_MinusLogProbMetric: 400.1768 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 279/1000
2023-09-10 11:54:34.054 
Epoch 279/1000 
	 loss: 384.9238, MinusLogProbMetric: 384.9238, val_loss: 401.9971, val_MinusLogProbMetric: 401.9971

Epoch 279: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.9238 - MinusLogProbMetric: 384.9238 - val_loss: 401.9971 - val_MinusLogProbMetric: 401.9971 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 280/1000
2023-09-10 11:54:49.462 
Epoch 280/1000 
	 loss: 385.1230, MinusLogProbMetric: 385.1230, val_loss: 399.7282, val_MinusLogProbMetric: 399.7282

Epoch 280: val_loss did not improve from 398.60297
196/196 - 15s - loss: 385.1230 - MinusLogProbMetric: 385.1230 - val_loss: 399.7282 - val_MinusLogProbMetric: 399.7282 - lr: 8.3333e-05 - 15s/epoch - 79ms/step
Epoch 281/1000
2023-09-10 11:55:03.469 
Epoch 281/1000 
	 loss: 384.6731, MinusLogProbMetric: 384.6731, val_loss: 399.7626, val_MinusLogProbMetric: 399.7626

Epoch 281: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.6731 - MinusLogProbMetric: 384.6731 - val_loss: 399.7626 - val_MinusLogProbMetric: 399.7626 - lr: 8.3333e-05 - 14s/epoch - 71ms/step
Epoch 282/1000
2023-09-10 11:55:19.856 
Epoch 282/1000 
	 loss: 384.7507, MinusLogProbMetric: 384.7507, val_loss: 399.8091, val_MinusLogProbMetric: 399.8091

Epoch 282: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.7507 - MinusLogProbMetric: 384.7507 - val_loss: 399.8091 - val_MinusLogProbMetric: 399.8091 - lr: 8.3333e-05 - 16s/epoch - 83ms/step
Epoch 283/1000
2023-09-10 11:55:37.001 
Epoch 283/1000 
	 loss: 384.6881, MinusLogProbMetric: 384.6881, val_loss: 399.9711, val_MinusLogProbMetric: 399.9711

Epoch 283: val_loss did not improve from 398.60297
196/196 - 17s - loss: 384.6881 - MinusLogProbMetric: 384.6881 - val_loss: 399.9711 - val_MinusLogProbMetric: 399.9711 - lr: 8.3333e-05 - 17s/epoch - 87ms/step
Epoch 284/1000
2023-09-10 11:55:52.753 
Epoch 284/1000 
	 loss: 384.6689, MinusLogProbMetric: 384.6689, val_loss: 399.0505, val_MinusLogProbMetric: 399.0505

Epoch 284: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.6689 - MinusLogProbMetric: 384.6689 - val_loss: 399.0505 - val_MinusLogProbMetric: 399.0505 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 285/1000
2023-09-10 11:56:08.047 
Epoch 285/1000 
	 loss: 384.5370, MinusLogProbMetric: 384.5370, val_loss: 400.8446, val_MinusLogProbMetric: 400.8446

Epoch 285: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.5370 - MinusLogProbMetric: 384.5370 - val_loss: 400.8446 - val_MinusLogProbMetric: 400.8446 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 286/1000
2023-09-10 11:56:23.755 
Epoch 286/1000 
	 loss: 384.7144, MinusLogProbMetric: 384.7144, val_loss: 399.6019, val_MinusLogProbMetric: 399.6019

Epoch 286: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.7144 - MinusLogProbMetric: 384.7144 - val_loss: 399.6019 - val_MinusLogProbMetric: 399.6019 - lr: 8.3333e-05 - 16s/epoch - 80ms/step
Epoch 287/1000
2023-09-10 11:56:39.656 
Epoch 287/1000 
	 loss: 384.6760, MinusLogProbMetric: 384.6760, val_loss: 399.5100, val_MinusLogProbMetric: 399.5100

Epoch 287: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.6760 - MinusLogProbMetric: 384.6760 - val_loss: 399.5100 - val_MinusLogProbMetric: 399.5100 - lr: 8.3333e-05 - 16s/epoch - 81ms/step
Epoch 288/1000
2023-09-10 11:56:54.959 
Epoch 288/1000 
	 loss: 384.6703, MinusLogProbMetric: 384.6703, val_loss: 399.3724, val_MinusLogProbMetric: 399.3724

Epoch 288: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.6703 - MinusLogProbMetric: 384.6703 - val_loss: 399.3724 - val_MinusLogProbMetric: 399.3724 - lr: 8.3333e-05 - 15s/epoch - 78ms/step
Epoch 289/1000
2023-09-10 11:57:09.993 
Epoch 289/1000 
	 loss: 384.6235, MinusLogProbMetric: 384.6235, val_loss: 399.6637, val_MinusLogProbMetric: 399.6637

Epoch 289: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.6235 - MinusLogProbMetric: 384.6235 - val_loss: 399.6637 - val_MinusLogProbMetric: 399.6637 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 290/1000
2023-09-10 11:57:24.895 
Epoch 290/1000 
	 loss: 384.6805, MinusLogProbMetric: 384.6805, val_loss: 400.0610, val_MinusLogProbMetric: 400.0610

Epoch 290: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.6805 - MinusLogProbMetric: 384.6805 - val_loss: 400.0610 - val_MinusLogProbMetric: 400.0610 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 291/1000
2023-09-10 11:57:38.871 
Epoch 291/1000 
	 loss: 384.6478, MinusLogProbMetric: 384.6478, val_loss: 399.5573, val_MinusLogProbMetric: 399.5573

Epoch 291: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.6478 - MinusLogProbMetric: 384.6478 - val_loss: 399.5573 - val_MinusLogProbMetric: 399.5573 - lr: 8.3333e-05 - 14s/epoch - 71ms/step
Epoch 292/1000
2023-09-10 11:57:53.172 
Epoch 292/1000 
	 loss: 384.8167, MinusLogProbMetric: 384.8167, val_loss: 399.8086, val_MinusLogProbMetric: 399.8086

Epoch 292: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.8167 - MinusLogProbMetric: 384.8167 - val_loss: 399.8086 - val_MinusLogProbMetric: 399.8086 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 293/1000
2023-09-10 11:58:08.303 
Epoch 293/1000 
	 loss: 384.5480, MinusLogProbMetric: 384.5480, val_loss: 399.7550, val_MinusLogProbMetric: 399.7550

Epoch 293: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.5480 - MinusLogProbMetric: 384.5480 - val_loss: 399.7550 - val_MinusLogProbMetric: 399.7550 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 294/1000
2023-09-10 11:58:23.023 
Epoch 294/1000 
	 loss: 384.4906, MinusLogProbMetric: 384.4906, val_loss: 399.6277, val_MinusLogProbMetric: 399.6277

Epoch 294: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.4906 - MinusLogProbMetric: 384.4906 - val_loss: 399.6277 - val_MinusLogProbMetric: 399.6277 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 295/1000
2023-09-10 11:58:37.616 
Epoch 295/1000 
	 loss: 384.6511, MinusLogProbMetric: 384.6511, val_loss: 399.6697, val_MinusLogProbMetric: 399.6697

Epoch 295: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.6511 - MinusLogProbMetric: 384.6511 - val_loss: 399.6697 - val_MinusLogProbMetric: 399.6697 - lr: 8.3333e-05 - 15s/epoch - 74ms/step
Epoch 296/1000
2023-09-10 11:58:51.849 
Epoch 296/1000 
	 loss: 384.5222, MinusLogProbMetric: 384.5222, val_loss: 400.1631, val_MinusLogProbMetric: 400.1631

Epoch 296: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.5222 - MinusLogProbMetric: 384.5222 - val_loss: 400.1631 - val_MinusLogProbMetric: 400.1631 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 297/1000
2023-09-10 11:59:07.864 
Epoch 297/1000 
	 loss: 384.5911, MinusLogProbMetric: 384.5911, val_loss: 400.2579, val_MinusLogProbMetric: 400.2579

Epoch 297: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.5911 - MinusLogProbMetric: 384.5911 - val_loss: 400.2579 - val_MinusLogProbMetric: 400.2579 - lr: 8.3333e-05 - 16s/epoch - 82ms/step
Epoch 298/1000
2023-09-10 11:59:24.709 
Epoch 298/1000 
	 loss: 384.5575, MinusLogProbMetric: 384.5575, val_loss: 399.6378, val_MinusLogProbMetric: 399.6378

Epoch 298: val_loss did not improve from 398.60297
196/196 - 17s - loss: 384.5575 - MinusLogProbMetric: 384.5575 - val_loss: 399.6378 - val_MinusLogProbMetric: 399.6378 - lr: 8.3333e-05 - 17s/epoch - 86ms/step
Epoch 299/1000
2023-09-10 11:59:39.701 
Epoch 299/1000 
	 loss: 384.9357, MinusLogProbMetric: 384.9357, val_loss: 400.0235, val_MinusLogProbMetric: 400.0235

Epoch 299: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.9357 - MinusLogProbMetric: 384.9357 - val_loss: 400.0235 - val_MinusLogProbMetric: 400.0235 - lr: 8.3333e-05 - 15s/epoch - 77ms/step
Epoch 300/1000
2023-09-10 11:59:55.639 
Epoch 300/1000 
	 loss: 384.2841, MinusLogProbMetric: 384.2841, val_loss: 400.7551, val_MinusLogProbMetric: 400.7551

Epoch 300: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.2841 - MinusLogProbMetric: 384.2841 - val_loss: 400.7551 - val_MinusLogProbMetric: 400.7551 - lr: 8.3333e-05 - 16s/epoch - 81ms/step
Epoch 301/1000
2023-09-10 12:00:11.224 
Epoch 301/1000 
	 loss: 384.7177, MinusLogProbMetric: 384.7177, val_loss: 400.9276, val_MinusLogProbMetric: 400.9276

Epoch 301: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.7177 - MinusLogProbMetric: 384.7177 - val_loss: 400.9276 - val_MinusLogProbMetric: 400.9276 - lr: 8.3333e-05 - 16s/epoch - 79ms/step
Epoch 302/1000
2023-09-10 12:00:25.976 
Epoch 302/1000 
	 loss: 384.5875, MinusLogProbMetric: 384.5875, val_loss: 402.5328, val_MinusLogProbMetric: 402.5328

Epoch 302: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.5875 - MinusLogProbMetric: 384.5875 - val_loss: 402.5328 - val_MinusLogProbMetric: 402.5328 - lr: 8.3333e-05 - 15s/epoch - 75ms/step
Epoch 303/1000
2023-09-10 12:00:40.829 
Epoch 303/1000 
	 loss: 384.4762, MinusLogProbMetric: 384.4762, val_loss: 401.0964, val_MinusLogProbMetric: 401.0964

Epoch 303: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.4762 - MinusLogProbMetric: 384.4762 - val_loss: 401.0964 - val_MinusLogProbMetric: 401.0964 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 304/1000
2023-09-10 12:00:56.329 
Epoch 304/1000 
	 loss: 384.5580, MinusLogProbMetric: 384.5580, val_loss: 400.1307, val_MinusLogProbMetric: 400.1307

Epoch 304: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.5580 - MinusLogProbMetric: 384.5580 - val_loss: 400.1307 - val_MinusLogProbMetric: 400.1307 - lr: 8.3333e-05 - 15s/epoch - 79ms/step
Epoch 305/1000
2023-09-10 12:01:10.564 
Epoch 305/1000 
	 loss: 384.3858, MinusLogProbMetric: 384.3858, val_loss: 399.8794, val_MinusLogProbMetric: 399.8794

Epoch 305: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.3858 - MinusLogProbMetric: 384.3858 - val_loss: 399.8794 - val_MinusLogProbMetric: 399.8794 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 306/1000
2023-09-10 12:01:25.979 
Epoch 306/1000 
	 loss: 384.5403, MinusLogProbMetric: 384.5403, val_loss: 401.2744, val_MinusLogProbMetric: 401.2744

Epoch 306: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.5403 - MinusLogProbMetric: 384.5403 - val_loss: 401.2744 - val_MinusLogProbMetric: 401.2744 - lr: 8.3333e-05 - 15s/epoch - 79ms/step
Epoch 307/1000
2023-09-10 12:01:40.122 
Epoch 307/1000 
	 loss: 384.7712, MinusLogProbMetric: 384.7712, val_loss: 400.0443, val_MinusLogProbMetric: 400.0443

Epoch 307: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.7712 - MinusLogProbMetric: 384.7712 - val_loss: 400.0443 - val_MinusLogProbMetric: 400.0443 - lr: 8.3333e-05 - 14s/epoch - 72ms/step
Epoch 308/1000
2023-09-10 12:01:54.949 
Epoch 308/1000 
	 loss: 384.4852, MinusLogProbMetric: 384.4852, val_loss: 400.2376, val_MinusLogProbMetric: 400.2376

Epoch 308: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.4852 - MinusLogProbMetric: 384.4852 - val_loss: 400.2376 - val_MinusLogProbMetric: 400.2376 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 309/1000
2023-09-10 12:02:11.163 
Epoch 309/1000 
	 loss: 384.4768, MinusLogProbMetric: 384.4768, val_loss: 401.2490, val_MinusLogProbMetric: 401.2490

Epoch 309: val_loss did not improve from 398.60297
196/196 - 16s - loss: 384.4768 - MinusLogProbMetric: 384.4768 - val_loss: 401.2490 - val_MinusLogProbMetric: 401.2490 - lr: 8.3333e-05 - 16s/epoch - 83ms/step
Epoch 310/1000
2023-09-10 12:02:26.062 
Epoch 310/1000 
	 loss: 384.3701, MinusLogProbMetric: 384.3701, val_loss: 400.4891, val_MinusLogProbMetric: 400.4891

Epoch 310: val_loss did not improve from 398.60297
196/196 - 15s - loss: 384.3701 - MinusLogProbMetric: 384.3701 - val_loss: 400.4891 - val_MinusLogProbMetric: 400.4891 - lr: 8.3333e-05 - 15s/epoch - 76ms/step
Epoch 311/1000
2023-09-10 12:02:40.406 
Epoch 311/1000 
	 loss: 384.5033, MinusLogProbMetric: 384.5033, val_loss: 401.0240, val_MinusLogProbMetric: 401.0240

Epoch 311: val_loss did not improve from 398.60297
196/196 - 14s - loss: 384.5033 - MinusLogProbMetric: 384.5033 - val_loss: 401.0240 - val_MinusLogProbMetric: 401.0240 - lr: 8.3333e-05 - 14s/epoch - 73ms/step
Epoch 312/1000
2023-09-10 12:02:50.447 
Epoch 312/1000 
	 loss: 384.5265, MinusLogProbMetric: 384.5265, val_loss: 400.0391, val_MinusLogProbMetric: 400.0391

Epoch 312: val_loss did not improve from 398.60297
196/196 - 10s - loss: 384.5265 - MinusLogProbMetric: 384.5265 - val_loss: 400.0391 - val_MinusLogProbMetric: 400.0391 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 313/1000
2023-09-10 12:03:07.421 
Epoch 313/1000 
	 loss: 384.4212, MinusLogProbMetric: 384.4212, val_loss: 401.5078, val_MinusLogProbMetric: 401.5078

Epoch 313: val_loss did not improve from 398.60297
196/196 - 17s - loss: 384.4212 - MinusLogProbMetric: 384.4212 - val_loss: 401.5078 - val_MinusLogProbMetric: 401.5078 - lr: 8.3333e-05 - 17s/epoch - 87ms/step
Epoch 314/1000
2023-09-10 12:03:30.291 
Epoch 314/1000 
	 loss: 384.3252, MinusLogProbMetric: 384.3252, val_loss: 400.4328, val_MinusLogProbMetric: 400.4328

Epoch 314: val_loss did not improve from 398.60297
196/196 - 23s - loss: 384.3252 - MinusLogProbMetric: 384.3252 - val_loss: 400.4328 - val_MinusLogProbMetric: 400.4328 - lr: 8.3333e-05 - 23s/epoch - 117ms/step
Epoch 315/1000
2023-09-10 12:03:54.237 
Epoch 315/1000 
	 loss: 384.4784, MinusLogProbMetric: 384.4784, val_loss: 400.6100, val_MinusLogProbMetric: 400.6100

Epoch 315: val_loss did not improve from 398.60297
196/196 - 24s - loss: 384.4784 - MinusLogProbMetric: 384.4784 - val_loss: 400.6100 - val_MinusLogProbMetric: 400.6100 - lr: 8.3333e-05 - 24s/epoch - 122ms/step
Epoch 316/1000
2023-09-10 12:04:17.119 
Epoch 316/1000 
	 loss: 384.5116, MinusLogProbMetric: 384.5116, val_loss: 401.3524, val_MinusLogProbMetric: 401.3524

Epoch 316: val_loss did not improve from 398.60297
196/196 - 23s - loss: 384.5116 - MinusLogProbMetric: 384.5116 - val_loss: 401.3524 - val_MinusLogProbMetric: 401.3524 - lr: 8.3333e-05 - 23s/epoch - 117ms/step
Epoch 317/1000
2023-09-10 12:04:39.714 
Epoch 317/1000 
	 loss: 385.1446, MinusLogProbMetric: 385.1446, val_loss: 400.3620, val_MinusLogProbMetric: 400.3620

Epoch 317: val_loss did not improve from 398.60297
196/196 - 23s - loss: 385.1446 - MinusLogProbMetric: 385.1446 - val_loss: 400.3620 - val_MinusLogProbMetric: 400.3620 - lr: 8.3333e-05 - 23s/epoch - 115ms/step
Epoch 318/1000
2023-09-10 12:05:03.166 
Epoch 318/1000 
	 loss: 384.2581, MinusLogProbMetric: 384.2581, val_loss: 400.2513, val_MinusLogProbMetric: 400.2513

Epoch 318: val_loss did not improve from 398.60297
196/196 - 23s - loss: 384.2581 - MinusLogProbMetric: 384.2581 - val_loss: 400.2513 - val_MinusLogProbMetric: 400.2513 - lr: 8.3333e-05 - 23s/epoch - 120ms/step
Epoch 319/1000
2023-09-10 12:05:27.450 
Epoch 319/1000 
	 loss: 384.1927, MinusLogProbMetric: 384.1927, val_loss: 401.1685, val_MinusLogProbMetric: 401.1685

Epoch 319: val_loss did not improve from 398.60297
196/196 - 24s - loss: 384.1927 - MinusLogProbMetric: 384.1927 - val_loss: 401.1685 - val_MinusLogProbMetric: 401.1685 - lr: 8.3333e-05 - 24s/epoch - 124ms/step
Epoch 320/1000
2023-09-10 12:05:50.966 
Epoch 320/1000 
	 loss: 382.8351, MinusLogProbMetric: 382.8351, val_loss: 400.0864, val_MinusLogProbMetric: 400.0864

Epoch 320: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.8351 - MinusLogProbMetric: 382.8351 - val_loss: 400.0864 - val_MinusLogProbMetric: 400.0864 - lr: 4.1667e-05 - 24s/epoch - 120ms/step
Epoch 321/1000
2023-09-10 12:06:12.568 
Epoch 321/1000 
	 loss: 382.7153, MinusLogProbMetric: 382.7153, val_loss: 400.1155, val_MinusLogProbMetric: 400.1155

Epoch 321: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.7153 - MinusLogProbMetric: 382.7153 - val_loss: 400.1155 - val_MinusLogProbMetric: 400.1155 - lr: 4.1667e-05 - 22s/epoch - 110ms/step
Epoch 322/1000
2023-09-10 12:06:35.249 
Epoch 322/1000 
	 loss: 382.7386, MinusLogProbMetric: 382.7386, val_loss: 400.5922, val_MinusLogProbMetric: 400.5922

Epoch 322: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.7386 - MinusLogProbMetric: 382.7386 - val_loss: 400.5922 - val_MinusLogProbMetric: 400.5922 - lr: 4.1667e-05 - 23s/epoch - 116ms/step
Epoch 323/1000
2023-09-10 12:06:57.190 
Epoch 323/1000 
	 loss: 382.7173, MinusLogProbMetric: 382.7173, val_loss: 400.5104, val_MinusLogProbMetric: 400.5104

Epoch 323: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.7173 - MinusLogProbMetric: 382.7173 - val_loss: 400.5104 - val_MinusLogProbMetric: 400.5104 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 324/1000
2023-09-10 12:07:20.989 
Epoch 324/1000 
	 loss: 382.7025, MinusLogProbMetric: 382.7025, val_loss: 400.3062, val_MinusLogProbMetric: 400.3062

Epoch 324: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.7025 - MinusLogProbMetric: 382.7025 - val_loss: 400.3062 - val_MinusLogProbMetric: 400.3062 - lr: 4.1667e-05 - 24s/epoch - 121ms/step
Epoch 325/1000
2023-09-10 12:07:44.775 
Epoch 325/1000 
	 loss: 382.6408, MinusLogProbMetric: 382.6408, val_loss: 400.3549, val_MinusLogProbMetric: 400.3549

Epoch 325: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.6408 - MinusLogProbMetric: 382.6408 - val_loss: 400.3549 - val_MinusLogProbMetric: 400.3549 - lr: 4.1667e-05 - 24s/epoch - 121ms/step
Epoch 326/1000
2023-09-10 12:08:05.222 
Epoch 326/1000 
	 loss: 382.6640, MinusLogProbMetric: 382.6640, val_loss: 400.5559, val_MinusLogProbMetric: 400.5559

Epoch 326: val_loss did not improve from 398.60297
196/196 - 20s - loss: 382.6640 - MinusLogProbMetric: 382.6640 - val_loss: 400.5559 - val_MinusLogProbMetric: 400.5559 - lr: 4.1667e-05 - 20s/epoch - 104ms/step
Epoch 327/1000
2023-09-10 12:08:29.023 
Epoch 327/1000 
	 loss: 382.6584, MinusLogProbMetric: 382.6584, val_loss: 400.5712, val_MinusLogProbMetric: 400.5712

Epoch 327: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.6584 - MinusLogProbMetric: 382.6584 - val_loss: 400.5712 - val_MinusLogProbMetric: 400.5712 - lr: 4.1667e-05 - 24s/epoch - 121ms/step
Epoch 328/1000
2023-09-10 12:08:53.070 
Epoch 328/1000 
	 loss: 382.6404, MinusLogProbMetric: 382.6404, val_loss: 400.6540, val_MinusLogProbMetric: 400.6540

Epoch 328: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.6404 - MinusLogProbMetric: 382.6404 - val_loss: 400.6540 - val_MinusLogProbMetric: 400.6540 - lr: 4.1667e-05 - 24s/epoch - 123ms/step
Epoch 329/1000
2023-09-10 12:09:18.007 
Epoch 329/1000 
	 loss: 382.7114, MinusLogProbMetric: 382.7114, val_loss: 401.0955, val_MinusLogProbMetric: 401.0955

Epoch 329: val_loss did not improve from 398.60297
196/196 - 25s - loss: 382.7114 - MinusLogProbMetric: 382.7114 - val_loss: 401.0955 - val_MinusLogProbMetric: 401.0955 - lr: 4.1667e-05 - 25s/epoch - 127ms/step
Epoch 330/1000
2023-09-10 12:09:41.486 
Epoch 330/1000 
	 loss: 382.6633, MinusLogProbMetric: 382.6633, val_loss: 401.0816, val_MinusLogProbMetric: 401.0816

Epoch 330: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.6633 - MinusLogProbMetric: 382.6633 - val_loss: 401.0816 - val_MinusLogProbMetric: 401.0816 - lr: 4.1667e-05 - 23s/epoch - 120ms/step
Epoch 331/1000
2023-09-10 12:10:04.445 
Epoch 331/1000 
	 loss: 382.9739, MinusLogProbMetric: 382.9739, val_loss: 400.8620, val_MinusLogProbMetric: 400.8620

Epoch 331: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.9739 - MinusLogProbMetric: 382.9739 - val_loss: 400.8620 - val_MinusLogProbMetric: 400.8620 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 332/1000
2023-09-10 12:10:26.600 
Epoch 332/1000 
	 loss: 382.8690, MinusLogProbMetric: 382.8690, val_loss: 401.0617, val_MinusLogProbMetric: 401.0617

Epoch 332: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.8690 - MinusLogProbMetric: 382.8690 - val_loss: 401.0617 - val_MinusLogProbMetric: 401.0617 - lr: 4.1667e-05 - 22s/epoch - 113ms/step
Epoch 333/1000
2023-09-10 12:10:48.184 
Epoch 333/1000 
	 loss: 382.7793, MinusLogProbMetric: 382.7793, val_loss: 400.8828, val_MinusLogProbMetric: 400.8828

Epoch 333: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.7793 - MinusLogProbMetric: 382.7793 - val_loss: 400.8828 - val_MinusLogProbMetric: 400.8828 - lr: 4.1667e-05 - 22s/epoch - 110ms/step
Epoch 334/1000
2023-09-10 12:11:10.538 
Epoch 334/1000 
	 loss: 382.8000, MinusLogProbMetric: 382.8000, val_loss: 401.0959, val_MinusLogProbMetric: 401.0959

Epoch 334: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.8000 - MinusLogProbMetric: 382.8000 - val_loss: 401.0959 - val_MinusLogProbMetric: 401.0959 - lr: 4.1667e-05 - 22s/epoch - 114ms/step
Epoch 335/1000
2023-09-10 12:11:34.195 
Epoch 335/1000 
	 loss: 382.6788, MinusLogProbMetric: 382.6788, val_loss: 401.0304, val_MinusLogProbMetric: 401.0304

Epoch 335: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.6788 - MinusLogProbMetric: 382.6788 - val_loss: 401.0304 - val_MinusLogProbMetric: 401.0304 - lr: 4.1667e-05 - 24s/epoch - 121ms/step
Epoch 336/1000
2023-09-10 12:11:56.756 
Epoch 336/1000 
	 loss: 382.6386, MinusLogProbMetric: 382.6386, val_loss: 401.0614, val_MinusLogProbMetric: 401.0614

Epoch 336: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.6386 - MinusLogProbMetric: 382.6386 - val_loss: 401.0614 - val_MinusLogProbMetric: 401.0614 - lr: 4.1667e-05 - 23s/epoch - 115ms/step
Epoch 337/1000
2023-09-10 12:12:18.724 
Epoch 337/1000 
	 loss: 382.5902, MinusLogProbMetric: 382.5902, val_loss: 401.0572, val_MinusLogProbMetric: 401.0572

Epoch 337: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.5902 - MinusLogProbMetric: 382.5902 - val_loss: 401.0572 - val_MinusLogProbMetric: 401.0572 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 338/1000
2023-09-10 12:12:39.363 
Epoch 338/1000 
	 loss: 382.5728, MinusLogProbMetric: 382.5728, val_loss: 401.0838, val_MinusLogProbMetric: 401.0838

Epoch 338: val_loss did not improve from 398.60297
196/196 - 21s - loss: 382.5728 - MinusLogProbMetric: 382.5728 - val_loss: 401.0838 - val_MinusLogProbMetric: 401.0838 - lr: 4.1667e-05 - 21s/epoch - 105ms/step
Epoch 339/1000
2023-09-10 12:13:02.244 
Epoch 339/1000 
	 loss: 382.7178, MinusLogProbMetric: 382.7178, val_loss: 402.3590, val_MinusLogProbMetric: 402.3590

Epoch 339: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.7178 - MinusLogProbMetric: 382.7178 - val_loss: 402.3590 - val_MinusLogProbMetric: 402.3590 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 340/1000
2023-09-10 12:13:23.819 
Epoch 340/1000 
	 loss: 382.7240, MinusLogProbMetric: 382.7240, val_loss: 401.1161, val_MinusLogProbMetric: 401.1161

Epoch 340: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.7240 - MinusLogProbMetric: 382.7240 - val_loss: 401.1161 - val_MinusLogProbMetric: 401.1161 - lr: 4.1667e-05 - 22s/epoch - 110ms/step
Epoch 341/1000
2023-09-10 12:13:48.101 
Epoch 341/1000 
	 loss: 382.6030, MinusLogProbMetric: 382.6030, val_loss: 401.0230, val_MinusLogProbMetric: 401.0230

Epoch 341: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.6030 - MinusLogProbMetric: 382.6030 - val_loss: 401.0230 - val_MinusLogProbMetric: 401.0230 - lr: 4.1667e-05 - 24s/epoch - 124ms/step
Epoch 342/1000
2023-09-10 12:14:12.029 
Epoch 342/1000 
	 loss: 382.5354, MinusLogProbMetric: 382.5354, val_loss: 401.4572, val_MinusLogProbMetric: 401.4572

Epoch 342: val_loss did not improve from 398.60297
196/196 - 24s - loss: 382.5354 - MinusLogProbMetric: 382.5354 - val_loss: 401.4572 - val_MinusLogProbMetric: 401.4572 - lr: 4.1667e-05 - 24s/epoch - 122ms/step
Epoch 343/1000
2023-09-10 12:14:39.242 
Epoch 343/1000 
	 loss: 382.7241, MinusLogProbMetric: 382.7241, val_loss: 401.3699, val_MinusLogProbMetric: 401.3699

Epoch 343: val_loss did not improve from 398.60297
196/196 - 27s - loss: 382.7241 - MinusLogProbMetric: 382.7241 - val_loss: 401.3699 - val_MinusLogProbMetric: 401.3699 - lr: 4.1667e-05 - 27s/epoch - 139ms/step
Epoch 344/1000
2023-09-10 12:15:04.601 
Epoch 344/1000 
	 loss: 382.6436, MinusLogProbMetric: 382.6436, val_loss: 401.4459, val_MinusLogProbMetric: 401.4459

Epoch 344: val_loss did not improve from 398.60297
196/196 - 25s - loss: 382.6436 - MinusLogProbMetric: 382.6436 - val_loss: 401.4459 - val_MinusLogProbMetric: 401.4459 - lr: 4.1667e-05 - 25s/epoch - 129ms/step
Epoch 345/1000
2023-09-10 12:15:25.870 
Epoch 345/1000 
	 loss: 382.5610, MinusLogProbMetric: 382.5610, val_loss: 401.4960, val_MinusLogProbMetric: 401.4960

Epoch 345: val_loss did not improve from 398.60297
196/196 - 21s - loss: 382.5610 - MinusLogProbMetric: 382.5610 - val_loss: 401.4960 - val_MinusLogProbMetric: 401.4960 - lr: 4.1667e-05 - 21s/epoch - 108ms/step
Epoch 346/1000
2023-09-10 12:15:50.394 
Epoch 346/1000 
	 loss: 382.7819, MinusLogProbMetric: 382.7819, val_loss: 401.4354, val_MinusLogProbMetric: 401.4354

Epoch 346: val_loss did not improve from 398.60297
196/196 - 25s - loss: 382.7819 - MinusLogProbMetric: 382.7819 - val_loss: 401.4354 - val_MinusLogProbMetric: 401.4354 - lr: 4.1667e-05 - 25s/epoch - 125ms/step
Epoch 347/1000
2023-09-10 12:16:13.672 
Epoch 347/1000 
	 loss: 382.7297, MinusLogProbMetric: 382.7297, val_loss: 401.4580, val_MinusLogProbMetric: 401.4580

Epoch 347: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.7297 - MinusLogProbMetric: 382.7297 - val_loss: 401.4580 - val_MinusLogProbMetric: 401.4580 - lr: 4.1667e-05 - 23s/epoch - 119ms/step
Epoch 348/1000
2023-09-10 12:16:34.022 
Epoch 348/1000 
	 loss: 382.5586, MinusLogProbMetric: 382.5586, val_loss: 401.4340, val_MinusLogProbMetric: 401.4340

Epoch 348: val_loss did not improve from 398.60297
196/196 - 20s - loss: 382.5586 - MinusLogProbMetric: 382.5586 - val_loss: 401.4340 - val_MinusLogProbMetric: 401.4340 - lr: 4.1667e-05 - 20s/epoch - 104ms/step
Epoch 349/1000
2023-09-10 12:16:56.712 
Epoch 349/1000 
	 loss: 382.4608, MinusLogProbMetric: 382.4608, val_loss: 401.8438, val_MinusLogProbMetric: 401.8438

Epoch 349: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.4608 - MinusLogProbMetric: 382.4608 - val_loss: 401.8438 - val_MinusLogProbMetric: 401.8438 - lr: 4.1667e-05 - 23s/epoch - 116ms/step
Epoch 350/1000
2023-09-10 12:17:17.258 
Epoch 350/1000 
	 loss: 382.6089, MinusLogProbMetric: 382.6089, val_loss: 401.7288, val_MinusLogProbMetric: 401.7288

Epoch 350: val_loss did not improve from 398.60297
196/196 - 21s - loss: 382.6089 - MinusLogProbMetric: 382.6089 - val_loss: 401.7288 - val_MinusLogProbMetric: 401.7288 - lr: 4.1667e-05 - 21s/epoch - 105ms/step
Epoch 351/1000
2023-09-10 12:17:40.772 
Epoch 351/1000 
	 loss: 382.6673, MinusLogProbMetric: 382.6673, val_loss: 402.2045, val_MinusLogProbMetric: 402.2045

Epoch 351: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.6673 - MinusLogProbMetric: 382.6673 - val_loss: 402.2045 - val_MinusLogProbMetric: 402.2045 - lr: 4.1667e-05 - 23s/epoch - 120ms/step
Epoch 352/1000
2023-09-10 12:18:03.664 
Epoch 352/1000 
	 loss: 382.5306, MinusLogProbMetric: 382.5306, val_loss: 401.5013, val_MinusLogProbMetric: 401.5013

Epoch 352: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.5306 - MinusLogProbMetric: 382.5306 - val_loss: 401.5013 - val_MinusLogProbMetric: 401.5013 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 353/1000
2023-09-10 12:18:26.660 
Epoch 353/1000 
	 loss: 382.5579, MinusLogProbMetric: 382.5579, val_loss: 402.2214, val_MinusLogProbMetric: 402.2214

Epoch 353: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.5579 - MinusLogProbMetric: 382.5579 - val_loss: 402.2214 - val_MinusLogProbMetric: 402.2214 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 354/1000
2023-09-10 12:18:51.875 
Epoch 354/1000 
	 loss: 382.5934, MinusLogProbMetric: 382.5934, val_loss: 402.1885, val_MinusLogProbMetric: 402.1885

Epoch 354: val_loss did not improve from 398.60297
196/196 - 25s - loss: 382.5934 - MinusLogProbMetric: 382.5934 - val_loss: 402.1885 - val_MinusLogProbMetric: 402.1885 - lr: 4.1667e-05 - 25s/epoch - 129ms/step
Epoch 355/1000
2023-09-10 12:19:15.209 
Epoch 355/1000 
	 loss: 382.8766, MinusLogProbMetric: 382.8766, val_loss: 402.0176, val_MinusLogProbMetric: 402.0176

Epoch 355: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.8766 - MinusLogProbMetric: 382.8766 - val_loss: 402.0176 - val_MinusLogProbMetric: 402.0176 - lr: 4.1667e-05 - 23s/epoch - 119ms/step
Epoch 356/1000
2023-09-10 12:19:37.899 
Epoch 356/1000 
	 loss: 382.5209, MinusLogProbMetric: 382.5209, val_loss: 402.2601, val_MinusLogProbMetric: 402.2601

Epoch 356: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.5209 - MinusLogProbMetric: 382.5209 - val_loss: 402.2601 - val_MinusLogProbMetric: 402.2601 - lr: 4.1667e-05 - 23s/epoch - 116ms/step
Epoch 357/1000
2023-09-10 12:19:59.820 
Epoch 357/1000 
	 loss: 382.7819, MinusLogProbMetric: 382.7819, val_loss: 402.0430, val_MinusLogProbMetric: 402.0430

Epoch 357: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.7819 - MinusLogProbMetric: 382.7819 - val_loss: 402.0430 - val_MinusLogProbMetric: 402.0430 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 358/1000
2023-09-10 12:20:21.864 
Epoch 358/1000 
	 loss: 382.4451, MinusLogProbMetric: 382.4451, val_loss: 402.3814, val_MinusLogProbMetric: 402.3814

Epoch 358: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.4451 - MinusLogProbMetric: 382.4451 - val_loss: 402.3814 - val_MinusLogProbMetric: 402.3814 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 359/1000
2023-09-10 12:20:43.512 
Epoch 359/1000 
	 loss: 382.5513, MinusLogProbMetric: 382.5513, val_loss: 402.1159, val_MinusLogProbMetric: 402.1159

Epoch 359: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.5513 - MinusLogProbMetric: 382.5513 - val_loss: 402.1159 - val_MinusLogProbMetric: 402.1159 - lr: 4.1667e-05 - 22s/epoch - 110ms/step
Epoch 360/1000
2023-09-10 12:21:05.423 
Epoch 360/1000 
	 loss: 382.4800, MinusLogProbMetric: 382.4800, val_loss: 402.0577, val_MinusLogProbMetric: 402.0577

Epoch 360: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.4800 - MinusLogProbMetric: 382.4800 - val_loss: 402.0577 - val_MinusLogProbMetric: 402.0577 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 361/1000
2023-09-10 12:21:28.544 
Epoch 361/1000 
	 loss: 382.4048, MinusLogProbMetric: 382.4048, val_loss: 402.1977, val_MinusLogProbMetric: 402.1977

Epoch 361: val_loss did not improve from 398.60297
196/196 - 23s - loss: 382.4048 - MinusLogProbMetric: 382.4048 - val_loss: 402.1977 - val_MinusLogProbMetric: 402.1977 - lr: 4.1667e-05 - 23s/epoch - 118ms/step
Epoch 362/1000
2023-09-10 12:21:50.148 
Epoch 362/1000 
	 loss: 382.4977, MinusLogProbMetric: 382.4977, val_loss: 402.4053, val_MinusLogProbMetric: 402.4053

Epoch 362: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.4977 - MinusLogProbMetric: 382.4977 - val_loss: 402.4053 - val_MinusLogProbMetric: 402.4053 - lr: 4.1667e-05 - 22s/epoch - 110ms/step
Epoch 363/1000
2023-09-10 12:22:11.284 
Epoch 363/1000 
	 loss: 382.3901, MinusLogProbMetric: 382.3901, val_loss: 402.9200, val_MinusLogProbMetric: 402.9200

Epoch 363: val_loss did not improve from 398.60297
196/196 - 21s - loss: 382.3901 - MinusLogProbMetric: 382.3901 - val_loss: 402.9200 - val_MinusLogProbMetric: 402.9200 - lr: 4.1667e-05 - 21s/epoch - 108ms/step
Epoch 364/1000
2023-09-10 12:22:33.652 
Epoch 364/1000 
	 loss: 382.6321, MinusLogProbMetric: 382.6321, val_loss: 403.6214, val_MinusLogProbMetric: 403.6214

Epoch 364: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.6321 - MinusLogProbMetric: 382.6321 - val_loss: 403.6214 - val_MinusLogProbMetric: 403.6214 - lr: 4.1667e-05 - 22s/epoch - 114ms/step
Epoch 365/1000
2023-09-10 12:22:54.586 
Epoch 365/1000 
	 loss: 382.8127, MinusLogProbMetric: 382.8127, val_loss: 402.5161, val_MinusLogProbMetric: 402.5161

Epoch 365: val_loss did not improve from 398.60297
196/196 - 21s - loss: 382.8127 - MinusLogProbMetric: 382.8127 - val_loss: 402.5161 - val_MinusLogProbMetric: 402.5161 - lr: 4.1667e-05 - 21s/epoch - 107ms/step
Epoch 366/1000
2023-09-10 12:23:16.675 
Epoch 366/1000 
	 loss: 382.4067, MinusLogProbMetric: 382.4067, val_loss: 403.0002, val_MinusLogProbMetric: 403.0002

Epoch 366: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.4067 - MinusLogProbMetric: 382.4067 - val_loss: 403.0002 - val_MinusLogProbMetric: 403.0002 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 367/1000
2023-09-10 12:23:36.851 
Epoch 367/1000 
	 loss: 382.4523, MinusLogProbMetric: 382.4523, val_loss: 403.5548, val_MinusLogProbMetric: 403.5548

Epoch 367: val_loss did not improve from 398.60297
196/196 - 20s - loss: 382.4523 - MinusLogProbMetric: 382.4523 - val_loss: 403.5548 - val_MinusLogProbMetric: 403.5548 - lr: 4.1667e-05 - 20s/epoch - 103ms/step
Epoch 368/1000
2023-09-10 12:23:58.888 
Epoch 368/1000 
	 loss: 382.4902, MinusLogProbMetric: 382.4902, val_loss: 402.7818, val_MinusLogProbMetric: 402.7818

Epoch 368: val_loss did not improve from 398.60297
196/196 - 22s - loss: 382.4902 - MinusLogProbMetric: 382.4902 - val_loss: 402.7818 - val_MinusLogProbMetric: 402.7818 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 369/1000
2023-09-10 12:24:20.968 
Epoch 369/1000 
	 loss: 382.6531, MinusLogProbMetric: 382.6531, val_loss: 402.9631, val_MinusLogProbMetric: 402.9631

Epoch 369: val_loss did not improve from 398.60297
Restoring model weights from the end of the best epoch: 269.
196/196 - 22s - loss: 382.6531 - MinusLogProbMetric: 382.6531 - val_loss: 402.9631 - val_MinusLogProbMetric: 402.9631 - lr: 4.1667e-05 - 22s/epoch - 114ms/step
Epoch 369: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 2071.6197321050568 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 2136.863323854981 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2072.2117412999505 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 2130.9129660580074 seconds.
Training succeeded with seed 440.
Model trained in 6229.68 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 8686.70 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 8687.11 s.
===========
Run 336/360 done in 15102.69 s.
===========

Directory ../../results/MAFN_new/run_337/ already exists.
Skipping it.
===========
Run 337/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_338/ already exists.
Skipping it.
===========
Run 338/360 already exists. Skipping it.
===========

===========
Generating train data for run 339.
===========
Train data generated in 2.41 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_339/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_339/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_339/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_339
self.data_kwargs: {'seed': 520}
self.x_data: [[6.0386963  0.30078053 4.582872   ... 4.9010735  5.585139   5.0534396 ]
 [7.9469204  4.5061865  5.2455854  ... 2.9358454  8.744124   6.9367347 ]
 [8.143589   4.4823375  5.2392807  ... 3.0099165  8.623259   7.0103106 ]
 ...
 [8.140467   4.6205688  5.2538304  ... 5.1522036  8.523501   6.461891  ]
 [5.550299   8.4923     5.931979   ... 9.995682   1.7941611  6.8577833 ]
 [7.7436986  5.02466    5.1777496  ... 2.148604   8.593714   7.418009  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_69 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_8 (LogProbLa  (None,)                  4191520   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,191,520
Trainable params: 4,191,520
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_8/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_8'")
self.model: <keras.engine.functional.Functional object at 0x7effb1069ab0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effb0a95f60>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effb0a95f60>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effb0a7c8b0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7effb123bc40>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7effb121c160>, <keras.callbacks.ModelCheckpoint object at 0x7effb121c220>, <keras.callbacks.EarlyStopping object at 0x7effb121c490>, <keras.callbacks.ReduceLROnPlateau object at 0x7effb121c4c0>, <keras.callbacks.TerminateOnNaN object at 0x7effb121c100>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_339/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 339/360 with hyperparameters:
timestamp = 2023-09-10 14:49:16.224080
ndims = 1000
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 4191520
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 6.0386963   0.30078053  4.582872    7.656263    0.50402063  8.927606
  5.0806236   0.7069437   3.2612228   9.222077    5.8550296   0.7950525
  3.7572262   5.421181   -0.42896372  5.3715286   5.0170646   4.5275445
  6.268279    8.342493    2.4881694   7.7397876   7.198324   10.337882
  7.1367445   7.992043    3.640705    1.6190335   9.687809   -0.10210621
  4.3673606   0.5702325   9.0355015   9.576009    7.180074    2.9750605
  2.7969558   2.6438603   1.315014    5.2577987   1.5748067   3.07832
  6.905322    7.2643003   0.31143492  3.629692    6.198628    9.935606
  4.738879    9.644313    2.6127305  -0.2701767   4.573748    2.6033232
  8.31127     2.847469    3.1219404   8.036686    8.350981    5.1923842
  7.0816703   3.7841296   0.439943    0.31411228  5.105436    0.16452146
  0.37245148  8.840347    7.522216    2.485342   -0.04555227  9.480491
  3.3716009   2.2168918   5.8693147   1.2792552   2.5388308   9.7780695
  6.3509502   5.2145343   4.668051    7.835037    0.81844634  9.829676
  8.602084    6.4478574   1.8822466   8.708197    9.9343      5.2983065
  4.648863    1.7545191   7.5778584   7.992651    1.2489895   7.932429
  0.19842413 10.670638    6.7138567   5.5415473   2.8593335   8.939356
  1.8772883   8.274395    9.729145    7.7069526   4.83206     0.20179847
  4.5409455   4.72331     2.8598065   4.388705    3.542864    1.3279399
  4.2783537   2.6017168   5.7597165   0.7641455   9.5386305   9.114207
  5.246056    8.810347    9.548426    1.1960151   4.535228    9.936641
 10.11391     6.0469294   1.2320046   5.771403    0.03692677  1.7631103
  9.768336    4.6296864   6.3364687   2.3349156   9.236544    8.197755
  3.2024207   7.716959    2.077003    4.211735    2.1907134   7.0612254
  1.2628212   4.2821627   1.9289484   4.29324     4.816094    7.6030316
  0.34979546  7.054235    2.5239222   2.5584276   7.064572    9.337272
  4.1277614   8.632163    1.1907344   7.2465253   7.3629594   1.4210125
  3.8094866   8.687733    1.3656402   0.28611335  5.895154    4.691248
  7.848699    8.486627    2.7608519   4.164383    5.0772963   6.1176133
 10.264451    6.3248825   3.0036852   2.4301364   9.323013    1.1239512
  6.9529996   8.971375    6.7585683   4.1878514   2.5465474   3.7158139
  7.954454    6.121273    8.889866    8.739019   10.887082    9.803803
  2.4961972   3.7658646   4.353828    5.831876    6.706101    2.2424636
  0.4813192   4.0677247   2.7481353   8.85868     8.81974     8.779158
  6.5635395   3.1331716   5.4378457   8.115037    0.15877736  7.7527685
 -0.23714772  9.2626095   7.987624    0.7620828   6.501852    3.2839687
  1.7200415   1.1543069   7.17581     5.3241725   9.85193    10.548408
 10.603701    2.2370188   9.374007    3.4676795   4.4167695   7.9351892
  2.2672663   5.607824    2.2299185   0.88661635  1.2501802   4.0727944
 -0.12534815  4.24075     6.864432    4.1316953   0.98898524  1.0468978
  2.6923618   1.5284702   9.68549     2.6858997   8.196742    5.9775615
  6.107674    3.8373623   9.739576    3.8176546   7.881323    5.9619036
  4.809063    9.994005    6.06644     0.60921174  5.0061116   8.33161
  7.0547867   8.514869    2.0673354   7.7308583   4.0995107   5.0039496
 10.610853    9.848376    8.120186    4.446167    8.818996    6.304151
  3.6133528   0.34783545  8.203926    4.955636    8.081435    7.584287
  7.8737516   3.389564    7.996908    6.0786796   4.5982037   7.0935416
  0.92889404  1.281023    2.9661057   9.792753    1.4344769   3.2898872
  1.1154623   3.3197548   4.133613    9.714192    7.8477564   3.915498
 -0.54802597  8.3167515   6.381558    1.8454669  11.718771    1.0781447
  8.230542    2.993074    4.4022226   7.81114     6.1109514   8.33177
  6.2205343   0.9577046   9.167438    7.7908244   7.120584    1.3328398
  3.1939583   1.6910427   8.12919     6.4541216   7.9364567  10.26773
  7.809719   10.104616    6.0293574   0.40289783 -0.560338    3.7847402
  7.9600444   9.035484   10.840271    1.0387208  -0.19058862  8.854946
  3.0963922   5.0594854  10.279567    5.074058    6.6726894   3.9883325
  7.652588    4.496253    3.0499647   2.3702488   2.5340867   3.782253
  6.6244855   9.641262    7.137413    6.8682413   1.8626316   4.317209
  4.4707828   6.841525    2.992224    2.4876325   3.3212593   7.333737
  5.75945     0.32461804  0.8335988   3.4026284   8.618828    6.705712
  6.8725452   7.33386     2.8872874   5.3803415   5.1434884   6.246975
  9.339241    0.6288371   8.414895    6.5827723   5.714417    7.4871626
  9.453507    0.7600125   1.494343    7.271453   -0.10680145  4.284081
  3.0645723   2.7818801   6.7562222   0.9355258   8.759254    4.4485765
  4.9456024   5.2843823   6.5932875   3.4578905   0.32452983  3.0972865
  0.45848465  5.198651    2.197647    9.560289    9.731855    6.5005336
  6.619211   10.057005    8.876658    8.295638    3.1194568   3.6742027
  2.26406     5.3983374   9.887169    9.133878    1.5052447   1.7451565
  8.9965925   5.319445    2.527405    6.8142905   6.4233      1.2479438
  4.035429    0.24714679  2.1173966   1.830858    1.9078584   7.0054536
  0.5009528   0.8397763   2.0496254   2.9811964   2.9665575   3.3201675
  7.2900653   9.622518    4.901422    7.8189707   3.9295015   0.91512156
  4.572243    3.2736297   4.8408017   7.065958    4.651118    9.0410385
  8.961053    5.5870433   5.2621417   1.1291223   3.93055     6.9391193
  3.508282    0.4460107   9.179407    7.387717    4.650465    8.17948
  7.53271     5.0031796   8.804058    9.204221    3.6460009   7.006398
  5.8495746   5.197357    9.277365    2.9547234  10.355085    8.981658
  5.367272    8.041138    7.377086    7.5142937   4.0544214   2.2740157
  6.749342    8.733181   -1.1557603   6.3426285   4.84659     8.766928
  2.8006268   4.1529183   4.987336    0.13959682  6.5040164   8.188027
  1.676772    2.4030275   0.5443996   9.24266     5.4919004   9.14114
  5.4362607   7.7436833   3.4114141   2.927477    3.843325    6.4828835
  2.9296427   9.1742115   8.056144   -0.09604371  2.0134284   1.6318083
  0.04543668  2.690591    4.990765    8.81346     2.1004107   4.4873705
 10.513251    7.137761    7.6034775   5.209668    9.811113    5.6359825
  0.19526497  2.564422    4.0089235   6.4994254   7.695936    4.1304693
  7.2958503   8.454953    2.967984    9.869264    7.2374787   8.593143
  5.7742076   7.5300508   7.2095394   7.823381    2.118999    5.039945
  4.053479    9.185997    0.9152442  10.862353    8.841984    0.75618994
  4.901044    7.2554336   7.1853967   9.084257    8.29529     4.220908
  5.8150444   7.7635503   1.2401824   1.3507668   4.54757     3.457343
  7.9834795   5.028612    3.85299     8.574433    8.163936   10.616821
  8.4081      4.1708117   1.2379287   8.800616    1.4772482   4.080577
  8.428701   10.380288    6.389518    6.8510385   0.61914694  4.0696154
  6.8948746   3.383478    0.4705223   3.009568    2.6594605   3.048335
  5.988357    7.1357174   3.261515    4.0008183   0.27625528 -0.3875654
  2.6110508   6.7222776   4.8376966   7.503794    6.6424117   8.686342
  7.1706657   9.419308    7.926278    6.2358265   6.0555067  -0.70361733
 10.064413    1.4912657   8.07811     7.900392    4.8439436   2.0139859
  1.0714337   7.2137423   4.526915    6.6356516   9.933811    1.5130765
  9.312532    3.7438834   3.550579    9.596389    9.815127    1.7642053
  7.4918814  -0.49520278  6.4749107   9.756271    7.145049    4.039104
  3.7851322   4.082335    6.1268287   8.183756    9.32123     0.28198594
  2.5236871  -0.31258178  2.2504802   3.5232162   4.9025984   6.3538814
  7.8291597   9.178961   10.243786    7.067563    8.285971    9.500681
  3.5682902   8.450219    0.17376387  0.216589    2.7681222   4.1601896
  6.1601834   1.706507    6.643297    7.9561872   1.7723906   4.5958123
  5.858561    4.6678243   8.187405    9.715012    8.1015      0.45350024
  7.7912116   0.77989995  2.3104167   1.3162912   1.205177    5.248102
  6.7170506   5.558635    9.548942    2.291232    7.7552695   8.649344
  5.677332    4.394188    6.64837     4.7241607   5.719767    3.967581
  4.259147    7.17209     1.0130833   1.7905484   8.393191    7.4030704
  2.735002    2.5851526   9.099808    7.8557224   6.1393533   2.1640992
  0.7774042   4.113809    6.8772874   9.341514    7.624882   -0.15643695
  2.3431437   3.3053102   1.6893227   7.5518737   7.47631     5.387754
  9.710713    1.6661869   8.289583    1.1974262   3.0808344   7.3471923
  0.8228001   5.6459312   3.6627483   7.2736874   8.484636    7.5182805
  6.5065517   0.4700985   2.234543    5.2005877   3.5432315   2.8302953
  2.0971265   9.56212     3.0628858   4.7415     -0.44130558  9.013574
  1.085037    3.311532    2.5385356   8.806095    2.0905962   7.8503737
  8.578108    9.528165    0.590898    1.9645467   7.9985986   1.753687
  3.172571    1.6611466   1.8709267   4.7864184   1.3145969   3.1479964
  4.083562    0.2390917   3.327033    0.9105044   6.7123947   7.861191
  7.02552     0.75634694  5.9596577   8.067755    2.4828937   7.6143017
  8.580062    7.3855762  -0.04546678  0.0738206   1.8115419   2.7274795
  6.6129613   3.8759396   6.692868    3.7261245   1.3076189   3.1666129
  9.223293    9.462051    2.376804    7.5547466   2.749257    8.444417
  1.3476957   6.958887    0.12667698  9.694718    6.407499    8.479325
  5.627874    4.950144    6.2193155   5.3255057   4.9456944   8.290707
  0.8348843   2.2261314   4.1954646   3.6872017   0.73160475  8.504263
  7.791428    5.3747725   9.8119135   0.7039877   7.6769605   2.5379546
  3.694837    2.045665    7.2654924   0.12175488  7.247275    7.029465
  0.6658832   8.352133    5.5662146   9.030525    7.8712974   5.6255913
  8.1955      3.5710793   4.832326    5.828453   10.745017    1.85231
 -0.526502    3.3114655   4.8024893   0.62556016  4.9190855   9.197764
  6.527681    8.61912     9.540909    9.433219    7.9817605   5.9839487
  4.9048758   0.6134869   5.948723   10.432518    8.046861    3.3048022
  1.5137587   7.991438    7.427192    9.765905    8.476495    5.9867887
  1.0616344   5.6400924   2.9184952   5.1216874   2.580817    8.646928
  7.5732      4.096987    6.089647    4.3319507   8.435398    2.1281555
  7.02788     9.129615    1.7530978   1.3687971   7.042738    7.6120076
  4.263667    6.845998    3.1399002   4.1320887   1.0887251   3.7039056
  2.7662733   3.7930636   9.0424595   1.3231362   3.5029469   6.702694
  9.477917    0.9764585   9.146437    0.77568066  5.0711017   4.2204366
  1.9013925   3.6039436   4.875466    8.647586    9.651502    6.2052207
  8.608539    6.7567143   3.158669    1.8811914   4.3497324   5.161394
  0.6098187   1.152159    6.051886    1.3697395   8.290108    2.6722713
  2.2818537   0.9584924   9.105338    1.0756454   1.5344902   8.241914
  2.561514    6.2516336   7.197662    6.6100316   8.612244    7.1160245
  1.4579626   5.4742584   6.604126    8.5800705   0.06284574  7.271172
  9.004775    7.700049    5.588264    4.5855756   4.7795944   7.2477436
  8.905804    6.081058    9.249524    7.4357276   0.8587049   4.7164693
  2.8504999   3.989924    3.8770769   2.9917765   5.714236    6.905015
  2.6859546   1.846874    0.41534102  4.812243    1.8113589  -0.9216505
  9.0558815   4.663535    1.0859932   8.355898    7.844323    4.0918174
  0.6433816   1.5224574   4.468763    8.928121    1.204919    8.635436
 -0.03399917  4.6824536   6.482672    0.5008905   5.682656    8.837162
  2.072514    7.1392884   6.1446853   2.1056101   0.07073235  0.26507834
  5.238253    9.371503    6.251286    7.188611    5.0308127   6.007279
  1.024926    8.809044    7.712478   10.019146    2.5657964   3.195103
  0.9103755   9.777725    7.5711966   3.4351816   5.4496226   4.112291
  1.660826    1.7369623   9.639072    2.935317    9.930944    0.73487484
  5.733989    1.3034487   0.502199    5.5747876   1.0674012   8.124411
  7.0287094   2.9280264   9.545342    7.30834     2.6214435   7.561452
  7.846946    1.3374016   3.65282     3.05842     6.171471    8.9460125
  1.6092017   8.305956   -0.07000089  6.6192155   4.523222    7.941383
  7.4171886   4.9010735   5.585139    5.0534396 ]
Epoch 1/1000
2023-09-10 14:50:53.869 
Epoch 1/1000 
	 loss: 1643.4490, MinusLogProbMetric: 1643.4490, val_loss: 600.5820, val_MinusLogProbMetric: 600.5820

Epoch 1: val_loss improved from inf to 600.58197, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 98s - loss: 1643.4490 - MinusLogProbMetric: 1643.4490 - val_loss: 600.5820 - val_MinusLogProbMetric: 600.5820 - lr: 0.0010 - 98s/epoch - 499ms/step
Epoch 2/1000
2023-09-10 14:51:15.248 
Epoch 2/1000 
	 loss: 557.8477, MinusLogProbMetric: 557.8477, val_loss: 514.1530, val_MinusLogProbMetric: 514.1530

Epoch 2: val_loss improved from 600.58197 to 514.15302, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 21s - loss: 557.8477 - MinusLogProbMetric: 557.8477 - val_loss: 514.1530 - val_MinusLogProbMetric: 514.1530 - lr: 0.0010 - 21s/epoch - 108ms/step
Epoch 3/1000
2023-09-10 14:51:38.180 
Epoch 3/1000 
	 loss: 511.9757, MinusLogProbMetric: 511.9757, val_loss: 500.6677, val_MinusLogProbMetric: 500.6677

Epoch 3: val_loss improved from 514.15302 to 500.66766, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 23s - loss: 511.9757 - MinusLogProbMetric: 511.9757 - val_loss: 500.6677 - val_MinusLogProbMetric: 500.6677 - lr: 0.0010 - 23s/epoch - 118ms/step
Epoch 4/1000
2023-09-10 14:51:57.836 
Epoch 4/1000 
	 loss: 489.6638, MinusLogProbMetric: 489.6638, val_loss: 489.1729, val_MinusLogProbMetric: 489.1729

Epoch 4: val_loss improved from 500.66766 to 489.17285, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 20s - loss: 489.6638 - MinusLogProbMetric: 489.6638 - val_loss: 489.1729 - val_MinusLogProbMetric: 489.1729 - lr: 0.0010 - 20s/epoch - 100ms/step
Epoch 5/1000
2023-09-10 14:52:16.144 
Epoch 5/1000 
	 loss: 477.2688, MinusLogProbMetric: 477.2688, val_loss: 473.7290, val_MinusLogProbMetric: 473.7290

Epoch 5: val_loss improved from 489.17285 to 473.72900, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 477.2688 - MinusLogProbMetric: 477.2688 - val_loss: 473.7290 - val_MinusLogProbMetric: 473.7290 - lr: 0.0010 - 18s/epoch - 94ms/step
Epoch 6/1000
2023-09-10 14:52:36.065 
Epoch 6/1000 
	 loss: 470.9918, MinusLogProbMetric: 470.9918, val_loss: 463.8205, val_MinusLogProbMetric: 463.8205

Epoch 6: val_loss improved from 473.72900 to 463.82053, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 20s - loss: 470.9918 - MinusLogProbMetric: 470.9918 - val_loss: 463.8205 - val_MinusLogProbMetric: 463.8205 - lr: 0.0010 - 20s/epoch - 103ms/step
Epoch 7/1000
2023-09-10 14:52:57.381 
Epoch 7/1000 
	 loss: 462.9242, MinusLogProbMetric: 462.9242, val_loss: 476.5615, val_MinusLogProbMetric: 476.5615

Epoch 7: val_loss did not improve from 463.82053
196/196 - 20s - loss: 462.9242 - MinusLogProbMetric: 462.9242 - val_loss: 476.5615 - val_MinusLogProbMetric: 476.5615 - lr: 0.0010 - 20s/epoch - 104ms/step
Epoch 8/1000
2023-09-10 14:53:19.246 
Epoch 8/1000 
	 loss: 456.6078, MinusLogProbMetric: 456.6078, val_loss: 527.9190, val_MinusLogProbMetric: 527.9190

Epoch 8: val_loss did not improve from 463.82053
196/196 - 22s - loss: 456.6078 - MinusLogProbMetric: 456.6078 - val_loss: 527.9190 - val_MinusLogProbMetric: 527.9190 - lr: 0.0010 - 22s/epoch - 112ms/step
Epoch 9/1000
2023-09-10 14:53:40.097 
Epoch 9/1000 
	 loss: 456.2096, MinusLogProbMetric: 456.2096, val_loss: 449.7392, val_MinusLogProbMetric: 449.7392

Epoch 9: val_loss improved from 463.82053 to 449.73920, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 22s - loss: 456.2096 - MinusLogProbMetric: 456.2096 - val_loss: 449.7392 - val_MinusLogProbMetric: 449.7392 - lr: 0.0010 - 22s/epoch - 112ms/step
Epoch 10/1000
2023-09-10 14:54:02.547 
Epoch 10/1000 
	 loss: 450.5600, MinusLogProbMetric: 450.5600, val_loss: 450.8052, val_MinusLogProbMetric: 450.8052

Epoch 10: val_loss did not improve from 449.73920
196/196 - 21s - loss: 450.5600 - MinusLogProbMetric: 450.5600 - val_loss: 450.8052 - val_MinusLogProbMetric: 450.8052 - lr: 0.0010 - 21s/epoch - 109ms/step
Epoch 11/1000
2023-09-10 14:54:20.996 
Epoch 11/1000 
	 loss: 450.0833, MinusLogProbMetric: 450.0833, val_loss: 449.9589, val_MinusLogProbMetric: 449.9589

Epoch 11: val_loss did not improve from 449.73920
196/196 - 18s - loss: 450.0833 - MinusLogProbMetric: 450.0833 - val_loss: 449.9589 - val_MinusLogProbMetric: 449.9589 - lr: 0.0010 - 18s/epoch - 94ms/step
Epoch 12/1000
2023-09-10 14:54:38.846 
Epoch 12/1000 
	 loss: 443.4588, MinusLogProbMetric: 443.4588, val_loss: 449.6099, val_MinusLogProbMetric: 449.6099

Epoch 12: val_loss improved from 449.73920 to 449.60989, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 443.4588 - MinusLogProbMetric: 443.4588 - val_loss: 449.6099 - val_MinusLogProbMetric: 449.6099 - lr: 0.0010 - 18s/epoch - 93ms/step
Epoch 13/1000
2023-09-10 14:54:57.967 
Epoch 13/1000 
	 loss: 438.9730, MinusLogProbMetric: 438.9730, val_loss: 442.4614, val_MinusLogProbMetric: 442.4614

Epoch 13: val_loss improved from 449.60989 to 442.46136, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 438.9730 - MinusLogProbMetric: 438.9730 - val_loss: 442.4614 - val_MinusLogProbMetric: 442.4614 - lr: 0.0010 - 19s/epoch - 99ms/step
Epoch 14/1000
2023-09-10 14:55:15.817 
Epoch 14/1000 
	 loss: 437.2480, MinusLogProbMetric: 437.2480, val_loss: 442.8808, val_MinusLogProbMetric: 442.8808

Epoch 14: val_loss did not improve from 442.46136
196/196 - 17s - loss: 437.2480 - MinusLogProbMetric: 437.2480 - val_loss: 442.8808 - val_MinusLogProbMetric: 442.8808 - lr: 0.0010 - 17s/epoch - 87ms/step
Epoch 15/1000
2023-09-10 14:55:34.537 
Epoch 15/1000 
	 loss: 434.6015, MinusLogProbMetric: 434.6015, val_loss: 433.1254, val_MinusLogProbMetric: 433.1254

Epoch 15: val_loss improved from 442.46136 to 433.12543, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 434.6015 - MinusLogProbMetric: 434.6015 - val_loss: 433.1254 - val_MinusLogProbMetric: 433.1254 - lr: 0.0010 - 19s/epoch - 98ms/step
Epoch 16/1000
2023-09-10 14:55:54.213 
Epoch 16/1000 
	 loss: 436.2955, MinusLogProbMetric: 436.2955, val_loss: 427.5273, val_MinusLogProbMetric: 427.5273

Epoch 16: val_loss improved from 433.12543 to 427.52734, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 20s - loss: 436.2955 - MinusLogProbMetric: 436.2955 - val_loss: 427.5273 - val_MinusLogProbMetric: 427.5273 - lr: 0.0010 - 20s/epoch - 101ms/step
Epoch 17/1000
2023-09-10 14:56:15.487 
Epoch 17/1000 
	 loss: 446.8134, MinusLogProbMetric: 446.8134, val_loss: 437.0678, val_MinusLogProbMetric: 437.0678

Epoch 17: val_loss did not improve from 427.52734
196/196 - 21s - loss: 446.8134 - MinusLogProbMetric: 446.8134 - val_loss: 437.0678 - val_MinusLogProbMetric: 437.0678 - lr: 0.0010 - 21s/epoch - 105ms/step
Epoch 18/1000
2023-09-10 14:56:34.092 
Epoch 18/1000 
	 loss: 433.2290, MinusLogProbMetric: 433.2290, val_loss: 454.7252, val_MinusLogProbMetric: 454.7252

Epoch 18: val_loss did not improve from 427.52734
196/196 - 19s - loss: 433.2290 - MinusLogProbMetric: 433.2290 - val_loss: 454.7252 - val_MinusLogProbMetric: 454.7252 - lr: 0.0010 - 19s/epoch - 95ms/step
Epoch 19/1000
2023-09-10 14:56:50.545 
Epoch 19/1000 
	 loss: 429.7697, MinusLogProbMetric: 429.7697, val_loss: 431.0500, val_MinusLogProbMetric: 431.0500

Epoch 19: val_loss did not improve from 427.52734
196/196 - 16s - loss: 429.7697 - MinusLogProbMetric: 429.7697 - val_loss: 431.0500 - val_MinusLogProbMetric: 431.0500 - lr: 0.0010 - 16s/epoch - 84ms/step
Epoch 20/1000
2023-09-10 14:57:09.126 
Epoch 20/1000 
	 loss: 426.9492, MinusLogProbMetric: 426.9492, val_loss: 427.3072, val_MinusLogProbMetric: 427.3072

Epoch 20: val_loss improved from 427.52734 to 427.30719, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 426.9492 - MinusLogProbMetric: 426.9492 - val_loss: 427.3072 - val_MinusLogProbMetric: 427.3072 - lr: 0.0010 - 19s/epoch - 98ms/step
Epoch 21/1000
2023-09-10 14:57:29.271 
Epoch 21/1000 
	 loss: 426.7913, MinusLogProbMetric: 426.7913, val_loss: 442.3756, val_MinusLogProbMetric: 442.3756

Epoch 21: val_loss did not improve from 427.30719
196/196 - 19s - loss: 426.7913 - MinusLogProbMetric: 426.7913 - val_loss: 442.3756 - val_MinusLogProbMetric: 442.3756 - lr: 0.0010 - 19s/epoch - 99ms/step
Epoch 22/1000
2023-09-10 14:57:47.724 
Epoch 22/1000 
	 loss: 426.6405, MinusLogProbMetric: 426.6405, val_loss: 420.5872, val_MinusLogProbMetric: 420.5872

Epoch 22: val_loss improved from 427.30719 to 420.58722, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 426.6405 - MinusLogProbMetric: 426.6405 - val_loss: 420.5872 - val_MinusLogProbMetric: 420.5872 - lr: 0.0010 - 19s/epoch - 98ms/step
Epoch 23/1000
2023-09-10 14:58:08.650 
Epoch 23/1000 
	 loss: 426.4062, MinusLogProbMetric: 426.4062, val_loss: 421.3316, val_MinusLogProbMetric: 421.3316

Epoch 23: val_loss did not improve from 420.58722
196/196 - 20s - loss: 426.4062 - MinusLogProbMetric: 426.4062 - val_loss: 421.3316 - val_MinusLogProbMetric: 421.3316 - lr: 0.0010 - 20s/epoch - 103ms/step
Epoch 24/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 55: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-10 14:58:14.597 
Epoch 24/1000 
	 loss: inf, MinusLogProbMetric: 2500735581290496.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 24: val_loss did not improve from 420.58722
196/196 - 6s - loss: inf - MinusLogProbMetric: 2500735581290496.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 6s/epoch - 30ms/step
The loss history contains Inf values.
Training failed: trying again with seed 105132 and lr 0.0003333333333333333.
===========
Generating train data for run 339.
===========
Train data generated in 3.14 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_339/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_339/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_339/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_339
self.data_kwargs: {'seed': 520}
self.x_data: [[6.0386963  0.30078053 4.582872   ... 4.9010735  5.585139   5.0534396 ]
 [7.9469204  4.5061865  5.2455854  ... 2.9358454  8.744124   6.9367347 ]
 [8.143589   4.4823375  5.2392807  ... 3.0099165  8.623259   7.0103106 ]
 ...
 [8.140467   4.6205688  5.2538304  ... 5.1522036  8.523501   6.461891  ]
 [5.550299   8.4923     5.931979   ... 9.995682   1.7941611  6.8577833 ]
 [7.7436986  5.02466    5.1777496  ... 2.148604   8.593714   7.418009  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_80 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_9 (LogProbLa  (None,)                  4191520   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,191,520
Trainable params: 4,191,520
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_9/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_9'")
self.model: <keras.engine.functional.Functional object at 0x7efaf467e5f0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7effb0a8f0a0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7effb0a8f0a0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7effca5f4c10>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7efb60721b10>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7efb60721ff0>, <keras.callbacks.ModelCheckpoint object at 0x7efb607220b0>, <keras.callbacks.EarlyStopping object at 0x7efb60722320>, <keras.callbacks.ReduceLROnPlateau object at 0x7efb60722350>, <keras.callbacks.TerminateOnNaN object at 0x7efb60721f90>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 339/360 with hyperparameters:
timestamp = 2023-09-10 14:58:24.271540
ndims = 1000
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 4191520
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 6.0386963   0.30078053  4.582872    7.656263    0.50402063  8.927606
  5.0806236   0.7069437   3.2612228   9.222077    5.8550296   0.7950525
  3.7572262   5.421181   -0.42896372  5.3715286   5.0170646   4.5275445
  6.268279    8.342493    2.4881694   7.7397876   7.198324   10.337882
  7.1367445   7.992043    3.640705    1.6190335   9.687809   -0.10210621
  4.3673606   0.5702325   9.0355015   9.576009    7.180074    2.9750605
  2.7969558   2.6438603   1.315014    5.2577987   1.5748067   3.07832
  6.905322    7.2643003   0.31143492  3.629692    6.198628    9.935606
  4.738879    9.644313    2.6127305  -0.2701767   4.573748    2.6033232
  8.31127     2.847469    3.1219404   8.036686    8.350981    5.1923842
  7.0816703   3.7841296   0.439943    0.31411228  5.105436    0.16452146
  0.37245148  8.840347    7.522216    2.485342   -0.04555227  9.480491
  3.3716009   2.2168918   5.8693147   1.2792552   2.5388308   9.7780695
  6.3509502   5.2145343   4.668051    7.835037    0.81844634  9.829676
  8.602084    6.4478574   1.8822466   8.708197    9.9343      5.2983065
  4.648863    1.7545191   7.5778584   7.992651    1.2489895   7.932429
  0.19842413 10.670638    6.7138567   5.5415473   2.8593335   8.939356
  1.8772883   8.274395    9.729145    7.7069526   4.83206     0.20179847
  4.5409455   4.72331     2.8598065   4.388705    3.542864    1.3279399
  4.2783537   2.6017168   5.7597165   0.7641455   9.5386305   9.114207
  5.246056    8.810347    9.548426    1.1960151   4.535228    9.936641
 10.11391     6.0469294   1.2320046   5.771403    0.03692677  1.7631103
  9.768336    4.6296864   6.3364687   2.3349156   9.236544    8.197755
  3.2024207   7.716959    2.077003    4.211735    2.1907134   7.0612254
  1.2628212   4.2821627   1.9289484   4.29324     4.816094    7.6030316
  0.34979546  7.054235    2.5239222   2.5584276   7.064572    9.337272
  4.1277614   8.632163    1.1907344   7.2465253   7.3629594   1.4210125
  3.8094866   8.687733    1.3656402   0.28611335  5.895154    4.691248
  7.848699    8.486627    2.7608519   4.164383    5.0772963   6.1176133
 10.264451    6.3248825   3.0036852   2.4301364   9.323013    1.1239512
  6.9529996   8.971375    6.7585683   4.1878514   2.5465474   3.7158139
  7.954454    6.121273    8.889866    8.739019   10.887082    9.803803
  2.4961972   3.7658646   4.353828    5.831876    6.706101    2.2424636
  0.4813192   4.0677247   2.7481353   8.85868     8.81974     8.779158
  6.5635395   3.1331716   5.4378457   8.115037    0.15877736  7.7527685
 -0.23714772  9.2626095   7.987624    0.7620828   6.501852    3.2839687
  1.7200415   1.1543069   7.17581     5.3241725   9.85193    10.548408
 10.603701    2.2370188   9.374007    3.4676795   4.4167695   7.9351892
  2.2672663   5.607824    2.2299185   0.88661635  1.2501802   4.0727944
 -0.12534815  4.24075     6.864432    4.1316953   0.98898524  1.0468978
  2.6923618   1.5284702   9.68549     2.6858997   8.196742    5.9775615
  6.107674    3.8373623   9.739576    3.8176546   7.881323    5.9619036
  4.809063    9.994005    6.06644     0.60921174  5.0061116   8.33161
  7.0547867   8.514869    2.0673354   7.7308583   4.0995107   5.0039496
 10.610853    9.848376    8.120186    4.446167    8.818996    6.304151
  3.6133528   0.34783545  8.203926    4.955636    8.081435    7.584287
  7.8737516   3.389564    7.996908    6.0786796   4.5982037   7.0935416
  0.92889404  1.281023    2.9661057   9.792753    1.4344769   3.2898872
  1.1154623   3.3197548   4.133613    9.714192    7.8477564   3.915498
 -0.54802597  8.3167515   6.381558    1.8454669  11.718771    1.0781447
  8.230542    2.993074    4.4022226   7.81114     6.1109514   8.33177
  6.2205343   0.9577046   9.167438    7.7908244   7.120584    1.3328398
  3.1939583   1.6910427   8.12919     6.4541216   7.9364567  10.26773
  7.809719   10.104616    6.0293574   0.40289783 -0.560338    3.7847402
  7.9600444   9.035484   10.840271    1.0387208  -0.19058862  8.854946
  3.0963922   5.0594854  10.279567    5.074058    6.6726894   3.9883325
  7.652588    4.496253    3.0499647   2.3702488   2.5340867   3.782253
  6.6244855   9.641262    7.137413    6.8682413   1.8626316   4.317209
  4.4707828   6.841525    2.992224    2.4876325   3.3212593   7.333737
  5.75945     0.32461804  0.8335988   3.4026284   8.618828    6.705712
  6.8725452   7.33386     2.8872874   5.3803415   5.1434884   6.246975
  9.339241    0.6288371   8.414895    6.5827723   5.714417    7.4871626
  9.453507    0.7600125   1.494343    7.271453   -0.10680145  4.284081
  3.0645723   2.7818801   6.7562222   0.9355258   8.759254    4.4485765
  4.9456024   5.2843823   6.5932875   3.4578905   0.32452983  3.0972865
  0.45848465  5.198651    2.197647    9.560289    9.731855    6.5005336
  6.619211   10.057005    8.876658    8.295638    3.1194568   3.6742027
  2.26406     5.3983374   9.887169    9.133878    1.5052447   1.7451565
  8.9965925   5.319445    2.527405    6.8142905   6.4233      1.2479438
  4.035429    0.24714679  2.1173966   1.830858    1.9078584   7.0054536
  0.5009528   0.8397763   2.0496254   2.9811964   2.9665575   3.3201675
  7.2900653   9.622518    4.901422    7.8189707   3.9295015   0.91512156
  4.572243    3.2736297   4.8408017   7.065958    4.651118    9.0410385
  8.961053    5.5870433   5.2621417   1.1291223   3.93055     6.9391193
  3.508282    0.4460107   9.179407    7.387717    4.650465    8.17948
  7.53271     5.0031796   8.804058    9.204221    3.6460009   7.006398
  5.8495746   5.197357    9.277365    2.9547234  10.355085    8.981658
  5.367272    8.041138    7.377086    7.5142937   4.0544214   2.2740157
  6.749342    8.733181   -1.1557603   6.3426285   4.84659     8.766928
  2.8006268   4.1529183   4.987336    0.13959682  6.5040164   8.188027
  1.676772    2.4030275   0.5443996   9.24266     5.4919004   9.14114
  5.4362607   7.7436833   3.4114141   2.927477    3.843325    6.4828835
  2.9296427   9.1742115   8.056144   -0.09604371  2.0134284   1.6318083
  0.04543668  2.690591    4.990765    8.81346     2.1004107   4.4873705
 10.513251    7.137761    7.6034775   5.209668    9.811113    5.6359825
  0.19526497  2.564422    4.0089235   6.4994254   7.695936    4.1304693
  7.2958503   8.454953    2.967984    9.869264    7.2374787   8.593143
  5.7742076   7.5300508   7.2095394   7.823381    2.118999    5.039945
  4.053479    9.185997    0.9152442  10.862353    8.841984    0.75618994
  4.901044    7.2554336   7.1853967   9.084257    8.29529     4.220908
  5.8150444   7.7635503   1.2401824   1.3507668   4.54757     3.457343
  7.9834795   5.028612    3.85299     8.574433    8.163936   10.616821
  8.4081      4.1708117   1.2379287   8.800616    1.4772482   4.080577
  8.428701   10.380288    6.389518    6.8510385   0.61914694  4.0696154
  6.8948746   3.383478    0.4705223   3.009568    2.6594605   3.048335
  5.988357    7.1357174   3.261515    4.0008183   0.27625528 -0.3875654
  2.6110508   6.7222776   4.8376966   7.503794    6.6424117   8.686342
  7.1706657   9.419308    7.926278    6.2358265   6.0555067  -0.70361733
 10.064413    1.4912657   8.07811     7.900392    4.8439436   2.0139859
  1.0714337   7.2137423   4.526915    6.6356516   9.933811    1.5130765
  9.312532    3.7438834   3.550579    9.596389    9.815127    1.7642053
  7.4918814  -0.49520278  6.4749107   9.756271    7.145049    4.039104
  3.7851322   4.082335    6.1268287   8.183756    9.32123     0.28198594
  2.5236871  -0.31258178  2.2504802   3.5232162   4.9025984   6.3538814
  7.8291597   9.178961   10.243786    7.067563    8.285971    9.500681
  3.5682902   8.450219    0.17376387  0.216589    2.7681222   4.1601896
  6.1601834   1.706507    6.643297    7.9561872   1.7723906   4.5958123
  5.858561    4.6678243   8.187405    9.715012    8.1015      0.45350024
  7.7912116   0.77989995  2.3104167   1.3162912   1.205177    5.248102
  6.7170506   5.558635    9.548942    2.291232    7.7552695   8.649344
  5.677332    4.394188    6.64837     4.7241607   5.719767    3.967581
  4.259147    7.17209     1.0130833   1.7905484   8.393191    7.4030704
  2.735002    2.5851526   9.099808    7.8557224   6.1393533   2.1640992
  0.7774042   4.113809    6.8772874   9.341514    7.624882   -0.15643695
  2.3431437   3.3053102   1.6893227   7.5518737   7.47631     5.387754
  9.710713    1.6661869   8.289583    1.1974262   3.0808344   7.3471923
  0.8228001   5.6459312   3.6627483   7.2736874   8.484636    7.5182805
  6.5065517   0.4700985   2.234543    5.2005877   3.5432315   2.8302953
  2.0971265   9.56212     3.0628858   4.7415     -0.44130558  9.013574
  1.085037    3.311532    2.5385356   8.806095    2.0905962   7.8503737
  8.578108    9.528165    0.590898    1.9645467   7.9985986   1.753687
  3.172571    1.6611466   1.8709267   4.7864184   1.3145969   3.1479964
  4.083562    0.2390917   3.327033    0.9105044   6.7123947   7.861191
  7.02552     0.75634694  5.9596577   8.067755    2.4828937   7.6143017
  8.580062    7.3855762  -0.04546678  0.0738206   1.8115419   2.7274795
  6.6129613   3.8759396   6.692868    3.7261245   1.3076189   3.1666129
  9.223293    9.462051    2.376804    7.5547466   2.749257    8.444417
  1.3476957   6.958887    0.12667698  9.694718    6.407499    8.479325
  5.627874    4.950144    6.2193155   5.3255057   4.9456944   8.290707
  0.8348843   2.2261314   4.1954646   3.6872017   0.73160475  8.504263
  7.791428    5.3747725   9.8119135   0.7039877   7.6769605   2.5379546
  3.694837    2.045665    7.2654924   0.12175488  7.247275    7.029465
  0.6658832   8.352133    5.5662146   9.030525    7.8712974   5.6255913
  8.1955      3.5710793   4.832326    5.828453   10.745017    1.85231
 -0.526502    3.3114655   4.8024893   0.62556016  4.9190855   9.197764
  6.527681    8.61912     9.540909    9.433219    7.9817605   5.9839487
  4.9048758   0.6134869   5.948723   10.432518    8.046861    3.3048022
  1.5137587   7.991438    7.427192    9.765905    8.476495    5.9867887
  1.0616344   5.6400924   2.9184952   5.1216874   2.580817    8.646928
  7.5732      4.096987    6.089647    4.3319507   8.435398    2.1281555
  7.02788     9.129615    1.7530978   1.3687971   7.042738    7.6120076
  4.263667    6.845998    3.1399002   4.1320887   1.0887251   3.7039056
  2.7662733   3.7930636   9.0424595   1.3231362   3.5029469   6.702694
  9.477917    0.9764585   9.146437    0.77568066  5.0711017   4.2204366
  1.9013925   3.6039436   4.875466    8.647586    9.651502    6.2052207
  8.608539    6.7567143   3.158669    1.8811914   4.3497324   5.161394
  0.6098187   1.152159    6.051886    1.3697395   8.290108    2.6722713
  2.2818537   0.9584924   9.105338    1.0756454   1.5344902   8.241914
  2.561514    6.2516336   7.197662    6.6100316   8.612244    7.1160245
  1.4579626   5.4742584   6.604126    8.5800705   0.06284574  7.271172
  9.004775    7.700049    5.588264    4.5855756   4.7795944   7.2477436
  8.905804    6.081058    9.249524    7.4357276   0.8587049   4.7164693
  2.8504999   3.989924    3.8770769   2.9917765   5.714236    6.905015
  2.6859546   1.846874    0.41534102  4.812243    1.8113589  -0.9216505
  9.0558815   4.663535    1.0859932   8.355898    7.844323    4.0918174
  0.6433816   1.5224574   4.468763    8.928121    1.204919    8.635436
 -0.03399917  4.6824536   6.482672    0.5008905   5.682656    8.837162
  2.072514    7.1392884   6.1446853   2.1056101   0.07073235  0.26507834
  5.238253    9.371503    6.251286    7.188611    5.0308127   6.007279
  1.024926    8.809044    7.712478   10.019146    2.5657964   3.195103
  0.9103755   9.777725    7.5711966   3.4351816   5.4496226   4.112291
  1.660826    1.7369623   9.639072    2.935317    9.930944    0.73487484
  5.733989    1.3034487   0.502199    5.5747876   1.0674012   8.124411
  7.0287094   2.9280264   9.545342    7.30834     2.6214435   7.561452
  7.846946    1.3374016   3.65282     3.05842     6.171471    8.9460125
  1.6092017   8.305956   -0.07000089  6.6192155   4.523222    7.941383
  7.4171886   4.9010735   5.585139    5.0534396 ]
Epoch 1/1000
2023-09-10 15:00:03.609 
Epoch 1/1000 
	 loss: 459.8774, MinusLogProbMetric: 459.8774, val_loss: 413.9599, val_MinusLogProbMetric: 413.9599

Epoch 1: val_loss improved from inf to 413.95987, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 99s - loss: 459.8774 - MinusLogProbMetric: 459.8774 - val_loss: 413.9599 - val_MinusLogProbMetric: 413.9599 - lr: 3.3333e-04 - 99s/epoch - 507ms/step
Epoch 2/1000
2023-09-10 15:00:21.538 
Epoch 2/1000 
	 loss: 410.9914, MinusLogProbMetric: 410.9914, val_loss: 410.9193, val_MinusLogProbMetric: 410.9193

Epoch 2: val_loss improved from 413.95987 to 410.91928, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 410.9914 - MinusLogProbMetric: 410.9914 - val_loss: 410.9193 - val_MinusLogProbMetric: 410.9193 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 3/1000
2023-09-10 15:00:42.316 
Epoch 3/1000 
	 loss: 409.7699, MinusLogProbMetric: 409.7699, val_loss: 410.9113, val_MinusLogProbMetric: 410.9113

Epoch 3: val_loss improved from 410.91928 to 410.91129, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 21s - loss: 409.7699 - MinusLogProbMetric: 409.7699 - val_loss: 410.9113 - val_MinusLogProbMetric: 410.9113 - lr: 3.3333e-04 - 21s/epoch - 109ms/step
Epoch 4/1000
2023-09-10 15:01:01.937 
Epoch 4/1000 
	 loss: 409.8891, MinusLogProbMetric: 409.8891, val_loss: 413.1237, val_MinusLogProbMetric: 413.1237

Epoch 4: val_loss did not improve from 410.91129
196/196 - 18s - loss: 409.8891 - MinusLogProbMetric: 409.8891 - val_loss: 413.1237 - val_MinusLogProbMetric: 413.1237 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 5/1000
2023-09-10 15:01:23.074 
Epoch 5/1000 
	 loss: 408.9422, MinusLogProbMetric: 408.9422, val_loss: 409.4638, val_MinusLogProbMetric: 409.4638

Epoch 5: val_loss improved from 410.91129 to 409.46381, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 22s - loss: 408.9422 - MinusLogProbMetric: 408.9422 - val_loss: 409.4638 - val_MinusLogProbMetric: 409.4638 - lr: 3.3333e-04 - 22s/epoch - 111ms/step
Epoch 6/1000
2023-09-10 15:01:42.127 
Epoch 6/1000 
	 loss: 408.8981, MinusLogProbMetric: 408.8981, val_loss: 410.8823, val_MinusLogProbMetric: 410.8823

Epoch 6: val_loss did not improve from 409.46381
196/196 - 18s - loss: 408.8981 - MinusLogProbMetric: 408.8981 - val_loss: 410.8823 - val_MinusLogProbMetric: 410.8823 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 7/1000
2023-09-10 15:02:01.027 
Epoch 7/1000 
	 loss: 408.0302, MinusLogProbMetric: 408.0302, val_loss: 408.8033, val_MinusLogProbMetric: 408.8033

Epoch 7: val_loss improved from 409.46381 to 408.80325, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 408.0302 - MinusLogProbMetric: 408.0302 - val_loss: 408.8033 - val_MinusLogProbMetric: 408.8033 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 8/1000
2023-09-10 15:02:19.945 
Epoch 8/1000 
	 loss: 407.9869, MinusLogProbMetric: 407.9869, val_loss: 407.1394, val_MinusLogProbMetric: 407.1394

Epoch 8: val_loss improved from 408.80325 to 407.13943, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 407.9869 - MinusLogProbMetric: 407.9869 - val_loss: 407.1394 - val_MinusLogProbMetric: 407.1394 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 9/1000
2023-09-10 15:02:38.225 
Epoch 9/1000 
	 loss: 407.6094, MinusLogProbMetric: 407.6094, val_loss: 407.0960, val_MinusLogProbMetric: 407.0960

Epoch 9: val_loss improved from 407.13943 to 407.09604, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 407.6094 - MinusLogProbMetric: 407.6094 - val_loss: 407.0960 - val_MinusLogProbMetric: 407.0960 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 10/1000
2023-09-10 15:02:58.557 
Epoch 10/1000 
	 loss: 407.3314, MinusLogProbMetric: 407.3314, val_loss: 416.6531, val_MinusLogProbMetric: 416.6531

Epoch 10: val_loss did not improve from 407.09604
196/196 - 20s - loss: 407.3314 - MinusLogProbMetric: 407.3314 - val_loss: 416.6531 - val_MinusLogProbMetric: 416.6531 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 11/1000
2023-09-10 15:03:15.398 
Epoch 11/1000 
	 loss: 407.3507, MinusLogProbMetric: 407.3507, val_loss: 410.6774, val_MinusLogProbMetric: 410.6774

Epoch 11: val_loss did not improve from 407.09604
196/196 - 17s - loss: 407.3507 - MinusLogProbMetric: 407.3507 - val_loss: 410.6774 - val_MinusLogProbMetric: 410.6774 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 12/1000
2023-09-10 15:03:34.426 
Epoch 12/1000 
	 loss: 406.6578, MinusLogProbMetric: 406.6578, val_loss: 407.8963, val_MinusLogProbMetric: 407.8963

Epoch 12: val_loss did not improve from 407.09604
196/196 - 19s - loss: 406.6578 - MinusLogProbMetric: 406.6578 - val_loss: 407.8963 - val_MinusLogProbMetric: 407.8963 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 13/1000
2023-09-10 15:03:52.355 
Epoch 13/1000 
	 loss: 407.0161, MinusLogProbMetric: 407.0161, val_loss: 407.8225, val_MinusLogProbMetric: 407.8225

Epoch 13: val_loss did not improve from 407.09604
196/196 - 18s - loss: 407.0161 - MinusLogProbMetric: 407.0161 - val_loss: 407.8225 - val_MinusLogProbMetric: 407.8225 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 14/1000
2023-09-10 15:04:09.268 
Epoch 14/1000 
	 loss: 406.1144, MinusLogProbMetric: 406.1144, val_loss: 407.5215, val_MinusLogProbMetric: 407.5215

Epoch 14: val_loss did not improve from 407.09604
196/196 - 17s - loss: 406.1144 - MinusLogProbMetric: 406.1144 - val_loss: 407.5215 - val_MinusLogProbMetric: 407.5215 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 15/1000
2023-09-10 15:04:26.608 
Epoch 15/1000 
	 loss: 405.6432, MinusLogProbMetric: 405.6432, val_loss: 410.3155, val_MinusLogProbMetric: 410.3155

Epoch 15: val_loss did not improve from 407.09604
196/196 - 17s - loss: 405.6432 - MinusLogProbMetric: 405.6432 - val_loss: 410.3155 - val_MinusLogProbMetric: 410.3155 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 16/1000
2023-09-10 15:04:45.266 
Epoch 16/1000 
	 loss: 406.0829, MinusLogProbMetric: 406.0829, val_loss: 407.4408, val_MinusLogProbMetric: 407.4408

Epoch 16: val_loss did not improve from 407.09604
196/196 - 19s - loss: 406.0829 - MinusLogProbMetric: 406.0829 - val_loss: 407.4408 - val_MinusLogProbMetric: 407.4408 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 17/1000
2023-09-10 15:05:03.142 
Epoch 17/1000 
	 loss: 405.6232, MinusLogProbMetric: 405.6232, val_loss: 411.3058, val_MinusLogProbMetric: 411.3058

Epoch 17: val_loss did not improve from 407.09604
196/196 - 18s - loss: 405.6232 - MinusLogProbMetric: 405.6232 - val_loss: 411.3058 - val_MinusLogProbMetric: 411.3058 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 18/1000
2023-09-10 15:05:21.408 
Epoch 18/1000 
	 loss: 405.4101, MinusLogProbMetric: 405.4101, val_loss: 405.7780, val_MinusLogProbMetric: 405.7780

Epoch 18: val_loss improved from 407.09604 to 405.77802, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 405.4101 - MinusLogProbMetric: 405.4101 - val_loss: 405.7780 - val_MinusLogProbMetric: 405.7780 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 19/1000
2023-09-10 15:05:41.315 
Epoch 19/1000 
	 loss: 404.6386, MinusLogProbMetric: 404.6386, val_loss: 406.3450, val_MinusLogProbMetric: 406.3450

Epoch 19: val_loss did not improve from 405.77802
196/196 - 19s - loss: 404.6386 - MinusLogProbMetric: 404.6386 - val_loss: 406.3450 - val_MinusLogProbMetric: 406.3450 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 20/1000
2023-09-10 15:05:58.536 
Epoch 20/1000 
	 loss: 405.0032, MinusLogProbMetric: 405.0032, val_loss: 405.6954, val_MinusLogProbMetric: 405.6954

Epoch 20: val_loss improved from 405.77802 to 405.69543, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 405.0032 - MinusLogProbMetric: 405.0032 - val_loss: 405.6954 - val_MinusLogProbMetric: 405.6954 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 21/1000
2023-09-10 15:06:16.410 
Epoch 21/1000 
	 loss: 404.5448, MinusLogProbMetric: 404.5448, val_loss: 406.9594, val_MinusLogProbMetric: 406.9594

Epoch 21: val_loss did not improve from 405.69543
196/196 - 17s - loss: 404.5448 - MinusLogProbMetric: 404.5448 - val_loss: 406.9594 - val_MinusLogProbMetric: 406.9594 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 22/1000
2023-09-10 15:06:34.084 
Epoch 22/1000 
	 loss: 404.9596, MinusLogProbMetric: 404.9596, val_loss: 405.4557, val_MinusLogProbMetric: 405.4557

Epoch 22: val_loss improved from 405.69543 to 405.45572, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 404.9596 - MinusLogProbMetric: 404.9596 - val_loss: 405.4557 - val_MinusLogProbMetric: 405.4557 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 23/1000
2023-09-10 15:06:53.574 
Epoch 23/1000 
	 loss: 404.5329, MinusLogProbMetric: 404.5329, val_loss: 407.3792, val_MinusLogProbMetric: 407.3792

Epoch 23: val_loss did not improve from 405.45572
196/196 - 19s - loss: 404.5329 - MinusLogProbMetric: 404.5329 - val_loss: 407.3792 - val_MinusLogProbMetric: 407.3792 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 24/1000
2023-09-10 15:07:11.980 
Epoch 24/1000 
	 loss: 404.6776, MinusLogProbMetric: 404.6776, val_loss: 405.0365, val_MinusLogProbMetric: 405.0365

Epoch 24: val_loss improved from 405.45572 to 405.03653, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 404.6776 - MinusLogProbMetric: 404.6776 - val_loss: 405.0365 - val_MinusLogProbMetric: 405.0365 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 25/1000
2023-09-10 15:07:33.493 
Epoch 25/1000 
	 loss: 403.3130, MinusLogProbMetric: 403.3130, val_loss: 406.9016, val_MinusLogProbMetric: 406.9016

Epoch 25: val_loss did not improve from 405.03653
196/196 - 21s - loss: 403.3130 - MinusLogProbMetric: 403.3130 - val_loss: 406.9016 - val_MinusLogProbMetric: 406.9016 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 26/1000
2023-09-10 15:07:52.679 
Epoch 26/1000 
	 loss: 403.7881, MinusLogProbMetric: 403.7881, val_loss: 405.1954, val_MinusLogProbMetric: 405.1954

Epoch 26: val_loss did not improve from 405.03653
196/196 - 19s - loss: 403.7881 - MinusLogProbMetric: 403.7881 - val_loss: 405.1954 - val_MinusLogProbMetric: 405.1954 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 27/1000
2023-09-10 15:08:11.424 
Epoch 27/1000 
	 loss: 403.3867, MinusLogProbMetric: 403.3867, val_loss: 404.2038, val_MinusLogProbMetric: 404.2038

Epoch 27: val_loss improved from 405.03653 to 404.20383, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 403.3867 - MinusLogProbMetric: 403.3867 - val_loss: 404.2038 - val_MinusLogProbMetric: 404.2038 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 28/1000
2023-09-10 15:08:31.440 
Epoch 28/1000 
	 loss: 403.4781, MinusLogProbMetric: 403.4781, val_loss: 406.2610, val_MinusLogProbMetric: 406.2610

Epoch 28: val_loss did not improve from 404.20383
196/196 - 19s - loss: 403.4781 - MinusLogProbMetric: 403.4781 - val_loss: 406.2610 - val_MinusLogProbMetric: 406.2610 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 29/1000
2023-09-10 15:08:49.502 
Epoch 29/1000 
	 loss: 403.2518, MinusLogProbMetric: 403.2518, val_loss: 405.0784, val_MinusLogProbMetric: 405.0784

Epoch 29: val_loss did not improve from 404.20383
196/196 - 18s - loss: 403.2518 - MinusLogProbMetric: 403.2518 - val_loss: 405.0784 - val_MinusLogProbMetric: 405.0784 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 30/1000
2023-09-10 15:09:10.415 
Epoch 30/1000 
	 loss: 403.3218, MinusLogProbMetric: 403.3218, val_loss: 403.3206, val_MinusLogProbMetric: 403.3206

Epoch 30: val_loss improved from 404.20383 to 403.32065, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 22s - loss: 403.3218 - MinusLogProbMetric: 403.3218 - val_loss: 403.3206 - val_MinusLogProbMetric: 403.3206 - lr: 3.3333e-04 - 22s/epoch - 110ms/step
Epoch 31/1000
2023-09-10 15:09:30.707 
Epoch 31/1000 
	 loss: 402.8376, MinusLogProbMetric: 402.8376, val_loss: 406.0225, val_MinusLogProbMetric: 406.0225

Epoch 31: val_loss did not improve from 403.32065
196/196 - 20s - loss: 402.8376 - MinusLogProbMetric: 402.8376 - val_loss: 406.0225 - val_MinusLogProbMetric: 406.0225 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 32/1000
2023-09-10 15:09:48.908 
Epoch 32/1000 
	 loss: 402.8104, MinusLogProbMetric: 402.8104, val_loss: 402.6909, val_MinusLogProbMetric: 402.6909

Epoch 32: val_loss improved from 403.32065 to 402.69095, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 402.8104 - MinusLogProbMetric: 402.8104 - val_loss: 402.6909 - val_MinusLogProbMetric: 402.6909 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 33/1000
2023-09-10 15:10:06.863 
Epoch 33/1000 
	 loss: 402.7329, MinusLogProbMetric: 402.7329, val_loss: 404.1302, val_MinusLogProbMetric: 404.1302

Epoch 33: val_loss did not improve from 402.69095
196/196 - 17s - loss: 402.7329 - MinusLogProbMetric: 402.7329 - val_loss: 404.1302 - val_MinusLogProbMetric: 404.1302 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 34/1000
2023-09-10 15:10:24.761 
Epoch 34/1000 
	 loss: 402.5889, MinusLogProbMetric: 402.5889, val_loss: 404.6530, val_MinusLogProbMetric: 404.6530

Epoch 34: val_loss did not improve from 402.69095
196/196 - 18s - loss: 402.5889 - MinusLogProbMetric: 402.5889 - val_loss: 404.6530 - val_MinusLogProbMetric: 404.6530 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 35/1000
2023-09-10 15:10:43.252 
Epoch 35/1000 
	 loss: 403.4407, MinusLogProbMetric: 403.4407, val_loss: 408.3777, val_MinusLogProbMetric: 408.3777

Epoch 35: val_loss did not improve from 402.69095
196/196 - 18s - loss: 403.4407 - MinusLogProbMetric: 403.4407 - val_loss: 408.3777 - val_MinusLogProbMetric: 408.3777 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 36/1000
2023-09-10 15:10:59.919 
Epoch 36/1000 
	 loss: 402.2110, MinusLogProbMetric: 402.2110, val_loss: 404.8537, val_MinusLogProbMetric: 404.8537

Epoch 36: val_loss did not improve from 402.69095
196/196 - 17s - loss: 402.2110 - MinusLogProbMetric: 402.2110 - val_loss: 404.8537 - val_MinusLogProbMetric: 404.8537 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 37/1000
2023-09-10 15:11:17.289 
Epoch 37/1000 
	 loss: 402.1529, MinusLogProbMetric: 402.1529, val_loss: 405.0024, val_MinusLogProbMetric: 405.0024

Epoch 37: val_loss did not improve from 402.69095
196/196 - 17s - loss: 402.1529 - MinusLogProbMetric: 402.1529 - val_loss: 405.0024 - val_MinusLogProbMetric: 405.0024 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 38/1000
2023-09-10 15:11:33.727 
Epoch 38/1000 
	 loss: 402.5602, MinusLogProbMetric: 402.5602, val_loss: 410.0419, val_MinusLogProbMetric: 410.0419

Epoch 38: val_loss did not improve from 402.69095
196/196 - 16s - loss: 402.5602 - MinusLogProbMetric: 402.5602 - val_loss: 410.0419 - val_MinusLogProbMetric: 410.0419 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 39/1000
2023-09-10 15:11:51.983 
Epoch 39/1000 
	 loss: 401.7950, MinusLogProbMetric: 401.7950, val_loss: 404.7382, val_MinusLogProbMetric: 404.7382

Epoch 39: val_loss did not improve from 402.69095
196/196 - 18s - loss: 401.7950 - MinusLogProbMetric: 401.7950 - val_loss: 404.7382 - val_MinusLogProbMetric: 404.7382 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 40/1000
2023-09-10 15:12:11.796 
Epoch 40/1000 
	 loss: 402.0635, MinusLogProbMetric: 402.0635, val_loss: 403.6560, val_MinusLogProbMetric: 403.6560

Epoch 40: val_loss did not improve from 402.69095
196/196 - 20s - loss: 402.0635 - MinusLogProbMetric: 402.0635 - val_loss: 403.6560 - val_MinusLogProbMetric: 403.6560 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 41/1000
2023-09-10 15:12:29.069 
Epoch 41/1000 
	 loss: 401.8920, MinusLogProbMetric: 401.8920, val_loss: 402.6126, val_MinusLogProbMetric: 402.6126

Epoch 41: val_loss improved from 402.69095 to 402.61258, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 401.8920 - MinusLogProbMetric: 401.8920 - val_loss: 402.6126 - val_MinusLogProbMetric: 402.6126 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 42/1000
2023-09-10 15:12:47.148 
Epoch 42/1000 
	 loss: 403.6017, MinusLogProbMetric: 403.6017, val_loss: 403.5548, val_MinusLogProbMetric: 403.5548

Epoch 42: val_loss did not improve from 402.61258
196/196 - 18s - loss: 403.6017 - MinusLogProbMetric: 403.6017 - val_loss: 403.5548 - val_MinusLogProbMetric: 403.5548 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 43/1000
2023-09-10 15:13:05.026 
Epoch 43/1000 
	 loss: 401.2096, MinusLogProbMetric: 401.2096, val_loss: 400.9670, val_MinusLogProbMetric: 400.9670

Epoch 43: val_loss improved from 402.61258 to 400.96698, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 401.2096 - MinusLogProbMetric: 401.2096 - val_loss: 400.9670 - val_MinusLogProbMetric: 400.9670 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 44/1000
2023-09-10 15:13:23.652 
Epoch 44/1000 
	 loss: 402.0592, MinusLogProbMetric: 402.0592, val_loss: 403.7440, val_MinusLogProbMetric: 403.7440

Epoch 44: val_loss did not improve from 400.96698
196/196 - 18s - loss: 402.0592 - MinusLogProbMetric: 402.0592 - val_loss: 403.7440 - val_MinusLogProbMetric: 403.7440 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 45/1000
2023-09-10 15:13:41.462 
Epoch 45/1000 
	 loss: 401.1974, MinusLogProbMetric: 401.1974, val_loss: 402.1053, val_MinusLogProbMetric: 402.1053

Epoch 45: val_loss did not improve from 400.96698
196/196 - 18s - loss: 401.1974 - MinusLogProbMetric: 401.1974 - val_loss: 402.1053 - val_MinusLogProbMetric: 402.1053 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 46/1000
2023-09-10 15:14:00.713 
Epoch 46/1000 
	 loss: 401.2239, MinusLogProbMetric: 401.2239, val_loss: 405.1311, val_MinusLogProbMetric: 405.1311

Epoch 46: val_loss did not improve from 400.96698
196/196 - 19s - loss: 401.2239 - MinusLogProbMetric: 401.2239 - val_loss: 405.1311 - val_MinusLogProbMetric: 405.1311 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 47/1000
2023-09-10 15:14:20.693 
Epoch 47/1000 
	 loss: 400.8354, MinusLogProbMetric: 400.8354, val_loss: 402.7230, val_MinusLogProbMetric: 402.7230

Epoch 47: val_loss did not improve from 400.96698
196/196 - 20s - loss: 400.8354 - MinusLogProbMetric: 400.8354 - val_loss: 402.7230 - val_MinusLogProbMetric: 402.7230 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 48/1000
2023-09-10 15:14:44.728 
Epoch 48/1000 
	 loss: 401.2589, MinusLogProbMetric: 401.2589, val_loss: 401.6487, val_MinusLogProbMetric: 401.6487

Epoch 48: val_loss did not improve from 400.96698
196/196 - 24s - loss: 401.2589 - MinusLogProbMetric: 401.2589 - val_loss: 401.6487 - val_MinusLogProbMetric: 401.6487 - lr: 3.3333e-04 - 24s/epoch - 123ms/step
Epoch 49/1000
2023-09-10 15:15:01.584 
Epoch 49/1000 
	 loss: 401.0632, MinusLogProbMetric: 401.0632, val_loss: 403.3935, val_MinusLogProbMetric: 403.3935

Epoch 49: val_loss did not improve from 400.96698
196/196 - 17s - loss: 401.0632 - MinusLogProbMetric: 401.0632 - val_loss: 403.3935 - val_MinusLogProbMetric: 403.3935 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 50/1000
2023-09-10 15:15:18.183 
Epoch 50/1000 
	 loss: 400.9286, MinusLogProbMetric: 400.9286, val_loss: 404.1623, val_MinusLogProbMetric: 404.1623

Epoch 50: val_loss did not improve from 400.96698
196/196 - 17s - loss: 400.9286 - MinusLogProbMetric: 400.9286 - val_loss: 404.1623 - val_MinusLogProbMetric: 404.1623 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 51/1000
2023-09-10 15:15:36.069 
Epoch 51/1000 
	 loss: 401.1118, MinusLogProbMetric: 401.1118, val_loss: 411.4345, val_MinusLogProbMetric: 411.4345

Epoch 51: val_loss did not improve from 400.96698
196/196 - 18s - loss: 401.1118 - MinusLogProbMetric: 401.1118 - val_loss: 411.4345 - val_MinusLogProbMetric: 411.4345 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 52/1000
2023-09-10 15:15:55.476 
Epoch 52/1000 
	 loss: 400.4453, MinusLogProbMetric: 400.4453, val_loss: 402.0867, val_MinusLogProbMetric: 402.0867

Epoch 52: val_loss did not improve from 400.96698
196/196 - 19s - loss: 400.4453 - MinusLogProbMetric: 400.4453 - val_loss: 402.0867 - val_MinusLogProbMetric: 402.0867 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 53/1000
2023-09-10 15:16:15.972 
Epoch 53/1000 
	 loss: 400.7401, MinusLogProbMetric: 400.7401, val_loss: 403.6655, val_MinusLogProbMetric: 403.6655

Epoch 53: val_loss did not improve from 400.96698
196/196 - 20s - loss: 400.7401 - MinusLogProbMetric: 400.7401 - val_loss: 403.6655 - val_MinusLogProbMetric: 403.6655 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 54/1000
2023-09-10 15:16:35.483 
Epoch 54/1000 
	 loss: 400.4925, MinusLogProbMetric: 400.4925, val_loss: 402.0372, val_MinusLogProbMetric: 402.0372

Epoch 54: val_loss did not improve from 400.96698
196/196 - 20s - loss: 400.4925 - MinusLogProbMetric: 400.4925 - val_loss: 402.0372 - val_MinusLogProbMetric: 402.0372 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 55/1000
2023-09-10 15:16:54.495 
Epoch 55/1000 
	 loss: 400.5246, MinusLogProbMetric: 400.5246, val_loss: 404.9782, val_MinusLogProbMetric: 404.9782

Epoch 55: val_loss did not improve from 400.96698
196/196 - 19s - loss: 400.5246 - MinusLogProbMetric: 400.5246 - val_loss: 404.9782 - val_MinusLogProbMetric: 404.9782 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 56/1000
2023-09-10 15:17:13.436 
Epoch 56/1000 
	 loss: 400.2293, MinusLogProbMetric: 400.2293, val_loss: 402.7786, val_MinusLogProbMetric: 402.7786

Epoch 56: val_loss did not improve from 400.96698
196/196 - 19s - loss: 400.2293 - MinusLogProbMetric: 400.2293 - val_loss: 402.7786 - val_MinusLogProbMetric: 402.7786 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 57/1000
2023-09-10 15:17:32.424 
Epoch 57/1000 
	 loss: 400.4097, MinusLogProbMetric: 400.4097, val_loss: 401.3487, val_MinusLogProbMetric: 401.3487

Epoch 57: val_loss did not improve from 400.96698
196/196 - 19s - loss: 400.4097 - MinusLogProbMetric: 400.4097 - val_loss: 401.3487 - val_MinusLogProbMetric: 401.3487 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 58/1000
2023-09-10 15:17:51.319 
Epoch 58/1000 
	 loss: 400.6532, MinusLogProbMetric: 400.6532, val_loss: 402.5758, val_MinusLogProbMetric: 402.5758

Epoch 58: val_loss did not improve from 400.96698
196/196 - 19s - loss: 400.6532 - MinusLogProbMetric: 400.6532 - val_loss: 402.5758 - val_MinusLogProbMetric: 402.5758 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 59/1000
2023-09-10 15:18:10.002 
Epoch 59/1000 
	 loss: 400.8419, MinusLogProbMetric: 400.8419, val_loss: 401.7148, val_MinusLogProbMetric: 401.7148

Epoch 59: val_loss did not improve from 400.96698
196/196 - 19s - loss: 400.8419 - MinusLogProbMetric: 400.8419 - val_loss: 401.7148 - val_MinusLogProbMetric: 401.7148 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 60/1000
2023-09-10 15:18:30.029 
Epoch 60/1000 
	 loss: 400.2120, MinusLogProbMetric: 400.2120, val_loss: 403.3340, val_MinusLogProbMetric: 403.3340

Epoch 60: val_loss did not improve from 400.96698
196/196 - 20s - loss: 400.2120 - MinusLogProbMetric: 400.2120 - val_loss: 403.3340 - val_MinusLogProbMetric: 403.3340 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 61/1000
2023-09-10 15:18:47.814 
Epoch 61/1000 
	 loss: 399.9481, MinusLogProbMetric: 399.9481, val_loss: 401.3744, val_MinusLogProbMetric: 401.3744

Epoch 61: val_loss did not improve from 400.96698
196/196 - 18s - loss: 399.9481 - MinusLogProbMetric: 399.9481 - val_loss: 401.3744 - val_MinusLogProbMetric: 401.3744 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 62/1000
2023-09-10 15:19:06.742 
Epoch 62/1000 
	 loss: 399.9189, MinusLogProbMetric: 399.9189, val_loss: 403.5131, val_MinusLogProbMetric: 403.5131

Epoch 62: val_loss did not improve from 400.96698
196/196 - 19s - loss: 399.9189 - MinusLogProbMetric: 399.9189 - val_loss: 403.5131 - val_MinusLogProbMetric: 403.5131 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 63/1000
2023-09-10 15:19:25.532 
Epoch 63/1000 
	 loss: 399.8156, MinusLogProbMetric: 399.8156, val_loss: 401.1476, val_MinusLogProbMetric: 401.1476

Epoch 63: val_loss did not improve from 400.96698
196/196 - 19s - loss: 399.8156 - MinusLogProbMetric: 399.8156 - val_loss: 401.1476 - val_MinusLogProbMetric: 401.1476 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 64/1000
2023-09-10 15:19:45.109 
Epoch 64/1000 
	 loss: 399.7020, MinusLogProbMetric: 399.7020, val_loss: 401.5585, val_MinusLogProbMetric: 401.5585

Epoch 64: val_loss did not improve from 400.96698
196/196 - 20s - loss: 399.7020 - MinusLogProbMetric: 399.7020 - val_loss: 401.5585 - val_MinusLogProbMetric: 401.5585 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 65/1000
2023-09-10 15:20:05.669 
Epoch 65/1000 
	 loss: 400.1739, MinusLogProbMetric: 400.1739, val_loss: 401.5824, val_MinusLogProbMetric: 401.5824

Epoch 65: val_loss did not improve from 400.96698
196/196 - 21s - loss: 400.1739 - MinusLogProbMetric: 400.1739 - val_loss: 401.5824 - val_MinusLogProbMetric: 401.5824 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 66/1000
2023-09-10 15:20:22.527 
Epoch 66/1000 
	 loss: 399.8708, MinusLogProbMetric: 399.8708, val_loss: 402.4840, val_MinusLogProbMetric: 402.4840

Epoch 66: val_loss did not improve from 400.96698
196/196 - 17s - loss: 399.8708 - MinusLogProbMetric: 399.8708 - val_loss: 402.4840 - val_MinusLogProbMetric: 402.4840 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 67/1000
2023-09-10 15:20:40.107 
Epoch 67/1000 
	 loss: 400.3867, MinusLogProbMetric: 400.3867, val_loss: 402.8631, val_MinusLogProbMetric: 402.8631

Epoch 67: val_loss did not improve from 400.96698
196/196 - 18s - loss: 400.3867 - MinusLogProbMetric: 400.3867 - val_loss: 402.8631 - val_MinusLogProbMetric: 402.8631 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 68/1000
2023-09-10 15:20:58.580 
Epoch 68/1000 
	 loss: 399.6912, MinusLogProbMetric: 399.6912, val_loss: 400.9690, val_MinusLogProbMetric: 400.9690

Epoch 68: val_loss did not improve from 400.96698
196/196 - 18s - loss: 399.6912 - MinusLogProbMetric: 399.6912 - val_loss: 400.9690 - val_MinusLogProbMetric: 400.9690 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 69/1000
2023-09-10 15:21:17.341 
Epoch 69/1000 
	 loss: 399.4240, MinusLogProbMetric: 399.4240, val_loss: 401.6855, val_MinusLogProbMetric: 401.6855

Epoch 69: val_loss did not improve from 400.96698
196/196 - 19s - loss: 399.4240 - MinusLogProbMetric: 399.4240 - val_loss: 401.6855 - val_MinusLogProbMetric: 401.6855 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 70/1000
2023-09-10 15:21:35.012 
Epoch 70/1000 
	 loss: 399.5412, MinusLogProbMetric: 399.5412, val_loss: 399.9355, val_MinusLogProbMetric: 399.9355

Epoch 70: val_loss improved from 400.96698 to 399.93546, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 18s - loss: 399.5412 - MinusLogProbMetric: 399.5412 - val_loss: 399.9355 - val_MinusLogProbMetric: 399.9355 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 71/1000
2023-09-10 15:21:52.867 
Epoch 71/1000 
	 loss: 399.5088, MinusLogProbMetric: 399.5088, val_loss: 400.9819, val_MinusLogProbMetric: 400.9819

Epoch 71: val_loss did not improve from 399.93546
196/196 - 17s - loss: 399.5088 - MinusLogProbMetric: 399.5088 - val_loss: 400.9819 - val_MinusLogProbMetric: 400.9819 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 72/1000
2023-09-10 15:22:10.107 
Epoch 72/1000 
	 loss: 399.2818, MinusLogProbMetric: 399.2818, val_loss: 402.7592, val_MinusLogProbMetric: 402.7592

Epoch 72: val_loss did not improve from 399.93546
196/196 - 17s - loss: 399.2818 - MinusLogProbMetric: 399.2818 - val_loss: 402.7592 - val_MinusLogProbMetric: 402.7592 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 73/1000
2023-09-10 15:22:28.492 
Epoch 73/1000 
	 loss: 399.5051, MinusLogProbMetric: 399.5051, val_loss: 402.8225, val_MinusLogProbMetric: 402.8225

Epoch 73: val_loss did not improve from 399.93546
196/196 - 18s - loss: 399.5051 - MinusLogProbMetric: 399.5051 - val_loss: 402.8225 - val_MinusLogProbMetric: 402.8225 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 74/1000
2023-09-10 15:22:47.095 
Epoch 74/1000 
	 loss: 399.4581, MinusLogProbMetric: 399.4581, val_loss: 401.1965, val_MinusLogProbMetric: 401.1965

Epoch 74: val_loss did not improve from 399.93546
196/196 - 19s - loss: 399.4581 - MinusLogProbMetric: 399.4581 - val_loss: 401.1965 - val_MinusLogProbMetric: 401.1965 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 75/1000
2023-09-10 15:23:06.849 
Epoch 75/1000 
	 loss: 399.0504, MinusLogProbMetric: 399.0504, val_loss: 402.4150, val_MinusLogProbMetric: 402.4150

Epoch 75: val_loss did not improve from 399.93546
196/196 - 20s - loss: 399.0504 - MinusLogProbMetric: 399.0504 - val_loss: 402.4150 - val_MinusLogProbMetric: 402.4150 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 76/1000
2023-09-10 15:23:25.020 
Epoch 76/1000 
	 loss: 399.6653, MinusLogProbMetric: 399.6653, val_loss: 401.2299, val_MinusLogProbMetric: 401.2299

Epoch 76: val_loss did not improve from 399.93546
196/196 - 18s - loss: 399.6653 - MinusLogProbMetric: 399.6653 - val_loss: 401.2299 - val_MinusLogProbMetric: 401.2299 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 77/1000
2023-09-10 15:23:43.051 
Epoch 77/1000 
	 loss: 399.2651, MinusLogProbMetric: 399.2651, val_loss: 403.7281, val_MinusLogProbMetric: 403.7281

Epoch 77: val_loss did not improve from 399.93546
196/196 - 18s - loss: 399.2651 - MinusLogProbMetric: 399.2651 - val_loss: 403.7281 - val_MinusLogProbMetric: 403.7281 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 78/1000
2023-09-10 15:24:02.075 
Epoch 78/1000 
	 loss: 399.2560, MinusLogProbMetric: 399.2560, val_loss: 401.4616, val_MinusLogProbMetric: 401.4616

Epoch 78: val_loss did not improve from 399.93546
196/196 - 19s - loss: 399.2560 - MinusLogProbMetric: 399.2560 - val_loss: 401.4616 - val_MinusLogProbMetric: 401.4616 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 79/1000
2023-09-10 15:24:21.336 
Epoch 79/1000 
	 loss: 398.5223, MinusLogProbMetric: 398.5223, val_loss: 402.5379, val_MinusLogProbMetric: 402.5379

Epoch 79: val_loss did not improve from 399.93546
196/196 - 19s - loss: 398.5223 - MinusLogProbMetric: 398.5223 - val_loss: 402.5379 - val_MinusLogProbMetric: 402.5379 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 80/1000
2023-09-10 15:24:39.053 
Epoch 80/1000 
	 loss: 399.0142, MinusLogProbMetric: 399.0142, val_loss: 400.4594, val_MinusLogProbMetric: 400.4594

Epoch 80: val_loss did not improve from 399.93546
196/196 - 18s - loss: 399.0142 - MinusLogProbMetric: 399.0142 - val_loss: 400.4594 - val_MinusLogProbMetric: 400.4594 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 81/1000
2023-09-10 15:24:57.953 
Epoch 81/1000 
	 loss: 399.3174, MinusLogProbMetric: 399.3174, val_loss: 400.8199, val_MinusLogProbMetric: 400.8199

Epoch 81: val_loss did not improve from 399.93546
196/196 - 19s - loss: 399.3174 - MinusLogProbMetric: 399.3174 - val_loss: 400.8199 - val_MinusLogProbMetric: 400.8199 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 82/1000
2023-09-10 15:25:14.978 
Epoch 82/1000 
	 loss: 398.6983, MinusLogProbMetric: 398.6983, val_loss: 400.7247, val_MinusLogProbMetric: 400.7247

Epoch 82: val_loss did not improve from 399.93546
196/196 - 17s - loss: 398.6983 - MinusLogProbMetric: 398.6983 - val_loss: 400.7247 - val_MinusLogProbMetric: 400.7247 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 83/1000
2023-09-10 15:25:33.231 
Epoch 83/1000 
	 loss: 398.9614, MinusLogProbMetric: 398.9614, val_loss: 400.3434, val_MinusLogProbMetric: 400.3434

Epoch 83: val_loss did not improve from 399.93546
196/196 - 18s - loss: 398.9614 - MinusLogProbMetric: 398.9614 - val_loss: 400.3434 - val_MinusLogProbMetric: 400.3434 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 84/1000
2023-09-10 15:25:51.462 
Epoch 84/1000 
	 loss: 398.4871, MinusLogProbMetric: 398.4871, val_loss: 406.2895, val_MinusLogProbMetric: 406.2895

Epoch 84: val_loss did not improve from 399.93546
196/196 - 18s - loss: 398.4871 - MinusLogProbMetric: 398.4871 - val_loss: 406.2895 - val_MinusLogProbMetric: 406.2895 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 85/1000
2023-09-10 15:26:10.089 
Epoch 85/1000 
	 loss: 398.9356, MinusLogProbMetric: 398.9356, val_loss: 402.0212, val_MinusLogProbMetric: 402.0212

Epoch 85: val_loss did not improve from 399.93546
196/196 - 19s - loss: 398.9356 - MinusLogProbMetric: 398.9356 - val_loss: 402.0212 - val_MinusLogProbMetric: 402.0212 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 86/1000
2023-09-10 15:26:28.682 
Epoch 86/1000 
	 loss: 398.5216, MinusLogProbMetric: 398.5216, val_loss: 401.9330, val_MinusLogProbMetric: 401.9330

Epoch 86: val_loss did not improve from 399.93546
196/196 - 19s - loss: 398.5216 - MinusLogProbMetric: 398.5216 - val_loss: 401.9330 - val_MinusLogProbMetric: 401.9330 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 87/1000
2023-09-10 15:26:46.955 
Epoch 87/1000 
	 loss: 398.6044, MinusLogProbMetric: 398.6044, val_loss: 400.6478, val_MinusLogProbMetric: 400.6478

Epoch 87: val_loss did not improve from 399.93546
196/196 - 18s - loss: 398.6044 - MinusLogProbMetric: 398.6044 - val_loss: 400.6478 - val_MinusLogProbMetric: 400.6478 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 88/1000
2023-09-10 15:27:05.427 
Epoch 88/1000 
	 loss: 399.1066, MinusLogProbMetric: 399.1066, val_loss: 400.6643, val_MinusLogProbMetric: 400.6643

Epoch 88: val_loss did not improve from 399.93546
196/196 - 18s - loss: 399.1066 - MinusLogProbMetric: 399.1066 - val_loss: 400.6643 - val_MinusLogProbMetric: 400.6643 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 89/1000
2023-09-10 15:27:25.187 
Epoch 89/1000 
	 loss: 399.6300, MinusLogProbMetric: 399.6300, val_loss: 403.2355, val_MinusLogProbMetric: 403.2355

Epoch 89: val_loss did not improve from 399.93546
196/196 - 20s - loss: 399.6300 - MinusLogProbMetric: 399.6300 - val_loss: 403.2355 - val_MinusLogProbMetric: 403.2355 - lr: 3.3333e-04 - 20s/epoch - 101ms/step
Epoch 90/1000
2023-09-10 15:27:42.427 
Epoch 90/1000 
	 loss: 397.8637, MinusLogProbMetric: 397.8637, val_loss: 402.9283, val_MinusLogProbMetric: 402.9283

Epoch 90: val_loss did not improve from 399.93546
196/196 - 17s - loss: 397.8637 - MinusLogProbMetric: 397.8637 - val_loss: 402.9283 - val_MinusLogProbMetric: 402.9283 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 91/1000
2023-09-10 15:28:01.976 
Epoch 91/1000 
	 loss: 398.2232, MinusLogProbMetric: 398.2232, val_loss: 399.5902, val_MinusLogProbMetric: 399.5902

Epoch 91: val_loss improved from 399.93546 to 399.59018, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 20s - loss: 398.2232 - MinusLogProbMetric: 398.2232 - val_loss: 399.5902 - val_MinusLogProbMetric: 399.5902 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 92/1000
2023-09-10 15:28:22.417 
Epoch 92/1000 
	 loss: 398.7971, MinusLogProbMetric: 398.7971, val_loss: 402.2585, val_MinusLogProbMetric: 402.2585

Epoch 92: val_loss did not improve from 399.59018
196/196 - 20s - loss: 398.7971 - MinusLogProbMetric: 398.7971 - val_loss: 402.2585 - val_MinusLogProbMetric: 402.2585 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 93/1000
2023-09-10 15:28:40.828 
Epoch 93/1000 
	 loss: 398.1814, MinusLogProbMetric: 398.1814, val_loss: 403.3127, val_MinusLogProbMetric: 403.3127

Epoch 93: val_loss did not improve from 399.59018
196/196 - 18s - loss: 398.1814 - MinusLogProbMetric: 398.1814 - val_loss: 403.3127 - val_MinusLogProbMetric: 403.3127 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 94/1000
2023-09-10 15:28:59.828 
Epoch 94/1000 
	 loss: 398.4279, MinusLogProbMetric: 398.4279, val_loss: 403.1683, val_MinusLogProbMetric: 403.1683

Epoch 94: val_loss did not improve from 399.59018
196/196 - 19s - loss: 398.4279 - MinusLogProbMetric: 398.4279 - val_loss: 403.1683 - val_MinusLogProbMetric: 403.1683 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 95/1000
2023-09-10 15:29:18.328 
Epoch 95/1000 
	 loss: 397.6392, MinusLogProbMetric: 397.6392, val_loss: 399.9468, val_MinusLogProbMetric: 399.9468

Epoch 95: val_loss did not improve from 399.59018
196/196 - 19s - loss: 397.6392 - MinusLogProbMetric: 397.6392 - val_loss: 399.9468 - val_MinusLogProbMetric: 399.9468 - lr: 3.3333e-04 - 19s/epoch - 94ms/step
Epoch 96/1000
2023-09-10 15:29:35.847 
Epoch 96/1000 
	 loss: 398.0616, MinusLogProbMetric: 398.0616, val_loss: 401.7057, val_MinusLogProbMetric: 401.7057

Epoch 96: val_loss did not improve from 399.59018
196/196 - 18s - loss: 398.0616 - MinusLogProbMetric: 398.0616 - val_loss: 401.7057 - val_MinusLogProbMetric: 401.7057 - lr: 3.3333e-04 - 18s/epoch - 89ms/step
Epoch 97/1000
2023-09-10 15:29:54.369 
Epoch 97/1000 
	 loss: 398.0578, MinusLogProbMetric: 398.0578, val_loss: 400.2358, val_MinusLogProbMetric: 400.2358

Epoch 97: val_loss did not improve from 399.59018
196/196 - 19s - loss: 398.0578 - MinusLogProbMetric: 398.0578 - val_loss: 400.2358 - val_MinusLogProbMetric: 400.2358 - lr: 3.3333e-04 - 19s/epoch - 94ms/step
Epoch 98/1000
2023-09-10 15:30:13.715 
Epoch 98/1000 
	 loss: 398.1703, MinusLogProbMetric: 398.1703, val_loss: 399.1532, val_MinusLogProbMetric: 399.1532

Epoch 98: val_loss improved from 399.59018 to 399.15317, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 20s - loss: 398.1703 - MinusLogProbMetric: 398.1703 - val_loss: 399.1532 - val_MinusLogProbMetric: 399.1532 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 99/1000
2023-09-10 15:30:33.182 
Epoch 99/1000 
	 loss: 399.1346, MinusLogProbMetric: 399.1346, val_loss: 400.5638, val_MinusLogProbMetric: 400.5638

Epoch 99: val_loss did not improve from 399.15317
196/196 - 19s - loss: 399.1346 - MinusLogProbMetric: 399.1346 - val_loss: 400.5638 - val_MinusLogProbMetric: 400.5638 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 100/1000
2023-09-10 15:30:50.244 
Epoch 100/1000 
	 loss: 397.4121, MinusLogProbMetric: 397.4121, val_loss: 399.2104, val_MinusLogProbMetric: 399.2104

Epoch 100: val_loss did not improve from 399.15317
196/196 - 17s - loss: 397.4121 - MinusLogProbMetric: 397.4121 - val_loss: 399.2104 - val_MinusLogProbMetric: 399.2104 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 101/1000
2023-09-10 15:31:08.334 
Epoch 101/1000 
	 loss: 398.3931, MinusLogProbMetric: 398.3931, val_loss: 400.2158, val_MinusLogProbMetric: 400.2158

Epoch 101: val_loss did not improve from 399.15317
196/196 - 18s - loss: 398.3931 - MinusLogProbMetric: 398.3931 - val_loss: 400.2158 - val_MinusLogProbMetric: 400.2158 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 102/1000
2023-09-10 15:31:28.400 
Epoch 102/1000 
	 loss: 397.6286, MinusLogProbMetric: 397.6286, val_loss: 404.9300, val_MinusLogProbMetric: 404.9300

Epoch 102: val_loss did not improve from 399.15317
196/196 - 20s - loss: 397.6286 - MinusLogProbMetric: 397.6286 - val_loss: 404.9300 - val_MinusLogProbMetric: 404.9300 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 103/1000
2023-09-10 15:31:46.403 
Epoch 103/1000 
	 loss: 397.7385, MinusLogProbMetric: 397.7385, val_loss: 401.3661, val_MinusLogProbMetric: 401.3661

Epoch 103: val_loss did not improve from 399.15317
196/196 - 18s - loss: 397.7385 - MinusLogProbMetric: 397.7385 - val_loss: 401.3661 - val_MinusLogProbMetric: 401.3661 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 104/1000
2023-09-10 15:32:04.028 
Epoch 104/1000 
	 loss: 397.6255, MinusLogProbMetric: 397.6255, val_loss: 401.2329, val_MinusLogProbMetric: 401.2329

Epoch 104: val_loss did not improve from 399.15317
196/196 - 18s - loss: 397.6255 - MinusLogProbMetric: 397.6255 - val_loss: 401.2329 - val_MinusLogProbMetric: 401.2329 - lr: 3.3333e-04 - 18s/epoch - 90ms/step
Epoch 105/1000
2023-09-10 15:32:23.566 
Epoch 105/1000 
	 loss: 397.6515, MinusLogProbMetric: 397.6515, val_loss: 400.9109, val_MinusLogProbMetric: 400.9109

Epoch 105: val_loss did not improve from 399.15317
196/196 - 20s - loss: 397.6515 - MinusLogProbMetric: 397.6515 - val_loss: 400.9109 - val_MinusLogProbMetric: 400.9109 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 106/1000
2023-09-10 15:32:41.691 
Epoch 106/1000 
	 loss: 397.6383, MinusLogProbMetric: 397.6383, val_loss: 402.0111, val_MinusLogProbMetric: 402.0111

Epoch 106: val_loss did not improve from 399.15317
196/196 - 18s - loss: 397.6383 - MinusLogProbMetric: 397.6383 - val_loss: 402.0111 - val_MinusLogProbMetric: 402.0111 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 107/1000
2023-09-10 15:33:00.949 
Epoch 107/1000 
	 loss: 397.4824, MinusLogProbMetric: 397.4824, val_loss: 401.2753, val_MinusLogProbMetric: 401.2753

Epoch 107: val_loss did not improve from 399.15317
196/196 - 19s - loss: 397.4824 - MinusLogProbMetric: 397.4824 - val_loss: 401.2753 - val_MinusLogProbMetric: 401.2753 - lr: 3.3333e-04 - 19s/epoch - 98ms/step
Epoch 108/1000
2023-09-10 15:33:21.512 
Epoch 108/1000 
	 loss: 399.3592, MinusLogProbMetric: 399.3592, val_loss: 400.3253, val_MinusLogProbMetric: 400.3253

Epoch 108: val_loss did not improve from 399.15317
196/196 - 21s - loss: 399.3592 - MinusLogProbMetric: 399.3592 - val_loss: 400.3253 - val_MinusLogProbMetric: 400.3253 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 109/1000
2023-09-10 15:33:39.745 
Epoch 109/1000 
	 loss: 396.8313, MinusLogProbMetric: 396.8313, val_loss: 401.4491, val_MinusLogProbMetric: 401.4491

Epoch 109: val_loss did not improve from 399.15317
196/196 - 18s - loss: 396.8313 - MinusLogProbMetric: 396.8313 - val_loss: 401.4491 - val_MinusLogProbMetric: 401.4491 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 110/1000
2023-09-10 15:33:58.486 
Epoch 110/1000 
	 loss: 397.6635, MinusLogProbMetric: 397.6635, val_loss: 399.2149, val_MinusLogProbMetric: 399.2149

Epoch 110: val_loss did not improve from 399.15317
196/196 - 19s - loss: 397.6635 - MinusLogProbMetric: 397.6635 - val_loss: 399.2149 - val_MinusLogProbMetric: 399.2149 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 111/1000
2023-09-10 15:34:17.426 
Epoch 111/1000 
	 loss: 397.7930, MinusLogProbMetric: 397.7930, val_loss: 401.2102, val_MinusLogProbMetric: 401.2102

Epoch 111: val_loss did not improve from 399.15317
196/196 - 19s - loss: 397.7930 - MinusLogProbMetric: 397.7930 - val_loss: 401.2102 - val_MinusLogProbMetric: 401.2102 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 112/1000
2023-09-10 15:34:35.920 
Epoch 112/1000 
	 loss: 397.0081, MinusLogProbMetric: 397.0081, val_loss: 400.4619, val_MinusLogProbMetric: 400.4619

Epoch 112: val_loss did not improve from 399.15317
196/196 - 18s - loss: 397.0081 - MinusLogProbMetric: 397.0081 - val_loss: 400.4619 - val_MinusLogProbMetric: 400.4619 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 113/1000
2023-09-10 15:34:56.048 
Epoch 113/1000 
	 loss: 397.1119, MinusLogProbMetric: 397.1119, val_loss: 402.8199, val_MinusLogProbMetric: 402.8199

Epoch 113: val_loss did not improve from 399.15317
196/196 - 20s - loss: 397.1119 - MinusLogProbMetric: 397.1119 - val_loss: 402.8199 - val_MinusLogProbMetric: 402.8199 - lr: 3.3333e-04 - 20s/epoch - 103ms/step
Epoch 114/1000
2023-09-10 15:35:13.476 
Epoch 114/1000 
	 loss: 397.1268, MinusLogProbMetric: 397.1268, val_loss: 399.7673, val_MinusLogProbMetric: 399.7673

Epoch 114: val_loss did not improve from 399.15317
196/196 - 17s - loss: 397.1268 - MinusLogProbMetric: 397.1268 - val_loss: 399.7673 - val_MinusLogProbMetric: 399.7673 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 115/1000
2023-09-10 15:35:32.295 
Epoch 115/1000 
	 loss: 397.4273, MinusLogProbMetric: 397.4273, val_loss: 399.6868, val_MinusLogProbMetric: 399.6868

Epoch 115: val_loss did not improve from 399.15317
196/196 - 19s - loss: 397.4273 - MinusLogProbMetric: 397.4273 - val_loss: 399.6868 - val_MinusLogProbMetric: 399.6868 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 116/1000
2023-09-10 15:35:51.269 
Epoch 116/1000 
	 loss: 397.1447, MinusLogProbMetric: 397.1447, val_loss: 401.3741, val_MinusLogProbMetric: 401.3741

Epoch 116: val_loss did not improve from 399.15317
196/196 - 19s - loss: 397.1447 - MinusLogProbMetric: 397.1447 - val_loss: 401.3741 - val_MinusLogProbMetric: 401.3741 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 117/1000
2023-09-10 15:36:11.188 
Epoch 117/1000 
	 loss: 397.5809, MinusLogProbMetric: 397.5809, val_loss: 400.6359, val_MinusLogProbMetric: 400.6359

Epoch 117: val_loss did not improve from 399.15317
196/196 - 20s - loss: 397.5809 - MinusLogProbMetric: 397.5809 - val_loss: 400.6359 - val_MinusLogProbMetric: 400.6359 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 118/1000
2023-09-10 15:36:33.535 
Epoch 118/1000 
	 loss: 396.6932, MinusLogProbMetric: 396.6932, val_loss: 406.2382, val_MinusLogProbMetric: 406.2382

Epoch 118: val_loss did not improve from 399.15317
196/196 - 22s - loss: 396.6932 - MinusLogProbMetric: 396.6932 - val_loss: 406.2382 - val_MinusLogProbMetric: 406.2382 - lr: 3.3333e-04 - 22s/epoch - 114ms/step
Epoch 119/1000
2023-09-10 15:36:53.865 
Epoch 119/1000 
	 loss: 396.9177, MinusLogProbMetric: 396.9177, val_loss: 405.9421, val_MinusLogProbMetric: 405.9421

Epoch 119: val_loss did not improve from 399.15317
196/196 - 20s - loss: 396.9177 - MinusLogProbMetric: 396.9177 - val_loss: 405.9421 - val_MinusLogProbMetric: 405.9421 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 120/1000
2023-09-10 15:37:12.893 
Epoch 120/1000 
	 loss: 396.8923, MinusLogProbMetric: 396.8923, val_loss: 399.2695, val_MinusLogProbMetric: 399.2695

Epoch 120: val_loss did not improve from 399.15317
196/196 - 19s - loss: 396.8923 - MinusLogProbMetric: 396.8923 - val_loss: 399.2695 - val_MinusLogProbMetric: 399.2695 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 121/1000
2023-09-10 15:37:29.931 
Epoch 121/1000 
	 loss: 397.0870, MinusLogProbMetric: 397.0870, val_loss: 401.5093, val_MinusLogProbMetric: 401.5093

Epoch 121: val_loss did not improve from 399.15317
196/196 - 17s - loss: 397.0870 - MinusLogProbMetric: 397.0870 - val_loss: 401.5093 - val_MinusLogProbMetric: 401.5093 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 122/1000
2023-09-10 15:37:50.310 
Epoch 122/1000 
	 loss: 396.7733, MinusLogProbMetric: 396.7733, val_loss: 399.9366, val_MinusLogProbMetric: 399.9366

Epoch 122: val_loss did not improve from 399.15317
196/196 - 20s - loss: 396.7733 - MinusLogProbMetric: 396.7733 - val_loss: 399.9366 - val_MinusLogProbMetric: 399.9366 - lr: 3.3333e-04 - 20s/epoch - 104ms/step
Epoch 123/1000
2023-09-10 15:38:08.281 
Epoch 123/1000 
	 loss: 397.9906, MinusLogProbMetric: 397.9906, val_loss: 398.6276, val_MinusLogProbMetric: 398.6276

Epoch 123: val_loss improved from 399.15317 to 398.62759, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 19s - loss: 397.9906 - MinusLogProbMetric: 397.9906 - val_loss: 398.6276 - val_MinusLogProbMetric: 398.6276 - lr: 3.3333e-04 - 19s/epoch - 96ms/step
Epoch 124/1000
2023-09-10 15:38:27.631 
Epoch 124/1000 
	 loss: 396.8058, MinusLogProbMetric: 396.8058, val_loss: 408.3770, val_MinusLogProbMetric: 408.3770

Epoch 124: val_loss did not improve from 398.62759
196/196 - 19s - loss: 396.8058 - MinusLogProbMetric: 396.8058 - val_loss: 408.3770 - val_MinusLogProbMetric: 408.3770 - lr: 3.3333e-04 - 19s/epoch - 95ms/step
Epoch 125/1000
2023-09-10 15:38:47.645 
Epoch 125/1000 
	 loss: 396.8049, MinusLogProbMetric: 396.8049, val_loss: 399.4289, val_MinusLogProbMetric: 399.4289

Epoch 125: val_loss did not improve from 398.62759
196/196 - 20s - loss: 396.8049 - MinusLogProbMetric: 396.8049 - val_loss: 399.4289 - val_MinusLogProbMetric: 399.4289 - lr: 3.3333e-04 - 20s/epoch - 102ms/step
Epoch 126/1000
2023-09-10 15:39:05.824 
Epoch 126/1000 
	 loss: 396.6716, MinusLogProbMetric: 396.6716, val_loss: 401.0234, val_MinusLogProbMetric: 401.0234

Epoch 126: val_loss did not improve from 398.62759
196/196 - 18s - loss: 396.6716 - MinusLogProbMetric: 396.6716 - val_loss: 401.0234 - val_MinusLogProbMetric: 401.0234 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 127/1000
2023-09-10 15:39:25.167 
Epoch 127/1000 
	 loss: 396.7614, MinusLogProbMetric: 396.7614, val_loss: 400.0451, val_MinusLogProbMetric: 400.0451

Epoch 127: val_loss did not improve from 398.62759
196/196 - 19s - loss: 396.7614 - MinusLogProbMetric: 396.7614 - val_loss: 400.0451 - val_MinusLogProbMetric: 400.0451 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 128/1000
2023-09-10 15:39:44.163 
Epoch 128/1000 
	 loss: 397.1517, MinusLogProbMetric: 397.1517, val_loss: 399.7659, val_MinusLogProbMetric: 399.7659

Epoch 128: val_loss did not improve from 398.62759
196/196 - 19s - loss: 397.1517 - MinusLogProbMetric: 397.1517 - val_loss: 399.7659 - val_MinusLogProbMetric: 399.7659 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 129/1000
2023-09-10 15:40:03.843 
Epoch 129/1000 
	 loss: 396.9661, MinusLogProbMetric: 396.9661, val_loss: 400.7641, val_MinusLogProbMetric: 400.7641

Epoch 129: val_loss did not improve from 398.62759
196/196 - 20s - loss: 396.9661 - MinusLogProbMetric: 396.9661 - val_loss: 400.7641 - val_MinusLogProbMetric: 400.7641 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 130/1000
2023-09-10 15:40:20.438 
Epoch 130/1000 
	 loss: 396.6237, MinusLogProbMetric: 396.6237, val_loss: 405.6869, val_MinusLogProbMetric: 405.6869

Epoch 130: val_loss did not improve from 398.62759
196/196 - 17s - loss: 396.6237 - MinusLogProbMetric: 396.6237 - val_loss: 405.6869 - val_MinusLogProbMetric: 405.6869 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 131/1000
2023-09-10 15:40:45.225 
Epoch 131/1000 
	 loss: 397.2581, MinusLogProbMetric: 397.2581, val_loss: 398.8631, val_MinusLogProbMetric: 398.8631

Epoch 131: val_loss did not improve from 398.62759
196/196 - 25s - loss: 397.2581 - MinusLogProbMetric: 397.2581 - val_loss: 398.8631 - val_MinusLogProbMetric: 398.8631 - lr: 3.3333e-04 - 25s/epoch - 127ms/step
Epoch 132/1000
2023-09-10 15:41:15.355 
Epoch 132/1000 
	 loss: 396.4747, MinusLogProbMetric: 396.4747, val_loss: 399.1632, val_MinusLogProbMetric: 399.1632

Epoch 132: val_loss did not improve from 398.62759
196/196 - 30s - loss: 396.4747 - MinusLogProbMetric: 396.4747 - val_loss: 399.1632 - val_MinusLogProbMetric: 399.1632 - lr: 3.3333e-04 - 30s/epoch - 154ms/step
Epoch 133/1000
2023-09-10 15:41:49.937 
Epoch 133/1000 
	 loss: 396.4552, MinusLogProbMetric: 396.4552, val_loss: 402.8302, val_MinusLogProbMetric: 402.8302

Epoch 133: val_loss did not improve from 398.62759
196/196 - 35s - loss: 396.4552 - MinusLogProbMetric: 396.4552 - val_loss: 402.8302 - val_MinusLogProbMetric: 402.8302 - lr: 3.3333e-04 - 35s/epoch - 176ms/step
Epoch 134/1000
2023-09-10 15:42:20.775 
Epoch 134/1000 
	 loss: 396.3995, MinusLogProbMetric: 396.3995, val_loss: 399.5259, val_MinusLogProbMetric: 399.5259

Epoch 134: val_loss did not improve from 398.62759
196/196 - 31s - loss: 396.3995 - MinusLogProbMetric: 396.3995 - val_loss: 399.5259 - val_MinusLogProbMetric: 399.5259 - lr: 3.3333e-04 - 31s/epoch - 157ms/step
Epoch 135/1000
2023-09-10 15:42:56.916 
Epoch 135/1000 
	 loss: 396.4796, MinusLogProbMetric: 396.4796, val_loss: 405.4264, val_MinusLogProbMetric: 405.4264

Epoch 135: val_loss did not improve from 398.62759
196/196 - 36s - loss: 396.4796 - MinusLogProbMetric: 396.4796 - val_loss: 405.4264 - val_MinusLogProbMetric: 405.4264 - lr: 3.3333e-04 - 36s/epoch - 184ms/step
Epoch 136/1000
2023-09-10 15:43:31.739 
Epoch 136/1000 
	 loss: 397.0275, MinusLogProbMetric: 397.0275, val_loss: 399.5190, val_MinusLogProbMetric: 399.5190

Epoch 136: val_loss did not improve from 398.62759
196/196 - 35s - loss: 397.0275 - MinusLogProbMetric: 397.0275 - val_loss: 399.5190 - val_MinusLogProbMetric: 399.5190 - lr: 3.3333e-04 - 35s/epoch - 178ms/step
Epoch 137/1000
2023-09-10 15:44:10.229 
Epoch 137/1000 
	 loss: 396.0070, MinusLogProbMetric: 396.0070, val_loss: 402.5988, val_MinusLogProbMetric: 402.5988

Epoch 137: val_loss did not improve from 398.62759
196/196 - 38s - loss: 396.0070 - MinusLogProbMetric: 396.0070 - val_loss: 402.5988 - val_MinusLogProbMetric: 402.5988 - lr: 3.3333e-04 - 38s/epoch - 196ms/step
Epoch 138/1000
2023-09-10 15:44:45.697 
Epoch 138/1000 
	 loss: 396.9041, MinusLogProbMetric: 396.9041, val_loss: 399.0162, val_MinusLogProbMetric: 399.0162

Epoch 138: val_loss did not improve from 398.62759
196/196 - 35s - loss: 396.9041 - MinusLogProbMetric: 396.9041 - val_loss: 399.0162 - val_MinusLogProbMetric: 399.0162 - lr: 3.3333e-04 - 35s/epoch - 181ms/step
Epoch 139/1000
2023-09-10 15:45:21.994 
Epoch 139/1000 
	 loss: 396.0455, MinusLogProbMetric: 396.0455, val_loss: 399.5125, val_MinusLogProbMetric: 399.5125

Epoch 139: val_loss did not improve from 398.62759
196/196 - 36s - loss: 396.0455 - MinusLogProbMetric: 396.0455 - val_loss: 399.5125 - val_MinusLogProbMetric: 399.5125 - lr: 3.3333e-04 - 36s/epoch - 185ms/step
Epoch 140/1000
2023-09-10 15:45:59.373 
Epoch 140/1000 
	 loss: 396.6559, MinusLogProbMetric: 396.6559, val_loss: 400.3572, val_MinusLogProbMetric: 400.3572

Epoch 140: val_loss did not improve from 398.62759
196/196 - 37s - loss: 396.6559 - MinusLogProbMetric: 396.6559 - val_loss: 400.3572 - val_MinusLogProbMetric: 400.3572 - lr: 3.3333e-04 - 37s/epoch - 191ms/step
Epoch 141/1000
2023-09-10 15:46:32.966 
Epoch 141/1000 
	 loss: 396.7325, MinusLogProbMetric: 396.7325, val_loss: 399.6101, val_MinusLogProbMetric: 399.6101

Epoch 141: val_loss did not improve from 398.62759
196/196 - 34s - loss: 396.7325 - MinusLogProbMetric: 396.7325 - val_loss: 399.6101 - val_MinusLogProbMetric: 399.6101 - lr: 3.3333e-04 - 34s/epoch - 171ms/step
Epoch 142/1000
2023-09-10 15:47:06.146 
Epoch 142/1000 
	 loss: 396.3372, MinusLogProbMetric: 396.3372, val_loss: 399.7345, val_MinusLogProbMetric: 399.7345

Epoch 142: val_loss did not improve from 398.62759
196/196 - 33s - loss: 396.3372 - MinusLogProbMetric: 396.3372 - val_loss: 399.7345 - val_MinusLogProbMetric: 399.7345 - lr: 3.3333e-04 - 33s/epoch - 169ms/step
Epoch 143/1000
2023-09-10 15:47:44.881 
Epoch 143/1000 
	 loss: 396.3758, MinusLogProbMetric: 396.3758, val_loss: 400.2537, val_MinusLogProbMetric: 400.2537

Epoch 143: val_loss did not improve from 398.62759
196/196 - 39s - loss: 396.3758 - MinusLogProbMetric: 396.3758 - val_loss: 400.2537 - val_MinusLogProbMetric: 400.2537 - lr: 3.3333e-04 - 39s/epoch - 198ms/step
Epoch 144/1000
2023-09-10 15:48:19.711 
Epoch 144/1000 
	 loss: 395.8392, MinusLogProbMetric: 395.8392, val_loss: 398.8953, val_MinusLogProbMetric: 398.8953

Epoch 144: val_loss did not improve from 398.62759
196/196 - 35s - loss: 395.8392 - MinusLogProbMetric: 395.8392 - val_loss: 398.8953 - val_MinusLogProbMetric: 398.8953 - lr: 3.3333e-04 - 35s/epoch - 178ms/step
Epoch 145/1000
2023-09-10 15:48:55.476 
Epoch 145/1000 
	 loss: 396.3677, MinusLogProbMetric: 396.3677, val_loss: 398.7972, val_MinusLogProbMetric: 398.7972

Epoch 145: val_loss did not improve from 398.62759
196/196 - 36s - loss: 396.3677 - MinusLogProbMetric: 396.3677 - val_loss: 398.7972 - val_MinusLogProbMetric: 398.7972 - lr: 3.3333e-04 - 36s/epoch - 182ms/step
Epoch 146/1000
2023-09-10 15:49:31.864 
Epoch 146/1000 
	 loss: 395.9889, MinusLogProbMetric: 395.9889, val_loss: 412.1311, val_MinusLogProbMetric: 412.1311

Epoch 146: val_loss did not improve from 398.62759
196/196 - 36s - loss: 395.9889 - MinusLogProbMetric: 395.9889 - val_loss: 412.1311 - val_MinusLogProbMetric: 412.1311 - lr: 3.3333e-04 - 36s/epoch - 186ms/step
Epoch 147/1000
2023-09-10 15:50:06.011 
Epoch 147/1000 
	 loss: 396.0964, MinusLogProbMetric: 396.0964, val_loss: 400.4643, val_MinusLogProbMetric: 400.4643

Epoch 147: val_loss did not improve from 398.62759
196/196 - 34s - loss: 396.0964 - MinusLogProbMetric: 396.0964 - val_loss: 400.4643 - val_MinusLogProbMetric: 400.4643 - lr: 3.3333e-04 - 34s/epoch - 174ms/step
Epoch 148/1000
2023-09-10 15:50:40.898 
Epoch 148/1000 
	 loss: 396.2415, MinusLogProbMetric: 396.2415, val_loss: 399.4015, val_MinusLogProbMetric: 399.4015

Epoch 148: val_loss did not improve from 398.62759
196/196 - 35s - loss: 396.2415 - MinusLogProbMetric: 396.2415 - val_loss: 399.4015 - val_MinusLogProbMetric: 399.4015 - lr: 3.3333e-04 - 35s/epoch - 178ms/step
Epoch 149/1000
2023-09-10 15:51:16.424 
Epoch 149/1000 
	 loss: 395.8512, MinusLogProbMetric: 395.8512, val_loss: 401.5590, val_MinusLogProbMetric: 401.5590

Epoch 149: val_loss did not improve from 398.62759
196/196 - 35s - loss: 395.8512 - MinusLogProbMetric: 395.8512 - val_loss: 401.5590 - val_MinusLogProbMetric: 401.5590 - lr: 3.3333e-04 - 35s/epoch - 181ms/step
Epoch 150/1000
2023-09-10 15:51:55.072 
Epoch 150/1000 
	 loss: 396.2300, MinusLogProbMetric: 396.2300, val_loss: 398.5630, val_MinusLogProbMetric: 398.5630

Epoch 150: val_loss improved from 398.62759 to 398.56302, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 40s - loss: 396.2300 - MinusLogProbMetric: 396.2300 - val_loss: 398.5630 - val_MinusLogProbMetric: 398.5630 - lr: 3.3333e-04 - 40s/epoch - 206ms/step
Epoch 151/1000
2023-09-10 15:52:34.861 
Epoch 151/1000 
	 loss: 395.7894, MinusLogProbMetric: 395.7894, val_loss: 399.6904, val_MinusLogProbMetric: 399.6904

Epoch 151: val_loss did not improve from 398.56302
196/196 - 38s - loss: 395.7894 - MinusLogProbMetric: 395.7894 - val_loss: 399.6904 - val_MinusLogProbMetric: 399.6904 - lr: 3.3333e-04 - 38s/epoch - 194ms/step
Epoch 152/1000
2023-09-10 15:53:16.863 
Epoch 152/1000 
	 loss: 396.6810, MinusLogProbMetric: 396.6810, val_loss: 400.3689, val_MinusLogProbMetric: 400.3689

Epoch 152: val_loss did not improve from 398.56302
196/196 - 42s - loss: 396.6810 - MinusLogProbMetric: 396.6810 - val_loss: 400.3689 - val_MinusLogProbMetric: 400.3689 - lr: 3.3333e-04 - 42s/epoch - 214ms/step
Epoch 153/1000
2023-09-10 15:54:00.749 
Epoch 153/1000 
	 loss: 395.6048, MinusLogProbMetric: 395.6048, val_loss: 399.5296, val_MinusLogProbMetric: 399.5296

Epoch 153: val_loss did not improve from 398.56302
196/196 - 44s - loss: 395.6048 - MinusLogProbMetric: 395.6048 - val_loss: 399.5296 - val_MinusLogProbMetric: 399.5296 - lr: 3.3333e-04 - 44s/epoch - 224ms/step
Epoch 154/1000
2023-09-10 15:54:37.228 
Epoch 154/1000 
	 loss: 395.8689, MinusLogProbMetric: 395.8689, val_loss: 402.9048, val_MinusLogProbMetric: 402.9048

Epoch 154: val_loss did not improve from 398.56302
196/196 - 36s - loss: 395.8689 - MinusLogProbMetric: 395.8689 - val_loss: 402.9048 - val_MinusLogProbMetric: 402.9048 - lr: 3.3333e-04 - 36s/epoch - 186ms/step
Epoch 155/1000
2023-09-10 15:55:11.135 
Epoch 155/1000 
	 loss: 395.5151, MinusLogProbMetric: 395.5151, val_loss: 401.0186, val_MinusLogProbMetric: 401.0186

Epoch 155: val_loss did not improve from 398.56302
196/196 - 34s - loss: 395.5151 - MinusLogProbMetric: 395.5151 - val_loss: 401.0186 - val_MinusLogProbMetric: 401.0186 - lr: 3.3333e-04 - 34s/epoch - 173ms/step
Epoch 156/1000
2023-09-10 15:55:48.583 
Epoch 156/1000 
	 loss: 395.8094, MinusLogProbMetric: 395.8094, val_loss: 407.7836, val_MinusLogProbMetric: 407.7836

Epoch 156: val_loss did not improve from 398.56302
196/196 - 37s - loss: 395.8094 - MinusLogProbMetric: 395.8094 - val_loss: 407.7836 - val_MinusLogProbMetric: 407.7836 - lr: 3.3333e-04 - 37s/epoch - 190ms/step
Epoch 157/1000
2023-09-10 15:56:27.635 
Epoch 157/1000 
	 loss: 395.7442, MinusLogProbMetric: 395.7442, val_loss: 400.8215, val_MinusLogProbMetric: 400.8215

Epoch 157: val_loss did not improve from 398.56302
196/196 - 39s - loss: 395.7442 - MinusLogProbMetric: 395.7442 - val_loss: 400.8215 - val_MinusLogProbMetric: 400.8215 - lr: 3.3333e-04 - 39s/epoch - 199ms/step
Epoch 158/1000
2023-09-10 15:57:13.533 
Epoch 158/1000 
	 loss: 395.9596, MinusLogProbMetric: 395.9596, val_loss: 416.9576, val_MinusLogProbMetric: 416.9576

Epoch 158: val_loss did not improve from 398.56302
196/196 - 46s - loss: 395.9596 - MinusLogProbMetric: 395.9596 - val_loss: 416.9576 - val_MinusLogProbMetric: 416.9576 - lr: 3.3333e-04 - 46s/epoch - 234ms/step
Epoch 159/1000
2023-09-10 15:57:55.902 
Epoch 159/1000 
	 loss: 395.6531, MinusLogProbMetric: 395.6531, val_loss: 400.3559, val_MinusLogProbMetric: 400.3559

Epoch 159: val_loss did not improve from 398.56302
196/196 - 42s - loss: 395.6531 - MinusLogProbMetric: 395.6531 - val_loss: 400.3559 - val_MinusLogProbMetric: 400.3559 - lr: 3.3333e-04 - 42s/epoch - 216ms/step
Epoch 160/1000
2023-09-10 15:58:38.153 
Epoch 160/1000 
	 loss: 395.7722, MinusLogProbMetric: 395.7722, val_loss: 401.2612, val_MinusLogProbMetric: 401.2612

Epoch 160: val_loss did not improve from 398.56302
196/196 - 42s - loss: 395.7722 - MinusLogProbMetric: 395.7722 - val_loss: 401.2612 - val_MinusLogProbMetric: 401.2612 - lr: 3.3333e-04 - 42s/epoch - 215ms/step
Epoch 161/1000
2023-09-10 15:59:13.250 
Epoch 161/1000 
	 loss: 395.6713, MinusLogProbMetric: 395.6713, val_loss: 398.4979, val_MinusLogProbMetric: 398.4979

Epoch 161: val_loss improved from 398.56302 to 398.49789, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 36s - loss: 395.6713 - MinusLogProbMetric: 395.6713 - val_loss: 398.4979 - val_MinusLogProbMetric: 398.4979 - lr: 3.3333e-04 - 36s/epoch - 184ms/step
Epoch 162/1000
2023-09-10 15:59:57.648 
Epoch 162/1000 
	 loss: 395.7175, MinusLogProbMetric: 395.7175, val_loss: 400.5511, val_MinusLogProbMetric: 400.5511

Epoch 162: val_loss did not improve from 398.49789
196/196 - 44s - loss: 395.7175 - MinusLogProbMetric: 395.7175 - val_loss: 400.5511 - val_MinusLogProbMetric: 400.5511 - lr: 3.3333e-04 - 44s/epoch - 222ms/step
Epoch 163/1000
2023-09-10 16:00:34.410 
Epoch 163/1000 
	 loss: 395.5545, MinusLogProbMetric: 395.5545, val_loss: 399.4027, val_MinusLogProbMetric: 399.4027

Epoch 163: val_loss did not improve from 398.49789
196/196 - 37s - loss: 395.5545 - MinusLogProbMetric: 395.5545 - val_loss: 399.4027 - val_MinusLogProbMetric: 399.4027 - lr: 3.3333e-04 - 37s/epoch - 187ms/step
Epoch 164/1000
2023-09-10 16:01:18.215 
Epoch 164/1000 
	 loss: 395.0933, MinusLogProbMetric: 395.0933, val_loss: 399.4014, val_MinusLogProbMetric: 399.4014

Epoch 164: val_loss did not improve from 398.49789
196/196 - 44s - loss: 395.0933 - MinusLogProbMetric: 395.0933 - val_loss: 399.4014 - val_MinusLogProbMetric: 399.4014 - lr: 3.3333e-04 - 44s/epoch - 223ms/step
Epoch 165/1000
2023-09-10 16:01:59.943 
Epoch 165/1000 
	 loss: 395.8568, MinusLogProbMetric: 395.8568, val_loss: 401.3461, val_MinusLogProbMetric: 401.3461

Epoch 165: val_loss did not improve from 398.49789
196/196 - 42s - loss: 395.8568 - MinusLogProbMetric: 395.8568 - val_loss: 401.3461 - val_MinusLogProbMetric: 401.3461 - lr: 3.3333e-04 - 42s/epoch - 213ms/step
Epoch 166/1000
2023-09-10 16:02:36.633 
Epoch 166/1000 
	 loss: 395.4374, MinusLogProbMetric: 395.4374, val_loss: 401.6173, val_MinusLogProbMetric: 401.6173

Epoch 166: val_loss did not improve from 398.49789
196/196 - 37s - loss: 395.4374 - MinusLogProbMetric: 395.4374 - val_loss: 401.6173 - val_MinusLogProbMetric: 401.6173 - lr: 3.3333e-04 - 37s/epoch - 187ms/step
Epoch 167/1000
2023-09-10 16:03:10.553 
Epoch 167/1000 
	 loss: 395.3051, MinusLogProbMetric: 395.3051, val_loss: 398.7566, val_MinusLogProbMetric: 398.7566

Epoch 167: val_loss did not improve from 398.49789
196/196 - 34s - loss: 395.3051 - MinusLogProbMetric: 395.3051 - val_loss: 398.7566 - val_MinusLogProbMetric: 398.7566 - lr: 3.3333e-04 - 34s/epoch - 173ms/step
Epoch 168/1000
2023-09-10 16:03:50.434 
Epoch 168/1000 
	 loss: 395.3513, MinusLogProbMetric: 395.3513, val_loss: 399.9789, val_MinusLogProbMetric: 399.9789

Epoch 168: val_loss did not improve from 398.49789
196/196 - 40s - loss: 395.3513 - MinusLogProbMetric: 395.3513 - val_loss: 399.9789 - val_MinusLogProbMetric: 399.9789 - lr: 3.3333e-04 - 40s/epoch - 204ms/step
Epoch 169/1000
2023-09-10 16:04:27.549 
Epoch 169/1000 
	 loss: 395.8837, MinusLogProbMetric: 395.8837, val_loss: 405.7775, val_MinusLogProbMetric: 405.7775

Epoch 169: val_loss did not improve from 398.49789
196/196 - 37s - loss: 395.8837 - MinusLogProbMetric: 395.8837 - val_loss: 405.7775 - val_MinusLogProbMetric: 405.7775 - lr: 3.3333e-04 - 37s/epoch - 189ms/step
Epoch 170/1000
2023-09-10 16:05:05.505 
Epoch 170/1000 
	 loss: 394.9041, MinusLogProbMetric: 394.9041, val_loss: 401.5511, val_MinusLogProbMetric: 401.5511

Epoch 170: val_loss did not improve from 398.49789
196/196 - 38s - loss: 394.9041 - MinusLogProbMetric: 394.9041 - val_loss: 401.5511 - val_MinusLogProbMetric: 401.5511 - lr: 3.3333e-04 - 38s/epoch - 194ms/step
Epoch 171/1000
2023-09-10 16:05:39.738 
Epoch 171/1000 
	 loss: 395.2264, MinusLogProbMetric: 395.2264, val_loss: 399.1004, val_MinusLogProbMetric: 399.1004

Epoch 171: val_loss did not improve from 398.49789
196/196 - 34s - loss: 395.2264 - MinusLogProbMetric: 395.2264 - val_loss: 399.1004 - val_MinusLogProbMetric: 399.1004 - lr: 3.3333e-04 - 34s/epoch - 175ms/step
Epoch 172/1000
2023-09-10 16:06:13.172 
Epoch 172/1000 
	 loss: 395.1998, MinusLogProbMetric: 395.1998, val_loss: 400.9929, val_MinusLogProbMetric: 400.9929

Epoch 172: val_loss did not improve from 398.49789
196/196 - 33s - loss: 395.1998 - MinusLogProbMetric: 395.1998 - val_loss: 400.9929 - val_MinusLogProbMetric: 400.9929 - lr: 3.3333e-04 - 33s/epoch - 170ms/step
Epoch 173/1000
2023-09-10 16:06:51.488 
Epoch 173/1000 
	 loss: 395.1407, MinusLogProbMetric: 395.1407, val_loss: 398.5510, val_MinusLogProbMetric: 398.5510

Epoch 173: val_loss did not improve from 398.49789
196/196 - 38s - loss: 395.1407 - MinusLogProbMetric: 395.1407 - val_loss: 398.5510 - val_MinusLogProbMetric: 398.5510 - lr: 3.3333e-04 - 38s/epoch - 195ms/step
Epoch 174/1000
2023-09-10 16:07:24.906 
Epoch 174/1000 
	 loss: 395.5214, MinusLogProbMetric: 395.5214, val_loss: 400.3002, val_MinusLogProbMetric: 400.3002

Epoch 174: val_loss did not improve from 398.49789
196/196 - 33s - loss: 395.5214 - MinusLogProbMetric: 395.5214 - val_loss: 400.3002 - val_MinusLogProbMetric: 400.3002 - lr: 3.3333e-04 - 33s/epoch - 170ms/step
Epoch 175/1000
2023-09-10 16:08:03.989 
Epoch 175/1000 
	 loss: 394.8713, MinusLogProbMetric: 394.8713, val_loss: 400.2622, val_MinusLogProbMetric: 400.2622

Epoch 175: val_loss did not improve from 398.49789
196/196 - 39s - loss: 394.8713 - MinusLogProbMetric: 394.8713 - val_loss: 400.2622 - val_MinusLogProbMetric: 400.2622 - lr: 3.3333e-04 - 39s/epoch - 199ms/step
Epoch 176/1000
2023-09-10 16:08:46.402 
Epoch 176/1000 
	 loss: 395.0150, MinusLogProbMetric: 395.0150, val_loss: 400.1778, val_MinusLogProbMetric: 400.1778

Epoch 176: val_loss did not improve from 398.49789
196/196 - 42s - loss: 395.0150 - MinusLogProbMetric: 395.0150 - val_loss: 400.1778 - val_MinusLogProbMetric: 400.1778 - lr: 3.3333e-04 - 42s/epoch - 216ms/step
Epoch 177/1000
2023-09-10 16:09:25.351 
Epoch 177/1000 
	 loss: 395.1920, MinusLogProbMetric: 395.1920, val_loss: 399.8369, val_MinusLogProbMetric: 399.8369

Epoch 177: val_loss did not improve from 398.49789
196/196 - 39s - loss: 395.1920 - MinusLogProbMetric: 395.1920 - val_loss: 399.8369 - val_MinusLogProbMetric: 399.8369 - lr: 3.3333e-04 - 39s/epoch - 199ms/step
Epoch 178/1000
2023-09-10 16:10:05.476 
Epoch 178/1000 
	 loss: 395.9078, MinusLogProbMetric: 395.9078, val_loss: 398.9304, val_MinusLogProbMetric: 398.9304

Epoch 178: val_loss did not improve from 398.49789
196/196 - 40s - loss: 395.9078 - MinusLogProbMetric: 395.9078 - val_loss: 398.9304 - val_MinusLogProbMetric: 398.9304 - lr: 3.3333e-04 - 40s/epoch - 204ms/step
Epoch 179/1000
2023-09-10 16:10:39.841 
Epoch 179/1000 
	 loss: 394.8296, MinusLogProbMetric: 394.8296, val_loss: 400.0290, val_MinusLogProbMetric: 400.0290

Epoch 179: val_loss did not improve from 398.49789
196/196 - 34s - loss: 394.8296 - MinusLogProbMetric: 394.8296 - val_loss: 400.0290 - val_MinusLogProbMetric: 400.0290 - lr: 3.3333e-04 - 34s/epoch - 175ms/step
Epoch 180/1000
2023-09-10 16:11:18.352 
Epoch 180/1000 
	 loss: 394.6529, MinusLogProbMetric: 394.6529, val_loss: 401.4852, val_MinusLogProbMetric: 401.4852

Epoch 180: val_loss did not improve from 398.49789
196/196 - 39s - loss: 394.6529 - MinusLogProbMetric: 394.6529 - val_loss: 401.4852 - val_MinusLogProbMetric: 401.4852 - lr: 3.3333e-04 - 39s/epoch - 196ms/step
Epoch 181/1000
2023-09-10 16:11:59.083 
Epoch 181/1000 
	 loss: 399.3428, MinusLogProbMetric: 399.3428, val_loss: 399.1304, val_MinusLogProbMetric: 399.1304

Epoch 181: val_loss did not improve from 398.49789
196/196 - 41s - loss: 399.3428 - MinusLogProbMetric: 399.3428 - val_loss: 399.1304 - val_MinusLogProbMetric: 399.1304 - lr: 3.3333e-04 - 41s/epoch - 208ms/step
Epoch 182/1000
2023-09-10 16:12:39.613 
Epoch 182/1000 
	 loss: 394.4012, MinusLogProbMetric: 394.4012, val_loss: 400.6021, val_MinusLogProbMetric: 400.6021

Epoch 182: val_loss did not improve from 398.49789
196/196 - 41s - loss: 394.4012 - MinusLogProbMetric: 394.4012 - val_loss: 400.6021 - val_MinusLogProbMetric: 400.6021 - lr: 3.3333e-04 - 41s/epoch - 207ms/step
Epoch 183/1000
2023-09-10 16:13:23.485 
Epoch 183/1000 
	 loss: 395.1427, MinusLogProbMetric: 395.1427, val_loss: 399.8537, val_MinusLogProbMetric: 399.8537

Epoch 183: val_loss did not improve from 398.49789
196/196 - 44s - loss: 395.1427 - MinusLogProbMetric: 395.1427 - val_loss: 399.8537 - val_MinusLogProbMetric: 399.8537 - lr: 3.3333e-04 - 44s/epoch - 224ms/step
Epoch 184/1000
2023-09-10 16:14:08.841 
Epoch 184/1000 
	 loss: 394.4423, MinusLogProbMetric: 394.4423, val_loss: 400.2584, val_MinusLogProbMetric: 400.2584

Epoch 184: val_loss did not improve from 398.49789
196/196 - 45s - loss: 394.4423 - MinusLogProbMetric: 394.4423 - val_loss: 400.2584 - val_MinusLogProbMetric: 400.2584 - lr: 3.3333e-04 - 45s/epoch - 231ms/step
Epoch 185/1000
2023-09-10 16:14:52.802 
Epoch 185/1000 
	 loss: 394.8440, MinusLogProbMetric: 394.8440, val_loss: 397.9497, val_MinusLogProbMetric: 397.9497

Epoch 185: val_loss improved from 398.49789 to 397.94971, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 46s - loss: 394.8440 - MinusLogProbMetric: 394.8440 - val_loss: 397.9497 - val_MinusLogProbMetric: 397.9497 - lr: 3.3333e-04 - 46s/epoch - 237ms/step
Epoch 186/1000
2023-09-10 16:15:40.039 
Epoch 186/1000 
	 loss: 394.9693, MinusLogProbMetric: 394.9693, val_loss: 403.5750, val_MinusLogProbMetric: 403.5750

Epoch 186: val_loss did not improve from 397.94971
196/196 - 45s - loss: 394.9693 - MinusLogProbMetric: 394.9693 - val_loss: 403.5750 - val_MinusLogProbMetric: 403.5750 - lr: 3.3333e-04 - 45s/epoch - 228ms/step
Epoch 187/1000
2023-09-10 16:16:18.237 
Epoch 187/1000 
	 loss: 394.6683, MinusLogProbMetric: 394.6683, val_loss: 402.2898, val_MinusLogProbMetric: 402.2898

Epoch 187: val_loss did not improve from 397.94971
196/196 - 38s - loss: 394.6683 - MinusLogProbMetric: 394.6683 - val_loss: 402.2898 - val_MinusLogProbMetric: 402.2898 - lr: 3.3333e-04 - 38s/epoch - 195ms/step
Epoch 188/1000
2023-09-10 16:16:53.909 
Epoch 188/1000 
	 loss: 394.7482, MinusLogProbMetric: 394.7482, val_loss: 399.5731, val_MinusLogProbMetric: 399.5731

Epoch 188: val_loss did not improve from 397.94971
196/196 - 36s - loss: 394.7482 - MinusLogProbMetric: 394.7482 - val_loss: 399.5731 - val_MinusLogProbMetric: 399.5731 - lr: 3.3333e-04 - 36s/epoch - 182ms/step
Epoch 189/1000
2023-09-10 16:17:32.429 
Epoch 189/1000 
	 loss: 394.7404, MinusLogProbMetric: 394.7404, val_loss: 399.9175, val_MinusLogProbMetric: 399.9175

Epoch 189: val_loss did not improve from 397.94971
196/196 - 39s - loss: 394.7404 - MinusLogProbMetric: 394.7404 - val_loss: 399.9175 - val_MinusLogProbMetric: 399.9175 - lr: 3.3333e-04 - 39s/epoch - 196ms/step
Epoch 190/1000
2023-09-10 16:18:15.334 
Epoch 190/1000 
	 loss: 394.6083, MinusLogProbMetric: 394.6083, val_loss: 399.4922, val_MinusLogProbMetric: 399.4922

Epoch 190: val_loss did not improve from 397.94971
196/196 - 43s - loss: 394.6083 - MinusLogProbMetric: 394.6083 - val_loss: 399.4922 - val_MinusLogProbMetric: 399.4922 - lr: 3.3333e-04 - 43s/epoch - 219ms/step
Epoch 191/1000
2023-09-10 16:18:55.590 
Epoch 191/1000 
	 loss: 394.4835, MinusLogProbMetric: 394.4835, val_loss: 399.1008, val_MinusLogProbMetric: 399.1008

Epoch 191: val_loss did not improve from 397.94971
196/196 - 40s - loss: 394.4835 - MinusLogProbMetric: 394.4835 - val_loss: 399.1008 - val_MinusLogProbMetric: 399.1008 - lr: 3.3333e-04 - 40s/epoch - 205ms/step
Epoch 192/1000
2023-09-10 16:19:36.056 
Epoch 192/1000 
	 loss: 394.5094, MinusLogProbMetric: 394.5094, val_loss: 400.9782, val_MinusLogProbMetric: 400.9782

Epoch 192: val_loss did not improve from 397.94971
196/196 - 40s - loss: 394.5094 - MinusLogProbMetric: 394.5094 - val_loss: 400.9782 - val_MinusLogProbMetric: 400.9782 - lr: 3.3333e-04 - 40s/epoch - 206ms/step
Epoch 193/1000
2023-09-10 16:20:14.978 
Epoch 193/1000 
	 loss: 395.1094, MinusLogProbMetric: 395.1094, val_loss: 399.1036, val_MinusLogProbMetric: 399.1036

Epoch 193: val_loss did not improve from 397.94971
196/196 - 39s - loss: 395.1094 - MinusLogProbMetric: 395.1094 - val_loss: 399.1036 - val_MinusLogProbMetric: 399.1036 - lr: 3.3333e-04 - 39s/epoch - 199ms/step
Epoch 194/1000
2023-09-10 16:20:56.187 
Epoch 194/1000 
	 loss: 394.1400, MinusLogProbMetric: 394.1400, val_loss: 407.7241, val_MinusLogProbMetric: 407.7241

Epoch 194: val_loss did not improve from 397.94971
196/196 - 41s - loss: 394.1400 - MinusLogProbMetric: 394.1400 - val_loss: 407.7241 - val_MinusLogProbMetric: 407.7241 - lr: 3.3333e-04 - 41s/epoch - 210ms/step
Epoch 195/1000
2023-09-10 16:21:39.378 
Epoch 195/1000 
	 loss: 394.5006, MinusLogProbMetric: 394.5006, val_loss: 400.1004, val_MinusLogProbMetric: 400.1004

Epoch 195: val_loss did not improve from 397.94971
196/196 - 43s - loss: 394.5006 - MinusLogProbMetric: 394.5006 - val_loss: 400.1004 - val_MinusLogProbMetric: 400.1004 - lr: 3.3333e-04 - 43s/epoch - 220ms/step
Epoch 196/1000
2023-09-10 16:22:17.902 
Epoch 196/1000 
	 loss: 394.8313, MinusLogProbMetric: 394.8313, val_loss: 401.7711, val_MinusLogProbMetric: 401.7711

Epoch 196: val_loss did not improve from 397.94971
196/196 - 39s - loss: 394.8313 - MinusLogProbMetric: 394.8313 - val_loss: 401.7711 - val_MinusLogProbMetric: 401.7711 - lr: 3.3333e-04 - 39s/epoch - 196ms/step
Epoch 197/1000
2023-09-10 16:22:50.895 
Epoch 197/1000 
	 loss: 394.5615, MinusLogProbMetric: 394.5615, val_loss: 399.7319, val_MinusLogProbMetric: 399.7319

Epoch 197: val_loss did not improve from 397.94971
196/196 - 33s - loss: 394.5615 - MinusLogProbMetric: 394.5615 - val_loss: 399.7319 - val_MinusLogProbMetric: 399.7319 - lr: 3.3333e-04 - 33s/epoch - 168ms/step
Epoch 198/1000
2023-09-10 16:23:26.217 
Epoch 198/1000 
	 loss: 395.5854, MinusLogProbMetric: 395.5854, val_loss: 398.3637, val_MinusLogProbMetric: 398.3637

Epoch 198: val_loss did not improve from 397.94971
196/196 - 35s - loss: 395.5854 - MinusLogProbMetric: 395.5854 - val_loss: 398.3637 - val_MinusLogProbMetric: 398.3637 - lr: 3.3333e-04 - 35s/epoch - 180ms/step
Epoch 199/1000
2023-09-10 16:24:05.875 
Epoch 199/1000 
	 loss: 394.0963, MinusLogProbMetric: 394.0963, val_loss: 398.4095, val_MinusLogProbMetric: 398.4095

Epoch 199: val_loss did not improve from 397.94971
196/196 - 40s - loss: 394.0963 - MinusLogProbMetric: 394.0963 - val_loss: 398.4095 - val_MinusLogProbMetric: 398.4095 - lr: 3.3333e-04 - 40s/epoch - 202ms/step
Epoch 200/1000
2023-09-10 16:24:48.429 
Epoch 200/1000 
	 loss: 394.0094, MinusLogProbMetric: 394.0094, val_loss: 399.7763, val_MinusLogProbMetric: 399.7763

Epoch 200: val_loss did not improve from 397.94971
196/196 - 43s - loss: 394.0094 - MinusLogProbMetric: 394.0094 - val_loss: 399.7763 - val_MinusLogProbMetric: 399.7763 - lr: 3.3333e-04 - 43s/epoch - 217ms/step
Epoch 201/1000
2023-09-10 16:25:30.142 
Epoch 201/1000 
	 loss: 394.6238, MinusLogProbMetric: 394.6238, val_loss: 399.6417, val_MinusLogProbMetric: 399.6417

Epoch 201: val_loss did not improve from 397.94971
196/196 - 42s - loss: 394.6238 - MinusLogProbMetric: 394.6238 - val_loss: 399.6417 - val_MinusLogProbMetric: 399.6417 - lr: 3.3333e-04 - 42s/epoch - 213ms/step
Epoch 202/1000
2023-09-10 16:26:08.056 
Epoch 202/1000 
	 loss: 394.5072, MinusLogProbMetric: 394.5072, val_loss: 404.8146, val_MinusLogProbMetric: 404.8146

Epoch 202: val_loss did not improve from 397.94971
196/196 - 38s - loss: 394.5072 - MinusLogProbMetric: 394.5072 - val_loss: 404.8146 - val_MinusLogProbMetric: 404.8146 - lr: 3.3333e-04 - 38s/epoch - 193ms/step
Epoch 203/1000
2023-09-10 16:26:46.469 
Epoch 203/1000 
	 loss: 394.2721, MinusLogProbMetric: 394.2721, val_loss: 404.6870, val_MinusLogProbMetric: 404.6870

Epoch 203: val_loss did not improve from 397.94971
196/196 - 38s - loss: 394.2721 - MinusLogProbMetric: 394.2721 - val_loss: 404.6870 - val_MinusLogProbMetric: 404.6870 - lr: 3.3333e-04 - 38s/epoch - 196ms/step
Epoch 204/1000
2023-09-10 16:27:22.899 
Epoch 204/1000 
	 loss: 393.9460, MinusLogProbMetric: 393.9460, val_loss: 400.6794, val_MinusLogProbMetric: 400.6794

Epoch 204: val_loss did not improve from 397.94971
196/196 - 36s - loss: 393.9460 - MinusLogProbMetric: 393.9460 - val_loss: 400.6794 - val_MinusLogProbMetric: 400.6794 - lr: 3.3333e-04 - 36s/epoch - 186ms/step
Epoch 205/1000
2023-09-10 16:28:00.678 
Epoch 205/1000 
	 loss: 394.3560, MinusLogProbMetric: 394.3560, val_loss: 399.8336, val_MinusLogProbMetric: 399.8336

Epoch 205: val_loss did not improve from 397.94971
196/196 - 38s - loss: 394.3560 - MinusLogProbMetric: 394.3560 - val_loss: 399.8336 - val_MinusLogProbMetric: 399.8336 - lr: 3.3333e-04 - 38s/epoch - 193ms/step
Epoch 206/1000
2023-09-10 16:28:34.689 
Epoch 206/1000 
	 loss: 394.4221, MinusLogProbMetric: 394.4221, val_loss: 398.5593, val_MinusLogProbMetric: 398.5593

Epoch 206: val_loss did not improve from 397.94971
196/196 - 34s - loss: 394.4221 - MinusLogProbMetric: 394.4221 - val_loss: 398.5593 - val_MinusLogProbMetric: 398.5593 - lr: 3.3333e-04 - 34s/epoch - 173ms/step
Epoch 207/1000
2023-09-10 16:29:11.658 
Epoch 207/1000 
	 loss: 394.2552, MinusLogProbMetric: 394.2552, val_loss: 398.6309, val_MinusLogProbMetric: 398.6309

Epoch 207: val_loss did not improve from 397.94971
196/196 - 37s - loss: 394.2552 - MinusLogProbMetric: 394.2552 - val_loss: 398.6309 - val_MinusLogProbMetric: 398.6309 - lr: 3.3333e-04 - 37s/epoch - 188ms/step
Epoch 208/1000
2023-09-10 16:29:45.691 
Epoch 208/1000 
	 loss: 394.0748, MinusLogProbMetric: 394.0748, val_loss: 399.6053, val_MinusLogProbMetric: 399.6053

Epoch 208: val_loss did not improve from 397.94971
196/196 - 34s - loss: 394.0748 - MinusLogProbMetric: 394.0748 - val_loss: 399.6053 - val_MinusLogProbMetric: 399.6053 - lr: 3.3333e-04 - 34s/epoch - 174ms/step
Epoch 209/1000
2023-09-10 16:30:17.613 
Epoch 209/1000 
	 loss: 394.6772, MinusLogProbMetric: 394.6772, val_loss: 403.1128, val_MinusLogProbMetric: 403.1128

Epoch 209: val_loss did not improve from 397.94971
196/196 - 32s - loss: 394.6772 - MinusLogProbMetric: 394.6772 - val_loss: 403.1128 - val_MinusLogProbMetric: 403.1128 - lr: 3.3333e-04 - 32s/epoch - 163ms/step
Epoch 210/1000
2023-09-10 16:30:49.563 
Epoch 210/1000 
	 loss: 394.0132, MinusLogProbMetric: 394.0132, val_loss: 398.9671, val_MinusLogProbMetric: 398.9671

Epoch 210: val_loss did not improve from 397.94971
196/196 - 32s - loss: 394.0132 - MinusLogProbMetric: 394.0132 - val_loss: 398.9671 - val_MinusLogProbMetric: 398.9671 - lr: 3.3333e-04 - 32s/epoch - 163ms/step
Epoch 211/1000
2023-09-10 16:31:24.669 
Epoch 211/1000 
	 loss: 394.2755, MinusLogProbMetric: 394.2755, val_loss: 399.3409, val_MinusLogProbMetric: 399.3409

Epoch 211: val_loss did not improve from 397.94971
196/196 - 35s - loss: 394.2755 - MinusLogProbMetric: 394.2755 - val_loss: 399.3409 - val_MinusLogProbMetric: 399.3409 - lr: 3.3333e-04 - 35s/epoch - 179ms/step
Epoch 212/1000
2023-09-10 16:31:59.450 
Epoch 212/1000 
	 loss: 394.2019, MinusLogProbMetric: 394.2019, val_loss: 399.7642, val_MinusLogProbMetric: 399.7642

Epoch 212: val_loss did not improve from 397.94971
196/196 - 35s - loss: 394.2019 - MinusLogProbMetric: 394.2019 - val_loss: 399.7642 - val_MinusLogProbMetric: 399.7642 - lr: 3.3333e-04 - 35s/epoch - 177ms/step
Epoch 213/1000
2023-09-10 16:32:33.713 
Epoch 213/1000 
	 loss: 394.7964, MinusLogProbMetric: 394.7964, val_loss: 400.7746, val_MinusLogProbMetric: 400.7746

Epoch 213: val_loss did not improve from 397.94971
196/196 - 34s - loss: 394.7964 - MinusLogProbMetric: 394.7964 - val_loss: 400.7746 - val_MinusLogProbMetric: 400.7746 - lr: 3.3333e-04 - 34s/epoch - 175ms/step
Epoch 214/1000
2023-09-10 16:33:08.220 
Epoch 214/1000 
	 loss: 393.7041, MinusLogProbMetric: 393.7041, val_loss: 398.3297, val_MinusLogProbMetric: 398.3297

Epoch 214: val_loss did not improve from 397.94971
196/196 - 34s - loss: 393.7041 - MinusLogProbMetric: 393.7041 - val_loss: 398.3297 - val_MinusLogProbMetric: 398.3297 - lr: 3.3333e-04 - 34s/epoch - 176ms/step
Epoch 215/1000
2023-09-10 16:33:44.409 
Epoch 215/1000 
	 loss: 393.7586, MinusLogProbMetric: 393.7586, val_loss: 398.8967, val_MinusLogProbMetric: 398.8967

Epoch 215: val_loss did not improve from 397.94971
196/196 - 36s - loss: 393.7586 - MinusLogProbMetric: 393.7586 - val_loss: 398.8967 - val_MinusLogProbMetric: 398.8967 - lr: 3.3333e-04 - 36s/epoch - 185ms/step
Epoch 216/1000
2023-09-10 16:34:20.330 
Epoch 216/1000 
	 loss: 394.3932, MinusLogProbMetric: 394.3932, val_loss: 399.8323, val_MinusLogProbMetric: 399.8323

Epoch 216: val_loss did not improve from 397.94971
196/196 - 36s - loss: 394.3932 - MinusLogProbMetric: 394.3932 - val_loss: 399.8323 - val_MinusLogProbMetric: 399.8323 - lr: 3.3333e-04 - 36s/epoch - 183ms/step
Epoch 217/1000
2023-09-10 16:34:58.272 
Epoch 217/1000 
	 loss: 393.7088, MinusLogProbMetric: 393.7088, val_loss: 403.9403, val_MinusLogProbMetric: 403.9403

Epoch 217: val_loss did not improve from 397.94971
196/196 - 38s - loss: 393.7088 - MinusLogProbMetric: 393.7088 - val_loss: 403.9403 - val_MinusLogProbMetric: 403.9403 - lr: 3.3333e-04 - 38s/epoch - 193ms/step
Epoch 218/1000
2023-09-10 16:35:32.242 
Epoch 218/1000 
	 loss: 395.0829, MinusLogProbMetric: 395.0829, val_loss: 398.9594, val_MinusLogProbMetric: 398.9594

Epoch 218: val_loss did not improve from 397.94971
196/196 - 34s - loss: 395.0829 - MinusLogProbMetric: 395.0829 - val_loss: 398.9594 - val_MinusLogProbMetric: 398.9594 - lr: 3.3333e-04 - 34s/epoch - 173ms/step
Epoch 219/1000
2023-09-10 16:36:05.510 
Epoch 219/1000 
	 loss: 393.5842, MinusLogProbMetric: 393.5842, val_loss: 398.6043, val_MinusLogProbMetric: 398.6043

Epoch 219: val_loss did not improve from 397.94971
196/196 - 33s - loss: 393.5842 - MinusLogProbMetric: 393.5842 - val_loss: 398.6043 - val_MinusLogProbMetric: 398.6043 - lr: 3.3333e-04 - 33s/epoch - 170ms/step
Epoch 220/1000
2023-09-10 16:36:38.945 
Epoch 220/1000 
	 loss: 393.8195, MinusLogProbMetric: 393.8195, val_loss: 398.4697, val_MinusLogProbMetric: 398.4697

Epoch 220: val_loss did not improve from 397.94971
196/196 - 33s - loss: 393.8195 - MinusLogProbMetric: 393.8195 - val_loss: 398.4697 - val_MinusLogProbMetric: 398.4697 - lr: 3.3333e-04 - 33s/epoch - 171ms/step
Epoch 221/1000
2023-09-10 16:37:19.004 
Epoch 221/1000 
	 loss: 394.8382, MinusLogProbMetric: 394.8382, val_loss: 400.9835, val_MinusLogProbMetric: 400.9835

Epoch 221: val_loss did not improve from 397.94971
196/196 - 40s - loss: 394.8382 - MinusLogProbMetric: 394.8382 - val_loss: 400.9835 - val_MinusLogProbMetric: 400.9835 - lr: 3.3333e-04 - 40s/epoch - 204ms/step
Epoch 222/1000
2023-09-10 16:37:57.609 
Epoch 222/1000 
	 loss: 393.4712, MinusLogProbMetric: 393.4712, val_loss: 398.5386, val_MinusLogProbMetric: 398.5386

Epoch 222: val_loss did not improve from 397.94971
196/196 - 39s - loss: 393.4712 - MinusLogProbMetric: 393.4712 - val_loss: 398.5386 - val_MinusLogProbMetric: 398.5386 - lr: 3.3333e-04 - 39s/epoch - 197ms/step
Epoch 223/1000
2023-09-10 16:38:38.865 
Epoch 223/1000 
	 loss: 393.8651, MinusLogProbMetric: 393.8651, val_loss: 409.0968, val_MinusLogProbMetric: 409.0968

Epoch 223: val_loss did not improve from 397.94971
196/196 - 41s - loss: 393.8651 - MinusLogProbMetric: 393.8651 - val_loss: 409.0968 - val_MinusLogProbMetric: 409.0968 - lr: 3.3333e-04 - 41s/epoch - 210ms/step
Epoch 224/1000
2023-09-10 16:39:17.378 
Epoch 224/1000 
	 loss: 393.6884, MinusLogProbMetric: 393.6884, val_loss: 399.2536, val_MinusLogProbMetric: 399.2536

Epoch 224: val_loss did not improve from 397.94971
196/196 - 39s - loss: 393.6884 - MinusLogProbMetric: 393.6884 - val_loss: 399.2536 - val_MinusLogProbMetric: 399.2536 - lr: 3.3333e-04 - 39s/epoch - 197ms/step
Epoch 225/1000
2023-09-10 16:39:56.397 
Epoch 225/1000 
	 loss: 394.5146, MinusLogProbMetric: 394.5146, val_loss: 410.3231, val_MinusLogProbMetric: 410.3231

Epoch 225: val_loss did not improve from 397.94971
196/196 - 39s - loss: 394.5146 - MinusLogProbMetric: 394.5146 - val_loss: 410.3231 - val_MinusLogProbMetric: 410.3231 - lr: 3.3333e-04 - 39s/epoch - 199ms/step
Epoch 226/1000
2023-09-10 16:40:37.169 
Epoch 226/1000 
	 loss: 393.8506, MinusLogProbMetric: 393.8506, val_loss: 398.3533, val_MinusLogProbMetric: 398.3533

Epoch 226: val_loss did not improve from 397.94971
196/196 - 41s - loss: 393.8506 - MinusLogProbMetric: 393.8506 - val_loss: 398.3533 - val_MinusLogProbMetric: 398.3533 - lr: 3.3333e-04 - 41s/epoch - 208ms/step
Epoch 227/1000
2023-09-10 16:41:16.583 
Epoch 227/1000 
	 loss: 393.4973, MinusLogProbMetric: 393.4973, val_loss: 401.9837, val_MinusLogProbMetric: 401.9837

Epoch 227: val_loss did not improve from 397.94971
196/196 - 39s - loss: 393.4973 - MinusLogProbMetric: 393.4973 - val_loss: 401.9837 - val_MinusLogProbMetric: 401.9837 - lr: 3.3333e-04 - 39s/epoch - 201ms/step
Epoch 228/1000
2023-09-10 16:41:58.634 
Epoch 228/1000 
	 loss: 393.3918, MinusLogProbMetric: 393.3918, val_loss: 399.8680, val_MinusLogProbMetric: 399.8680

Epoch 228: val_loss did not improve from 397.94971
196/196 - 42s - loss: 393.3918 - MinusLogProbMetric: 393.3918 - val_loss: 399.8680 - val_MinusLogProbMetric: 399.8680 - lr: 3.3333e-04 - 42s/epoch - 214ms/step
Epoch 229/1000
2023-09-10 16:42:37.448 
Epoch 229/1000 
	 loss: 393.6508, MinusLogProbMetric: 393.6508, val_loss: 402.6526, val_MinusLogProbMetric: 402.6526

Epoch 229: val_loss did not improve from 397.94971
196/196 - 39s - loss: 393.6508 - MinusLogProbMetric: 393.6508 - val_loss: 402.6526 - val_MinusLogProbMetric: 402.6526 - lr: 3.3333e-04 - 39s/epoch - 198ms/step
Epoch 230/1000
2023-09-10 16:43:24.008 
Epoch 230/1000 
	 loss: 394.7019, MinusLogProbMetric: 394.7019, val_loss: 398.8022, val_MinusLogProbMetric: 398.8022

Epoch 230: val_loss did not improve from 397.94971
196/196 - 47s - loss: 394.7019 - MinusLogProbMetric: 394.7019 - val_loss: 398.8022 - val_MinusLogProbMetric: 398.8022 - lr: 3.3333e-04 - 47s/epoch - 237ms/step
Epoch 231/1000
2023-09-10 16:43:58.486 
Epoch 231/1000 
	 loss: 393.4364, MinusLogProbMetric: 393.4364, val_loss: 403.7505, val_MinusLogProbMetric: 403.7505

Epoch 231: val_loss did not improve from 397.94971
196/196 - 34s - loss: 393.4364 - MinusLogProbMetric: 393.4364 - val_loss: 403.7505 - val_MinusLogProbMetric: 403.7505 - lr: 3.3333e-04 - 34s/epoch - 176ms/step
Epoch 232/1000
2023-09-10 16:44:39.137 
Epoch 232/1000 
	 loss: 393.8933, MinusLogProbMetric: 393.8933, val_loss: 400.0234, val_MinusLogProbMetric: 400.0234

Epoch 232: val_loss did not improve from 397.94971
196/196 - 41s - loss: 393.8933 - MinusLogProbMetric: 393.8933 - val_loss: 400.0234 - val_MinusLogProbMetric: 400.0234 - lr: 3.3333e-04 - 41s/epoch - 207ms/step
Epoch 233/1000
2023-09-10 16:45:16.359 
Epoch 233/1000 
	 loss: 393.5852, MinusLogProbMetric: 393.5852, val_loss: 399.6506, val_MinusLogProbMetric: 399.6506

Epoch 233: val_loss did not improve from 397.94971
196/196 - 37s - loss: 393.5852 - MinusLogProbMetric: 393.5852 - val_loss: 399.6506 - val_MinusLogProbMetric: 399.6506 - lr: 3.3333e-04 - 37s/epoch - 190ms/step
Epoch 234/1000
2023-09-10 16:45:49.818 
Epoch 234/1000 
	 loss: 393.4398, MinusLogProbMetric: 393.4398, val_loss: 400.7121, val_MinusLogProbMetric: 400.7121

Epoch 234: val_loss did not improve from 397.94971
196/196 - 33s - loss: 393.4398 - MinusLogProbMetric: 393.4398 - val_loss: 400.7121 - val_MinusLogProbMetric: 400.7121 - lr: 3.3333e-04 - 33s/epoch - 170ms/step
Epoch 235/1000
2023-09-10 16:46:23.007 
Epoch 235/1000 
	 loss: 393.7269, MinusLogProbMetric: 393.7269, val_loss: 399.8977, val_MinusLogProbMetric: 399.8977

Epoch 235: val_loss did not improve from 397.94971
196/196 - 33s - loss: 393.7269 - MinusLogProbMetric: 393.7269 - val_loss: 399.8977 - val_MinusLogProbMetric: 399.8977 - lr: 3.3333e-04 - 33s/epoch - 169ms/step
Epoch 236/1000
2023-09-10 16:47:02.066 
Epoch 236/1000 
	 loss: 389.2101, MinusLogProbMetric: 389.2101, val_loss: 395.4562, val_MinusLogProbMetric: 395.4562

Epoch 236: val_loss improved from 397.94971 to 395.45624, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 40s - loss: 389.2101 - MinusLogProbMetric: 389.2101 - val_loss: 395.4562 - val_MinusLogProbMetric: 395.4562 - lr: 1.6667e-04 - 40s/epoch - 205ms/step
Epoch 237/1000
2023-09-10 16:47:37.425 
Epoch 237/1000 
	 loss: 389.3924, MinusLogProbMetric: 389.3924, val_loss: 395.9705, val_MinusLogProbMetric: 395.9705

Epoch 237: val_loss did not improve from 395.45624
196/196 - 34s - loss: 389.3924 - MinusLogProbMetric: 389.3924 - val_loss: 395.9705 - val_MinusLogProbMetric: 395.9705 - lr: 1.6667e-04 - 34s/epoch - 174ms/step
Epoch 238/1000
2023-09-10 16:48:14.005 
Epoch 238/1000 
	 loss: 388.9104, MinusLogProbMetric: 388.9104, val_loss: 396.5822, val_MinusLogProbMetric: 396.5822

Epoch 238: val_loss did not improve from 395.45624
196/196 - 37s - loss: 388.9104 - MinusLogProbMetric: 388.9104 - val_loss: 396.5822 - val_MinusLogProbMetric: 396.5822 - lr: 1.6667e-04 - 37s/epoch - 186ms/step
Epoch 239/1000
2023-09-10 16:48:48.078 
Epoch 239/1000 
	 loss: 389.4987, MinusLogProbMetric: 389.4987, val_loss: 395.9230, val_MinusLogProbMetric: 395.9230

Epoch 239: val_loss did not improve from 395.45624
196/196 - 34s - loss: 389.4987 - MinusLogProbMetric: 389.4987 - val_loss: 395.9230 - val_MinusLogProbMetric: 395.9230 - lr: 1.6667e-04 - 34s/epoch - 174ms/step
Epoch 240/1000
2023-09-10 16:49:25.663 
Epoch 240/1000 
	 loss: 389.1893, MinusLogProbMetric: 389.1893, val_loss: 395.6575, val_MinusLogProbMetric: 395.6575

Epoch 240: val_loss did not improve from 395.45624
196/196 - 38s - loss: 389.1893 - MinusLogProbMetric: 389.1893 - val_loss: 395.6575 - val_MinusLogProbMetric: 395.6575 - lr: 1.6667e-04 - 38s/epoch - 192ms/step
Epoch 241/1000
2023-09-10 16:49:58.119 
Epoch 241/1000 
	 loss: 389.1683, MinusLogProbMetric: 389.1683, val_loss: 395.9891, val_MinusLogProbMetric: 395.9891

Epoch 241: val_loss did not improve from 395.45624
196/196 - 32s - loss: 389.1683 - MinusLogProbMetric: 389.1683 - val_loss: 395.9891 - val_MinusLogProbMetric: 395.9891 - lr: 1.6667e-04 - 32s/epoch - 165ms/step
Epoch 242/1000
2023-09-10 16:50:33.331 
Epoch 242/1000 
	 loss: 389.7532, MinusLogProbMetric: 389.7532, val_loss: 395.8295, val_MinusLogProbMetric: 395.8295

Epoch 242: val_loss did not improve from 395.45624
196/196 - 35s - loss: 389.7532 - MinusLogProbMetric: 389.7532 - val_loss: 395.8295 - val_MinusLogProbMetric: 395.8295 - lr: 1.6667e-04 - 35s/epoch - 180ms/step
Epoch 243/1000
2023-09-10 16:51:10.243 
Epoch 243/1000 
	 loss: 389.1940, MinusLogProbMetric: 389.1940, val_loss: 395.7922, val_MinusLogProbMetric: 395.7922

Epoch 243: val_loss did not improve from 395.45624
196/196 - 37s - loss: 389.1940 - MinusLogProbMetric: 389.1940 - val_loss: 395.7922 - val_MinusLogProbMetric: 395.7922 - lr: 1.6667e-04 - 37s/epoch - 188ms/step
Epoch 244/1000
2023-09-10 16:51:45.390 
Epoch 244/1000 
	 loss: 389.2057, MinusLogProbMetric: 389.2057, val_loss: 397.0933, val_MinusLogProbMetric: 397.0933

Epoch 244: val_loss did not improve from 395.45624
196/196 - 35s - loss: 389.2057 - MinusLogProbMetric: 389.2057 - val_loss: 397.0933 - val_MinusLogProbMetric: 397.0933 - lr: 1.6667e-04 - 35s/epoch - 179ms/step
Epoch 245/1000
2023-09-10 16:52:19.890 
Epoch 245/1000 
	 loss: 389.2524, MinusLogProbMetric: 389.2524, val_loss: 396.2306, val_MinusLogProbMetric: 396.2306

Epoch 245: val_loss did not improve from 395.45624
196/196 - 34s - loss: 389.2524 - MinusLogProbMetric: 389.2524 - val_loss: 396.2306 - val_MinusLogProbMetric: 396.2306 - lr: 1.6667e-04 - 34s/epoch - 176ms/step
Epoch 246/1000
2023-09-10 16:52:56.018 
Epoch 246/1000 
	 loss: 389.3199, MinusLogProbMetric: 389.3199, val_loss: 403.1483, val_MinusLogProbMetric: 403.1483

Epoch 246: val_loss did not improve from 395.45624
196/196 - 36s - loss: 389.3199 - MinusLogProbMetric: 389.3199 - val_loss: 403.1483 - val_MinusLogProbMetric: 403.1483 - lr: 1.6667e-04 - 36s/epoch - 184ms/step
Epoch 247/1000
2023-09-10 16:53:31.269 
Epoch 247/1000 
	 loss: 389.4501, MinusLogProbMetric: 389.4501, val_loss: 396.3368, val_MinusLogProbMetric: 396.3368

Epoch 247: val_loss did not improve from 395.45624
196/196 - 35s - loss: 389.4501 - MinusLogProbMetric: 389.4501 - val_loss: 396.3368 - val_MinusLogProbMetric: 396.3368 - lr: 1.6667e-04 - 35s/epoch - 180ms/step
Epoch 248/1000
2023-09-10 16:54:05.432 
Epoch 248/1000 
	 loss: 389.3095, MinusLogProbMetric: 389.3095, val_loss: 396.5831, val_MinusLogProbMetric: 396.5831

Epoch 248: val_loss did not improve from 395.45624
196/196 - 34s - loss: 389.3095 - MinusLogProbMetric: 389.3095 - val_loss: 396.5831 - val_MinusLogProbMetric: 396.5831 - lr: 1.6667e-04 - 34s/epoch - 174ms/step
Epoch 249/1000
2023-09-10 16:54:38.902 
Epoch 249/1000 
	 loss: 389.0036, MinusLogProbMetric: 389.0036, val_loss: 397.3293, val_MinusLogProbMetric: 397.3293

Epoch 249: val_loss did not improve from 395.45624
196/196 - 33s - loss: 389.0036 - MinusLogProbMetric: 389.0036 - val_loss: 397.3293 - val_MinusLogProbMetric: 397.3293 - lr: 1.6667e-04 - 33s/epoch - 171ms/step
Epoch 250/1000
2023-09-10 16:55:14.112 
Epoch 250/1000 
	 loss: 389.3204, MinusLogProbMetric: 389.3204, val_loss: 397.9765, val_MinusLogProbMetric: 397.9765

Epoch 250: val_loss did not improve from 395.45624
196/196 - 35s - loss: 389.3204 - MinusLogProbMetric: 389.3204 - val_loss: 397.9765 - val_MinusLogProbMetric: 397.9765 - lr: 1.6667e-04 - 35s/epoch - 180ms/step
Epoch 251/1000
2023-09-10 16:55:47.343 
Epoch 251/1000 
	 loss: 389.1624, MinusLogProbMetric: 389.1624, val_loss: 396.7849, val_MinusLogProbMetric: 396.7849

Epoch 251: val_loss did not improve from 395.45624
196/196 - 33s - loss: 389.1624 - MinusLogProbMetric: 389.1624 - val_loss: 396.7849 - val_MinusLogProbMetric: 396.7849 - lr: 1.6667e-04 - 33s/epoch - 169ms/step
Epoch 252/1000
2023-09-10 16:56:26.428 
Epoch 252/1000 
	 loss: 389.3368, MinusLogProbMetric: 389.3368, val_loss: 396.4338, val_MinusLogProbMetric: 396.4338

Epoch 252: val_loss did not improve from 395.45624
196/196 - 39s - loss: 389.3368 - MinusLogProbMetric: 389.3368 - val_loss: 396.4338 - val_MinusLogProbMetric: 396.4338 - lr: 1.6667e-04 - 39s/epoch - 199ms/step
Epoch 253/1000
2023-09-10 16:56:58.762 
Epoch 253/1000 
	 loss: 389.0795, MinusLogProbMetric: 389.0795, val_loss: 396.4554, val_MinusLogProbMetric: 396.4554

Epoch 253: val_loss did not improve from 395.45624
196/196 - 32s - loss: 389.0795 - MinusLogProbMetric: 389.0795 - val_loss: 396.4554 - val_MinusLogProbMetric: 396.4554 - lr: 1.6667e-04 - 32s/epoch - 165ms/step
Epoch 254/1000
2023-09-10 16:57:38.656 
Epoch 254/1000 
	 loss: 389.0821, MinusLogProbMetric: 389.0821, val_loss: 396.0791, val_MinusLogProbMetric: 396.0791

Epoch 254: val_loss did not improve from 395.45624
196/196 - 40s - loss: 389.0821 - MinusLogProbMetric: 389.0821 - val_loss: 396.0791 - val_MinusLogProbMetric: 396.0791 - lr: 1.6667e-04 - 40s/epoch - 204ms/step
Epoch 255/1000
2023-09-10 16:58:18.783 
Epoch 255/1000 
	 loss: 389.4230, MinusLogProbMetric: 389.4230, val_loss: 395.6929, val_MinusLogProbMetric: 395.6929

Epoch 255: val_loss did not improve from 395.45624
196/196 - 40s - loss: 389.4230 - MinusLogProbMetric: 389.4230 - val_loss: 395.6929 - val_MinusLogProbMetric: 395.6929 - lr: 1.6667e-04 - 40s/epoch - 205ms/step
Epoch 256/1000
2023-09-10 16:58:55.935 
Epoch 256/1000 
	 loss: 389.0695, MinusLogProbMetric: 389.0695, val_loss: 396.7434, val_MinusLogProbMetric: 396.7434

Epoch 256: val_loss did not improve from 395.45624
196/196 - 37s - loss: 389.0695 - MinusLogProbMetric: 389.0695 - val_loss: 396.7434 - val_MinusLogProbMetric: 396.7434 - lr: 1.6667e-04 - 37s/epoch - 190ms/step
Epoch 257/1000
2023-09-10 16:59:35.528 
Epoch 257/1000 
	 loss: 389.3999, MinusLogProbMetric: 389.3999, val_loss: 395.5711, val_MinusLogProbMetric: 395.5711

Epoch 257: val_loss did not improve from 395.45624
196/196 - 40s - loss: 389.3999 - MinusLogProbMetric: 389.3999 - val_loss: 395.5711 - val_MinusLogProbMetric: 395.5711 - lr: 1.6667e-04 - 40s/epoch - 202ms/step
Epoch 258/1000
2023-09-10 17:00:18.283 
Epoch 258/1000 
	 loss: 388.8919, MinusLogProbMetric: 388.8919, val_loss: 396.7995, val_MinusLogProbMetric: 396.7995

Epoch 258: val_loss did not improve from 395.45624
196/196 - 43s - loss: 388.8919 - MinusLogProbMetric: 388.8919 - val_loss: 396.7995 - val_MinusLogProbMetric: 396.7995 - lr: 1.6667e-04 - 43s/epoch - 218ms/step
Epoch 259/1000
2023-09-10 17:00:57.033 
Epoch 259/1000 
	 loss: 389.3160, MinusLogProbMetric: 389.3160, val_loss: 396.3305, val_MinusLogProbMetric: 396.3305

Epoch 259: val_loss did not improve from 395.45624
196/196 - 39s - loss: 389.3160 - MinusLogProbMetric: 389.3160 - val_loss: 396.3305 - val_MinusLogProbMetric: 396.3305 - lr: 1.6667e-04 - 39s/epoch - 198ms/step
Epoch 260/1000
2023-09-10 17:01:36.734 
Epoch 260/1000 
	 loss: 388.9269, MinusLogProbMetric: 388.9269, val_loss: 396.5504, val_MinusLogProbMetric: 396.5504

Epoch 260: val_loss did not improve from 395.45624
196/196 - 40s - loss: 388.9269 - MinusLogProbMetric: 388.9269 - val_loss: 396.5504 - val_MinusLogProbMetric: 396.5504 - lr: 1.6667e-04 - 40s/epoch - 202ms/step
Epoch 261/1000
2023-09-10 17:02:18.367 
Epoch 261/1000 
	 loss: 389.2534, MinusLogProbMetric: 389.2534, val_loss: 395.5716, val_MinusLogProbMetric: 395.5716

Epoch 261: val_loss did not improve from 395.45624
196/196 - 42s - loss: 389.2534 - MinusLogProbMetric: 389.2534 - val_loss: 395.5716 - val_MinusLogProbMetric: 395.5716 - lr: 1.6667e-04 - 42s/epoch - 212ms/step
Epoch 262/1000
2023-09-10 17:02:58.580 
Epoch 262/1000 
	 loss: 389.1331, MinusLogProbMetric: 389.1331, val_loss: 396.7364, val_MinusLogProbMetric: 396.7364

Epoch 262: val_loss did not improve from 395.45624
196/196 - 40s - loss: 389.1331 - MinusLogProbMetric: 389.1331 - val_loss: 396.7364 - val_MinusLogProbMetric: 396.7364 - lr: 1.6667e-04 - 40s/epoch - 205ms/step
Epoch 263/1000
2023-09-10 17:03:37.286 
Epoch 263/1000 
	 loss: 389.1448, MinusLogProbMetric: 389.1448, val_loss: 396.2114, val_MinusLogProbMetric: 396.2114

Epoch 263: val_loss did not improve from 395.45624
196/196 - 39s - loss: 389.1448 - MinusLogProbMetric: 389.1448 - val_loss: 396.2114 - val_MinusLogProbMetric: 396.2114 - lr: 1.6667e-04 - 39s/epoch - 197ms/step
Epoch 264/1000
2023-09-10 17:04:15.402 
Epoch 264/1000 
	 loss: 389.0283, MinusLogProbMetric: 389.0283, val_loss: 396.4209, val_MinusLogProbMetric: 396.4209

Epoch 264: val_loss did not improve from 395.45624
196/196 - 38s - loss: 389.0283 - MinusLogProbMetric: 389.0283 - val_loss: 396.4209 - val_MinusLogProbMetric: 396.4209 - lr: 1.6667e-04 - 38s/epoch - 194ms/step
Epoch 265/1000
2023-09-10 17:04:52.287 
Epoch 265/1000 
	 loss: 389.0300, MinusLogProbMetric: 389.0300, val_loss: 395.1932, val_MinusLogProbMetric: 395.1932

Epoch 265: val_loss improved from 395.45624 to 395.19324, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 39s - loss: 389.0300 - MinusLogProbMetric: 389.0300 - val_loss: 395.1932 - val_MinusLogProbMetric: 395.1932 - lr: 1.6667e-04 - 39s/epoch - 200ms/step
Epoch 266/1000
2023-09-10 17:05:30.137 
Epoch 266/1000 
	 loss: 389.0125, MinusLogProbMetric: 389.0125, val_loss: 398.6355, val_MinusLogProbMetric: 398.6355

Epoch 266: val_loss did not improve from 395.19324
196/196 - 36s - loss: 389.0125 - MinusLogProbMetric: 389.0125 - val_loss: 398.6355 - val_MinusLogProbMetric: 398.6355 - lr: 1.6667e-04 - 36s/epoch - 181ms/step
Epoch 267/1000
2023-09-10 17:06:07.407 
Epoch 267/1000 
	 loss: 389.1254, MinusLogProbMetric: 389.1254, val_loss: 396.2960, val_MinusLogProbMetric: 396.2960

Epoch 267: val_loss did not improve from 395.19324
196/196 - 37s - loss: 389.1254 - MinusLogProbMetric: 389.1254 - val_loss: 396.2960 - val_MinusLogProbMetric: 396.2960 - lr: 1.6667e-04 - 37s/epoch - 190ms/step
Epoch 268/1000
2023-09-10 17:06:46.636 
Epoch 268/1000 
	 loss: 388.9160, MinusLogProbMetric: 388.9160, val_loss: 396.5539, val_MinusLogProbMetric: 396.5539

Epoch 268: val_loss did not improve from 395.19324
196/196 - 39s - loss: 388.9160 - MinusLogProbMetric: 388.9160 - val_loss: 396.5539 - val_MinusLogProbMetric: 396.5539 - lr: 1.6667e-04 - 39s/epoch - 200ms/step
Epoch 269/1000
2023-09-10 17:07:28.010 
Epoch 269/1000 
	 loss: 388.8170, MinusLogProbMetric: 388.8170, val_loss: 396.7621, val_MinusLogProbMetric: 396.7621

Epoch 269: val_loss did not improve from 395.19324
196/196 - 41s - loss: 388.8170 - MinusLogProbMetric: 388.8170 - val_loss: 396.7621 - val_MinusLogProbMetric: 396.7621 - lr: 1.6667e-04 - 41s/epoch - 211ms/step
Epoch 270/1000
2023-09-10 17:08:05.755 
Epoch 270/1000 
	 loss: 389.2410, MinusLogProbMetric: 389.2410, val_loss: 396.7010, val_MinusLogProbMetric: 396.7010

Epoch 270: val_loss did not improve from 395.19324
196/196 - 38s - loss: 389.2410 - MinusLogProbMetric: 389.2410 - val_loss: 396.7010 - val_MinusLogProbMetric: 396.7010 - lr: 1.6667e-04 - 38s/epoch - 192ms/step
Epoch 271/1000
2023-09-10 17:08:46.197 
Epoch 271/1000 
	 loss: 389.1195, MinusLogProbMetric: 389.1195, val_loss: 395.8172, val_MinusLogProbMetric: 395.8172

Epoch 271: val_loss did not improve from 395.19324
196/196 - 40s - loss: 389.1195 - MinusLogProbMetric: 389.1195 - val_loss: 395.8172 - val_MinusLogProbMetric: 395.8172 - lr: 1.6667e-04 - 40s/epoch - 206ms/step
Epoch 272/1000
2023-09-10 17:09:26.347 
Epoch 272/1000 
	 loss: 388.9569, MinusLogProbMetric: 388.9569, val_loss: 395.9994, val_MinusLogProbMetric: 395.9994

Epoch 272: val_loss did not improve from 395.19324
196/196 - 40s - loss: 388.9569 - MinusLogProbMetric: 388.9569 - val_loss: 395.9994 - val_MinusLogProbMetric: 395.9994 - lr: 1.6667e-04 - 40s/epoch - 205ms/step
Epoch 273/1000
2023-09-10 17:10:02.897 
Epoch 273/1000 
	 loss: 389.1941, MinusLogProbMetric: 389.1941, val_loss: 395.1193, val_MinusLogProbMetric: 395.1193

Epoch 273: val_loss improved from 395.19324 to 395.11929, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 38s - loss: 389.1941 - MinusLogProbMetric: 389.1941 - val_loss: 395.1193 - val_MinusLogProbMetric: 395.1193 - lr: 1.6667e-04 - 38s/epoch - 194ms/step
Epoch 274/1000
2023-09-10 17:10:45.139 
Epoch 274/1000 
	 loss: 389.1559, MinusLogProbMetric: 389.1559, val_loss: 397.1287, val_MinusLogProbMetric: 397.1287

Epoch 274: val_loss did not improve from 395.11929
196/196 - 41s - loss: 389.1559 - MinusLogProbMetric: 389.1559 - val_loss: 397.1287 - val_MinusLogProbMetric: 397.1287 - lr: 1.6667e-04 - 41s/epoch - 208ms/step
Epoch 275/1000
2023-09-10 17:11:28.002 
Epoch 275/1000 
	 loss: 388.6946, MinusLogProbMetric: 388.6946, val_loss: 395.7623, val_MinusLogProbMetric: 395.7623

Epoch 275: val_loss did not improve from 395.11929
196/196 - 43s - loss: 388.6946 - MinusLogProbMetric: 388.6946 - val_loss: 395.7623 - val_MinusLogProbMetric: 395.7623 - lr: 1.6667e-04 - 43s/epoch - 218ms/step
Epoch 276/1000
2023-09-10 17:12:11.421 
Epoch 276/1000 
	 loss: 388.9359, MinusLogProbMetric: 388.9359, val_loss: 396.3896, val_MinusLogProbMetric: 396.3896

Epoch 276: val_loss did not improve from 395.11929
196/196 - 43s - loss: 388.9359 - MinusLogProbMetric: 388.9359 - val_loss: 396.3896 - val_MinusLogProbMetric: 396.3896 - lr: 1.6667e-04 - 43s/epoch - 221ms/step
Epoch 277/1000
2023-09-10 17:12:48.350 
Epoch 277/1000 
	 loss: 389.0692, MinusLogProbMetric: 389.0692, val_loss: 397.9811, val_MinusLogProbMetric: 397.9811

Epoch 277: val_loss did not improve from 395.11929
196/196 - 37s - loss: 389.0692 - MinusLogProbMetric: 389.0692 - val_loss: 397.9811 - val_MinusLogProbMetric: 397.9811 - lr: 1.6667e-04 - 37s/epoch - 188ms/step
Epoch 278/1000
2023-09-10 17:13:31.291 
Epoch 278/1000 
	 loss: 389.0918, MinusLogProbMetric: 389.0918, val_loss: 397.1709, val_MinusLogProbMetric: 397.1709

Epoch 278: val_loss did not improve from 395.11929
196/196 - 43s - loss: 389.0918 - MinusLogProbMetric: 389.0918 - val_loss: 397.1709 - val_MinusLogProbMetric: 397.1709 - lr: 1.6667e-04 - 43s/epoch - 219ms/step
Epoch 279/1000
2023-09-10 17:14:10.209 
Epoch 279/1000 
	 loss: 388.7658, MinusLogProbMetric: 388.7658, val_loss: 396.5555, val_MinusLogProbMetric: 396.5555

Epoch 279: val_loss did not improve from 395.11929
196/196 - 39s - loss: 388.7658 - MinusLogProbMetric: 388.7658 - val_loss: 396.5555 - val_MinusLogProbMetric: 396.5555 - lr: 1.6667e-04 - 39s/epoch - 199ms/step
Epoch 280/1000
2023-09-10 17:14:52.289 
Epoch 280/1000 
	 loss: 388.8823, MinusLogProbMetric: 388.8823, val_loss: 395.8766, val_MinusLogProbMetric: 395.8766

Epoch 280: val_loss did not improve from 395.11929
196/196 - 42s - loss: 388.8823 - MinusLogProbMetric: 388.8823 - val_loss: 395.8766 - val_MinusLogProbMetric: 395.8766 - lr: 1.6667e-04 - 42s/epoch - 215ms/step
Epoch 281/1000
2023-09-10 17:15:33.094 
Epoch 281/1000 
	 loss: 388.8090, MinusLogProbMetric: 388.8090, val_loss: 396.5577, val_MinusLogProbMetric: 396.5577

Epoch 281: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.8090 - MinusLogProbMetric: 388.8090 - val_loss: 396.5577 - val_MinusLogProbMetric: 396.5577 - lr: 1.6667e-04 - 41s/epoch - 208ms/step
Epoch 282/1000
2023-09-10 17:16:12.526 
Epoch 282/1000 
	 loss: 388.8030, MinusLogProbMetric: 388.8030, val_loss: 398.9803, val_MinusLogProbMetric: 398.9803

Epoch 282: val_loss did not improve from 395.11929
196/196 - 39s - loss: 388.8030 - MinusLogProbMetric: 388.8030 - val_loss: 398.9803 - val_MinusLogProbMetric: 398.9803 - lr: 1.6667e-04 - 39s/epoch - 201ms/step
Epoch 283/1000
2023-09-10 17:16:53.450 
Epoch 283/1000 
	 loss: 388.8300, MinusLogProbMetric: 388.8300, val_loss: 395.7672, val_MinusLogProbMetric: 395.7672

Epoch 283: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.8300 - MinusLogProbMetric: 388.8300 - val_loss: 395.7672 - val_MinusLogProbMetric: 395.7672 - lr: 1.6667e-04 - 41s/epoch - 208ms/step
Epoch 284/1000
2023-09-10 17:17:34.025 
Epoch 284/1000 
	 loss: 388.8161, MinusLogProbMetric: 388.8161, val_loss: 395.2851, val_MinusLogProbMetric: 395.2851

Epoch 284: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.8161 - MinusLogProbMetric: 388.8161 - val_loss: 395.2851 - val_MinusLogProbMetric: 395.2851 - lr: 1.6667e-04 - 41s/epoch - 207ms/step
Epoch 285/1000
2023-09-10 17:18:17.385 
Epoch 285/1000 
	 loss: 388.6693, MinusLogProbMetric: 388.6693, val_loss: 395.8613, val_MinusLogProbMetric: 395.8613

Epoch 285: val_loss did not improve from 395.11929
196/196 - 43s - loss: 388.6693 - MinusLogProbMetric: 388.6693 - val_loss: 395.8613 - val_MinusLogProbMetric: 395.8613 - lr: 1.6667e-04 - 43s/epoch - 221ms/step
Epoch 286/1000
2023-09-10 17:19:06.299 
Epoch 286/1000 
	 loss: 389.0178, MinusLogProbMetric: 389.0178, val_loss: 397.0635, val_MinusLogProbMetric: 397.0635

Epoch 286: val_loss did not improve from 395.11929
196/196 - 49s - loss: 389.0178 - MinusLogProbMetric: 389.0178 - val_loss: 397.0635 - val_MinusLogProbMetric: 397.0635 - lr: 1.6667e-04 - 49s/epoch - 249ms/step
Epoch 287/1000
2023-09-10 17:19:42.821 
Epoch 287/1000 
	 loss: 388.6513, MinusLogProbMetric: 388.6513, val_loss: 396.5348, val_MinusLogProbMetric: 396.5348

Epoch 287: val_loss did not improve from 395.11929
196/196 - 36s - loss: 388.6513 - MinusLogProbMetric: 388.6513 - val_loss: 396.5348 - val_MinusLogProbMetric: 396.5348 - lr: 1.6667e-04 - 36s/epoch - 186ms/step
Epoch 288/1000
2023-09-10 17:20:23.595 
Epoch 288/1000 
	 loss: 388.8647, MinusLogProbMetric: 388.8647, val_loss: 397.1129, val_MinusLogProbMetric: 397.1129

Epoch 288: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.8647 - MinusLogProbMetric: 388.8647 - val_loss: 397.1129 - val_MinusLogProbMetric: 397.1129 - lr: 1.6667e-04 - 41s/epoch - 208ms/step
Epoch 289/1000
2023-09-10 17:21:00.769 
Epoch 289/1000 
	 loss: 388.8690, MinusLogProbMetric: 388.8690, val_loss: 397.2127, val_MinusLogProbMetric: 397.2127

Epoch 289: val_loss did not improve from 395.11929
196/196 - 37s - loss: 388.8690 - MinusLogProbMetric: 388.8690 - val_loss: 397.2127 - val_MinusLogProbMetric: 397.2127 - lr: 1.6667e-04 - 37s/epoch - 190ms/step
Epoch 290/1000
2023-09-10 17:21:38.829 
Epoch 290/1000 
	 loss: 388.5665, MinusLogProbMetric: 388.5665, val_loss: 397.5036, val_MinusLogProbMetric: 397.5036

Epoch 290: val_loss did not improve from 395.11929
196/196 - 38s - loss: 388.5665 - MinusLogProbMetric: 388.5665 - val_loss: 397.5036 - val_MinusLogProbMetric: 397.5036 - lr: 1.6667e-04 - 38s/epoch - 194ms/step
Epoch 291/1000
2023-09-10 17:22:18.315 
Epoch 291/1000 
	 loss: 388.8961, MinusLogProbMetric: 388.8961, val_loss: 396.4467, val_MinusLogProbMetric: 396.4467

Epoch 291: val_loss did not improve from 395.11929
196/196 - 39s - loss: 388.8961 - MinusLogProbMetric: 388.8961 - val_loss: 396.4467 - val_MinusLogProbMetric: 396.4467 - lr: 1.6667e-04 - 39s/epoch - 201ms/step
Epoch 292/1000
2023-09-10 17:22:59.179 
Epoch 292/1000 
	 loss: 388.6927, MinusLogProbMetric: 388.6927, val_loss: 395.7609, val_MinusLogProbMetric: 395.7609

Epoch 292: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.6927 - MinusLogProbMetric: 388.6927 - val_loss: 395.7609 - val_MinusLogProbMetric: 395.7609 - lr: 1.6667e-04 - 41s/epoch - 208ms/step
Epoch 293/1000
2023-09-10 17:23:46.475 
Epoch 293/1000 
	 loss: 388.6850, MinusLogProbMetric: 388.6850, val_loss: 396.9740, val_MinusLogProbMetric: 396.9740

Epoch 293: val_loss did not improve from 395.11929
196/196 - 47s - loss: 388.6850 - MinusLogProbMetric: 388.6850 - val_loss: 396.9740 - val_MinusLogProbMetric: 396.9740 - lr: 1.6667e-04 - 47s/epoch - 241ms/step
Epoch 294/1000
2023-09-10 17:24:28.323 
Epoch 294/1000 
	 loss: 388.5186, MinusLogProbMetric: 388.5186, val_loss: 396.4696, val_MinusLogProbMetric: 396.4696

Epoch 294: val_loss did not improve from 395.11929
196/196 - 42s - loss: 388.5186 - MinusLogProbMetric: 388.5186 - val_loss: 396.4696 - val_MinusLogProbMetric: 396.4696 - lr: 1.6667e-04 - 42s/epoch - 213ms/step
Epoch 295/1000
2023-09-10 17:25:13.000 
Epoch 295/1000 
	 loss: 389.0367, MinusLogProbMetric: 389.0367, val_loss: 397.1761, val_MinusLogProbMetric: 397.1761

Epoch 295: val_loss did not improve from 395.11929
196/196 - 45s - loss: 389.0367 - MinusLogProbMetric: 389.0367 - val_loss: 397.1761 - val_MinusLogProbMetric: 397.1761 - lr: 1.6667e-04 - 45s/epoch - 228ms/step
Epoch 296/1000
2023-09-10 17:25:55.394 
Epoch 296/1000 
	 loss: 388.5977, MinusLogProbMetric: 388.5977, val_loss: 395.7937, val_MinusLogProbMetric: 395.7937

Epoch 296: val_loss did not improve from 395.11929
196/196 - 42s - loss: 388.5977 - MinusLogProbMetric: 388.5977 - val_loss: 395.7937 - val_MinusLogProbMetric: 395.7937 - lr: 1.6667e-04 - 42s/epoch - 216ms/step
Epoch 297/1000
2023-09-10 17:26:33.521 
Epoch 297/1000 
	 loss: 388.8583, MinusLogProbMetric: 388.8583, val_loss: 398.8059, val_MinusLogProbMetric: 398.8059

Epoch 297: val_loss did not improve from 395.11929
196/196 - 38s - loss: 388.8583 - MinusLogProbMetric: 388.8583 - val_loss: 398.8059 - val_MinusLogProbMetric: 398.8059 - lr: 1.6667e-04 - 38s/epoch - 194ms/step
Epoch 298/1000
2023-09-10 17:27:08.624 
Epoch 298/1000 
	 loss: 388.4779, MinusLogProbMetric: 388.4779, val_loss: 396.1197, val_MinusLogProbMetric: 396.1197

Epoch 298: val_loss did not improve from 395.11929
196/196 - 35s - loss: 388.4779 - MinusLogProbMetric: 388.4779 - val_loss: 396.1197 - val_MinusLogProbMetric: 396.1197 - lr: 1.6667e-04 - 35s/epoch - 179ms/step
Epoch 299/1000
2023-09-10 17:27:46.564 
Epoch 299/1000 
	 loss: 388.6082, MinusLogProbMetric: 388.6082, val_loss: 396.1377, val_MinusLogProbMetric: 396.1377

Epoch 299: val_loss did not improve from 395.11929
196/196 - 38s - loss: 388.6082 - MinusLogProbMetric: 388.6082 - val_loss: 396.1377 - val_MinusLogProbMetric: 396.1377 - lr: 1.6667e-04 - 38s/epoch - 193ms/step
Epoch 300/1000
2023-09-10 17:28:20.849 
Epoch 300/1000 
	 loss: 388.8925, MinusLogProbMetric: 388.8925, val_loss: 395.4100, val_MinusLogProbMetric: 395.4100

Epoch 300: val_loss did not improve from 395.11929
196/196 - 34s - loss: 388.8925 - MinusLogProbMetric: 388.8925 - val_loss: 395.4100 - val_MinusLogProbMetric: 395.4100 - lr: 1.6667e-04 - 34s/epoch - 175ms/step
Epoch 301/1000
2023-09-10 17:29:00.611 
Epoch 301/1000 
	 loss: 388.9158, MinusLogProbMetric: 388.9158, val_loss: 395.8882, val_MinusLogProbMetric: 395.8882

Epoch 301: val_loss did not improve from 395.11929
196/196 - 40s - loss: 388.9158 - MinusLogProbMetric: 388.9158 - val_loss: 395.8882 - val_MinusLogProbMetric: 395.8882 - lr: 1.6667e-04 - 40s/epoch - 203ms/step
Epoch 302/1000
2023-09-10 17:29:42.521 
Epoch 302/1000 
	 loss: 388.5479, MinusLogProbMetric: 388.5479, val_loss: 395.2905, val_MinusLogProbMetric: 395.2905

Epoch 302: val_loss did not improve from 395.11929
196/196 - 42s - loss: 388.5479 - MinusLogProbMetric: 388.5479 - val_loss: 395.2905 - val_MinusLogProbMetric: 395.2905 - lr: 1.6667e-04 - 42s/epoch - 214ms/step
Epoch 303/1000
2023-09-10 17:30:21.262 
Epoch 303/1000 
	 loss: 388.7005, MinusLogProbMetric: 388.7005, val_loss: 395.9421, val_MinusLogProbMetric: 395.9421

Epoch 303: val_loss did not improve from 395.11929
196/196 - 39s - loss: 388.7005 - MinusLogProbMetric: 388.7005 - val_loss: 395.9421 - val_MinusLogProbMetric: 395.9421 - lr: 1.6667e-04 - 39s/epoch - 197ms/step
Epoch 304/1000
2023-09-10 17:30:59.291 
Epoch 304/1000 
	 loss: 388.6457, MinusLogProbMetric: 388.6457, val_loss: 395.5571, val_MinusLogProbMetric: 395.5571

Epoch 304: val_loss did not improve from 395.11929
196/196 - 38s - loss: 388.6457 - MinusLogProbMetric: 388.6457 - val_loss: 395.5571 - val_MinusLogProbMetric: 395.5571 - lr: 1.6667e-04 - 38s/epoch - 194ms/step
Epoch 305/1000
2023-09-10 17:31:44.443 
Epoch 305/1000 
	 loss: 388.5511, MinusLogProbMetric: 388.5511, val_loss: 396.7467, val_MinusLogProbMetric: 396.7466

Epoch 305: val_loss did not improve from 395.11929
196/196 - 45s - loss: 388.5511 - MinusLogProbMetric: 388.5511 - val_loss: 396.7467 - val_MinusLogProbMetric: 396.7466 - lr: 1.6667e-04 - 45s/epoch - 230ms/step
Epoch 306/1000
2023-09-10 17:32:21.018 
Epoch 306/1000 
	 loss: 388.8843, MinusLogProbMetric: 388.8843, val_loss: 396.1812, val_MinusLogProbMetric: 396.1812

Epoch 306: val_loss did not improve from 395.11929
196/196 - 37s - loss: 388.8843 - MinusLogProbMetric: 388.8843 - val_loss: 396.1812 - val_MinusLogProbMetric: 396.1812 - lr: 1.6667e-04 - 37s/epoch - 187ms/step
Epoch 307/1000
2023-09-10 17:33:08.050 
Epoch 307/1000 
	 loss: 388.6213, MinusLogProbMetric: 388.6213, val_loss: 395.8809, val_MinusLogProbMetric: 395.8809

Epoch 307: val_loss did not improve from 395.11929
196/196 - 47s - loss: 388.6213 - MinusLogProbMetric: 388.6213 - val_loss: 395.8809 - val_MinusLogProbMetric: 395.8809 - lr: 1.6667e-04 - 47s/epoch - 240ms/step
Epoch 308/1000
2023-09-10 17:33:47.806 
Epoch 308/1000 
	 loss: 388.7410, MinusLogProbMetric: 388.7410, val_loss: 397.4262, val_MinusLogProbMetric: 397.4262

Epoch 308: val_loss did not improve from 395.11929
196/196 - 40s - loss: 388.7410 - MinusLogProbMetric: 388.7410 - val_loss: 397.4262 - val_MinusLogProbMetric: 397.4262 - lr: 1.6667e-04 - 40s/epoch - 203ms/step
Epoch 309/1000
2023-09-10 17:34:23.803 
Epoch 309/1000 
	 loss: 388.8051, MinusLogProbMetric: 388.8051, val_loss: 398.0220, val_MinusLogProbMetric: 398.0220

Epoch 309: val_loss did not improve from 395.11929
196/196 - 36s - loss: 388.8051 - MinusLogProbMetric: 388.8051 - val_loss: 398.0220 - val_MinusLogProbMetric: 398.0220 - lr: 1.6667e-04 - 36s/epoch - 183ms/step
Epoch 310/1000
2023-09-10 17:35:08.417 
Epoch 310/1000 
	 loss: 388.6136, MinusLogProbMetric: 388.6136, val_loss: 396.6574, val_MinusLogProbMetric: 396.6574

Epoch 310: val_loss did not improve from 395.11929
196/196 - 45s - loss: 388.6136 - MinusLogProbMetric: 388.6136 - val_loss: 396.6574 - val_MinusLogProbMetric: 396.6574 - lr: 1.6667e-04 - 45s/epoch - 228ms/step
Epoch 311/1000
2023-09-10 17:35:44.095 
Epoch 311/1000 
	 loss: 388.6217, MinusLogProbMetric: 388.6217, val_loss: 396.4886, val_MinusLogProbMetric: 396.4886

Epoch 311: val_loss did not improve from 395.11929
196/196 - 36s - loss: 388.6217 - MinusLogProbMetric: 388.6217 - val_loss: 396.4886 - val_MinusLogProbMetric: 396.4886 - lr: 1.6667e-04 - 36s/epoch - 182ms/step
Epoch 312/1000
2023-09-10 17:36:18.602 
Epoch 312/1000 
	 loss: 388.7981, MinusLogProbMetric: 388.7981, val_loss: 395.9425, val_MinusLogProbMetric: 395.9425

Epoch 312: val_loss did not improve from 395.11929
196/196 - 34s - loss: 388.7981 - MinusLogProbMetric: 388.7981 - val_loss: 395.9425 - val_MinusLogProbMetric: 395.9425 - lr: 1.6667e-04 - 34s/epoch - 176ms/step
Epoch 313/1000
2023-09-10 17:37:02.042 
Epoch 313/1000 
	 loss: 388.4844, MinusLogProbMetric: 388.4844, val_loss: 395.6521, val_MinusLogProbMetric: 395.6521

Epoch 313: val_loss did not improve from 395.11929
196/196 - 43s - loss: 388.4844 - MinusLogProbMetric: 388.4844 - val_loss: 395.6521 - val_MinusLogProbMetric: 395.6521 - lr: 1.6667e-04 - 43s/epoch - 222ms/step
Epoch 314/1000
2023-09-10 17:37:37.729 
Epoch 314/1000 
	 loss: 388.7073, MinusLogProbMetric: 388.7073, val_loss: 399.1059, val_MinusLogProbMetric: 399.1059

Epoch 314: val_loss did not improve from 395.11929
196/196 - 36s - loss: 388.7073 - MinusLogProbMetric: 388.7073 - val_loss: 399.1059 - val_MinusLogProbMetric: 399.1059 - lr: 1.6667e-04 - 36s/epoch - 182ms/step
Epoch 315/1000
2023-09-10 17:38:24.755 
Epoch 315/1000 
	 loss: 388.5630, MinusLogProbMetric: 388.5630, val_loss: 395.2728, val_MinusLogProbMetric: 395.2728

Epoch 315: val_loss did not improve from 395.11929
196/196 - 47s - loss: 388.5630 - MinusLogProbMetric: 388.5630 - val_loss: 395.2728 - val_MinusLogProbMetric: 395.2728 - lr: 1.6667e-04 - 47s/epoch - 240ms/step
Epoch 316/1000
2023-09-10 17:39:05.228 
Epoch 316/1000 
	 loss: 388.4928, MinusLogProbMetric: 388.4928, val_loss: 396.9465, val_MinusLogProbMetric: 396.9465

Epoch 316: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.4928 - MinusLogProbMetric: 388.4928 - val_loss: 396.9465 - val_MinusLogProbMetric: 396.9465 - lr: 1.6667e-04 - 41s/epoch - 207ms/step
Epoch 317/1000
2023-09-10 17:39:42.515 
Epoch 317/1000 
	 loss: 388.4624, MinusLogProbMetric: 388.4624, val_loss: 396.0076, val_MinusLogProbMetric: 396.0076

Epoch 317: val_loss did not improve from 395.11929
196/196 - 37s - loss: 388.4624 - MinusLogProbMetric: 388.4624 - val_loss: 396.0076 - val_MinusLogProbMetric: 396.0076 - lr: 1.6667e-04 - 37s/epoch - 190ms/step
Epoch 318/1000
2023-09-10 17:40:19.733 
Epoch 318/1000 
	 loss: 388.5389, MinusLogProbMetric: 388.5389, val_loss: 396.1507, val_MinusLogProbMetric: 396.1507

Epoch 318: val_loss did not improve from 395.11929
196/196 - 37s - loss: 388.5389 - MinusLogProbMetric: 388.5389 - val_loss: 396.1507 - val_MinusLogProbMetric: 396.1507 - lr: 1.6667e-04 - 37s/epoch - 190ms/step
Epoch 319/1000
2023-09-10 17:41:00.306 
Epoch 319/1000 
	 loss: 388.3679, MinusLogProbMetric: 388.3679, val_loss: 396.6114, val_MinusLogProbMetric: 396.6114

Epoch 319: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.3679 - MinusLogProbMetric: 388.3679 - val_loss: 396.6114 - val_MinusLogProbMetric: 396.6114 - lr: 1.6667e-04 - 41s/epoch - 207ms/step
Epoch 320/1000
2023-09-10 17:41:37.308 
Epoch 320/1000 
	 loss: 388.4128, MinusLogProbMetric: 388.4128, val_loss: 395.6230, val_MinusLogProbMetric: 395.6230

Epoch 320: val_loss did not improve from 395.11929
196/196 - 37s - loss: 388.4128 - MinusLogProbMetric: 388.4128 - val_loss: 395.6230 - val_MinusLogProbMetric: 395.6230 - lr: 1.6667e-04 - 37s/epoch - 189ms/step
Epoch 321/1000
2023-09-10 17:42:14.105 
Epoch 321/1000 
	 loss: 388.6722, MinusLogProbMetric: 388.6722, val_loss: 396.4781, val_MinusLogProbMetric: 396.4781

Epoch 321: val_loss did not improve from 395.11929
196/196 - 37s - loss: 388.6722 - MinusLogProbMetric: 388.6722 - val_loss: 396.4781 - val_MinusLogProbMetric: 396.4781 - lr: 1.6667e-04 - 37s/epoch - 188ms/step
Epoch 322/1000
2023-09-10 17:42:55.587 
Epoch 322/1000 
	 loss: 388.4922, MinusLogProbMetric: 388.4922, val_loss: 396.5018, val_MinusLogProbMetric: 396.5018

Epoch 322: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.4922 - MinusLogProbMetric: 388.4922 - val_loss: 396.5018 - val_MinusLogProbMetric: 396.5018 - lr: 1.6667e-04 - 41s/epoch - 212ms/step
Epoch 323/1000
2023-09-10 17:43:36.394 
Epoch 323/1000 
	 loss: 388.4440, MinusLogProbMetric: 388.4440, val_loss: 396.3048, val_MinusLogProbMetric: 396.3048

Epoch 323: val_loss did not improve from 395.11929
196/196 - 41s - loss: 388.4440 - MinusLogProbMetric: 388.4440 - val_loss: 396.3048 - val_MinusLogProbMetric: 396.3048 - lr: 1.6667e-04 - 41s/epoch - 208ms/step
Epoch 324/1000
2023-09-10 17:44:17.210 
Epoch 324/1000 
	 loss: 386.1475, MinusLogProbMetric: 386.1475, val_loss: 394.3751, val_MinusLogProbMetric: 394.3751

Epoch 324: val_loss improved from 395.11929 to 394.37512, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 43s - loss: 386.1475 - MinusLogProbMetric: 386.1475 - val_loss: 394.3751 - val_MinusLogProbMetric: 394.3751 - lr: 8.3333e-05 - 43s/epoch - 217ms/step
Epoch 325/1000
2023-09-10 17:44:56.190 
Epoch 325/1000 
	 loss: 385.9743, MinusLogProbMetric: 385.9743, val_loss: 394.6281, val_MinusLogProbMetric: 394.6281

Epoch 325: val_loss did not improve from 394.37512
196/196 - 37s - loss: 385.9743 - MinusLogProbMetric: 385.9743 - val_loss: 394.6281 - val_MinusLogProbMetric: 394.6281 - lr: 8.3333e-05 - 37s/epoch - 190ms/step
Epoch 326/1000
2023-09-10 17:45:43.715 
Epoch 326/1000 
	 loss: 386.0190, MinusLogProbMetric: 386.0190, val_loss: 395.8827, val_MinusLogProbMetric: 395.8827

Epoch 326: val_loss did not improve from 394.37512
196/196 - 48s - loss: 386.0190 - MinusLogProbMetric: 386.0190 - val_loss: 395.8827 - val_MinusLogProbMetric: 395.8827 - lr: 8.3333e-05 - 48s/epoch - 242ms/step
Epoch 327/1000
2023-09-10 17:46:22.916 
Epoch 327/1000 
	 loss: 385.9297, MinusLogProbMetric: 385.9297, val_loss: 394.7338, val_MinusLogProbMetric: 394.7338

Epoch 327: val_loss did not improve from 394.37512
196/196 - 39s - loss: 385.9297 - MinusLogProbMetric: 385.9297 - val_loss: 394.7338 - val_MinusLogProbMetric: 394.7338 - lr: 8.3333e-05 - 39s/epoch - 200ms/step
Epoch 328/1000
2023-09-10 17:47:03.192 
Epoch 328/1000 
	 loss: 386.9141, MinusLogProbMetric: 386.9141, val_loss: 394.5059, val_MinusLogProbMetric: 394.5059

Epoch 328: val_loss did not improve from 394.37512
196/196 - 40s - loss: 386.9141 - MinusLogProbMetric: 386.9141 - val_loss: 394.5059 - val_MinusLogProbMetric: 394.5059 - lr: 8.3333e-05 - 40s/epoch - 205ms/step
Epoch 329/1000
2023-09-10 17:47:40.759 
Epoch 329/1000 
	 loss: 385.9615, MinusLogProbMetric: 385.9615, val_loss: 394.4002, val_MinusLogProbMetric: 394.4002

Epoch 329: val_loss did not improve from 394.37512
196/196 - 38s - loss: 385.9615 - MinusLogProbMetric: 385.9615 - val_loss: 394.4002 - val_MinusLogProbMetric: 394.4002 - lr: 8.3333e-05 - 38s/epoch - 192ms/step
Epoch 330/1000
2023-09-10 17:48:18.559 
Epoch 330/1000 
	 loss: 386.1762, MinusLogProbMetric: 386.1762, val_loss: 395.0829, val_MinusLogProbMetric: 395.0829

Epoch 330: val_loss did not improve from 394.37512
196/196 - 38s - loss: 386.1762 - MinusLogProbMetric: 386.1762 - val_loss: 395.0829 - val_MinusLogProbMetric: 395.0829 - lr: 8.3333e-05 - 38s/epoch - 193ms/step
Epoch 331/1000
2023-09-10 17:48:53.161 
Epoch 331/1000 
	 loss: 386.0586, MinusLogProbMetric: 386.0586, val_loss: 394.8638, val_MinusLogProbMetric: 394.8638

Epoch 331: val_loss did not improve from 394.37512
196/196 - 35s - loss: 386.0586 - MinusLogProbMetric: 386.0586 - val_loss: 394.8638 - val_MinusLogProbMetric: 394.8638 - lr: 8.3333e-05 - 35s/epoch - 176ms/step
Epoch 332/1000
2023-09-10 17:49:32.839 
Epoch 332/1000 
	 loss: 386.2292, MinusLogProbMetric: 386.2292, val_loss: 394.5181, val_MinusLogProbMetric: 394.5181

Epoch 332: val_loss did not improve from 394.37512
196/196 - 40s - loss: 386.2292 - MinusLogProbMetric: 386.2292 - val_loss: 394.5181 - val_MinusLogProbMetric: 394.5181 - lr: 8.3333e-05 - 40s/epoch - 202ms/step
Epoch 333/1000
2023-09-10 17:50:06.030 
Epoch 333/1000 
	 loss: 386.1998, MinusLogProbMetric: 386.1998, val_loss: 394.7815, val_MinusLogProbMetric: 394.7815

Epoch 333: val_loss did not improve from 394.37512
196/196 - 33s - loss: 386.1998 - MinusLogProbMetric: 386.1998 - val_loss: 394.7815 - val_MinusLogProbMetric: 394.7815 - lr: 8.3333e-05 - 33s/epoch - 169ms/step
Epoch 334/1000
2023-09-10 17:50:43.439 
Epoch 334/1000 
	 loss: 387.2163, MinusLogProbMetric: 387.2163, val_loss: 394.6323, val_MinusLogProbMetric: 394.6323

Epoch 334: val_loss did not improve from 394.37512
196/196 - 37s - loss: 387.2163 - MinusLogProbMetric: 387.2163 - val_loss: 394.6323 - val_MinusLogProbMetric: 394.6323 - lr: 8.3333e-05 - 37s/epoch - 191ms/step
Epoch 335/1000
2023-09-10 17:51:26.335 
Epoch 335/1000 
	 loss: 386.0237, MinusLogProbMetric: 386.0237, val_loss: 394.7184, val_MinusLogProbMetric: 394.7184

Epoch 335: val_loss did not improve from 394.37512
196/196 - 43s - loss: 386.0237 - MinusLogProbMetric: 386.0237 - val_loss: 394.7184 - val_MinusLogProbMetric: 394.7184 - lr: 8.3333e-05 - 43s/epoch - 219ms/step
Epoch 336/1000
2023-09-10 17:52:07.329 
Epoch 336/1000 
	 loss: 386.0607, MinusLogProbMetric: 386.0607, val_loss: 394.7677, val_MinusLogProbMetric: 394.7677

Epoch 336: val_loss did not improve from 394.37512
196/196 - 41s - loss: 386.0607 - MinusLogProbMetric: 386.0607 - val_loss: 394.7677 - val_MinusLogProbMetric: 394.7677 - lr: 8.3333e-05 - 41s/epoch - 209ms/step
Epoch 337/1000
2023-09-10 17:52:51.853 
Epoch 337/1000 
	 loss: 386.0497, MinusLogProbMetric: 386.0497, val_loss: 394.7973, val_MinusLogProbMetric: 394.7973

Epoch 337: val_loss did not improve from 394.37512
196/196 - 45s - loss: 386.0497 - MinusLogProbMetric: 386.0497 - val_loss: 394.7973 - val_MinusLogProbMetric: 394.7973 - lr: 8.3333e-05 - 45s/epoch - 227ms/step
Epoch 338/1000
2023-09-10 17:53:30.750 
Epoch 338/1000 
	 loss: 386.1127, MinusLogProbMetric: 386.1127, val_loss: 394.3852, val_MinusLogProbMetric: 394.3852

Epoch 338: val_loss did not improve from 394.37512
196/196 - 39s - loss: 386.1127 - MinusLogProbMetric: 386.1127 - val_loss: 394.3852 - val_MinusLogProbMetric: 394.3852 - lr: 8.3333e-05 - 39s/epoch - 198ms/step
Epoch 339/1000
2023-09-10 17:54:05.529 
Epoch 339/1000 
	 loss: 386.0830, MinusLogProbMetric: 386.0830, val_loss: 394.6070, val_MinusLogProbMetric: 394.6070

Epoch 339: val_loss did not improve from 394.37512
196/196 - 35s - loss: 386.0830 - MinusLogProbMetric: 386.0830 - val_loss: 394.6070 - val_MinusLogProbMetric: 394.6070 - lr: 8.3333e-05 - 35s/epoch - 178ms/step
Epoch 340/1000
2023-09-10 17:54:42.922 
Epoch 340/1000 
	 loss: 385.9474, MinusLogProbMetric: 385.9474, val_loss: 394.8303, val_MinusLogProbMetric: 394.8303

Epoch 340: val_loss did not improve from 394.37512
196/196 - 37s - loss: 385.9474 - MinusLogProbMetric: 385.9474 - val_loss: 394.8303 - val_MinusLogProbMetric: 394.8303 - lr: 8.3333e-05 - 37s/epoch - 190ms/step
Epoch 341/1000
2023-09-10 17:55:22.629 
Epoch 341/1000 
	 loss: 386.4745, MinusLogProbMetric: 386.4745, val_loss: 394.8331, val_MinusLogProbMetric: 394.8331

Epoch 341: val_loss did not improve from 394.37512
196/196 - 40s - loss: 386.4745 - MinusLogProbMetric: 386.4745 - val_loss: 394.8331 - val_MinusLogProbMetric: 394.8331 - lr: 8.3333e-05 - 40s/epoch - 203ms/step
Epoch 342/1000
2023-09-10 17:56:04.746 
Epoch 342/1000 
	 loss: 386.0700, MinusLogProbMetric: 386.0700, val_loss: 394.7282, val_MinusLogProbMetric: 394.7282

Epoch 342: val_loss did not improve from 394.37512
196/196 - 42s - loss: 386.0700 - MinusLogProbMetric: 386.0700 - val_loss: 394.7282 - val_MinusLogProbMetric: 394.7282 - lr: 8.3333e-05 - 42s/epoch - 215ms/step
Epoch 343/1000
2023-09-10 17:56:48.727 
Epoch 343/1000 
	 loss: 386.0604, MinusLogProbMetric: 386.0604, val_loss: 395.0072, val_MinusLogProbMetric: 395.0072

Epoch 343: val_loss did not improve from 394.37512
196/196 - 44s - loss: 386.0604 - MinusLogProbMetric: 386.0604 - val_loss: 395.0072 - val_MinusLogProbMetric: 395.0072 - lr: 8.3333e-05 - 44s/epoch - 224ms/step
Epoch 344/1000
2023-09-10 17:57:25.571 
Epoch 344/1000 
	 loss: 386.0590, MinusLogProbMetric: 386.0590, val_loss: 394.4764, val_MinusLogProbMetric: 394.4764

Epoch 344: val_loss did not improve from 394.37512
196/196 - 37s - loss: 386.0590 - MinusLogProbMetric: 386.0590 - val_loss: 394.4764 - val_MinusLogProbMetric: 394.4764 - lr: 8.3333e-05 - 37s/epoch - 188ms/step
Epoch 345/1000
2023-09-10 17:58:04.215 
Epoch 345/1000 
	 loss: 385.9725, MinusLogProbMetric: 385.9725, val_loss: 394.6561, val_MinusLogProbMetric: 394.6561

Epoch 345: val_loss did not improve from 394.37512
196/196 - 39s - loss: 385.9725 - MinusLogProbMetric: 385.9725 - val_loss: 394.6561 - val_MinusLogProbMetric: 394.6561 - lr: 8.3333e-05 - 39s/epoch - 197ms/step
Epoch 346/1000
2023-09-10 17:58:39.588 
Epoch 346/1000 
	 loss: 386.0726, MinusLogProbMetric: 386.0726, val_loss: 394.5595, val_MinusLogProbMetric: 394.5595

Epoch 346: val_loss did not improve from 394.37512
196/196 - 35s - loss: 386.0726 - MinusLogProbMetric: 386.0726 - val_loss: 394.5595 - val_MinusLogProbMetric: 394.5595 - lr: 8.3333e-05 - 35s/epoch - 180ms/step
Epoch 347/1000
2023-09-10 17:59:16.981 
Epoch 347/1000 
	 loss: 386.1640, MinusLogProbMetric: 386.1640, val_loss: 394.7357, val_MinusLogProbMetric: 394.7357

Epoch 347: val_loss did not improve from 394.37512
196/196 - 37s - loss: 386.1640 - MinusLogProbMetric: 386.1640 - val_loss: 394.7357 - val_MinusLogProbMetric: 394.7357 - lr: 8.3333e-05 - 37s/epoch - 191ms/step
Epoch 348/1000
2023-09-10 17:59:54.226 
Epoch 348/1000 
	 loss: 385.9202, MinusLogProbMetric: 385.9202, val_loss: 394.3372, val_MinusLogProbMetric: 394.3372

Epoch 348: val_loss improved from 394.37512 to 394.33722, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 38s - loss: 385.9202 - MinusLogProbMetric: 385.9202 - val_loss: 394.3372 - val_MinusLogProbMetric: 394.3372 - lr: 8.3333e-05 - 38s/epoch - 196ms/step
Epoch 349/1000
2023-09-10 18:00:37.087 
Epoch 349/1000 
	 loss: 386.6946, MinusLogProbMetric: 386.6946, val_loss: 395.0491, val_MinusLogProbMetric: 395.0491

Epoch 349: val_loss did not improve from 394.33722
196/196 - 42s - loss: 386.6946 - MinusLogProbMetric: 386.6946 - val_loss: 395.0491 - val_MinusLogProbMetric: 395.0491 - lr: 8.3333e-05 - 42s/epoch - 213ms/step
Epoch 350/1000
2023-09-10 18:01:17.597 
Epoch 350/1000 
	 loss: 385.8118, MinusLogProbMetric: 385.8118, val_loss: 394.6275, val_MinusLogProbMetric: 394.6275

Epoch 350: val_loss did not improve from 394.33722
196/196 - 40s - loss: 385.8118 - MinusLogProbMetric: 385.8118 - val_loss: 394.6275 - val_MinusLogProbMetric: 394.6275 - lr: 8.3333e-05 - 40s/epoch - 206ms/step
Epoch 351/1000
2023-09-10 18:01:56.941 
Epoch 351/1000 
	 loss: 385.7725, MinusLogProbMetric: 385.7725, val_loss: 394.6246, val_MinusLogProbMetric: 394.6246

Epoch 351: val_loss did not improve from 394.33722
196/196 - 39s - loss: 385.7725 - MinusLogProbMetric: 385.7725 - val_loss: 394.6246 - val_MinusLogProbMetric: 394.6246 - lr: 8.3333e-05 - 39s/epoch - 201ms/step
Epoch 352/1000
2023-09-10 18:02:35.664 
Epoch 352/1000 
	 loss: 386.2497, MinusLogProbMetric: 386.2497, val_loss: 397.3717, val_MinusLogProbMetric: 397.3717

Epoch 352: val_loss did not improve from 394.33722
196/196 - 39s - loss: 386.2497 - MinusLogProbMetric: 386.2497 - val_loss: 397.3717 - val_MinusLogProbMetric: 397.3717 - lr: 8.3333e-05 - 39s/epoch - 197ms/step
Epoch 353/1000
2023-09-10 18:03:08.789 
Epoch 353/1000 
	 loss: 386.1012, MinusLogProbMetric: 386.1012, val_loss: 394.5005, val_MinusLogProbMetric: 394.5005

Epoch 353: val_loss did not improve from 394.33722
196/196 - 33s - loss: 386.1012 - MinusLogProbMetric: 386.1012 - val_loss: 394.5005 - val_MinusLogProbMetric: 394.5005 - lr: 8.3333e-05 - 33s/epoch - 169ms/step
Epoch 354/1000
2023-09-10 18:03:41.892 
Epoch 354/1000 
	 loss: 385.9419, MinusLogProbMetric: 385.9419, val_loss: 395.2177, val_MinusLogProbMetric: 395.2177

Epoch 354: val_loss did not improve from 394.33722
196/196 - 33s - loss: 385.9419 - MinusLogProbMetric: 385.9419 - val_loss: 395.2177 - val_MinusLogProbMetric: 395.2177 - lr: 8.3333e-05 - 33s/epoch - 169ms/step
Epoch 355/1000
2023-09-10 18:04:13.953 
Epoch 355/1000 
	 loss: 386.1739, MinusLogProbMetric: 386.1739, val_loss: 394.5864, val_MinusLogProbMetric: 394.5864

Epoch 355: val_loss did not improve from 394.33722
196/196 - 32s - loss: 386.1739 - MinusLogProbMetric: 386.1739 - val_loss: 394.5864 - val_MinusLogProbMetric: 394.5864 - lr: 8.3333e-05 - 32s/epoch - 164ms/step
Epoch 356/1000
2023-09-10 18:04:53.528 
Epoch 356/1000 
	 loss: 385.9401, MinusLogProbMetric: 385.9401, val_loss: 394.5761, val_MinusLogProbMetric: 394.5761

Epoch 356: val_loss did not improve from 394.33722
196/196 - 40s - loss: 385.9401 - MinusLogProbMetric: 385.9401 - val_loss: 394.5761 - val_MinusLogProbMetric: 394.5761 - lr: 8.3333e-05 - 40s/epoch - 202ms/step
Epoch 357/1000
2023-09-10 18:05:27.769 
Epoch 357/1000 
	 loss: 385.9747, MinusLogProbMetric: 385.9747, val_loss: 394.9857, val_MinusLogProbMetric: 394.9857

Epoch 357: val_loss did not improve from 394.33722
196/196 - 34s - loss: 385.9747 - MinusLogProbMetric: 385.9747 - val_loss: 394.9857 - val_MinusLogProbMetric: 394.9857 - lr: 8.3333e-05 - 34s/epoch - 175ms/step
Epoch 358/1000
2023-09-10 18:06:01.168 
Epoch 358/1000 
	 loss: 385.9080, MinusLogProbMetric: 385.9080, val_loss: 395.5538, val_MinusLogProbMetric: 395.5538

Epoch 358: val_loss did not improve from 394.33722
196/196 - 33s - loss: 385.9080 - MinusLogProbMetric: 385.9080 - val_loss: 395.5538 - val_MinusLogProbMetric: 395.5538 - lr: 8.3333e-05 - 33s/epoch - 170ms/step
Epoch 359/1000
2023-09-10 18:06:35.599 
Epoch 359/1000 
	 loss: 386.0700, MinusLogProbMetric: 386.0700, val_loss: 395.1651, val_MinusLogProbMetric: 395.1651

Epoch 359: val_loss did not improve from 394.33722
196/196 - 34s - loss: 386.0700 - MinusLogProbMetric: 386.0700 - val_loss: 395.1651 - val_MinusLogProbMetric: 395.1651 - lr: 8.3333e-05 - 34s/epoch - 175ms/step
Epoch 360/1000
2023-09-10 18:07:09.602 
Epoch 360/1000 
	 loss: 385.9686, MinusLogProbMetric: 385.9686, val_loss: 394.7038, val_MinusLogProbMetric: 394.7038

Epoch 360: val_loss did not improve from 394.33722
196/196 - 34s - loss: 385.9686 - MinusLogProbMetric: 385.9686 - val_loss: 394.7038 - val_MinusLogProbMetric: 394.7038 - lr: 8.3333e-05 - 34s/epoch - 173ms/step
Epoch 361/1000
2023-09-10 18:07:44.561 
Epoch 361/1000 
	 loss: 385.9677, MinusLogProbMetric: 385.9677, val_loss: 397.3504, val_MinusLogProbMetric: 397.3504

Epoch 361: val_loss did not improve from 394.33722
196/196 - 35s - loss: 385.9677 - MinusLogProbMetric: 385.9677 - val_loss: 397.3504 - val_MinusLogProbMetric: 397.3504 - lr: 8.3333e-05 - 35s/epoch - 178ms/step
Epoch 362/1000
2023-09-10 18:08:16.896 
Epoch 362/1000 
	 loss: 386.1440, MinusLogProbMetric: 386.1440, val_loss: 394.6002, val_MinusLogProbMetric: 394.6002

Epoch 362: val_loss did not improve from 394.33722
196/196 - 32s - loss: 386.1440 - MinusLogProbMetric: 386.1440 - val_loss: 394.6002 - val_MinusLogProbMetric: 394.6002 - lr: 8.3333e-05 - 32s/epoch - 165ms/step
Epoch 363/1000
2023-09-10 18:08:50.979 
Epoch 363/1000 
	 loss: 386.0552, MinusLogProbMetric: 386.0552, val_loss: 394.8423, val_MinusLogProbMetric: 394.8423

Epoch 363: val_loss did not improve from 394.33722
196/196 - 34s - loss: 386.0552 - MinusLogProbMetric: 386.0552 - val_loss: 394.8423 - val_MinusLogProbMetric: 394.8423 - lr: 8.3333e-05 - 34s/epoch - 174ms/step
Epoch 364/1000
2023-09-10 18:09:32.663 
Epoch 364/1000 
	 loss: 385.8196, MinusLogProbMetric: 385.8196, val_loss: 395.3382, val_MinusLogProbMetric: 395.3382

Epoch 364: val_loss did not improve from 394.33722
196/196 - 42s - loss: 385.8196 - MinusLogProbMetric: 385.8196 - val_loss: 395.3382 - val_MinusLogProbMetric: 395.3382 - lr: 8.3333e-05 - 42s/epoch - 213ms/step
Epoch 365/1000
2023-09-10 18:10:11.694 
Epoch 365/1000 
	 loss: 385.9836, MinusLogProbMetric: 385.9836, val_loss: 394.1534, val_MinusLogProbMetric: 394.1534

Epoch 365: val_loss improved from 394.33722 to 394.15338, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_339/weights/best_weights.h5
196/196 - 40s - loss: 385.9836 - MinusLogProbMetric: 385.9836 - val_loss: 394.1534 - val_MinusLogProbMetric: 394.1534 - lr: 8.3333e-05 - 40s/epoch - 206ms/step
Epoch 366/1000
2023-09-10 18:10:53.322 
Epoch 366/1000 
	 loss: 385.9942, MinusLogProbMetric: 385.9942, val_loss: 394.4702, val_MinusLogProbMetric: 394.4702

Epoch 366: val_loss did not improve from 394.15338
196/196 - 40s - loss: 385.9942 - MinusLogProbMetric: 385.9942 - val_loss: 394.4702 - val_MinusLogProbMetric: 394.4702 - lr: 8.3333e-05 - 40s/epoch - 205ms/step
Epoch 367/1000
2023-09-10 18:11:31.495 
Epoch 367/1000 
	 loss: 385.8571, MinusLogProbMetric: 385.8571, val_loss: 394.7160, val_MinusLogProbMetric: 394.7160

Epoch 367: val_loss did not improve from 394.15338
196/196 - 38s - loss: 385.8571 - MinusLogProbMetric: 385.8571 - val_loss: 394.7160 - val_MinusLogProbMetric: 394.7160 - lr: 8.3333e-05 - 38s/epoch - 195ms/step
Epoch 368/1000
2023-09-10 18:12:07.638 
Epoch 368/1000 
	 loss: 385.9830, MinusLogProbMetric: 385.9830, val_loss: 394.3726, val_MinusLogProbMetric: 394.3726

Epoch 368: val_loss did not improve from 394.15338
196/196 - 36s - loss: 385.9830 - MinusLogProbMetric: 385.9830 - val_loss: 394.3726 - val_MinusLogProbMetric: 394.3726 - lr: 8.3333e-05 - 36s/epoch - 184ms/step
Epoch 369/1000
2023-09-10 18:12:42.512 
Epoch 369/1000 
	 loss: 385.7741, MinusLogProbMetric: 385.7741, val_loss: 394.8726, val_MinusLogProbMetric: 394.8726

Epoch 369: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.7741 - MinusLogProbMetric: 385.7741 - val_loss: 394.8726 - val_MinusLogProbMetric: 394.8726 - lr: 8.3333e-05 - 35s/epoch - 178ms/step
Epoch 370/1000
2023-09-10 18:13:20.369 
Epoch 370/1000 
	 loss: 385.7683, MinusLogProbMetric: 385.7683, val_loss: 395.6296, val_MinusLogProbMetric: 395.6296

Epoch 370: val_loss did not improve from 394.15338
196/196 - 38s - loss: 385.7683 - MinusLogProbMetric: 385.7683 - val_loss: 395.6296 - val_MinusLogProbMetric: 395.6296 - lr: 8.3333e-05 - 38s/epoch - 193ms/step
Epoch 371/1000
2023-09-10 18:13:56.311 
Epoch 371/1000 
	 loss: 385.8828, MinusLogProbMetric: 385.8828, val_loss: 395.1117, val_MinusLogProbMetric: 395.1117

Epoch 371: val_loss did not improve from 394.15338
196/196 - 36s - loss: 385.8828 - MinusLogProbMetric: 385.8828 - val_loss: 395.1117 - val_MinusLogProbMetric: 395.1117 - lr: 8.3333e-05 - 36s/epoch - 183ms/step
Epoch 372/1000
2023-09-10 18:14:35.689 
Epoch 372/1000 
	 loss: 386.0205, MinusLogProbMetric: 386.0205, val_loss: 394.5814, val_MinusLogProbMetric: 394.5814

Epoch 372: val_loss did not improve from 394.15338
196/196 - 39s - loss: 386.0205 - MinusLogProbMetric: 386.0205 - val_loss: 394.5814 - val_MinusLogProbMetric: 394.5814 - lr: 8.3333e-05 - 39s/epoch - 201ms/step
Epoch 373/1000
2023-09-10 18:15:13.270 
Epoch 373/1000 
	 loss: 386.2418, MinusLogProbMetric: 386.2418, val_loss: 394.7018, val_MinusLogProbMetric: 394.7018

Epoch 373: val_loss did not improve from 394.15338
196/196 - 38s - loss: 386.2418 - MinusLogProbMetric: 386.2418 - val_loss: 394.7018 - val_MinusLogProbMetric: 394.7018 - lr: 8.3333e-05 - 38s/epoch - 192ms/step
Epoch 374/1000
2023-09-10 18:15:52.169 
Epoch 374/1000 
	 loss: 385.9044, MinusLogProbMetric: 385.9044, val_loss: 395.8648, val_MinusLogProbMetric: 395.8648

Epoch 374: val_loss did not improve from 394.15338
196/196 - 39s - loss: 385.9044 - MinusLogProbMetric: 385.9044 - val_loss: 395.8648 - val_MinusLogProbMetric: 395.8648 - lr: 8.3333e-05 - 39s/epoch - 198ms/step
Epoch 375/1000
2023-09-10 18:16:27.699 
Epoch 375/1000 
	 loss: 385.7858, MinusLogProbMetric: 385.7858, val_loss: 394.7923, val_MinusLogProbMetric: 394.7923

Epoch 375: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.7858 - MinusLogProbMetric: 385.7858 - val_loss: 394.7923 - val_MinusLogProbMetric: 394.7923 - lr: 8.3333e-05 - 35s/epoch - 181ms/step
Epoch 376/1000
2023-09-10 18:17:13.419 
Epoch 376/1000 
	 loss: 386.0960, MinusLogProbMetric: 386.0960, val_loss: 395.4089, val_MinusLogProbMetric: 395.4089

Epoch 376: val_loss did not improve from 394.15338
196/196 - 46s - loss: 386.0960 - MinusLogProbMetric: 386.0960 - val_loss: 395.4089 - val_MinusLogProbMetric: 395.4089 - lr: 8.3333e-05 - 46s/epoch - 233ms/step
Epoch 377/1000
2023-09-10 18:17:54.750 
Epoch 377/1000 
	 loss: 386.0796, MinusLogProbMetric: 386.0796, val_loss: 394.6374, val_MinusLogProbMetric: 394.6374

Epoch 377: val_loss did not improve from 394.15338
196/196 - 41s - loss: 386.0796 - MinusLogProbMetric: 386.0796 - val_loss: 394.6374 - val_MinusLogProbMetric: 394.6374 - lr: 8.3333e-05 - 41s/epoch - 211ms/step
Epoch 378/1000
2023-09-10 18:18:30.253 
Epoch 378/1000 
	 loss: 385.7576, MinusLogProbMetric: 385.7576, val_loss: 395.0950, val_MinusLogProbMetric: 395.0950

Epoch 378: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.7576 - MinusLogProbMetric: 385.7576 - val_loss: 395.0950 - val_MinusLogProbMetric: 395.0950 - lr: 8.3333e-05 - 35s/epoch - 181ms/step
Epoch 379/1000
2023-09-10 18:19:10.129 
Epoch 379/1000 
	 loss: 386.0631, MinusLogProbMetric: 386.0631, val_loss: 395.0536, val_MinusLogProbMetric: 395.0536

Epoch 379: val_loss did not improve from 394.15338
196/196 - 40s - loss: 386.0631 - MinusLogProbMetric: 386.0631 - val_loss: 395.0536 - val_MinusLogProbMetric: 395.0536 - lr: 8.3333e-05 - 40s/epoch - 203ms/step
Epoch 380/1000
2023-09-10 18:19:43.933 
Epoch 380/1000 
	 loss: 386.0399, MinusLogProbMetric: 386.0399, val_loss: 395.9392, val_MinusLogProbMetric: 395.9392

Epoch 380: val_loss did not improve from 394.15338
196/196 - 34s - loss: 386.0399 - MinusLogProbMetric: 386.0399 - val_loss: 395.9392 - val_MinusLogProbMetric: 395.9392 - lr: 8.3333e-05 - 34s/epoch - 172ms/step
Epoch 381/1000
2023-09-10 18:20:20.432 
Epoch 381/1000 
	 loss: 385.8896, MinusLogProbMetric: 385.8896, val_loss: 395.1092, val_MinusLogProbMetric: 395.1092

Epoch 381: val_loss did not improve from 394.15338
196/196 - 36s - loss: 385.8896 - MinusLogProbMetric: 385.8896 - val_loss: 395.1092 - val_MinusLogProbMetric: 395.1092 - lr: 8.3333e-05 - 36s/epoch - 186ms/step
Epoch 382/1000
2023-09-10 18:20:55.316 
Epoch 382/1000 
	 loss: 385.9194, MinusLogProbMetric: 385.9194, val_loss: 396.4062, val_MinusLogProbMetric: 396.4062

Epoch 382: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.9194 - MinusLogProbMetric: 385.9194 - val_loss: 396.4062 - val_MinusLogProbMetric: 396.4062 - lr: 8.3333e-05 - 35s/epoch - 178ms/step
Epoch 383/1000
2023-09-10 18:21:30.433 
Epoch 383/1000 
	 loss: 385.8445, MinusLogProbMetric: 385.8445, val_loss: 395.4195, val_MinusLogProbMetric: 395.4195

Epoch 383: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.8445 - MinusLogProbMetric: 385.8445 - val_loss: 395.4195 - val_MinusLogProbMetric: 395.4195 - lr: 8.3333e-05 - 35s/epoch - 179ms/step
Epoch 384/1000
2023-09-10 18:22:02.007 
Epoch 384/1000 
	 loss: 385.7222, MinusLogProbMetric: 385.7222, val_loss: 395.8283, val_MinusLogProbMetric: 395.8283

Epoch 384: val_loss did not improve from 394.15338
196/196 - 32s - loss: 385.7222 - MinusLogProbMetric: 385.7222 - val_loss: 395.8283 - val_MinusLogProbMetric: 395.8283 - lr: 8.3333e-05 - 32s/epoch - 161ms/step
Epoch 385/1000
2023-09-10 18:22:33.480 
Epoch 385/1000 
	 loss: 385.9377, MinusLogProbMetric: 385.9377, val_loss: 396.3280, val_MinusLogProbMetric: 396.3280

Epoch 385: val_loss did not improve from 394.15338
196/196 - 31s - loss: 385.9377 - MinusLogProbMetric: 385.9377 - val_loss: 396.3280 - val_MinusLogProbMetric: 396.3280 - lr: 8.3333e-05 - 31s/epoch - 161ms/step
Epoch 386/1000
2023-09-10 18:23:08.461 
Epoch 386/1000 
	 loss: 385.9070, MinusLogProbMetric: 385.9070, val_loss: 395.1084, val_MinusLogProbMetric: 395.1084

Epoch 386: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.9070 - MinusLogProbMetric: 385.9070 - val_loss: 395.1084 - val_MinusLogProbMetric: 395.1084 - lr: 8.3333e-05 - 35s/epoch - 179ms/step
Epoch 387/1000
2023-09-10 18:23:45.945 
Epoch 387/1000 
	 loss: 385.9236, MinusLogProbMetric: 385.9236, val_loss: 395.5332, val_MinusLogProbMetric: 395.5332

Epoch 387: val_loss did not improve from 394.15338
196/196 - 37s - loss: 385.9236 - MinusLogProbMetric: 385.9236 - val_loss: 395.5332 - val_MinusLogProbMetric: 395.5332 - lr: 8.3333e-05 - 37s/epoch - 191ms/step
Epoch 388/1000
2023-09-10 18:24:23.050 
Epoch 388/1000 
	 loss: 386.1174, MinusLogProbMetric: 386.1174, val_loss: 395.1062, val_MinusLogProbMetric: 395.1062

Epoch 388: val_loss did not improve from 394.15338
196/196 - 37s - loss: 386.1174 - MinusLogProbMetric: 386.1174 - val_loss: 395.1062 - val_MinusLogProbMetric: 395.1062 - lr: 8.3333e-05 - 37s/epoch - 189ms/step
Epoch 389/1000
2023-09-10 18:24:57.915 
Epoch 389/1000 
	 loss: 385.9418, MinusLogProbMetric: 385.9418, val_loss: 394.6862, val_MinusLogProbMetric: 394.6862

Epoch 389: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.9418 - MinusLogProbMetric: 385.9418 - val_loss: 394.6862 - val_MinusLogProbMetric: 394.6862 - lr: 8.3333e-05 - 35s/epoch - 178ms/step
Epoch 390/1000
2023-09-10 18:25:36.810 
Epoch 390/1000 
	 loss: 386.0940, MinusLogProbMetric: 386.0940, val_loss: 394.7280, val_MinusLogProbMetric: 394.7280

Epoch 390: val_loss did not improve from 394.15338
196/196 - 39s - loss: 386.0940 - MinusLogProbMetric: 386.0940 - val_loss: 394.7280 - val_MinusLogProbMetric: 394.7280 - lr: 8.3333e-05 - 39s/epoch - 198ms/step
Epoch 391/1000
2023-09-10 18:26:12.833 
Epoch 391/1000 
	 loss: 385.9638, MinusLogProbMetric: 385.9638, val_loss: 395.3738, val_MinusLogProbMetric: 395.3738

Epoch 391: val_loss did not improve from 394.15338
196/196 - 36s - loss: 385.9638 - MinusLogProbMetric: 385.9638 - val_loss: 395.3738 - val_MinusLogProbMetric: 395.3738 - lr: 8.3333e-05 - 36s/epoch - 184ms/step
Epoch 392/1000
2023-09-10 18:26:50.370 
Epoch 392/1000 
	 loss: 386.1394, MinusLogProbMetric: 386.1394, val_loss: 395.7519, val_MinusLogProbMetric: 395.7519

Epoch 392: val_loss did not improve from 394.15338
196/196 - 38s - loss: 386.1394 - MinusLogProbMetric: 386.1394 - val_loss: 395.7519 - val_MinusLogProbMetric: 395.7519 - lr: 8.3333e-05 - 38s/epoch - 192ms/step
Epoch 393/1000
2023-09-10 18:27:29.610 
Epoch 393/1000 
	 loss: 386.2189, MinusLogProbMetric: 386.2189, val_loss: 395.6342, val_MinusLogProbMetric: 395.6342

Epoch 393: val_loss did not improve from 394.15338
196/196 - 39s - loss: 386.2189 - MinusLogProbMetric: 386.2189 - val_loss: 395.6342 - val_MinusLogProbMetric: 395.6342 - lr: 8.3333e-05 - 39s/epoch - 200ms/step
Epoch 394/1000
2023-09-10 18:28:09.819 
Epoch 394/1000 
	 loss: 385.9768, MinusLogProbMetric: 385.9768, val_loss: 395.2353, val_MinusLogProbMetric: 395.2353

Epoch 394: val_loss did not improve from 394.15338
196/196 - 40s - loss: 385.9768 - MinusLogProbMetric: 385.9768 - val_loss: 395.2353 - val_MinusLogProbMetric: 395.2353 - lr: 8.3333e-05 - 40s/epoch - 205ms/step
Epoch 395/1000
2023-09-10 18:28:45.055 
Epoch 395/1000 
	 loss: 385.9440, MinusLogProbMetric: 385.9440, val_loss: 396.1446, val_MinusLogProbMetric: 396.1446

Epoch 395: val_loss did not improve from 394.15338
196/196 - 35s - loss: 385.9440 - MinusLogProbMetric: 385.9440 - val_loss: 396.1446 - val_MinusLogProbMetric: 396.1446 - lr: 8.3333e-05 - 35s/epoch - 180ms/step
Epoch 396/1000
2023-09-10 18:29:22.371 
Epoch 396/1000 
	 loss: 386.1875, MinusLogProbMetric: 386.1875, val_loss: 394.6858, val_MinusLogProbMetric: 394.6858

Epoch 396: val_loss did not improve from 394.15338
196/196 - 37s - loss: 386.1875 - MinusLogProbMetric: 386.1875 - val_loss: 394.6858 - val_MinusLogProbMetric: 394.6858 - lr: 8.3333e-05 - 37s/epoch - 190ms/step
Epoch 397/1000
2023-09-10 18:30:03.805 
Epoch 397/1000 
	 loss: 385.8134, MinusLogProbMetric: 385.8134, val_loss: 395.4984, val_MinusLogProbMetric: 395.4984

Epoch 397: val_loss did not improve from 394.15338
196/196 - 41s - loss: 385.8134 - MinusLogProbMetric: 385.8134 - val_loss: 395.4984 - val_MinusLogProbMetric: 395.4984 - lr: 8.3333e-05 - 41s/epoch - 212ms/step
Epoch 398/1000
2023-09-10 18:30:46.096 
Epoch 398/1000 
	 loss: 385.9660, MinusLogProbMetric: 385.9660, val_loss: 395.0950, val_MinusLogProbMetric: 395.0950

Epoch 398: val_loss did not improve from 394.15338
196/196 - 42s - loss: 385.9660 - MinusLogProbMetric: 385.9660 - val_loss: 395.0950 - val_MinusLogProbMetric: 395.0950 - lr: 8.3333e-05 - 42s/epoch - 215ms/step
Epoch 399/1000
2023-09-10 18:31:25.135 
Epoch 399/1000 
	 loss: 385.8932, MinusLogProbMetric: 385.8932, val_loss: 394.7683, val_MinusLogProbMetric: 394.7683

Epoch 399: val_loss did not improve from 394.15338
196/196 - 39s - loss: 385.8932 - MinusLogProbMetric: 385.8932 - val_loss: 394.7683 - val_MinusLogProbMetric: 394.7683 - lr: 8.3333e-05 - 39s/epoch - 199ms/step
Epoch 400/1000
2023-09-10 18:32:04.949 
Epoch 400/1000 
	 loss: 386.0694, MinusLogProbMetric: 386.0694, val_loss: 396.9219, val_MinusLogProbMetric: 396.9219

Epoch 400: val_loss did not improve from 394.15338
196/196 - 40s - loss: 386.0694 - MinusLogProbMetric: 386.0694 - val_loss: 396.9219 - val_MinusLogProbMetric: 396.9219 - lr: 8.3333e-05 - 40s/epoch - 203ms/step
Epoch 401/1000
2023-09-10 18:32:39.803 
Epoch 401/1000 
	 loss: 386.2576, MinusLogProbMetric: 386.2576, val_loss: 394.8212, val_MinusLogProbMetric: 394.8212

Epoch 401: val_loss did not improve from 394.15338
196/196 - 35s - loss: 386.2576 - MinusLogProbMetric: 386.2576 - val_loss: 394.8212 - val_MinusLogProbMetric: 394.8212 - lr: 8.3333e-05 - 35s/epoch - 178ms/step
Epoch 402/1000
2023-09-10 18:33:20.963 
Epoch 402/1000 
	 loss: 385.7622, MinusLogProbMetric: 385.7622, val_loss: 394.9692, val_MinusLogProbMetric: 394.9692

Epoch 402: val_loss did not improve from 394.15338
196/196 - 41s - loss: 385.7622 - MinusLogProbMetric: 385.7622 - val_loss: 394.9692 - val_MinusLogProbMetric: 394.9692 - lr: 8.3333e-05 - 41s/epoch - 210ms/step
Epoch 403/1000
2023-09-10 18:33:58.982 
Epoch 403/1000 
	 loss: 385.7370, MinusLogProbMetric: 385.7370, val_loss: 396.4965, val_MinusLogProbMetric: 396.4965

Epoch 403: val_loss did not improve from 394.15338
196/196 - 38s - loss: 385.7370 - MinusLogProbMetric: 385.7370 - val_loss: 396.4965 - val_MinusLogProbMetric: 396.4965 - lr: 8.3333e-05 - 38s/epoch - 194ms/step
Epoch 404/1000
2023-09-10 18:34:39.595 
Epoch 404/1000 
	 loss: 386.4547, MinusLogProbMetric: 386.4547, val_loss: 395.0458, val_MinusLogProbMetric: 395.0458

Epoch 404: val_loss did not improve from 394.15338
196/196 - 41s - loss: 386.4547 - MinusLogProbMetric: 386.4547 - val_loss: 395.0458 - val_MinusLogProbMetric: 395.0458 - lr: 8.3333e-05 - 41s/epoch - 207ms/step
Epoch 405/1000
2023-09-10 18:35:20.968 
Epoch 405/1000 
	 loss: 385.7564, MinusLogProbMetric: 385.7564, val_loss: 395.0354, val_MinusLogProbMetric: 395.0354

Epoch 405: val_loss did not improve from 394.15338
196/196 - 41s - loss: 385.7564 - MinusLogProbMetric: 385.7564 - val_loss: 395.0354 - val_MinusLogProbMetric: 395.0354 - lr: 8.3333e-05 - 41s/epoch - 211ms/step
Epoch 406/1000
2023-09-10 18:36:00.958 
Epoch 406/1000 
	 loss: 385.6983, MinusLogProbMetric: 385.6983, val_loss: 396.9162, val_MinusLogProbMetric: 396.9162

Epoch 406: val_loss did not improve from 394.15338
196/196 - 40s - loss: 385.6983 - MinusLogProbMetric: 385.6983 - val_loss: 396.9162 - val_MinusLogProbMetric: 396.9162 - lr: 8.3333e-05 - 40s/epoch - 204ms/step
Epoch 407/1000
2023-09-10 18:36:40.463 
Epoch 407/1000 
	 loss: 385.8322, MinusLogProbMetric: 385.8322, val_loss: 395.1386, val_MinusLogProbMetric: 395.1386

Epoch 407: val_loss did not improve from 394.15338
196/196 - 40s - loss: 385.8322 - MinusLogProbMetric: 385.8322 - val_loss: 395.1386 - val_MinusLogProbMetric: 395.1386 - lr: 8.3333e-05 - 40s/epoch - 202ms/step
Epoch 408/1000
2023-09-10 18:37:16.509 
Epoch 408/1000 
	 loss: 385.7991, MinusLogProbMetric: 385.7991, val_loss: 395.0355, val_MinusLogProbMetric: 395.0355

Epoch 408: val_loss did not improve from 394.15338
196/196 - 36s - loss: 385.7991 - MinusLogProbMetric: 385.7991 - val_loss: 395.0355 - val_MinusLogProbMetric: 395.0355 - lr: 8.3333e-05 - 36s/epoch - 183ms/step
Epoch 409/1000
2023-09-10 18:37:53.230 
Epoch 409/1000 
	 loss: 385.8323, MinusLogProbMetric: 385.8323, val_loss: 396.3931, val_MinusLogProbMetric: 396.3931

Epoch 409: val_loss did not improve from 394.15338
196/196 - 37s - loss: 385.8323 - MinusLogProbMetric: 385.8323 - val_loss: 396.3931 - val_MinusLogProbMetric: 396.3931 - lr: 8.3333e-05 - 37s/epoch - 187ms/step
Epoch 410/1000
2023-09-10 18:38:25.508 
Epoch 410/1000 
	 loss: 385.9091, MinusLogProbMetric: 385.9091, val_loss: 394.9804, val_MinusLogProbMetric: 394.9804

Epoch 410: val_loss did not improve from 394.15338
196/196 - 32s - loss: 385.9091 - MinusLogProbMetric: 385.9091 - val_loss: 394.9804 - val_MinusLogProbMetric: 394.9804 - lr: 8.3333e-05 - 32s/epoch - 165ms/step
Epoch 411/1000
2023-09-10 18:39:06.932 
Epoch 411/1000 
	 loss: 385.8922, MinusLogProbMetric: 385.8922, val_loss: 395.4065, val_MinusLogProbMetric: 395.4065

Epoch 411: val_loss did not improve from 394.15338
196/196 - 41s - loss: 385.8922 - MinusLogProbMetric: 385.8922 - val_loss: 395.4065 - val_MinusLogProbMetric: 395.4065 - lr: 8.3333e-05 - 41s/epoch - 211ms/step
Epoch 412/1000
2023-09-10 18:39:43.586 
Epoch 412/1000 
	 loss: 385.6715, MinusLogProbMetric: 385.6715, val_loss: 395.4175, val_MinusLogProbMetric: 395.4175

Epoch 412: val_loss did not improve from 394.15338
196/196 - 37s - loss: 385.6715 - MinusLogProbMetric: 385.6715 - val_loss: 395.4175 - val_MinusLogProbMetric: 395.4175 - lr: 8.3333e-05 - 37s/epoch - 187ms/step
Epoch 413/1000
2023-09-10 18:40:17.290 
Epoch 413/1000 
	 loss: 386.0231, MinusLogProbMetric: 386.0231, val_loss: 394.8858, val_MinusLogProbMetric: 394.8858

Epoch 413: val_loss did not improve from 394.15338
196/196 - 34s - loss: 386.0231 - MinusLogProbMetric: 386.0231 - val_loss: 394.8858 - val_MinusLogProbMetric: 394.8858 - lr: 8.3333e-05 - 34s/epoch - 172ms/step
Epoch 414/1000
2023-09-10 18:40:55.600 
Epoch 414/1000 
	 loss: 385.6543, MinusLogProbMetric: 385.6543, val_loss: 395.0356, val_MinusLogProbMetric: 395.0356

Epoch 414: val_loss did not improve from 394.15338
196/196 - 38s - loss: 385.6543 - MinusLogProbMetric: 385.6543 - val_loss: 395.0356 - val_MinusLogProbMetric: 395.0356 - lr: 8.3333e-05 - 38s/epoch - 195ms/step
Epoch 415/1000
2023-09-10 18:41:27.295 
Epoch 415/1000 
	 loss: 386.0499, MinusLogProbMetric: 386.0499, val_loss: 395.0299, val_MinusLogProbMetric: 395.0299

Epoch 415: val_loss did not improve from 394.15338
196/196 - 32s - loss: 386.0499 - MinusLogProbMetric: 386.0499 - val_loss: 395.0299 - val_MinusLogProbMetric: 395.0299 - lr: 8.3333e-05 - 32s/epoch - 162ms/step
Epoch 416/1000
2023-09-10 18:42:00.017 
Epoch 416/1000 
	 loss: 384.6875, MinusLogProbMetric: 384.6875, val_loss: 394.2403, val_MinusLogProbMetric: 394.2403

Epoch 416: val_loss did not improve from 394.15338
196/196 - 33s - loss: 384.6875 - MinusLogProbMetric: 384.6875 - val_loss: 394.2403 - val_MinusLogProbMetric: 394.2403 - lr: 4.1667e-05 - 33s/epoch - 167ms/step
Epoch 417/1000
2023-09-10 18:42:36.786 
Epoch 417/1000 
	 loss: 384.5830, MinusLogProbMetric: 384.5830, val_loss: 394.4883, val_MinusLogProbMetric: 394.4883

Epoch 417: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.5830 - MinusLogProbMetric: 384.5830 - val_loss: 394.4883 - val_MinusLogProbMetric: 394.4883 - lr: 4.1667e-05 - 37s/epoch - 188ms/step
Epoch 418/1000
2023-09-10 18:43:15.120 
Epoch 418/1000 
	 loss: 384.5547, MinusLogProbMetric: 384.5547, val_loss: 394.5171, val_MinusLogProbMetric: 394.5171

Epoch 418: val_loss did not improve from 394.15338
196/196 - 38s - loss: 384.5547 - MinusLogProbMetric: 384.5547 - val_loss: 394.5171 - val_MinusLogProbMetric: 394.5171 - lr: 4.1667e-05 - 38s/epoch - 195ms/step
Epoch 419/1000
2023-09-10 18:43:54.087 
Epoch 419/1000 
	 loss: 384.5726, MinusLogProbMetric: 384.5726, val_loss: 395.0282, val_MinusLogProbMetric: 395.0282

Epoch 419: val_loss did not improve from 394.15338
196/196 - 39s - loss: 384.5726 - MinusLogProbMetric: 384.5726 - val_loss: 395.0282 - val_MinusLogProbMetric: 395.0282 - lr: 4.1667e-05 - 39s/epoch - 199ms/step
Epoch 420/1000
2023-09-10 18:44:27.862 
Epoch 420/1000 
	 loss: 384.5963, MinusLogProbMetric: 384.5963, val_loss: 394.5544, val_MinusLogProbMetric: 394.5544

Epoch 420: val_loss did not improve from 394.15338
196/196 - 34s - loss: 384.5963 - MinusLogProbMetric: 384.5963 - val_loss: 394.5544 - val_MinusLogProbMetric: 394.5544 - lr: 4.1667e-05 - 34s/epoch - 172ms/step
Epoch 421/1000
2023-09-10 18:45:07.450 
Epoch 421/1000 
	 loss: 384.5681, MinusLogProbMetric: 384.5681, val_loss: 394.3056, val_MinusLogProbMetric: 394.3056

Epoch 421: val_loss did not improve from 394.15338
196/196 - 40s - loss: 384.5681 - MinusLogProbMetric: 384.5681 - val_loss: 394.3056 - val_MinusLogProbMetric: 394.3056 - lr: 4.1667e-05 - 40s/epoch - 202ms/step
Epoch 422/1000
2023-09-10 18:45:39.246 
Epoch 422/1000 
	 loss: 384.5293, MinusLogProbMetric: 384.5293, val_loss: 394.3628, val_MinusLogProbMetric: 394.3628

Epoch 422: val_loss did not improve from 394.15338
196/196 - 32s - loss: 384.5293 - MinusLogProbMetric: 384.5293 - val_loss: 394.3628 - val_MinusLogProbMetric: 394.3628 - lr: 4.1667e-05 - 32s/epoch - 162ms/step
Epoch 423/1000
2023-09-10 18:46:14.960 
Epoch 423/1000 
	 loss: 384.5714, MinusLogProbMetric: 384.5714, val_loss: 394.5516, val_MinusLogProbMetric: 394.5516

Epoch 423: val_loss did not improve from 394.15338
196/196 - 36s - loss: 384.5714 - MinusLogProbMetric: 384.5714 - val_loss: 394.5516 - val_MinusLogProbMetric: 394.5516 - lr: 4.1667e-05 - 36s/epoch - 182ms/step
Epoch 424/1000
2023-09-10 18:46:52.023 
Epoch 424/1000 
	 loss: 384.5428, MinusLogProbMetric: 384.5428, val_loss: 394.5658, val_MinusLogProbMetric: 394.5658

Epoch 424: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.5428 - MinusLogProbMetric: 384.5428 - val_loss: 394.5658 - val_MinusLogProbMetric: 394.5658 - lr: 4.1667e-05 - 37s/epoch - 189ms/step
Epoch 425/1000
2023-09-10 18:47:26.860 
Epoch 425/1000 
	 loss: 384.5039, MinusLogProbMetric: 384.5039, val_loss: 394.8010, val_MinusLogProbMetric: 394.8010

Epoch 425: val_loss did not improve from 394.15338
196/196 - 35s - loss: 384.5039 - MinusLogProbMetric: 384.5039 - val_loss: 394.8010 - val_MinusLogProbMetric: 394.8010 - lr: 4.1667e-05 - 35s/epoch - 178ms/step
Epoch 426/1000
2023-09-10 18:48:06.996 
Epoch 426/1000 
	 loss: 384.5948, MinusLogProbMetric: 384.5948, val_loss: 394.8696, val_MinusLogProbMetric: 394.8696

Epoch 426: val_loss did not improve from 394.15338
196/196 - 40s - loss: 384.5948 - MinusLogProbMetric: 384.5948 - val_loss: 394.8696 - val_MinusLogProbMetric: 394.8696 - lr: 4.1667e-05 - 40s/epoch - 205ms/step
Epoch 427/1000
2023-09-10 18:48:48.735 
Epoch 427/1000 
	 loss: 384.7464, MinusLogProbMetric: 384.7464, val_loss: 394.5318, val_MinusLogProbMetric: 394.5318

Epoch 427: val_loss did not improve from 394.15338
196/196 - 42s - loss: 384.7464 - MinusLogProbMetric: 384.7464 - val_loss: 394.5318 - val_MinusLogProbMetric: 394.5318 - lr: 4.1667e-05 - 42s/epoch - 213ms/step
Epoch 428/1000
2023-09-10 18:49:24.414 
Epoch 428/1000 
	 loss: 384.6095, MinusLogProbMetric: 384.6095, val_loss: 394.5793, val_MinusLogProbMetric: 394.5793

Epoch 428: val_loss did not improve from 394.15338
196/196 - 36s - loss: 384.6095 - MinusLogProbMetric: 384.6095 - val_loss: 394.5793 - val_MinusLogProbMetric: 394.5793 - lr: 4.1667e-05 - 36s/epoch - 182ms/step
Epoch 429/1000
2023-09-10 18:50:01.821 
Epoch 429/1000 
	 loss: 384.5896, MinusLogProbMetric: 384.5896, val_loss: 394.2705, val_MinusLogProbMetric: 394.2705

Epoch 429: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.5896 - MinusLogProbMetric: 384.5896 - val_loss: 394.2705 - val_MinusLogProbMetric: 394.2705 - lr: 4.1667e-05 - 37s/epoch - 191ms/step
Epoch 430/1000
2023-09-10 18:50:38.589 
Epoch 430/1000 
	 loss: 384.6378, MinusLogProbMetric: 384.6378, val_loss: 394.5270, val_MinusLogProbMetric: 394.5270

Epoch 430: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.6378 - MinusLogProbMetric: 384.6378 - val_loss: 394.5270 - val_MinusLogProbMetric: 394.5270 - lr: 4.1667e-05 - 37s/epoch - 188ms/step
Epoch 431/1000
2023-09-10 18:51:15.692 
Epoch 431/1000 
	 loss: 384.6689, MinusLogProbMetric: 384.6689, val_loss: 395.0619, val_MinusLogProbMetric: 395.0619

Epoch 431: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.6689 - MinusLogProbMetric: 384.6689 - val_loss: 395.0619 - val_MinusLogProbMetric: 395.0619 - lr: 4.1667e-05 - 37s/epoch - 189ms/step
Epoch 432/1000
2023-09-10 18:51:56.561 
Epoch 432/1000 
	 loss: 384.8194, MinusLogProbMetric: 384.8194, val_loss: 394.8423, val_MinusLogProbMetric: 394.8423

Epoch 432: val_loss did not improve from 394.15338
196/196 - 41s - loss: 384.8194 - MinusLogProbMetric: 384.8194 - val_loss: 394.8423 - val_MinusLogProbMetric: 394.8423 - lr: 4.1667e-05 - 41s/epoch - 208ms/step
Epoch 433/1000
2023-09-10 18:52:34.841 
Epoch 433/1000 
	 loss: 384.5693, MinusLogProbMetric: 384.5693, val_loss: 394.4970, val_MinusLogProbMetric: 394.4970

Epoch 433: val_loss did not improve from 394.15338
196/196 - 38s - loss: 384.5693 - MinusLogProbMetric: 384.5693 - val_loss: 394.4970 - val_MinusLogProbMetric: 394.4970 - lr: 4.1667e-05 - 38s/epoch - 195ms/step
Epoch 434/1000
2023-09-10 18:53:11.165 
Epoch 434/1000 
	 loss: 384.5205, MinusLogProbMetric: 384.5205, val_loss: 394.6776, val_MinusLogProbMetric: 394.6776

Epoch 434: val_loss did not improve from 394.15338
196/196 - 36s - loss: 384.5205 - MinusLogProbMetric: 384.5205 - val_loss: 394.6776 - val_MinusLogProbMetric: 394.6776 - lr: 4.1667e-05 - 36s/epoch - 185ms/step
Epoch 435/1000
2023-09-10 18:53:55.986 
Epoch 435/1000 
	 loss: 384.5851, MinusLogProbMetric: 384.5851, val_loss: 394.3237, val_MinusLogProbMetric: 394.3237

Epoch 435: val_loss did not improve from 394.15338
196/196 - 45s - loss: 384.5851 - MinusLogProbMetric: 384.5851 - val_loss: 394.3237 - val_MinusLogProbMetric: 394.3237 - lr: 4.1667e-05 - 45s/epoch - 229ms/step
Epoch 436/1000
2023-09-10 18:54:31.100 
Epoch 436/1000 
	 loss: 384.6027, MinusLogProbMetric: 384.6027, val_loss: 394.4004, val_MinusLogProbMetric: 394.4004

Epoch 436: val_loss did not improve from 394.15338
196/196 - 35s - loss: 384.6027 - MinusLogProbMetric: 384.6027 - val_loss: 394.4004 - val_MinusLogProbMetric: 394.4004 - lr: 4.1667e-05 - 35s/epoch - 179ms/step
Epoch 437/1000
2023-09-10 18:55:10.094 
Epoch 437/1000 
	 loss: 384.6530, MinusLogProbMetric: 384.6530, val_loss: 394.7134, val_MinusLogProbMetric: 394.7134

Epoch 437: val_loss did not improve from 394.15338
196/196 - 39s - loss: 384.6530 - MinusLogProbMetric: 384.6530 - val_loss: 394.7134 - val_MinusLogProbMetric: 394.7134 - lr: 4.1667e-05 - 39s/epoch - 199ms/step
Epoch 438/1000
2023-09-10 18:55:52.082 
Epoch 438/1000 
	 loss: 384.6142, MinusLogProbMetric: 384.6142, val_loss: 394.4287, val_MinusLogProbMetric: 394.4287

Epoch 438: val_loss did not improve from 394.15338
196/196 - 42s - loss: 384.6142 - MinusLogProbMetric: 384.6142 - val_loss: 394.4287 - val_MinusLogProbMetric: 394.4287 - lr: 4.1667e-05 - 42s/epoch - 214ms/step
Epoch 439/1000
2023-09-10 18:56:29.961 
Epoch 439/1000 
	 loss: 384.5223, MinusLogProbMetric: 384.5223, val_loss: 394.6773, val_MinusLogProbMetric: 394.6773

Epoch 439: val_loss did not improve from 394.15338
196/196 - 38s - loss: 384.5223 - MinusLogProbMetric: 384.5223 - val_loss: 394.6773 - val_MinusLogProbMetric: 394.6773 - lr: 4.1667e-05 - 38s/epoch - 193ms/step
Epoch 440/1000
2023-09-10 18:57:06.182 
Epoch 440/1000 
	 loss: 384.6150, MinusLogProbMetric: 384.6150, val_loss: 394.5069, val_MinusLogProbMetric: 394.5069

Epoch 440: val_loss did not improve from 394.15338
196/196 - 36s - loss: 384.6150 - MinusLogProbMetric: 384.6150 - val_loss: 394.5069 - val_MinusLogProbMetric: 394.5069 - lr: 4.1667e-05 - 36s/epoch - 185ms/step
Epoch 441/1000
2023-09-10 18:57:45.270 
Epoch 441/1000 
	 loss: 384.5431, MinusLogProbMetric: 384.5431, val_loss: 394.4803, val_MinusLogProbMetric: 394.4803

Epoch 441: val_loss did not improve from 394.15338
196/196 - 39s - loss: 384.5431 - MinusLogProbMetric: 384.5431 - val_loss: 394.4803 - val_MinusLogProbMetric: 394.4803 - lr: 4.1667e-05 - 39s/epoch - 199ms/step
Epoch 442/1000
2023-09-10 18:58:28.236 
Epoch 442/1000 
	 loss: 384.5903, MinusLogProbMetric: 384.5903, val_loss: 394.6729, val_MinusLogProbMetric: 394.6729

Epoch 442: val_loss did not improve from 394.15338
196/196 - 43s - loss: 384.5903 - MinusLogProbMetric: 384.5903 - val_loss: 394.6729 - val_MinusLogProbMetric: 394.6729 - lr: 4.1667e-05 - 43s/epoch - 219ms/step
Epoch 443/1000
2023-09-10 18:59:08.121 
Epoch 443/1000 
	 loss: 384.5242, MinusLogProbMetric: 384.5242, val_loss: 394.4285, val_MinusLogProbMetric: 394.4285

Epoch 443: val_loss did not improve from 394.15338
196/196 - 40s - loss: 384.5242 - MinusLogProbMetric: 384.5242 - val_loss: 394.4285 - val_MinusLogProbMetric: 394.4285 - lr: 4.1667e-05 - 40s/epoch - 203ms/step
Epoch 444/1000
2023-09-10 18:59:44.876 
Epoch 444/1000 
	 loss: 384.5743, MinusLogProbMetric: 384.5743, val_loss: 395.0928, val_MinusLogProbMetric: 395.0928

Epoch 444: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.5743 - MinusLogProbMetric: 384.5743 - val_loss: 395.0928 - val_MinusLogProbMetric: 395.0928 - lr: 4.1667e-05 - 37s/epoch - 187ms/step
Epoch 445/1000
2023-09-10 19:00:26.043 
Epoch 445/1000 
	 loss: 384.5572, MinusLogProbMetric: 384.5572, val_loss: 394.3207, val_MinusLogProbMetric: 394.3207

Epoch 445: val_loss did not improve from 394.15338
196/196 - 41s - loss: 384.5572 - MinusLogProbMetric: 384.5572 - val_loss: 394.3207 - val_MinusLogProbMetric: 394.3207 - lr: 4.1667e-05 - 41s/epoch - 210ms/step
Epoch 446/1000
2023-09-10 19:01:05.520 
Epoch 446/1000 
	 loss: 384.5211, MinusLogProbMetric: 384.5211, val_loss: 394.2920, val_MinusLogProbMetric: 394.2920

Epoch 446: val_loss did not improve from 394.15338
196/196 - 39s - loss: 384.5211 - MinusLogProbMetric: 384.5211 - val_loss: 394.2920 - val_MinusLogProbMetric: 394.2920 - lr: 4.1667e-05 - 39s/epoch - 201ms/step
Epoch 447/1000
2023-09-10 19:01:46.941 
Epoch 447/1000 
	 loss: 384.6191, MinusLogProbMetric: 384.6191, val_loss: 394.8516, val_MinusLogProbMetric: 394.8516

Epoch 447: val_loss did not improve from 394.15338
196/196 - 41s - loss: 384.6191 - MinusLogProbMetric: 384.6191 - val_loss: 394.8516 - val_MinusLogProbMetric: 394.8516 - lr: 4.1667e-05 - 41s/epoch - 211ms/step
Epoch 448/1000
2023-09-10 19:02:23.473 
Epoch 448/1000 
	 loss: 384.5764, MinusLogProbMetric: 384.5764, val_loss: 394.5032, val_MinusLogProbMetric: 394.5032

Epoch 448: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.5764 - MinusLogProbMetric: 384.5764 - val_loss: 394.5032 - val_MinusLogProbMetric: 394.5032 - lr: 4.1667e-05 - 37s/epoch - 186ms/step
Epoch 449/1000
2023-09-10 19:03:00.441 
Epoch 449/1000 
	 loss: 384.5537, MinusLogProbMetric: 384.5537, val_loss: 395.0966, val_MinusLogProbMetric: 395.0966

Epoch 449: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.5537 - MinusLogProbMetric: 384.5537 - val_loss: 395.0966 - val_MinusLogProbMetric: 395.0966 - lr: 4.1667e-05 - 37s/epoch - 189ms/step
Epoch 450/1000
2023-09-10 19:03:32.325 
Epoch 450/1000 
	 loss: 384.4355, MinusLogProbMetric: 384.4355, val_loss: 395.4381, val_MinusLogProbMetric: 395.4381

Epoch 450: val_loss did not improve from 394.15338
196/196 - 32s - loss: 384.4355 - MinusLogProbMetric: 384.4355 - val_loss: 395.4381 - val_MinusLogProbMetric: 395.4381 - lr: 4.1667e-05 - 32s/epoch - 163ms/step
Epoch 451/1000
2023-09-10 19:04:15.274 
Epoch 451/1000 
	 loss: 384.5266, MinusLogProbMetric: 384.5266, val_loss: 394.6111, val_MinusLogProbMetric: 394.6111

Epoch 451: val_loss did not improve from 394.15338
196/196 - 43s - loss: 384.5266 - MinusLogProbMetric: 384.5266 - val_loss: 394.6111 - val_MinusLogProbMetric: 394.6111 - lr: 4.1667e-05 - 43s/epoch - 219ms/step
Epoch 452/1000
2023-09-10 19:04:58.660 
Epoch 452/1000 
	 loss: 384.4315, MinusLogProbMetric: 384.4315, val_loss: 394.2679, val_MinusLogProbMetric: 394.2679

Epoch 452: val_loss did not improve from 394.15338
196/196 - 43s - loss: 384.4315 - MinusLogProbMetric: 384.4315 - val_loss: 394.2679 - val_MinusLogProbMetric: 394.2679 - lr: 4.1667e-05 - 43s/epoch - 221ms/step
Epoch 453/1000
2023-09-10 19:05:40.227 
Epoch 453/1000 
	 loss: 384.4318, MinusLogProbMetric: 384.4318, val_loss: 394.7104, val_MinusLogProbMetric: 394.7104

Epoch 453: val_loss did not improve from 394.15338
196/196 - 42s - loss: 384.4318 - MinusLogProbMetric: 384.4318 - val_loss: 394.7104 - val_MinusLogProbMetric: 394.7104 - lr: 4.1667e-05 - 42s/epoch - 212ms/step
Epoch 454/1000
2023-09-10 19:06:21.267 
Epoch 454/1000 
	 loss: 384.5367, MinusLogProbMetric: 384.5367, val_loss: 394.5018, val_MinusLogProbMetric: 394.5018

Epoch 454: val_loss did not improve from 394.15338
196/196 - 41s - loss: 384.5367 - MinusLogProbMetric: 384.5367 - val_loss: 394.5018 - val_MinusLogProbMetric: 394.5018 - lr: 4.1667e-05 - 41s/epoch - 209ms/step
Epoch 455/1000
2023-09-10 19:06:54.938 
Epoch 455/1000 
	 loss: 384.5085, MinusLogProbMetric: 384.5085, val_loss: 394.8225, val_MinusLogProbMetric: 394.8225

Epoch 455: val_loss did not improve from 394.15338
196/196 - 34s - loss: 384.5085 - MinusLogProbMetric: 384.5085 - val_loss: 394.8225 - val_MinusLogProbMetric: 394.8225 - lr: 4.1667e-05 - 34s/epoch - 172ms/step
Epoch 456/1000
2023-09-10 19:07:35.304 
Epoch 456/1000 
	 loss: 384.4662, MinusLogProbMetric: 384.4662, val_loss: 394.7725, val_MinusLogProbMetric: 394.7725

Epoch 456: val_loss did not improve from 394.15338
196/196 - 40s - loss: 384.4662 - MinusLogProbMetric: 384.4662 - val_loss: 394.7725 - val_MinusLogProbMetric: 394.7725 - lr: 4.1667e-05 - 40s/epoch - 206ms/step
Epoch 457/1000
2023-09-10 19:08:16.409 
Epoch 457/1000 
	 loss: 384.4668, MinusLogProbMetric: 384.4668, val_loss: 394.6083, val_MinusLogProbMetric: 394.6083

Epoch 457: val_loss did not improve from 394.15338
196/196 - 41s - loss: 384.4668 - MinusLogProbMetric: 384.4668 - val_loss: 394.6083 - val_MinusLogProbMetric: 394.6083 - lr: 4.1667e-05 - 41s/epoch - 209ms/step
Epoch 458/1000
2023-09-10 19:08:56.300 
Epoch 458/1000 
	 loss: 384.4187, MinusLogProbMetric: 384.4187, val_loss: 394.8034, val_MinusLogProbMetric: 394.8034

Epoch 458: val_loss did not improve from 394.15338
196/196 - 40s - loss: 384.4187 - MinusLogProbMetric: 384.4187 - val_loss: 394.8034 - val_MinusLogProbMetric: 394.8034 - lr: 4.1667e-05 - 40s/epoch - 204ms/step
Epoch 459/1000
2023-09-10 19:09:33.609 
Epoch 459/1000 
	 loss: 384.5526, MinusLogProbMetric: 384.5526, val_loss: 395.0999, val_MinusLogProbMetric: 395.0999

Epoch 459: val_loss did not improve from 394.15338
196/196 - 37s - loss: 384.5526 - MinusLogProbMetric: 384.5526 - val_loss: 395.0999 - val_MinusLogProbMetric: 395.0999 - lr: 4.1667e-05 - 37s/epoch - 190ms/step
Epoch 460/1000
2023-09-10 19:10:14.816 
Epoch 460/1000 
	 loss: 384.6607, MinusLogProbMetric: 384.6607, val_loss: 394.6127, val_MinusLogProbMetric: 394.6127

Epoch 460: val_loss did not improve from 394.15338
196/196 - 41s - loss: 384.6607 - MinusLogProbMetric: 384.6607 - val_loss: 394.6127 - val_MinusLogProbMetric: 394.6127 - lr: 4.1667e-05 - 41s/epoch - 210ms/step
Epoch 461/1000
2023-09-10 19:10:52.953 
Epoch 461/1000 
	 loss: 384.4858, MinusLogProbMetric: 384.4858, val_loss: 394.7845, val_MinusLogProbMetric: 394.7845

Epoch 461: val_loss did not improve from 394.15338
196/196 - 38s - loss: 384.4858 - MinusLogProbMetric: 384.4858 - val_loss: 394.7845 - val_MinusLogProbMetric: 394.7845 - lr: 4.1667e-05 - 38s/epoch - 194ms/step
Epoch 462/1000
2023-09-10 19:11:32.497 
Epoch 462/1000 
	 loss: 384.4586, MinusLogProbMetric: 384.4586, val_loss: 394.4368, val_MinusLogProbMetric: 394.4368

Epoch 462: val_loss did not improve from 394.15338
196/196 - 40s - loss: 384.4586 - MinusLogProbMetric: 384.4586 - val_loss: 394.4368 - val_MinusLogProbMetric: 394.4368 - lr: 4.1667e-05 - 40s/epoch - 202ms/step
Epoch 463/1000
2023-09-10 19:12:10.553 
Epoch 463/1000 
	 loss: 384.4855, MinusLogProbMetric: 384.4855, val_loss: 395.0738, val_MinusLogProbMetric: 395.0738

Epoch 463: val_loss did not improve from 394.15338
196/196 - 38s - loss: 384.4855 - MinusLogProbMetric: 384.4855 - val_loss: 395.0738 - val_MinusLogProbMetric: 395.0738 - lr: 4.1667e-05 - 38s/epoch - 194ms/step
Epoch 464/1000
2023-09-10 19:12:49.250 
Epoch 464/1000 
	 loss: 384.5177, MinusLogProbMetric: 384.5177, val_loss: 394.9405, val_MinusLogProbMetric: 394.9405

Epoch 464: val_loss did not improve from 394.15338
196/196 - 39s - loss: 384.5177 - MinusLogProbMetric: 384.5177 - val_loss: 394.9405 - val_MinusLogProbMetric: 394.9405 - lr: 4.1667e-05 - 39s/epoch - 197ms/step
Epoch 465/1000
2023-09-10 19:13:25.043 
Epoch 465/1000 
	 loss: 384.4716, MinusLogProbMetric: 384.4716, val_loss: 394.9843, val_MinusLogProbMetric: 394.9843

Epoch 465: val_loss did not improve from 394.15338
Restoring model weights from the end of the best epoch: 365.
196/196 - 36s - loss: 384.4716 - MinusLogProbMetric: 384.4716 - val_loss: 394.9843 - val_MinusLogProbMetric: 394.9843 - lr: 4.1667e-05 - 36s/epoch - 186ms/step
Epoch 465: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function LRMetric.Test_tf.<locals>.compute_test at 0x7effb125a830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
LR metric calculation completed in 1792.9201490039704 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
WARNING:tensorflow:5 out of the last 5 calls to <function KSTest.Test_tf.<locals>.compute_test at 0x7effb12595a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
KS tests calculation completed in 1752.455985157052 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function SWDMetric.Test_tf.<locals>.compute_test at 0x7effb12595a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
SWD metric calculation completed in 1773.3314105580794 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
WARNING:tensorflow:5 out of the last 5 calls to <function FNMetric.Test_tf.<locals>.compute_test at 0x7effb125b1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
FN metric calculation completed in 1735.7208029610338 seconds.
Training succeeded with seed 520.
Model trained in 15301.56 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 7438.34 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 7439.16 s.
===========
Run 339/360 done in 23296.86 s.
===========

Directory ../../results/MAFN_new/run_340/ already exists.
Skipping it.
===========
Run 340/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_341/ already exists.
Skipping it.
===========
Run 341/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_342/ already exists.
Skipping it.
===========
Run 342/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_343/ already exists.
Skipping it.
===========
Run 343/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_344/ already exists.
Skipping it.
===========
Run 344/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_345/ already exists.
Skipping it.
===========
Run 345/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_346/ already exists.
Skipping it.
===========
Run 346/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_347/ already exists.
Skipping it.
===========
Run 347/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_348/ already exists.
Skipping it.
===========
Run 348/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_349/ already exists.
Skipping it.
===========
Run 349/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_350/ already exists.
Skipping it.
===========
Run 350/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_351/ already exists.
Skipping it.
===========
Run 351/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_352/ already exists.
Skipping it.
===========
Run 352/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_353/ already exists.
Skipping it.
===========
Run 353/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_354/ already exists.
Skipping it.
===========
Run 354/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_355/ already exists.
Skipping it.
===========
Run 355/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_356/ already exists.
Skipping it.
===========
Run 356/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_357/ already exists.
Skipping it.
===========
Run 357/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_358/ already exists.
Skipping it.
===========
Run 358/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_359/ already exists.
Skipping it.
===========
Run 359/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_360/ already exists.
Skipping it.
===========
Run 360/360 already exists. Skipping it.
===========

Traceback (most recent call last):
  File "/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py", line 741, in <module>
    results_frame: pd.DataFrame = pd.DataFrame(dict_copy)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/frame.py", line 709, in __init__
    mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 481, in dict_to_mgr
    return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 115, in arrays_to_mgr
    index = _extract_index(arrays)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 655, in _extract_index
    raise ValueError("All arrays must be of the same length")
ValueError: All arrays must be of the same length
