2023-09-09 22:36:05.787783: Importing os...
2023-09-09 22:36:05.787990: Importing sys...
2023-09-09 22:36:05.788004: Importing and initializing argparse...
Visible devices: [0]
2023-09-09 22:36:05.818977: Importing timer from timeit...
2023-09-09 22:36:05.820700: Setting env variables for tf import (only device [0] will be available)...
2023-09-09 22:36:05.820841: Importing numpy...
2023-09-09 22:36:06.107785: Importing pandas...
2023-09-09 22:36:06.650074: Importing shutil...
2023-09-09 22:36:06.650368: Importing subprocess...
2023-09-09 22:36:06.650405: Importing tensorflow...
Tensorflow version: 2.12.0
2023-09-09 22:36:13.375442: Importing tensorflow_probability...
Tensorflow probability version: 0.20.1
2023-09-09 22:36:14.421819: Importing textwrap...
2023-09-09 22:36:14.421936: Importing timeit...
2023-09-09 22:36:14.421961: Importing traceback...
2023-09-09 22:36:14.421972: Importing typing...
2023-09-09 22:36:14.421989: Setting tf configs...
2023-09-09 22:36:15.057699: Importing custom module...
Successfully loaded GPU model: NVIDIA A40
2023-09-09 22:36:18.192647: All modues imported successfully.
Directory ../../results/MAFN_new/ already exists.
Directory ../../results/MAFN_new/run_1/ already exists.
Skipping it.
===========
Run 1/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_2/ already exists.
Skipping it.
===========
Run 2/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_3/ already exists.
Skipping it.
===========
Run 3/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_4/ already exists.
Skipping it.
===========
Run 4/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_5/ already exists.
Skipping it.
===========
Run 5/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_6/ already exists.
Skipping it.
===========
Run 6/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_7/ already exists.
Skipping it.
===========
Run 7/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_8/ already exists.
Skipping it.
===========
Run 8/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_9/ already exists.
Skipping it.
===========
Run 9/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_10/ already exists.
Skipping it.
===========
Run 10/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_11/ already exists.
Skipping it.
===========
Run 11/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_12/ already exists.
Skipping it.
===========
Run 12/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_13/ already exists.
Skipping it.
===========
Run 13/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_14/ already exists.
Skipping it.
===========
Run 14/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_15/ already exists.
Skipping it.
===========
Run 15/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_16/ already exists.
Skipping it.
===========
Run 16/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_17/ already exists.
Skipping it.
===========
Run 17/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_18/ already exists.
Skipping it.
===========
Run 18/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_19/ already exists.
Skipping it.
===========
Run 19/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_20/ already exists.
Skipping it.
===========
Run 20/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_21/ already exists.
Skipping it.
===========
Run 21/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_22/ already exists.
Skipping it.
===========
Run 22/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_23/ already exists.
Skipping it.
===========
Run 23/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_24/ already exists.
Skipping it.
===========
Run 24/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_25/ already exists.
Skipping it.
===========
Run 25/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_26/ already exists.
Skipping it.
===========
Run 26/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_27/ already exists.
Skipping it.
===========
Run 27/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_28/ already exists.
Skipping it.
===========
Run 28/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_29/ already exists.
Skipping it.
===========
Run 29/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_30/ already exists.
Skipping it.
===========
Run 30/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_31/ already exists.
Skipping it.
===========
Run 31/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_32/ already exists.
Skipping it.
===========
Run 32/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_33/ already exists.
Skipping it.
===========
Run 33/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_34/ already exists.
Skipping it.
===========
Run 34/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_35/ already exists.
Skipping it.
===========
Run 35/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_36/ already exists.
Skipping it.
===========
Run 36/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_37/ already exists.
Skipping it.
===========
Run 37/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_38/ already exists.
Skipping it.
===========
Run 38/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_39/ already exists.
Skipping it.
===========
Run 39/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_40/ already exists.
Skipping it.
===========
Run 40/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_41/ already exists.
Skipping it.
===========
Run 41/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_42/ already exists.
Skipping it.
===========
Run 42/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_43/ already exists.
Skipping it.
===========
Run 43/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_44/ already exists.
Skipping it.
===========
Run 44/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_45/ already exists.
Skipping it.
===========
Run 45/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_46/ already exists.
Skipping it.
===========
Run 46/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_47/ already exists.
Skipping it.
===========
Run 47/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_48/ already exists.
Skipping it.
===========
Run 48/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_49/ already exists.
Skipping it.
===========
Run 49/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_50/ already exists.
Skipping it.
===========
Run 50/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_51/ already exists.
Skipping it.
===========
Run 51/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_52/ already exists.
Skipping it.
===========
Run 52/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_53/ already exists.
Skipping it.
===========
Run 53/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_54/ already exists.
Skipping it.
===========
Run 54/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_55/ already exists.
Skipping it.
===========
Run 55/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_56/ already exists.
Skipping it.
===========
Run 56/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_57/ already exists.
Skipping it.
===========
Run 57/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_58/ already exists.
Skipping it.
===========
Run 58/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_59/ already exists.
Skipping it.
===========
Run 59/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_60/ already exists.
Skipping it.
===========
Run 60/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_61/ already exists.
Skipping it.
===========
Run 61/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_62/ already exists.
Skipping it.
===========
Run 62/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_63/ already exists.
Skipping it.
===========
Run 63/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_64/ already exists.
Skipping it.
===========
Run 64/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_65/ already exists.
Skipping it.
===========
Run 65/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_66/ already exists.
Skipping it.
===========
Run 66/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_67/ already exists.
Skipping it.
===========
Run 67/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_68/ already exists.
Skipping it.
===========
Run 68/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_69/ already exists.
Skipping it.
===========
Run 69/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_70/ already exists.
Skipping it.
===========
Run 70/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_71/ already exists.
Skipping it.
===========
Run 71/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_72/ already exists.
Skipping it.
===========
Run 72/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_73/ already exists.
Skipping it.
===========
Run 73/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_74/ already exists.
Skipping it.
===========
Run 74/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_75/ already exists.
Skipping it.
===========
Run 75/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_76/ already exists.
Skipping it.
===========
Run 76/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_77/ already exists.
Skipping it.
===========
Run 77/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_78/ already exists.
Skipping it.
===========
Run 78/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_79/ already exists.
Skipping it.
===========
Run 79/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_80/ already exists.
Skipping it.
===========
Run 80/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_81/ already exists.
Skipping it.
===========
Run 81/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_82/ already exists.
Skipping it.
===========
Run 82/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_83/ already exists.
Skipping it.
===========
Run 83/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_84/ already exists.
Skipping it.
===========
Run 84/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_85/ already exists.
Skipping it.
===========
Run 85/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_86/ already exists.
Skipping it.
===========
Run 86/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_87/ already exists.
Skipping it.
===========
Run 87/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_88/ already exists.
Skipping it.
===========
Run 88/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_89/ already exists.
Skipping it.
===========
Run 89/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_90/ already exists.
Skipping it.
===========
Run 90/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_91/ already exists.
Skipping it.
===========
Run 91/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_92/ already exists.
Skipping it.
===========
Run 92/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_93/ already exists.
Skipping it.
===========
Run 93/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_94/ already exists.
Skipping it.
===========
Run 94/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_95/ already exists.
Skipping it.
===========
Run 95/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_96/ already exists.
Skipping it.
===========
Run 96/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_97/ already exists.
Skipping it.
===========
Run 97/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_98/ already exists.
Skipping it.
===========
Run 98/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_99/ already exists.
Skipping it.
===========
Run 99/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_100/ already exists.
Skipping it.
===========
Run 100/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_101/ already exists.
Skipping it.
===========
Run 101/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_102/ already exists.
Skipping it.
===========
Run 102/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_103/ already exists.
Skipping it.
===========
Run 103/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_104/ already exists.
Skipping it.
===========
Run 104/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_105/ already exists.
Skipping it.
===========
Run 105/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_106/ already exists.
Skipping it.
===========
Run 106/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_107/ already exists.
Skipping it.
===========
Run 107/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_108/ already exists.
Skipping it.
===========
Run 108/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_109/ already exists.
Skipping it.
===========
Run 109/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_110/ already exists.
Skipping it.
===========
Run 110/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_111/ already exists.
Skipping it.
===========
Run 111/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_112/ already exists.
Skipping it.
===========
Run 112/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_113/ already exists.
Skipping it.
===========
Run 113/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_114/ already exists.
Skipping it.
===========
Run 114/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_115/ already exists.
Skipping it.
===========
Run 115/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_116/ already exists.
Skipping it.
===========
Run 116/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_117/ already exists.
Skipping it.
===========
Run 117/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_118/ already exists.
Skipping it.
===========
Run 118/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_119/ already exists.
Skipping it.
===========
Run 119/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_120/ already exists.
Skipping it.
===========
Run 120/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_121/ already exists.
Skipping it.
===========
Run 121/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_122/ already exists.
Skipping it.
===========
Run 122/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_123/ already exists.
Skipping it.
===========
Run 123/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_124/ already exists.
Skipping it.
===========
Run 124/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_125/ already exists.
Skipping it.
===========
Run 125/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_126/ already exists.
Skipping it.
===========
Run 126/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_127/ already exists.
Skipping it.
===========
Run 127/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_128/ already exists.
Skipping it.
===========
Run 128/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_129/ already exists.
Skipping it.
===========
Run 129/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_130/ already exists.
Skipping it.
===========
Run 130/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_131/ already exists.
Skipping it.
===========
Run 131/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_132/ already exists.
Skipping it.
===========
Run 132/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_133/ already exists.
Skipping it.
===========
Run 133/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_134/ already exists.
Skipping it.
===========
Run 134/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_135/ already exists.
Skipping it.
===========
Run 135/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_136/ already exists.
Skipping it.
===========
Run 136/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_137/ already exists.
Skipping it.
===========
Run 137/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_138/ already exists.
Skipping it.
===========
Run 138/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_139/ already exists.
Skipping it.
===========
Run 139/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_140/ already exists.
Skipping it.
===========
Run 140/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_141/ already exists.
Skipping it.
===========
Run 141/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_142/ already exists.
Skipping it.
===========
Run 142/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_143/ already exists.
Skipping it.
===========
Run 143/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_144/ already exists.
Skipping it.
===========
Run 144/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_145/ already exists.
Skipping it.
===========
Run 145/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_146/ already exists.
Skipping it.
===========
Run 146/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_147/ already exists.
Skipping it.
===========
Run 147/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_148/ already exists.
Skipping it.
===========
Run 148/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_149/ already exists.
Skipping it.
===========
Run 149/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_150/ already exists.
Skipping it.
===========
Run 150/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_151/ already exists.
Skipping it.
===========
Run 151/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_152/ already exists.
Skipping it.
===========
Run 152/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_153/ already exists.
Skipping it.
===========
Run 153/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_154/ already exists.
Skipping it.
===========
Run 154/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_155/ already exists.
Skipping it.
===========
Run 155/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_156/ already exists.
Skipping it.
===========
Run 156/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_157/ already exists.
Skipping it.
===========
Run 157/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_158/ already exists.
Skipping it.
===========
Run 158/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_159/ already exists.
Skipping it.
===========
Run 159/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_160/ already exists.
Skipping it.
===========
Run 160/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_161/ already exists.
Skipping it.
===========
Run 161/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_162/ already exists.
Skipping it.
===========
Run 162/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_163/ already exists.
Skipping it.
===========
Run 163/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_164/ already exists.
Skipping it.
===========
Run 164/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_165/ already exists.
Skipping it.
===========
Run 165/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_166/ already exists.
Skipping it.
===========
Run 166/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_167/ already exists.
Skipping it.
===========
Run 167/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_168/ already exists.
Skipping it.
===========
Run 168/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_169/ already exists.
Skipping it.
===========
Run 169/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_170/ already exists.
Skipping it.
===========
Run 170/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_171/ already exists.
Skipping it.
===========
Run 171/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_172/ already exists.
Skipping it.
===========
Run 172/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_173/ already exists.
Skipping it.
===========
Run 173/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_174/ already exists.
Skipping it.
===========
Run 174/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_175/ already exists.
Skipping it.
===========
Run 175/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_176/ already exists.
Skipping it.
===========
Run 176/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_177/ already exists.
Skipping it.
===========
Run 177/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_178/ already exists.
Skipping it.
===========
Run 178/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_179/ already exists.
Skipping it.
===========
Run 179/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_180/ already exists.
Skipping it.
===========
Run 180/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_181/ already exists.
Skipping it.
===========
Run 181/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_182/ already exists.
Skipping it.
===========
Run 182/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_183/ already exists.
Skipping it.
===========
Run 183/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_184/ already exists.
Skipping it.
===========
Run 184/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_185/ already exists.
Skipping it.
===========
Run 185/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_186/ already exists.
Skipping it.
===========
Run 186/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_187/ already exists.
Skipping it.
===========
Run 187/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_188/ already exists.
Skipping it.
===========
Run 188/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_189/ already exists.
Skipping it.
===========
Run 189/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_190/ already exists.
Skipping it.
===========
Run 190/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_191/ already exists.
Skipping it.
===========
Run 191/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_192/ already exists.
Skipping it.
===========
Run 192/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_193/ already exists.
Skipping it.
===========
Run 193/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_194/ already exists.
Skipping it.
===========
Run 194/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_195/ already exists.
Skipping it.
===========
Run 195/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_196/ already exists.
Skipping it.
===========
Run 196/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_197/ already exists.
Skipping it.
===========
Run 197/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_198/ already exists.
Skipping it.
===========
Run 198/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_199/ already exists.
Skipping it.
===========
Run 199/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_200/ already exists.
Skipping it.
===========
Run 200/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_201/ already exists.
Skipping it.
===========
Run 201/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_202/ already exists.
Skipping it.
===========
Run 202/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_203/ already exists.
Skipping it.
===========
Run 203/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_204/ already exists.
Skipping it.
===========
Run 204/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_205/ already exists.
Skipping it.
===========
Run 205/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_206/ already exists.
Skipping it.
===========
Run 206/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_207/ already exists.
Skipping it.
===========
Run 207/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_208/ already exists.
Skipping it.
===========
Run 208/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_209/ already exists.
Skipping it.
===========
Run 209/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_210/ already exists.
Skipping it.
===========
Run 210/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_211/ already exists.
Skipping it.
===========
Run 211/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_212/ already exists.
Skipping it.
===========
Run 212/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_213/ already exists.
Skipping it.
===========
Run 213/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_214/ already exists.
Skipping it.
===========
Run 214/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_215/ already exists.
Skipping it.
===========
Run 215/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_216/ already exists.
Skipping it.
===========
Run 216/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_217/ already exists.
Skipping it.
===========
Run 217/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_218/ already exists.
Skipping it.
===========
Run 218/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_219/ already exists.
Skipping it.
===========
Run 219/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_220/ already exists.
Skipping it.
===========
Run 220/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_221/ already exists.
Skipping it.
===========
Run 221/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_222/ already exists.
Skipping it.
===========
Run 222/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_223/ already exists.
Skipping it.
===========
Run 223/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_224/ already exists.
Skipping it.
===========
Run 224/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_225/ already exists.
Skipping it.
===========
Run 225/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_226/ already exists.
Skipping it.
===========
Run 226/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_227/ already exists.
Skipping it.
===========
Run 227/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_228/ already exists.
Skipping it.
===========
Run 228/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_229/ already exists.
Skipping it.
===========
Run 229/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_230/ already exists.
Skipping it.
===========
Run 230/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_231/ already exists.
Skipping it.
===========
Run 231/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_232/ already exists.
Skipping it.
===========
Run 232/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_233/ already exists.
Skipping it.
===========
Run 233/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_234/ already exists.
Skipping it.
===========
Run 234/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_235/ already exists.
Skipping it.
===========
Run 235/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_236/ already exists.
Skipping it.
===========
Run 236/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_237/ already exists.
Skipping it.
===========
Run 237/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_238/ already exists.
Skipping it.
===========
Run 238/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_239/ already exists.
Skipping it.
===========
Run 239/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_240/ already exists.
Skipping it.
===========
Run 240/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_241/ already exists.
Skipping it.
===========
Run 241/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_242/ already exists.
Skipping it.
===========
Run 242/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_243/ already exists.
Skipping it.
===========
Run 243/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_244/ already exists.
Skipping it.
===========
Run 244/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_245/ already exists.
Skipping it.
===========
Run 245/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_246/ already exists.
Skipping it.
===========
Run 246/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_247/ already exists.
Skipping it.
===========
Run 247/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_248/ already exists.
Skipping it.
===========
Run 248/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_249/ already exists.
Skipping it.
===========
Run 249/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_250/ already exists.
Skipping it.
===========
Run 250/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_251/ already exists.
Skipping it.
===========
Run 251/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_252/ already exists.
Skipping it.
===========
Run 252/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_253/ already exists.
Skipping it.
===========
Run 253/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_254/ already exists.
Skipping it.
===========
Run 254/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_255/ already exists.
Skipping it.
===========
Run 255/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_256/ already exists.
Skipping it.
===========
Run 256/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_257/ already exists.
Skipping it.
===========
Run 257/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_258/ already exists.
Skipping it.
===========
Run 258/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_259/ already exists.
Skipping it.
===========
Run 259/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_260/ already exists.
Skipping it.
===========
Run 260/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_261/ already exists.
Skipping it.
===========
Run 261/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_262/ already exists.
Skipping it.
===========
Run 262/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_263/ already exists.
Skipping it.
===========
Run 263/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_264/ already exists.
Skipping it.
===========
Run 264/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_265/ already exists.
Skipping it.
===========
Run 265/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_266/ already exists.
Skipping it.
===========
Run 266/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_267/ already exists.
Skipping it.
===========
Run 267/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_268/ already exists.
Skipping it.
===========
Run 268/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_269/ already exists.
Skipping it.
===========
Run 269/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_270/ already exists.
Skipping it.
===========
Run 270/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_271/ already exists.
Skipping it.
===========
Run 271/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_272/ already exists.
Skipping it.
===========
Run 272/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_273/ already exists.
Skipping it.
===========
Run 273/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_274/ already exists.
Skipping it.
===========
Run 274/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_275/ already exists.
Skipping it.
===========
Run 275/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_276/ already exists.
Skipping it.
===========
Run 276/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_277/ already exists.
Skipping it.
===========
Run 277/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_278/ already exists.
Skipping it.
===========
Run 278/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_279/ already exists.
Skipping it.
===========
Run 279/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_280/ already exists.
Skipping it.
===========
Run 280/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_281/ already exists.
Skipping it.
===========
Run 281/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_282/ already exists.
Skipping it.
===========
Run 282/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_283/ already exists.
Skipping it.
===========
Run 283/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_284/ already exists.
Skipping it.
===========
Run 284/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_285/ already exists.
Skipping it.
===========
Run 285/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_286/ already exists.
Skipping it.
===========
Run 286/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_287/ already exists.
Skipping it.
===========
Run 287/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_288/ already exists.
Skipping it.
===========
Run 288/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_289/ already exists.
Skipping it.
===========
Run 289/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_290/ already exists.
Skipping it.
===========
Run 290/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_291/ already exists.
Skipping it.
===========
Run 291/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_292/ already exists.
Skipping it.
===========
Run 292/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_293/ already exists.
Skipping it.
===========
Run 293/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_294/ already exists.
Skipping it.
===========
Run 294/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_295/ already exists.
Skipping it.
===========
Run 295/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_296/ already exists.
Skipping it.
===========
Run 296/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_297/ already exists.
Skipping it.
===========
Run 297/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_298/ already exists.
Skipping it.
===========
Run 298/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_299/ already exists.
Skipping it.
===========
Run 299/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_300/ already exists.
Skipping it.
===========
Run 300/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_301/ already exists.
Skipping it.
===========
Run 301/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_302/ already exists.
Skipping it.
===========
Run 302/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_303/ already exists.
Skipping it.
===========
Run 303/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_304/ already exists.
Skipping it.
===========
Run 304/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_305/ already exists.
Skipping it.
===========
Run 305/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_306/ already exists.
Skipping it.
===========
Run 306/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_307/ already exists.
Skipping it.
===========
Run 307/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_308/ already exists.
Skipping it.
===========
Run 308/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_309/ already exists.
Skipping it.
===========
Run 309/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_310/ already exists.
Skipping it.
===========
Run 310/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_311/ already exists.
Skipping it.
===========
Run 311/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_312/ already exists.
Skipping it.
===========
Run 312/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_313/ already exists.
Skipping it.
===========
Run 313/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_314/ already exists.
Skipping it.
===========
Run 314/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_315/ already exists.
Skipping it.
===========
Run 315/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_316/ already exists.
Skipping it.
===========
Run 316/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_317/ already exists.
Skipping it.
===========
Run 317/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_318/ already exists.
Skipping it.
===========
Run 318/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_319/ already exists.
Skipping it.
===========
Run 319/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_320/ already exists.
Skipping it.
===========
Run 320/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_321/ already exists.
Skipping it.
===========
Run 321/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_322/ already exists.
Skipping it.
===========
Run 322/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_323/ already exists.
Skipping it.
===========
Run 323/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_324/ already exists.
Skipping it.
===========
Run 324/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_325/ already exists.
Skipping it.
===========
Run 325/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_326/ already exists.
Skipping it.
===========
Run 326/360 already exists. Skipping it.
===========

===========
Generating train data for run 327.
===========
Train data generated in 2.71 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_327/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_327/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.6836276 , -0.60898554,  4.901356  , ...,  4.578798  ,
         5.78743   ,  5.8673487 ],
       [ 8.249707  ,  4.460014  ,  5.2482004 , ...,  1.7374016 ,
         8.867281  ,  6.8796477 ],
       [ 6.103276  ,  7.069252  ,  6.2995415 , ..., 11.163949  ,
         2.6241696 ,  6.7860346 ],
       ...,
       [ 5.7729836 ,  0.39295188,  4.752078  , ...,  4.8545365 ,
         6.277194  ,  5.1011395 ],
       [ 8.14715   ,  4.7503    ,  5.215126  , ...,  3.7450724 ,
         8.238651  ,  6.647562  ],
       [ 5.6715584 ,  7.2547503 ,  6.700116  , ..., 10.850491  ,
         1.1671181 ,  6.458376  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_327/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_327
self.data_kwargs: {'seed': 187}
self.x_data: [[8.405046   4.6301365  5.2287283  ... 2.9590435  8.640119   7.4559712 ]
 [6.027003   0.2016806  4.6617384  ... 4.692235   6.373698   5.3374834 ]
 [5.680177   0.10050362 4.564641   ... 4.4050727  6.0966487  6.0310545 ]
 ...
 [6.204324   0.5308406  4.687448   ... 4.736321   6.117902   4.3074207 ]
 [7.884271   4.844002   5.2654357  ... 2.2312212  7.9686017  6.4498177 ]
 [5.7032723  1.704168   4.78966    ... 5.263417   6.7690263  5.8227935 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1000)]            0         
                                                                 
 log_prob_layer (LogProbLaye  (None,)                  4191520   
 r)                                                              
                                                                 
=================================================================
Total params: 4,191,520
Trainable params: 4,191,520
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer'")
self.model: <keras.engine.functional.Functional object at 0x7f1a2050ebf0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f19fc5d8310>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f19fc5d8310>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f19fc52cbe0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f19fc4c9060>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f19fc4c9960>, <keras.callbacks.ModelCheckpoint object at 0x7f19fc4c9ab0>, <keras.callbacks.EarlyStopping object at 0x7f19fc4c9cc0>, <keras.callbacks.ReduceLROnPlateau object at 0x7f19fc4c9cf0>, <keras.callbacks.TerminateOnNaN object at 0x7f19fc4c9a20>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.6836276 , -0.60898554,  4.901356  , ...,  4.578798  ,
         5.78743   ,  5.8673487 ],
       [ 8.249707  ,  4.460014  ,  5.2482004 , ...,  1.7374016 ,
         8.867281  ,  6.8796477 ],
       [ 6.103276  ,  7.069252  ,  6.2995415 , ..., 11.163949  ,
         2.6241696 ,  6.7860346 ],
       ...,
       [ 5.7729836 ,  0.39295188,  4.752078  , ...,  4.8545365 ,
         6.277194  ,  5.1011395 ],
       [ 8.14715   ,  4.7503    ,  5.215126  , ...,  3.7450724 ,
         8.238651  ,  6.647562  ],
       [ 5.6715584 ,  7.2547503 ,  6.700116  , ..., 10.850491  ,
         1.1671181 ,  6.458376  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_327/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 327/360 with hyperparameters:
timestamp = 2023-09-09 22:36:29.973200
ndims = 1000
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 4191520
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 8.405046    4.6301365   5.2287283   2.4556472   6.2928953   3.594312
  6.0004463   1.8052834   1.8765529   4.0951214   4.4015846   3.3011546
  1.1913271   0.29790348  0.444705    2.0839415   4.8839054   7.6232376
  5.0511703  10.082624    1.0256902   1.8862149   3.3338983   5.485959
  8.678817    4.2863455   2.746828    0.5995625   8.487818    4.326282
  5.4844646   9.668893    0.9005003   2.511495    7.4595304   8.076063
  7.482936    5.8244066  10.038453    4.2971616   6.199124    0.14504078
  4.115744    7.085761    2.2268302   8.105376    6.8798943   3.1965656
  7.803503    1.4473212   9.836955    1.2955343   9.292721    2.2835047
  7.347313   -0.344647    2.3793294   7.1599417   6.239404    1.8819436
  3.6855946   3.1096044   3.9889503   6.345884    8.7655735   3.506798
  3.8915956   1.4826899   7.7798705   6.4561133   3.7245452   5.022784
  6.785575    1.8807405  -0.53786993  3.331518    6.3648286   5.060461
  5.671335    8.188019    5.050044    0.8326328   9.021144    5.101296
  8.440869    7.8830547   9.847927    2.9928007   7.1174664   4.000934
  4.0642667   3.5513847   3.3835356   9.485252    2.8910272   2.857944
  5.1031704   2.365148    4.392073    7.9044094   2.2182727   3.5326295
  6.429046    5.444268    9.853491    6.801449    7.615357    9.654012
  4.2561636   3.94246     0.5266583   1.6963573   0.9076003   1.6972958
  8.415306    6.55893     6.517854    7.7323823   2.263416    3.867008
  7.0743175   4.310728    0.44073427  5.454958    8.770797    4.023472
  3.8313503   9.876201    6.083322    4.588916    0.97578037  8.022623
  6.904659    9.723064    1.5232677   1.2301477   7.2426834   2.4050941
  1.7633336   1.3129089   8.420942    5.7998257   0.4667193   4.692241
  6.5908155   5.257252    5.725936    2.6134639   8.439922    5.6147094
  7.455604    9.777677    4.190657    9.502805    0.30458957  0.2189286
  5.797137    3.0544481   2.6193647   2.5525932   3.284805    7.4161353
  5.749028    7.889573    7.898816    8.574444    3.8091307   4.298687
  9.481366    6.0068207   1.523428    5.6352916   4.365734    9.867473
  1.3835607   6.134872    7.2581935   2.8856063   9.735012    7.5791473
  9.23718     0.3085858   6.8750105   3.0606773   9.2376585   6.005112
  5.5536275   0.9032261   6.0153728   6.3190417   9.369196    5.911083
  9.520276   10.025198    7.444127    4.7846828   6.6327243  10.038699
  0.737067    1.1364235   0.7629767   7.3339915   3.2413385   6.3641744
  4.723883    3.890898    5.1846333   6.4865723   9.4478655   5.8353424
  6.1596503   0.8805034  10.229148    5.1357536   8.719589    0.61422366
  4.6646357   2.5584815   2.6442034   7.3017416   5.692237    3.2181895
  0.7464954   9.628433    9.805298    0.8460964   0.74706554  6.1736875
  9.794054    9.817206    5.73489     2.8118153   2.995823    9.004283
  3.2283762   1.9297047   2.5467188   2.732583    2.62711     5.3906684
  8.859532    7.221753    0.22360349  0.31767347  3.3918247   3.5905416
  8.748679    9.150864    4.0089087   6.819023    9.95121     7.2592616
  6.618907    0.7986359   3.617743    8.477222    2.5446649   8.356348
  6.784008    2.7764812   5.149644    5.879593    6.8204975   4.7749815
  1.5671438   7.5464864   2.9128666   9.640756    2.7195537   2.422054
  1.9658555   5.744532   10.17906     1.88257     3.3741965   5.759674
  4.4506254   5.799042    8.574516    9.521442    4.848262    7.099014
  7.410928    4.176586    2.7669337   6.7037125   6.396343    9.116149
  0.6767711   8.802082    5.400854   -0.46128303  4.315248    7.679634
  4.337188    9.473796    4.3057194   3.8800864   8.321836    5.464394
  6.8586717   7.8846817   6.758233    4.5121193   1.5240693   5.1997232
  7.966815    3.110014    9.149139    5.2918534   6.043538    8.5325165
  7.029521    0.71871924  9.851924    2.0979629   7.107039    5.8480177
  4.6838837   2.2520099   7.556054    1.2082794  10.557993    8.230412
  5.3685956   3.7290514   3.748278    4.2430515   8.3245535   2.619837
  3.433112    1.6606942   2.8829854   1.0669343   9.924688    5.8388543
  6.973813    0.9312429   3.8876076   8.887293    0.8722724   2.881507
  6.283689    6.159739    8.345073    9.115302    1.4750379   2.7552269
  4.2736816   0.15881406 -0.24159682  2.4190745   4.887695    2.6831913
  8.220071    3.2441287   8.8378105   9.509058    3.559123    3.1608875
  3.3725164   7.9289885   2.9474692   4.059424    4.7409554   5.2013454
  9.994335    2.323355    3.3355927   2.5336983   3.2941818   2.2210457
  3.2414346   9.904477    2.334639    4.492616   10.475705    7.142849
  4.6010633   7.570345    1.3164223   4.2845144   0.5250243   2.3362412
  2.8345227   3.6286557   4.130509    9.905742    2.1830826   4.842215
  6.807653    7.5327077   7.2363663   2.9334166   5.234727    1.7384282
  2.0550947   4.500183    7.394765    4.995599    7.815772   10.710524
 -0.19277403  5.792584    6.1900487   9.671367    0.28583023  5.668808
  1.2390957   0.5417446   6.8533115   7.9632573   8.180385   -0.4858576
  4.0685763   2.4839914   2.1516795   1.9025909   2.110797    2.6641178
  2.6061893   9.366816    4.2622356   8.9237175   1.1875978   7.9966984
  0.44503674  4.7554154  -0.20823273  7.945292   10.080656    0.3404049
  8.932869    8.365952    3.7764497   9.093311    2.3442857   4.1149993
  0.99684995  6.8027267   0.3532521   4.712874    6.197236    8.98079
  0.7532523   7.324172    6.816783    7.1629744   5.789584    1.8008664
  6.6962724   3.5133753   8.672127    1.7033234   5.757915    3.8499484
  7.6907835   2.515215    0.675339    6.6755958   4.1274943   5.9000664
  0.6306852  10.170123    8.690909    5.6241055   0.83715045  3.7537289
  9.811078    7.1486425   1.5089558   4.5211      9.977777    5.041157
  0.20099962  7.1491528   2.411008    0.98729235  4.0264      6.1107965
  0.8201466   6.400518    5.2138658   8.338983    4.008616    5.4276114
  7.5568547   9.328188    3.5043116   5.993576    6.732445    0.1456024
  8.195436    4.0946035   6.8117595   5.4540176   7.008695    7.6902666
  1.121738    6.662947    9.421039    3.6054578   8.282917    6.2551546
  8.867136    2.7717266   1.666508    1.9828001   2.582295    7.401628
  7.3309445   6.1640267   2.2886527   8.620049    9.976319    5.427213
  6.492129    5.227495    2.6098144   3.1037233   2.451418    1.547883
  9.130067    9.089639    3.8307672   2.809064    9.412396    3.0656943
  5.384379    1.269433    2.1198947   5.4160995   5.9553137   6.8595047
  8.024387    9.932428    7.275275    5.4964776   9.2686615  -0.8320414
  6.634356    3.5646963   1.6928086   9.683453    3.4941626   6.2850795
  8.140037    5.0819607   1.6098254   8.515681    3.746112   10.339378
  9.723754    8.560821    3.4616127   8.136909    8.474316    5.334234
  4.3071146   0.3017891   7.5740643   8.525242    1.961537    2.785501
  4.6199455   0.20740837  0.8326539   4.594327    2.569767    3.3214014
  4.017394    9.219309   10.736801    1.9790065   8.832557    0.9678319
  5.233325   -0.19063437  3.1312854   8.050418    4.191532    9.204013
  7.268445    9.203028    4.342827    8.019755    3.3341756   3.743745
  3.9635062   3.979517    0.6836107   5.098467    0.71361184  8.4552765
  0.5069707   4.833144    3.1548538   1.8944778   7.8488803   7.0419393
  1.2548511   6.628743    7.354838    8.050705    1.1345416   6.8048496
  6.528121    8.252401    4.5538      4.949585    8.730731    7.4312305
  5.643753    2.5072966   8.962284    4.0641007   0.7590125   5.4753785
  9.738958    4.561652   -0.360509    6.1097317   9.957747    7.0762954
  5.690881    8.773466    8.0799      5.2899666   6.263382    7.4875503
  8.585341    0.6384524   8.029185    4.3010435   6.264173    7.7155027
  5.2268887   1.5704446   4.016696    0.5981313   6.7822347   9.855953
  7.53499     5.1501827   5.5134096   2.8642232   5.220349    3.4915414
  4.7451196   2.6037292   9.620164    6.549827    0.7027252  -0.15775523
 10.00958     3.973167    3.273789    1.7160401   9.183787    7.1865473
  5.1355295   4.8474526   3.5554662   6.6154428   4.344493    2.1984468
  5.4696417   4.251729    8.8025255   4.26232     4.9216294   7.9483533
  4.526991    9.588897    8.017048    8.2831135   9.821576    4.1731563
  5.8485947   6.667628    7.001741    9.226937    2.9446237   2.5925434
  8.618449    8.161273    1.7101693   5.5401206   8.14539     2.020844
  0.89211583  5.7496552   4.987388    7.4813085   0.39198843  4.8122907
  2.6751356   5.1997175   7.827039    0.7617685   1.984582    6.211319
  7.497485    5.6864862   9.833999    4.343862    0.91428226  6.860134
  8.022065    5.7952833   5.549028    8.938169    0.7987054   1.0077511
  1.547055    2.4538176   5.900641    5.950689    2.172312    4.864265
  5.3084598   2.74433     7.4509587   4.642633    7.352649    1.6610278
  5.3932858   8.224104    1.7825346   4.6216807   6.3162665   2.1527483
  7.82622     0.4708147   9.143722    4.7161274   2.9691823   0.9679443
  3.9266372   6.638867    0.10056549  3.118843    7.3452816   6.4795094
  2.0939577   2.478408    8.811012    3.114293    2.1261327  10.111931
  4.855735    1.2398901   5.2605786   5.4892864   9.44359     1.744517
  0.8859111   0.84614795  8.730755    4.4898634   1.9797392   5.9254265
  5.903251    2.0259151   7.1823764   4.0827475   2.3360302   5.4425554
  3.0566494   1.579066    8.333391    1.4978724   3.288137    3.852397
  2.935655    2.1213212   6.9459066   3.5336087   1.8826928   5.0965667
  1.2400447   4.7354097   8.616984    2.6134915   5.8834224   5.1864443
 -0.13750565  6.549661    8.984314    0.7847537   7.2001395   6.8008256
  8.44678     2.6799302   3.2838757   7.0237226  -0.23040357  7.540698
  8.530038    4.6869135   3.2353654   3.3326626  -2.8252068   1.808005
  8.638641    9.090046    2.7026813   9.352778    3.2715847   2.764985
  2.5781574   8.643513    9.775191    3.6196568   6.3544054   2.67319
 -0.27903366  3.0261974   5.7475586   1.8039718   8.191788    4.8235297
  2.4119723   4.80837     7.8066583   3.14657     7.254359    3.8570547
  8.983632    8.136105    3.6973224   0.29414394  6.2837157   1.7246333
  1.2347451   8.727795    9.613968    2.8966768   3.0174162   1.6892313
  4.788908    8.051952    6.6716456   8.591153    1.2762189   7.83716
 10.090976    2.9488695   6.9059463   3.4287705   2.638495    9.951833
  3.8517146   1.0833437   3.8833115   4.4572515   7.453829    9.261691
 10.299599    8.9711075   4.912658    7.687476    2.8381176   0.8803614
  3.6029894   7.0204277   3.0225866   9.093265    9.016605    1.5790088
  2.4555895   8.069907    3.3349042   3.3253474   3.304729    8.906204
  0.14018849 -0.09102672  5.6968327   2.8784204   6.3043637   1.5840611
  9.080589    7.872192    0.68985736  8.022463    9.62591     9.730082
  6.885892    1.2239211   6.788951    3.103189    8.581392    7.224449
  6.0487485   6.9063663   4.2010665   4.5798826   9.059492    3.4417286
  0.25157684  4.0677304   8.905279    6.148643   11.682095    0.95629424
  9.730315    5.5144877   4.490063    4.5312085   1.2480376   3.6158848
  7.4273086  -0.96325046  1.452391    0.25324896  8.457037    6.1265316
  1.3514678   8.127087   10.009373    9.350058    8.951299   -0.29766494
  6.0847034   2.4157875   5.6192784   2.8229573   0.7195138   4.5521054
  4.8054247   9.962674    0.39720708  3.1612184   8.577424    7.115589
  7.7674336   6.298065    7.663883    4.695144    1.1639674   7.7367616
  5.669413    1.2667739   7.7379103   9.650189    3.731491    3.391371
  0.73656756  6.0238733   9.167239    1.2704167   4.995278    0.9358564
  0.38653633  6.6325297   8.341552    3.6262543   7.874937    2.0914352
  2.2575343   7.0230904   4.9926057   4.8522496   0.38922572  1.2943935
  0.4778885   8.9588175   1.688771    8.19581     3.4283693   8.456239
  2.8242724   2.5323164   0.56487453  2.687169    3.4400296   8.293358
  4.435119    8.654662    5.423925   -0.7138738   3.3961737   6.6198845
  2.3316503   8.031245    4.494654    0.59436065  7.459087    5.8713436
  0.84994775  5.0717716   3.7515552   9.185751    2.3369966   9.342911
  5.7315216   2.9590435   8.640119    7.4559712 ]
Epoch 1/1000
2023-09-09 22:38:01.615 
Epoch 1/1000 
	 loss: 1657.0245, MinusLogProbMetric: 1657.0245, val_loss: 602.3015, val_MinusLogProbMetric: 602.3015

Epoch 1: val_loss improved from inf to 602.30145, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 92s - loss: 1657.0245 - MinusLogProbMetric: 1657.0245 - val_loss: 602.3015 - val_MinusLogProbMetric: 602.3015 - lr: 0.0010 - 92s/epoch - 468ms/step
Epoch 2/1000
2023-09-09 22:38:20.240 
Epoch 2/1000 
	 loss: 577.1960, MinusLogProbMetric: 577.1960, val_loss: 550.4634, val_MinusLogProbMetric: 550.4634

Epoch 2: val_loss improved from 602.30145 to 550.46338, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 577.1960 - MinusLogProbMetric: 577.1960 - val_loss: 550.4634 - val_MinusLogProbMetric: 550.4634 - lr: 0.0010 - 18s/epoch - 93ms/step
Epoch 3/1000
2023-09-09 22:38:36.404 
Epoch 3/1000 
	 loss: 910.3648, MinusLogProbMetric: 910.3648, val_loss: 577.2822, val_MinusLogProbMetric: 577.2822

Epoch 3: val_loss did not improve from 550.46338
196/196 - 16s - loss: 910.3648 - MinusLogProbMetric: 910.3648 - val_loss: 577.2822 - val_MinusLogProbMetric: 577.2822 - lr: 0.0010 - 16s/epoch - 80ms/step
Epoch 4/1000
2023-09-09 22:38:54.375 
Epoch 4/1000 
	 loss: 531.1857, MinusLogProbMetric: 531.1857, val_loss: 501.9919, val_MinusLogProbMetric: 501.9919

Epoch 4: val_loss improved from 550.46338 to 501.99191, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 19s - loss: 531.1857 - MinusLogProbMetric: 531.1857 - val_loss: 501.9919 - val_MinusLogProbMetric: 501.9919 - lr: 0.0010 - 19s/epoch - 94ms/step
Epoch 5/1000
2023-09-09 22:39:11.025 
Epoch 5/1000 
	 loss: 495.3997, MinusLogProbMetric: 495.3997, val_loss: 484.8569, val_MinusLogProbMetric: 484.8569

Epoch 5: val_loss improved from 501.99191 to 484.85693, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 495.3997 - MinusLogProbMetric: 495.3997 - val_loss: 484.8569 - val_MinusLogProbMetric: 484.8569 - lr: 0.0010 - 17s/epoch - 85ms/step
Epoch 6/1000
2023-09-09 22:39:27.658 
Epoch 6/1000 
	 loss: 481.8889, MinusLogProbMetric: 481.8889, val_loss: 480.9468, val_MinusLogProbMetric: 480.9468

Epoch 6: val_loss improved from 484.85693 to 480.94678, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 481.8889 - MinusLogProbMetric: 481.8889 - val_loss: 480.9468 - val_MinusLogProbMetric: 480.9468 - lr: 0.0010 - 17s/epoch - 85ms/step
Epoch 7/1000
2023-09-09 22:39:44.967 
Epoch 7/1000 
	 loss: 471.8910, MinusLogProbMetric: 471.8910, val_loss: 468.2783, val_MinusLogProbMetric: 468.2783

Epoch 7: val_loss improved from 480.94678 to 468.27832, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 471.8910 - MinusLogProbMetric: 471.8910 - val_loss: 468.2783 - val_MinusLogProbMetric: 468.2783 - lr: 0.0010 - 17s/epoch - 89ms/step
Epoch 8/1000
2023-09-09 22:40:01.899 
Epoch 8/1000 
	 loss: 464.6873, MinusLogProbMetric: 464.6873, val_loss: 466.5261, val_MinusLogProbMetric: 466.5261

Epoch 8: val_loss improved from 468.27832 to 466.52612, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 464.6873 - MinusLogProbMetric: 464.6873 - val_loss: 466.5261 - val_MinusLogProbMetric: 466.5261 - lr: 0.0010 - 17s/epoch - 87ms/step
Epoch 9/1000
2023-09-09 22:40:18.108 
Epoch 9/1000 
	 loss: 458.6390, MinusLogProbMetric: 458.6390, val_loss: 457.2696, val_MinusLogProbMetric: 457.2696

Epoch 9: val_loss improved from 466.52612 to 457.26956, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 16s - loss: 458.6390 - MinusLogProbMetric: 458.6390 - val_loss: 457.2696 - val_MinusLogProbMetric: 457.2696 - lr: 0.0010 - 16s/epoch - 82ms/step
Epoch 10/1000
2023-09-09 22:40:33.739 
Epoch 10/1000 
	 loss: 456.7558, MinusLogProbMetric: 456.7558, val_loss: 453.1715, val_MinusLogProbMetric: 453.1715

Epoch 10: val_loss improved from 457.26956 to 453.17148, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 16s - loss: 456.7558 - MinusLogProbMetric: 456.7558 - val_loss: 453.1715 - val_MinusLogProbMetric: 453.1715 - lr: 0.0010 - 16s/epoch - 79ms/step
Epoch 11/1000
2023-09-09 22:40:49.076 
Epoch 11/1000 
	 loss: 451.2414, MinusLogProbMetric: 451.2414, val_loss: 450.0322, val_MinusLogProbMetric: 450.0322

Epoch 11: val_loss improved from 453.17148 to 450.03217, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 15s - loss: 451.2414 - MinusLogProbMetric: 451.2414 - val_loss: 450.0322 - val_MinusLogProbMetric: 450.0322 - lr: 0.0010 - 15s/epoch - 78ms/step
Epoch 12/1000
2023-09-09 22:41:06.014 
Epoch 12/1000 
	 loss: 447.4194, MinusLogProbMetric: 447.4194, val_loss: 453.4374, val_MinusLogProbMetric: 453.4374

Epoch 12: val_loss did not improve from 450.03217
196/196 - 16s - loss: 447.4194 - MinusLogProbMetric: 447.4194 - val_loss: 453.4374 - val_MinusLogProbMetric: 453.4374 - lr: 0.0010 - 16s/epoch - 84ms/step
Epoch 13/1000
2023-09-09 22:41:21.369 
Epoch 13/1000 
	 loss: 443.3590, MinusLogProbMetric: 443.3590, val_loss: 440.9134, val_MinusLogProbMetric: 440.9134

Epoch 13: val_loss improved from 450.03217 to 440.91339, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 16s - loss: 443.3590 - MinusLogProbMetric: 443.3590 - val_loss: 440.9134 - val_MinusLogProbMetric: 440.9134 - lr: 0.0010 - 16s/epoch - 84ms/step
Epoch 14/1000
2023-09-09 22:41:39.843 
Epoch 14/1000 
	 loss: 441.9143, MinusLogProbMetric: 441.9143, val_loss: 440.6072, val_MinusLogProbMetric: 440.6072

Epoch 14: val_loss improved from 440.91339 to 440.60721, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 441.9143 - MinusLogProbMetric: 441.9143 - val_loss: 440.6072 - val_MinusLogProbMetric: 440.6072 - lr: 0.0010 - 18s/epoch - 92ms/step
Epoch 15/1000
2023-09-09 22:41:57.000 
Epoch 15/1000 
	 loss: 440.3606, MinusLogProbMetric: 440.3606, val_loss: 436.7775, val_MinusLogProbMetric: 436.7775

Epoch 15: val_loss improved from 440.60721 to 436.77747, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 440.3606 - MinusLogProbMetric: 440.3606 - val_loss: 436.7775 - val_MinusLogProbMetric: 436.7775 - lr: 0.0010 - 17s/epoch - 87ms/step
Epoch 16/1000
2023-09-09 22:42:12.448 
Epoch 16/1000 
	 loss: 436.1853, MinusLogProbMetric: 436.1853, val_loss: 437.7388, val_MinusLogProbMetric: 437.7388

Epoch 16: val_loss did not improve from 436.77747
196/196 - 15s - loss: 436.1853 - MinusLogProbMetric: 436.1853 - val_loss: 437.7388 - val_MinusLogProbMetric: 437.7388 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 17/1000
2023-09-09 22:42:27.733 
Epoch 17/1000 
	 loss: 437.4243, MinusLogProbMetric: 437.4243, val_loss: 435.2393, val_MinusLogProbMetric: 435.2393

Epoch 17: val_loss improved from 436.77747 to 435.23932, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 16s - loss: 437.4243 - MinusLogProbMetric: 437.4243 - val_loss: 435.2393 - val_MinusLogProbMetric: 435.2393 - lr: 0.0010 - 16s/epoch - 81ms/step
Epoch 18/1000
2023-09-09 22:42:43.244 
Epoch 18/1000 
	 loss: 434.9294, MinusLogProbMetric: 434.9294, val_loss: 441.0909, val_MinusLogProbMetric: 441.0909

Epoch 18: val_loss did not improve from 435.23932
196/196 - 15s - loss: 434.9294 - MinusLogProbMetric: 434.9294 - val_loss: 441.0909 - val_MinusLogProbMetric: 441.0909 - lr: 0.0010 - 15s/epoch - 76ms/step
Epoch 19/1000
2023-09-09 22:43:00.804 
Epoch 19/1000 
	 loss: 434.9543, MinusLogProbMetric: 434.9543, val_loss: 438.7298, val_MinusLogProbMetric: 438.7298

Epoch 19: val_loss did not improve from 435.23932
196/196 - 18s - loss: 434.9543 - MinusLogProbMetric: 434.9543 - val_loss: 438.7298 - val_MinusLogProbMetric: 438.7298 - lr: 0.0010 - 18s/epoch - 90ms/step
Epoch 20/1000
2023-09-09 22:43:16.718 
Epoch 20/1000 
	 loss: 429.8616, MinusLogProbMetric: 429.8616, val_loss: 427.6503, val_MinusLogProbMetric: 427.6503

Epoch 20: val_loss improved from 435.23932 to 427.65033, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 429.8616 - MinusLogProbMetric: 429.8616 - val_loss: 427.6503 - val_MinusLogProbMetric: 427.6503 - lr: 0.0010 - 17s/epoch - 85ms/step
Epoch 21/1000
2023-09-09 22:43:34.336 
Epoch 21/1000 
	 loss: 428.1169, MinusLogProbMetric: 428.1169, val_loss: 425.3196, val_MinusLogProbMetric: 425.3196

Epoch 21: val_loss improved from 427.65033 to 425.31958, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 428.1169 - MinusLogProbMetric: 428.1169 - val_loss: 425.3196 - val_MinusLogProbMetric: 425.3196 - lr: 0.0010 - 18s/epoch - 89ms/step
Epoch 22/1000
2023-09-09 22:43:50.987 
Epoch 22/1000 
	 loss: 427.8160, MinusLogProbMetric: 427.8160, val_loss: 426.5877, val_MinusLogProbMetric: 426.5877

Epoch 22: val_loss did not improve from 425.31958
196/196 - 16s - loss: 427.8160 - MinusLogProbMetric: 427.8160 - val_loss: 426.5877 - val_MinusLogProbMetric: 426.5877 - lr: 0.0010 - 16s/epoch - 82ms/step
Epoch 23/1000
2023-09-09 22:44:07.626 
Epoch 23/1000 
	 loss: 425.6606, MinusLogProbMetric: 425.6606, val_loss: 433.4526, val_MinusLogProbMetric: 433.4526

Epoch 23: val_loss did not improve from 425.31958
196/196 - 17s - loss: 425.6606 - MinusLogProbMetric: 425.6606 - val_loss: 433.4526 - val_MinusLogProbMetric: 433.4526 - lr: 0.0010 - 17s/epoch - 85ms/step
Epoch 24/1000
2023-09-09 22:44:23.383 
Epoch 24/1000 
	 loss: 425.8918, MinusLogProbMetric: 425.8918, val_loss: 429.5873, val_MinusLogProbMetric: 429.5873

Epoch 24: val_loss did not improve from 425.31958
196/196 - 16s - loss: 425.8918 - MinusLogProbMetric: 425.8918 - val_loss: 429.5873 - val_MinusLogProbMetric: 429.5873 - lr: 0.0010 - 16s/epoch - 80ms/step
Epoch 25/1000
2023-09-09 22:44:41.563 
Epoch 25/1000 
	 loss: 423.1261, MinusLogProbMetric: 423.1261, val_loss: 423.8367, val_MinusLogProbMetric: 423.8367

Epoch 25: val_loss improved from 425.31958 to 423.83670, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 19s - loss: 423.1261 - MinusLogProbMetric: 423.1261 - val_loss: 423.8367 - val_MinusLogProbMetric: 423.8367 - lr: 0.0010 - 19s/epoch - 95ms/step
Epoch 26/1000
2023-09-09 22:44:59.361 
Epoch 26/1000 
	 loss: 423.6923, MinusLogProbMetric: 423.6923, val_loss: 423.8418, val_MinusLogProbMetric: 423.8418

Epoch 26: val_loss did not improve from 423.83670
196/196 - 17s - loss: 423.6923 - MinusLogProbMetric: 423.6923 - val_loss: 423.8418 - val_MinusLogProbMetric: 423.8418 - lr: 0.0010 - 17s/epoch - 88ms/step
Epoch 27/1000
2023-09-09 22:45:15.729 
Epoch 27/1000 
	 loss: 422.6994, MinusLogProbMetric: 422.6994, val_loss: 421.6649, val_MinusLogProbMetric: 421.6649

Epoch 27: val_loss improved from 423.83670 to 421.66495, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 422.6994 - MinusLogProbMetric: 422.6994 - val_loss: 421.6649 - val_MinusLogProbMetric: 421.6649 - lr: 0.0010 - 17s/epoch - 87ms/step
Epoch 28/1000
2023-09-09 22:45:33.551 
Epoch 28/1000 
	 loss: 421.7918, MinusLogProbMetric: 421.7918, val_loss: 419.3301, val_MinusLogProbMetric: 419.3301

Epoch 28: val_loss improved from 421.66495 to 419.33008, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 421.7918 - MinusLogProbMetric: 421.7918 - val_loss: 419.3301 - val_MinusLogProbMetric: 419.3301 - lr: 0.0010 - 18s/epoch - 90ms/step
Epoch 29/1000
2023-09-09 22:45:50.246 
Epoch 29/1000 
	 loss: 423.1259, MinusLogProbMetric: 423.1259, val_loss: 420.1148, val_MinusLogProbMetric: 420.1148

Epoch 29: val_loss did not improve from 419.33008
196/196 - 16s - loss: 423.1259 - MinusLogProbMetric: 423.1259 - val_loss: 420.1148 - val_MinusLogProbMetric: 420.1148 - lr: 0.0010 - 16s/epoch - 83ms/step
Epoch 30/1000
2023-09-09 22:46:06.858 
Epoch 30/1000 
	 loss: 419.8761, MinusLogProbMetric: 419.8761, val_loss: 418.8457, val_MinusLogProbMetric: 418.8457

Epoch 30: val_loss improved from 419.33008 to 418.84570, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 419.8761 - MinusLogProbMetric: 419.8761 - val_loss: 418.8457 - val_MinusLogProbMetric: 418.8457 - lr: 0.0010 - 17s/epoch - 87ms/step
Epoch 31/1000
2023-09-09 22:46:24.689 
Epoch 31/1000 
	 loss: 419.8185, MinusLogProbMetric: 419.8185, val_loss: 485.0107, val_MinusLogProbMetric: 485.0107

Epoch 31: val_loss did not improve from 418.84570
196/196 - 17s - loss: 419.8185 - MinusLogProbMetric: 419.8185 - val_loss: 485.0107 - val_MinusLogProbMetric: 485.0107 - lr: 0.0010 - 17s/epoch - 88ms/step
Epoch 32/1000
2023-09-09 22:46:40.590 
Epoch 32/1000 
	 loss: 423.6403, MinusLogProbMetric: 423.6403, val_loss: 432.5253, val_MinusLogProbMetric: 432.5253

Epoch 32: val_loss did not improve from 418.84570
196/196 - 16s - loss: 423.6403 - MinusLogProbMetric: 423.6403 - val_loss: 432.5253 - val_MinusLogProbMetric: 432.5253 - lr: 0.0010 - 16s/epoch - 81ms/step
Epoch 33/1000
2023-09-09 22:46:56.129 
Epoch 33/1000 
	 loss: 419.0223, MinusLogProbMetric: 419.0223, val_loss: 420.7327, val_MinusLogProbMetric: 420.7327

Epoch 33: val_loss did not improve from 418.84570
196/196 - 16s - loss: 419.0223 - MinusLogProbMetric: 419.0223 - val_loss: 420.7327 - val_MinusLogProbMetric: 420.7327 - lr: 0.0010 - 16s/epoch - 79ms/step
Epoch 34/1000
2023-09-09 22:47:13.406 
Epoch 34/1000 
	 loss: 419.1287, MinusLogProbMetric: 419.1287, val_loss: 423.4011, val_MinusLogProbMetric: 423.4011

Epoch 34: val_loss did not improve from 418.84570
196/196 - 17s - loss: 419.1287 - MinusLogProbMetric: 419.1287 - val_loss: 423.4011 - val_MinusLogProbMetric: 423.4011 - lr: 0.0010 - 17s/epoch - 88ms/step
Epoch 35/1000
2023-09-09 22:47:28.578 
Epoch 35/1000 
	 loss: 416.0823, MinusLogProbMetric: 416.0823, val_loss: 435.4107, val_MinusLogProbMetric: 435.4107

Epoch 35: val_loss did not improve from 418.84570
196/196 - 15s - loss: 416.0823 - MinusLogProbMetric: 416.0823 - val_loss: 435.4107 - val_MinusLogProbMetric: 435.4107 - lr: 0.0010 - 15s/epoch - 77ms/step
Epoch 36/1000
2023-09-09 22:47:43.480 
Epoch 36/1000 
	 loss: 417.8106, MinusLogProbMetric: 417.8106, val_loss: 415.9951, val_MinusLogProbMetric: 415.9951

Epoch 36: val_loss improved from 418.84570 to 415.99509, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 15s - loss: 417.8106 - MinusLogProbMetric: 417.8106 - val_loss: 415.9951 - val_MinusLogProbMetric: 415.9951 - lr: 0.0010 - 15s/epoch - 79ms/step
Epoch 37/1000
2023-09-09 22:48:00.782 
Epoch 37/1000 
	 loss: 417.5574, MinusLogProbMetric: 417.5574, val_loss: 418.0569, val_MinusLogProbMetric: 418.0569

Epoch 37: val_loss did not improve from 415.99509
196/196 - 17s - loss: 417.5574 - MinusLogProbMetric: 417.5574 - val_loss: 418.0569 - val_MinusLogProbMetric: 418.0569 - lr: 0.0010 - 17s/epoch - 85ms/step
Epoch 38/1000
2023-09-09 22:48:18.133 
Epoch 38/1000 
	 loss: 416.0523, MinusLogProbMetric: 416.0523, val_loss: 415.8654, val_MinusLogProbMetric: 415.8654

Epoch 38: val_loss improved from 415.99509 to 415.86545, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 416.0523 - MinusLogProbMetric: 416.0523 - val_loss: 415.8654 - val_MinusLogProbMetric: 415.8654 - lr: 0.0010 - 18s/epoch - 91ms/step
Epoch 39/1000
2023-09-09 22:48:38.072 
Epoch 39/1000 
	 loss: 416.1883, MinusLogProbMetric: 416.1883, val_loss: 415.6659, val_MinusLogProbMetric: 415.6659

Epoch 39: val_loss improved from 415.86545 to 415.66589, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 20s - loss: 416.1883 - MinusLogProbMetric: 416.1883 - val_loss: 415.6659 - val_MinusLogProbMetric: 415.6659 - lr: 0.0010 - 20s/epoch - 102ms/step
Epoch 40/1000
2023-09-09 22:48:55.318 
Epoch 40/1000 
	 loss: 415.7460, MinusLogProbMetric: 415.7460, val_loss: 417.3764, val_MinusLogProbMetric: 417.3764

Epoch 40: val_loss did not improve from 415.66589
196/196 - 17s - loss: 415.7460 - MinusLogProbMetric: 415.7460 - val_loss: 417.3764 - val_MinusLogProbMetric: 417.3764 - lr: 0.0010 - 17s/epoch - 85ms/step
Epoch 41/1000
2023-09-09 22:49:12.802 
Epoch 41/1000 
	 loss: 415.4958, MinusLogProbMetric: 415.4958, val_loss: 424.0848, val_MinusLogProbMetric: 424.0848

Epoch 41: val_loss did not improve from 415.66589
196/196 - 17s - loss: 415.4958 - MinusLogProbMetric: 415.4958 - val_loss: 424.0848 - val_MinusLogProbMetric: 424.0848 - lr: 0.0010 - 17s/epoch - 89ms/step
Epoch 42/1000
2023-09-09 22:49:29.689 
Epoch 42/1000 
	 loss: 415.2736, MinusLogProbMetric: 415.2736, val_loss: 414.6395, val_MinusLogProbMetric: 414.6395

Epoch 42: val_loss improved from 415.66589 to 414.63947, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 415.2736 - MinusLogProbMetric: 415.2736 - val_loss: 414.6395 - val_MinusLogProbMetric: 414.6395 - lr: 0.0010 - 17s/epoch - 89ms/step
Epoch 43/1000
2023-09-09 22:49:47.108 
Epoch 43/1000 
	 loss: 414.2099, MinusLogProbMetric: 414.2099, val_loss: 441.3380, val_MinusLogProbMetric: 441.3380

Epoch 43: val_loss did not improve from 414.63947
196/196 - 17s - loss: 414.2099 - MinusLogProbMetric: 414.2099 - val_loss: 441.3380 - val_MinusLogProbMetric: 441.3380 - lr: 0.0010 - 17s/epoch - 86ms/step
Epoch 44/1000
2023-09-09 22:50:04.569 
Epoch 44/1000 
	 loss: 414.2759, MinusLogProbMetric: 414.2759, val_loss: 411.9691, val_MinusLogProbMetric: 411.9691

Epoch 44: val_loss improved from 414.63947 to 411.96906, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 414.2759 - MinusLogProbMetric: 414.2759 - val_loss: 411.9691 - val_MinusLogProbMetric: 411.9691 - lr: 0.0010 - 18s/epoch - 92ms/step
Epoch 45/1000
2023-09-09 22:50:21.496 
Epoch 45/1000 
	 loss: 413.0276, MinusLogProbMetric: 413.0276, val_loss: 413.6190, val_MinusLogProbMetric: 413.6190

Epoch 45: val_loss did not improve from 411.96906
196/196 - 16s - loss: 413.0276 - MinusLogProbMetric: 413.0276 - val_loss: 413.6190 - val_MinusLogProbMetric: 413.6190 - lr: 0.0010 - 16s/epoch - 83ms/step
Epoch 46/1000
2023-09-09 22:50:39.170 
Epoch 46/1000 
	 loss: 412.9982, MinusLogProbMetric: 412.9982, val_loss: 411.5930, val_MinusLogProbMetric: 411.5930

Epoch 46: val_loss improved from 411.96906 to 411.59299, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 412.9982 - MinusLogProbMetric: 412.9982 - val_loss: 411.5930 - val_MinusLogProbMetric: 411.5930 - lr: 0.0010 - 18s/epoch - 92ms/step
Epoch 47/1000
2023-09-09 22:50:57.691 
Epoch 47/1000 
	 loss: 412.8598, MinusLogProbMetric: 412.8598, val_loss: 412.5634, val_MinusLogProbMetric: 412.5634

Epoch 47: val_loss did not improve from 411.59299
196/196 - 18s - loss: 412.8598 - MinusLogProbMetric: 412.8598 - val_loss: 412.5634 - val_MinusLogProbMetric: 412.5634 - lr: 0.0010 - 18s/epoch - 92ms/step
Epoch 48/1000
2023-09-09 22:51:14.005 
Epoch 48/1000 
	 loss: 414.3387, MinusLogProbMetric: 414.3387, val_loss: 414.7773, val_MinusLogProbMetric: 414.7773

Epoch 48: val_loss did not improve from 411.59299
196/196 - 16s - loss: 414.3387 - MinusLogProbMetric: 414.3387 - val_loss: 414.7773 - val_MinusLogProbMetric: 414.7773 - lr: 0.0010 - 16s/epoch - 83ms/step
Epoch 49/1000
2023-09-09 22:51:33.108 
Epoch 49/1000 
	 loss: 411.7737, MinusLogProbMetric: 411.7737, val_loss: 411.3663, val_MinusLogProbMetric: 411.3663

Epoch 49: val_loss improved from 411.59299 to 411.36630, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 20s - loss: 411.7737 - MinusLogProbMetric: 411.7737 - val_loss: 411.3663 - val_MinusLogProbMetric: 411.3663 - lr: 0.0010 - 20s/epoch - 100ms/step
Epoch 50/1000
2023-09-09 22:51:49.831 
Epoch 50/1000 
	 loss: 412.4089, MinusLogProbMetric: 412.4089, val_loss: 412.4404, val_MinusLogProbMetric: 412.4404

Epoch 50: val_loss did not improve from 411.36630
196/196 - 16s - loss: 412.4089 - MinusLogProbMetric: 412.4089 - val_loss: 412.4404 - val_MinusLogProbMetric: 412.4404 - lr: 0.0010 - 16s/epoch - 82ms/step
Epoch 51/1000
2023-09-09 22:52:05.914 
Epoch 51/1000 
	 loss: 412.1698, MinusLogProbMetric: 412.1698, val_loss: 415.6483, val_MinusLogProbMetric: 415.6483

Epoch 51: val_loss did not improve from 411.36630
196/196 - 16s - loss: 412.1698 - MinusLogProbMetric: 412.1698 - val_loss: 415.6483 - val_MinusLogProbMetric: 415.6483 - lr: 0.0010 - 16s/epoch - 82ms/step
Epoch 52/1000
2023-09-09 22:52:25.677 
Epoch 52/1000 
	 loss: 411.5898, MinusLogProbMetric: 411.5898, val_loss: 409.2848, val_MinusLogProbMetric: 409.2848

Epoch 52: val_loss improved from 411.36630 to 409.28476, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 20s - loss: 411.5898 - MinusLogProbMetric: 411.5898 - val_loss: 409.2848 - val_MinusLogProbMetric: 409.2848 - lr: 0.0010 - 20s/epoch - 104ms/step
Epoch 53/1000
2023-09-09 22:52:44.897 
Epoch 53/1000 
	 loss: 412.1805, MinusLogProbMetric: 412.1805, val_loss: 419.4226, val_MinusLogProbMetric: 419.4226

Epoch 53: val_loss did not improve from 409.28476
196/196 - 19s - loss: 412.1805 - MinusLogProbMetric: 412.1805 - val_loss: 419.4226 - val_MinusLogProbMetric: 419.4226 - lr: 0.0010 - 19s/epoch - 95ms/step
Epoch 54/1000
2023-09-09 22:53:02.333 
Epoch 54/1000 
	 loss: 411.4947, MinusLogProbMetric: 411.4947, val_loss: 413.1793, val_MinusLogProbMetric: 413.1793

Epoch 54: val_loss did not improve from 409.28476
196/196 - 17s - loss: 411.4947 - MinusLogProbMetric: 411.4947 - val_loss: 413.1793 - val_MinusLogProbMetric: 413.1793 - lr: 0.0010 - 17s/epoch - 89ms/step
Epoch 55/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 31: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-09 22:53:06.070 
Epoch 55/1000 
	 loss: nan, MinusLogProbMetric: 20981212248718432213577710436352.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 55: val_loss did not improve from 409.28476
196/196 - 4s - loss: nan - MinusLogProbMetric: 20981212248718432213577710436352.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 4s/epoch - 19ms/step
The loss history contains NaN values.
Training failed: trying again with seed 511595 and lr 0.0003333333333333333.
===========
Generating train data for run 327.
===========
Train data generated in 1.93 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_327/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_327/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.6836276 , -0.60898554,  4.901356  , ...,  4.578798  ,
         5.78743   ,  5.8673487 ],
       [ 8.249707  ,  4.460014  ,  5.2482004 , ...,  1.7374016 ,
         8.867281  ,  6.8796477 ],
       [ 6.103276  ,  7.069252  ,  6.2995415 , ..., 11.163949  ,
         2.6241696 ,  6.7860346 ],
       ...,
       [ 5.7729836 ,  0.39295188,  4.752078  , ...,  4.8545365 ,
         6.277194  ,  5.1011395 ],
       [ 8.14715   ,  4.7503    ,  5.215126  , ...,  3.7450724 ,
         8.238651  ,  6.647562  ],
       [ 5.6715584 ,  7.2547503 ,  6.700116  , ..., 10.850491  ,
         1.1671181 ,  6.458376  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_327/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_327
self.data_kwargs: {'seed': 187}
self.x_data: [[8.405046   4.6301365  5.2287283  ... 2.9590435  8.640119   7.4559712 ]
 [6.027003   0.2016806  4.6617384  ... 4.692235   6.373698   5.3374834 ]
 [5.680177   0.10050362 4.564641   ... 4.4050727  6.0966487  6.0310545 ]
 ...
 [6.204324   0.5308406  4.687448   ... 4.736321   6.117902   4.3074207 ]
 [7.884271   4.844002   5.2654357  ... 2.2312212  7.9686017  6.4498177 ]
 [5.7032723  1.704168   4.78966    ... 5.263417   6.7690263  5.8227935 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_12 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_1 (LogProbLa  (None,)                  4191520   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,191,520
Trainable params: 4,191,520
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_1/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_1'")
self.model: <keras.engine.functional.Functional object at 0x7f1db8e7f7c0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f1db8d96a40>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f1db8d96a40>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f1db8e7ece0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f1db8b44c10>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f1db8b450f0>, <keras.callbacks.ModelCheckpoint object at 0x7f1db8b451b0>, <keras.callbacks.EarlyStopping object at 0x7f1db8b45420>, <keras.callbacks.ReduceLROnPlateau object at 0x7f1db8b45450>, <keras.callbacks.TerminateOnNaN object at 0x7f1db8b45090>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.6836276 , -0.60898554,  4.901356  , ...,  4.578798  ,
         5.78743   ,  5.8673487 ],
       [ 8.249707  ,  4.460014  ,  5.2482004 , ...,  1.7374016 ,
         8.867281  ,  6.8796477 ],
       [ 6.103276  ,  7.069252  ,  6.2995415 , ..., 11.163949  ,
         2.6241696 ,  6.7860346 ],
       ...,
       [ 5.7729836 ,  0.39295188,  4.752078  , ...,  4.8545365 ,
         6.277194  ,  5.1011395 ],
       [ 8.14715   ,  4.7503    ,  5.215126  , ...,  3.7450724 ,
         8.238651  ,  6.647562  ],
       [ 5.6715584 ,  7.2547503 ,  6.700116  , ..., 10.850491  ,
         1.1671181 ,  6.458376  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 327/360 with hyperparameters:
timestamp = 2023-09-09 22:53:14.085226
ndims = 1000
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 4191520
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 8.405046    4.6301365   5.2287283   2.4556472   6.2928953   3.594312
  6.0004463   1.8052834   1.8765529   4.0951214   4.4015846   3.3011546
  1.1913271   0.29790348  0.444705    2.0839415   4.8839054   7.6232376
  5.0511703  10.082624    1.0256902   1.8862149   3.3338983   5.485959
  8.678817    4.2863455   2.746828    0.5995625   8.487818    4.326282
  5.4844646   9.668893    0.9005003   2.511495    7.4595304   8.076063
  7.482936    5.8244066  10.038453    4.2971616   6.199124    0.14504078
  4.115744    7.085761    2.2268302   8.105376    6.8798943   3.1965656
  7.803503    1.4473212   9.836955    1.2955343   9.292721    2.2835047
  7.347313   -0.344647    2.3793294   7.1599417   6.239404    1.8819436
  3.6855946   3.1096044   3.9889503   6.345884    8.7655735   3.506798
  3.8915956   1.4826899   7.7798705   6.4561133   3.7245452   5.022784
  6.785575    1.8807405  -0.53786993  3.331518    6.3648286   5.060461
  5.671335    8.188019    5.050044    0.8326328   9.021144    5.101296
  8.440869    7.8830547   9.847927    2.9928007   7.1174664   4.000934
  4.0642667   3.5513847   3.3835356   9.485252    2.8910272   2.857944
  5.1031704   2.365148    4.392073    7.9044094   2.2182727   3.5326295
  6.429046    5.444268    9.853491    6.801449    7.615357    9.654012
  4.2561636   3.94246     0.5266583   1.6963573   0.9076003   1.6972958
  8.415306    6.55893     6.517854    7.7323823   2.263416    3.867008
  7.0743175   4.310728    0.44073427  5.454958    8.770797    4.023472
  3.8313503   9.876201    6.083322    4.588916    0.97578037  8.022623
  6.904659    9.723064    1.5232677   1.2301477   7.2426834   2.4050941
  1.7633336   1.3129089   8.420942    5.7998257   0.4667193   4.692241
  6.5908155   5.257252    5.725936    2.6134639   8.439922    5.6147094
  7.455604    9.777677    4.190657    9.502805    0.30458957  0.2189286
  5.797137    3.0544481   2.6193647   2.5525932   3.284805    7.4161353
  5.749028    7.889573    7.898816    8.574444    3.8091307   4.298687
  9.481366    6.0068207   1.523428    5.6352916   4.365734    9.867473
  1.3835607   6.134872    7.2581935   2.8856063   9.735012    7.5791473
  9.23718     0.3085858   6.8750105   3.0606773   9.2376585   6.005112
  5.5536275   0.9032261   6.0153728   6.3190417   9.369196    5.911083
  9.520276   10.025198    7.444127    4.7846828   6.6327243  10.038699
  0.737067    1.1364235   0.7629767   7.3339915   3.2413385   6.3641744
  4.723883    3.890898    5.1846333   6.4865723   9.4478655   5.8353424
  6.1596503   0.8805034  10.229148    5.1357536   8.719589    0.61422366
  4.6646357   2.5584815   2.6442034   7.3017416   5.692237    3.2181895
  0.7464954   9.628433    9.805298    0.8460964   0.74706554  6.1736875
  9.794054    9.817206    5.73489     2.8118153   2.995823    9.004283
  3.2283762   1.9297047   2.5467188   2.732583    2.62711     5.3906684
  8.859532    7.221753    0.22360349  0.31767347  3.3918247   3.5905416
  8.748679    9.150864    4.0089087   6.819023    9.95121     7.2592616
  6.618907    0.7986359   3.617743    8.477222    2.5446649   8.356348
  6.784008    2.7764812   5.149644    5.879593    6.8204975   4.7749815
  1.5671438   7.5464864   2.9128666   9.640756    2.7195537   2.422054
  1.9658555   5.744532   10.17906     1.88257     3.3741965   5.759674
  4.4506254   5.799042    8.574516    9.521442    4.848262    7.099014
  7.410928    4.176586    2.7669337   6.7037125   6.396343    9.116149
  0.6767711   8.802082    5.400854   -0.46128303  4.315248    7.679634
  4.337188    9.473796    4.3057194   3.8800864   8.321836    5.464394
  6.8586717   7.8846817   6.758233    4.5121193   1.5240693   5.1997232
  7.966815    3.110014    9.149139    5.2918534   6.043538    8.5325165
  7.029521    0.71871924  9.851924    2.0979629   7.107039    5.8480177
  4.6838837   2.2520099   7.556054    1.2082794  10.557993    8.230412
  5.3685956   3.7290514   3.748278    4.2430515   8.3245535   2.619837
  3.433112    1.6606942   2.8829854   1.0669343   9.924688    5.8388543
  6.973813    0.9312429   3.8876076   8.887293    0.8722724   2.881507
  6.283689    6.159739    8.345073    9.115302    1.4750379   2.7552269
  4.2736816   0.15881406 -0.24159682  2.4190745   4.887695    2.6831913
  8.220071    3.2441287   8.8378105   9.509058    3.559123    3.1608875
  3.3725164   7.9289885   2.9474692   4.059424    4.7409554   5.2013454
  9.994335    2.323355    3.3355927   2.5336983   3.2941818   2.2210457
  3.2414346   9.904477    2.334639    4.492616   10.475705    7.142849
  4.6010633   7.570345    1.3164223   4.2845144   0.5250243   2.3362412
  2.8345227   3.6286557   4.130509    9.905742    2.1830826   4.842215
  6.807653    7.5327077   7.2363663   2.9334166   5.234727    1.7384282
  2.0550947   4.500183    7.394765    4.995599    7.815772   10.710524
 -0.19277403  5.792584    6.1900487   9.671367    0.28583023  5.668808
  1.2390957   0.5417446   6.8533115   7.9632573   8.180385   -0.4858576
  4.0685763   2.4839914   2.1516795   1.9025909   2.110797    2.6641178
  2.6061893   9.366816    4.2622356   8.9237175   1.1875978   7.9966984
  0.44503674  4.7554154  -0.20823273  7.945292   10.080656    0.3404049
  8.932869    8.365952    3.7764497   9.093311    2.3442857   4.1149993
  0.99684995  6.8027267   0.3532521   4.712874    6.197236    8.98079
  0.7532523   7.324172    6.816783    7.1629744   5.789584    1.8008664
  6.6962724   3.5133753   8.672127    1.7033234   5.757915    3.8499484
  7.6907835   2.515215    0.675339    6.6755958   4.1274943   5.9000664
  0.6306852  10.170123    8.690909    5.6241055   0.83715045  3.7537289
  9.811078    7.1486425   1.5089558   4.5211      9.977777    5.041157
  0.20099962  7.1491528   2.411008    0.98729235  4.0264      6.1107965
  0.8201466   6.400518    5.2138658   8.338983    4.008616    5.4276114
  7.5568547   9.328188    3.5043116   5.993576    6.732445    0.1456024
  8.195436    4.0946035   6.8117595   5.4540176   7.008695    7.6902666
  1.121738    6.662947    9.421039    3.6054578   8.282917    6.2551546
  8.867136    2.7717266   1.666508    1.9828001   2.582295    7.401628
  7.3309445   6.1640267   2.2886527   8.620049    9.976319    5.427213
  6.492129    5.227495    2.6098144   3.1037233   2.451418    1.547883
  9.130067    9.089639    3.8307672   2.809064    9.412396    3.0656943
  5.384379    1.269433    2.1198947   5.4160995   5.9553137   6.8595047
  8.024387    9.932428    7.275275    5.4964776   9.2686615  -0.8320414
  6.634356    3.5646963   1.6928086   9.683453    3.4941626   6.2850795
  8.140037    5.0819607   1.6098254   8.515681    3.746112   10.339378
  9.723754    8.560821    3.4616127   8.136909    8.474316    5.334234
  4.3071146   0.3017891   7.5740643   8.525242    1.961537    2.785501
  4.6199455   0.20740837  0.8326539   4.594327    2.569767    3.3214014
  4.017394    9.219309   10.736801    1.9790065   8.832557    0.9678319
  5.233325   -0.19063437  3.1312854   8.050418    4.191532    9.204013
  7.268445    9.203028    4.342827    8.019755    3.3341756   3.743745
  3.9635062   3.979517    0.6836107   5.098467    0.71361184  8.4552765
  0.5069707   4.833144    3.1548538   1.8944778   7.8488803   7.0419393
  1.2548511   6.628743    7.354838    8.050705    1.1345416   6.8048496
  6.528121    8.252401    4.5538      4.949585    8.730731    7.4312305
  5.643753    2.5072966   8.962284    4.0641007   0.7590125   5.4753785
  9.738958    4.561652   -0.360509    6.1097317   9.957747    7.0762954
  5.690881    8.773466    8.0799      5.2899666   6.263382    7.4875503
  8.585341    0.6384524   8.029185    4.3010435   6.264173    7.7155027
  5.2268887   1.5704446   4.016696    0.5981313   6.7822347   9.855953
  7.53499     5.1501827   5.5134096   2.8642232   5.220349    3.4915414
  4.7451196   2.6037292   9.620164    6.549827    0.7027252  -0.15775523
 10.00958     3.973167    3.273789    1.7160401   9.183787    7.1865473
  5.1355295   4.8474526   3.5554662   6.6154428   4.344493    2.1984468
  5.4696417   4.251729    8.8025255   4.26232     4.9216294   7.9483533
  4.526991    9.588897    8.017048    8.2831135   9.821576    4.1731563
  5.8485947   6.667628    7.001741    9.226937    2.9446237   2.5925434
  8.618449    8.161273    1.7101693   5.5401206   8.14539     2.020844
  0.89211583  5.7496552   4.987388    7.4813085   0.39198843  4.8122907
  2.6751356   5.1997175   7.827039    0.7617685   1.984582    6.211319
  7.497485    5.6864862   9.833999    4.343862    0.91428226  6.860134
  8.022065    5.7952833   5.549028    8.938169    0.7987054   1.0077511
  1.547055    2.4538176   5.900641    5.950689    2.172312    4.864265
  5.3084598   2.74433     7.4509587   4.642633    7.352649    1.6610278
  5.3932858   8.224104    1.7825346   4.6216807   6.3162665   2.1527483
  7.82622     0.4708147   9.143722    4.7161274   2.9691823   0.9679443
  3.9266372   6.638867    0.10056549  3.118843    7.3452816   6.4795094
  2.0939577   2.478408    8.811012    3.114293    2.1261327  10.111931
  4.855735    1.2398901   5.2605786   5.4892864   9.44359     1.744517
  0.8859111   0.84614795  8.730755    4.4898634   1.9797392   5.9254265
  5.903251    2.0259151   7.1823764   4.0827475   2.3360302   5.4425554
  3.0566494   1.579066    8.333391    1.4978724   3.288137    3.852397
  2.935655    2.1213212   6.9459066   3.5336087   1.8826928   5.0965667
  1.2400447   4.7354097   8.616984    2.6134915   5.8834224   5.1864443
 -0.13750565  6.549661    8.984314    0.7847537   7.2001395   6.8008256
  8.44678     2.6799302   3.2838757   7.0237226  -0.23040357  7.540698
  8.530038    4.6869135   3.2353654   3.3326626  -2.8252068   1.808005
  8.638641    9.090046    2.7026813   9.352778    3.2715847   2.764985
  2.5781574   8.643513    9.775191    3.6196568   6.3544054   2.67319
 -0.27903366  3.0261974   5.7475586   1.8039718   8.191788    4.8235297
  2.4119723   4.80837     7.8066583   3.14657     7.254359    3.8570547
  8.983632    8.136105    3.6973224   0.29414394  6.2837157   1.7246333
  1.2347451   8.727795    9.613968    2.8966768   3.0174162   1.6892313
  4.788908    8.051952    6.6716456   8.591153    1.2762189   7.83716
 10.090976    2.9488695   6.9059463   3.4287705   2.638495    9.951833
  3.8517146   1.0833437   3.8833115   4.4572515   7.453829    9.261691
 10.299599    8.9711075   4.912658    7.687476    2.8381176   0.8803614
  3.6029894   7.0204277   3.0225866   9.093265    9.016605    1.5790088
  2.4555895   8.069907    3.3349042   3.3253474   3.304729    8.906204
  0.14018849 -0.09102672  5.6968327   2.8784204   6.3043637   1.5840611
  9.080589    7.872192    0.68985736  8.022463    9.62591     9.730082
  6.885892    1.2239211   6.788951    3.103189    8.581392    7.224449
  6.0487485   6.9063663   4.2010665   4.5798826   9.059492    3.4417286
  0.25157684  4.0677304   8.905279    6.148643   11.682095    0.95629424
  9.730315    5.5144877   4.490063    4.5312085   1.2480376   3.6158848
  7.4273086  -0.96325046  1.452391    0.25324896  8.457037    6.1265316
  1.3514678   8.127087   10.009373    9.350058    8.951299   -0.29766494
  6.0847034   2.4157875   5.6192784   2.8229573   0.7195138   4.5521054
  4.8054247   9.962674    0.39720708  3.1612184   8.577424    7.115589
  7.7674336   6.298065    7.663883    4.695144    1.1639674   7.7367616
  5.669413    1.2667739   7.7379103   9.650189    3.731491    3.391371
  0.73656756  6.0238733   9.167239    1.2704167   4.995278    0.9358564
  0.38653633  6.6325297   8.341552    3.6262543   7.874937    2.0914352
  2.2575343   7.0230904   4.9926057   4.8522496   0.38922572  1.2943935
  0.4778885   8.9588175   1.688771    8.19581     3.4283693   8.456239
  2.8242724   2.5323164   0.56487453  2.687169    3.4400296   8.293358
  4.435119    8.654662    5.423925   -0.7138738   3.3961737   6.6198845
  2.3316503   8.031245    4.494654    0.59436065  7.459087    5.8713436
  0.84994775  5.0717716   3.7515552   9.185751    2.3369966   9.342911
  5.7315216   2.9590435   8.640119    7.4559712 ]
Epoch 1/1000
2023-09-09 22:54:36.451 
Epoch 1/1000 
	 loss: 448.7476, MinusLogProbMetric: 448.7476, val_loss: 404.9501, val_MinusLogProbMetric: 404.9501

Epoch 1: val_loss improved from inf to 404.95013, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 82s - loss: 448.7476 - MinusLogProbMetric: 448.7476 - val_loss: 404.9501 - val_MinusLogProbMetric: 404.9501 - lr: 3.3333e-04 - 82s/epoch - 419ms/step
Epoch 2/1000
2023-09-09 22:54:53.889 
Epoch 2/1000 
	 loss: 403.0348, MinusLogProbMetric: 403.0348, val_loss: 406.6615, val_MinusLogProbMetric: 406.6615

Epoch 2: val_loss did not improve from 404.95013
196/196 - 17s - loss: 403.0348 - MinusLogProbMetric: 403.0348 - val_loss: 406.6615 - val_MinusLogProbMetric: 406.6615 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 3/1000
2023-09-09 22:55:09.453 
Epoch 3/1000 
	 loss: 402.6362, MinusLogProbMetric: 402.6362, val_loss: 405.4231, val_MinusLogProbMetric: 405.4231

Epoch 3: val_loss did not improve from 404.95013
196/196 - 16s - loss: 402.6362 - MinusLogProbMetric: 402.6362 - val_loss: 405.4231 - val_MinusLogProbMetric: 405.4231 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 4/1000
2023-09-09 22:55:24.751 
Epoch 4/1000 
	 loss: 403.0583, MinusLogProbMetric: 403.0583, val_loss: 404.5650, val_MinusLogProbMetric: 404.5650

Epoch 4: val_loss improved from 404.95013 to 404.56500, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 16s - loss: 403.0583 - MinusLogProbMetric: 403.0583 - val_loss: 404.5650 - val_MinusLogProbMetric: 404.5650 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 5/1000
2023-09-09 22:55:41.213 
Epoch 5/1000 
	 loss: 402.6376, MinusLogProbMetric: 402.6376, val_loss: 404.7298, val_MinusLogProbMetric: 404.7298

Epoch 5: val_loss did not improve from 404.56500
196/196 - 16s - loss: 402.6376 - MinusLogProbMetric: 402.6376 - val_loss: 404.7298 - val_MinusLogProbMetric: 404.7298 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 6/1000
2023-09-09 22:55:56.098 
Epoch 6/1000 
	 loss: 403.2539, MinusLogProbMetric: 403.2539, val_loss: 402.3156, val_MinusLogProbMetric: 402.3156

Epoch 6: val_loss improved from 404.56500 to 402.31561, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 15s - loss: 403.2539 - MinusLogProbMetric: 403.2539 - val_loss: 402.3156 - val_MinusLogProbMetric: 402.3156 - lr: 3.3333e-04 - 15s/epoch - 78ms/step
Epoch 7/1000
2023-09-09 22:56:11.472 
Epoch 7/1000 
	 loss: 403.2538, MinusLogProbMetric: 403.2538, val_loss: 403.1805, val_MinusLogProbMetric: 403.1805

Epoch 7: val_loss did not improve from 402.31561
196/196 - 15s - loss: 403.2538 - MinusLogProbMetric: 403.2538 - val_loss: 403.1805 - val_MinusLogProbMetric: 403.1805 - lr: 3.3333e-04 - 15s/epoch - 76ms/step
Epoch 8/1000
2023-09-09 22:56:27.047 
Epoch 8/1000 
	 loss: 402.4484, MinusLogProbMetric: 402.4484, val_loss: 405.7745, val_MinusLogProbMetric: 405.7745

Epoch 8: val_loss did not improve from 402.31561
196/196 - 16s - loss: 402.4484 - MinusLogProbMetric: 402.4484 - val_loss: 405.7745 - val_MinusLogProbMetric: 405.7745 - lr: 3.3333e-04 - 16s/epoch - 79ms/step
Epoch 9/1000
2023-09-09 22:56:41.806 
Epoch 9/1000 
	 loss: 403.6259, MinusLogProbMetric: 403.6259, val_loss: 432.6534, val_MinusLogProbMetric: 432.6534

Epoch 9: val_loss did not improve from 402.31561
196/196 - 15s - loss: 403.6259 - MinusLogProbMetric: 403.6259 - val_loss: 432.6534 - val_MinusLogProbMetric: 432.6534 - lr: 3.3333e-04 - 15s/epoch - 75ms/step
Epoch 10/1000
2023-09-09 22:56:58.038 
Epoch 10/1000 
	 loss: 402.7654, MinusLogProbMetric: 402.7654, val_loss: 403.0284, val_MinusLogProbMetric: 403.0284

Epoch 10: val_loss did not improve from 402.31561
196/196 - 16s - loss: 402.7654 - MinusLogProbMetric: 402.7654 - val_loss: 403.0284 - val_MinusLogProbMetric: 403.0284 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 11/1000
2023-09-09 22:57:12.624 
Epoch 11/1000 
	 loss: 402.5245, MinusLogProbMetric: 402.5245, val_loss: 402.7810, val_MinusLogProbMetric: 402.7810

Epoch 11: val_loss did not improve from 402.31561
196/196 - 15s - loss: 402.5245 - MinusLogProbMetric: 402.5245 - val_loss: 402.7810 - val_MinusLogProbMetric: 402.7810 - lr: 3.3333e-04 - 15s/epoch - 74ms/step
Epoch 12/1000
2023-09-09 22:57:28.704 
Epoch 12/1000 
	 loss: 401.5619, MinusLogProbMetric: 401.5619, val_loss: 402.6234, val_MinusLogProbMetric: 402.6234

Epoch 12: val_loss did not improve from 402.31561
196/196 - 16s - loss: 401.5619 - MinusLogProbMetric: 401.5619 - val_loss: 402.6234 - val_MinusLogProbMetric: 402.6234 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 13/1000
2023-09-09 22:57:45.682 
Epoch 13/1000 
	 loss: 401.4920, MinusLogProbMetric: 401.4920, val_loss: 401.9018, val_MinusLogProbMetric: 401.9018

Epoch 13: val_loss improved from 402.31561 to 401.90179, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 401.4920 - MinusLogProbMetric: 401.4920 - val_loss: 401.9018 - val_MinusLogProbMetric: 401.9018 - lr: 3.3333e-04 - 18s/epoch - 89ms/step
Epoch 14/1000
2023-09-09 22:58:04.203 
Epoch 14/1000 
	 loss: 401.4879, MinusLogProbMetric: 401.4879, val_loss: 402.2856, val_MinusLogProbMetric: 402.2856

Epoch 14: val_loss did not improve from 401.90179
196/196 - 18s - loss: 401.4879 - MinusLogProbMetric: 401.4879 - val_loss: 402.2856 - val_MinusLogProbMetric: 402.2856 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 15/1000
2023-09-09 22:58:20.110 
Epoch 15/1000 
	 loss: 401.4551, MinusLogProbMetric: 401.4551, val_loss: 402.4982, val_MinusLogProbMetric: 402.4982

Epoch 15: val_loss did not improve from 401.90179
196/196 - 16s - loss: 401.4551 - MinusLogProbMetric: 401.4551 - val_loss: 402.4982 - val_MinusLogProbMetric: 402.4982 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 16/1000
2023-09-09 22:58:37.129 
Epoch 16/1000 
	 loss: 400.7111, MinusLogProbMetric: 400.7111, val_loss: 401.2743, val_MinusLogProbMetric: 401.2743

Epoch 16: val_loss improved from 401.90179 to 401.27432, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 400.7111 - MinusLogProbMetric: 400.7111 - val_loss: 401.2743 - val_MinusLogProbMetric: 401.2743 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 17/1000
2023-09-09 22:58:54.679 
Epoch 17/1000 
	 loss: 401.1118, MinusLogProbMetric: 401.1118, val_loss: 405.5840, val_MinusLogProbMetric: 405.5840

Epoch 17: val_loss did not improve from 401.27432
196/196 - 17s - loss: 401.1118 - MinusLogProbMetric: 401.1118 - val_loss: 405.5840 - val_MinusLogProbMetric: 405.5840 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 18/1000
2023-09-09 22:59:10.099 
Epoch 18/1000 
	 loss: 400.8293, MinusLogProbMetric: 400.8293, val_loss: 404.0195, val_MinusLogProbMetric: 404.0195

Epoch 18: val_loss did not improve from 401.27432
196/196 - 15s - loss: 400.8293 - MinusLogProbMetric: 400.8293 - val_loss: 404.0195 - val_MinusLogProbMetric: 404.0195 - lr: 3.3333e-04 - 15s/epoch - 79ms/step
Epoch 19/1000
2023-09-09 22:59:26.432 
Epoch 19/1000 
	 loss: 400.7993, MinusLogProbMetric: 400.7993, val_loss: 402.3495, val_MinusLogProbMetric: 402.3495

Epoch 19: val_loss did not improve from 401.27432
196/196 - 16s - loss: 400.7993 - MinusLogProbMetric: 400.7993 - val_loss: 402.3495 - val_MinusLogProbMetric: 402.3495 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 20/1000
2023-09-09 22:59:43.577 
Epoch 20/1000 
	 loss: 400.4590, MinusLogProbMetric: 400.4590, val_loss: 402.5419, val_MinusLogProbMetric: 402.5419

Epoch 20: val_loss did not improve from 401.27432
196/196 - 17s - loss: 400.4590 - MinusLogProbMetric: 400.4590 - val_loss: 402.5419 - val_MinusLogProbMetric: 402.5419 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 21/1000
2023-09-09 23:00:02.493 
Epoch 21/1000 
	 loss: 400.3989, MinusLogProbMetric: 400.3989, val_loss: 410.2680, val_MinusLogProbMetric: 410.2680

Epoch 21: val_loss did not improve from 401.27432
196/196 - 19s - loss: 400.3989 - MinusLogProbMetric: 400.3989 - val_loss: 410.2680 - val_MinusLogProbMetric: 410.2680 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 22/1000
2023-09-09 23:00:20.801 
Epoch 22/1000 
	 loss: 400.4409, MinusLogProbMetric: 400.4409, val_loss: 402.0657, val_MinusLogProbMetric: 402.0657

Epoch 22: val_loss did not improve from 401.27432
196/196 - 18s - loss: 400.4409 - MinusLogProbMetric: 400.4409 - val_loss: 402.0657 - val_MinusLogProbMetric: 402.0657 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 23/1000
2023-09-09 23:00:38.858 
Epoch 23/1000 
	 loss: 400.9960, MinusLogProbMetric: 400.9960, val_loss: 402.8380, val_MinusLogProbMetric: 402.8380

Epoch 23: val_loss did not improve from 401.27432
196/196 - 18s - loss: 400.9960 - MinusLogProbMetric: 400.9960 - val_loss: 402.8380 - val_MinusLogProbMetric: 402.8380 - lr: 3.3333e-04 - 18s/epoch - 92ms/step
Epoch 24/1000
2023-09-09 23:00:56.101 
Epoch 24/1000 
	 loss: 399.6025, MinusLogProbMetric: 399.6025, val_loss: 400.5467, val_MinusLogProbMetric: 400.5467

Epoch 24: val_loss improved from 401.27432 to 400.54672, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 18s - loss: 399.6025 - MinusLogProbMetric: 399.6025 - val_loss: 400.5467 - val_MinusLogProbMetric: 400.5467 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 25/1000
2023-09-09 23:01:17.574 
Epoch 25/1000 
	 loss: 400.3769, MinusLogProbMetric: 400.3769, val_loss: 401.0223, val_MinusLogProbMetric: 401.0223

Epoch 25: val_loss did not improve from 400.54672
196/196 - 21s - loss: 400.3769 - MinusLogProbMetric: 400.3769 - val_loss: 401.0223 - val_MinusLogProbMetric: 401.0223 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 26/1000
2023-09-09 23:01:35.329 
Epoch 26/1000 
	 loss: 399.7007, MinusLogProbMetric: 399.7007, val_loss: 404.9055, val_MinusLogProbMetric: 404.9055

Epoch 26: val_loss did not improve from 400.54672
196/196 - 18s - loss: 399.7007 - MinusLogProbMetric: 399.7007 - val_loss: 404.9055 - val_MinusLogProbMetric: 404.9055 - lr: 3.3333e-04 - 18s/epoch - 91ms/step
Epoch 27/1000
2023-09-09 23:01:53.513 
Epoch 27/1000 
	 loss: 399.8087, MinusLogProbMetric: 399.8087, val_loss: 400.8314, val_MinusLogProbMetric: 400.8314

Epoch 27: val_loss did not improve from 400.54672
196/196 - 18s - loss: 399.8087 - MinusLogProbMetric: 399.8087 - val_loss: 400.8314 - val_MinusLogProbMetric: 400.8314 - lr: 3.3333e-04 - 18s/epoch - 93ms/step
Epoch 28/1000
2023-09-09 23:02:12.611 
Epoch 28/1000 
	 loss: 399.7650, MinusLogProbMetric: 399.7650, val_loss: 409.3738, val_MinusLogProbMetric: 409.3738

Epoch 28: val_loss did not improve from 400.54672
196/196 - 19s - loss: 399.7650 - MinusLogProbMetric: 399.7650 - val_loss: 409.3738 - val_MinusLogProbMetric: 409.3738 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 29/1000
2023-09-09 23:02:31.648 
Epoch 29/1000 
	 loss: 399.8571, MinusLogProbMetric: 399.8571, val_loss: 400.8199, val_MinusLogProbMetric: 400.8199

Epoch 29: val_loss did not improve from 400.54672
196/196 - 19s - loss: 399.8571 - MinusLogProbMetric: 399.8571 - val_loss: 400.8199 - val_MinusLogProbMetric: 400.8199 - lr: 3.3333e-04 - 19s/epoch - 97ms/step
Epoch 30/1000
2023-09-09 23:02:52.712 
Epoch 30/1000 
	 loss: 399.1276, MinusLogProbMetric: 399.1276, val_loss: 400.6417, val_MinusLogProbMetric: 400.6417

Epoch 30: val_loss did not improve from 400.54672
196/196 - 21s - loss: 399.1276 - MinusLogProbMetric: 399.1276 - val_loss: 400.6417 - val_MinusLogProbMetric: 400.6417 - lr: 3.3333e-04 - 21s/epoch - 107ms/step
Epoch 31/1000
2023-09-09 23:03:13.899 
Epoch 31/1000 
	 loss: 399.0492, MinusLogProbMetric: 399.0492, val_loss: 401.6347, val_MinusLogProbMetric: 401.6347

Epoch 31: val_loss did not improve from 400.54672
196/196 - 21s - loss: 399.0492 - MinusLogProbMetric: 399.0492 - val_loss: 401.6347 - val_MinusLogProbMetric: 401.6347 - lr: 3.3333e-04 - 21s/epoch - 108ms/step
Epoch 32/1000
2023-09-09 23:03:34.709 
Epoch 32/1000 
	 loss: 399.1979, MinusLogProbMetric: 399.1979, val_loss: 399.5390, val_MinusLogProbMetric: 399.5390

Epoch 32: val_loss improved from 400.54672 to 399.53903, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 22s - loss: 399.1979 - MinusLogProbMetric: 399.1979 - val_loss: 399.5390 - val_MinusLogProbMetric: 399.5390 - lr: 3.3333e-04 - 22s/epoch - 110ms/step
Epoch 33/1000
2023-09-09 23:03:56.458 
Epoch 33/1000 
	 loss: 399.0924, MinusLogProbMetric: 399.0924, val_loss: 400.5443, val_MinusLogProbMetric: 400.5443

Epoch 33: val_loss did not improve from 399.53903
196/196 - 21s - loss: 399.0924 - MinusLogProbMetric: 399.0924 - val_loss: 400.5443 - val_MinusLogProbMetric: 400.5443 - lr: 3.3333e-04 - 21s/epoch - 107ms/step
Epoch 34/1000
2023-09-09 23:04:17.317 
Epoch 34/1000 
	 loss: 399.1120, MinusLogProbMetric: 399.1120, val_loss: 402.9049, val_MinusLogProbMetric: 402.9049

Epoch 34: val_loss did not improve from 399.53903
196/196 - 21s - loss: 399.1120 - MinusLogProbMetric: 399.1120 - val_loss: 402.9049 - val_MinusLogProbMetric: 402.9049 - lr: 3.3333e-04 - 21s/epoch - 106ms/step
Epoch 35/1000
2023-09-09 23:04:37.990 
Epoch 35/1000 
	 loss: 400.2103, MinusLogProbMetric: 400.2103, val_loss: 402.4068, val_MinusLogProbMetric: 402.4068

Epoch 35: val_loss did not improve from 399.53903
196/196 - 21s - loss: 400.2103 - MinusLogProbMetric: 400.2103 - val_loss: 402.4068 - val_MinusLogProbMetric: 402.4068 - lr: 3.3333e-04 - 21s/epoch - 105ms/step
Epoch 36/1000
2023-09-09 23:04:59.653 
Epoch 36/1000 
	 loss: 399.2585, MinusLogProbMetric: 399.2585, val_loss: 403.3048, val_MinusLogProbMetric: 403.3048

Epoch 36: val_loss did not improve from 399.53903
196/196 - 22s - loss: 399.2585 - MinusLogProbMetric: 399.2585 - val_loss: 403.3048 - val_MinusLogProbMetric: 403.3048 - lr: 3.3333e-04 - 22s/epoch - 111ms/step
Epoch 37/1000
2023-09-09 23:05:19.169 
Epoch 37/1000 
	 loss: 398.1129, MinusLogProbMetric: 398.1129, val_loss: 402.4690, val_MinusLogProbMetric: 402.4690

Epoch 37: val_loss did not improve from 399.53903
196/196 - 20s - loss: 398.1129 - MinusLogProbMetric: 398.1129 - val_loss: 402.4690 - val_MinusLogProbMetric: 402.4690 - lr: 3.3333e-04 - 20s/epoch - 100ms/step
Epoch 38/1000
2023-09-09 23:05:36.585 
Epoch 38/1000 
	 loss: 399.1031, MinusLogProbMetric: 399.1031, val_loss: 399.7141, val_MinusLogProbMetric: 399.7141

Epoch 38: val_loss did not improve from 399.53903
196/196 - 17s - loss: 399.1031 - MinusLogProbMetric: 399.1031 - val_loss: 399.7141 - val_MinusLogProbMetric: 399.7141 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 39/1000
2023-09-09 23:05:53.623 
Epoch 39/1000 
	 loss: 398.9678, MinusLogProbMetric: 398.9678, val_loss: 401.0766, val_MinusLogProbMetric: 401.0766

Epoch 39: val_loss did not improve from 399.53903
196/196 - 17s - loss: 398.9678 - MinusLogProbMetric: 398.9678 - val_loss: 401.0766 - val_MinusLogProbMetric: 401.0766 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 40/1000
2023-09-09 23:06:10.736 
Epoch 40/1000 
	 loss: 398.1353, MinusLogProbMetric: 398.1353, val_loss: 401.0778, val_MinusLogProbMetric: 401.0778

Epoch 40: val_loss did not improve from 399.53903
196/196 - 17s - loss: 398.1353 - MinusLogProbMetric: 398.1353 - val_loss: 401.0778 - val_MinusLogProbMetric: 401.0778 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 41/1000
2023-09-09 23:06:27.883 
Epoch 41/1000 
	 loss: 399.6402, MinusLogProbMetric: 399.6402, val_loss: 400.4146, val_MinusLogProbMetric: 400.4146

Epoch 41: val_loss did not improve from 399.53903
196/196 - 17s - loss: 399.6402 - MinusLogProbMetric: 399.6402 - val_loss: 400.4146 - val_MinusLogProbMetric: 400.4146 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 42/1000
2023-09-09 23:06:45.126 
Epoch 42/1000 
	 loss: 398.5506, MinusLogProbMetric: 398.5506, val_loss: 400.1771, val_MinusLogProbMetric: 400.1771

Epoch 42: val_loss did not improve from 399.53903
196/196 - 17s - loss: 398.5506 - MinusLogProbMetric: 398.5506 - val_loss: 400.1771 - val_MinusLogProbMetric: 400.1771 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 43/1000
2023-09-09 23:07:02.295 
Epoch 43/1000 
	 loss: 398.5127, MinusLogProbMetric: 398.5127, val_loss: 402.5141, val_MinusLogProbMetric: 402.5141

Epoch 43: val_loss did not improve from 399.53903
196/196 - 17s - loss: 398.5127 - MinusLogProbMetric: 398.5127 - val_loss: 402.5141 - val_MinusLogProbMetric: 402.5141 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 44/1000
2023-09-09 23:07:19.229 
Epoch 44/1000 
	 loss: 398.0537, MinusLogProbMetric: 398.0537, val_loss: 404.6807, val_MinusLogProbMetric: 404.6807

Epoch 44: val_loss did not improve from 399.53903
196/196 - 17s - loss: 398.0537 - MinusLogProbMetric: 398.0537 - val_loss: 404.6807 - val_MinusLogProbMetric: 404.6807 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 45/1000
2023-09-09 23:07:36.632 
Epoch 45/1000 
	 loss: 398.6286, MinusLogProbMetric: 398.6286, val_loss: 400.5925, val_MinusLogProbMetric: 400.5925

Epoch 45: val_loss did not improve from 399.53903
196/196 - 17s - loss: 398.6286 - MinusLogProbMetric: 398.6286 - val_loss: 400.5925 - val_MinusLogProbMetric: 400.5925 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 46/1000
2023-09-09 23:07:53.232 
Epoch 46/1000 
	 loss: 397.7482, MinusLogProbMetric: 397.7482, val_loss: 400.8511, val_MinusLogProbMetric: 400.8511

Epoch 46: val_loss did not improve from 399.53903
196/196 - 17s - loss: 397.7482 - MinusLogProbMetric: 397.7482 - val_loss: 400.8511 - val_MinusLogProbMetric: 400.8511 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 47/1000
2023-09-09 23:08:10.359 
Epoch 47/1000 
	 loss: 397.8821, MinusLogProbMetric: 397.8821, val_loss: 403.6144, val_MinusLogProbMetric: 403.6144

Epoch 47: val_loss did not improve from 399.53903
196/196 - 17s - loss: 397.8821 - MinusLogProbMetric: 397.8821 - val_loss: 403.6144 - val_MinusLogProbMetric: 403.6144 - lr: 3.3333e-04 - 17s/epoch - 87ms/step
Epoch 48/1000
2023-09-09 23:08:26.890 
Epoch 48/1000 
	 loss: 398.3566, MinusLogProbMetric: 398.3566, val_loss: 402.5914, val_MinusLogProbMetric: 402.5914

Epoch 48: val_loss did not improve from 399.53903
196/196 - 17s - loss: 398.3566 - MinusLogProbMetric: 398.3566 - val_loss: 402.5914 - val_MinusLogProbMetric: 402.5914 - lr: 3.3333e-04 - 17s/epoch - 84ms/step
Epoch 49/1000
2023-09-09 23:08:43.621 
Epoch 49/1000 
	 loss: 397.5661, MinusLogProbMetric: 397.5661, val_loss: 398.8999, val_MinusLogProbMetric: 398.8999

Epoch 49: val_loss improved from 399.53903 to 398.89993, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 17s - loss: 397.5661 - MinusLogProbMetric: 397.5661 - val_loss: 398.8999 - val_MinusLogProbMetric: 398.8999 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 50/1000
2023-09-09 23:09:00.952 
Epoch 50/1000 
	 loss: 397.9404, MinusLogProbMetric: 397.9404, val_loss: 402.3447, val_MinusLogProbMetric: 402.3447

Epoch 50: val_loss did not improve from 398.89993
196/196 - 17s - loss: 397.9404 - MinusLogProbMetric: 397.9404 - val_loss: 402.3447 - val_MinusLogProbMetric: 402.3447 - lr: 3.3333e-04 - 17s/epoch - 85ms/step
Epoch 51/1000
2023-09-09 23:09:17.163 
Epoch 51/1000 
	 loss: 398.6201, MinusLogProbMetric: 398.6201, val_loss: 403.3460, val_MinusLogProbMetric: 403.3460

Epoch 51: val_loss did not improve from 398.89993
196/196 - 16s - loss: 398.6201 - MinusLogProbMetric: 398.6201 - val_loss: 403.3460 - val_MinusLogProbMetric: 403.3460 - lr: 3.3333e-04 - 16s/epoch - 83ms/step
Epoch 52/1000
2023-09-09 23:09:33.302 
Epoch 52/1000 
	 loss: 398.1698, MinusLogProbMetric: 398.1698, val_loss: 402.0162, val_MinusLogProbMetric: 402.0162

Epoch 52: val_loss did not improve from 398.89993
196/196 - 16s - loss: 398.1698 - MinusLogProbMetric: 398.1698 - val_loss: 402.0162 - val_MinusLogProbMetric: 402.0162 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 53/1000
2023-09-09 23:09:50.751 
Epoch 53/1000 
	 loss: 396.9709, MinusLogProbMetric: 396.9709, val_loss: 404.3840, val_MinusLogProbMetric: 404.3840

Epoch 53: val_loss did not improve from 398.89993
196/196 - 17s - loss: 396.9709 - MinusLogProbMetric: 396.9709 - val_loss: 404.3840 - val_MinusLogProbMetric: 404.3840 - lr: 3.3333e-04 - 17s/epoch - 89ms/step
Epoch 54/1000
2023-09-09 23:10:06.842 
Epoch 54/1000 
	 loss: 397.3801, MinusLogProbMetric: 397.3801, val_loss: 399.9953, val_MinusLogProbMetric: 399.9953

Epoch 54: val_loss did not improve from 398.89993
196/196 - 16s - loss: 397.3801 - MinusLogProbMetric: 397.3801 - val_loss: 399.9953 - val_MinusLogProbMetric: 399.9953 - lr: 3.3333e-04 - 16s/epoch - 82ms/step
Epoch 55/1000
2023-09-09 23:10:22.812 
Epoch 55/1000 
	 loss: 397.1440, MinusLogProbMetric: 397.1440, val_loss: 400.6761, val_MinusLogProbMetric: 400.6761

Epoch 55: val_loss did not improve from 398.89993
196/196 - 16s - loss: 397.1440 - MinusLogProbMetric: 397.1440 - val_loss: 400.6761 - val_MinusLogProbMetric: 400.6761 - lr: 3.3333e-04 - 16s/epoch - 81ms/step
Epoch 56/1000
2023-09-09 23:10:39.688 
Epoch 56/1000 
	 loss: 397.2471, MinusLogProbMetric: 397.2471, val_loss: 400.0276, val_MinusLogProbMetric: 400.0276

Epoch 56: val_loss did not improve from 398.89993
196/196 - 17s - loss: 397.2471 - MinusLogProbMetric: 397.2471 - val_loss: 400.0276 - val_MinusLogProbMetric: 400.0276 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 57/1000
2023-09-09 23:10:56.069 
Epoch 57/1000 
	 loss: 396.9526, MinusLogProbMetric: 396.9526, val_loss: 400.0437, val_MinusLogProbMetric: 400.0437

Epoch 57: val_loss did not improve from 398.89993
196/196 - 16s - loss: 396.9526 - MinusLogProbMetric: 396.9526 - val_loss: 400.0437 - val_MinusLogProbMetric: 400.0437 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 58/1000
2023-09-09 23:11:12.548 
Epoch 58/1000 
	 loss: 397.4762, MinusLogProbMetric: 397.4762, val_loss: 401.5771, val_MinusLogProbMetric: 401.5771

Epoch 58: val_loss did not improve from 398.89993
196/196 - 16s - loss: 397.4762 - MinusLogProbMetric: 397.4762 - val_loss: 401.5771 - val_MinusLogProbMetric: 401.5771 - lr: 3.3333e-04 - 16s/epoch - 84ms/step
Epoch 59/1000
2023-09-09 23:11:29.390 
Epoch 59/1000 
	 loss: 397.3639, MinusLogProbMetric: 397.3639, val_loss: 417.4611, val_MinusLogProbMetric: 417.4611

Epoch 59: val_loss did not improve from 398.89993
196/196 - 17s - loss: 397.3639 - MinusLogProbMetric: 397.3639 - val_loss: 417.4611 - val_MinusLogProbMetric: 417.4611 - lr: 3.3333e-04 - 17s/epoch - 86ms/step
Epoch 60/1000
2023-09-09 23:11:46.726 
Epoch 60/1000 
	 loss: 401.5902, MinusLogProbMetric: 401.5902, val_loss: 401.2457, val_MinusLogProbMetric: 401.2457

Epoch 60: val_loss did not improve from 398.89993
196/196 - 17s - loss: 401.5902 - MinusLogProbMetric: 401.5902 - val_loss: 401.2457 - val_MinusLogProbMetric: 401.2457 - lr: 3.3333e-04 - 17s/epoch - 88ms/step
Epoch 61/1000
2023-09-09 23:12:01.059 
Epoch 61/1000 
	 loss: 396.7898, MinusLogProbMetric: 396.7898, val_loss: 400.7920, val_MinusLogProbMetric: 400.7920

Epoch 61: val_loss did not improve from 398.89993
196/196 - 14s - loss: 396.7898 - MinusLogProbMetric: 396.7898 - val_loss: 400.7920 - val_MinusLogProbMetric: 400.7920 - lr: 3.3333e-04 - 14s/epoch - 73ms/step
Epoch 62/1000
2023-09-09 23:12:19.473 
Epoch 62/1000 
	 loss: 396.4180, MinusLogProbMetric: 396.4180, val_loss: 401.0484, val_MinusLogProbMetric: 401.0484

Epoch 62: val_loss did not improve from 398.89993
196/196 - 18s - loss: 396.4180 - MinusLogProbMetric: 396.4180 - val_loss: 401.0484 - val_MinusLogProbMetric: 401.0484 - lr: 3.3333e-04 - 18s/epoch - 94ms/step
Epoch 63/1000
2023-09-09 23:12:43.741 
Epoch 63/1000 
	 loss: 396.3204, MinusLogProbMetric: 396.3204, val_loss: 401.1283, val_MinusLogProbMetric: 401.1283

Epoch 63: val_loss did not improve from 398.89993
196/196 - 24s - loss: 396.3204 - MinusLogProbMetric: 396.3204 - val_loss: 401.1283 - val_MinusLogProbMetric: 401.1283 - lr: 3.3333e-04 - 24s/epoch - 124ms/step
Epoch 64/1000
2023-09-09 23:13:03.222 
Epoch 64/1000 
	 loss: 396.7033, MinusLogProbMetric: 396.7033, val_loss: 401.5345, val_MinusLogProbMetric: 401.5345

Epoch 64: val_loss did not improve from 398.89993
196/196 - 19s - loss: 396.7033 - MinusLogProbMetric: 396.7033 - val_loss: 401.5345 - val_MinusLogProbMetric: 401.5345 - lr: 3.3333e-04 - 19s/epoch - 99ms/step
Epoch 65/1000
2023-09-09 23:13:24.574 
Epoch 65/1000 
	 loss: 397.4165, MinusLogProbMetric: 397.4165, val_loss: 399.9465, val_MinusLogProbMetric: 399.9465

Epoch 65: val_loss did not improve from 398.89993
196/196 - 21s - loss: 397.4165 - MinusLogProbMetric: 397.4165 - val_loss: 399.9465 - val_MinusLogProbMetric: 399.9465 - lr: 3.3333e-04 - 21s/epoch - 109ms/step
Epoch 66/1000
2023-09-09 23:13:46.339 
Epoch 66/1000 
	 loss: 396.0338, MinusLogProbMetric: 396.0338, val_loss: 401.1644, val_MinusLogProbMetric: 401.1644

Epoch 66: val_loss did not improve from 398.89993
196/196 - 22s - loss: 396.0338 - MinusLogProbMetric: 396.0338 - val_loss: 401.1644 - val_MinusLogProbMetric: 401.1644 - lr: 3.3333e-04 - 22s/epoch - 111ms/step
Epoch 67/1000
2023-09-09 23:14:10.316 
Epoch 67/1000 
	 loss: 396.3891, MinusLogProbMetric: 396.3891, val_loss: 399.5945, val_MinusLogProbMetric: 399.5945

Epoch 67: val_loss did not improve from 398.89993
196/196 - 24s - loss: 396.3891 - MinusLogProbMetric: 396.3891 - val_loss: 399.5945 - val_MinusLogProbMetric: 399.5945 - lr: 3.3333e-04 - 24s/epoch - 122ms/step
Epoch 68/1000
2023-09-09 23:14:36.188 
Epoch 68/1000 
	 loss: 395.9664, MinusLogProbMetric: 395.9664, val_loss: 400.8246, val_MinusLogProbMetric: 400.8246

Epoch 68: val_loss did not improve from 398.89993
196/196 - 26s - loss: 395.9664 - MinusLogProbMetric: 395.9664 - val_loss: 400.8246 - val_MinusLogProbMetric: 400.8246 - lr: 3.3333e-04 - 26s/epoch - 132ms/step
Epoch 69/1000
2023-09-09 23:15:00.222 
Epoch 69/1000 
	 loss: 396.2957, MinusLogProbMetric: 396.2957, val_loss: 403.1952, val_MinusLogProbMetric: 403.1952

Epoch 69: val_loss did not improve from 398.89993
196/196 - 24s - loss: 396.2957 - MinusLogProbMetric: 396.2957 - val_loss: 403.1952 - val_MinusLogProbMetric: 403.1952 - lr: 3.3333e-04 - 24s/epoch - 123ms/step
Epoch 70/1000
2023-09-09 23:15:28.187 
Epoch 70/1000 
	 loss: 396.2984, MinusLogProbMetric: 396.2984, val_loss: 401.9810, val_MinusLogProbMetric: 401.9810

Epoch 70: val_loss did not improve from 398.89993
196/196 - 28s - loss: 396.2984 - MinusLogProbMetric: 396.2984 - val_loss: 401.9810 - val_MinusLogProbMetric: 401.9810 - lr: 3.3333e-04 - 28s/epoch - 143ms/step
Epoch 71/1000
2023-09-09 23:15:55.676 
Epoch 71/1000 
	 loss: 396.4481, MinusLogProbMetric: 396.4481, val_loss: 399.6933, val_MinusLogProbMetric: 399.6933

Epoch 71: val_loss did not improve from 398.89993
196/196 - 28s - loss: 396.4481 - MinusLogProbMetric: 396.4481 - val_loss: 399.6933 - val_MinusLogProbMetric: 399.6933 - lr: 3.3333e-04 - 28s/epoch - 140ms/step
Epoch 72/1000
2023-09-09 23:16:21.289 
Epoch 72/1000 
	 loss: 395.9033, MinusLogProbMetric: 395.9033, val_loss: 400.5492, val_MinusLogProbMetric: 400.5492

Epoch 72: val_loss did not improve from 398.89993
196/196 - 26s - loss: 395.9033 - MinusLogProbMetric: 395.9033 - val_loss: 400.5492 - val_MinusLogProbMetric: 400.5492 - lr: 3.3333e-04 - 26s/epoch - 130ms/step
Epoch 73/1000
2023-09-09 23:16:47.576 
Epoch 73/1000 
	 loss: 395.9528, MinusLogProbMetric: 395.9528, val_loss: 400.1517, val_MinusLogProbMetric: 400.1517

Epoch 73: val_loss did not improve from 398.89993
196/196 - 26s - loss: 395.9528 - MinusLogProbMetric: 395.9528 - val_loss: 400.1517 - val_MinusLogProbMetric: 400.1517 - lr: 3.3333e-04 - 26s/epoch - 134ms/step
Epoch 74/1000
2023-09-09 23:17:13.354 
Epoch 74/1000 
	 loss: 396.6819, MinusLogProbMetric: 396.6819, val_loss: 399.5242, val_MinusLogProbMetric: 399.5242

Epoch 74: val_loss did not improve from 398.89993
196/196 - 26s - loss: 396.6819 - MinusLogProbMetric: 396.6819 - val_loss: 399.5242 - val_MinusLogProbMetric: 399.5242 - lr: 3.3333e-04 - 26s/epoch - 132ms/step
Epoch 75/1000
2023-09-09 23:17:39.119 
Epoch 75/1000 
	 loss: 395.7478, MinusLogProbMetric: 395.7478, val_loss: 406.0334, val_MinusLogProbMetric: 406.0334

Epoch 75: val_loss did not improve from 398.89993
196/196 - 26s - loss: 395.7478 - MinusLogProbMetric: 395.7478 - val_loss: 406.0334 - val_MinusLogProbMetric: 406.0334 - lr: 3.3333e-04 - 26s/epoch - 131ms/step
Epoch 76/1000
2023-09-09 23:18:05.793 
Epoch 76/1000 
	 loss: 395.8413, MinusLogProbMetric: 395.8413, val_loss: 399.1282, val_MinusLogProbMetric: 399.1282

Epoch 76: val_loss did not improve from 398.89993
196/196 - 27s - loss: 395.8413 - MinusLogProbMetric: 395.8413 - val_loss: 399.1282 - val_MinusLogProbMetric: 399.1282 - lr: 3.3333e-04 - 27s/epoch - 136ms/step
Epoch 77/1000
2023-09-09 23:18:33.185 
Epoch 77/1000 
	 loss: 396.7630, MinusLogProbMetric: 396.7630, val_loss: 403.2437, val_MinusLogProbMetric: 403.2437

Epoch 77: val_loss did not improve from 398.89993
196/196 - 27s - loss: 396.7630 - MinusLogProbMetric: 396.7630 - val_loss: 403.2437 - val_MinusLogProbMetric: 403.2437 - lr: 3.3333e-04 - 27s/epoch - 140ms/step
Epoch 78/1000
2023-09-09 23:18:59.870 
Epoch 78/1000 
	 loss: 395.5575, MinusLogProbMetric: 395.5575, val_loss: 400.1805, val_MinusLogProbMetric: 400.1805

Epoch 78: val_loss did not improve from 398.89993
196/196 - 27s - loss: 395.5575 - MinusLogProbMetric: 395.5575 - val_loss: 400.1805 - val_MinusLogProbMetric: 400.1805 - lr: 3.3333e-04 - 27s/epoch - 136ms/step
Epoch 79/1000
2023-09-09 23:19:25.583 
Epoch 79/1000 
	 loss: 395.8658, MinusLogProbMetric: 395.8658, val_loss: 407.3062, val_MinusLogProbMetric: 407.3062

Epoch 79: val_loss did not improve from 398.89993
196/196 - 26s - loss: 395.8658 - MinusLogProbMetric: 395.8658 - val_loss: 407.3062 - val_MinusLogProbMetric: 407.3062 - lr: 3.3333e-04 - 26s/epoch - 131ms/step
Epoch 80/1000
2023-09-09 23:19:49.868 
Epoch 80/1000 
	 loss: 396.0848, MinusLogProbMetric: 396.0848, val_loss: 400.9264, val_MinusLogProbMetric: 400.9264

Epoch 80: val_loss did not improve from 398.89993
196/196 - 24s - loss: 396.0848 - MinusLogProbMetric: 396.0848 - val_loss: 400.9264 - val_MinusLogProbMetric: 400.9264 - lr: 3.3333e-04 - 24s/epoch - 124ms/step
Epoch 81/1000
2023-09-09 23:20:14.903 
Epoch 81/1000 
	 loss: 397.2105, MinusLogProbMetric: 397.2105, val_loss: 399.1767, val_MinusLogProbMetric: 399.1767

Epoch 81: val_loss did not improve from 398.89993
196/196 - 25s - loss: 397.2105 - MinusLogProbMetric: 397.2105 - val_loss: 399.1767 - val_MinusLogProbMetric: 399.1767 - lr: 3.3333e-04 - 25s/epoch - 128ms/step
Epoch 82/1000
2023-09-09 23:20:39.921 
Epoch 82/1000 
	 loss: 395.4698, MinusLogProbMetric: 395.4698, val_loss: 398.8935, val_MinusLogProbMetric: 398.8935

Epoch 82: val_loss improved from 398.89993 to 398.89349, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 26s - loss: 395.4698 - MinusLogProbMetric: 395.4698 - val_loss: 398.8935 - val_MinusLogProbMetric: 398.8935 - lr: 3.3333e-04 - 26s/epoch - 133ms/step
Epoch 83/1000
2023-09-09 23:21:09.067 
Epoch 83/1000 
	 loss: 396.0334, MinusLogProbMetric: 396.0334, val_loss: 400.5169, val_MinusLogProbMetric: 400.5169

Epoch 83: val_loss did not improve from 398.89349
196/196 - 28s - loss: 396.0334 - MinusLogProbMetric: 396.0334 - val_loss: 400.5169 - val_MinusLogProbMetric: 400.5169 - lr: 3.3333e-04 - 28s/epoch - 144ms/step
Epoch 84/1000
2023-09-09 23:21:33.742 
Epoch 84/1000 
	 loss: 395.8494, MinusLogProbMetric: 395.8494, val_loss: 400.7593, val_MinusLogProbMetric: 400.7593

Epoch 84: val_loss did not improve from 398.89349
196/196 - 25s - loss: 395.8494 - MinusLogProbMetric: 395.8494 - val_loss: 400.7593 - val_MinusLogProbMetric: 400.7593 - lr: 3.3333e-04 - 25s/epoch - 126ms/step
Epoch 85/1000
2023-09-09 23:22:00.188 
Epoch 85/1000 
	 loss: 396.1236, MinusLogProbMetric: 396.1236, val_loss: 400.6791, val_MinusLogProbMetric: 400.6791

Epoch 85: val_loss did not improve from 398.89349
196/196 - 26s - loss: 396.1236 - MinusLogProbMetric: 396.1236 - val_loss: 400.6791 - val_MinusLogProbMetric: 400.6791 - lr: 3.3333e-04 - 26s/epoch - 135ms/step
Epoch 86/1000
2023-09-09 23:22:27.350 
Epoch 86/1000 
	 loss: 395.9664, MinusLogProbMetric: 395.9664, val_loss: 407.2576, val_MinusLogProbMetric: 407.2576

Epoch 86: val_loss did not improve from 398.89349
196/196 - 27s - loss: 395.9664 - MinusLogProbMetric: 395.9664 - val_loss: 407.2576 - val_MinusLogProbMetric: 407.2576 - lr: 3.3333e-04 - 27s/epoch - 139ms/step
Epoch 87/1000
2023-09-09 23:22:53.734 
Epoch 87/1000 
	 loss: 395.6369, MinusLogProbMetric: 395.6369, val_loss: 402.8089, val_MinusLogProbMetric: 402.8089

Epoch 87: val_loss did not improve from 398.89349
196/196 - 26s - loss: 395.6369 - MinusLogProbMetric: 395.6369 - val_loss: 402.8089 - val_MinusLogProbMetric: 402.8089 - lr: 3.3333e-04 - 26s/epoch - 134ms/step
Epoch 88/1000
2023-09-09 23:23:19.410 
Epoch 88/1000 
	 loss: 395.1821, MinusLogProbMetric: 395.1821, val_loss: 401.2857, val_MinusLogProbMetric: 401.2857

Epoch 88: val_loss did not improve from 398.89349
196/196 - 26s - loss: 395.1821 - MinusLogProbMetric: 395.1821 - val_loss: 401.2857 - val_MinusLogProbMetric: 401.2857 - lr: 3.3333e-04 - 26s/epoch - 131ms/step
Epoch 89/1000
2023-09-09 23:23:45.833 
Epoch 89/1000 
	 loss: 395.5229, MinusLogProbMetric: 395.5229, val_loss: 401.7609, val_MinusLogProbMetric: 401.7609

Epoch 89: val_loss did not improve from 398.89349
196/196 - 26s - loss: 395.5229 - MinusLogProbMetric: 395.5229 - val_loss: 401.7609 - val_MinusLogProbMetric: 401.7609 - lr: 3.3333e-04 - 26s/epoch - 135ms/step
Epoch 90/1000
2023-09-09 23:24:10.789 
Epoch 90/1000 
	 loss: 395.4805, MinusLogProbMetric: 395.4805, val_loss: 408.9274, val_MinusLogProbMetric: 408.9274

Epoch 90: val_loss did not improve from 398.89349
196/196 - 25s - loss: 395.4805 - MinusLogProbMetric: 395.4805 - val_loss: 408.9274 - val_MinusLogProbMetric: 408.9274 - lr: 3.3333e-04 - 25s/epoch - 127ms/step
Epoch 91/1000
2023-09-09 23:24:36.031 
Epoch 91/1000 
	 loss: 395.6505, MinusLogProbMetric: 395.6505, val_loss: 402.8195, val_MinusLogProbMetric: 402.8195

Epoch 91: val_loss did not improve from 398.89349
196/196 - 25s - loss: 395.6505 - MinusLogProbMetric: 395.6505 - val_loss: 402.8195 - val_MinusLogProbMetric: 402.8195 - lr: 3.3333e-04 - 25s/epoch - 129ms/step
Epoch 92/1000
2023-09-09 23:25:00.370 
Epoch 92/1000 
	 loss: 394.7898, MinusLogProbMetric: 394.7898, val_loss: 423.4536, val_MinusLogProbMetric: 423.4536

Epoch 92: val_loss did not improve from 398.89349
196/196 - 24s - loss: 394.7898 - MinusLogProbMetric: 394.7898 - val_loss: 423.4536 - val_MinusLogProbMetric: 423.4536 - lr: 3.3333e-04 - 24s/epoch - 124ms/step
Epoch 93/1000
2023-09-09 23:25:27.960 
Epoch 93/1000 
	 loss: 395.7858, MinusLogProbMetric: 395.7858, val_loss: 401.7807, val_MinusLogProbMetric: 401.7807

Epoch 93: val_loss did not improve from 398.89349
196/196 - 28s - loss: 395.7858 - MinusLogProbMetric: 395.7858 - val_loss: 401.7807 - val_MinusLogProbMetric: 401.7807 - lr: 3.3333e-04 - 28s/epoch - 141ms/step
Epoch 94/1000
2023-09-09 23:25:53.414 
Epoch 94/1000 
	 loss: 395.4665, MinusLogProbMetric: 395.4665, val_loss: 399.4304, val_MinusLogProbMetric: 399.4304

Epoch 94: val_loss did not improve from 398.89349
196/196 - 25s - loss: 395.4665 - MinusLogProbMetric: 395.4665 - val_loss: 399.4304 - val_MinusLogProbMetric: 399.4304 - lr: 3.3333e-04 - 25s/epoch - 130ms/step
Epoch 95/1000
2023-09-09 23:26:19.690 
Epoch 95/1000 
	 loss: 395.1883, MinusLogProbMetric: 395.1883, val_loss: 399.4764, val_MinusLogProbMetric: 399.4764

Epoch 95: val_loss did not improve from 398.89349
196/196 - 26s - loss: 395.1883 - MinusLogProbMetric: 395.1883 - val_loss: 399.4764 - val_MinusLogProbMetric: 399.4764 - lr: 3.3333e-04 - 26s/epoch - 134ms/step
Epoch 96/1000
2023-09-09 23:26:44.973 
Epoch 96/1000 
	 loss: 395.1548, MinusLogProbMetric: 395.1548, val_loss: 399.3184, val_MinusLogProbMetric: 399.3184

Epoch 96: val_loss did not improve from 398.89349
196/196 - 25s - loss: 395.1548 - MinusLogProbMetric: 395.1548 - val_loss: 399.3184 - val_MinusLogProbMetric: 399.3184 - lr: 3.3333e-04 - 25s/epoch - 129ms/step
Epoch 97/1000
2023-09-09 23:27:11.796 
Epoch 97/1000 
	 loss: 395.5037, MinusLogProbMetric: 395.5037, val_loss: 402.3253, val_MinusLogProbMetric: 402.3253

Epoch 97: val_loss did not improve from 398.89349
196/196 - 27s - loss: 395.5037 - MinusLogProbMetric: 395.5037 - val_loss: 402.3253 - val_MinusLogProbMetric: 402.3253 - lr: 3.3333e-04 - 27s/epoch - 137ms/step
Epoch 98/1000
2023-09-09 23:27:37.857 
Epoch 98/1000 
	 loss: 394.7486, MinusLogProbMetric: 394.7486, val_loss: 400.9639, val_MinusLogProbMetric: 400.9639

Epoch 98: val_loss did not improve from 398.89349
196/196 - 26s - loss: 394.7486 - MinusLogProbMetric: 394.7486 - val_loss: 400.9639 - val_MinusLogProbMetric: 400.9639 - lr: 3.3333e-04 - 26s/epoch - 133ms/step
Epoch 99/1000
2023-09-09 23:28:04.389 
Epoch 99/1000 
	 loss: 394.7218, MinusLogProbMetric: 394.7218, val_loss: 400.0826, val_MinusLogProbMetric: 400.0826

Epoch 99: val_loss did not improve from 398.89349
196/196 - 27s - loss: 394.7218 - MinusLogProbMetric: 394.7218 - val_loss: 400.0826 - val_MinusLogProbMetric: 400.0826 - lr: 3.3333e-04 - 27s/epoch - 135ms/step
Epoch 100/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 13: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-09 23:28:07.743 
Epoch 100/1000 
	 loss: nan, MinusLogProbMetric: 12515.1650, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 100: val_loss did not improve from 398.89349
196/196 - 3s - loss: nan - MinusLogProbMetric: 12515.1650 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 3.3333e-04 - 3s/epoch - 17ms/step
The loss history contains NaN values.
Training failed: trying again with seed 511595 and lr 0.0001111111111111111.
===========
Generating train data for run 327.
===========
Train data generated in 3.54 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_327/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 187}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0001111111111111111, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_327/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.6836276 , -0.60898554,  4.901356  , ...,  4.578798  ,
         5.78743   ,  5.8673487 ],
       [ 8.249707  ,  4.460014  ,  5.2482004 , ...,  1.7374016 ,
         8.867281  ,  6.8796477 ],
       [ 6.103276  ,  7.069252  ,  6.2995415 , ..., 11.163949  ,
         2.6241696 ,  6.7860346 ],
       ...,
       [ 5.7729836 ,  0.39295188,  4.752078  , ...,  4.8545365 ,
         6.277194  ,  5.1011395 ],
       [ 8.14715   ,  4.7503    ,  5.215126  , ...,  3.7450724 ,
         8.238651  ,  6.647562  ],
       [ 5.6715584 ,  7.2547503 ,  6.700116  , ..., 10.850491  ,
         1.1671181 ,  6.458376  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_327/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_327
self.data_kwargs: {'seed': 187}
self.x_data: [[8.405046   4.6301365  5.2287283  ... 2.9590435  8.640119   7.4559712 ]
 [6.027003   0.2016806  4.6617384  ... 4.692235   6.373698   5.3374834 ]
 [5.680177   0.10050362 4.564641   ... 4.4050727  6.0966487  6.0310545 ]
 ...
 [6.204324   0.5308406  4.687448   ... 4.736321   6.117902   4.3074207 ]
 [7.884271   4.844002   5.2654357  ... 2.2312212  7.9686017  6.4498177 ]
 [5.7032723  1.704168   4.78966    ... 5.263417   6.7690263  5.8227935 ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_23 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_2 (LogProbLa  (None,)                  4191520   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,191,520
Trainable params: 4,191,520
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_2/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_2'")
self.model: <keras.engine.functional.Functional object at 0x7f197c5b0250>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0001111111111111111, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f197c26d630>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0001111111111111111, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f197c26d630>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f193c617e50>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f19f438d540>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f19f438da20>, <keras.callbacks.ModelCheckpoint object at 0x7f19f438dae0>, <keras.callbacks.EarlyStopping object at 0x7f19f438dd50>, <keras.callbacks.ReduceLROnPlateau object at 0x7f19f438dd80>, <keras.callbacks.TerminateOnNaN object at 0x7f19f438d9c0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 5.6836276 , -0.60898554,  4.901356  , ...,  4.578798  ,
         5.78743   ,  5.8673487 ],
       [ 8.249707  ,  4.460014  ,  5.2482004 , ...,  1.7374016 ,
         8.867281  ,  6.8796477 ],
       [ 6.103276  ,  7.069252  ,  6.2995415 , ..., 11.163949  ,
         2.6241696 ,  6.7860346 ],
       ...,
       [ 5.7729836 ,  0.39295188,  4.752078  , ...,  4.8545365 ,
         6.277194  ,  5.1011395 ],
       [ 8.14715   ,  4.7503    ,  5.215126  , ...,  3.7450724 ,
         8.238651  ,  6.647562  ],
       [ 5.6715584 ,  7.2547503 ,  6.700116  , ..., 10.850491  ,
         1.1671181 ,  6.458376  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 327/360 with hyperparameters:
timestamp = 2023-09-09 23:28:22.587015
ndims = 1000
seed_train = 187
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 10
spline_knots = --
range_min = -5
hidden_layers = 128-128-128
trainable_parameters = 4191520
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0001111111111111111...
Train first sample: [ 8.405046    4.6301365   5.2287283   2.4556472   6.2928953   3.594312
  6.0004463   1.8052834   1.8765529   4.0951214   4.4015846   3.3011546
  1.1913271   0.29790348  0.444705    2.0839415   4.8839054   7.6232376
  5.0511703  10.082624    1.0256902   1.8862149   3.3338983   5.485959
  8.678817    4.2863455   2.746828    0.5995625   8.487818    4.326282
  5.4844646   9.668893    0.9005003   2.511495    7.4595304   8.076063
  7.482936    5.8244066  10.038453    4.2971616   6.199124    0.14504078
  4.115744    7.085761    2.2268302   8.105376    6.8798943   3.1965656
  7.803503    1.4473212   9.836955    1.2955343   9.292721    2.2835047
  7.347313   -0.344647    2.3793294   7.1599417   6.239404    1.8819436
  3.6855946   3.1096044   3.9889503   6.345884    8.7655735   3.506798
  3.8915956   1.4826899   7.7798705   6.4561133   3.7245452   5.022784
  6.785575    1.8807405  -0.53786993  3.331518    6.3648286   5.060461
  5.671335    8.188019    5.050044    0.8326328   9.021144    5.101296
  8.440869    7.8830547   9.847927    2.9928007   7.1174664   4.000934
  4.0642667   3.5513847   3.3835356   9.485252    2.8910272   2.857944
  5.1031704   2.365148    4.392073    7.9044094   2.2182727   3.5326295
  6.429046    5.444268    9.853491    6.801449    7.615357    9.654012
  4.2561636   3.94246     0.5266583   1.6963573   0.9076003   1.6972958
  8.415306    6.55893     6.517854    7.7323823   2.263416    3.867008
  7.0743175   4.310728    0.44073427  5.454958    8.770797    4.023472
  3.8313503   9.876201    6.083322    4.588916    0.97578037  8.022623
  6.904659    9.723064    1.5232677   1.2301477   7.2426834   2.4050941
  1.7633336   1.3129089   8.420942    5.7998257   0.4667193   4.692241
  6.5908155   5.257252    5.725936    2.6134639   8.439922    5.6147094
  7.455604    9.777677    4.190657    9.502805    0.30458957  0.2189286
  5.797137    3.0544481   2.6193647   2.5525932   3.284805    7.4161353
  5.749028    7.889573    7.898816    8.574444    3.8091307   4.298687
  9.481366    6.0068207   1.523428    5.6352916   4.365734    9.867473
  1.3835607   6.134872    7.2581935   2.8856063   9.735012    7.5791473
  9.23718     0.3085858   6.8750105   3.0606773   9.2376585   6.005112
  5.5536275   0.9032261   6.0153728   6.3190417   9.369196    5.911083
  9.520276   10.025198    7.444127    4.7846828   6.6327243  10.038699
  0.737067    1.1364235   0.7629767   7.3339915   3.2413385   6.3641744
  4.723883    3.890898    5.1846333   6.4865723   9.4478655   5.8353424
  6.1596503   0.8805034  10.229148    5.1357536   8.719589    0.61422366
  4.6646357   2.5584815   2.6442034   7.3017416   5.692237    3.2181895
  0.7464954   9.628433    9.805298    0.8460964   0.74706554  6.1736875
  9.794054    9.817206    5.73489     2.8118153   2.995823    9.004283
  3.2283762   1.9297047   2.5467188   2.732583    2.62711     5.3906684
  8.859532    7.221753    0.22360349  0.31767347  3.3918247   3.5905416
  8.748679    9.150864    4.0089087   6.819023    9.95121     7.2592616
  6.618907    0.7986359   3.617743    8.477222    2.5446649   8.356348
  6.784008    2.7764812   5.149644    5.879593    6.8204975   4.7749815
  1.5671438   7.5464864   2.9128666   9.640756    2.7195537   2.422054
  1.9658555   5.744532   10.17906     1.88257     3.3741965   5.759674
  4.4506254   5.799042    8.574516    9.521442    4.848262    7.099014
  7.410928    4.176586    2.7669337   6.7037125   6.396343    9.116149
  0.6767711   8.802082    5.400854   -0.46128303  4.315248    7.679634
  4.337188    9.473796    4.3057194   3.8800864   8.321836    5.464394
  6.8586717   7.8846817   6.758233    4.5121193   1.5240693   5.1997232
  7.966815    3.110014    9.149139    5.2918534   6.043538    8.5325165
  7.029521    0.71871924  9.851924    2.0979629   7.107039    5.8480177
  4.6838837   2.2520099   7.556054    1.2082794  10.557993    8.230412
  5.3685956   3.7290514   3.748278    4.2430515   8.3245535   2.619837
  3.433112    1.6606942   2.8829854   1.0669343   9.924688    5.8388543
  6.973813    0.9312429   3.8876076   8.887293    0.8722724   2.881507
  6.283689    6.159739    8.345073    9.115302    1.4750379   2.7552269
  4.2736816   0.15881406 -0.24159682  2.4190745   4.887695    2.6831913
  8.220071    3.2441287   8.8378105   9.509058    3.559123    3.1608875
  3.3725164   7.9289885   2.9474692   4.059424    4.7409554   5.2013454
  9.994335    2.323355    3.3355927   2.5336983   3.2941818   2.2210457
  3.2414346   9.904477    2.334639    4.492616   10.475705    7.142849
  4.6010633   7.570345    1.3164223   4.2845144   0.5250243   2.3362412
  2.8345227   3.6286557   4.130509    9.905742    2.1830826   4.842215
  6.807653    7.5327077   7.2363663   2.9334166   5.234727    1.7384282
  2.0550947   4.500183    7.394765    4.995599    7.815772   10.710524
 -0.19277403  5.792584    6.1900487   9.671367    0.28583023  5.668808
  1.2390957   0.5417446   6.8533115   7.9632573   8.180385   -0.4858576
  4.0685763   2.4839914   2.1516795   1.9025909   2.110797    2.6641178
  2.6061893   9.366816    4.2622356   8.9237175   1.1875978   7.9966984
  0.44503674  4.7554154  -0.20823273  7.945292   10.080656    0.3404049
  8.932869    8.365952    3.7764497   9.093311    2.3442857   4.1149993
  0.99684995  6.8027267   0.3532521   4.712874    6.197236    8.98079
  0.7532523   7.324172    6.816783    7.1629744   5.789584    1.8008664
  6.6962724   3.5133753   8.672127    1.7033234   5.757915    3.8499484
  7.6907835   2.515215    0.675339    6.6755958   4.1274943   5.9000664
  0.6306852  10.170123    8.690909    5.6241055   0.83715045  3.7537289
  9.811078    7.1486425   1.5089558   4.5211      9.977777    5.041157
  0.20099962  7.1491528   2.411008    0.98729235  4.0264      6.1107965
  0.8201466   6.400518    5.2138658   8.338983    4.008616    5.4276114
  7.5568547   9.328188    3.5043116   5.993576    6.732445    0.1456024
  8.195436    4.0946035   6.8117595   5.4540176   7.008695    7.6902666
  1.121738    6.662947    9.421039    3.6054578   8.282917    6.2551546
  8.867136    2.7717266   1.666508    1.9828001   2.582295    7.401628
  7.3309445   6.1640267   2.2886527   8.620049    9.976319    5.427213
  6.492129    5.227495    2.6098144   3.1037233   2.451418    1.547883
  9.130067    9.089639    3.8307672   2.809064    9.412396    3.0656943
  5.384379    1.269433    2.1198947   5.4160995   5.9553137   6.8595047
  8.024387    9.932428    7.275275    5.4964776   9.2686615  -0.8320414
  6.634356    3.5646963   1.6928086   9.683453    3.4941626   6.2850795
  8.140037    5.0819607   1.6098254   8.515681    3.746112   10.339378
  9.723754    8.560821    3.4616127   8.136909    8.474316    5.334234
  4.3071146   0.3017891   7.5740643   8.525242    1.961537    2.785501
  4.6199455   0.20740837  0.8326539   4.594327    2.569767    3.3214014
  4.017394    9.219309   10.736801    1.9790065   8.832557    0.9678319
  5.233325   -0.19063437  3.1312854   8.050418    4.191532    9.204013
  7.268445    9.203028    4.342827    8.019755    3.3341756   3.743745
  3.9635062   3.979517    0.6836107   5.098467    0.71361184  8.4552765
  0.5069707   4.833144    3.1548538   1.8944778   7.8488803   7.0419393
  1.2548511   6.628743    7.354838    8.050705    1.1345416   6.8048496
  6.528121    8.252401    4.5538      4.949585    8.730731    7.4312305
  5.643753    2.5072966   8.962284    4.0641007   0.7590125   5.4753785
  9.738958    4.561652   -0.360509    6.1097317   9.957747    7.0762954
  5.690881    8.773466    8.0799      5.2899666   6.263382    7.4875503
  8.585341    0.6384524   8.029185    4.3010435   6.264173    7.7155027
  5.2268887   1.5704446   4.016696    0.5981313   6.7822347   9.855953
  7.53499     5.1501827   5.5134096   2.8642232   5.220349    3.4915414
  4.7451196   2.6037292   9.620164    6.549827    0.7027252  -0.15775523
 10.00958     3.973167    3.273789    1.7160401   9.183787    7.1865473
  5.1355295   4.8474526   3.5554662   6.6154428   4.344493    2.1984468
  5.4696417   4.251729    8.8025255   4.26232     4.9216294   7.9483533
  4.526991    9.588897    8.017048    8.2831135   9.821576    4.1731563
  5.8485947   6.667628    7.001741    9.226937    2.9446237   2.5925434
  8.618449    8.161273    1.7101693   5.5401206   8.14539     2.020844
  0.89211583  5.7496552   4.987388    7.4813085   0.39198843  4.8122907
  2.6751356   5.1997175   7.827039    0.7617685   1.984582    6.211319
  7.497485    5.6864862   9.833999    4.343862    0.91428226  6.860134
  8.022065    5.7952833   5.549028    8.938169    0.7987054   1.0077511
  1.547055    2.4538176   5.900641    5.950689    2.172312    4.864265
  5.3084598   2.74433     7.4509587   4.642633    7.352649    1.6610278
  5.3932858   8.224104    1.7825346   4.6216807   6.3162665   2.1527483
  7.82622     0.4708147   9.143722    4.7161274   2.9691823   0.9679443
  3.9266372   6.638867    0.10056549  3.118843    7.3452816   6.4795094
  2.0939577   2.478408    8.811012    3.114293    2.1261327  10.111931
  4.855735    1.2398901   5.2605786   5.4892864   9.44359     1.744517
  0.8859111   0.84614795  8.730755    4.4898634   1.9797392   5.9254265
  5.903251    2.0259151   7.1823764   4.0827475   2.3360302   5.4425554
  3.0566494   1.579066    8.333391    1.4978724   3.288137    3.852397
  2.935655    2.1213212   6.9459066   3.5336087   1.8826928   5.0965667
  1.2400447   4.7354097   8.616984    2.6134915   5.8834224   5.1864443
 -0.13750565  6.549661    8.984314    0.7847537   7.2001395   6.8008256
  8.44678     2.6799302   3.2838757   7.0237226  -0.23040357  7.540698
  8.530038    4.6869135   3.2353654   3.3326626  -2.8252068   1.808005
  8.638641    9.090046    2.7026813   9.352778    3.2715847   2.764985
  2.5781574   8.643513    9.775191    3.6196568   6.3544054   2.67319
 -0.27903366  3.0261974   5.7475586   1.8039718   8.191788    4.8235297
  2.4119723   4.80837     7.8066583   3.14657     7.254359    3.8570547
  8.983632    8.136105    3.6973224   0.29414394  6.2837157   1.7246333
  1.2347451   8.727795    9.613968    2.8966768   3.0174162   1.6892313
  4.788908    8.051952    6.6716456   8.591153    1.2762189   7.83716
 10.090976    2.9488695   6.9059463   3.4287705   2.638495    9.951833
  3.8517146   1.0833437   3.8833115   4.4572515   7.453829    9.261691
 10.299599    8.9711075   4.912658    7.687476    2.8381176   0.8803614
  3.6029894   7.0204277   3.0225866   9.093265    9.016605    1.5790088
  2.4555895   8.069907    3.3349042   3.3253474   3.304729    8.906204
  0.14018849 -0.09102672  5.6968327   2.8784204   6.3043637   1.5840611
  9.080589    7.872192    0.68985736  8.022463    9.62591     9.730082
  6.885892    1.2239211   6.788951    3.103189    8.581392    7.224449
  6.0487485   6.9063663   4.2010665   4.5798826   9.059492    3.4417286
  0.25157684  4.0677304   8.905279    6.148643   11.682095    0.95629424
  9.730315    5.5144877   4.490063    4.5312085   1.2480376   3.6158848
  7.4273086  -0.96325046  1.452391    0.25324896  8.457037    6.1265316
  1.3514678   8.127087   10.009373    9.350058    8.951299   -0.29766494
  6.0847034   2.4157875   5.6192784   2.8229573   0.7195138   4.5521054
  4.8054247   9.962674    0.39720708  3.1612184   8.577424    7.115589
  7.7674336   6.298065    7.663883    4.695144    1.1639674   7.7367616
  5.669413    1.2667739   7.7379103   9.650189    3.731491    3.391371
  0.73656756  6.0238733   9.167239    1.2704167   4.995278    0.9358564
  0.38653633  6.6325297   8.341552    3.6262543   7.874937    2.0914352
  2.2575343   7.0230904   4.9926057   4.8522496   0.38922572  1.2943935
  0.4778885   8.9588175   1.688771    8.19581     3.4283693   8.456239
  2.8242724   2.5323164   0.56487453  2.687169    3.4400296   8.293358
  4.435119    8.654662    5.423925   -0.7138738   3.3961737   6.6198845
  2.3316503   8.031245    4.494654    0.59436065  7.459087    5.8713436
  0.84994775  5.0717716   3.7515552   9.185751    2.3369966   9.342911
  5.7315216   2.9590435   8.640119    7.4559712 ]
Epoch 1/1000
2023-09-09 23:30:24.488 
Epoch 1/1000 
	 loss: 396.1934, MinusLogProbMetric: 396.1934, val_loss: 396.1527, val_MinusLogProbMetric: 396.1527

Epoch 1: val_loss improved from inf to 396.15274, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 123s - loss: 396.1934 - MinusLogProbMetric: 396.1934 - val_loss: 396.1527 - val_MinusLogProbMetric: 396.1527 - lr: 1.1111e-04 - 123s/epoch - 628ms/step
Epoch 2/1000
2023-09-09 23:30:53.854 
Epoch 2/1000 
	 loss: 390.7451, MinusLogProbMetric: 390.7451, val_loss: 397.3488, val_MinusLogProbMetric: 397.3488

Epoch 2: val_loss did not improve from 396.15274
196/196 - 27s - loss: 390.7451 - MinusLogProbMetric: 390.7451 - val_loss: 397.3488 - val_MinusLogProbMetric: 397.3488 - lr: 1.1111e-04 - 27s/epoch - 140ms/step
Epoch 3/1000
2023-09-09 23:31:20.174 
Epoch 3/1000 
	 loss: 390.8168, MinusLogProbMetric: 390.8168, val_loss: 395.7099, val_MinusLogProbMetric: 395.7099

Epoch 3: val_loss improved from 396.15274 to 395.70993, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 27s - loss: 390.8168 - MinusLogProbMetric: 390.8168 - val_loss: 395.7099 - val_MinusLogProbMetric: 395.7099 - lr: 1.1111e-04 - 27s/epoch - 138ms/step
Epoch 4/1000
2023-09-09 23:31:48.955 
Epoch 4/1000 
	 loss: 390.9982, MinusLogProbMetric: 390.9982, val_loss: 395.9354, val_MinusLogProbMetric: 395.9354

Epoch 4: val_loss did not improve from 395.70993
196/196 - 28s - loss: 390.9982 - MinusLogProbMetric: 390.9982 - val_loss: 395.9354 - val_MinusLogProbMetric: 395.9354 - lr: 1.1111e-04 - 28s/epoch - 143ms/step
Epoch 5/1000
2023-09-09 23:32:17.955 
Epoch 5/1000 
	 loss: 390.7642, MinusLogProbMetric: 390.7642, val_loss: 395.6489, val_MinusLogProbMetric: 395.6489

Epoch 5: val_loss improved from 395.70993 to 395.64890, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 30s - loss: 390.7642 - MinusLogProbMetric: 390.7642 - val_loss: 395.6489 - val_MinusLogProbMetric: 395.6489 - lr: 1.1111e-04 - 30s/epoch - 152ms/step
Epoch 6/1000
2023-09-09 23:32:44.548 
Epoch 6/1000 
	 loss: 390.5939, MinusLogProbMetric: 390.5939, val_loss: 395.7798, val_MinusLogProbMetric: 395.7798

Epoch 6: val_loss did not improve from 395.64890
196/196 - 26s - loss: 390.5939 - MinusLogProbMetric: 390.5939 - val_loss: 395.7798 - val_MinusLogProbMetric: 395.7798 - lr: 1.1111e-04 - 26s/epoch - 132ms/step
Epoch 7/1000
2023-09-09 23:33:12.024 
Epoch 7/1000 
	 loss: 390.8832, MinusLogProbMetric: 390.8832, val_loss: 395.8719, val_MinusLogProbMetric: 395.8719

Epoch 7: val_loss did not improve from 395.64890
196/196 - 27s - loss: 390.8832 - MinusLogProbMetric: 390.8832 - val_loss: 395.8719 - val_MinusLogProbMetric: 395.8719 - lr: 1.1111e-04 - 27s/epoch - 140ms/step
Epoch 8/1000
2023-09-09 23:33:41.009 
Epoch 8/1000 
	 loss: 390.6136, MinusLogProbMetric: 390.6136, val_loss: 396.5432, val_MinusLogProbMetric: 396.5432

Epoch 8: val_loss did not improve from 395.64890
196/196 - 29s - loss: 390.6136 - MinusLogProbMetric: 390.6136 - val_loss: 396.5432 - val_MinusLogProbMetric: 396.5432 - lr: 1.1111e-04 - 29s/epoch - 148ms/step
Epoch 9/1000
2023-09-09 23:34:08.958 
Epoch 9/1000 
	 loss: 390.4540, MinusLogProbMetric: 390.4540, val_loss: 396.3347, val_MinusLogProbMetric: 396.3347

Epoch 9: val_loss did not improve from 395.64890
196/196 - 28s - loss: 390.4540 - MinusLogProbMetric: 390.4540 - val_loss: 396.3347 - val_MinusLogProbMetric: 396.3347 - lr: 1.1111e-04 - 28s/epoch - 142ms/step
Epoch 10/1000
2023-09-09 23:34:38.027 
Epoch 10/1000 
	 loss: 390.3860, MinusLogProbMetric: 390.3860, val_loss: 397.7137, val_MinusLogProbMetric: 397.7137

Epoch 10: val_loss did not improve from 395.64890
196/196 - 29s - loss: 390.3860 - MinusLogProbMetric: 390.3860 - val_loss: 397.7137 - val_MinusLogProbMetric: 397.7137 - lr: 1.1111e-04 - 29s/epoch - 148ms/step
Epoch 11/1000
2023-09-09 23:35:07.012 
Epoch 11/1000 
	 loss: 390.4614, MinusLogProbMetric: 390.4614, val_loss: 396.0274, val_MinusLogProbMetric: 396.0274

Epoch 11: val_loss did not improve from 395.64890
196/196 - 29s - loss: 390.4614 - MinusLogProbMetric: 390.4614 - val_loss: 396.0274 - val_MinusLogProbMetric: 396.0274 - lr: 1.1111e-04 - 29s/epoch - 148ms/step
Epoch 12/1000
2023-09-09 23:35:34.260 
Epoch 12/1000 
	 loss: 390.8849, MinusLogProbMetric: 390.8849, val_loss: 395.6646, val_MinusLogProbMetric: 395.6646

Epoch 12: val_loss did not improve from 395.64890
196/196 - 27s - loss: 390.8849 - MinusLogProbMetric: 390.8849 - val_loss: 395.6646 - val_MinusLogProbMetric: 395.6646 - lr: 1.1111e-04 - 27s/epoch - 139ms/step
Epoch 13/1000
2023-09-09 23:36:01.377 
Epoch 13/1000 
	 loss: 390.1148, MinusLogProbMetric: 390.1148, val_loss: 396.9372, val_MinusLogProbMetric: 396.9372

Epoch 13: val_loss did not improve from 395.64890
196/196 - 27s - loss: 390.1148 - MinusLogProbMetric: 390.1148 - val_loss: 396.9372 - val_MinusLogProbMetric: 396.9372 - lr: 1.1111e-04 - 27s/epoch - 138ms/step
Epoch 14/1000
2023-09-09 23:36:28.749 
Epoch 14/1000 
	 loss: 390.6085, MinusLogProbMetric: 390.6085, val_loss: 395.6502, val_MinusLogProbMetric: 395.6502

Epoch 14: val_loss did not improve from 395.64890
196/196 - 27s - loss: 390.6085 - MinusLogProbMetric: 390.6085 - val_loss: 395.6502 - val_MinusLogProbMetric: 395.6502 - lr: 1.1111e-04 - 27s/epoch - 140ms/step
Epoch 15/1000
2023-09-09 23:36:58.191 
Epoch 15/1000 
	 loss: 390.2375, MinusLogProbMetric: 390.2375, val_loss: 396.6591, val_MinusLogProbMetric: 396.6591

Epoch 15: val_loss did not improve from 395.64890
196/196 - 29s - loss: 390.2375 - MinusLogProbMetric: 390.2375 - val_loss: 396.6591 - val_MinusLogProbMetric: 396.6591 - lr: 1.1111e-04 - 29s/epoch - 150ms/step
Epoch 16/1000
2023-09-09 23:37:26.518 
Epoch 16/1000 
	 loss: 389.9682, MinusLogProbMetric: 389.9682, val_loss: 395.4459, val_MinusLogProbMetric: 395.4459

Epoch 16: val_loss improved from 395.64890 to 395.44589, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 30s - loss: 389.9682 - MinusLogProbMetric: 389.9682 - val_loss: 395.4459 - val_MinusLogProbMetric: 395.4459 - lr: 1.1111e-04 - 30s/epoch - 151ms/step
Epoch 17/1000
2023-09-09 23:37:58.029 
Epoch 17/1000 
	 loss: 390.1398, MinusLogProbMetric: 390.1398, val_loss: 396.7385, val_MinusLogProbMetric: 396.7385

Epoch 17: val_loss did not improve from 395.44589
196/196 - 30s - loss: 390.1398 - MinusLogProbMetric: 390.1398 - val_loss: 396.7385 - val_MinusLogProbMetric: 396.7385 - lr: 1.1111e-04 - 30s/epoch - 154ms/step
Epoch 18/1000
2023-09-09 23:38:25.867 
Epoch 18/1000 
	 loss: 390.0527, MinusLogProbMetric: 390.0527, val_loss: 396.3425, val_MinusLogProbMetric: 396.3425

Epoch 18: val_loss did not improve from 395.44589
196/196 - 28s - loss: 390.0527 - MinusLogProbMetric: 390.0527 - val_loss: 396.3425 - val_MinusLogProbMetric: 396.3425 - lr: 1.1111e-04 - 28s/epoch - 142ms/step
Epoch 19/1000
2023-09-09 23:38:53.295 
Epoch 19/1000 
	 loss: 389.9449, MinusLogProbMetric: 389.9449, val_loss: 395.4209, val_MinusLogProbMetric: 395.4209

Epoch 19: val_loss improved from 395.44589 to 395.42087, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 29s - loss: 389.9449 - MinusLogProbMetric: 389.9449 - val_loss: 395.4209 - val_MinusLogProbMetric: 395.4209 - lr: 1.1111e-04 - 29s/epoch - 145ms/step
Epoch 20/1000
2023-09-09 23:39:23.569 
Epoch 20/1000 
	 loss: 390.0070, MinusLogProbMetric: 390.0070, val_loss: 396.9126, val_MinusLogProbMetric: 396.9126

Epoch 20: val_loss did not improve from 395.42087
196/196 - 29s - loss: 390.0070 - MinusLogProbMetric: 390.0070 - val_loss: 396.9126 - val_MinusLogProbMetric: 396.9126 - lr: 1.1111e-04 - 29s/epoch - 149ms/step
Epoch 21/1000
2023-09-09 23:39:52.489 
Epoch 21/1000 
	 loss: 389.9949, MinusLogProbMetric: 389.9949, val_loss: 396.8472, val_MinusLogProbMetric: 396.8472

Epoch 21: val_loss did not improve from 395.42087
196/196 - 29s - loss: 389.9949 - MinusLogProbMetric: 389.9949 - val_loss: 396.8472 - val_MinusLogProbMetric: 396.8472 - lr: 1.1111e-04 - 29s/epoch - 147ms/step
Epoch 22/1000
2023-09-09 23:40:21.359 
Epoch 22/1000 
	 loss: 389.9892, MinusLogProbMetric: 389.9892, val_loss: 396.3193, val_MinusLogProbMetric: 396.3193

Epoch 22: val_loss did not improve from 395.42087
196/196 - 29s - loss: 389.9892 - MinusLogProbMetric: 389.9892 - val_loss: 396.3193 - val_MinusLogProbMetric: 396.3193 - lr: 1.1111e-04 - 29s/epoch - 147ms/step
Epoch 23/1000
2023-09-09 23:40:50.291 
Epoch 23/1000 
	 loss: 389.8172, MinusLogProbMetric: 389.8172, val_loss: 395.4204, val_MinusLogProbMetric: 395.4204

Epoch 23: val_loss improved from 395.42087 to 395.42044, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 30s - loss: 389.8172 - MinusLogProbMetric: 389.8172 - val_loss: 395.4204 - val_MinusLogProbMetric: 395.4204 - lr: 1.1111e-04 - 30s/epoch - 153ms/step
Epoch 24/1000
2023-09-09 23:41:18.587 
Epoch 24/1000 
	 loss: 389.7973, MinusLogProbMetric: 389.7973, val_loss: 395.7459, val_MinusLogProbMetric: 395.7459

Epoch 24: val_loss did not improve from 395.42044
196/196 - 27s - loss: 389.7973 - MinusLogProbMetric: 389.7973 - val_loss: 395.7459 - val_MinusLogProbMetric: 395.7459 - lr: 1.1111e-04 - 27s/epoch - 139ms/step
Epoch 25/1000
2023-09-09 23:41:47.538 
Epoch 25/1000 
	 loss: 389.7996, MinusLogProbMetric: 389.7996, val_loss: 396.1731, val_MinusLogProbMetric: 396.1731

Epoch 25: val_loss did not improve from 395.42044
196/196 - 29s - loss: 389.7996 - MinusLogProbMetric: 389.7996 - val_loss: 396.1731 - val_MinusLogProbMetric: 396.1731 - lr: 1.1111e-04 - 29s/epoch - 148ms/step
Epoch 26/1000
2023-09-09 23:42:15.573 
Epoch 26/1000 
	 loss: 389.6794, MinusLogProbMetric: 389.6794, val_loss: 396.5303, val_MinusLogProbMetric: 396.5303

Epoch 26: val_loss did not improve from 395.42044
196/196 - 28s - loss: 389.6794 - MinusLogProbMetric: 389.6794 - val_loss: 396.5303 - val_MinusLogProbMetric: 396.5303 - lr: 1.1111e-04 - 28s/epoch - 143ms/step
Epoch 27/1000
2023-09-09 23:42:44.436 
Epoch 27/1000 
	 loss: 389.7128, MinusLogProbMetric: 389.7128, val_loss: 395.5181, val_MinusLogProbMetric: 395.5181

Epoch 27: val_loss did not improve from 395.42044
196/196 - 29s - loss: 389.7128 - MinusLogProbMetric: 389.7128 - val_loss: 395.5181 - val_MinusLogProbMetric: 395.5181 - lr: 1.1111e-04 - 29s/epoch - 147ms/step
Epoch 28/1000
2023-09-09 23:43:12.184 
Epoch 28/1000 
	 loss: 389.8305, MinusLogProbMetric: 389.8305, val_loss: 395.2445, val_MinusLogProbMetric: 395.2445

Epoch 28: val_loss improved from 395.42044 to 395.24454, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 29s - loss: 389.8305 - MinusLogProbMetric: 389.8305 - val_loss: 395.2445 - val_MinusLogProbMetric: 395.2445 - lr: 1.1111e-04 - 29s/epoch - 146ms/step
Epoch 29/1000
2023-09-09 23:43:42.176 
Epoch 29/1000 
	 loss: 389.7556, MinusLogProbMetric: 389.7556, val_loss: 396.4401, val_MinusLogProbMetric: 396.4401

Epoch 29: val_loss did not improve from 395.24454
196/196 - 29s - loss: 389.7556 - MinusLogProbMetric: 389.7556 - val_loss: 396.4401 - val_MinusLogProbMetric: 396.4401 - lr: 1.1111e-04 - 29s/epoch - 148ms/step
Epoch 30/1000
2023-09-09 23:44:11.209 
Epoch 30/1000 
	 loss: 389.8462, MinusLogProbMetric: 389.8462, val_loss: 396.1320, val_MinusLogProbMetric: 396.1320

Epoch 30: val_loss did not improve from 395.24454
196/196 - 29s - loss: 389.8462 - MinusLogProbMetric: 389.8462 - val_loss: 396.1320 - val_MinusLogProbMetric: 396.1320 - lr: 1.1111e-04 - 29s/epoch - 148ms/step
Epoch 31/1000
2023-09-09 23:44:38.777 
Epoch 31/1000 
	 loss: 389.4827, MinusLogProbMetric: 389.4827, val_loss: 397.4512, val_MinusLogProbMetric: 397.4512

Epoch 31: val_loss did not improve from 395.24454
196/196 - 28s - loss: 389.4827 - MinusLogProbMetric: 389.4827 - val_loss: 397.4512 - val_MinusLogProbMetric: 397.4512 - lr: 1.1111e-04 - 28s/epoch - 141ms/step
Epoch 32/1000
2023-09-09 23:45:04.165 
Epoch 32/1000 
	 loss: 389.7675, MinusLogProbMetric: 389.7675, val_loss: 395.6388, val_MinusLogProbMetric: 395.6388

Epoch 32: val_loss did not improve from 395.24454
196/196 - 25s - loss: 389.7675 - MinusLogProbMetric: 389.7675 - val_loss: 395.6388 - val_MinusLogProbMetric: 395.6388 - lr: 1.1111e-04 - 25s/epoch - 130ms/step
Epoch 33/1000
2023-09-09 23:45:27.933 
Epoch 33/1000 
	 loss: 389.5758, MinusLogProbMetric: 389.5758, val_loss: 395.4642, val_MinusLogProbMetric: 395.4642

Epoch 33: val_loss did not improve from 395.24454
196/196 - 24s - loss: 389.5758 - MinusLogProbMetric: 389.5758 - val_loss: 395.4642 - val_MinusLogProbMetric: 395.4642 - lr: 1.1111e-04 - 24s/epoch - 121ms/step
Epoch 34/1000
2023-09-09 23:45:53.426 
Epoch 34/1000 
	 loss: 389.4377, MinusLogProbMetric: 389.4377, val_loss: 395.6426, val_MinusLogProbMetric: 395.6426

Epoch 34: val_loss did not improve from 395.24454
196/196 - 26s - loss: 389.4377 - MinusLogProbMetric: 389.4377 - val_loss: 395.6426 - val_MinusLogProbMetric: 395.6426 - lr: 1.1111e-04 - 26s/epoch - 130ms/step
Epoch 35/1000
2023-09-09 23:46:17.829 
Epoch 35/1000 
	 loss: 389.5677, MinusLogProbMetric: 389.5677, val_loss: 395.6031, val_MinusLogProbMetric: 395.6031

Epoch 35: val_loss did not improve from 395.24454
196/196 - 24s - loss: 389.5677 - MinusLogProbMetric: 389.5677 - val_loss: 395.6031 - val_MinusLogProbMetric: 395.6031 - lr: 1.1111e-04 - 24s/epoch - 124ms/step
Epoch 36/1000
2023-09-09 23:46:40.660 
Epoch 36/1000 
	 loss: 389.5333, MinusLogProbMetric: 389.5333, val_loss: 396.4321, val_MinusLogProbMetric: 396.4321

Epoch 36: val_loss did not improve from 395.24454
196/196 - 23s - loss: 389.5333 - MinusLogProbMetric: 389.5333 - val_loss: 396.4321 - val_MinusLogProbMetric: 396.4321 - lr: 1.1111e-04 - 23s/epoch - 116ms/step
Epoch 37/1000
2023-09-09 23:47:04.860 
Epoch 37/1000 
	 loss: 389.4467, MinusLogProbMetric: 389.4467, val_loss: 396.4101, val_MinusLogProbMetric: 396.4101

Epoch 37: val_loss did not improve from 395.24454
196/196 - 24s - loss: 389.4467 - MinusLogProbMetric: 389.4467 - val_loss: 396.4101 - val_MinusLogProbMetric: 396.4101 - lr: 1.1111e-04 - 24s/epoch - 123ms/step
Epoch 38/1000
2023-09-09 23:47:28.032 
Epoch 38/1000 
	 loss: 389.3758, MinusLogProbMetric: 389.3758, val_loss: 397.9604, val_MinusLogProbMetric: 397.9604

Epoch 38: val_loss did not improve from 395.24454
196/196 - 23s - loss: 389.3758 - MinusLogProbMetric: 389.3758 - val_loss: 397.9604 - val_MinusLogProbMetric: 397.9604 - lr: 1.1111e-04 - 23s/epoch - 118ms/step
Epoch 39/1000
2023-09-09 23:47:50.564 
Epoch 39/1000 
	 loss: 389.4257, MinusLogProbMetric: 389.4257, val_loss: 396.3314, val_MinusLogProbMetric: 396.3314

Epoch 39: val_loss did not improve from 395.24454
196/196 - 23s - loss: 389.4257 - MinusLogProbMetric: 389.4257 - val_loss: 396.3314 - val_MinusLogProbMetric: 396.3314 - lr: 1.1111e-04 - 23s/epoch - 115ms/step
Epoch 40/1000
2023-09-09 23:48:11.028 
Epoch 40/1000 
	 loss: 389.5172, MinusLogProbMetric: 389.5172, val_loss: 396.6628, val_MinusLogProbMetric: 396.6628

Epoch 40: val_loss did not improve from 395.24454
196/196 - 20s - loss: 389.5172 - MinusLogProbMetric: 389.5172 - val_loss: 396.6628 - val_MinusLogProbMetric: 396.6628 - lr: 1.1111e-04 - 20s/epoch - 104ms/step
Epoch 41/1000
2023-09-09 23:48:31.949 
Epoch 41/1000 
	 loss: 389.4933, MinusLogProbMetric: 389.4933, val_loss: 395.5321, val_MinusLogProbMetric: 395.5321

Epoch 41: val_loss did not improve from 395.24454
196/196 - 21s - loss: 389.4933 - MinusLogProbMetric: 389.4933 - val_loss: 395.5321 - val_MinusLogProbMetric: 395.5321 - lr: 1.1111e-04 - 21s/epoch - 107ms/step
Epoch 42/1000
2023-09-09 23:48:51.711 
Epoch 42/1000 
	 loss: 389.8021, MinusLogProbMetric: 389.8021, val_loss: 400.2587, val_MinusLogProbMetric: 400.2587

Epoch 42: val_loss did not improve from 395.24454
196/196 - 20s - loss: 389.8021 - MinusLogProbMetric: 389.8021 - val_loss: 400.2587 - val_MinusLogProbMetric: 400.2587 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 43/1000
2023-09-09 23:49:11.143 
Epoch 43/1000 
	 loss: 389.4049, MinusLogProbMetric: 389.4049, val_loss: 395.7879, val_MinusLogProbMetric: 395.7879

Epoch 43: val_loss did not improve from 395.24454
196/196 - 19s - loss: 389.4049 - MinusLogProbMetric: 389.4049 - val_loss: 395.7879 - val_MinusLogProbMetric: 395.7879 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 44/1000
2023-09-09 23:49:31.343 
Epoch 44/1000 
	 loss: 389.3082, MinusLogProbMetric: 389.3082, val_loss: 395.6045, val_MinusLogProbMetric: 395.6045

Epoch 44: val_loss did not improve from 395.24454
196/196 - 20s - loss: 389.3082 - MinusLogProbMetric: 389.3082 - val_loss: 395.6045 - val_MinusLogProbMetric: 395.6045 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 45/1000
2023-09-09 23:49:52.318 
Epoch 45/1000 
	 loss: 389.2568, MinusLogProbMetric: 389.2568, val_loss: 396.2398, val_MinusLogProbMetric: 396.2398

Epoch 45: val_loss did not improve from 395.24454
196/196 - 21s - loss: 389.2568 - MinusLogProbMetric: 389.2568 - val_loss: 396.2398 - val_MinusLogProbMetric: 396.2398 - lr: 1.1111e-04 - 21s/epoch - 107ms/step
Epoch 46/1000
2023-09-09 23:50:14.622 
Epoch 46/1000 
	 loss: 389.2397, MinusLogProbMetric: 389.2397, val_loss: 395.5045, val_MinusLogProbMetric: 395.5045

Epoch 46: val_loss did not improve from 395.24454
196/196 - 22s - loss: 389.2397 - MinusLogProbMetric: 389.2397 - val_loss: 395.5045 - val_MinusLogProbMetric: 395.5045 - lr: 1.1111e-04 - 22s/epoch - 114ms/step
Epoch 47/1000
2023-09-09 23:50:35.749 
Epoch 47/1000 
	 loss: 389.1667, MinusLogProbMetric: 389.1667, val_loss: 395.1424, val_MinusLogProbMetric: 395.1424

Epoch 47: val_loss improved from 395.24454 to 395.14243, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 22s - loss: 389.1667 - MinusLogProbMetric: 389.1667 - val_loss: 395.1424 - val_MinusLogProbMetric: 395.1424 - lr: 1.1111e-04 - 22s/epoch - 113ms/step
Epoch 48/1000
2023-09-09 23:50:56.076 
Epoch 48/1000 
	 loss: 389.2405, MinusLogProbMetric: 389.2405, val_loss: 395.9340, val_MinusLogProbMetric: 395.9340

Epoch 48: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.2405 - MinusLogProbMetric: 389.2405 - val_loss: 395.9340 - val_MinusLogProbMetric: 395.9340 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 49/1000
2023-09-09 23:51:15.140 
Epoch 49/1000 
	 loss: 389.3348, MinusLogProbMetric: 389.3348, val_loss: 396.1601, val_MinusLogProbMetric: 396.1601

Epoch 49: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.3348 - MinusLogProbMetric: 389.3348 - val_loss: 396.1601 - val_MinusLogProbMetric: 396.1601 - lr: 1.1111e-04 - 19s/epoch - 97ms/step
Epoch 50/1000
2023-09-09 23:51:33.690 
Epoch 50/1000 
	 loss: 389.2167, MinusLogProbMetric: 389.2167, val_loss: 395.7786, val_MinusLogProbMetric: 395.7786

Epoch 50: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.2167 - MinusLogProbMetric: 389.2167 - val_loss: 395.7786 - val_MinusLogProbMetric: 395.7786 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 51/1000
2023-09-09 23:51:54.970 
Epoch 51/1000 
	 loss: 389.2871, MinusLogProbMetric: 389.2871, val_loss: 395.8064, val_MinusLogProbMetric: 395.8064

Epoch 51: val_loss did not improve from 395.14243
196/196 - 21s - loss: 389.2871 - MinusLogProbMetric: 389.2871 - val_loss: 395.8064 - val_MinusLogProbMetric: 395.8064 - lr: 1.1111e-04 - 21s/epoch - 109ms/step
Epoch 52/1000
2023-09-09 23:52:14.858 
Epoch 52/1000 
	 loss: 388.9626, MinusLogProbMetric: 388.9626, val_loss: 397.4750, val_MinusLogProbMetric: 397.4750

Epoch 52: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.9626 - MinusLogProbMetric: 388.9626 - val_loss: 397.4750 - val_MinusLogProbMetric: 397.4750 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 53/1000
2023-09-09 23:52:35.184 
Epoch 53/1000 
	 loss: 389.3101, MinusLogProbMetric: 389.3101, val_loss: 395.1669, val_MinusLogProbMetric: 395.1669

Epoch 53: val_loss did not improve from 395.14243
196/196 - 20s - loss: 389.3101 - MinusLogProbMetric: 389.3101 - val_loss: 395.1669 - val_MinusLogProbMetric: 395.1669 - lr: 1.1111e-04 - 20s/epoch - 104ms/step
Epoch 54/1000
2023-09-09 23:52:53.857 
Epoch 54/1000 
	 loss: 389.2657, MinusLogProbMetric: 389.2657, val_loss: 395.4114, val_MinusLogProbMetric: 395.4114

Epoch 54: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.2657 - MinusLogProbMetric: 389.2657 - val_loss: 395.4114 - val_MinusLogProbMetric: 395.4114 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 55/1000
2023-09-09 23:53:11.378 
Epoch 55/1000 
	 loss: 389.2665, MinusLogProbMetric: 389.2665, val_loss: 395.8423, val_MinusLogProbMetric: 395.8423

Epoch 55: val_loss did not improve from 395.14243
196/196 - 18s - loss: 389.2665 - MinusLogProbMetric: 389.2665 - val_loss: 395.8423 - val_MinusLogProbMetric: 395.8423 - lr: 1.1111e-04 - 18s/epoch - 89ms/step
Epoch 56/1000
2023-09-09 23:53:31.008 
Epoch 56/1000 
	 loss: 389.1304, MinusLogProbMetric: 389.1304, val_loss: 396.6531, val_MinusLogProbMetric: 396.6531

Epoch 56: val_loss did not improve from 395.14243
196/196 - 20s - loss: 389.1304 - MinusLogProbMetric: 389.1304 - val_loss: 396.6531 - val_MinusLogProbMetric: 396.6531 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 57/1000
2023-09-09 23:53:49.206 
Epoch 57/1000 
	 loss: 388.9573, MinusLogProbMetric: 388.9573, val_loss: 397.2293, val_MinusLogProbMetric: 397.2293

Epoch 57: val_loss did not improve from 395.14243
196/196 - 18s - loss: 388.9573 - MinusLogProbMetric: 388.9573 - val_loss: 397.2293 - val_MinusLogProbMetric: 397.2293 - lr: 1.1111e-04 - 18s/epoch - 93ms/step
Epoch 58/1000
2023-09-09 23:54:08.665 
Epoch 58/1000 
	 loss: 388.8454, MinusLogProbMetric: 388.8454, val_loss: 395.7068, val_MinusLogProbMetric: 395.7068

Epoch 58: val_loss did not improve from 395.14243
196/196 - 19s - loss: 388.8454 - MinusLogProbMetric: 388.8454 - val_loss: 395.7068 - val_MinusLogProbMetric: 395.7068 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 59/1000
2023-09-09 23:54:27.575 
Epoch 59/1000 
	 loss: 389.1624, MinusLogProbMetric: 389.1624, val_loss: 395.3912, val_MinusLogProbMetric: 395.3912

Epoch 59: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.1624 - MinusLogProbMetric: 389.1624 - val_loss: 395.3912 - val_MinusLogProbMetric: 395.3912 - lr: 1.1111e-04 - 19s/epoch - 96ms/step
Epoch 60/1000
2023-09-09 23:54:46.810 
Epoch 60/1000 
	 loss: 389.4435, MinusLogProbMetric: 389.4435, val_loss: 395.2314, val_MinusLogProbMetric: 395.2314

Epoch 60: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.4435 - MinusLogProbMetric: 389.4435 - val_loss: 395.2314 - val_MinusLogProbMetric: 395.2314 - lr: 1.1111e-04 - 19s/epoch - 98ms/step
Epoch 61/1000
2023-09-09 23:55:06.118 
Epoch 61/1000 
	 loss: 388.9428, MinusLogProbMetric: 388.9428, val_loss: 396.9258, val_MinusLogProbMetric: 396.9258

Epoch 61: val_loss did not improve from 395.14243
196/196 - 19s - loss: 388.9428 - MinusLogProbMetric: 388.9428 - val_loss: 396.9258 - val_MinusLogProbMetric: 396.9258 - lr: 1.1111e-04 - 19s/epoch - 98ms/step
Epoch 62/1000
2023-09-09 23:55:26.062 
Epoch 62/1000 
	 loss: 388.9104, MinusLogProbMetric: 388.9104, val_loss: 395.9789, val_MinusLogProbMetric: 395.9789

Epoch 62: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.9104 - MinusLogProbMetric: 388.9104 - val_loss: 395.9789 - val_MinusLogProbMetric: 395.9789 - lr: 1.1111e-04 - 20s/epoch - 102ms/step
Epoch 63/1000
2023-09-09 23:55:46.110 
Epoch 63/1000 
	 loss: 388.9260, MinusLogProbMetric: 388.9260, val_loss: 396.2555, val_MinusLogProbMetric: 396.2555

Epoch 63: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.9260 - MinusLogProbMetric: 388.9260 - val_loss: 396.2555 - val_MinusLogProbMetric: 396.2555 - lr: 1.1111e-04 - 20s/epoch - 102ms/step
Epoch 64/1000
2023-09-09 23:56:06.148 
Epoch 64/1000 
	 loss: 389.1370, MinusLogProbMetric: 389.1370, val_loss: 395.8469, val_MinusLogProbMetric: 395.8469

Epoch 64: val_loss did not improve from 395.14243
196/196 - 20s - loss: 389.1370 - MinusLogProbMetric: 389.1370 - val_loss: 395.8469 - val_MinusLogProbMetric: 395.8469 - lr: 1.1111e-04 - 20s/epoch - 102ms/step
Epoch 65/1000
2023-09-09 23:56:27.032 
Epoch 65/1000 
	 loss: 389.0204, MinusLogProbMetric: 389.0204, val_loss: 395.3101, val_MinusLogProbMetric: 395.3101

Epoch 65: val_loss did not improve from 395.14243
196/196 - 21s - loss: 389.0204 - MinusLogProbMetric: 389.0204 - val_loss: 395.3101 - val_MinusLogProbMetric: 395.3101 - lr: 1.1111e-04 - 21s/epoch - 106ms/step
Epoch 66/1000
2023-09-09 23:56:47.330 
Epoch 66/1000 
	 loss: 388.8147, MinusLogProbMetric: 388.8147, val_loss: 395.9357, val_MinusLogProbMetric: 395.9357

Epoch 66: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.8147 - MinusLogProbMetric: 388.8147 - val_loss: 395.9357 - val_MinusLogProbMetric: 395.9357 - lr: 1.1111e-04 - 20s/epoch - 104ms/step
Epoch 67/1000
2023-09-09 23:57:06.295 
Epoch 67/1000 
	 loss: 389.1405, MinusLogProbMetric: 389.1405, val_loss: 396.6944, val_MinusLogProbMetric: 396.6944

Epoch 67: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.1405 - MinusLogProbMetric: 389.1405 - val_loss: 396.6944 - val_MinusLogProbMetric: 396.6944 - lr: 1.1111e-04 - 19s/epoch - 97ms/step
Epoch 68/1000
2023-09-09 23:57:26.522 
Epoch 68/1000 
	 loss: 389.1419, MinusLogProbMetric: 389.1419, val_loss: 396.1989, val_MinusLogProbMetric: 396.1989

Epoch 68: val_loss did not improve from 395.14243
196/196 - 20s - loss: 389.1419 - MinusLogProbMetric: 389.1419 - val_loss: 396.1989 - val_MinusLogProbMetric: 396.1989 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 69/1000
2023-09-09 23:57:47.358 
Epoch 69/1000 
	 loss: 388.9926, MinusLogProbMetric: 388.9926, val_loss: 396.0402, val_MinusLogProbMetric: 396.0402

Epoch 69: val_loss did not improve from 395.14243
196/196 - 21s - loss: 388.9926 - MinusLogProbMetric: 388.9926 - val_loss: 396.0402 - val_MinusLogProbMetric: 396.0402 - lr: 1.1111e-04 - 21s/epoch - 106ms/step
Epoch 70/1000
2023-09-09 23:58:07.637 
Epoch 70/1000 
	 loss: 388.7289, MinusLogProbMetric: 388.7289, val_loss: 395.9913, val_MinusLogProbMetric: 395.9913

Epoch 70: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.7289 - MinusLogProbMetric: 388.7289 - val_loss: 395.9913 - val_MinusLogProbMetric: 395.9913 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 71/1000
2023-09-09 23:58:28.474 
Epoch 71/1000 
	 loss: 389.0034, MinusLogProbMetric: 389.0034, val_loss: 395.7172, val_MinusLogProbMetric: 395.7172

Epoch 71: val_loss did not improve from 395.14243
196/196 - 21s - loss: 389.0034 - MinusLogProbMetric: 389.0034 - val_loss: 395.7172 - val_MinusLogProbMetric: 395.7172 - lr: 1.1111e-04 - 21s/epoch - 106ms/step
Epoch 72/1000
2023-09-09 23:58:48.641 
Epoch 72/1000 
	 loss: 388.9225, MinusLogProbMetric: 388.9225, val_loss: 395.5589, val_MinusLogProbMetric: 395.5589

Epoch 72: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.9225 - MinusLogProbMetric: 388.9225 - val_loss: 395.5589 - val_MinusLogProbMetric: 395.5589 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 73/1000
2023-09-09 23:59:07.366 
Epoch 73/1000 
	 loss: 389.3654, MinusLogProbMetric: 389.3654, val_loss: 395.6560, val_MinusLogProbMetric: 395.6560

Epoch 73: val_loss did not improve from 395.14243
196/196 - 19s - loss: 389.3654 - MinusLogProbMetric: 389.3654 - val_loss: 395.6560 - val_MinusLogProbMetric: 395.6560 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 74/1000
2023-09-09 23:59:27.136 
Epoch 74/1000 
	 loss: 388.6215, MinusLogProbMetric: 388.6215, val_loss: 395.6841, val_MinusLogProbMetric: 395.6841

Epoch 74: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.6215 - MinusLogProbMetric: 388.6215 - val_loss: 395.6841 - val_MinusLogProbMetric: 395.6841 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 75/1000
2023-09-09 23:59:47.167 
Epoch 75/1000 
	 loss: 388.9647, MinusLogProbMetric: 388.9647, val_loss: 395.4772, val_MinusLogProbMetric: 395.4772

Epoch 75: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.9647 - MinusLogProbMetric: 388.9647 - val_loss: 395.4772 - val_MinusLogProbMetric: 395.4772 - lr: 1.1111e-04 - 20s/epoch - 102ms/step
Epoch 76/1000
2023-09-10 00:00:07.626 
Epoch 76/1000 
	 loss: 388.5867, MinusLogProbMetric: 388.5867, val_loss: 395.8968, val_MinusLogProbMetric: 395.8968

Epoch 76: val_loss did not improve from 395.14243
196/196 - 20s - loss: 388.5867 - MinusLogProbMetric: 388.5867 - val_loss: 395.8968 - val_MinusLogProbMetric: 395.8968 - lr: 1.1111e-04 - 20s/epoch - 104ms/step
Epoch 77/1000
2023-09-10 00:00:26.708 
Epoch 77/1000 
	 loss: 388.8688, MinusLogProbMetric: 388.8688, val_loss: 395.8185, val_MinusLogProbMetric: 395.8185

Epoch 77: val_loss did not improve from 395.14243
196/196 - 19s - loss: 388.8688 - MinusLogProbMetric: 388.8688 - val_loss: 395.8185 - val_MinusLogProbMetric: 395.8185 - lr: 1.1111e-04 - 19s/epoch - 97ms/step
Epoch 78/1000
2023-09-10 00:00:45.550 
Epoch 78/1000 
	 loss: 388.7385, MinusLogProbMetric: 388.7385, val_loss: 395.8133, val_MinusLogProbMetric: 395.8133

Epoch 78: val_loss did not improve from 395.14243
196/196 - 19s - loss: 388.7385 - MinusLogProbMetric: 388.7385 - val_loss: 395.8133 - val_MinusLogProbMetric: 395.8133 - lr: 1.1111e-04 - 19s/epoch - 96ms/step
Epoch 79/1000
2023-09-10 00:01:04.088 
Epoch 79/1000 
	 loss: 388.8444, MinusLogProbMetric: 388.8444, val_loss: 395.6222, val_MinusLogProbMetric: 395.6222

Epoch 79: val_loss did not improve from 395.14243
196/196 - 19s - loss: 388.8444 - MinusLogProbMetric: 388.8444 - val_loss: 395.6222 - val_MinusLogProbMetric: 395.6222 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 80/1000
2023-09-10 00:01:23.505 
Epoch 80/1000 
	 loss: 388.8882, MinusLogProbMetric: 388.8882, val_loss: 394.9425, val_MinusLogProbMetric: 394.9425

Epoch 80: val_loss improved from 395.14243 to 394.94247, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 20s - loss: 388.8882 - MinusLogProbMetric: 388.8882 - val_loss: 394.9425 - val_MinusLogProbMetric: 394.9425 - lr: 1.1111e-04 - 20s/epoch - 102ms/step
Epoch 81/1000
2023-09-10 00:01:43.453 
Epoch 81/1000 
	 loss: 388.4646, MinusLogProbMetric: 388.4646, val_loss: 396.1175, val_MinusLogProbMetric: 396.1175

Epoch 81: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.4646 - MinusLogProbMetric: 388.4646 - val_loss: 396.1175 - val_MinusLogProbMetric: 396.1175 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 82/1000
2023-09-10 00:02:03.322 
Epoch 82/1000 
	 loss: 388.6378, MinusLogProbMetric: 388.6378, val_loss: 395.7064, val_MinusLogProbMetric: 395.7064

Epoch 82: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.6378 - MinusLogProbMetric: 388.6378 - val_loss: 395.7064 - val_MinusLogProbMetric: 395.7064 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 83/1000
2023-09-10 00:02:23.125 
Epoch 83/1000 
	 loss: 388.4134, MinusLogProbMetric: 388.4134, val_loss: 396.8024, val_MinusLogProbMetric: 396.8024

Epoch 83: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.4134 - MinusLogProbMetric: 388.4134 - val_loss: 396.8024 - val_MinusLogProbMetric: 396.8024 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 84/1000
2023-09-10 00:02:42.260 
Epoch 84/1000 
	 loss: 388.6774, MinusLogProbMetric: 388.6774, val_loss: 395.9169, val_MinusLogProbMetric: 395.9169

Epoch 84: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.6774 - MinusLogProbMetric: 388.6774 - val_loss: 395.9169 - val_MinusLogProbMetric: 395.9169 - lr: 1.1111e-04 - 19s/epoch - 98ms/step
Epoch 85/1000
2023-09-10 00:03:01.873 
Epoch 85/1000 
	 loss: 388.7908, MinusLogProbMetric: 388.7908, val_loss: 396.0831, val_MinusLogProbMetric: 396.0831

Epoch 85: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.7908 - MinusLogProbMetric: 388.7908 - val_loss: 396.0831 - val_MinusLogProbMetric: 396.0831 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 86/1000
2023-09-10 00:03:21.516 
Epoch 86/1000 
	 loss: 388.5044, MinusLogProbMetric: 388.5044, val_loss: 395.7123, val_MinusLogProbMetric: 395.7123

Epoch 86: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.5044 - MinusLogProbMetric: 388.5044 - val_loss: 395.7123 - val_MinusLogProbMetric: 395.7123 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 87/1000
2023-09-10 00:03:40.958 
Epoch 87/1000 
	 loss: 389.0055, MinusLogProbMetric: 389.0055, val_loss: 396.7122, val_MinusLogProbMetric: 396.7122

Epoch 87: val_loss did not improve from 394.94247
196/196 - 19s - loss: 389.0055 - MinusLogProbMetric: 389.0055 - val_loss: 396.7122 - val_MinusLogProbMetric: 396.7122 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 88/1000
2023-09-10 00:03:59.437 
Epoch 88/1000 
	 loss: 388.5645, MinusLogProbMetric: 388.5645, val_loss: 396.5673, val_MinusLogProbMetric: 396.5673

Epoch 88: val_loss did not improve from 394.94247
196/196 - 18s - loss: 388.5645 - MinusLogProbMetric: 388.5645 - val_loss: 396.5673 - val_MinusLogProbMetric: 396.5673 - lr: 1.1111e-04 - 18s/epoch - 94ms/step
Epoch 89/1000
2023-09-10 00:04:19.599 
Epoch 89/1000 
	 loss: 388.4216, MinusLogProbMetric: 388.4216, val_loss: 397.4936, val_MinusLogProbMetric: 397.4936

Epoch 89: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.4216 - MinusLogProbMetric: 388.4216 - val_loss: 397.4936 - val_MinusLogProbMetric: 397.4936 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 90/1000
2023-09-10 00:04:39.033 
Epoch 90/1000 
	 loss: 388.4668, MinusLogProbMetric: 388.4668, val_loss: 396.4605, val_MinusLogProbMetric: 396.4605

Epoch 90: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.4668 - MinusLogProbMetric: 388.4668 - val_loss: 396.4605 - val_MinusLogProbMetric: 396.4605 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 91/1000
2023-09-10 00:04:57.711 
Epoch 91/1000 
	 loss: 388.5168, MinusLogProbMetric: 388.5168, val_loss: 396.6498, val_MinusLogProbMetric: 396.6498

Epoch 91: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.5168 - MinusLogProbMetric: 388.5168 - val_loss: 396.6498 - val_MinusLogProbMetric: 396.6498 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 92/1000
2023-09-10 00:05:16.336 
Epoch 92/1000 
	 loss: 388.5620, MinusLogProbMetric: 388.5620, val_loss: 397.0429, val_MinusLogProbMetric: 397.0429

Epoch 92: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.5620 - MinusLogProbMetric: 388.5620 - val_loss: 397.0429 - val_MinusLogProbMetric: 397.0429 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 93/1000
2023-09-10 00:05:35.780 
Epoch 93/1000 
	 loss: 388.4071, MinusLogProbMetric: 388.4071, val_loss: 396.3857, val_MinusLogProbMetric: 396.3857

Epoch 93: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.4071 - MinusLogProbMetric: 388.4071 - val_loss: 396.3857 - val_MinusLogProbMetric: 396.3857 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 94/1000
2023-09-10 00:05:54.500 
Epoch 94/1000 
	 loss: 388.5864, MinusLogProbMetric: 388.5864, val_loss: 396.6101, val_MinusLogProbMetric: 396.6101

Epoch 94: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.5864 - MinusLogProbMetric: 388.5864 - val_loss: 396.6101 - val_MinusLogProbMetric: 396.6101 - lr: 1.1111e-04 - 19s/epoch - 96ms/step
Epoch 95/1000
2023-09-10 00:06:12.571 
Epoch 95/1000 
	 loss: 388.6361, MinusLogProbMetric: 388.6361, val_loss: 397.5540, val_MinusLogProbMetric: 397.5540

Epoch 95: val_loss did not improve from 394.94247
196/196 - 18s - loss: 388.6361 - MinusLogProbMetric: 388.6361 - val_loss: 397.5540 - val_MinusLogProbMetric: 397.5540 - lr: 1.1111e-04 - 18s/epoch - 92ms/step
Epoch 96/1000
2023-09-10 00:06:32.100 
Epoch 96/1000 
	 loss: 388.2393, MinusLogProbMetric: 388.2393, val_loss: 396.6670, val_MinusLogProbMetric: 396.6670

Epoch 96: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.2393 - MinusLogProbMetric: 388.2393 - val_loss: 396.6670 - val_MinusLogProbMetric: 396.6670 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 97/1000
2023-09-10 00:06:53.075 
Epoch 97/1000 
	 loss: 388.4992, MinusLogProbMetric: 388.4992, val_loss: 397.9954, val_MinusLogProbMetric: 397.9954

Epoch 97: val_loss did not improve from 394.94247
196/196 - 21s - loss: 388.4992 - MinusLogProbMetric: 388.4992 - val_loss: 397.9954 - val_MinusLogProbMetric: 397.9954 - lr: 1.1111e-04 - 21s/epoch - 107ms/step
Epoch 98/1000
2023-09-10 00:07:14.400 
Epoch 98/1000 
	 loss: 388.3624, MinusLogProbMetric: 388.3624, val_loss: 396.0606, val_MinusLogProbMetric: 396.0606

Epoch 98: val_loss did not improve from 394.94247
196/196 - 21s - loss: 388.3624 - MinusLogProbMetric: 388.3624 - val_loss: 396.0606 - val_MinusLogProbMetric: 396.0606 - lr: 1.1111e-04 - 21s/epoch - 109ms/step
Epoch 99/1000
2023-09-10 00:07:32.439 
Epoch 99/1000 
	 loss: 388.5139, MinusLogProbMetric: 388.5139, val_loss: 396.3317, val_MinusLogProbMetric: 396.3317

Epoch 99: val_loss did not improve from 394.94247
196/196 - 18s - loss: 388.5139 - MinusLogProbMetric: 388.5139 - val_loss: 396.3317 - val_MinusLogProbMetric: 396.3317 - lr: 1.1111e-04 - 18s/epoch - 92ms/step
Epoch 100/1000
2023-09-10 00:07:51.966 
Epoch 100/1000 
	 loss: 388.5549, MinusLogProbMetric: 388.5549, val_loss: 396.8292, val_MinusLogProbMetric: 396.8292

Epoch 100: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.5549 - MinusLogProbMetric: 388.5549 - val_loss: 396.8292 - val_MinusLogProbMetric: 396.8292 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 101/1000
2023-09-10 00:08:10.968 
Epoch 101/1000 
	 loss: 388.2619, MinusLogProbMetric: 388.2619, val_loss: 397.5385, val_MinusLogProbMetric: 397.5385

Epoch 101: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.2619 - MinusLogProbMetric: 388.2619 - val_loss: 397.5385 - val_MinusLogProbMetric: 397.5385 - lr: 1.1111e-04 - 19s/epoch - 97ms/step
Epoch 102/1000
2023-09-10 00:08:29.872 
Epoch 102/1000 
	 loss: 388.4127, MinusLogProbMetric: 388.4127, val_loss: 396.3492, val_MinusLogProbMetric: 396.3492

Epoch 102: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.4127 - MinusLogProbMetric: 388.4127 - val_loss: 396.3492 - val_MinusLogProbMetric: 396.3492 - lr: 1.1111e-04 - 19s/epoch - 96ms/step
Epoch 103/1000
2023-09-10 00:08:49.386 
Epoch 103/1000 
	 loss: 388.5882, MinusLogProbMetric: 388.5882, val_loss: 400.7494, val_MinusLogProbMetric: 400.7494

Epoch 103: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.5882 - MinusLogProbMetric: 388.5882 - val_loss: 400.7494 - val_MinusLogProbMetric: 400.7494 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 104/1000
2023-09-10 00:09:09.188 
Epoch 104/1000 
	 loss: 388.4672, MinusLogProbMetric: 388.4672, val_loss: 396.0247, val_MinusLogProbMetric: 396.0247

Epoch 104: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.4672 - MinusLogProbMetric: 388.4672 - val_loss: 396.0247 - val_MinusLogProbMetric: 396.0247 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 105/1000
2023-09-10 00:09:29.469 
Epoch 105/1000 
	 loss: 388.2390, MinusLogProbMetric: 388.2390, val_loss: 397.1443, val_MinusLogProbMetric: 397.1443

Epoch 105: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.2390 - MinusLogProbMetric: 388.2390 - val_loss: 397.1443 - val_MinusLogProbMetric: 397.1443 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 106/1000
2023-09-10 00:09:49.768 
Epoch 106/1000 
	 loss: 388.3094, MinusLogProbMetric: 388.3094, val_loss: 396.2738, val_MinusLogProbMetric: 396.2738

Epoch 106: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.3094 - MinusLogProbMetric: 388.3094 - val_loss: 396.2738 - val_MinusLogProbMetric: 396.2738 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 107/1000
2023-09-10 00:10:09.362 
Epoch 107/1000 
	 loss: 388.3616, MinusLogProbMetric: 388.3616, val_loss: 397.2640, val_MinusLogProbMetric: 397.2640

Epoch 107: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.3616 - MinusLogProbMetric: 388.3616 - val_loss: 397.2640 - val_MinusLogProbMetric: 397.2640 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 108/1000
2023-09-10 00:10:27.725 
Epoch 108/1000 
	 loss: 388.4851, MinusLogProbMetric: 388.4851, val_loss: 396.1107, val_MinusLogProbMetric: 396.1107

Epoch 108: val_loss did not improve from 394.94247
196/196 - 18s - loss: 388.4851 - MinusLogProbMetric: 388.4851 - val_loss: 396.1107 - val_MinusLogProbMetric: 396.1107 - lr: 1.1111e-04 - 18s/epoch - 94ms/step
Epoch 109/1000
2023-09-10 00:10:47.434 
Epoch 109/1000 
	 loss: 388.2101, MinusLogProbMetric: 388.2101, val_loss: 395.3283, val_MinusLogProbMetric: 395.3283

Epoch 109: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.2101 - MinusLogProbMetric: 388.2101 - val_loss: 395.3283 - val_MinusLogProbMetric: 395.3283 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 110/1000
2023-09-10 00:11:06.862 
Epoch 110/1000 
	 loss: 388.2575, MinusLogProbMetric: 388.2575, val_loss: 396.9839, val_MinusLogProbMetric: 396.9839

Epoch 110: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.2575 - MinusLogProbMetric: 388.2575 - val_loss: 396.9839 - val_MinusLogProbMetric: 396.9839 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 111/1000
2023-09-10 00:11:26.508 
Epoch 111/1000 
	 loss: 388.1916, MinusLogProbMetric: 388.1916, val_loss: 400.2334, val_MinusLogProbMetric: 400.2334

Epoch 111: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.1916 - MinusLogProbMetric: 388.1916 - val_loss: 400.2334 - val_MinusLogProbMetric: 400.2334 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 112/1000
2023-09-10 00:11:45.868 
Epoch 112/1000 
	 loss: 388.1937, MinusLogProbMetric: 388.1937, val_loss: 397.6795, val_MinusLogProbMetric: 397.6795

Epoch 112: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.1937 - MinusLogProbMetric: 388.1937 - val_loss: 397.6795 - val_MinusLogProbMetric: 397.6795 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 113/1000
2023-09-10 00:12:04.574 
Epoch 113/1000 
	 loss: 388.3110, MinusLogProbMetric: 388.3110, val_loss: 398.3489, val_MinusLogProbMetric: 398.3489

Epoch 113: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.3110 - MinusLogProbMetric: 388.3110 - val_loss: 398.3489 - val_MinusLogProbMetric: 398.3489 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 114/1000
2023-09-10 00:12:24.268 
Epoch 114/1000 
	 loss: 388.7793, MinusLogProbMetric: 388.7793, val_loss: 396.5462, val_MinusLogProbMetric: 396.5462

Epoch 114: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.7793 - MinusLogProbMetric: 388.7793 - val_loss: 396.5462 - val_MinusLogProbMetric: 396.5462 - lr: 1.1111e-04 - 20s/epoch - 101ms/step
Epoch 115/1000
2023-09-10 00:12:44.201 
Epoch 115/1000 
	 loss: 388.2222, MinusLogProbMetric: 388.2222, val_loss: 395.5417, val_MinusLogProbMetric: 395.5417

Epoch 115: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.2222 - MinusLogProbMetric: 388.2222 - val_loss: 395.5417 - val_MinusLogProbMetric: 395.5417 - lr: 1.1111e-04 - 20s/epoch - 102ms/step
Epoch 116/1000
2023-09-10 00:13:03.708 
Epoch 116/1000 
	 loss: 388.3260, MinusLogProbMetric: 388.3260, val_loss: 399.3572, val_MinusLogProbMetric: 399.3572

Epoch 116: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.3260 - MinusLogProbMetric: 388.3260 - val_loss: 399.3572 - val_MinusLogProbMetric: 399.3572 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 117/1000
2023-09-10 00:13:23.184 
Epoch 117/1000 
	 loss: 388.2886, MinusLogProbMetric: 388.2886, val_loss: 398.0616, val_MinusLogProbMetric: 398.0616

Epoch 117: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.2886 - MinusLogProbMetric: 388.2886 - val_loss: 398.0616 - val_MinusLogProbMetric: 398.0616 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 118/1000
2023-09-10 00:13:42.801 
Epoch 118/1000 
	 loss: 388.0623, MinusLogProbMetric: 388.0623, val_loss: 396.1967, val_MinusLogProbMetric: 396.1967

Epoch 118: val_loss did not improve from 394.94247
196/196 - 20s - loss: 388.0623 - MinusLogProbMetric: 388.0623 - val_loss: 396.1967 - val_MinusLogProbMetric: 396.1967 - lr: 1.1111e-04 - 20s/epoch - 100ms/step
Epoch 119/1000
2023-09-10 00:14:02.215 
Epoch 119/1000 
	 loss: 388.0907, MinusLogProbMetric: 388.0907, val_loss: 397.4130, val_MinusLogProbMetric: 397.4130

Epoch 119: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.0907 - MinusLogProbMetric: 388.0907 - val_loss: 397.4130 - val_MinusLogProbMetric: 397.4130 - lr: 1.1111e-04 - 19s/epoch - 99ms/step
Epoch 120/1000
2023-09-10 00:14:20.002 
Epoch 120/1000 
	 loss: 388.6435, MinusLogProbMetric: 388.6435, val_loss: 395.9404, val_MinusLogProbMetric: 395.9404

Epoch 120: val_loss did not improve from 394.94247
196/196 - 18s - loss: 388.6435 - MinusLogProbMetric: 388.6435 - val_loss: 395.9404 - val_MinusLogProbMetric: 395.9404 - lr: 1.1111e-04 - 18s/epoch - 91ms/step
Epoch 121/1000
2023-09-10 00:14:38.284 
Epoch 121/1000 
	 loss: 387.8990, MinusLogProbMetric: 387.8990, val_loss: 396.5376, val_MinusLogProbMetric: 396.5376

Epoch 121: val_loss did not improve from 394.94247
196/196 - 18s - loss: 387.8990 - MinusLogProbMetric: 387.8990 - val_loss: 396.5376 - val_MinusLogProbMetric: 396.5376 - lr: 1.1111e-04 - 18s/epoch - 93ms/step
Epoch 122/1000
2023-09-10 00:14:57.602 
Epoch 122/1000 
	 loss: 388.0681, MinusLogProbMetric: 388.0681, val_loss: 398.1357, val_MinusLogProbMetric: 398.1357

Epoch 122: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.0681 - MinusLogProbMetric: 388.0681 - val_loss: 398.1357 - val_MinusLogProbMetric: 398.1357 - lr: 1.1111e-04 - 19s/epoch - 98ms/step
Epoch 123/1000
2023-09-10 00:15:16.328 
Epoch 123/1000 
	 loss: 388.0910, MinusLogProbMetric: 388.0910, val_loss: 396.1419, val_MinusLogProbMetric: 396.1419

Epoch 123: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.0910 - MinusLogProbMetric: 388.0910 - val_loss: 396.1419 - val_MinusLogProbMetric: 396.1419 - lr: 1.1111e-04 - 19s/epoch - 96ms/step
Epoch 124/1000
2023-09-10 00:15:35.033 
Epoch 124/1000 
	 loss: 388.3260, MinusLogProbMetric: 388.3260, val_loss: 396.4174, val_MinusLogProbMetric: 396.4174

Epoch 124: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.3260 - MinusLogProbMetric: 388.3260 - val_loss: 396.4174 - val_MinusLogProbMetric: 396.4174 - lr: 1.1111e-04 - 19s/epoch - 95ms/step
Epoch 125/1000
2023-09-10 00:15:55.268 
Epoch 125/1000 
	 loss: 387.9613, MinusLogProbMetric: 387.9613, val_loss: 397.3556, val_MinusLogProbMetric: 397.3556

Epoch 125: val_loss did not improve from 394.94247
196/196 - 20s - loss: 387.9613 - MinusLogProbMetric: 387.9613 - val_loss: 397.3556 - val_MinusLogProbMetric: 397.3556 - lr: 1.1111e-04 - 20s/epoch - 103ms/step
Epoch 126/1000
2023-09-10 00:16:14.536 
Epoch 126/1000 
	 loss: 388.8703, MinusLogProbMetric: 388.8703, val_loss: 399.2426, val_MinusLogProbMetric: 399.2426

Epoch 126: val_loss did not improve from 394.94247
196/196 - 19s - loss: 388.8703 - MinusLogProbMetric: 388.8703 - val_loss: 399.2426 - val_MinusLogProbMetric: 399.2426 - lr: 1.1111e-04 - 19s/epoch - 98ms/step
Epoch 127/1000
2023-09-10 00:16:32.600 
Epoch 127/1000 
	 loss: 387.8159, MinusLogProbMetric: 387.8159, val_loss: 397.8153, val_MinusLogProbMetric: 397.8153

Epoch 127: val_loss did not improve from 394.94247
196/196 - 18s - loss: 387.8159 - MinusLogProbMetric: 387.8159 - val_loss: 397.8153 - val_MinusLogProbMetric: 397.8153 - lr: 1.1111e-04 - 18s/epoch - 92ms/step
Epoch 128/1000
2023-09-10 00:16:53.820 
Epoch 128/1000 
	 loss: 387.9677, MinusLogProbMetric: 387.9677, val_loss: 397.7389, val_MinusLogProbMetric: 397.7389

Epoch 128: val_loss did not improve from 394.94247
196/196 - 21s - loss: 387.9677 - MinusLogProbMetric: 387.9677 - val_loss: 397.7389 - val_MinusLogProbMetric: 397.7389 - lr: 1.1111e-04 - 21s/epoch - 108ms/step
Epoch 129/1000
2023-09-10 00:17:11.281 
Epoch 129/1000 
	 loss: 387.8877, MinusLogProbMetric: 387.8877, val_loss: 396.4756, val_MinusLogProbMetric: 396.4756

Epoch 129: val_loss did not improve from 394.94247
196/196 - 17s - loss: 387.8877 - MinusLogProbMetric: 387.8877 - val_loss: 396.4756 - val_MinusLogProbMetric: 396.4756 - lr: 1.1111e-04 - 17s/epoch - 89ms/step
Epoch 130/1000
2023-09-10 00:17:29.674 
Epoch 130/1000 
	 loss: 388.0696, MinusLogProbMetric: 388.0696, val_loss: 396.3510, val_MinusLogProbMetric: 396.3510

Epoch 130: val_loss did not improve from 394.94247
196/196 - 18s - loss: 388.0696 - MinusLogProbMetric: 388.0696 - val_loss: 396.3510 - val_MinusLogProbMetric: 396.3510 - lr: 1.1111e-04 - 18s/epoch - 94ms/step
Epoch 131/1000
2023-09-10 00:17:50.188 
Epoch 131/1000 
	 loss: 385.8260, MinusLogProbMetric: 385.8260, val_loss: 394.5038, val_MinusLogProbMetric: 394.5038

Epoch 131: val_loss improved from 394.94247 to 394.50381, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 21s - loss: 385.8260 - MinusLogProbMetric: 385.8260 - val_loss: 394.5038 - val_MinusLogProbMetric: 394.5038 - lr: 5.5556e-05 - 21s/epoch - 108ms/step
Epoch 132/1000
2023-09-10 00:18:10.806 
Epoch 132/1000 
	 loss: 385.6463, MinusLogProbMetric: 385.6463, val_loss: 394.7760, val_MinusLogProbMetric: 394.7760

Epoch 132: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.6463 - MinusLogProbMetric: 385.6463 - val_loss: 394.7760 - val_MinusLogProbMetric: 394.7760 - lr: 5.5556e-05 - 20s/epoch - 102ms/step
Epoch 133/1000
2023-09-10 00:18:30.226 
Epoch 133/1000 
	 loss: 385.7597, MinusLogProbMetric: 385.7597, val_loss: 394.8221, val_MinusLogProbMetric: 394.8221

Epoch 133: val_loss did not improve from 394.50381
196/196 - 19s - loss: 385.7597 - MinusLogProbMetric: 385.7597 - val_loss: 394.8221 - val_MinusLogProbMetric: 394.8221 - lr: 5.5556e-05 - 19s/epoch - 99ms/step
Epoch 134/1000
2023-09-10 00:18:49.296 
Epoch 134/1000 
	 loss: 385.8714, MinusLogProbMetric: 385.8714, val_loss: 395.0243, val_MinusLogProbMetric: 395.0243

Epoch 134: val_loss did not improve from 394.50381
196/196 - 19s - loss: 385.8714 - MinusLogProbMetric: 385.8714 - val_loss: 395.0243 - val_MinusLogProbMetric: 395.0243 - lr: 5.5556e-05 - 19s/epoch - 97ms/step
Epoch 135/1000
2023-09-10 00:19:07.187 
Epoch 135/1000 
	 loss: 385.9565, MinusLogProbMetric: 385.9565, val_loss: 395.1275, val_MinusLogProbMetric: 395.1275

Epoch 135: val_loss did not improve from 394.50381
196/196 - 18s - loss: 385.9565 - MinusLogProbMetric: 385.9565 - val_loss: 395.1275 - val_MinusLogProbMetric: 395.1275 - lr: 5.5556e-05 - 18s/epoch - 91ms/step
Epoch 136/1000
2023-09-10 00:19:25.668 
Epoch 136/1000 
	 loss: 386.0019, MinusLogProbMetric: 386.0019, val_loss: 394.8423, val_MinusLogProbMetric: 394.8423

Epoch 136: val_loss did not improve from 394.50381
196/196 - 18s - loss: 386.0019 - MinusLogProbMetric: 386.0019 - val_loss: 394.8423 - val_MinusLogProbMetric: 394.8423 - lr: 5.5556e-05 - 18s/epoch - 94ms/step
Epoch 137/1000
2023-09-10 00:19:45.512 
Epoch 137/1000 
	 loss: 385.8423, MinusLogProbMetric: 385.8423, val_loss: 395.0023, val_MinusLogProbMetric: 395.0023

Epoch 137: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.8423 - MinusLogProbMetric: 385.8423 - val_loss: 395.0023 - val_MinusLogProbMetric: 395.0023 - lr: 5.5556e-05 - 20s/epoch - 101ms/step
Epoch 138/1000
2023-09-10 00:20:04.740 
Epoch 138/1000 
	 loss: 385.9354, MinusLogProbMetric: 385.9354, val_loss: 395.2766, val_MinusLogProbMetric: 395.2766

Epoch 138: val_loss did not improve from 394.50381
196/196 - 19s - loss: 385.9354 - MinusLogProbMetric: 385.9354 - val_loss: 395.2766 - val_MinusLogProbMetric: 395.2766 - lr: 5.5556e-05 - 19s/epoch - 98ms/step
Epoch 139/1000
2023-09-10 00:20:25.030 
Epoch 139/1000 
	 loss: 385.7277, MinusLogProbMetric: 385.7277, val_loss: 395.0761, val_MinusLogProbMetric: 395.0761

Epoch 139: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.7277 - MinusLogProbMetric: 385.7277 - val_loss: 395.0761 - val_MinusLogProbMetric: 395.0761 - lr: 5.5556e-05 - 20s/epoch - 104ms/step
Epoch 140/1000
2023-09-10 00:20:44.204 
Epoch 140/1000 
	 loss: 385.8275, MinusLogProbMetric: 385.8275, val_loss: 395.5608, val_MinusLogProbMetric: 395.5608

Epoch 140: val_loss did not improve from 394.50381
196/196 - 19s - loss: 385.8275 - MinusLogProbMetric: 385.8275 - val_loss: 395.5608 - val_MinusLogProbMetric: 395.5608 - lr: 5.5556e-05 - 19s/epoch - 98ms/step
Epoch 141/1000
2023-09-10 00:21:03.822 
Epoch 141/1000 
	 loss: 385.7463, MinusLogProbMetric: 385.7463, val_loss: 395.3021, val_MinusLogProbMetric: 395.3021

Epoch 141: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.7463 - MinusLogProbMetric: 385.7463 - val_loss: 395.3021 - val_MinusLogProbMetric: 395.3021 - lr: 5.5556e-05 - 20s/epoch - 100ms/step
Epoch 142/1000
2023-09-10 00:21:24.509 
Epoch 142/1000 
	 loss: 385.8546, MinusLogProbMetric: 385.8546, val_loss: 394.9445, val_MinusLogProbMetric: 394.9445

Epoch 142: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.8546 - MinusLogProbMetric: 385.8546 - val_loss: 394.9445 - val_MinusLogProbMetric: 394.9445 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 143/1000
2023-09-10 00:21:45.345 
Epoch 143/1000 
	 loss: 385.7129, MinusLogProbMetric: 385.7129, val_loss: 394.6826, val_MinusLogProbMetric: 394.6826

Epoch 143: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.7129 - MinusLogProbMetric: 385.7129 - val_loss: 394.6826 - val_MinusLogProbMetric: 394.6826 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 144/1000
2023-09-10 00:22:04.128 
Epoch 144/1000 
	 loss: 385.8372, MinusLogProbMetric: 385.8372, val_loss: 395.9243, val_MinusLogProbMetric: 395.9243

Epoch 144: val_loss did not improve from 394.50381
196/196 - 19s - loss: 385.8372 - MinusLogProbMetric: 385.8372 - val_loss: 395.9243 - val_MinusLogProbMetric: 395.9243 - lr: 5.5556e-05 - 19s/epoch - 96ms/step
Epoch 145/1000
2023-09-10 00:22:23.284 
Epoch 145/1000 
	 loss: 385.7844, MinusLogProbMetric: 385.7844, val_loss: 395.7955, val_MinusLogProbMetric: 395.7955

Epoch 145: val_loss did not improve from 394.50381
196/196 - 19s - loss: 385.7844 - MinusLogProbMetric: 385.7844 - val_loss: 395.7955 - val_MinusLogProbMetric: 395.7955 - lr: 5.5556e-05 - 19s/epoch - 98ms/step
Epoch 146/1000
2023-09-10 00:22:44.467 
Epoch 146/1000 
	 loss: 385.9722, MinusLogProbMetric: 385.9722, val_loss: 394.8576, val_MinusLogProbMetric: 394.8576

Epoch 146: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.9722 - MinusLogProbMetric: 385.9722 - val_loss: 394.8576 - val_MinusLogProbMetric: 394.8576 - lr: 5.5556e-05 - 21s/epoch - 108ms/step
Epoch 147/1000
2023-09-10 00:23:03.077 
Epoch 147/1000 
	 loss: 386.0169, MinusLogProbMetric: 386.0169, val_loss: 395.0129, val_MinusLogProbMetric: 395.0129

Epoch 147: val_loss did not improve from 394.50381
196/196 - 19s - loss: 386.0169 - MinusLogProbMetric: 386.0169 - val_loss: 395.0129 - val_MinusLogProbMetric: 395.0129 - lr: 5.5556e-05 - 19s/epoch - 95ms/step
Epoch 148/1000
2023-09-10 00:23:18.193 
Epoch 148/1000 
	 loss: 385.7209, MinusLogProbMetric: 385.7209, val_loss: 395.4771, val_MinusLogProbMetric: 395.4771

Epoch 148: val_loss did not improve from 394.50381
196/196 - 15s - loss: 385.7209 - MinusLogProbMetric: 385.7209 - val_loss: 395.4771 - val_MinusLogProbMetric: 395.4771 - lr: 5.5556e-05 - 15s/epoch - 77ms/step
Epoch 149/1000
2023-09-10 00:23:36.199 
Epoch 149/1000 
	 loss: 385.9222, MinusLogProbMetric: 385.9222, val_loss: 395.5151, val_MinusLogProbMetric: 395.5151

Epoch 149: val_loss did not improve from 394.50381
196/196 - 18s - loss: 385.9222 - MinusLogProbMetric: 385.9222 - val_loss: 395.5151 - val_MinusLogProbMetric: 395.5151 - lr: 5.5556e-05 - 18s/epoch - 92ms/step
Epoch 150/1000
2023-09-10 00:23:55.943 
Epoch 150/1000 
	 loss: 385.9046, MinusLogProbMetric: 385.9046, val_loss: 394.8265, val_MinusLogProbMetric: 394.8265

Epoch 150: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.9046 - MinusLogProbMetric: 385.9046 - val_loss: 394.8265 - val_MinusLogProbMetric: 394.8265 - lr: 5.5556e-05 - 20s/epoch - 101ms/step
Epoch 151/1000
2023-09-10 00:24:16.366 
Epoch 151/1000 
	 loss: 385.8396, MinusLogProbMetric: 385.8396, val_loss: 394.6555, val_MinusLogProbMetric: 394.6555

Epoch 151: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.8396 - MinusLogProbMetric: 385.8396 - val_loss: 394.6555 - val_MinusLogProbMetric: 394.6555 - lr: 5.5556e-05 - 20s/epoch - 104ms/step
Epoch 152/1000
2023-09-10 00:24:37.828 
Epoch 152/1000 
	 loss: 385.8104, MinusLogProbMetric: 385.8104, val_loss: 394.9841, val_MinusLogProbMetric: 394.9841

Epoch 152: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.8104 - MinusLogProbMetric: 385.8104 - val_loss: 394.9841 - val_MinusLogProbMetric: 394.9841 - lr: 5.5556e-05 - 21s/epoch - 110ms/step
Epoch 153/1000
2023-09-10 00:24:57.910 
Epoch 153/1000 
	 loss: 385.7095, MinusLogProbMetric: 385.7095, val_loss: 395.3118, val_MinusLogProbMetric: 395.3118

Epoch 153: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.7095 - MinusLogProbMetric: 385.7095 - val_loss: 395.3118 - val_MinusLogProbMetric: 395.3118 - lr: 5.5556e-05 - 20s/epoch - 102ms/step
Epoch 154/1000
2023-09-10 00:25:18.680 
Epoch 154/1000 
	 loss: 385.8224, MinusLogProbMetric: 385.8224, val_loss: 395.5296, val_MinusLogProbMetric: 395.5296

Epoch 154: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.8224 - MinusLogProbMetric: 385.8224 - val_loss: 395.5296 - val_MinusLogProbMetric: 395.5296 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 155/1000
2023-09-10 00:25:39.163 
Epoch 155/1000 
	 loss: 385.8458, MinusLogProbMetric: 385.8458, val_loss: 395.1631, val_MinusLogProbMetric: 395.1631

Epoch 155: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.8458 - MinusLogProbMetric: 385.8458 - val_loss: 395.1631 - val_MinusLogProbMetric: 395.1631 - lr: 5.5556e-05 - 20s/epoch - 104ms/step
Epoch 156/1000
2023-09-10 00:25:59.456 
Epoch 156/1000 
	 loss: 385.8739, MinusLogProbMetric: 385.8739, val_loss: 395.2658, val_MinusLogProbMetric: 395.2658

Epoch 156: val_loss did not improve from 394.50381
196/196 - 20s - loss: 385.8739 - MinusLogProbMetric: 385.8739 - val_loss: 395.2658 - val_MinusLogProbMetric: 395.2658 - lr: 5.5556e-05 - 20s/epoch - 104ms/step
Epoch 157/1000
2023-09-10 00:26:20.273 
Epoch 157/1000 
	 loss: 385.8869, MinusLogProbMetric: 385.8869, val_loss: 394.9401, val_MinusLogProbMetric: 394.9401

Epoch 157: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.8869 - MinusLogProbMetric: 385.8869 - val_loss: 394.9401 - val_MinusLogProbMetric: 394.9401 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 158/1000
2023-09-10 00:26:40.982 
Epoch 158/1000 
	 loss: 385.6752, MinusLogProbMetric: 385.6752, val_loss: 395.0733, val_MinusLogProbMetric: 395.0733

Epoch 158: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.6752 - MinusLogProbMetric: 385.6752 - val_loss: 395.0733 - val_MinusLogProbMetric: 395.0733 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 159/1000
2023-09-10 00:27:02.127 
Epoch 159/1000 
	 loss: 385.7262, MinusLogProbMetric: 385.7262, val_loss: 395.1355, val_MinusLogProbMetric: 395.1355

Epoch 159: val_loss did not improve from 394.50381
196/196 - 21s - loss: 385.7262 - MinusLogProbMetric: 385.7262 - val_loss: 395.1355 - val_MinusLogProbMetric: 395.1355 - lr: 5.5556e-05 - 21s/epoch - 108ms/step
Epoch 160/1000
2023-09-10 00:27:25.027 
Epoch 160/1000 
	 loss: 385.7125, MinusLogProbMetric: 385.7125, val_loss: 395.3261, val_MinusLogProbMetric: 395.3261

Epoch 160: val_loss did not improve from 394.50381
196/196 - 23s - loss: 385.7125 - MinusLogProbMetric: 385.7125 - val_loss: 395.3261 - val_MinusLogProbMetric: 395.3261 - lr: 5.5556e-05 - 23s/epoch - 117ms/step
Epoch 161/1000
2023-09-10 00:27:47.169 
Epoch 161/1000 
	 loss: 385.6490, MinusLogProbMetric: 385.6490, val_loss: 394.7621, val_MinusLogProbMetric: 394.7621

Epoch 161: val_loss did not improve from 394.50381
196/196 - 22s - loss: 385.6490 - MinusLogProbMetric: 385.6490 - val_loss: 394.7621 - val_MinusLogProbMetric: 394.7621 - lr: 5.5556e-05 - 22s/epoch - 113ms/step
Epoch 162/1000
2023-09-10 00:28:09.717 
Epoch 162/1000 
	 loss: 385.6219, MinusLogProbMetric: 385.6219, val_loss: 395.6218, val_MinusLogProbMetric: 395.6218

Epoch 162: val_loss did not improve from 394.50381
196/196 - 23s - loss: 385.6219 - MinusLogProbMetric: 385.6219 - val_loss: 395.6218 - val_MinusLogProbMetric: 395.6218 - lr: 5.5556e-05 - 23s/epoch - 115ms/step
Epoch 163/1000
2023-09-10 00:28:29.131 
Epoch 163/1000 
	 loss: 385.6780, MinusLogProbMetric: 385.6780, val_loss: 395.3392, val_MinusLogProbMetric: 395.3392

Epoch 163: val_loss did not improve from 394.50381
196/196 - 19s - loss: 385.6780 - MinusLogProbMetric: 385.6780 - val_loss: 395.3392 - val_MinusLogProbMetric: 395.3392 - lr: 5.5556e-05 - 19s/epoch - 99ms/step
Epoch 164/1000
2023-09-10 00:28:51.610 
Epoch 164/1000 
	 loss: 385.8594, MinusLogProbMetric: 385.8594, val_loss: 394.5008, val_MinusLogProbMetric: 394.5008

Epoch 164: val_loss improved from 394.50381 to 394.50076, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_327/weights/best_weights.h5
196/196 - 23s - loss: 385.8594 - MinusLogProbMetric: 385.8594 - val_loss: 394.5008 - val_MinusLogProbMetric: 394.5008 - lr: 5.5556e-05 - 23s/epoch - 120ms/step
Epoch 165/1000
2023-09-10 00:29:13.470 
Epoch 165/1000 
	 loss: 385.7674, MinusLogProbMetric: 385.7674, val_loss: 394.7241, val_MinusLogProbMetric: 394.7241

Epoch 165: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.7674 - MinusLogProbMetric: 385.7674 - val_loss: 394.7241 - val_MinusLogProbMetric: 394.7241 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 166/1000
2023-09-10 00:29:37.582 
Epoch 166/1000 
	 loss: 385.9576, MinusLogProbMetric: 385.9576, val_loss: 394.8261, val_MinusLogProbMetric: 394.8261

Epoch 166: val_loss did not improve from 394.50076
196/196 - 24s - loss: 385.9576 - MinusLogProbMetric: 385.9576 - val_loss: 394.8261 - val_MinusLogProbMetric: 394.8261 - lr: 5.5556e-05 - 24s/epoch - 123ms/step
Epoch 167/1000
2023-09-10 00:29:59.536 
Epoch 167/1000 
	 loss: 385.7092, MinusLogProbMetric: 385.7092, val_loss: 394.7719, val_MinusLogProbMetric: 394.7719

Epoch 167: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.7092 - MinusLogProbMetric: 385.7092 - val_loss: 394.7719 - val_MinusLogProbMetric: 394.7719 - lr: 5.5556e-05 - 22s/epoch - 112ms/step
Epoch 168/1000
2023-09-10 00:30:19.500 
Epoch 168/1000 
	 loss: 385.5900, MinusLogProbMetric: 385.5900, val_loss: 395.1430, val_MinusLogProbMetric: 395.1430

Epoch 168: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.5900 - MinusLogProbMetric: 385.5900 - val_loss: 395.1430 - val_MinusLogProbMetric: 395.1430 - lr: 5.5556e-05 - 20s/epoch - 102ms/step
Epoch 169/1000
2023-09-10 00:30:39.713 
Epoch 169/1000 
	 loss: 385.7709, MinusLogProbMetric: 385.7709, val_loss: 395.8046, val_MinusLogProbMetric: 395.8046

Epoch 169: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.7709 - MinusLogProbMetric: 385.7709 - val_loss: 395.8046 - val_MinusLogProbMetric: 395.8046 - lr: 5.5556e-05 - 20s/epoch - 103ms/step
Epoch 170/1000
2023-09-10 00:31:00.091 
Epoch 170/1000 
	 loss: 385.6012, MinusLogProbMetric: 385.6012, val_loss: 395.1034, val_MinusLogProbMetric: 395.1034

Epoch 170: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.6012 - MinusLogProbMetric: 385.6012 - val_loss: 395.1034 - val_MinusLogProbMetric: 395.1034 - lr: 5.5556e-05 - 20s/epoch - 104ms/step
Epoch 171/1000
2023-09-10 00:31:20.883 
Epoch 171/1000 
	 loss: 385.8732, MinusLogProbMetric: 385.8732, val_loss: 395.5669, val_MinusLogProbMetric: 395.5669

Epoch 171: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.8732 - MinusLogProbMetric: 385.8732 - val_loss: 395.5669 - val_MinusLogProbMetric: 395.5669 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 172/1000
2023-09-10 00:31:43.096 
Epoch 172/1000 
	 loss: 385.4930, MinusLogProbMetric: 385.4930, val_loss: 395.3694, val_MinusLogProbMetric: 395.3694

Epoch 172: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.4930 - MinusLogProbMetric: 385.4930 - val_loss: 395.3694 - val_MinusLogProbMetric: 395.3694 - lr: 5.5556e-05 - 22s/epoch - 113ms/step
Epoch 173/1000
2023-09-10 00:32:04.249 
Epoch 173/1000 
	 loss: 385.7055, MinusLogProbMetric: 385.7055, val_loss: 395.1423, val_MinusLogProbMetric: 395.1423

Epoch 173: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.7055 - MinusLogProbMetric: 385.7055 - val_loss: 395.1423 - val_MinusLogProbMetric: 395.1423 - lr: 5.5556e-05 - 21s/epoch - 108ms/step
Epoch 174/1000
2023-09-10 00:32:23.959 
Epoch 174/1000 
	 loss: 385.7195, MinusLogProbMetric: 385.7195, val_loss: 395.1378, val_MinusLogProbMetric: 395.1378

Epoch 174: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.7195 - MinusLogProbMetric: 385.7195 - val_loss: 395.1378 - val_MinusLogProbMetric: 395.1378 - lr: 5.5556e-05 - 20s/epoch - 100ms/step
Epoch 175/1000
2023-09-10 00:32:43.064 
Epoch 175/1000 
	 loss: 385.7955, MinusLogProbMetric: 385.7955, val_loss: 395.7536, val_MinusLogProbMetric: 395.7536

Epoch 175: val_loss did not improve from 394.50076
196/196 - 19s - loss: 385.7955 - MinusLogProbMetric: 385.7955 - val_loss: 395.7536 - val_MinusLogProbMetric: 395.7536 - lr: 5.5556e-05 - 19s/epoch - 97ms/step
Epoch 176/1000
2023-09-10 00:33:03.079 
Epoch 176/1000 
	 loss: 385.5604, MinusLogProbMetric: 385.5604, val_loss: 395.1320, val_MinusLogProbMetric: 395.1320

Epoch 176: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.5604 - MinusLogProbMetric: 385.5604 - val_loss: 395.1320 - val_MinusLogProbMetric: 395.1320 - lr: 5.5556e-05 - 20s/epoch - 102ms/step
Epoch 177/1000
2023-09-10 00:33:24.153 
Epoch 177/1000 
	 loss: 385.5688, MinusLogProbMetric: 385.5688, val_loss: 395.1107, val_MinusLogProbMetric: 395.1107

Epoch 177: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.5688 - MinusLogProbMetric: 385.5688 - val_loss: 395.1107 - val_MinusLogProbMetric: 395.1107 - lr: 5.5556e-05 - 21s/epoch - 108ms/step
Epoch 178/1000
2023-09-10 00:33:45.599 
Epoch 178/1000 
	 loss: 385.6209, MinusLogProbMetric: 385.6209, val_loss: 395.4007, val_MinusLogProbMetric: 395.4007

Epoch 178: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.6209 - MinusLogProbMetric: 385.6209 - val_loss: 395.4007 - val_MinusLogProbMetric: 395.4007 - lr: 5.5556e-05 - 21s/epoch - 109ms/step
Epoch 179/1000
2023-09-10 00:34:04.907 
Epoch 179/1000 
	 loss: 385.9677, MinusLogProbMetric: 385.9677, val_loss: 395.2729, val_MinusLogProbMetric: 395.2729

Epoch 179: val_loss did not improve from 394.50076
196/196 - 19s - loss: 385.9677 - MinusLogProbMetric: 385.9677 - val_loss: 395.2729 - val_MinusLogProbMetric: 395.2729 - lr: 5.5556e-05 - 19s/epoch - 98ms/step
Epoch 180/1000
2023-09-10 00:34:27.262 
Epoch 180/1000 
	 loss: 385.4380, MinusLogProbMetric: 385.4380, val_loss: 394.9442, val_MinusLogProbMetric: 394.9442

Epoch 180: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.4380 - MinusLogProbMetric: 385.4380 - val_loss: 394.9442 - val_MinusLogProbMetric: 394.9442 - lr: 5.5556e-05 - 22s/epoch - 114ms/step
Epoch 181/1000
2023-09-10 00:34:47.658 
Epoch 181/1000 
	 loss: 385.4816, MinusLogProbMetric: 385.4816, val_loss: 395.4956, val_MinusLogProbMetric: 395.4956

Epoch 181: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.4816 - MinusLogProbMetric: 385.4816 - val_loss: 395.4956 - val_MinusLogProbMetric: 395.4956 - lr: 5.5556e-05 - 20s/epoch - 104ms/step
Epoch 182/1000
2023-09-10 00:35:07.219 
Epoch 182/1000 
	 loss: 385.6191, MinusLogProbMetric: 385.6191, val_loss: 395.6085, val_MinusLogProbMetric: 395.6085

Epoch 182: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.6191 - MinusLogProbMetric: 385.6191 - val_loss: 395.6085 - val_MinusLogProbMetric: 395.6085 - lr: 5.5556e-05 - 20s/epoch - 100ms/step
Epoch 183/1000
2023-09-10 00:35:28.596 
Epoch 183/1000 
	 loss: 385.4863, MinusLogProbMetric: 385.4863, val_loss: 395.1296, val_MinusLogProbMetric: 395.1296

Epoch 183: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.4863 - MinusLogProbMetric: 385.4863 - val_loss: 395.1296 - val_MinusLogProbMetric: 395.1296 - lr: 5.5556e-05 - 21s/epoch - 109ms/step
Epoch 184/1000
2023-09-10 00:35:49.268 
Epoch 184/1000 
	 loss: 385.5707, MinusLogProbMetric: 385.5707, val_loss: 395.0643, val_MinusLogProbMetric: 395.0643

Epoch 184: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.5707 - MinusLogProbMetric: 385.5707 - val_loss: 395.0643 - val_MinusLogProbMetric: 395.0643 - lr: 5.5556e-05 - 21s/epoch - 105ms/step
Epoch 185/1000
2023-09-10 00:36:11.083 
Epoch 185/1000 
	 loss: 385.4274, MinusLogProbMetric: 385.4274, val_loss: 395.7573, val_MinusLogProbMetric: 395.7573

Epoch 185: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.4274 - MinusLogProbMetric: 385.4274 - val_loss: 395.7573 - val_MinusLogProbMetric: 395.7573 - lr: 5.5556e-05 - 22s/epoch - 111ms/step
Epoch 186/1000
2023-09-10 00:36:33.401 
Epoch 186/1000 
	 loss: 385.4397, MinusLogProbMetric: 385.4397, val_loss: 395.5071, val_MinusLogProbMetric: 395.5071

Epoch 186: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.4397 - MinusLogProbMetric: 385.4397 - val_loss: 395.5071 - val_MinusLogProbMetric: 395.5071 - lr: 5.5556e-05 - 22s/epoch - 114ms/step
Epoch 187/1000
2023-09-10 00:36:54.323 
Epoch 187/1000 
	 loss: 385.5996, MinusLogProbMetric: 385.5996, val_loss: 395.4822, val_MinusLogProbMetric: 395.4822

Epoch 187: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.5996 - MinusLogProbMetric: 385.5996 - val_loss: 395.4822 - val_MinusLogProbMetric: 395.4822 - lr: 5.5556e-05 - 21s/epoch - 107ms/step
Epoch 188/1000
2023-09-10 00:37:13.451 
Epoch 188/1000 
	 loss: 385.5396, MinusLogProbMetric: 385.5396, val_loss: 395.3822, val_MinusLogProbMetric: 395.3822

Epoch 188: val_loss did not improve from 394.50076
196/196 - 19s - loss: 385.5396 - MinusLogProbMetric: 385.5396 - val_loss: 395.3822 - val_MinusLogProbMetric: 395.3822 - lr: 5.5556e-05 - 19s/epoch - 98ms/step
Epoch 189/1000
2023-09-10 00:37:33.260 
Epoch 189/1000 
	 loss: 385.5809, MinusLogProbMetric: 385.5809, val_loss: 394.8968, val_MinusLogProbMetric: 394.8968

Epoch 189: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.5809 - MinusLogProbMetric: 385.5809 - val_loss: 394.8968 - val_MinusLogProbMetric: 394.8968 - lr: 5.5556e-05 - 20s/epoch - 101ms/step
Epoch 190/1000
2023-09-10 00:37:51.770 
Epoch 190/1000 
	 loss: 385.3392, MinusLogProbMetric: 385.3392, val_loss: 395.5979, val_MinusLogProbMetric: 395.5979

Epoch 190: val_loss did not improve from 394.50076
196/196 - 19s - loss: 385.3392 - MinusLogProbMetric: 385.3392 - val_loss: 395.5979 - val_MinusLogProbMetric: 395.5979 - lr: 5.5556e-05 - 19s/epoch - 94ms/step
Epoch 191/1000
2023-09-10 00:38:11.414 
Epoch 191/1000 
	 loss: 385.3678, MinusLogProbMetric: 385.3678, val_loss: 395.1503, val_MinusLogProbMetric: 395.1503

Epoch 191: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.3678 - MinusLogProbMetric: 385.3678 - val_loss: 395.1503 - val_MinusLogProbMetric: 395.1503 - lr: 5.5556e-05 - 20s/epoch - 100ms/step
Epoch 192/1000
2023-09-10 00:38:32.999 
Epoch 192/1000 
	 loss: 385.6478, MinusLogProbMetric: 385.6478, val_loss: 395.1557, val_MinusLogProbMetric: 395.1557

Epoch 192: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.6478 - MinusLogProbMetric: 385.6478 - val_loss: 395.1557 - val_MinusLogProbMetric: 395.1557 - lr: 5.5556e-05 - 22s/epoch - 110ms/step
Epoch 193/1000
2023-09-10 00:38:53.483 
Epoch 193/1000 
	 loss: 385.5635, MinusLogProbMetric: 385.5635, val_loss: 395.1543, val_MinusLogProbMetric: 395.1543

Epoch 193: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.5635 - MinusLogProbMetric: 385.5635 - val_loss: 395.1543 - val_MinusLogProbMetric: 395.1543 - lr: 5.5556e-05 - 20s/epoch - 104ms/step
Epoch 194/1000
2023-09-10 00:39:13.008 
Epoch 194/1000 
	 loss: 385.6477, MinusLogProbMetric: 385.6477, val_loss: 395.2248, val_MinusLogProbMetric: 395.2248

Epoch 194: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.6477 - MinusLogProbMetric: 385.6477 - val_loss: 395.2248 - val_MinusLogProbMetric: 395.2248 - lr: 5.5556e-05 - 20s/epoch - 100ms/step
Epoch 195/1000
2023-09-10 00:39:31.597 
Epoch 195/1000 
	 loss: 385.7033, MinusLogProbMetric: 385.7033, val_loss: 395.2516, val_MinusLogProbMetric: 395.2516

Epoch 195: val_loss did not improve from 394.50076
196/196 - 19s - loss: 385.7033 - MinusLogProbMetric: 385.7033 - val_loss: 395.2516 - val_MinusLogProbMetric: 395.2516 - lr: 5.5556e-05 - 19s/epoch - 95ms/step
Epoch 196/1000
2023-09-10 00:39:53.869 
Epoch 196/1000 
	 loss: 385.7582, MinusLogProbMetric: 385.7582, val_loss: 395.6813, val_MinusLogProbMetric: 395.6813

Epoch 196: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.7582 - MinusLogProbMetric: 385.7582 - val_loss: 395.6813 - val_MinusLogProbMetric: 395.6813 - lr: 5.5556e-05 - 22s/epoch - 114ms/step
Epoch 197/1000
2023-09-10 00:40:14.413 
Epoch 197/1000 
	 loss: 385.3783, MinusLogProbMetric: 385.3783, val_loss: 396.2438, val_MinusLogProbMetric: 396.2438

Epoch 197: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.3783 - MinusLogProbMetric: 385.3783 - val_loss: 396.2438 - val_MinusLogProbMetric: 396.2438 - lr: 5.5556e-05 - 21s/epoch - 105ms/step
Epoch 198/1000
2023-09-10 00:40:33.285 
Epoch 198/1000 
	 loss: 385.5453, MinusLogProbMetric: 385.5453, val_loss: 396.8529, val_MinusLogProbMetric: 396.8529

Epoch 198: val_loss did not improve from 394.50076
196/196 - 19s - loss: 385.5453 - MinusLogProbMetric: 385.5453 - val_loss: 396.8529 - val_MinusLogProbMetric: 396.8529 - lr: 5.5556e-05 - 19s/epoch - 96ms/step
Epoch 199/1000
2023-09-10 00:40:54.644 
Epoch 199/1000 
	 loss: 385.5737, MinusLogProbMetric: 385.5737, val_loss: 395.0088, val_MinusLogProbMetric: 395.0088

Epoch 199: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.5737 - MinusLogProbMetric: 385.5737 - val_loss: 395.0088 - val_MinusLogProbMetric: 395.0088 - lr: 5.5556e-05 - 21s/epoch - 109ms/step
Epoch 200/1000
2023-09-10 00:41:14.300 
Epoch 200/1000 
	 loss: 385.4153, MinusLogProbMetric: 385.4153, val_loss: 394.9803, val_MinusLogProbMetric: 394.9803

Epoch 200: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.4153 - MinusLogProbMetric: 385.4153 - val_loss: 394.9803 - val_MinusLogProbMetric: 394.9803 - lr: 5.5556e-05 - 20s/epoch - 100ms/step
Epoch 201/1000
2023-09-10 00:41:36.520 
Epoch 201/1000 
	 loss: 385.5477, MinusLogProbMetric: 385.5477, val_loss: 395.3918, val_MinusLogProbMetric: 395.3918

Epoch 201: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.5477 - MinusLogProbMetric: 385.5477 - val_loss: 395.3918 - val_MinusLogProbMetric: 395.3918 - lr: 5.5556e-05 - 22s/epoch - 113ms/step
Epoch 202/1000
2023-09-10 00:41:57.311 
Epoch 202/1000 
	 loss: 385.3531, MinusLogProbMetric: 385.3531, val_loss: 395.5946, val_MinusLogProbMetric: 395.5946

Epoch 202: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.3531 - MinusLogProbMetric: 385.3531 - val_loss: 395.5946 - val_MinusLogProbMetric: 395.5946 - lr: 5.5556e-05 - 21s/epoch - 106ms/step
Epoch 203/1000
2023-09-10 00:42:18.766 
Epoch 203/1000 
	 loss: 385.5120, MinusLogProbMetric: 385.5120, val_loss: 395.2801, val_MinusLogProbMetric: 395.2801

Epoch 203: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.5120 - MinusLogProbMetric: 385.5120 - val_loss: 395.2801 - val_MinusLogProbMetric: 395.2801 - lr: 5.5556e-05 - 21s/epoch - 109ms/step
Epoch 204/1000
2023-09-10 00:42:41.365 
Epoch 204/1000 
	 loss: 385.4805, MinusLogProbMetric: 385.4805, val_loss: 397.0933, val_MinusLogProbMetric: 397.0933

Epoch 204: val_loss did not improve from 394.50076
196/196 - 23s - loss: 385.4805 - MinusLogProbMetric: 385.4805 - val_loss: 397.0933 - val_MinusLogProbMetric: 397.0933 - lr: 5.5556e-05 - 23s/epoch - 115ms/step
Epoch 205/1000
2023-09-10 00:43:00.889 
Epoch 205/1000 
	 loss: 385.5999, MinusLogProbMetric: 385.5999, val_loss: 396.8125, val_MinusLogProbMetric: 396.8125

Epoch 205: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.5999 - MinusLogProbMetric: 385.5999 - val_loss: 396.8125 - val_MinusLogProbMetric: 396.8125 - lr: 5.5556e-05 - 20s/epoch - 100ms/step
Epoch 206/1000
2023-09-10 00:43:22.064 
Epoch 206/1000 
	 loss: 385.4919, MinusLogProbMetric: 385.4919, val_loss: 395.8595, val_MinusLogProbMetric: 395.8595

Epoch 206: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.4919 - MinusLogProbMetric: 385.4919 - val_loss: 395.8595 - val_MinusLogProbMetric: 395.8595 - lr: 5.5556e-05 - 21s/epoch - 108ms/step
Epoch 207/1000
2023-09-10 00:43:43.432 
Epoch 207/1000 
	 loss: 385.5627, MinusLogProbMetric: 385.5627, val_loss: 396.3388, val_MinusLogProbMetric: 396.3388

Epoch 207: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.5627 - MinusLogProbMetric: 385.5627 - val_loss: 396.3388 - val_MinusLogProbMetric: 396.3388 - lr: 5.5556e-05 - 21s/epoch - 109ms/step
Epoch 208/1000
2023-09-10 00:44:06.742 
Epoch 208/1000 
	 loss: 385.6695, MinusLogProbMetric: 385.6695, val_loss: 395.5321, val_MinusLogProbMetric: 395.5321

Epoch 208: val_loss did not improve from 394.50076
196/196 - 23s - loss: 385.6695 - MinusLogProbMetric: 385.6695 - val_loss: 395.5321 - val_MinusLogProbMetric: 395.5321 - lr: 5.5556e-05 - 23s/epoch - 119ms/step
Epoch 209/1000
2023-09-10 00:44:29.036 
Epoch 209/1000 
	 loss: 385.3964, MinusLogProbMetric: 385.3964, val_loss: 396.6084, val_MinusLogProbMetric: 396.6084

Epoch 209: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.3964 - MinusLogProbMetric: 385.3964 - val_loss: 396.6084 - val_MinusLogProbMetric: 396.6084 - lr: 5.5556e-05 - 22s/epoch - 114ms/step
Epoch 210/1000
2023-09-10 00:44:48.505 
Epoch 210/1000 
	 loss: 385.3249, MinusLogProbMetric: 385.3249, val_loss: 395.5365, val_MinusLogProbMetric: 395.5365

Epoch 210: val_loss did not improve from 394.50076
196/196 - 19s - loss: 385.3249 - MinusLogProbMetric: 385.3249 - val_loss: 395.5365 - val_MinusLogProbMetric: 395.5365 - lr: 5.5556e-05 - 19s/epoch - 99ms/step
Epoch 211/1000
2023-09-10 00:45:10.607 
Epoch 211/1000 
	 loss: 385.5082, MinusLogProbMetric: 385.5082, val_loss: 395.4413, val_MinusLogProbMetric: 395.4413

Epoch 211: val_loss did not improve from 394.50076
196/196 - 22s - loss: 385.5082 - MinusLogProbMetric: 385.5082 - val_loss: 395.4413 - val_MinusLogProbMetric: 395.4413 - lr: 5.5556e-05 - 22s/epoch - 113ms/step
Epoch 212/1000
2023-09-10 00:45:31.848 
Epoch 212/1000 
	 loss: 385.7711, MinusLogProbMetric: 385.7711, val_loss: 395.1898, val_MinusLogProbMetric: 395.1898

Epoch 212: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.7711 - MinusLogProbMetric: 385.7711 - val_loss: 395.1898 - val_MinusLogProbMetric: 395.1898 - lr: 5.5556e-05 - 21s/epoch - 108ms/step
Epoch 213/1000
2023-09-10 00:45:52.847 
Epoch 213/1000 
	 loss: 385.2684, MinusLogProbMetric: 385.2684, val_loss: 396.0346, val_MinusLogProbMetric: 396.0346

Epoch 213: val_loss did not improve from 394.50076
196/196 - 21s - loss: 385.2684 - MinusLogProbMetric: 385.2684 - val_loss: 396.0346 - val_MinusLogProbMetric: 396.0346 - lr: 5.5556e-05 - 21s/epoch - 107ms/step
Epoch 214/1000
2023-09-10 00:46:12.881 
Epoch 214/1000 
	 loss: 385.4157, MinusLogProbMetric: 385.4157, val_loss: 396.1333, val_MinusLogProbMetric: 396.1333

Epoch 214: val_loss did not improve from 394.50076
196/196 - 20s - loss: 385.4157 - MinusLogProbMetric: 385.4157 - val_loss: 396.1333 - val_MinusLogProbMetric: 396.1333 - lr: 5.5556e-05 - 20s/epoch - 102ms/step
Epoch 215/1000
2023-09-10 00:46:35.500 
Epoch 215/1000 
	 loss: 384.4692, MinusLogProbMetric: 384.4692, val_loss: 394.6750, val_MinusLogProbMetric: 394.6750

Epoch 215: val_loss did not improve from 394.50076
196/196 - 23s - loss: 384.4692 - MinusLogProbMetric: 384.4692 - val_loss: 394.6750 - val_MinusLogProbMetric: 394.6750 - lr: 2.7778e-05 - 23s/epoch - 115ms/step
Epoch 216/1000
2023-09-10 00:46:55.063 
Epoch 216/1000 
	 loss: 384.3842, MinusLogProbMetric: 384.3842, val_loss: 394.8432, val_MinusLogProbMetric: 394.8432

Epoch 216: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.3842 - MinusLogProbMetric: 384.3842 - val_loss: 394.8432 - val_MinusLogProbMetric: 394.8432 - lr: 2.7778e-05 - 20s/epoch - 100ms/step
Epoch 217/1000
2023-09-10 00:47:17.174 
Epoch 217/1000 
	 loss: 384.3432, MinusLogProbMetric: 384.3432, val_loss: 394.8403, val_MinusLogProbMetric: 394.8403

Epoch 217: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.3432 - MinusLogProbMetric: 384.3432 - val_loss: 394.8403 - val_MinusLogProbMetric: 394.8403 - lr: 2.7778e-05 - 22s/epoch - 113ms/step
Epoch 218/1000
2023-09-10 00:47:38.130 
Epoch 218/1000 
	 loss: 384.3496, MinusLogProbMetric: 384.3496, val_loss: 395.0475, val_MinusLogProbMetric: 395.0475

Epoch 218: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3496 - MinusLogProbMetric: 384.3496 - val_loss: 395.0475 - val_MinusLogProbMetric: 395.0475 - lr: 2.7778e-05 - 21s/epoch - 107ms/step
Epoch 219/1000
2023-09-10 00:48:00.198 
Epoch 219/1000 
	 loss: 384.3430, MinusLogProbMetric: 384.3430, val_loss: 394.7767, val_MinusLogProbMetric: 394.7767

Epoch 219: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.3430 - MinusLogProbMetric: 384.3430 - val_loss: 394.7767 - val_MinusLogProbMetric: 394.7767 - lr: 2.7778e-05 - 22s/epoch - 113ms/step
Epoch 220/1000
2023-09-10 00:48:20.225 
Epoch 220/1000 
	 loss: 384.3738, MinusLogProbMetric: 384.3738, val_loss: 394.6991, val_MinusLogProbMetric: 394.6991

Epoch 220: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.3738 - MinusLogProbMetric: 384.3738 - val_loss: 394.6991 - val_MinusLogProbMetric: 394.6991 - lr: 2.7778e-05 - 20s/epoch - 102ms/step
Epoch 221/1000
2023-09-10 00:48:41.144 
Epoch 221/1000 
	 loss: 384.3354, MinusLogProbMetric: 384.3354, val_loss: 394.9049, val_MinusLogProbMetric: 394.9049

Epoch 221: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3354 - MinusLogProbMetric: 384.3354 - val_loss: 394.9049 - val_MinusLogProbMetric: 394.9049 - lr: 2.7778e-05 - 21s/epoch - 107ms/step
Epoch 222/1000
2023-09-10 00:49:02.260 
Epoch 222/1000 
	 loss: 384.2940, MinusLogProbMetric: 384.2940, val_loss: 394.6575, val_MinusLogProbMetric: 394.6575

Epoch 222: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.2940 - MinusLogProbMetric: 384.2940 - val_loss: 394.6575 - val_MinusLogProbMetric: 394.6575 - lr: 2.7778e-05 - 21s/epoch - 108ms/step
Epoch 223/1000
2023-09-10 00:49:23.175 
Epoch 223/1000 
	 loss: 384.4128, MinusLogProbMetric: 384.4128, val_loss: 394.9622, val_MinusLogProbMetric: 394.9622

Epoch 223: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.4128 - MinusLogProbMetric: 384.4128 - val_loss: 394.9622 - val_MinusLogProbMetric: 394.9622 - lr: 2.7778e-05 - 21s/epoch - 107ms/step
Epoch 224/1000
2023-09-10 00:49:41.995 
Epoch 224/1000 
	 loss: 384.3502, MinusLogProbMetric: 384.3502, val_loss: 394.6678, val_MinusLogProbMetric: 394.6678

Epoch 224: val_loss did not improve from 394.50076
196/196 - 19s - loss: 384.3502 - MinusLogProbMetric: 384.3502 - val_loss: 394.6678 - val_MinusLogProbMetric: 394.6678 - lr: 2.7778e-05 - 19s/epoch - 96ms/step
Epoch 225/1000
2023-09-10 00:50:02.234 
Epoch 225/1000 
	 loss: 384.2758, MinusLogProbMetric: 384.2758, val_loss: 394.9473, val_MinusLogProbMetric: 394.9473

Epoch 225: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2758 - MinusLogProbMetric: 384.2758 - val_loss: 394.9473 - val_MinusLogProbMetric: 394.9473 - lr: 2.7778e-05 - 20s/epoch - 103ms/step
Epoch 226/1000
2023-09-10 00:50:23.758 
Epoch 226/1000 
	 loss: 384.2689, MinusLogProbMetric: 384.2689, val_loss: 395.0929, val_MinusLogProbMetric: 395.0929

Epoch 226: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.2689 - MinusLogProbMetric: 384.2689 - val_loss: 395.0929 - val_MinusLogProbMetric: 395.0929 - lr: 2.7778e-05 - 22s/epoch - 110ms/step
Epoch 227/1000
2023-09-10 00:50:45.182 
Epoch 227/1000 
	 loss: 384.3930, MinusLogProbMetric: 384.3930, val_loss: 395.0018, val_MinusLogProbMetric: 395.0018

Epoch 227: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3930 - MinusLogProbMetric: 384.3930 - val_loss: 395.0018 - val_MinusLogProbMetric: 395.0018 - lr: 2.7778e-05 - 21s/epoch - 109ms/step
Epoch 228/1000
2023-09-10 00:51:05.993 
Epoch 228/1000 
	 loss: 384.3984, MinusLogProbMetric: 384.3984, val_loss: 394.9400, val_MinusLogProbMetric: 394.9400

Epoch 228: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3984 - MinusLogProbMetric: 384.3984 - val_loss: 394.9400 - val_MinusLogProbMetric: 394.9400 - lr: 2.7778e-05 - 21s/epoch - 106ms/step
Epoch 229/1000
2023-09-10 00:51:27.963 
Epoch 229/1000 
	 loss: 384.3685, MinusLogProbMetric: 384.3685, val_loss: 395.0882, val_MinusLogProbMetric: 395.0882

Epoch 229: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.3685 - MinusLogProbMetric: 384.3685 - val_loss: 395.0882 - val_MinusLogProbMetric: 395.0882 - lr: 2.7778e-05 - 22s/epoch - 112ms/step
Epoch 230/1000
2023-09-10 00:51:47.240 
Epoch 230/1000 
	 loss: 384.3494, MinusLogProbMetric: 384.3494, val_loss: 395.1916, val_MinusLogProbMetric: 395.1916

Epoch 230: val_loss did not improve from 394.50076
196/196 - 19s - loss: 384.3494 - MinusLogProbMetric: 384.3494 - val_loss: 395.1916 - val_MinusLogProbMetric: 395.1916 - lr: 2.7778e-05 - 19s/epoch - 98ms/step
Epoch 231/1000
2023-09-10 00:52:06.633 
Epoch 231/1000 
	 loss: 384.2542, MinusLogProbMetric: 384.2542, val_loss: 394.8030, val_MinusLogProbMetric: 394.8030

Epoch 231: val_loss did not improve from 394.50076
196/196 - 19s - loss: 384.2542 - MinusLogProbMetric: 384.2542 - val_loss: 394.8030 - val_MinusLogProbMetric: 394.8030 - lr: 2.7778e-05 - 19s/epoch - 99ms/step
Epoch 232/1000
2023-09-10 00:52:28.818 
Epoch 232/1000 
	 loss: 384.2869, MinusLogProbMetric: 384.2869, val_loss: 395.0671, val_MinusLogProbMetric: 395.0671

Epoch 232: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.2869 - MinusLogProbMetric: 384.2869 - val_loss: 395.0671 - val_MinusLogProbMetric: 395.0671 - lr: 2.7778e-05 - 22s/epoch - 113ms/step
Epoch 233/1000
2023-09-10 00:52:51.504 
Epoch 233/1000 
	 loss: 384.2823, MinusLogProbMetric: 384.2823, val_loss: 394.9965, val_MinusLogProbMetric: 394.9965

Epoch 233: val_loss did not improve from 394.50076
196/196 - 23s - loss: 384.2823 - MinusLogProbMetric: 384.2823 - val_loss: 394.9965 - val_MinusLogProbMetric: 394.9965 - lr: 2.7778e-05 - 23s/epoch - 116ms/step
Epoch 234/1000
2023-09-10 00:53:12.229 
Epoch 234/1000 
	 loss: 384.3459, MinusLogProbMetric: 384.3459, val_loss: 395.1227, val_MinusLogProbMetric: 395.1227

Epoch 234: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3459 - MinusLogProbMetric: 384.3459 - val_loss: 395.1227 - val_MinusLogProbMetric: 395.1227 - lr: 2.7778e-05 - 21s/epoch - 106ms/step
Epoch 235/1000
2023-09-10 00:53:33.754 
Epoch 235/1000 
	 loss: 384.3677, MinusLogProbMetric: 384.3677, val_loss: 394.9893, val_MinusLogProbMetric: 394.9893

Epoch 235: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.3677 - MinusLogProbMetric: 384.3677 - val_loss: 394.9893 - val_MinusLogProbMetric: 394.9893 - lr: 2.7778e-05 - 22s/epoch - 110ms/step
Epoch 236/1000
2023-09-10 00:53:53.152 
Epoch 236/1000 
	 loss: 384.3087, MinusLogProbMetric: 384.3087, val_loss: 395.0401, val_MinusLogProbMetric: 395.0401

Epoch 236: val_loss did not improve from 394.50076
196/196 - 19s - loss: 384.3087 - MinusLogProbMetric: 384.3087 - val_loss: 395.0401 - val_MinusLogProbMetric: 395.0401 - lr: 2.7778e-05 - 19s/epoch - 99ms/step
Epoch 237/1000
2023-09-10 00:54:13.162 
Epoch 237/1000 
	 loss: 384.3354, MinusLogProbMetric: 384.3354, val_loss: 395.1215, val_MinusLogProbMetric: 395.1215

Epoch 237: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.3354 - MinusLogProbMetric: 384.3354 - val_loss: 395.1215 - val_MinusLogProbMetric: 395.1215 - lr: 2.7778e-05 - 20s/epoch - 102ms/step
Epoch 238/1000
2023-09-10 00:54:35.674 
Epoch 238/1000 
	 loss: 384.2953, MinusLogProbMetric: 384.2953, val_loss: 395.4691, val_MinusLogProbMetric: 395.4691

Epoch 238: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.2953 - MinusLogProbMetric: 384.2953 - val_loss: 395.4691 - val_MinusLogProbMetric: 395.4691 - lr: 2.7778e-05 - 22s/epoch - 115ms/step
Epoch 239/1000
2023-09-10 00:54:58.393 
Epoch 239/1000 
	 loss: 384.4507, MinusLogProbMetric: 384.4507, val_loss: 394.9307, val_MinusLogProbMetric: 394.9307

Epoch 239: val_loss did not improve from 394.50076
196/196 - 23s - loss: 384.4507 - MinusLogProbMetric: 384.4507 - val_loss: 394.9307 - val_MinusLogProbMetric: 394.9307 - lr: 2.7778e-05 - 23s/epoch - 116ms/step
Epoch 240/1000
2023-09-10 00:55:20.358 
Epoch 240/1000 
	 loss: 384.3372, MinusLogProbMetric: 384.3372, val_loss: 394.9429, val_MinusLogProbMetric: 394.9429

Epoch 240: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.3372 - MinusLogProbMetric: 384.3372 - val_loss: 394.9429 - val_MinusLogProbMetric: 394.9429 - lr: 2.7778e-05 - 22s/epoch - 112ms/step
Epoch 241/1000
2023-09-10 00:55:40.410 
Epoch 241/1000 
	 loss: 384.2496, MinusLogProbMetric: 384.2496, val_loss: 395.2543, val_MinusLogProbMetric: 395.2543

Epoch 241: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2496 - MinusLogProbMetric: 384.2496 - val_loss: 395.2543 - val_MinusLogProbMetric: 395.2543 - lr: 2.7778e-05 - 20s/epoch - 102ms/step
Epoch 242/1000
2023-09-10 00:56:00.860 
Epoch 242/1000 
	 loss: 384.2491, MinusLogProbMetric: 384.2491, val_loss: 395.2077, val_MinusLogProbMetric: 395.2077

Epoch 242: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2491 - MinusLogProbMetric: 384.2491 - val_loss: 395.2077 - val_MinusLogProbMetric: 395.2077 - lr: 2.7778e-05 - 20s/epoch - 104ms/step
Epoch 243/1000
2023-09-10 00:56:22.209 
Epoch 243/1000 
	 loss: 384.2497, MinusLogProbMetric: 384.2497, val_loss: 395.0283, val_MinusLogProbMetric: 395.0283

Epoch 243: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.2497 - MinusLogProbMetric: 384.2497 - val_loss: 395.0283 - val_MinusLogProbMetric: 395.0283 - lr: 2.7778e-05 - 21s/epoch - 109ms/step
Epoch 244/1000
2023-09-10 00:56:43.644 
Epoch 244/1000 
	 loss: 384.3049, MinusLogProbMetric: 384.3049, val_loss: 394.9077, val_MinusLogProbMetric: 394.9077

Epoch 244: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3049 - MinusLogProbMetric: 384.3049 - val_loss: 394.9077 - val_MinusLogProbMetric: 394.9077 - lr: 2.7778e-05 - 21s/epoch - 109ms/step
Epoch 245/1000
2023-09-10 00:57:06.699 
Epoch 245/1000 
	 loss: 384.3458, MinusLogProbMetric: 384.3458, val_loss: 394.9988, val_MinusLogProbMetric: 394.9988

Epoch 245: val_loss did not improve from 394.50076
196/196 - 23s - loss: 384.3458 - MinusLogProbMetric: 384.3458 - val_loss: 394.9988 - val_MinusLogProbMetric: 394.9988 - lr: 2.7778e-05 - 23s/epoch - 118ms/step
Epoch 246/1000
2023-09-10 00:57:29.741 
Epoch 246/1000 
	 loss: 384.3392, MinusLogProbMetric: 384.3392, val_loss: 394.8242, val_MinusLogProbMetric: 394.8242

Epoch 246: val_loss did not improve from 394.50076
196/196 - 23s - loss: 384.3392 - MinusLogProbMetric: 384.3392 - val_loss: 394.8242 - val_MinusLogProbMetric: 394.8242 - lr: 2.7778e-05 - 23s/epoch - 118ms/step
Epoch 247/1000
2023-09-10 00:57:49.623 
Epoch 247/1000 
	 loss: 384.3221, MinusLogProbMetric: 384.3221, val_loss: 394.8812, val_MinusLogProbMetric: 394.8812

Epoch 247: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.3221 - MinusLogProbMetric: 384.3221 - val_loss: 394.8812 - val_MinusLogProbMetric: 394.8812 - lr: 2.7778e-05 - 20s/epoch - 101ms/step
Epoch 248/1000
2023-09-10 00:58:11.274 
Epoch 248/1000 
	 loss: 384.3446, MinusLogProbMetric: 384.3446, val_loss: 394.9945, val_MinusLogProbMetric: 394.9945

Epoch 248: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.3446 - MinusLogProbMetric: 384.3446 - val_loss: 394.9945 - val_MinusLogProbMetric: 394.9945 - lr: 2.7778e-05 - 22s/epoch - 111ms/step
Epoch 249/1000
2023-09-10 00:58:31.917 
Epoch 249/1000 
	 loss: 384.3116, MinusLogProbMetric: 384.3116, val_loss: 394.7969, val_MinusLogProbMetric: 394.7969

Epoch 249: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3116 - MinusLogProbMetric: 384.3116 - val_loss: 394.7969 - val_MinusLogProbMetric: 394.7969 - lr: 2.7778e-05 - 21s/epoch - 105ms/step
Epoch 250/1000
2023-09-10 00:58:53.109 
Epoch 250/1000 
	 loss: 384.3399, MinusLogProbMetric: 384.3399, val_loss: 395.5894, val_MinusLogProbMetric: 395.5894

Epoch 250: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3399 - MinusLogProbMetric: 384.3399 - val_loss: 395.5894 - val_MinusLogProbMetric: 395.5894 - lr: 2.7778e-05 - 21s/epoch - 108ms/step
Epoch 251/1000
2023-09-10 00:59:14.909 
Epoch 251/1000 
	 loss: 384.2686, MinusLogProbMetric: 384.2686, val_loss: 394.9335, val_MinusLogProbMetric: 394.9335

Epoch 251: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.2686 - MinusLogProbMetric: 384.2686 - val_loss: 394.9335 - val_MinusLogProbMetric: 394.9335 - lr: 2.7778e-05 - 22s/epoch - 111ms/step
Epoch 252/1000
2023-09-10 00:59:35.391 
Epoch 252/1000 
	 loss: 384.2784, MinusLogProbMetric: 384.2784, val_loss: 395.5178, val_MinusLogProbMetric: 395.5178

Epoch 252: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2784 - MinusLogProbMetric: 384.2784 - val_loss: 395.5178 - val_MinusLogProbMetric: 395.5178 - lr: 2.7778e-05 - 20s/epoch - 104ms/step
Epoch 253/1000
2023-09-10 00:59:55.612 
Epoch 253/1000 
	 loss: 384.2241, MinusLogProbMetric: 384.2241, val_loss: 394.7453, val_MinusLogProbMetric: 394.7453

Epoch 253: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2241 - MinusLogProbMetric: 384.2241 - val_loss: 394.7453 - val_MinusLogProbMetric: 394.7453 - lr: 2.7778e-05 - 20s/epoch - 103ms/step
Epoch 254/1000
2023-09-10 01:00:15.710 
Epoch 254/1000 
	 loss: 384.2073, MinusLogProbMetric: 384.2073, val_loss: 394.7369, val_MinusLogProbMetric: 394.7369

Epoch 254: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2073 - MinusLogProbMetric: 384.2073 - val_loss: 394.7369 - val_MinusLogProbMetric: 394.7369 - lr: 2.7778e-05 - 20s/epoch - 103ms/step
Epoch 255/1000
2023-09-10 01:00:36.172 
Epoch 255/1000 
	 loss: 384.1875, MinusLogProbMetric: 384.1875, val_loss: 394.9813, val_MinusLogProbMetric: 394.9813

Epoch 255: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.1875 - MinusLogProbMetric: 384.1875 - val_loss: 394.9813 - val_MinusLogProbMetric: 394.9813 - lr: 2.7778e-05 - 20s/epoch - 104ms/step
Epoch 256/1000
2023-09-10 01:00:59.403 
Epoch 256/1000 
	 loss: 384.2382, MinusLogProbMetric: 384.2382, val_loss: 394.9683, val_MinusLogProbMetric: 394.9683

Epoch 256: val_loss did not improve from 394.50076
196/196 - 23s - loss: 384.2382 - MinusLogProbMetric: 384.2382 - val_loss: 394.9683 - val_MinusLogProbMetric: 394.9683 - lr: 2.7778e-05 - 23s/epoch - 118ms/step
Epoch 257/1000
2023-09-10 01:01:19.936 
Epoch 257/1000 
	 loss: 384.3414, MinusLogProbMetric: 384.3414, val_loss: 394.7039, val_MinusLogProbMetric: 394.7039

Epoch 257: val_loss did not improve from 394.50076
196/196 - 21s - loss: 384.3414 - MinusLogProbMetric: 384.3414 - val_loss: 394.7039 - val_MinusLogProbMetric: 394.7039 - lr: 2.7778e-05 - 21s/epoch - 105ms/step
Epoch 258/1000
2023-09-10 01:01:39.669 
Epoch 258/1000 
	 loss: 384.3579, MinusLogProbMetric: 384.3579, val_loss: 396.2638, val_MinusLogProbMetric: 396.2638

Epoch 258: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.3579 - MinusLogProbMetric: 384.3579 - val_loss: 396.2638 - val_MinusLogProbMetric: 396.2638 - lr: 2.7778e-05 - 20s/epoch - 101ms/step
Epoch 259/1000
2023-09-10 01:02:01.749 
Epoch 259/1000 
	 loss: 384.2600, MinusLogProbMetric: 384.2600, val_loss: 394.9811, val_MinusLogProbMetric: 394.9811

Epoch 259: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.2600 - MinusLogProbMetric: 384.2600 - val_loss: 394.9811 - val_MinusLogProbMetric: 394.9811 - lr: 2.7778e-05 - 22s/epoch - 113ms/step
Epoch 260/1000
2023-09-10 01:02:20.322 
Epoch 260/1000 
	 loss: 384.1335, MinusLogProbMetric: 384.1335, val_loss: 394.8542, val_MinusLogProbMetric: 394.8542

Epoch 260: val_loss did not improve from 394.50076
196/196 - 18s - loss: 384.1335 - MinusLogProbMetric: 384.1335 - val_loss: 394.8542 - val_MinusLogProbMetric: 394.8542 - lr: 2.7778e-05 - 18s/epoch - 94ms/step
Epoch 261/1000
2023-09-10 01:02:40.537 
Epoch 261/1000 
	 loss: 384.2760, MinusLogProbMetric: 384.2760, val_loss: 394.8625, val_MinusLogProbMetric: 394.8625

Epoch 261: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2760 - MinusLogProbMetric: 384.2760 - val_loss: 394.8625 - val_MinusLogProbMetric: 394.8625 - lr: 2.7778e-05 - 20s/epoch - 103ms/step
Epoch 262/1000
2023-09-10 01:03:00.511 
Epoch 262/1000 
	 loss: 384.2409, MinusLogProbMetric: 384.2409, val_loss: 395.2166, val_MinusLogProbMetric: 395.2166

Epoch 262: val_loss did not improve from 394.50076
196/196 - 20s - loss: 384.2409 - MinusLogProbMetric: 384.2409 - val_loss: 395.2166 - val_MinusLogProbMetric: 395.2166 - lr: 2.7778e-05 - 20s/epoch - 102ms/step
Epoch 263/1000
2023-09-10 01:03:22.547 
Epoch 263/1000 
	 loss: 384.2847, MinusLogProbMetric: 384.2847, val_loss: 395.2275, val_MinusLogProbMetric: 395.2275

Epoch 263: val_loss did not improve from 394.50076
196/196 - 22s - loss: 384.2847 - MinusLogProbMetric: 384.2847 - val_loss: 395.2275 - val_MinusLogProbMetric: 395.2275 - lr: 2.7778e-05 - 22s/epoch - 112ms/step
Epoch 264/1000
2023-09-10 01:03:42.974 
Epoch 264/1000 
	 loss: 384.1081, MinusLogProbMetric: 384.1081, val_loss: 395.0032, val_MinusLogProbMetric: 395.0032

Epoch 264: val_loss did not improve from 394.50076
Restoring model weights from the end of the best epoch: 164.
196/196 - 21s - loss: 384.1081 - MinusLogProbMetric: 384.1081 - val_loss: 395.0032 - val_MinusLogProbMetric: 395.0032 - lr: 2.7778e-05 - 21s/epoch - 105ms/step
Epoch 264: early stopping
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 5353.367201733985 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 6303.6473745700205 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 5225.420529664028 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 6179.750799864065 seconds.
Training succeeded with seed 187.
Model trained in 5720.56 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 23320.97 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 23322.04 s.
===========
Run 327/360 done in 32163.19 s.
===========

Directory ../../results/MAFN_new/run_328/ already exists.
Skipping it.
===========
Run 328/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_329/ already exists.
Skipping it.
===========
Run 329/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_330/ already exists.
Skipping it.
===========
Run 330/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_331/ already exists.
Skipping it.
===========
Run 331/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_332/ already exists.
Skipping it.
===========
Run 332/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_333/ already exists.
Skipping it.
===========
Run 333/360 already exists. Skipping it.
===========

===========
Generating train data for run 334.
===========
Train data generated in 1.78 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_334/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_334/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_334/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_334
self.data_kwargs: {'seed': 440}
self.x_data: [[ 5.975928    0.18705393  4.579732   ...  5.052782    6.363114
   3.5951567 ]
 [ 8.245443    4.908681    5.163151   ...  2.2962263   8.159441
   6.519855  ]
 [ 5.979998    0.06695901  4.8433633  ...  4.708263    6.650848
   7.1221867 ]
 ...
 [ 8.616862    3.848415    5.171632   ...  3.7576704   8.165923
   7.0578055 ]
 [ 8.209467    4.7939653   5.2042055  ...  3.0320504   8.283145
   7.183658  ]
 [ 6.448749   -0.35270444  4.789608   ...  4.7734337   6.228376
   4.513551  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_34 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_3 (LogProbLa  (None,)                  4509200   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,509,200
Trainable params: 4,509,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_3/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_3'")
self.model: <keras.engine.functional.Functional object at 0x7f191c5def80>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f191c5b35b0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f191c5b35b0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f191c5df940>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f1d86e41c30>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f1d86e42110>, <keras.callbacks.ModelCheckpoint object at 0x7f1d86e421d0>, <keras.callbacks.EarlyStopping object at 0x7f1d86e42440>, <keras.callbacks.ReduceLROnPlateau object at 0x7f1d86e42470>, <keras.callbacks.TerminateOnNaN object at 0x7f1d86e420b0>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_334/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 334/360 with hyperparameters:
timestamp = 2023-09-10 07:32:30.061083
ndims = 1000
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 4509200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 5.9759278e+00  1.8705393e-01  4.5797319e+00  7.3813486e+00
  4.9839023e-01  9.1128473e+00  5.1425128e+00  1.0601972e+00
  1.8690022e+00  9.7343407e+00  6.0127983e+00  1.2467406e+00
  2.1360984e+00  5.5741024e+00  8.1917816e-01  3.7718730e+00
  5.1906404e+00  3.0766895e+00  6.0415301e+00  7.3736296e+00
  2.8012948e+00  7.5884948e+00  7.1015620e+00  1.0307134e+01
  6.5797253e+00  7.9973593e+00  3.9854233e+00  1.8046517e+00
  9.7217255e+00  1.0974171e+00  5.1221895e+00  8.3442938e-01
  9.2890491e+00  9.2900143e+00  7.2703452e+00  3.3996055e+00
  2.9350464e+00  2.6254275e+00  1.3082062e+00  5.2701192e+00
  1.3725662e+00  3.2777114e+00  6.2085199e+00  7.2575483e+00
  5.7510644e-02  4.4865317e+00  6.2462301e+00  8.9988785e+00
  4.7538991e+00  9.9086142e+00  2.3183393e+00  4.7639337e-01
  4.5737805e+00  2.5859902e+00  8.1949062e+00  2.6238203e+00
  3.0378006e+00  7.9298201e+00  8.4647675e+00  4.9066219e+00
  6.4023814e+00  3.9823089e+00 -4.2869711e-01  1.5175290e-02
  6.1451683e+00 -2.2587168e-01 -9.5339119e-02  8.5243511e+00
  9.1139994e+00 -1.0624671e-01 -6.7571568e-01  9.4670458e+00
  2.6047506e+00  9.5776010e-01  6.6801319e+00  9.6847260e-01
  3.1678288e+00  9.7247944e+00  6.2540312e+00  6.3839302e+00
  3.4341021e+00  7.7830091e+00  1.6556205e+00  9.9951563e+00
  8.6061764e+00  6.2981930e+00  1.2968564e+00  8.2717495e+00
  9.2503586e+00  5.0443635e+00  4.8242106e+00  1.5439949e+00
  7.4578109e+00  9.9600182e+00  1.0782404e+00  7.4997787e+00
 -6.1716002e-01  1.0503052e+01  6.2509499e+00  5.6324120e+00
  2.8450089e+00  8.2806787e+00  2.7606368e+00  8.2886658e+00
  1.0619202e+01  7.7074742e+00  4.5604439e+00  1.0194874e+00
  4.4170108e+00  4.2977200e+00  1.7771544e+00  4.3124924e+00
  3.5204492e+00  7.5383079e-01  4.9013953e+00  1.8483464e+00
  5.2527041e+00  2.9501736e-01  9.0906477e+00  6.7014809e+00
  5.4151597e+00  8.2172470e+00  9.6032486e+00  1.1688474e+00
  7.4652319e+00  9.9523344e+00  1.0106757e+01  5.6442394e+00
  1.2893100e+00  6.2976708e+00 -6.0980135e-01  2.0239670e+00
  9.4813910e+00  9.1562080e-01  6.0650496e+00  3.3473954e+00
  9.4390936e+00  6.5065956e+00  2.8910985e+00  7.6608114e+00
  1.1822252e+00  2.8502061e+00  2.2126217e+00  7.5678649e+00
  1.3060629e+00  4.1730914e+00  2.7150269e+00  4.2508979e+00
  3.1311915e+00  8.0161762e+00  1.1140229e+00  6.6955643e+00
  2.3109643e+00  2.5608201e+00  9.0579319e+00  8.9470587e+00
  1.9467136e+00  7.7616472e+00  1.1755015e+00  6.9813056e+00
  7.1541829e+00  1.1629101e+00  4.0641637e+00  8.5495291e+00
  1.0037423e+00  3.7546790e-01  5.4117308e+00  3.8483400e+00
  7.5943928e+00  1.0048924e+01  3.0955133e+00  3.7507610e+00
  4.7484083e+00  5.6718163e+00  9.9414043e+00  6.6468272e+00
  5.5795021e+00  2.8773146e+00  9.3531322e+00  1.8336586e+00
  8.0805283e+00  9.5689878e+00  7.0799055e+00  4.9151144e+00
  2.3026161e+00  3.8051813e+00  7.9677577e+00  6.0892525e+00
  9.0358343e+00  8.3774691e+00  8.6793871e+00  8.7717085e+00
  2.5660608e+00  4.4672542e+00  3.7499821e+00  6.0084786e+00
  6.4533715e+00  2.9849510e+00  6.0209244e-01  4.3385081e+00
  3.7030458e+00  9.5341787e+00  9.2192812e+00  7.2649994e+00
  6.9098902e+00  2.3594141e+00  5.7481446e+00  8.3444004e+00
  1.5395805e+00  8.0469885e+00  7.2350705e-01  7.6298466e+00
  7.5203185e+00  6.8629438e-01  6.1138077e+00  5.6196861e+00
  1.5752215e+00  1.0186056e+00  7.5847526e+00  4.9043198e+00
  1.0365025e+01  1.0957176e+01  1.0342247e+01  2.2840269e+00
  8.8948154e+00  2.1656735e+00  4.4965944e+00  6.3290133e+00
  1.9084119e+00  6.1508875e+00  7.1696973e-01  1.0796700e+00
  1.2289739e+00  3.7995231e+00  4.2479050e-01  4.0374312e+00
  6.2082539e+00  3.8042982e+00  1.1126742e+00 -2.8491318e-02
  2.3989291e+00  1.5484333e+00  9.0736609e+00  2.2606084e+00
  7.8717704e+00  5.8197365e+00  5.3839073e+00  4.4864936e+00
  9.7097330e+00  5.1985941e+00  7.8766909e+00  4.8876739e+00
  3.9949443e+00  7.6952267e+00  6.1897888e+00  1.1930196e+00
  4.7831144e+00  7.5184402e+00  7.9867325e+00  9.8890352e+00
  2.8126411e+00  6.6819544e+00  2.9722786e+00  4.3866873e+00
  9.6697216e+00  9.3694468e+00  8.5144243e+00  4.4165196e+00
  8.8433590e+00  4.9158731e+00  4.2708116e+00  6.1693680e-01
  6.9947834e+00  4.8547955e+00  8.8329058e+00  7.1928735e+00
  8.0629263e+00  3.3316441e+00  8.6988659e+00  5.4551535e+00
  5.0940285e+00  7.1205068e+00 -7.6878732e-01  1.4425153e+00
  2.9650118e+00  9.9633141e+00  1.3754138e+00  3.5696523e+00
  1.2369231e+00  3.2220390e+00  4.1846347e+00  9.2791929e+00
  7.7624817e+00  3.6623871e+00  7.8092593e-01  7.3296189e+00
  5.7747946e+00  2.3126864e-01  9.6106710e+00  9.5668274e-01
  8.3702803e+00  2.9747019e+00  4.3602333e+00  7.8842506e+00
  6.2896223e+00  8.5025053e+00  6.1606364e+00  1.0106425e+00
  8.6921835e+00  7.3920555e+00  7.1117039e+00  1.2270844e+00
  4.3614955e+00  2.5761406e+00  8.1967859e+00  6.2408938e+00
  9.4475508e+00  9.6550465e+00  8.4041348e+00  1.0130975e+01
  5.6460967e+00  4.0990400e-01 -8.8367611e-03  3.5952890e+00
  9.2217665e+00  8.4936142e+00  9.9719982e+00  6.2442482e-01
  1.5329283e+00  8.9031639e+00  2.9812365e+00  4.6210904e+00
  9.6318512e+00  3.3671608e+00  6.6170344e+00  4.0481849e+00
  7.8299704e+00  4.1430693e+00  2.1972313e+00  2.7806988e+00
  2.4690957e+00  6.2265091e+00  8.0078650e+00  8.5526848e+00
  7.8363638e+00  6.6496010e+00  1.7129709e+00  3.3299735e+00
  4.1951280e+00  7.1778541e+00  2.9357438e+00  3.2394106e+00
  4.3329515e+00  7.8274932e+00  5.8496819e+00  4.6137288e-01
  7.5736916e-01  3.1835232e+00  7.2212210e+00  7.3863716e+00
  7.1284332e+00  7.4827847e+00  2.6439285e+00  5.7008662e+00
  5.0590334e+00  8.0088997e+00  9.6267881e+00  2.4991486e+00
  8.2448721e+00  6.5369444e+00  6.2472978e+00  7.7897358e+00
  9.4234190e+00  9.6731400e-01  1.6939137e+00  7.3830414e+00
  1.0644419e+00  5.3757925e+00  4.4202948e+00  1.9308488e+00
  8.0857773e+00 -3.4219015e-01  8.6868877e+00  4.4470925e+00
  4.9024949e+00  5.6183209e+00  6.1064873e+00  3.4613369e+00
  1.2080189e+00  3.4117126e+00  4.1149378e-02  6.4430194e+00
  1.9570980e+00  9.7712898e+00  9.6677971e+00  6.8640056e+00
  6.0994020e+00  1.0187636e+01  8.8685141e+00  8.2290039e+00
  3.1689963e+00  3.6186795e+00  2.5079422e+00  3.3114364e+00
  9.9208021e+00  9.1239557e+00  1.3143113e+00  6.8661511e-01
  8.9672060e+00  5.2539353e+00  1.7683913e+00  6.8201876e+00
  6.3931870e+00  1.2865118e+00  3.4232042e+00  1.2203555e+00
  2.0503523e+00  8.4730494e-01  1.9659302e+00  6.6408830e+00
  3.0317956e-01  8.8737220e-01  2.3188889e-01  3.0580165e+00
  3.1296854e+00  2.1522398e+00  7.4903617e+00  9.1460247e+00
  5.0951142e+00  8.5311861e+00  3.9055674e+00 -2.2732937e-01
  4.0364518e+00  2.6478162e+00  5.1365023e+00  7.4299526e+00
  4.6355362e+00  8.9175758e+00  8.7688503e+00  5.5298843e+00
  4.4609528e+00  1.2880317e+00  4.0175514e+00  6.7396054e+00
  3.7963538e+00  1.2283164e+00  9.0873432e+00  7.1056828e+00
  5.5581961e+00  8.0034761e+00  8.3522511e+00  4.6975536e+00
  8.0432367e+00  8.6975918e+00  9.9233341e-01  6.2826734e+00
  5.9927521e+00  5.0778217e+00  8.8290005e+00  2.5841575e+00
  9.9096069e+00  8.9677849e+00  4.5229397e+00  8.1403732e+00
  6.6729965e+00  6.2468095e+00  3.7025385e+00  2.1858666e+00
  7.0194511e+00  8.6221571e+00 -2.3119065e-01  6.4518013e+00
  4.6490231e+00  9.1139078e+00  2.6489720e+00  4.4286499e+00
  4.7887325e+00  1.6389720e+00  8.0717764e+00  8.0382366e+00
  1.3237777e+00  2.9469595e+00  6.6192156e-01  9.5147648e+00
  6.1208944e+00  9.9296083e+00  5.8978138e+00  6.4843559e+00
  4.2908926e+00  3.5816567e+00  3.7703094e+00  7.1296864e+00
  3.3137634e+00  9.1458826e+00  1.0168221e+01  4.6002930e-01
  1.9140388e+00  7.9359615e-01  5.7083476e-01  2.0637333e+00
  4.4295535e+00  8.4761515e+00  2.1790206e+00  4.8846216e+00
  1.1725900e+01  6.4370713e+00  7.5755668e+00  5.3716149e+00
  9.8037472e+00  6.0171165e+00 -1.0524909e+00  2.8919909e+00
  3.9641018e+00  5.4104433e+00  7.7196703e+00  4.5299621e+00
  7.0386343e+00  8.1372356e+00  2.8667083e+00  9.8477182e+00
  6.2275105e+00  8.9304132e+00  5.8799353e+00  7.2770109e+00
  7.7765956e+00  9.1447611e+00  1.3774345e+00  4.7782230e+00
  4.5103283e+00  9.6529636e+00  1.0817671e+00  9.6128826e+00
  8.8991022e+00  7.8995752e-01  5.2336302e+00  7.1597772e+00
  6.9343681e+00  9.0601816e+00  8.0068483e+00  3.5910506e+00
  5.0274186e+00  7.0993495e+00  3.2836149e+00  1.3527107e+00
  3.3847008e+00  3.9555850e+00  8.4203587e+00  5.7436528e+00
  4.4528852e+00  8.3769274e+00  8.4812574e+00  9.8149929e+00
  8.4825897e+00  4.3883948e+00  1.1693200e+00  8.5065060e+00
  1.7731776e+00  3.4153044e+00  9.9896975e+00  8.2860680e+00
  6.3954239e+00  7.1741295e+00  6.7204058e-01  5.1233587e+00
  6.6728873e+00  3.4099829e+00  3.0468628e+00  2.3115411e+00
  4.1901307e+00  4.4959798e+00  5.7105017e+00  7.4096904e+00
  2.9691739e+00  2.5698562e+00  3.1576818e-01 -5.9249759e-02
  2.4639745e+00  7.8125792e+00  7.1327791e+00  7.7584710e+00
  6.2746820e+00  8.4847488e+00  6.9726362e+00  1.0046572e+01
  8.4835949e+00  6.7527709e+00  5.9673371e+00  4.3935239e-01
  1.1263874e+01  1.3709677e+00  7.3908615e+00  7.9875464e+00
  3.9839177e+00  2.2393181e+00  8.4422034e-01  6.9838266e+00
  4.5242758e+00  7.4394574e+00  9.1695070e+00  1.5673304e+00
  9.3064995e+00  3.2363920e+00  3.0193369e+00  9.7506819e+00
  9.7927599e+00  2.1529837e+00  5.8980074e+00  1.1057787e+00
  6.5593362e+00  8.3812113e+00  5.5978317e+00  3.2321651e+00
  3.8758488e+00  4.0856094e+00  7.0214200e+00  8.6556015e+00
  9.3241930e+00  2.9402196e-02  1.4503651e+00  4.8388457e-01
  2.0156007e+00  4.3253636e+00  5.0806727e+00  6.2870202e+00
  8.3587704e+00  9.1714058e+00  1.1041972e+01  6.7473054e+00
  8.3084793e+00  7.5109200e+00  3.7499793e+00  7.7249527e+00
  3.9467406e-01  6.4965940e-01  2.9256980e+00  4.6755557e+00
  6.6328969e+00  1.9519567e-01  7.0285888e+00  8.4598532e+00
  1.9452683e+00  4.4380093e+00  4.9697065e+00  4.4265666e+00
  7.9045653e+00  9.4661942e+00  8.0525227e+00  8.8097310e-01
  6.8595657e+00  1.7693057e+00  2.4858186e+00  1.4309098e+00
  1.8431244e+00  4.7576222e+00  6.7128339e+00  4.3999271e+00
  9.4328070e+00  2.1000056e+00  7.5769453e+00  8.7397270e+00
  5.8346295e+00  4.8793106e+00  4.7135677e+00  4.4952607e+00
  5.7733207e+00  3.9166284e+00  4.1439590e+00  6.8955579e+00
  6.8403614e-01  2.0110247e+00  9.0629015e+00  8.0548077e+00
  2.7293277e+00  4.2169027e+00  9.2188635e+00  9.0293961e+00
  6.1455669e+00  2.1301951e+00  5.6030965e-01  4.4237075e+00
  7.3219604e+00  8.5027437e+00  8.5191278e+00  4.1766196e-01
  2.4718022e+00  3.2887347e+00  1.7133644e+00  7.1094151e+00
  7.3223224e+00  4.3398414e+00  9.8931112e+00  1.3441966e+00
  9.0235968e+00  1.2211851e+00  2.6455071e+00  7.5472803e+00
  1.1029721e+00  4.7136912e+00  2.8467078e+00  7.3037176e+00
  9.4062443e+00  7.6552663e+00  8.4975100e+00  6.3747257e-02
  2.3440433e+00  5.1499615e+00  3.5230517e+00  1.9831378e+00
  3.5230274e+00  9.6046629e+00  3.3157225e+00  4.3171234e+00
  1.3997978e+00  7.7749600e+00  3.3477159e+00  1.9058161e+00
  2.5061352e+00  9.0734358e+00  2.0535131e+00  8.7670698e+00
  7.5356512e+00  1.0142322e+01 -3.0124056e-01  2.2794275e+00
  7.4697652e+00  1.9831645e+00  2.1713405e+00  2.2061615e+00
  1.5869830e+00  4.8229289e+00  1.4017915e+00  3.4431477e+00
  4.9791493e+00  7.0362866e-01  4.3548961e+00  6.2790900e-01
  5.3626833e+00  9.2004957e+00  7.4519486e+00  9.5844626e-01
  5.9674959e+00  8.2974005e+00  2.5478227e+00  7.6181903e+00
  8.8209562e+00  7.9951472e+00  2.8410530e-01  4.9098748e-01
  2.0705619e+00  2.6533947e+00  5.7332134e+00  2.9440532e+00
  7.7568593e+00  3.6492581e+00  2.4384577e+00  2.8873272e+00
  9.4621639e+00  9.1508560e+00  2.0058784e+00  6.5649538e+00
  2.7415826e+00  8.4922266e+00  4.9448359e-01  7.5271797e+00
 -1.5808821e-01  9.7426481e+00  6.3803730e+00  8.4051380e+00
  5.7340975e+00  4.6641579e+00  6.2364306e+00  5.1810746e+00
  5.3571901e+00  8.9868603e+00  1.8257052e+00  8.8656920e-01
  4.3585706e+00  3.5430098e+00  7.3958582e-01  8.3649902e+00
  7.7803888e+00  5.7408032e+00  9.7680950e+00  6.9590604e-01
  7.2661672e+00  2.1069894e+00  3.6764739e+00  3.4602623e+00
  7.6012840e+00  2.0565724e-01  8.5318031e+00  7.2798491e+00
  1.4081079e+00  8.3596611e+00  7.2540979e+00  9.5279789e+00
  7.3339424e+00  5.2405219e+00  8.5954704e+00  2.9429979e+00
  5.2126360e+00  3.8612814e+00  9.0659313e+00  1.9871573e+00
  3.8985163e-01  3.2772667e+00  4.5025587e+00  1.2284964e-02
  6.7665458e+00  9.5286417e+00  7.1374736e+00  6.0702968e+00
  9.5389080e+00  9.5242043e+00  8.4405804e+00  6.5415311e+00
  4.7715144e+00  1.9164640e-01  6.2476826e+00  9.6162710e+00
  8.1386156e+00  3.4102411e+00  1.4985125e+00  7.9778295e+00
  7.4183102e+00  9.5704803e+00  7.8087254e+00  6.9231396e+00
  1.3841813e+00  4.7959905e+00  2.9273345e+00  5.1850367e+00
  3.0295143e+00  8.6389799e+00  9.0257702e+00  3.6582994e+00
  5.9157324e+00  4.1758962e+00  9.3391609e+00  1.7730776e+00
  7.6125379e+00  1.0046360e+01  2.1057978e+00  1.7478250e+00
  7.1132212e+00  7.9645081e+00  5.2505498e+00  6.4574647e+00
  3.2315047e+00  4.3446302e+00  1.2056727e+00  2.9674428e+00
  2.7837610e+00  4.7524495e+00  9.8256521e+00  1.5932522e+00
  4.8396316e+00  5.9174523e+00  9.4890871e+00  1.2948707e+00
  9.0378551e+00  1.3124785e+00  5.4293876e+00  4.4993534e+00
  2.0538125e+00  3.5617321e+00  5.4850354e+00  8.2304430e+00
  9.7063475e+00  4.5277615e+00  8.3297014e+00  6.6988935e+00
  3.0370085e+00  2.5210819e+00  4.3796597e+00  5.5016708e+00
  1.9651670e+00  2.4778838e+00  5.8789811e+00  3.1068649e+00
  8.4105711e+00  2.6629505e+00 -3.3057988e-01  9.0704960e-01
  9.3188791e+00  1.0806879e+00 -8.1481934e-03  9.1659679e+00
  2.1467557e+00  7.2326632e+00  8.2058630e+00  5.8045855e+00
  8.4636183e+00  6.8212204e+00  5.0721443e-01  5.9133248e+00
  7.4281392e+00  7.8691220e+00 -6.8311334e-02  7.2124262e+00
  8.6880360e+00  6.6583366e+00  5.0127316e+00  4.6381230e+00
  5.9561200e+00  6.8466635e+00  9.5994196e+00  6.0355244e+00
  8.7480297e+00  7.6578970e+00  1.2954912e+00  4.2609344e+00
  2.7702582e+00  3.0329621e+00  3.6327574e+00  3.4195125e+00
  5.5413127e+00  5.8191652e+00  2.7070973e+00  1.6614884e+00
  3.8416210e-01  6.2802663e+00  2.0622129e+00 -6.8790317e-01
  9.2128534e+00  4.7458625e+00  9.4553316e-01  8.3560362e+00
  9.9401188e+00  3.5302291e+00  4.7089720e-01  1.3786711e+00
  5.3229847e+00  9.2913418e+00  1.6849303e+00  8.2535496e+00
 -2.5821114e-01  4.1421123e+00  6.4032269e+00  6.6551906e-01
  5.3515515e+00  9.1520185e+00  1.5094744e+00  7.4785428e+00
  6.0626564e+00  1.8558639e+00  4.4214793e-02  7.5862879e-01
  4.2469244e+00  8.8614159e+00  6.5688152e+00  7.3740344e+00
  4.8993049e+00  5.7953315e+00  9.2521513e-01  8.7253218e+00
  7.7945423e+00  9.9947720e+00  3.9001837e+00  2.8082497e+00
  2.2034130e+00  9.5151176e+00  7.4653130e+00  5.4289103e-01
  5.5686536e+00  4.1999950e+00  1.3804873e+00  1.5220041e+00
  9.6445208e+00  3.1844208e+00  8.2594252e+00  5.8706766e-01
  3.8130655e+00  9.4813788e-01  1.4116070e-01  5.6962514e+00
  2.8564551e+00  7.0057955e+00  6.3632298e+00  1.4823904e+00
  9.5153828e+00  7.8791199e+00  2.7109826e+00  5.3147154e+00
  7.3835139e+00  3.6906118e+00  4.5995116e+00  4.1400166e+00
  6.1948090e+00  8.8411551e+00  1.6546024e+00  8.7375402e+00
  5.7898629e-01  6.4826312e+00  4.3135948e+00  7.4583459e+00
  6.8681207e+00  5.0527821e+00  6.3631139e+00  3.5951567e+00]
Epoch 1/1000
2023-09-10 07:33:18.130 
Epoch 1/1000 
	 loss: 1673.9572, MinusLogProbMetric: 1673.9572, val_loss: 883.5455, val_MinusLogProbMetric: 883.5455

Epoch 1: val_loss improved from inf to 883.54547, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 48s - loss: 1673.9572 - MinusLogProbMetric: 1673.9572 - val_loss: 883.5455 - val_MinusLogProbMetric: 883.5455 - lr: 0.0010 - 48s/epoch - 245ms/step
Epoch 2/1000
2023-09-10 07:33:28.606 
Epoch 2/1000 
	 loss: 635.9724, MinusLogProbMetric: 635.9724, val_loss: 529.2914, val_MinusLogProbMetric: 529.2914

Epoch 2: val_loss improved from 883.54547 to 529.29144, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 635.9724 - MinusLogProbMetric: 635.9724 - val_loss: 529.2914 - val_MinusLogProbMetric: 529.2914 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 3/1000
2023-09-10 07:33:37.737 
Epoch 3/1000 
	 loss: 647.5198, MinusLogProbMetric: 647.5198, val_loss: 526.3024, val_MinusLogProbMetric: 526.3024

Epoch 3: val_loss improved from 529.29144 to 526.30237, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 647.5198 - MinusLogProbMetric: 647.5198 - val_loss: 526.3024 - val_MinusLogProbMetric: 526.3024 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 4/1000
2023-09-10 07:33:48.324 
Epoch 4/1000 
	 loss: 510.5529, MinusLogProbMetric: 510.5529, val_loss: 486.5223, val_MinusLogProbMetric: 486.5223

Epoch 4: val_loss improved from 526.30237 to 486.52231, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 510.5529 - MinusLogProbMetric: 510.5529 - val_loss: 486.5223 - val_MinusLogProbMetric: 486.5223 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 5/1000
2023-09-10 07:33:56.156 
Epoch 5/1000 
	 loss: 495.2986, MinusLogProbMetric: 495.2986, val_loss: 564.0060, val_MinusLogProbMetric: 564.0060

Epoch 5: val_loss did not improve from 486.52231
196/196 - 7s - loss: 495.2986 - MinusLogProbMetric: 495.2986 - val_loss: 564.0060 - val_MinusLogProbMetric: 564.0060 - lr: 0.0010 - 7s/epoch - 38ms/step
Epoch 6/1000
2023-09-10 07:34:04.718 
Epoch 6/1000 
	 loss: 482.1940, MinusLogProbMetric: 482.1940, val_loss: 481.6351, val_MinusLogProbMetric: 481.6351

Epoch 6: val_loss improved from 486.52231 to 481.63513, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 482.1940 - MinusLogProbMetric: 482.1940 - val_loss: 481.6351 - val_MinusLogProbMetric: 481.6351 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 7/1000
2023-09-10 07:34:12.446 
Epoch 7/1000 
	 loss: 470.5742, MinusLogProbMetric: 470.5742, val_loss: 453.0226, val_MinusLogProbMetric: 453.0226

Epoch 7: val_loss improved from 481.63513 to 453.02255, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 470.5742 - MinusLogProbMetric: 470.5742 - val_loss: 453.0226 - val_MinusLogProbMetric: 453.0226 - lr: 0.0010 - 8s/epoch - 40ms/step
Epoch 8/1000
2023-09-10 07:34:21.908 
Epoch 8/1000 
	 loss: 459.4138, MinusLogProbMetric: 459.4138, val_loss: 456.4551, val_MinusLogProbMetric: 456.4551

Epoch 8: val_loss did not improve from 453.02255
196/196 - 9s - loss: 459.4138 - MinusLogProbMetric: 459.4138 - val_loss: 456.4551 - val_MinusLogProbMetric: 456.4551 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 9/1000
2023-09-10 07:34:31.643 
Epoch 9/1000 
	 loss: 467.7227, MinusLogProbMetric: 467.7227, val_loss: 457.0190, val_MinusLogProbMetric: 457.0190

Epoch 9: val_loss did not improve from 453.02255
196/196 - 10s - loss: 467.7227 - MinusLogProbMetric: 467.7227 - val_loss: 457.0190 - val_MinusLogProbMetric: 457.0190 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 10/1000
2023-09-10 07:34:39.719 
Epoch 10/1000 
	 loss: 461.5418, MinusLogProbMetric: 461.5418, val_loss: 452.1055, val_MinusLogProbMetric: 452.1055

Epoch 10: val_loss improved from 453.02255 to 452.10553, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 461.5418 - MinusLogProbMetric: 461.5418 - val_loss: 452.1055 - val_MinusLogProbMetric: 452.1055 - lr: 0.0010 - 8s/epoch - 43ms/step
Epoch 11/1000
2023-09-10 07:34:47.077 
Epoch 11/1000 
	 loss: 449.1563, MinusLogProbMetric: 449.1563, val_loss: 441.9642, val_MinusLogProbMetric: 441.9642

Epoch 11: val_loss improved from 452.10553 to 441.96423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 449.1563 - MinusLogProbMetric: 449.1563 - val_loss: 441.9642 - val_MinusLogProbMetric: 441.9642 - lr: 0.0010 - 7s/epoch - 37ms/step
Epoch 12/1000
2023-09-10 07:34:57.544 
Epoch 12/1000 
	 loss: 445.5565, MinusLogProbMetric: 445.5565, val_loss: 443.5462, val_MinusLogProbMetric: 443.5462

Epoch 12: val_loss did not improve from 441.96423
196/196 - 10s - loss: 445.5565 - MinusLogProbMetric: 445.5565 - val_loss: 443.5462 - val_MinusLogProbMetric: 443.5462 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 13/1000
2023-09-10 07:35:05.550 
Epoch 13/1000 
	 loss: 448.4858, MinusLogProbMetric: 448.4858, val_loss: 465.1517, val_MinusLogProbMetric: 465.1517

Epoch 13: val_loss did not improve from 441.96423
196/196 - 8s - loss: 448.4858 - MinusLogProbMetric: 448.4858 - val_loss: 465.1517 - val_MinusLogProbMetric: 465.1517 - lr: 0.0010 - 8s/epoch - 41ms/step
Epoch 14/1000
2023-09-10 07:35:14.410 
Epoch 14/1000 
	 loss: 439.2449, MinusLogProbMetric: 439.2449, val_loss: 436.3900, val_MinusLogProbMetric: 436.3900

Epoch 14: val_loss improved from 441.96423 to 436.39001, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 439.2449 - MinusLogProbMetric: 439.2449 - val_loss: 436.3900 - val_MinusLogProbMetric: 436.3900 - lr: 0.0010 - 9s/epoch - 48ms/step
Epoch 15/1000
2023-09-10 07:35:23.272 
Epoch 15/1000 
	 loss: 435.8445, MinusLogProbMetric: 435.8445, val_loss: 435.5812, val_MinusLogProbMetric: 435.5812

Epoch 15: val_loss improved from 436.39001 to 435.58118, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 435.8445 - MinusLogProbMetric: 435.8445 - val_loss: 435.5812 - val_MinusLogProbMetric: 435.5812 - lr: 0.0010 - 9s/epoch - 45ms/step
Epoch 16/1000
2023-09-10 07:35:31.457 
Epoch 16/1000 
	 loss: 433.8441, MinusLogProbMetric: 433.8441, val_loss: 429.6103, val_MinusLogProbMetric: 429.6103

Epoch 16: val_loss improved from 435.58118 to 429.61032, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 433.8441 - MinusLogProbMetric: 433.8441 - val_loss: 429.6103 - val_MinusLogProbMetric: 429.6103 - lr: 0.0010 - 8s/epoch - 41ms/step
Epoch 17/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 153: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-10 07:35:37.709 
Epoch 17/1000 
	 loss: nan, MinusLogProbMetric: 5921169.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 17: val_loss did not improve from 429.61032
196/196 - 6s - loss: nan - MinusLogProbMetric: 5921169.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 6s/epoch - 30ms/step
The loss history contains NaN values.
Training failed: trying again with seed 978294 and lr 0.0003333333333333333.
===========
Generating train data for run 334.
===========
Train data generated in 39.59 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_334/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 440}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_334/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_334/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_334
self.data_kwargs: {'seed': 440}
self.x_data: [[ 5.975928    0.18705393  4.579732   ...  5.052782    6.363114
   3.5951567 ]
 [ 8.245443    4.908681    5.163151   ...  2.2962263   8.159441
   6.519855  ]
 [ 5.979998    0.06695901  4.8433633  ...  4.708263    6.650848
   7.1221867 ]
 ...
 [ 8.616862    3.848415    5.171632   ...  3.7576704   8.165923
   7.0578055 ]
 [ 8.209467    4.7939653   5.2042055  ...  3.0320504   8.283145
   7.183658  ]
 [ 6.448749   -0.35270444  4.789608   ...  4.7734337   6.228376
   4.513551  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_40 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_4 (LogProbLa  (None,)                  4509200   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,509,200
Trainable params: 4,509,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_4/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_4'")
self.model: <keras.engine.functional.Functional object at 0x7f1d64c3b430>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f1d64c8cf70>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f1d64c8cf70>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f1d5c5aaad0>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f1d64bb1d80>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f1d64bb2260>, <keras.callbacks.ModelCheckpoint object at 0x7f1d64bb2320>, <keras.callbacks.EarlyStopping object at 0x7f1d64bb2590>, <keras.callbacks.ReduceLROnPlateau object at 0x7f1d64bb25c0>, <keras.callbacks.TerminateOnNaN object at 0x7f1d64bb2200>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.079587 ,  6.1984696,  7.6198487, ...,  9.8733   ,  1.2133766,
         6.3345976],
       [ 5.234588 ,  7.498538 ,  5.7464294, ..., 10.933875 ,  0.4187709,
         6.5884576],
       [ 7.800186 ,  4.269176 ,  5.1269364, ...,  2.4002125,  8.245506 ,
         6.792781 ],
       ...,
       [ 5.657867 ,  0.4851762,  4.7903004, ...,  5.063982 ,  6.747285 ,
         3.2595367],
       [ 7.8507524,  4.4384494,  5.2666016, ...,  3.8509533,  8.5486555,
         6.834612 ],
       [ 8.079243 ,  4.798266 ,  5.2613087, ...,  3.0539343,  8.016419 ,
         6.717349 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 334/360 with hyperparameters:
timestamp = 2023-09-10 07:36:20.289134
ndims = 1000
seed_train = 440
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 4509200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 5.9759278e+00  1.8705393e-01  4.5797319e+00  7.3813486e+00
  4.9839023e-01  9.1128473e+00  5.1425128e+00  1.0601972e+00
  1.8690022e+00  9.7343407e+00  6.0127983e+00  1.2467406e+00
  2.1360984e+00  5.5741024e+00  8.1917816e-01  3.7718730e+00
  5.1906404e+00  3.0766895e+00  6.0415301e+00  7.3736296e+00
  2.8012948e+00  7.5884948e+00  7.1015620e+00  1.0307134e+01
  6.5797253e+00  7.9973593e+00  3.9854233e+00  1.8046517e+00
  9.7217255e+00  1.0974171e+00  5.1221895e+00  8.3442938e-01
  9.2890491e+00  9.2900143e+00  7.2703452e+00  3.3996055e+00
  2.9350464e+00  2.6254275e+00  1.3082062e+00  5.2701192e+00
  1.3725662e+00  3.2777114e+00  6.2085199e+00  7.2575483e+00
  5.7510644e-02  4.4865317e+00  6.2462301e+00  8.9988785e+00
  4.7538991e+00  9.9086142e+00  2.3183393e+00  4.7639337e-01
  4.5737805e+00  2.5859902e+00  8.1949062e+00  2.6238203e+00
  3.0378006e+00  7.9298201e+00  8.4647675e+00  4.9066219e+00
  6.4023814e+00  3.9823089e+00 -4.2869711e-01  1.5175290e-02
  6.1451683e+00 -2.2587168e-01 -9.5339119e-02  8.5243511e+00
  9.1139994e+00 -1.0624671e-01 -6.7571568e-01  9.4670458e+00
  2.6047506e+00  9.5776010e-01  6.6801319e+00  9.6847260e-01
  3.1678288e+00  9.7247944e+00  6.2540312e+00  6.3839302e+00
  3.4341021e+00  7.7830091e+00  1.6556205e+00  9.9951563e+00
  8.6061764e+00  6.2981930e+00  1.2968564e+00  8.2717495e+00
  9.2503586e+00  5.0443635e+00  4.8242106e+00  1.5439949e+00
  7.4578109e+00  9.9600182e+00  1.0782404e+00  7.4997787e+00
 -6.1716002e-01  1.0503052e+01  6.2509499e+00  5.6324120e+00
  2.8450089e+00  8.2806787e+00  2.7606368e+00  8.2886658e+00
  1.0619202e+01  7.7074742e+00  4.5604439e+00  1.0194874e+00
  4.4170108e+00  4.2977200e+00  1.7771544e+00  4.3124924e+00
  3.5204492e+00  7.5383079e-01  4.9013953e+00  1.8483464e+00
  5.2527041e+00  2.9501736e-01  9.0906477e+00  6.7014809e+00
  5.4151597e+00  8.2172470e+00  9.6032486e+00  1.1688474e+00
  7.4652319e+00  9.9523344e+00  1.0106757e+01  5.6442394e+00
  1.2893100e+00  6.2976708e+00 -6.0980135e-01  2.0239670e+00
  9.4813910e+00  9.1562080e-01  6.0650496e+00  3.3473954e+00
  9.4390936e+00  6.5065956e+00  2.8910985e+00  7.6608114e+00
  1.1822252e+00  2.8502061e+00  2.2126217e+00  7.5678649e+00
  1.3060629e+00  4.1730914e+00  2.7150269e+00  4.2508979e+00
  3.1311915e+00  8.0161762e+00  1.1140229e+00  6.6955643e+00
  2.3109643e+00  2.5608201e+00  9.0579319e+00  8.9470587e+00
  1.9467136e+00  7.7616472e+00  1.1755015e+00  6.9813056e+00
  7.1541829e+00  1.1629101e+00  4.0641637e+00  8.5495291e+00
  1.0037423e+00  3.7546790e-01  5.4117308e+00  3.8483400e+00
  7.5943928e+00  1.0048924e+01  3.0955133e+00  3.7507610e+00
  4.7484083e+00  5.6718163e+00  9.9414043e+00  6.6468272e+00
  5.5795021e+00  2.8773146e+00  9.3531322e+00  1.8336586e+00
  8.0805283e+00  9.5689878e+00  7.0799055e+00  4.9151144e+00
  2.3026161e+00  3.8051813e+00  7.9677577e+00  6.0892525e+00
  9.0358343e+00  8.3774691e+00  8.6793871e+00  8.7717085e+00
  2.5660608e+00  4.4672542e+00  3.7499821e+00  6.0084786e+00
  6.4533715e+00  2.9849510e+00  6.0209244e-01  4.3385081e+00
  3.7030458e+00  9.5341787e+00  9.2192812e+00  7.2649994e+00
  6.9098902e+00  2.3594141e+00  5.7481446e+00  8.3444004e+00
  1.5395805e+00  8.0469885e+00  7.2350705e-01  7.6298466e+00
  7.5203185e+00  6.8629438e-01  6.1138077e+00  5.6196861e+00
  1.5752215e+00  1.0186056e+00  7.5847526e+00  4.9043198e+00
  1.0365025e+01  1.0957176e+01  1.0342247e+01  2.2840269e+00
  8.8948154e+00  2.1656735e+00  4.4965944e+00  6.3290133e+00
  1.9084119e+00  6.1508875e+00  7.1696973e-01  1.0796700e+00
  1.2289739e+00  3.7995231e+00  4.2479050e-01  4.0374312e+00
  6.2082539e+00  3.8042982e+00  1.1126742e+00 -2.8491318e-02
  2.3989291e+00  1.5484333e+00  9.0736609e+00  2.2606084e+00
  7.8717704e+00  5.8197365e+00  5.3839073e+00  4.4864936e+00
  9.7097330e+00  5.1985941e+00  7.8766909e+00  4.8876739e+00
  3.9949443e+00  7.6952267e+00  6.1897888e+00  1.1930196e+00
  4.7831144e+00  7.5184402e+00  7.9867325e+00  9.8890352e+00
  2.8126411e+00  6.6819544e+00  2.9722786e+00  4.3866873e+00
  9.6697216e+00  9.3694468e+00  8.5144243e+00  4.4165196e+00
  8.8433590e+00  4.9158731e+00  4.2708116e+00  6.1693680e-01
  6.9947834e+00  4.8547955e+00  8.8329058e+00  7.1928735e+00
  8.0629263e+00  3.3316441e+00  8.6988659e+00  5.4551535e+00
  5.0940285e+00  7.1205068e+00 -7.6878732e-01  1.4425153e+00
  2.9650118e+00  9.9633141e+00  1.3754138e+00  3.5696523e+00
  1.2369231e+00  3.2220390e+00  4.1846347e+00  9.2791929e+00
  7.7624817e+00  3.6623871e+00  7.8092593e-01  7.3296189e+00
  5.7747946e+00  2.3126864e-01  9.6106710e+00  9.5668274e-01
  8.3702803e+00  2.9747019e+00  4.3602333e+00  7.8842506e+00
  6.2896223e+00  8.5025053e+00  6.1606364e+00  1.0106425e+00
  8.6921835e+00  7.3920555e+00  7.1117039e+00  1.2270844e+00
  4.3614955e+00  2.5761406e+00  8.1967859e+00  6.2408938e+00
  9.4475508e+00  9.6550465e+00  8.4041348e+00  1.0130975e+01
  5.6460967e+00  4.0990400e-01 -8.8367611e-03  3.5952890e+00
  9.2217665e+00  8.4936142e+00  9.9719982e+00  6.2442482e-01
  1.5329283e+00  8.9031639e+00  2.9812365e+00  4.6210904e+00
  9.6318512e+00  3.3671608e+00  6.6170344e+00  4.0481849e+00
  7.8299704e+00  4.1430693e+00  2.1972313e+00  2.7806988e+00
  2.4690957e+00  6.2265091e+00  8.0078650e+00  8.5526848e+00
  7.8363638e+00  6.6496010e+00  1.7129709e+00  3.3299735e+00
  4.1951280e+00  7.1778541e+00  2.9357438e+00  3.2394106e+00
  4.3329515e+00  7.8274932e+00  5.8496819e+00  4.6137288e-01
  7.5736916e-01  3.1835232e+00  7.2212210e+00  7.3863716e+00
  7.1284332e+00  7.4827847e+00  2.6439285e+00  5.7008662e+00
  5.0590334e+00  8.0088997e+00  9.6267881e+00  2.4991486e+00
  8.2448721e+00  6.5369444e+00  6.2472978e+00  7.7897358e+00
  9.4234190e+00  9.6731400e-01  1.6939137e+00  7.3830414e+00
  1.0644419e+00  5.3757925e+00  4.4202948e+00  1.9308488e+00
  8.0857773e+00 -3.4219015e-01  8.6868877e+00  4.4470925e+00
  4.9024949e+00  5.6183209e+00  6.1064873e+00  3.4613369e+00
  1.2080189e+00  3.4117126e+00  4.1149378e-02  6.4430194e+00
  1.9570980e+00  9.7712898e+00  9.6677971e+00  6.8640056e+00
  6.0994020e+00  1.0187636e+01  8.8685141e+00  8.2290039e+00
  3.1689963e+00  3.6186795e+00  2.5079422e+00  3.3114364e+00
  9.9208021e+00  9.1239557e+00  1.3143113e+00  6.8661511e-01
  8.9672060e+00  5.2539353e+00  1.7683913e+00  6.8201876e+00
  6.3931870e+00  1.2865118e+00  3.4232042e+00  1.2203555e+00
  2.0503523e+00  8.4730494e-01  1.9659302e+00  6.6408830e+00
  3.0317956e-01  8.8737220e-01  2.3188889e-01  3.0580165e+00
  3.1296854e+00  2.1522398e+00  7.4903617e+00  9.1460247e+00
  5.0951142e+00  8.5311861e+00  3.9055674e+00 -2.2732937e-01
  4.0364518e+00  2.6478162e+00  5.1365023e+00  7.4299526e+00
  4.6355362e+00  8.9175758e+00  8.7688503e+00  5.5298843e+00
  4.4609528e+00  1.2880317e+00  4.0175514e+00  6.7396054e+00
  3.7963538e+00  1.2283164e+00  9.0873432e+00  7.1056828e+00
  5.5581961e+00  8.0034761e+00  8.3522511e+00  4.6975536e+00
  8.0432367e+00  8.6975918e+00  9.9233341e-01  6.2826734e+00
  5.9927521e+00  5.0778217e+00  8.8290005e+00  2.5841575e+00
  9.9096069e+00  8.9677849e+00  4.5229397e+00  8.1403732e+00
  6.6729965e+00  6.2468095e+00  3.7025385e+00  2.1858666e+00
  7.0194511e+00  8.6221571e+00 -2.3119065e-01  6.4518013e+00
  4.6490231e+00  9.1139078e+00  2.6489720e+00  4.4286499e+00
  4.7887325e+00  1.6389720e+00  8.0717764e+00  8.0382366e+00
  1.3237777e+00  2.9469595e+00  6.6192156e-01  9.5147648e+00
  6.1208944e+00  9.9296083e+00  5.8978138e+00  6.4843559e+00
  4.2908926e+00  3.5816567e+00  3.7703094e+00  7.1296864e+00
  3.3137634e+00  9.1458826e+00  1.0168221e+01  4.6002930e-01
  1.9140388e+00  7.9359615e-01  5.7083476e-01  2.0637333e+00
  4.4295535e+00  8.4761515e+00  2.1790206e+00  4.8846216e+00
  1.1725900e+01  6.4370713e+00  7.5755668e+00  5.3716149e+00
  9.8037472e+00  6.0171165e+00 -1.0524909e+00  2.8919909e+00
  3.9641018e+00  5.4104433e+00  7.7196703e+00  4.5299621e+00
  7.0386343e+00  8.1372356e+00  2.8667083e+00  9.8477182e+00
  6.2275105e+00  8.9304132e+00  5.8799353e+00  7.2770109e+00
  7.7765956e+00  9.1447611e+00  1.3774345e+00  4.7782230e+00
  4.5103283e+00  9.6529636e+00  1.0817671e+00  9.6128826e+00
  8.8991022e+00  7.8995752e-01  5.2336302e+00  7.1597772e+00
  6.9343681e+00  9.0601816e+00  8.0068483e+00  3.5910506e+00
  5.0274186e+00  7.0993495e+00  3.2836149e+00  1.3527107e+00
  3.3847008e+00  3.9555850e+00  8.4203587e+00  5.7436528e+00
  4.4528852e+00  8.3769274e+00  8.4812574e+00  9.8149929e+00
  8.4825897e+00  4.3883948e+00  1.1693200e+00  8.5065060e+00
  1.7731776e+00  3.4153044e+00  9.9896975e+00  8.2860680e+00
  6.3954239e+00  7.1741295e+00  6.7204058e-01  5.1233587e+00
  6.6728873e+00  3.4099829e+00  3.0468628e+00  2.3115411e+00
  4.1901307e+00  4.4959798e+00  5.7105017e+00  7.4096904e+00
  2.9691739e+00  2.5698562e+00  3.1576818e-01 -5.9249759e-02
  2.4639745e+00  7.8125792e+00  7.1327791e+00  7.7584710e+00
  6.2746820e+00  8.4847488e+00  6.9726362e+00  1.0046572e+01
  8.4835949e+00  6.7527709e+00  5.9673371e+00  4.3935239e-01
  1.1263874e+01  1.3709677e+00  7.3908615e+00  7.9875464e+00
  3.9839177e+00  2.2393181e+00  8.4422034e-01  6.9838266e+00
  4.5242758e+00  7.4394574e+00  9.1695070e+00  1.5673304e+00
  9.3064995e+00  3.2363920e+00  3.0193369e+00  9.7506819e+00
  9.7927599e+00  2.1529837e+00  5.8980074e+00  1.1057787e+00
  6.5593362e+00  8.3812113e+00  5.5978317e+00  3.2321651e+00
  3.8758488e+00  4.0856094e+00  7.0214200e+00  8.6556015e+00
  9.3241930e+00  2.9402196e-02  1.4503651e+00  4.8388457e-01
  2.0156007e+00  4.3253636e+00  5.0806727e+00  6.2870202e+00
  8.3587704e+00  9.1714058e+00  1.1041972e+01  6.7473054e+00
  8.3084793e+00  7.5109200e+00  3.7499793e+00  7.7249527e+00
  3.9467406e-01  6.4965940e-01  2.9256980e+00  4.6755557e+00
  6.6328969e+00  1.9519567e-01  7.0285888e+00  8.4598532e+00
  1.9452683e+00  4.4380093e+00  4.9697065e+00  4.4265666e+00
  7.9045653e+00  9.4661942e+00  8.0525227e+00  8.8097310e-01
  6.8595657e+00  1.7693057e+00  2.4858186e+00  1.4309098e+00
  1.8431244e+00  4.7576222e+00  6.7128339e+00  4.3999271e+00
  9.4328070e+00  2.1000056e+00  7.5769453e+00  8.7397270e+00
  5.8346295e+00  4.8793106e+00  4.7135677e+00  4.4952607e+00
  5.7733207e+00  3.9166284e+00  4.1439590e+00  6.8955579e+00
  6.8403614e-01  2.0110247e+00  9.0629015e+00  8.0548077e+00
  2.7293277e+00  4.2169027e+00  9.2188635e+00  9.0293961e+00
  6.1455669e+00  2.1301951e+00  5.6030965e-01  4.4237075e+00
  7.3219604e+00  8.5027437e+00  8.5191278e+00  4.1766196e-01
  2.4718022e+00  3.2887347e+00  1.7133644e+00  7.1094151e+00
  7.3223224e+00  4.3398414e+00  9.8931112e+00  1.3441966e+00
  9.0235968e+00  1.2211851e+00  2.6455071e+00  7.5472803e+00
  1.1029721e+00  4.7136912e+00  2.8467078e+00  7.3037176e+00
  9.4062443e+00  7.6552663e+00  8.4975100e+00  6.3747257e-02
  2.3440433e+00  5.1499615e+00  3.5230517e+00  1.9831378e+00
  3.5230274e+00  9.6046629e+00  3.3157225e+00  4.3171234e+00
  1.3997978e+00  7.7749600e+00  3.3477159e+00  1.9058161e+00
  2.5061352e+00  9.0734358e+00  2.0535131e+00  8.7670698e+00
  7.5356512e+00  1.0142322e+01 -3.0124056e-01  2.2794275e+00
  7.4697652e+00  1.9831645e+00  2.1713405e+00  2.2061615e+00
  1.5869830e+00  4.8229289e+00  1.4017915e+00  3.4431477e+00
  4.9791493e+00  7.0362866e-01  4.3548961e+00  6.2790900e-01
  5.3626833e+00  9.2004957e+00  7.4519486e+00  9.5844626e-01
  5.9674959e+00  8.2974005e+00  2.5478227e+00  7.6181903e+00
  8.8209562e+00  7.9951472e+00  2.8410530e-01  4.9098748e-01
  2.0705619e+00  2.6533947e+00  5.7332134e+00  2.9440532e+00
  7.7568593e+00  3.6492581e+00  2.4384577e+00  2.8873272e+00
  9.4621639e+00  9.1508560e+00  2.0058784e+00  6.5649538e+00
  2.7415826e+00  8.4922266e+00  4.9448359e-01  7.5271797e+00
 -1.5808821e-01  9.7426481e+00  6.3803730e+00  8.4051380e+00
  5.7340975e+00  4.6641579e+00  6.2364306e+00  5.1810746e+00
  5.3571901e+00  8.9868603e+00  1.8257052e+00  8.8656920e-01
  4.3585706e+00  3.5430098e+00  7.3958582e-01  8.3649902e+00
  7.7803888e+00  5.7408032e+00  9.7680950e+00  6.9590604e-01
  7.2661672e+00  2.1069894e+00  3.6764739e+00  3.4602623e+00
  7.6012840e+00  2.0565724e-01  8.5318031e+00  7.2798491e+00
  1.4081079e+00  8.3596611e+00  7.2540979e+00  9.5279789e+00
  7.3339424e+00  5.2405219e+00  8.5954704e+00  2.9429979e+00
  5.2126360e+00  3.8612814e+00  9.0659313e+00  1.9871573e+00
  3.8985163e-01  3.2772667e+00  4.5025587e+00  1.2284964e-02
  6.7665458e+00  9.5286417e+00  7.1374736e+00  6.0702968e+00
  9.5389080e+00  9.5242043e+00  8.4405804e+00  6.5415311e+00
  4.7715144e+00  1.9164640e-01  6.2476826e+00  9.6162710e+00
  8.1386156e+00  3.4102411e+00  1.4985125e+00  7.9778295e+00
  7.4183102e+00  9.5704803e+00  7.8087254e+00  6.9231396e+00
  1.3841813e+00  4.7959905e+00  2.9273345e+00  5.1850367e+00
  3.0295143e+00  8.6389799e+00  9.0257702e+00  3.6582994e+00
  5.9157324e+00  4.1758962e+00  9.3391609e+00  1.7730776e+00
  7.6125379e+00  1.0046360e+01  2.1057978e+00  1.7478250e+00
  7.1132212e+00  7.9645081e+00  5.2505498e+00  6.4574647e+00
  3.2315047e+00  4.3446302e+00  1.2056727e+00  2.9674428e+00
  2.7837610e+00  4.7524495e+00  9.8256521e+00  1.5932522e+00
  4.8396316e+00  5.9174523e+00  9.4890871e+00  1.2948707e+00
  9.0378551e+00  1.3124785e+00  5.4293876e+00  4.4993534e+00
  2.0538125e+00  3.5617321e+00  5.4850354e+00  8.2304430e+00
  9.7063475e+00  4.5277615e+00  8.3297014e+00  6.6988935e+00
  3.0370085e+00  2.5210819e+00  4.3796597e+00  5.5016708e+00
  1.9651670e+00  2.4778838e+00  5.8789811e+00  3.1068649e+00
  8.4105711e+00  2.6629505e+00 -3.3057988e-01  9.0704960e-01
  9.3188791e+00  1.0806879e+00 -8.1481934e-03  9.1659679e+00
  2.1467557e+00  7.2326632e+00  8.2058630e+00  5.8045855e+00
  8.4636183e+00  6.8212204e+00  5.0721443e-01  5.9133248e+00
  7.4281392e+00  7.8691220e+00 -6.8311334e-02  7.2124262e+00
  8.6880360e+00  6.6583366e+00  5.0127316e+00  4.6381230e+00
  5.9561200e+00  6.8466635e+00  9.5994196e+00  6.0355244e+00
  8.7480297e+00  7.6578970e+00  1.2954912e+00  4.2609344e+00
  2.7702582e+00  3.0329621e+00  3.6327574e+00  3.4195125e+00
  5.5413127e+00  5.8191652e+00  2.7070973e+00  1.6614884e+00
  3.8416210e-01  6.2802663e+00  2.0622129e+00 -6.8790317e-01
  9.2128534e+00  4.7458625e+00  9.4553316e-01  8.3560362e+00
  9.9401188e+00  3.5302291e+00  4.7089720e-01  1.3786711e+00
  5.3229847e+00  9.2913418e+00  1.6849303e+00  8.2535496e+00
 -2.5821114e-01  4.1421123e+00  6.4032269e+00  6.6551906e-01
  5.3515515e+00  9.1520185e+00  1.5094744e+00  7.4785428e+00
  6.0626564e+00  1.8558639e+00  4.4214793e-02  7.5862879e-01
  4.2469244e+00  8.8614159e+00  6.5688152e+00  7.3740344e+00
  4.8993049e+00  5.7953315e+00  9.2521513e-01  8.7253218e+00
  7.7945423e+00  9.9947720e+00  3.9001837e+00  2.8082497e+00
  2.2034130e+00  9.5151176e+00  7.4653130e+00  5.4289103e-01
  5.5686536e+00  4.1999950e+00  1.3804873e+00  1.5220041e+00
  9.6445208e+00  3.1844208e+00  8.2594252e+00  5.8706766e-01
  3.8130655e+00  9.4813788e-01  1.4116070e-01  5.6962514e+00
  2.8564551e+00  7.0057955e+00  6.3632298e+00  1.4823904e+00
  9.5153828e+00  7.8791199e+00  2.7109826e+00  5.3147154e+00
  7.3835139e+00  3.6906118e+00  4.5995116e+00  4.1400166e+00
  6.1948090e+00  8.8411551e+00  1.6546024e+00  8.7375402e+00
  5.7898629e-01  6.4826312e+00  4.3135948e+00  7.4583459e+00
  6.8681207e+00  5.0527821e+00  6.3631139e+00  3.5951567e+00]
Epoch 1/1000
2023-09-10 07:37:04.672 
Epoch 1/1000 
	 loss: 442.4770, MinusLogProbMetric: 442.4770, val_loss: 418.3960, val_MinusLogProbMetric: 418.3960

Epoch 1: val_loss improved from inf to 418.39597, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 44s - loss: 442.4770 - MinusLogProbMetric: 442.4770 - val_loss: 418.3960 - val_MinusLogProbMetric: 418.3960 - lr: 3.3333e-04 - 44s/epoch - 226ms/step
Epoch 2/1000
2023-09-10 07:37:14.605 
Epoch 2/1000 
	 loss: 418.3277, MinusLogProbMetric: 418.3277, val_loss: 418.2589, val_MinusLogProbMetric: 418.2589

Epoch 2: val_loss improved from 418.39597 to 418.25891, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 418.3277 - MinusLogProbMetric: 418.3277 - val_loss: 418.2589 - val_MinusLogProbMetric: 418.2589 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 3/1000
2023-09-10 07:37:23.201 
Epoch 3/1000 
	 loss: 417.4986, MinusLogProbMetric: 417.4986, val_loss: 417.3620, val_MinusLogProbMetric: 417.3620

Epoch 3: val_loss improved from 418.25891 to 417.36203, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 417.4986 - MinusLogProbMetric: 417.4986 - val_loss: 417.3620 - val_MinusLogProbMetric: 417.3620 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 4/1000
2023-09-10 07:37:33.072 
Epoch 4/1000 
	 loss: 416.3710, MinusLogProbMetric: 416.3710, val_loss: 417.9048, val_MinusLogProbMetric: 417.9048

Epoch 4: val_loss did not improve from 417.36203
196/196 - 10s - loss: 416.3710 - MinusLogProbMetric: 416.3710 - val_loss: 417.9048 - val_MinusLogProbMetric: 417.9048 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 5/1000
2023-09-10 07:37:41.072 
Epoch 5/1000 
	 loss: 415.5058, MinusLogProbMetric: 415.5058, val_loss: 425.3341, val_MinusLogProbMetric: 425.3341

Epoch 5: val_loss did not improve from 417.36203
196/196 - 8s - loss: 415.5058 - MinusLogProbMetric: 415.5058 - val_loss: 425.3341 - val_MinusLogProbMetric: 425.3341 - lr: 3.3333e-04 - 8s/epoch - 41ms/step
Epoch 6/1000
2023-09-10 07:37:48.959 
Epoch 6/1000 
	 loss: 416.2481, MinusLogProbMetric: 416.2481, val_loss: 417.1601, val_MinusLogProbMetric: 417.1601

Epoch 6: val_loss improved from 417.36203 to 417.16013, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 416.2481 - MinusLogProbMetric: 416.2481 - val_loss: 417.1601 - val_MinusLogProbMetric: 417.1601 - lr: 3.3333e-04 - 8s/epoch - 41ms/step
Epoch 7/1000
2023-09-10 07:37:55.842 
Epoch 7/1000 
	 loss: 414.3318, MinusLogProbMetric: 414.3318, val_loss: 413.4173, val_MinusLogProbMetric: 413.4173

Epoch 7: val_loss improved from 417.16013 to 413.41733, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 414.3318 - MinusLogProbMetric: 414.3318 - val_loss: 413.4173 - val_MinusLogProbMetric: 413.4173 - lr: 3.3333e-04 - 7s/epoch - 36ms/step
Epoch 8/1000
2023-09-10 07:38:03.827 
Epoch 8/1000 
	 loss: 413.7484, MinusLogProbMetric: 413.7484, val_loss: 413.5218, val_MinusLogProbMetric: 413.5218

Epoch 8: val_loss did not improve from 413.41733
196/196 - 8s - loss: 413.7484 - MinusLogProbMetric: 413.7484 - val_loss: 413.5218 - val_MinusLogProbMetric: 413.5218 - lr: 3.3333e-04 - 8s/epoch - 39ms/step
Epoch 9/1000
2023-09-10 07:38:11.558 
Epoch 9/1000 
	 loss: 412.9072, MinusLogProbMetric: 412.9072, val_loss: 421.4378, val_MinusLogProbMetric: 421.4378

Epoch 9: val_loss did not improve from 413.41733
196/196 - 8s - loss: 412.9072 - MinusLogProbMetric: 412.9072 - val_loss: 421.4378 - val_MinusLogProbMetric: 421.4378 - lr: 3.3333e-04 - 8s/epoch - 39ms/step
Epoch 10/1000
2023-09-10 07:38:20.253 
Epoch 10/1000 
	 loss: 411.7192, MinusLogProbMetric: 411.7192, val_loss: 414.2941, val_MinusLogProbMetric: 414.2941

Epoch 10: val_loss did not improve from 413.41733
196/196 - 9s - loss: 411.7192 - MinusLogProbMetric: 411.7192 - val_loss: 414.2941 - val_MinusLogProbMetric: 414.2941 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 11/1000
2023-09-10 07:38:27.183 
Epoch 11/1000 
	 loss: 411.6962, MinusLogProbMetric: 411.6962, val_loss: 416.8847, val_MinusLogProbMetric: 416.8847

Epoch 11: val_loss did not improve from 413.41733
196/196 - 7s - loss: 411.6962 - MinusLogProbMetric: 411.6962 - val_loss: 416.8847 - val_MinusLogProbMetric: 416.8847 - lr: 3.3333e-04 - 7s/epoch - 35ms/step
Epoch 12/1000
2023-09-10 07:38:37.277 
Epoch 12/1000 
	 loss: 410.8713, MinusLogProbMetric: 410.8713, val_loss: 410.7549, val_MinusLogProbMetric: 410.7549

Epoch 12: val_loss improved from 413.41733 to 410.75494, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 410.8713 - MinusLogProbMetric: 410.8713 - val_loss: 410.7549 - val_MinusLogProbMetric: 410.7549 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 13/1000
2023-09-10 07:38:45.018 
Epoch 13/1000 
	 loss: 410.8270, MinusLogProbMetric: 410.8270, val_loss: 410.0698, val_MinusLogProbMetric: 410.0698

Epoch 13: val_loss improved from 410.75494 to 410.06976, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 410.8270 - MinusLogProbMetric: 410.8270 - val_loss: 410.0698 - val_MinusLogProbMetric: 410.0698 - lr: 3.3333e-04 - 8s/epoch - 40ms/step
Epoch 14/1000
2023-09-10 07:38:54.551 
Epoch 14/1000 
	 loss: 410.0338, MinusLogProbMetric: 410.0338, val_loss: 411.6602, val_MinusLogProbMetric: 411.6602

Epoch 14: val_loss did not improve from 410.06976
196/196 - 9s - loss: 410.0338 - MinusLogProbMetric: 410.0338 - val_loss: 411.6602 - val_MinusLogProbMetric: 411.6602 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 15/1000
2023-09-10 07:39:01.526 
Epoch 15/1000 
	 loss: 410.6793, MinusLogProbMetric: 410.6793, val_loss: 409.5556, val_MinusLogProbMetric: 409.5556

Epoch 15: val_loss improved from 410.06976 to 409.55560, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 410.6793 - MinusLogProbMetric: 410.6793 - val_loss: 409.5556 - val_MinusLogProbMetric: 409.5556 - lr: 3.3333e-04 - 7s/epoch - 37ms/step
Epoch 16/1000
2023-09-10 07:39:09.664 
Epoch 16/1000 
	 loss: 409.7617, MinusLogProbMetric: 409.7617, val_loss: 408.8496, val_MinusLogProbMetric: 408.8496

Epoch 16: val_loss improved from 409.55560 to 408.84961, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 409.7617 - MinusLogProbMetric: 409.7617 - val_loss: 408.8496 - val_MinusLogProbMetric: 408.8496 - lr: 3.3333e-04 - 8s/epoch - 41ms/step
Epoch 17/1000
2023-09-10 07:39:17.418 
Epoch 17/1000 
	 loss: 409.3184, MinusLogProbMetric: 409.3184, val_loss: 408.7763, val_MinusLogProbMetric: 408.7763

Epoch 17: val_loss improved from 408.84961 to 408.77628, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 409.3184 - MinusLogProbMetric: 409.3184 - val_loss: 408.7763 - val_MinusLogProbMetric: 408.7763 - lr: 3.3333e-04 - 8s/epoch - 40ms/step
Epoch 18/1000
2023-09-10 07:39:27.579 
Epoch 18/1000 
	 loss: 408.5213, MinusLogProbMetric: 408.5213, val_loss: 411.2175, val_MinusLogProbMetric: 411.2175

Epoch 18: val_loss did not improve from 408.77628
196/196 - 10s - loss: 408.5213 - MinusLogProbMetric: 408.5213 - val_loss: 411.2175 - val_MinusLogProbMetric: 411.2175 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 19/1000
2023-09-10 07:39:35.209 
Epoch 19/1000 
	 loss: 409.2252, MinusLogProbMetric: 409.2252, val_loss: 408.9346, val_MinusLogProbMetric: 408.9346

Epoch 19: val_loss did not improve from 408.77628
196/196 - 8s - loss: 409.2252 - MinusLogProbMetric: 409.2252 - val_loss: 408.9346 - val_MinusLogProbMetric: 408.9346 - lr: 3.3333e-04 - 8s/epoch - 39ms/step
Epoch 20/1000
2023-09-10 07:39:43.892 
Epoch 20/1000 
	 loss: 408.0691, MinusLogProbMetric: 408.0691, val_loss: 409.0499, val_MinusLogProbMetric: 409.0499

Epoch 20: val_loss did not improve from 408.77628
196/196 - 9s - loss: 408.0691 - MinusLogProbMetric: 408.0691 - val_loss: 409.0499 - val_MinusLogProbMetric: 409.0499 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 21/1000
2023-09-10 07:39:51.038 
Epoch 21/1000 
	 loss: 407.6329, MinusLogProbMetric: 407.6329, val_loss: 406.8214, val_MinusLogProbMetric: 406.8214

Epoch 21: val_loss improved from 408.77628 to 406.82141, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 407.6329 - MinusLogProbMetric: 407.6329 - val_loss: 406.8214 - val_MinusLogProbMetric: 406.8214 - lr: 3.3333e-04 - 7s/epoch - 38ms/step
Epoch 22/1000
2023-09-10 07:39:58.843 
Epoch 22/1000 
	 loss: 408.1263, MinusLogProbMetric: 408.1263, val_loss: 406.5463, val_MinusLogProbMetric: 406.5463

Epoch 22: val_loss improved from 406.82141 to 406.54626, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 408.1263 - MinusLogProbMetric: 408.1263 - val_loss: 406.5463 - val_MinusLogProbMetric: 406.5463 - lr: 3.3333e-04 - 8s/epoch - 40ms/step
Epoch 23/1000
2023-09-10 07:40:06.660 
Epoch 23/1000 
	 loss: 406.8158, MinusLogProbMetric: 406.8158, val_loss: 416.7319, val_MinusLogProbMetric: 416.7319

Epoch 23: val_loss did not improve from 406.54626
196/196 - 8s - loss: 406.8158 - MinusLogProbMetric: 406.8158 - val_loss: 416.7319 - val_MinusLogProbMetric: 416.7319 - lr: 3.3333e-04 - 8s/epoch - 38ms/step
Epoch 24/1000
2023-09-10 07:40:15.619 
Epoch 24/1000 
	 loss: 407.4971, MinusLogProbMetric: 407.4971, val_loss: 407.9410, val_MinusLogProbMetric: 407.9410

Epoch 24: val_loss did not improve from 406.54626
196/196 - 9s - loss: 407.4971 - MinusLogProbMetric: 407.4971 - val_loss: 407.9410 - val_MinusLogProbMetric: 407.9410 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 25/1000
2023-09-10 07:40:24.161 
Epoch 25/1000 
	 loss: 406.3296, MinusLogProbMetric: 406.3296, val_loss: 405.8671, val_MinusLogProbMetric: 405.8671

Epoch 25: val_loss improved from 406.54626 to 405.86713, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 406.3296 - MinusLogProbMetric: 406.3296 - val_loss: 405.8671 - val_MinusLogProbMetric: 405.8671 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 26/1000
2023-09-10 07:40:34.759 
Epoch 26/1000 
	 loss: 413.2722, MinusLogProbMetric: 413.2722, val_loss: 405.6995, val_MinusLogProbMetric: 405.6995

Epoch 26: val_loss improved from 405.86713 to 405.69949, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 413.2722 - MinusLogProbMetric: 413.2722 - val_loss: 405.6995 - val_MinusLogProbMetric: 405.6995 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 27/1000
2023-09-10 07:40:46.721 
Epoch 27/1000 
	 loss: 405.6666, MinusLogProbMetric: 405.6666, val_loss: 406.7842, val_MinusLogProbMetric: 406.7842

Epoch 27: val_loss did not improve from 405.69949
196/196 - 12s - loss: 405.6666 - MinusLogProbMetric: 405.6666 - val_loss: 406.7842 - val_MinusLogProbMetric: 406.7842 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 28/1000
2023-09-10 07:40:55.877 
Epoch 28/1000 
	 loss: 405.4532, MinusLogProbMetric: 405.4532, val_loss: 406.9163, val_MinusLogProbMetric: 406.9163

Epoch 28: val_loss did not improve from 405.69949
196/196 - 9s - loss: 405.4532 - MinusLogProbMetric: 405.4532 - val_loss: 406.9163 - val_MinusLogProbMetric: 406.9163 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 29/1000
2023-09-10 07:41:06.427 
Epoch 29/1000 
	 loss: 405.1792, MinusLogProbMetric: 405.1792, val_loss: 421.8217, val_MinusLogProbMetric: 421.8217

Epoch 29: val_loss did not improve from 405.69949
196/196 - 11s - loss: 405.1792 - MinusLogProbMetric: 405.1792 - val_loss: 421.8217 - val_MinusLogProbMetric: 421.8217 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 30/1000
2023-09-10 07:41:17.643 
Epoch 30/1000 
	 loss: 405.2466, MinusLogProbMetric: 405.2466, val_loss: 408.0328, val_MinusLogProbMetric: 408.0328

Epoch 30: val_loss did not improve from 405.69949
196/196 - 11s - loss: 405.2466 - MinusLogProbMetric: 405.2466 - val_loss: 408.0328 - val_MinusLogProbMetric: 408.0328 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 31/1000
2023-09-10 07:41:28.175 
Epoch 31/1000 
	 loss: 404.9818, MinusLogProbMetric: 404.9818, val_loss: 406.5742, val_MinusLogProbMetric: 406.5742

Epoch 31: val_loss did not improve from 405.69949
196/196 - 11s - loss: 404.9818 - MinusLogProbMetric: 404.9818 - val_loss: 406.5742 - val_MinusLogProbMetric: 406.5742 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 32/1000
2023-09-10 07:41:38.152 
Epoch 32/1000 
	 loss: 405.3018, MinusLogProbMetric: 405.3018, val_loss: 406.5947, val_MinusLogProbMetric: 406.5947

Epoch 32: val_loss did not improve from 405.69949
196/196 - 10s - loss: 405.3018 - MinusLogProbMetric: 405.3018 - val_loss: 406.5947 - val_MinusLogProbMetric: 406.5947 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 33/1000
2023-09-10 07:41:49.040 
Epoch 33/1000 
	 loss: 404.6938, MinusLogProbMetric: 404.6938, val_loss: 403.9641, val_MinusLogProbMetric: 403.9641

Epoch 33: val_loss improved from 405.69949 to 403.96411, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 404.6938 - MinusLogProbMetric: 404.6938 - val_loss: 403.9641 - val_MinusLogProbMetric: 403.9641 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 34/1000
2023-09-10 07:41:59.075 
Epoch 34/1000 
	 loss: 406.1006, MinusLogProbMetric: 406.1006, val_loss: 408.6718, val_MinusLogProbMetric: 408.6718

Epoch 34: val_loss did not improve from 403.96411
196/196 - 9s - loss: 406.1006 - MinusLogProbMetric: 406.1006 - val_loss: 408.6718 - val_MinusLogProbMetric: 408.6718 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 35/1000
2023-09-10 07:42:10.608 
Epoch 35/1000 
	 loss: 404.8331, MinusLogProbMetric: 404.8331, val_loss: 404.7880, val_MinusLogProbMetric: 404.7880

Epoch 35: val_loss did not improve from 403.96411
196/196 - 12s - loss: 404.8331 - MinusLogProbMetric: 404.8331 - val_loss: 404.7880 - val_MinusLogProbMetric: 404.7880 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 36/1000
2023-09-10 07:42:21.311 
Epoch 36/1000 
	 loss: 404.0058, MinusLogProbMetric: 404.0058, val_loss: 404.4582, val_MinusLogProbMetric: 404.4582

Epoch 36: val_loss did not improve from 403.96411
196/196 - 11s - loss: 404.0058 - MinusLogProbMetric: 404.0058 - val_loss: 404.4582 - val_MinusLogProbMetric: 404.4582 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 37/1000
2023-09-10 07:42:29.497 
Epoch 37/1000 
	 loss: 404.6950, MinusLogProbMetric: 404.6950, val_loss: 403.6550, val_MinusLogProbMetric: 403.6550

Epoch 37: val_loss improved from 403.96411 to 403.65500, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 404.6950 - MinusLogProbMetric: 404.6950 - val_loss: 403.6550 - val_MinusLogProbMetric: 403.6550 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 38/1000
2023-09-10 07:42:40.707 
Epoch 38/1000 
	 loss: 404.5307, MinusLogProbMetric: 404.5307, val_loss: 405.2694, val_MinusLogProbMetric: 405.2694

Epoch 38: val_loss did not improve from 403.65500
196/196 - 11s - loss: 404.5307 - MinusLogProbMetric: 404.5307 - val_loss: 405.2694 - val_MinusLogProbMetric: 405.2694 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 39/1000
2023-09-10 07:42:52.226 
Epoch 39/1000 
	 loss: 403.3515, MinusLogProbMetric: 403.3515, val_loss: 405.5908, val_MinusLogProbMetric: 405.5908

Epoch 39: val_loss did not improve from 403.65500
196/196 - 12s - loss: 403.3515 - MinusLogProbMetric: 403.3515 - val_loss: 405.5908 - val_MinusLogProbMetric: 405.5908 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 40/1000
2023-09-10 07:43:02.005 
Epoch 40/1000 
	 loss: 403.6791, MinusLogProbMetric: 403.6791, val_loss: 406.7256, val_MinusLogProbMetric: 406.7256

Epoch 40: val_loss did not improve from 403.65500
196/196 - 10s - loss: 403.6791 - MinusLogProbMetric: 403.6791 - val_loss: 406.7256 - val_MinusLogProbMetric: 406.7256 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 41/1000
2023-09-10 07:43:12.507 
Epoch 41/1000 
	 loss: 403.5282, MinusLogProbMetric: 403.5282, val_loss: 404.6490, val_MinusLogProbMetric: 404.6490

Epoch 41: val_loss did not improve from 403.65500
196/196 - 10s - loss: 403.5282 - MinusLogProbMetric: 403.5282 - val_loss: 404.6490 - val_MinusLogProbMetric: 404.6490 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 42/1000
2023-09-10 07:43:22.433 
Epoch 42/1000 
	 loss: 403.7458, MinusLogProbMetric: 403.7458, val_loss: 403.4973, val_MinusLogProbMetric: 403.4973

Epoch 42: val_loss improved from 403.65500 to 403.49731, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 403.7458 - MinusLogProbMetric: 403.7458 - val_loss: 403.4973 - val_MinusLogProbMetric: 403.4973 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 43/1000
2023-09-10 07:43:32.879 
Epoch 43/1000 
	 loss: 403.7662, MinusLogProbMetric: 403.7662, val_loss: 403.2956, val_MinusLogProbMetric: 403.2956

Epoch 43: val_loss improved from 403.49731 to 403.29562, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 403.7662 - MinusLogProbMetric: 403.7662 - val_loss: 403.2956 - val_MinusLogProbMetric: 403.2956 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 44/1000
2023-09-10 07:43:44.807 
Epoch 44/1000 
	 loss: 402.7756, MinusLogProbMetric: 402.7756, val_loss: 405.0378, val_MinusLogProbMetric: 405.0378

Epoch 44: val_loss did not improve from 403.29562
196/196 - 12s - loss: 402.7756 - MinusLogProbMetric: 402.7756 - val_loss: 405.0378 - val_MinusLogProbMetric: 405.0378 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 45/1000
2023-09-10 07:43:55.471 
Epoch 45/1000 
	 loss: 402.7298, MinusLogProbMetric: 402.7298, val_loss: 404.5187, val_MinusLogProbMetric: 404.5187

Epoch 45: val_loss did not improve from 403.29562
196/196 - 11s - loss: 402.7298 - MinusLogProbMetric: 402.7298 - val_loss: 404.5187 - val_MinusLogProbMetric: 404.5187 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 46/1000
2023-09-10 07:44:06.129 
Epoch 46/1000 
	 loss: 402.6794, MinusLogProbMetric: 402.6794, val_loss: 404.8156, val_MinusLogProbMetric: 404.8156

Epoch 46: val_loss did not improve from 403.29562
196/196 - 11s - loss: 402.6794 - MinusLogProbMetric: 402.6794 - val_loss: 404.8156 - val_MinusLogProbMetric: 404.8156 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 47/1000
2023-09-10 07:44:17.623 
Epoch 47/1000 
	 loss: 402.4363, MinusLogProbMetric: 402.4363, val_loss: 404.9519, val_MinusLogProbMetric: 404.9519

Epoch 47: val_loss did not improve from 403.29562
196/196 - 11s - loss: 402.4363 - MinusLogProbMetric: 402.4363 - val_loss: 404.9519 - val_MinusLogProbMetric: 404.9519 - lr: 3.3333e-04 - 11s/epoch - 59ms/step
Epoch 48/1000
2023-09-10 07:44:27.904 
Epoch 48/1000 
	 loss: 403.1454, MinusLogProbMetric: 403.1454, val_loss: 403.8108, val_MinusLogProbMetric: 403.8108

Epoch 48: val_loss did not improve from 403.29562
196/196 - 10s - loss: 403.1454 - MinusLogProbMetric: 403.1454 - val_loss: 403.8108 - val_MinusLogProbMetric: 403.8108 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 49/1000
2023-09-10 07:44:36.881 
Epoch 49/1000 
	 loss: 402.2193, MinusLogProbMetric: 402.2193, val_loss: 410.8954, val_MinusLogProbMetric: 410.8954

Epoch 49: val_loss did not improve from 403.29562
196/196 - 9s - loss: 402.2193 - MinusLogProbMetric: 402.2193 - val_loss: 410.8954 - val_MinusLogProbMetric: 410.8954 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 50/1000
2023-09-10 07:44:47.565 
Epoch 50/1000 
	 loss: 401.8643, MinusLogProbMetric: 401.8643, val_loss: 402.5460, val_MinusLogProbMetric: 402.5460

Epoch 50: val_loss improved from 403.29562 to 402.54596, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 401.8643 - MinusLogProbMetric: 401.8643 - val_loss: 402.5460 - val_MinusLogProbMetric: 402.5460 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 51/1000
2023-09-10 07:44:58.456 
Epoch 51/1000 
	 loss: 402.7202, MinusLogProbMetric: 402.7202, val_loss: 401.6022, val_MinusLogProbMetric: 401.6022

Epoch 51: val_loss improved from 402.54596 to 401.60220, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 402.7202 - MinusLogProbMetric: 402.7202 - val_loss: 401.6022 - val_MinusLogProbMetric: 401.6022 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 52/1000
2023-09-10 07:45:08.718 
Epoch 52/1000 
	 loss: 401.5812, MinusLogProbMetric: 401.5812, val_loss: 406.9255, val_MinusLogProbMetric: 406.9255

Epoch 52: val_loss did not improve from 401.60220
196/196 - 10s - loss: 401.5812 - MinusLogProbMetric: 401.5812 - val_loss: 406.9255 - val_MinusLogProbMetric: 406.9255 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 53/1000
2023-09-10 07:45:20.042 
Epoch 53/1000 
	 loss: 402.3625, MinusLogProbMetric: 402.3625, val_loss: 401.5446, val_MinusLogProbMetric: 401.5446

Epoch 53: val_loss improved from 401.60220 to 401.54459, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 402.3625 - MinusLogProbMetric: 402.3625 - val_loss: 401.5446 - val_MinusLogProbMetric: 401.5446 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 54/1000
2023-09-10 07:45:30.334 
Epoch 54/1000 
	 loss: 401.5552, MinusLogProbMetric: 401.5552, val_loss: 402.9949, val_MinusLogProbMetric: 402.9949

Epoch 54: val_loss did not improve from 401.54459
196/196 - 10s - loss: 401.5552 - MinusLogProbMetric: 401.5552 - val_loss: 402.9949 - val_MinusLogProbMetric: 402.9949 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 55/1000
2023-09-10 07:45:39.759 
Epoch 55/1000 
	 loss: 402.8610, MinusLogProbMetric: 402.8610, val_loss: 402.4019, val_MinusLogProbMetric: 402.4019

Epoch 55: val_loss did not improve from 401.54459
196/196 - 9s - loss: 402.8610 - MinusLogProbMetric: 402.8610 - val_loss: 402.4019 - val_MinusLogProbMetric: 402.4019 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 56/1000
2023-09-10 07:45:49.428 
Epoch 56/1000 
	 loss: 401.1619, MinusLogProbMetric: 401.1619, val_loss: 409.6677, val_MinusLogProbMetric: 409.6677

Epoch 56: val_loss did not improve from 401.54459
196/196 - 10s - loss: 401.1619 - MinusLogProbMetric: 401.1619 - val_loss: 409.6677 - val_MinusLogProbMetric: 409.6677 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 57/1000
2023-09-10 07:45:59.938 
Epoch 57/1000 
	 loss: 402.4574, MinusLogProbMetric: 402.4574, val_loss: 408.9771, val_MinusLogProbMetric: 408.9771

Epoch 57: val_loss did not improve from 401.54459
196/196 - 11s - loss: 402.4574 - MinusLogProbMetric: 402.4574 - val_loss: 408.9771 - val_MinusLogProbMetric: 408.9771 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 58/1000
2023-09-10 07:46:09.872 
Epoch 58/1000 
	 loss: 5406.5010, MinusLogProbMetric: 5406.5010, val_loss: 1959.4170, val_MinusLogProbMetric: 1959.4170

Epoch 58: val_loss did not improve from 401.54459
196/196 - 10s - loss: 5406.5010 - MinusLogProbMetric: 5406.5010 - val_loss: 1959.4170 - val_MinusLogProbMetric: 1959.4170 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 59/1000
2023-09-10 07:46:17.809 
Epoch 59/1000 
	 loss: 684.9457, MinusLogProbMetric: 684.9457, val_loss: 467.6772, val_MinusLogProbMetric: 467.6772

Epoch 59: val_loss did not improve from 401.54459
196/196 - 8s - loss: 684.9457 - MinusLogProbMetric: 684.9457 - val_loss: 467.6772 - val_MinusLogProbMetric: 467.6772 - lr: 3.3333e-04 - 8s/epoch - 40ms/step
Epoch 60/1000
2023-09-10 07:46:25.476 
Epoch 60/1000 
	 loss: 452.2030, MinusLogProbMetric: 452.2030, val_loss: 445.2017, val_MinusLogProbMetric: 445.2017

Epoch 60: val_loss did not improve from 401.54459
196/196 - 8s - loss: 452.2030 - MinusLogProbMetric: 452.2030 - val_loss: 445.2017 - val_MinusLogProbMetric: 445.2017 - lr: 3.3333e-04 - 8s/epoch - 39ms/step
Epoch 61/1000
2023-09-10 07:46:35.194 
Epoch 61/1000 
	 loss: 439.2134, MinusLogProbMetric: 439.2134, val_loss: 436.7775, val_MinusLogProbMetric: 436.7775

Epoch 61: val_loss did not improve from 401.54459
196/196 - 10s - loss: 439.2134 - MinusLogProbMetric: 439.2134 - val_loss: 436.7775 - val_MinusLogProbMetric: 436.7775 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 62/1000
2023-09-10 07:46:43.247 
Epoch 62/1000 
	 loss: 432.9545, MinusLogProbMetric: 432.9545, val_loss: 431.6781, val_MinusLogProbMetric: 431.6781

Epoch 62: val_loss did not improve from 401.54459
196/196 - 8s - loss: 432.9545 - MinusLogProbMetric: 432.9545 - val_loss: 431.6781 - val_MinusLogProbMetric: 431.6781 - lr: 3.3333e-04 - 8s/epoch - 41ms/step
Epoch 63/1000
2023-09-10 07:46:54.642 
Epoch 63/1000 
	 loss: 428.9595, MinusLogProbMetric: 428.9595, val_loss: 428.7766, val_MinusLogProbMetric: 428.7766

Epoch 63: val_loss did not improve from 401.54459
196/196 - 11s - loss: 428.9595 - MinusLogProbMetric: 428.9595 - val_loss: 428.7766 - val_MinusLogProbMetric: 428.7766 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 64/1000
2023-09-10 07:47:05.942 
Epoch 64/1000 
	 loss: 425.8081, MinusLogProbMetric: 425.8081, val_loss: 426.0387, val_MinusLogProbMetric: 426.0387

Epoch 64: val_loss did not improve from 401.54459
196/196 - 11s - loss: 425.8081 - MinusLogProbMetric: 425.8081 - val_loss: 426.0387 - val_MinusLogProbMetric: 426.0387 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 65/1000
2023-09-10 07:47:15.509 
Epoch 65/1000 
	 loss: 423.2975, MinusLogProbMetric: 423.2975, val_loss: 423.6937, val_MinusLogProbMetric: 423.6937

Epoch 65: val_loss did not improve from 401.54459
196/196 - 10s - loss: 423.2975 - MinusLogProbMetric: 423.2975 - val_loss: 423.6937 - val_MinusLogProbMetric: 423.6937 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 66/1000
2023-09-10 07:47:26.938 
Epoch 66/1000 
	 loss: 421.1330, MinusLogProbMetric: 421.1330, val_loss: 421.2589, val_MinusLogProbMetric: 421.2589

Epoch 66: val_loss did not improve from 401.54459
196/196 - 11s - loss: 421.1330 - MinusLogProbMetric: 421.1330 - val_loss: 421.2589 - val_MinusLogProbMetric: 421.2589 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 67/1000
2023-09-10 07:47:35.290 
Epoch 67/1000 
	 loss: 419.1326, MinusLogProbMetric: 419.1326, val_loss: 419.6549, val_MinusLogProbMetric: 419.6549

Epoch 67: val_loss did not improve from 401.54459
196/196 - 8s - loss: 419.1326 - MinusLogProbMetric: 419.1326 - val_loss: 419.6549 - val_MinusLogProbMetric: 419.6549 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 68/1000
2023-09-10 07:47:45.535 
Epoch 68/1000 
	 loss: 417.3297, MinusLogProbMetric: 417.3297, val_loss: 418.1991, val_MinusLogProbMetric: 418.1991

Epoch 68: val_loss did not improve from 401.54459
196/196 - 10s - loss: 417.3297 - MinusLogProbMetric: 417.3297 - val_loss: 418.1991 - val_MinusLogProbMetric: 418.1991 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 69/1000
2023-09-10 07:47:56.498 
Epoch 69/1000 
	 loss: 415.7928, MinusLogProbMetric: 415.7928, val_loss: 415.7728, val_MinusLogProbMetric: 415.7728

Epoch 69: val_loss did not improve from 401.54459
196/196 - 11s - loss: 415.7928 - MinusLogProbMetric: 415.7928 - val_loss: 415.7728 - val_MinusLogProbMetric: 415.7728 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 70/1000
2023-09-10 07:48:06.094 
Epoch 70/1000 
	 loss: 414.2391, MinusLogProbMetric: 414.2391, val_loss: 414.8418, val_MinusLogProbMetric: 414.8418

Epoch 70: val_loss did not improve from 401.54459
196/196 - 10s - loss: 414.2391 - MinusLogProbMetric: 414.2391 - val_loss: 414.8418 - val_MinusLogProbMetric: 414.8418 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 71/1000
2023-09-10 07:48:15.718 
Epoch 71/1000 
	 loss: 412.8988, MinusLogProbMetric: 412.8988, val_loss: 413.4244, val_MinusLogProbMetric: 413.4244

Epoch 71: val_loss did not improve from 401.54459
196/196 - 10s - loss: 412.8988 - MinusLogProbMetric: 412.8988 - val_loss: 413.4244 - val_MinusLogProbMetric: 413.4244 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 72/1000
2023-09-10 07:48:26.565 
Epoch 72/1000 
	 loss: 411.8939, MinusLogProbMetric: 411.8939, val_loss: 413.2786, val_MinusLogProbMetric: 413.2786

Epoch 72: val_loss did not improve from 401.54459
196/196 - 11s - loss: 411.8939 - MinusLogProbMetric: 411.8939 - val_loss: 413.2786 - val_MinusLogProbMetric: 413.2786 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 73/1000
2023-09-10 07:48:38.361 
Epoch 73/1000 
	 loss: 411.1589, MinusLogProbMetric: 411.1589, val_loss: 412.8746, val_MinusLogProbMetric: 412.8746

Epoch 73: val_loss did not improve from 401.54459
196/196 - 12s - loss: 411.1589 - MinusLogProbMetric: 411.1589 - val_loss: 412.8746 - val_MinusLogProbMetric: 412.8746 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 74/1000
2023-09-10 07:48:48.401 
Epoch 74/1000 
	 loss: 410.4109, MinusLogProbMetric: 410.4109, val_loss: 411.3038, val_MinusLogProbMetric: 411.3038

Epoch 74: val_loss did not improve from 401.54459
196/196 - 10s - loss: 410.4109 - MinusLogProbMetric: 410.4109 - val_loss: 411.3038 - val_MinusLogProbMetric: 411.3038 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 75/1000
2023-09-10 07:48:58.012 
Epoch 75/1000 
	 loss: 409.7373, MinusLogProbMetric: 409.7373, val_loss: 410.7495, val_MinusLogProbMetric: 410.7495

Epoch 75: val_loss did not improve from 401.54459
196/196 - 10s - loss: 409.7373 - MinusLogProbMetric: 409.7373 - val_loss: 410.7495 - val_MinusLogProbMetric: 410.7495 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 76/1000
2023-09-10 07:49:06.587 
Epoch 76/1000 
	 loss: 409.2071, MinusLogProbMetric: 409.2071, val_loss: 410.3732, val_MinusLogProbMetric: 410.3732

Epoch 76: val_loss did not improve from 401.54459
196/196 - 9s - loss: 409.2071 - MinusLogProbMetric: 409.2071 - val_loss: 410.3732 - val_MinusLogProbMetric: 410.3732 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 77/1000
2023-09-10 07:49:17.642 
Epoch 77/1000 
	 loss: 408.7319, MinusLogProbMetric: 408.7319, val_loss: 409.6783, val_MinusLogProbMetric: 409.6783

Epoch 77: val_loss did not improve from 401.54459
196/196 - 11s - loss: 408.7319 - MinusLogProbMetric: 408.7319 - val_loss: 409.6783 - val_MinusLogProbMetric: 409.6783 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 78/1000
2023-09-10 07:49:28.503 
Epoch 78/1000 
	 loss: 408.1444, MinusLogProbMetric: 408.1444, val_loss: 409.2698, val_MinusLogProbMetric: 409.2698

Epoch 78: val_loss did not improve from 401.54459
196/196 - 11s - loss: 408.1444 - MinusLogProbMetric: 408.1444 - val_loss: 409.2698 - val_MinusLogProbMetric: 409.2698 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 79/1000
2023-09-10 07:49:38.769 
Epoch 79/1000 
	 loss: 407.7187, MinusLogProbMetric: 407.7187, val_loss: 409.2394, val_MinusLogProbMetric: 409.2394

Epoch 79: val_loss did not improve from 401.54459
196/196 - 10s - loss: 407.7187 - MinusLogProbMetric: 407.7187 - val_loss: 409.2394 - val_MinusLogProbMetric: 409.2394 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 80/1000
2023-09-10 07:49:48.564 
Epoch 80/1000 
	 loss: 407.3157, MinusLogProbMetric: 407.3157, val_loss: 408.7727, val_MinusLogProbMetric: 408.7727

Epoch 80: val_loss did not improve from 401.54459
196/196 - 10s - loss: 407.3157 - MinusLogProbMetric: 407.3157 - val_loss: 408.7727 - val_MinusLogProbMetric: 408.7727 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 81/1000
2023-09-10 07:49:57.437 
Epoch 81/1000 
	 loss: 407.0123, MinusLogProbMetric: 407.0123, val_loss: 408.0439, val_MinusLogProbMetric: 408.0439

Epoch 81: val_loss did not improve from 401.54459
196/196 - 9s - loss: 407.0123 - MinusLogProbMetric: 407.0123 - val_loss: 408.0439 - val_MinusLogProbMetric: 408.0439 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 82/1000
2023-09-10 07:50:06.382 
Epoch 82/1000 
	 loss: 406.5168, MinusLogProbMetric: 406.5168, val_loss: 407.4929, val_MinusLogProbMetric: 407.4929

Epoch 82: val_loss did not improve from 401.54459
196/196 - 9s - loss: 406.5168 - MinusLogProbMetric: 406.5168 - val_loss: 407.4929 - val_MinusLogProbMetric: 407.4929 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 83/1000
2023-09-10 07:50:13.546 
Epoch 83/1000 
	 loss: 406.2630, MinusLogProbMetric: 406.2630, val_loss: 407.4834, val_MinusLogProbMetric: 407.4834

Epoch 83: val_loss did not improve from 401.54459
196/196 - 7s - loss: 406.2630 - MinusLogProbMetric: 406.2630 - val_loss: 407.4834 - val_MinusLogProbMetric: 407.4834 - lr: 3.3333e-04 - 7s/epoch - 37ms/step
Epoch 84/1000
2023-09-10 07:50:22.453 
Epoch 84/1000 
	 loss: 405.8619, MinusLogProbMetric: 405.8619, val_loss: 407.1032, val_MinusLogProbMetric: 407.1032

Epoch 84: val_loss did not improve from 401.54459
196/196 - 9s - loss: 405.8619 - MinusLogProbMetric: 405.8619 - val_loss: 407.1032 - val_MinusLogProbMetric: 407.1032 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 85/1000
2023-09-10 07:50:29.748 
Epoch 85/1000 
	 loss: 405.4879, MinusLogProbMetric: 405.4879, val_loss: 406.5757, val_MinusLogProbMetric: 406.5757

Epoch 85: val_loss did not improve from 401.54459
196/196 - 7s - loss: 405.4879 - MinusLogProbMetric: 405.4879 - val_loss: 406.5757 - val_MinusLogProbMetric: 406.5757 - lr: 3.3333e-04 - 7s/epoch - 37ms/step
Epoch 86/1000
2023-09-10 07:50:38.124 
Epoch 86/1000 
	 loss: 405.3059, MinusLogProbMetric: 405.3059, val_loss: 406.3605, val_MinusLogProbMetric: 406.3605

Epoch 86: val_loss did not improve from 401.54459
196/196 - 8s - loss: 405.3059 - MinusLogProbMetric: 405.3059 - val_loss: 406.3605 - val_MinusLogProbMetric: 406.3605 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 87/1000
2023-09-10 07:50:49.026 
Epoch 87/1000 
	 loss: 404.9812, MinusLogProbMetric: 404.9812, val_loss: 406.4909, val_MinusLogProbMetric: 406.4909

Epoch 87: val_loss did not improve from 401.54459
196/196 - 11s - loss: 404.9812 - MinusLogProbMetric: 404.9812 - val_loss: 406.4909 - val_MinusLogProbMetric: 406.4909 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 88/1000
2023-09-10 07:50:58.260 
Epoch 88/1000 
	 loss: 404.7880, MinusLogProbMetric: 404.7880, val_loss: 406.1938, val_MinusLogProbMetric: 406.1938

Epoch 88: val_loss did not improve from 401.54459
196/196 - 9s - loss: 404.7880 - MinusLogProbMetric: 404.7880 - val_loss: 406.1938 - val_MinusLogProbMetric: 406.1938 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 89/1000
2023-09-10 07:51:07.969 
Epoch 89/1000 
	 loss: 404.4244, MinusLogProbMetric: 404.4244, val_loss: 405.8676, val_MinusLogProbMetric: 405.8676

Epoch 89: val_loss did not improve from 401.54459
196/196 - 10s - loss: 404.4244 - MinusLogProbMetric: 404.4244 - val_loss: 405.8676 - val_MinusLogProbMetric: 405.8676 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 90/1000
2023-09-10 07:51:18.682 
Epoch 90/1000 
	 loss: 404.1791, MinusLogProbMetric: 404.1791, val_loss: 406.1707, val_MinusLogProbMetric: 406.1707

Epoch 90: val_loss did not improve from 401.54459
196/196 - 11s - loss: 404.1791 - MinusLogProbMetric: 404.1791 - val_loss: 406.1707 - val_MinusLogProbMetric: 406.1707 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 91/1000
2023-09-10 07:51:29.868 
Epoch 91/1000 
	 loss: 404.1305, MinusLogProbMetric: 404.1305, val_loss: 405.4841, val_MinusLogProbMetric: 405.4841

Epoch 91: val_loss did not improve from 401.54459
196/196 - 11s - loss: 404.1305 - MinusLogProbMetric: 404.1305 - val_loss: 405.4841 - val_MinusLogProbMetric: 405.4841 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 92/1000
2023-09-10 07:51:38.219 
Epoch 92/1000 
	 loss: 403.7579, MinusLogProbMetric: 403.7579, val_loss: 405.2548, val_MinusLogProbMetric: 405.2548

Epoch 92: val_loss did not improve from 401.54459
196/196 - 8s - loss: 403.7579 - MinusLogProbMetric: 403.7579 - val_loss: 405.2548 - val_MinusLogProbMetric: 405.2548 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 93/1000
2023-09-10 07:51:49.267 
Epoch 93/1000 
	 loss: 403.4711, MinusLogProbMetric: 403.4711, val_loss: 404.4402, val_MinusLogProbMetric: 404.4402

Epoch 93: val_loss did not improve from 401.54459
196/196 - 11s - loss: 403.4711 - MinusLogProbMetric: 403.4711 - val_loss: 404.4402 - val_MinusLogProbMetric: 404.4402 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 94/1000
2023-09-10 07:52:00.893 
Epoch 94/1000 
	 loss: 403.3928, MinusLogProbMetric: 403.3928, val_loss: 404.9030, val_MinusLogProbMetric: 404.9030

Epoch 94: val_loss did not improve from 401.54459
196/196 - 12s - loss: 403.3928 - MinusLogProbMetric: 403.3928 - val_loss: 404.9030 - val_MinusLogProbMetric: 404.9030 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 95/1000
2023-09-10 07:52:09.401 
Epoch 95/1000 
	 loss: 403.1626, MinusLogProbMetric: 403.1626, val_loss: 404.1458, val_MinusLogProbMetric: 404.1458

Epoch 95: val_loss did not improve from 401.54459
196/196 - 9s - loss: 403.1626 - MinusLogProbMetric: 403.1626 - val_loss: 404.1458 - val_MinusLogProbMetric: 404.1458 - lr: 3.3333e-04 - 9s/epoch - 43ms/step
Epoch 96/1000
2023-09-10 07:52:18.419 
Epoch 96/1000 
	 loss: 403.0412, MinusLogProbMetric: 403.0412, val_loss: 404.9018, val_MinusLogProbMetric: 404.9018

Epoch 96: val_loss did not improve from 401.54459
196/196 - 9s - loss: 403.0412 - MinusLogProbMetric: 403.0412 - val_loss: 404.9018 - val_MinusLogProbMetric: 404.9018 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 97/1000
2023-09-10 07:52:27.874 
Epoch 97/1000 
	 loss: 402.7462, MinusLogProbMetric: 402.7462, val_loss: 403.8752, val_MinusLogProbMetric: 403.8752

Epoch 97: val_loss did not improve from 401.54459
196/196 - 9s - loss: 402.7462 - MinusLogProbMetric: 402.7462 - val_loss: 403.8752 - val_MinusLogProbMetric: 403.8752 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 98/1000
2023-09-10 07:52:39.704 
Epoch 98/1000 
	 loss: 402.5834, MinusLogProbMetric: 402.5834, val_loss: 404.1008, val_MinusLogProbMetric: 404.1008

Epoch 98: val_loss did not improve from 401.54459
196/196 - 12s - loss: 402.5834 - MinusLogProbMetric: 402.5834 - val_loss: 404.1008 - val_MinusLogProbMetric: 404.1008 - lr: 3.3333e-04 - 12s/epoch - 60ms/step
Epoch 99/1000
2023-09-10 07:52:50.302 
Epoch 99/1000 
	 loss: 402.4346, MinusLogProbMetric: 402.4346, val_loss: 403.8187, val_MinusLogProbMetric: 403.8187

Epoch 99: val_loss did not improve from 401.54459
196/196 - 11s - loss: 402.4346 - MinusLogProbMetric: 402.4346 - val_loss: 403.8187 - val_MinusLogProbMetric: 403.8187 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 100/1000
2023-09-10 07:52:59.148 
Epoch 100/1000 
	 loss: 402.3011, MinusLogProbMetric: 402.3011, val_loss: 403.4987, val_MinusLogProbMetric: 403.4987

Epoch 100: val_loss did not improve from 401.54459
196/196 - 9s - loss: 402.3011 - MinusLogProbMetric: 402.3011 - val_loss: 403.4987 - val_MinusLogProbMetric: 403.4987 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 101/1000
2023-09-10 07:53:09.348 
Epoch 101/1000 
	 loss: 402.0794, MinusLogProbMetric: 402.0794, val_loss: 404.2125, val_MinusLogProbMetric: 404.2125

Epoch 101: val_loss did not improve from 401.54459
196/196 - 10s - loss: 402.0794 - MinusLogProbMetric: 402.0794 - val_loss: 404.2125 - val_MinusLogProbMetric: 404.2125 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 102/1000
2023-09-10 07:53:20.036 
Epoch 102/1000 
	 loss: 401.9692, MinusLogProbMetric: 401.9692, val_loss: 403.5488, val_MinusLogProbMetric: 403.5488

Epoch 102: val_loss did not improve from 401.54459
196/196 - 11s - loss: 401.9692 - MinusLogProbMetric: 401.9692 - val_loss: 403.5488 - val_MinusLogProbMetric: 403.5488 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 103/1000
2023-09-10 07:53:28.476 
Epoch 103/1000 
	 loss: 401.7196, MinusLogProbMetric: 401.7196, val_loss: 403.1256, val_MinusLogProbMetric: 403.1256

Epoch 103: val_loss did not improve from 401.54459
196/196 - 8s - loss: 401.7196 - MinusLogProbMetric: 401.7196 - val_loss: 403.1256 - val_MinusLogProbMetric: 403.1256 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 104/1000
2023-09-10 07:53:38.550 
Epoch 104/1000 
	 loss: 400.2274, MinusLogProbMetric: 400.2274, val_loss: 401.4186, val_MinusLogProbMetric: 401.4186

Epoch 104: val_loss improved from 401.54459 to 401.41858, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 400.2274 - MinusLogProbMetric: 400.2274 - val_loss: 401.4186 - val_MinusLogProbMetric: 401.4186 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 105/1000
2023-09-10 07:53:47.875 
Epoch 105/1000 
	 loss: 400.0744, MinusLogProbMetric: 400.0744, val_loss: 401.7034, val_MinusLogProbMetric: 401.7034

Epoch 105: val_loss did not improve from 401.41858
196/196 - 9s - loss: 400.0744 - MinusLogProbMetric: 400.0744 - val_loss: 401.7034 - val_MinusLogProbMetric: 401.7034 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 106/1000
2023-09-10 07:53:58.262 
Epoch 106/1000 
	 loss: 400.0070, MinusLogProbMetric: 400.0070, val_loss: 401.5087, val_MinusLogProbMetric: 401.5087

Epoch 106: val_loss did not improve from 401.41858
196/196 - 10s - loss: 400.0070 - MinusLogProbMetric: 400.0070 - val_loss: 401.5087 - val_MinusLogProbMetric: 401.5087 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 107/1000
2023-09-10 07:54:08.619 
Epoch 107/1000 
	 loss: 399.9225, MinusLogProbMetric: 399.9225, val_loss: 401.4115, val_MinusLogProbMetric: 401.4115

Epoch 107: val_loss improved from 401.41858 to 401.41150, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 399.9225 - MinusLogProbMetric: 399.9225 - val_loss: 401.4115 - val_MinusLogProbMetric: 401.4115 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 108/1000
2023-09-10 07:54:19.675 
Epoch 108/1000 
	 loss: 399.8682, MinusLogProbMetric: 399.8682, val_loss: 401.0740, val_MinusLogProbMetric: 401.0740

Epoch 108: val_loss improved from 401.41150 to 401.07401, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 399.8682 - MinusLogProbMetric: 399.8682 - val_loss: 401.0740 - val_MinusLogProbMetric: 401.0740 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 109/1000
2023-09-10 07:54:31.055 
Epoch 109/1000 
	 loss: 399.8034, MinusLogProbMetric: 399.8034, val_loss: 401.1597, val_MinusLogProbMetric: 401.1597

Epoch 109: val_loss did not improve from 401.07401
196/196 - 11s - loss: 399.8034 - MinusLogProbMetric: 399.8034 - val_loss: 401.1597 - val_MinusLogProbMetric: 401.1597 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 110/1000
2023-09-10 07:54:38.766 
Epoch 110/1000 
	 loss: 399.6945, MinusLogProbMetric: 399.6945, val_loss: 400.9861, val_MinusLogProbMetric: 400.9861

Epoch 110: val_loss improved from 401.07401 to 400.98605, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 399.6945 - MinusLogProbMetric: 399.6945 - val_loss: 400.9861 - val_MinusLogProbMetric: 400.9861 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 111/1000
2023-09-10 07:54:49.804 
Epoch 111/1000 
	 loss: 399.6577, MinusLogProbMetric: 399.6577, val_loss: 400.8676, val_MinusLogProbMetric: 400.8676

Epoch 111: val_loss improved from 400.98605 to 400.86755, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 399.6577 - MinusLogProbMetric: 399.6577 - val_loss: 400.8676 - val_MinusLogProbMetric: 400.8676 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 112/1000
2023-09-10 07:55:00.477 
Epoch 112/1000 
	 loss: 399.5842, MinusLogProbMetric: 399.5842, val_loss: 400.8617, val_MinusLogProbMetric: 400.8617

Epoch 112: val_loss improved from 400.86755 to 400.86172, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 399.5842 - MinusLogProbMetric: 399.5842 - val_loss: 400.8617 - val_MinusLogProbMetric: 400.8617 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 113/1000
2023-09-10 07:55:11.673 
Epoch 113/1000 
	 loss: 399.4657, MinusLogProbMetric: 399.4657, val_loss: 400.9543, val_MinusLogProbMetric: 400.9543

Epoch 113: val_loss did not improve from 400.86172
196/196 - 11s - loss: 399.4657 - MinusLogProbMetric: 399.4657 - val_loss: 400.9543 - val_MinusLogProbMetric: 400.9543 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 114/1000
2023-09-10 07:55:23.482 
Epoch 114/1000 
	 loss: 399.4536, MinusLogProbMetric: 399.4536, val_loss: 400.8468, val_MinusLogProbMetric: 400.8468

Epoch 114: val_loss improved from 400.86172 to 400.84680, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 399.4536 - MinusLogProbMetric: 399.4536 - val_loss: 400.8468 - val_MinusLogProbMetric: 400.8468 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 115/1000
2023-09-10 07:55:34.716 
Epoch 115/1000 
	 loss: 399.3719, MinusLogProbMetric: 399.3719, val_loss: 401.0303, val_MinusLogProbMetric: 401.0303

Epoch 115: val_loss did not improve from 400.84680
196/196 - 11s - loss: 399.3719 - MinusLogProbMetric: 399.3719 - val_loss: 401.0303 - val_MinusLogProbMetric: 401.0303 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 116/1000
2023-09-10 07:55:42.367 
Epoch 116/1000 
	 loss: 399.2881, MinusLogProbMetric: 399.2881, val_loss: 400.5621, val_MinusLogProbMetric: 400.5621

Epoch 116: val_loss improved from 400.84680 to 400.56207, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 399.2881 - MinusLogProbMetric: 399.2881 - val_loss: 400.5621 - val_MinusLogProbMetric: 400.5621 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 117/1000
2023-09-10 07:55:53.864 
Epoch 117/1000 
	 loss: 399.2353, MinusLogProbMetric: 399.2353, val_loss: 400.8196, val_MinusLogProbMetric: 400.8196

Epoch 117: val_loss did not improve from 400.56207
196/196 - 11s - loss: 399.2353 - MinusLogProbMetric: 399.2353 - val_loss: 400.8196 - val_MinusLogProbMetric: 400.8196 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 118/1000
2023-09-10 07:56:03.032 
Epoch 118/1000 
	 loss: 399.2744, MinusLogProbMetric: 399.2744, val_loss: 400.4974, val_MinusLogProbMetric: 400.4974

Epoch 118: val_loss improved from 400.56207 to 400.49738, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 399.2744 - MinusLogProbMetric: 399.2744 - val_loss: 400.4974 - val_MinusLogProbMetric: 400.4974 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 119/1000
2023-09-10 07:56:14.038 
Epoch 119/1000 
	 loss: 399.1482, MinusLogProbMetric: 399.1482, val_loss: 400.5680, val_MinusLogProbMetric: 400.5680

Epoch 119: val_loss did not improve from 400.49738
196/196 - 11s - loss: 399.1482 - MinusLogProbMetric: 399.1482 - val_loss: 400.5680 - val_MinusLogProbMetric: 400.5680 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 120/1000
2023-09-10 07:56:24.152 
Epoch 120/1000 
	 loss: 399.0327, MinusLogProbMetric: 399.0327, val_loss: 400.5651, val_MinusLogProbMetric: 400.5651

Epoch 120: val_loss did not improve from 400.49738
196/196 - 10s - loss: 399.0327 - MinusLogProbMetric: 399.0327 - val_loss: 400.5651 - val_MinusLogProbMetric: 400.5651 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 121/1000
2023-09-10 07:56:31.353 
Epoch 121/1000 
	 loss: 398.9834, MinusLogProbMetric: 398.9834, val_loss: 400.4804, val_MinusLogProbMetric: 400.4804

Epoch 121: val_loss improved from 400.49738 to 400.48041, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 398.9834 - MinusLogProbMetric: 398.9834 - val_loss: 400.4804 - val_MinusLogProbMetric: 400.4804 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 122/1000
2023-09-10 07:56:39.784 
Epoch 122/1000 
	 loss: 398.9603, MinusLogProbMetric: 398.9603, val_loss: 400.0765, val_MinusLogProbMetric: 400.0765

Epoch 122: val_loss improved from 400.48041 to 400.07654, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 398.9603 - MinusLogProbMetric: 398.9603 - val_loss: 400.0765 - val_MinusLogProbMetric: 400.0765 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 123/1000
2023-09-10 07:56:47.838 
Epoch 123/1000 
	 loss: 398.7871, MinusLogProbMetric: 398.7871, val_loss: 400.0784, val_MinusLogProbMetric: 400.0784

Epoch 123: val_loss did not improve from 400.07654
196/196 - 8s - loss: 398.7871 - MinusLogProbMetric: 398.7871 - val_loss: 400.0784 - val_MinusLogProbMetric: 400.0784 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 124/1000
2023-09-10 07:56:56.408 
Epoch 124/1000 
	 loss: 398.8161, MinusLogProbMetric: 398.8161, val_loss: 400.0277, val_MinusLogProbMetric: 400.0277

Epoch 124: val_loss improved from 400.07654 to 400.02774, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 398.8161 - MinusLogProbMetric: 398.8161 - val_loss: 400.0277 - val_MinusLogProbMetric: 400.0277 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 125/1000
2023-09-10 07:57:07.567 
Epoch 125/1000 
	 loss: 398.7398, MinusLogProbMetric: 398.7398, val_loss: 400.0331, val_MinusLogProbMetric: 400.0331

Epoch 125: val_loss did not improve from 400.02774
196/196 - 11s - loss: 398.7398 - MinusLogProbMetric: 398.7398 - val_loss: 400.0331 - val_MinusLogProbMetric: 400.0331 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 126/1000
2023-09-10 07:57:15.533 
Epoch 126/1000 
	 loss: 398.7548, MinusLogProbMetric: 398.7548, val_loss: 400.0178, val_MinusLogProbMetric: 400.0178

Epoch 126: val_loss improved from 400.02774 to 400.01776, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 398.7548 - MinusLogProbMetric: 398.7548 - val_loss: 400.0178 - val_MinusLogProbMetric: 400.0178 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 127/1000
2023-09-10 07:57:24.381 
Epoch 127/1000 
	 loss: 398.6465, MinusLogProbMetric: 398.6465, val_loss: 400.2674, val_MinusLogProbMetric: 400.2674

Epoch 127: val_loss did not improve from 400.01776
196/196 - 9s - loss: 398.6465 - MinusLogProbMetric: 398.6465 - val_loss: 400.2674 - val_MinusLogProbMetric: 400.2674 - lr: 1.6667e-04 - 9s/epoch - 43ms/step
Epoch 128/1000
2023-09-10 07:57:32.339 
Epoch 128/1000 
	 loss: 398.5746, MinusLogProbMetric: 398.5746, val_loss: 400.0274, val_MinusLogProbMetric: 400.0274

Epoch 128: val_loss did not improve from 400.01776
196/196 - 8s - loss: 398.5746 - MinusLogProbMetric: 398.5746 - val_loss: 400.0274 - val_MinusLogProbMetric: 400.0274 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 129/1000
2023-09-10 07:57:39.905 
Epoch 129/1000 
	 loss: 398.5617, MinusLogProbMetric: 398.5617, val_loss: 399.6239, val_MinusLogProbMetric: 399.6239

Epoch 129: val_loss improved from 400.01776 to 399.62387, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 398.5617 - MinusLogProbMetric: 398.5617 - val_loss: 399.6239 - val_MinusLogProbMetric: 399.6239 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 130/1000
2023-09-10 07:57:50.692 
Epoch 130/1000 
	 loss: 398.4022, MinusLogProbMetric: 398.4022, val_loss: 399.7950, val_MinusLogProbMetric: 399.7950

Epoch 130: val_loss did not improve from 399.62387
196/196 - 10s - loss: 398.4022 - MinusLogProbMetric: 398.4022 - val_loss: 399.7950 - val_MinusLogProbMetric: 399.7950 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 131/1000
2023-09-10 07:57:58.597 
Epoch 131/1000 
	 loss: 398.4127, MinusLogProbMetric: 398.4127, val_loss: 399.7453, val_MinusLogProbMetric: 399.7453

Epoch 131: val_loss did not improve from 399.62387
196/196 - 8s - loss: 398.4127 - MinusLogProbMetric: 398.4127 - val_loss: 399.7453 - val_MinusLogProbMetric: 399.7453 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 132/1000
2023-09-10 07:58:06.734 
Epoch 132/1000 
	 loss: 398.3450, MinusLogProbMetric: 398.3450, val_loss: 399.6136, val_MinusLogProbMetric: 399.6136

Epoch 132: val_loss improved from 399.62387 to 399.61365, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 398.3450 - MinusLogProbMetric: 398.3450 - val_loss: 399.6136 - val_MinusLogProbMetric: 399.6136 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 133/1000
2023-09-10 07:58:17.361 
Epoch 133/1000 
	 loss: 398.2586, MinusLogProbMetric: 398.2586, val_loss: 399.7933, val_MinusLogProbMetric: 399.7933

Epoch 133: val_loss did not improve from 399.61365
196/196 - 10s - loss: 398.2586 - MinusLogProbMetric: 398.2586 - val_loss: 399.7933 - val_MinusLogProbMetric: 399.7933 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 134/1000
2023-09-10 07:58:25.681 
Epoch 134/1000 
	 loss: 398.1868, MinusLogProbMetric: 398.1868, val_loss: 399.6998, val_MinusLogProbMetric: 399.6998

Epoch 134: val_loss did not improve from 399.61365
196/196 - 8s - loss: 398.1868 - MinusLogProbMetric: 398.1868 - val_loss: 399.6998 - val_MinusLogProbMetric: 399.6998 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 135/1000
2023-09-10 07:58:32.663 
Epoch 135/1000 
	 loss: 398.1459, MinusLogProbMetric: 398.1459, val_loss: 399.8495, val_MinusLogProbMetric: 399.8495

Epoch 135: val_loss did not improve from 399.61365
196/196 - 7s - loss: 398.1459 - MinusLogProbMetric: 398.1459 - val_loss: 399.8495 - val_MinusLogProbMetric: 399.8495 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 136/1000
2023-09-10 07:58:40.893 
Epoch 136/1000 
	 loss: 398.0875, MinusLogProbMetric: 398.0875, val_loss: 399.3410, val_MinusLogProbMetric: 399.3410

Epoch 136: val_loss improved from 399.61365 to 399.34103, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 398.0875 - MinusLogProbMetric: 398.0875 - val_loss: 399.3410 - val_MinusLogProbMetric: 399.3410 - lr: 1.6667e-04 - 9s/epoch - 43ms/step
Epoch 137/1000
2023-09-10 07:58:49.174 
Epoch 137/1000 
	 loss: 398.1086, MinusLogProbMetric: 398.1086, val_loss: 399.4467, val_MinusLogProbMetric: 399.4467

Epoch 137: val_loss did not improve from 399.34103
196/196 - 8s - loss: 398.1086 - MinusLogProbMetric: 398.1086 - val_loss: 399.4467 - val_MinusLogProbMetric: 399.4467 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 138/1000
2023-09-10 07:58:58.249 
Epoch 138/1000 
	 loss: 398.0739, MinusLogProbMetric: 398.0739, val_loss: 399.5375, val_MinusLogProbMetric: 399.5375

Epoch 138: val_loss did not improve from 399.34103
196/196 - 9s - loss: 398.0739 - MinusLogProbMetric: 398.0739 - val_loss: 399.5375 - val_MinusLogProbMetric: 399.5375 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 139/1000
2023-09-10 07:59:06.004 
Epoch 139/1000 
	 loss: 397.9030, MinusLogProbMetric: 397.9030, val_loss: 399.4189, val_MinusLogProbMetric: 399.4189

Epoch 139: val_loss did not improve from 399.34103
196/196 - 8s - loss: 397.9030 - MinusLogProbMetric: 397.9030 - val_loss: 399.4189 - val_MinusLogProbMetric: 399.4189 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 140/1000
2023-09-10 07:59:15.007 
Epoch 140/1000 
	 loss: 397.9514, MinusLogProbMetric: 397.9514, val_loss: 399.8687, val_MinusLogProbMetric: 399.8687

Epoch 140: val_loss did not improve from 399.34103
196/196 - 9s - loss: 397.9514 - MinusLogProbMetric: 397.9514 - val_loss: 399.8687 - val_MinusLogProbMetric: 399.8687 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 141/1000
2023-09-10 07:59:23.253 
Epoch 141/1000 
	 loss: 397.8799, MinusLogProbMetric: 397.8799, val_loss: 399.3422, val_MinusLogProbMetric: 399.3422

Epoch 141: val_loss did not improve from 399.34103
196/196 - 8s - loss: 397.8799 - MinusLogProbMetric: 397.8799 - val_loss: 399.3422 - val_MinusLogProbMetric: 399.3422 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 142/1000
2023-09-10 07:59:30.993 
Epoch 142/1000 
	 loss: 397.8213, MinusLogProbMetric: 397.8213, val_loss: 399.4122, val_MinusLogProbMetric: 399.4122

Epoch 142: val_loss did not improve from 399.34103
196/196 - 8s - loss: 397.8213 - MinusLogProbMetric: 397.8213 - val_loss: 399.4122 - val_MinusLogProbMetric: 399.4122 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 143/1000
2023-09-10 07:59:39.421 
Epoch 143/1000 
	 loss: 397.7379, MinusLogProbMetric: 397.7379, val_loss: 399.0163, val_MinusLogProbMetric: 399.0163

Epoch 143: val_loss improved from 399.34103 to 399.01633, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 397.7379 - MinusLogProbMetric: 397.7379 - val_loss: 399.0163 - val_MinusLogProbMetric: 399.0163 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 144/1000
2023-09-10 07:59:49.367 
Epoch 144/1000 
	 loss: 397.7654, MinusLogProbMetric: 397.7654, val_loss: 399.1374, val_MinusLogProbMetric: 399.1374

Epoch 144: val_loss did not improve from 399.01633
196/196 - 10s - loss: 397.7654 - MinusLogProbMetric: 397.7654 - val_loss: 399.1374 - val_MinusLogProbMetric: 399.1374 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 145/1000
2023-09-10 07:59:57.808 
Epoch 145/1000 
	 loss: 397.7529, MinusLogProbMetric: 397.7529, val_loss: 399.0054, val_MinusLogProbMetric: 399.0054

Epoch 145: val_loss improved from 399.01633 to 399.00537, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 397.7529 - MinusLogProbMetric: 397.7529 - val_loss: 399.0054 - val_MinusLogProbMetric: 399.0054 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 146/1000
2023-09-10 08:00:09.022 
Epoch 146/1000 
	 loss: 397.5432, MinusLogProbMetric: 397.5432, val_loss: 400.0333, val_MinusLogProbMetric: 400.0333

Epoch 146: val_loss did not improve from 399.00537
196/196 - 11s - loss: 397.5432 - MinusLogProbMetric: 397.5432 - val_loss: 400.0333 - val_MinusLogProbMetric: 400.0333 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 147/1000
2023-09-10 08:00:17.609 
Epoch 147/1000 
	 loss: 397.5840, MinusLogProbMetric: 397.5840, val_loss: 398.8613, val_MinusLogProbMetric: 398.8613

Epoch 147: val_loss improved from 399.00537 to 398.86133, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 397.5840 - MinusLogProbMetric: 397.5840 - val_loss: 398.8613 - val_MinusLogProbMetric: 398.8613 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 148/1000
2023-09-10 08:00:25.662 
Epoch 148/1000 
	 loss: 397.6038, MinusLogProbMetric: 397.6038, val_loss: 399.5368, val_MinusLogProbMetric: 399.5368

Epoch 148: val_loss did not improve from 398.86133
196/196 - 8s - loss: 397.6038 - MinusLogProbMetric: 397.6038 - val_loss: 399.5368 - val_MinusLogProbMetric: 399.5368 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 149/1000
2023-09-10 08:00:32.847 
Epoch 149/1000 
	 loss: 397.4249, MinusLogProbMetric: 397.4249, val_loss: 399.0062, val_MinusLogProbMetric: 399.0062

Epoch 149: val_loss did not improve from 398.86133
196/196 - 7s - loss: 397.4249 - MinusLogProbMetric: 397.4249 - val_loss: 399.0062 - val_MinusLogProbMetric: 399.0062 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 150/1000
2023-09-10 08:00:41.887 
Epoch 150/1000 
	 loss: 397.4626, MinusLogProbMetric: 397.4626, val_loss: 398.9606, val_MinusLogProbMetric: 398.9606

Epoch 150: val_loss did not improve from 398.86133
196/196 - 9s - loss: 397.4626 - MinusLogProbMetric: 397.4626 - val_loss: 398.9606 - val_MinusLogProbMetric: 398.9606 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 151/1000
2023-09-10 08:00:49.193 
Epoch 151/1000 
	 loss: 397.3266, MinusLogProbMetric: 397.3266, val_loss: 399.0962, val_MinusLogProbMetric: 399.0962

Epoch 151: val_loss did not improve from 398.86133
196/196 - 7s - loss: 397.3266 - MinusLogProbMetric: 397.3266 - val_loss: 399.0962 - val_MinusLogProbMetric: 399.0962 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 152/1000
2023-09-10 08:00:57.501 
Epoch 152/1000 
	 loss: 397.3947, MinusLogProbMetric: 397.3947, val_loss: 398.7928, val_MinusLogProbMetric: 398.7928

Epoch 152: val_loss improved from 398.86133 to 398.79279, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 397.3947 - MinusLogProbMetric: 397.3947 - val_loss: 398.7928 - val_MinusLogProbMetric: 398.7928 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 153/1000
2023-09-10 08:01:05.241 
Epoch 153/1000 
	 loss: 397.2777, MinusLogProbMetric: 397.2777, val_loss: 398.6044, val_MinusLogProbMetric: 398.6044

Epoch 153: val_loss improved from 398.79279 to 398.60443, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 397.2777 - MinusLogProbMetric: 397.2777 - val_loss: 398.6044 - val_MinusLogProbMetric: 398.6044 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 154/1000
2023-09-10 08:01:13.712 
Epoch 154/1000 
	 loss: 397.3146, MinusLogProbMetric: 397.3146, val_loss: 398.3632, val_MinusLogProbMetric: 398.3632

Epoch 154: val_loss improved from 398.60443 to 398.36319, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 397.3146 - MinusLogProbMetric: 397.3146 - val_loss: 398.3632 - val_MinusLogProbMetric: 398.3632 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 155/1000
2023-09-10 08:01:21.052 
Epoch 155/1000 
	 loss: 397.1968, MinusLogProbMetric: 397.1968, val_loss: 398.6314, val_MinusLogProbMetric: 398.6314

Epoch 155: val_loss did not improve from 398.36319
196/196 - 7s - loss: 397.1968 - MinusLogProbMetric: 397.1968 - val_loss: 398.6314 - val_MinusLogProbMetric: 398.6314 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 156/1000
2023-09-10 08:01:28.815 
Epoch 156/1000 
	 loss: 397.1495, MinusLogProbMetric: 397.1495, val_loss: 398.6367, val_MinusLogProbMetric: 398.6367

Epoch 156: val_loss did not improve from 398.36319
196/196 - 8s - loss: 397.1495 - MinusLogProbMetric: 397.1495 - val_loss: 398.6367 - val_MinusLogProbMetric: 398.6367 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 157/1000
2023-09-10 08:01:36.150 
Epoch 157/1000 
	 loss: 397.1294, MinusLogProbMetric: 397.1294, val_loss: 399.2550, val_MinusLogProbMetric: 399.2550

Epoch 157: val_loss did not improve from 398.36319
196/196 - 7s - loss: 397.1294 - MinusLogProbMetric: 397.1294 - val_loss: 399.2550 - val_MinusLogProbMetric: 399.2550 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 158/1000
2023-09-10 08:01:43.848 
Epoch 158/1000 
	 loss: 397.1930, MinusLogProbMetric: 397.1930, val_loss: 398.6208, val_MinusLogProbMetric: 398.6208

Epoch 158: val_loss did not improve from 398.36319
196/196 - 8s - loss: 397.1930 - MinusLogProbMetric: 397.1930 - val_loss: 398.6208 - val_MinusLogProbMetric: 398.6208 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 159/1000
2023-09-10 08:01:54.272 
Epoch 159/1000 
	 loss: 397.0591, MinusLogProbMetric: 397.0591, val_loss: 398.3011, val_MinusLogProbMetric: 398.3011

Epoch 159: val_loss improved from 398.36319 to 398.30106, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 397.0591 - MinusLogProbMetric: 397.0591 - val_loss: 398.3011 - val_MinusLogProbMetric: 398.3011 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 160/1000
2023-09-10 08:02:03.110 
Epoch 160/1000 
	 loss: 396.9907, MinusLogProbMetric: 396.9907, val_loss: 398.5659, val_MinusLogProbMetric: 398.5659

Epoch 160: val_loss did not improve from 398.30106
196/196 - 8s - loss: 396.9907 - MinusLogProbMetric: 396.9907 - val_loss: 398.5659 - val_MinusLogProbMetric: 398.5659 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 161/1000
2023-09-10 08:02:12.138 
Epoch 161/1000 
	 loss: 396.9307, MinusLogProbMetric: 396.9307, val_loss: 399.4768, val_MinusLogProbMetric: 399.4768

Epoch 161: val_loss did not improve from 398.30106
196/196 - 9s - loss: 396.9307 - MinusLogProbMetric: 396.9307 - val_loss: 399.4768 - val_MinusLogProbMetric: 399.4768 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 162/1000
2023-09-10 08:02:22.376 
Epoch 162/1000 
	 loss: 396.9860, MinusLogProbMetric: 396.9860, val_loss: 398.4642, val_MinusLogProbMetric: 398.4642

Epoch 162: val_loss did not improve from 398.30106
196/196 - 10s - loss: 396.9860 - MinusLogProbMetric: 396.9860 - val_loss: 398.4642 - val_MinusLogProbMetric: 398.4642 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 163/1000
2023-09-10 08:02:30.489 
Epoch 163/1000 
	 loss: 396.8868, MinusLogProbMetric: 396.8868, val_loss: 398.3765, val_MinusLogProbMetric: 398.3765

Epoch 163: val_loss did not improve from 398.30106
196/196 - 8s - loss: 396.8868 - MinusLogProbMetric: 396.8868 - val_loss: 398.3765 - val_MinusLogProbMetric: 398.3765 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 164/1000
2023-09-10 08:02:40.738 
Epoch 164/1000 
	 loss: 396.8359, MinusLogProbMetric: 396.8359, val_loss: 398.1017, val_MinusLogProbMetric: 398.1017

Epoch 164: val_loss improved from 398.30106 to 398.10165, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 396.8359 - MinusLogProbMetric: 396.8359 - val_loss: 398.1017 - val_MinusLogProbMetric: 398.1017 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 165/1000
2023-09-10 08:02:48.822 
Epoch 165/1000 
	 loss: 396.7657, MinusLogProbMetric: 396.7657, val_loss: 398.0199, val_MinusLogProbMetric: 398.0199

Epoch 165: val_loss improved from 398.10165 to 398.01987, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 396.7657 - MinusLogProbMetric: 396.7657 - val_loss: 398.0199 - val_MinusLogProbMetric: 398.0199 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 166/1000
2023-09-10 08:03:00.802 
Epoch 166/1000 
	 loss: 396.8156, MinusLogProbMetric: 396.8156, val_loss: 398.7991, val_MinusLogProbMetric: 398.7991

Epoch 166: val_loss did not improve from 398.01987
196/196 - 12s - loss: 396.8156 - MinusLogProbMetric: 396.8156 - val_loss: 398.7991 - val_MinusLogProbMetric: 398.7991 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 167/1000
2023-09-10 08:03:10.821 
Epoch 167/1000 
	 loss: 396.8179, MinusLogProbMetric: 396.8179, val_loss: 398.0899, val_MinusLogProbMetric: 398.0899

Epoch 167: val_loss did not improve from 398.01987
196/196 - 10s - loss: 396.8179 - MinusLogProbMetric: 396.8179 - val_loss: 398.0899 - val_MinusLogProbMetric: 398.0899 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 168/1000
2023-09-10 08:03:21.187 
Epoch 168/1000 
	 loss: 396.7462, MinusLogProbMetric: 396.7462, val_loss: 398.2269, val_MinusLogProbMetric: 398.2269

Epoch 168: val_loss did not improve from 398.01987
196/196 - 10s - loss: 396.7462 - MinusLogProbMetric: 396.7462 - val_loss: 398.2269 - val_MinusLogProbMetric: 398.2269 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 169/1000
2023-09-10 08:03:30.993 
Epoch 169/1000 
	 loss: 396.6664, MinusLogProbMetric: 396.6664, val_loss: 398.4913, val_MinusLogProbMetric: 398.4913

Epoch 169: val_loss did not improve from 398.01987
196/196 - 10s - loss: 396.6664 - MinusLogProbMetric: 396.6664 - val_loss: 398.4913 - val_MinusLogProbMetric: 398.4913 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 170/1000
2023-09-10 08:03:38.655 
Epoch 170/1000 
	 loss: 396.6142, MinusLogProbMetric: 396.6142, val_loss: 398.1387, val_MinusLogProbMetric: 398.1387

Epoch 170: val_loss did not improve from 398.01987
196/196 - 8s - loss: 396.6142 - MinusLogProbMetric: 396.6142 - val_loss: 398.1387 - val_MinusLogProbMetric: 398.1387 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 171/1000
2023-09-10 08:03:49.980 
Epoch 171/1000 
	 loss: 396.5125, MinusLogProbMetric: 396.5125, val_loss: 397.7751, val_MinusLogProbMetric: 397.7751

Epoch 171: val_loss improved from 398.01987 to 397.77515, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 396.5125 - MinusLogProbMetric: 396.5125 - val_loss: 397.7751 - val_MinusLogProbMetric: 397.7751 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 172/1000
2023-09-10 08:03:58.732 
Epoch 172/1000 
	 loss: 396.6188, MinusLogProbMetric: 396.6188, val_loss: 398.4312, val_MinusLogProbMetric: 398.4312

Epoch 172: val_loss did not improve from 397.77515
196/196 - 8s - loss: 396.6188 - MinusLogProbMetric: 396.6188 - val_loss: 398.4312 - val_MinusLogProbMetric: 398.4312 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 173/1000
2023-09-10 08:04:08.154 
Epoch 173/1000 
	 loss: 396.5466, MinusLogProbMetric: 396.5466, val_loss: 397.8281, val_MinusLogProbMetric: 397.8281

Epoch 173: val_loss did not improve from 397.77515
196/196 - 9s - loss: 396.5466 - MinusLogProbMetric: 396.5466 - val_loss: 397.8281 - val_MinusLogProbMetric: 397.8281 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 174/1000
2023-09-10 08:04:17.620 
Epoch 174/1000 
	 loss: 396.3969, MinusLogProbMetric: 396.3969, val_loss: 398.2094, val_MinusLogProbMetric: 398.2094

Epoch 174: val_loss did not improve from 397.77515
196/196 - 9s - loss: 396.3969 - MinusLogProbMetric: 396.3969 - val_loss: 398.2094 - val_MinusLogProbMetric: 398.2094 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 175/1000
2023-09-10 08:04:25.011 
Epoch 175/1000 
	 loss: 396.4707, MinusLogProbMetric: 396.4707, val_loss: 398.1875, val_MinusLogProbMetric: 398.1875

Epoch 175: val_loss did not improve from 397.77515
196/196 - 7s - loss: 396.4707 - MinusLogProbMetric: 396.4707 - val_loss: 398.1875 - val_MinusLogProbMetric: 398.1875 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 176/1000
2023-09-10 08:04:33.629 
Epoch 176/1000 
	 loss: 396.4446, MinusLogProbMetric: 396.4446, val_loss: 399.1863, val_MinusLogProbMetric: 399.1863

Epoch 176: val_loss did not improve from 397.77515
196/196 - 9s - loss: 396.4446 - MinusLogProbMetric: 396.4446 - val_loss: 399.1863 - val_MinusLogProbMetric: 399.1863 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 177/1000
2023-09-10 08:04:44.025 
Epoch 177/1000 
	 loss: 396.3169, MinusLogProbMetric: 396.3169, val_loss: 397.7676, val_MinusLogProbMetric: 397.7676

Epoch 177: val_loss improved from 397.77515 to 397.76764, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 396.3169 - MinusLogProbMetric: 396.3169 - val_loss: 397.7676 - val_MinusLogProbMetric: 397.7676 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 178/1000
2023-09-10 08:04:53.500 
Epoch 178/1000 
	 loss: 396.2438, MinusLogProbMetric: 396.2438, val_loss: 398.0184, val_MinusLogProbMetric: 398.0184

Epoch 178: val_loss did not improve from 397.76764
196/196 - 9s - loss: 396.2438 - MinusLogProbMetric: 396.2438 - val_loss: 398.0184 - val_MinusLogProbMetric: 398.0184 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 179/1000
2023-09-10 08:05:00.666 
Epoch 179/1000 
	 loss: 396.2777, MinusLogProbMetric: 396.2777, val_loss: 398.3283, val_MinusLogProbMetric: 398.3283

Epoch 179: val_loss did not improve from 397.76764
196/196 - 7s - loss: 396.2777 - MinusLogProbMetric: 396.2777 - val_loss: 398.3283 - val_MinusLogProbMetric: 398.3283 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 180/1000
2023-09-10 08:05:07.614 
Epoch 180/1000 
	 loss: 396.4028, MinusLogProbMetric: 396.4028, val_loss: 397.7639, val_MinusLogProbMetric: 397.7639

Epoch 180: val_loss improved from 397.76764 to 397.76385, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 396.4028 - MinusLogProbMetric: 396.4028 - val_loss: 397.7639 - val_MinusLogProbMetric: 397.7639 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 181/1000
2023-09-10 08:05:16.556 
Epoch 181/1000 
	 loss: 396.2364, MinusLogProbMetric: 396.2364, val_loss: 397.7428, val_MinusLogProbMetric: 397.7428

Epoch 181: val_loss improved from 397.76385 to 397.74277, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 396.2364 - MinusLogProbMetric: 396.2364 - val_loss: 397.7428 - val_MinusLogProbMetric: 397.7428 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 182/1000
2023-09-10 08:05:26.862 
Epoch 182/1000 
	 loss: 396.1926, MinusLogProbMetric: 396.1926, val_loss: 397.5950, val_MinusLogProbMetric: 397.5950

Epoch 182: val_loss improved from 397.74277 to 397.59503, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 396.1926 - MinusLogProbMetric: 396.1926 - val_loss: 397.5950 - val_MinusLogProbMetric: 397.5950 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 183/1000
2023-09-10 08:05:38.164 
Epoch 183/1000 
	 loss: 396.2248, MinusLogProbMetric: 396.2248, val_loss: 398.3717, val_MinusLogProbMetric: 398.3717

Epoch 183: val_loss did not improve from 397.59503
196/196 - 11s - loss: 396.2248 - MinusLogProbMetric: 396.2248 - val_loss: 398.3717 - val_MinusLogProbMetric: 398.3717 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 184/1000
2023-09-10 08:05:50.025 
Epoch 184/1000 
	 loss: 396.2151, MinusLogProbMetric: 396.2151, val_loss: 397.5475, val_MinusLogProbMetric: 397.5475

Epoch 184: val_loss improved from 397.59503 to 397.54749, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 396.2151 - MinusLogProbMetric: 396.2151 - val_loss: 397.5475 - val_MinusLogProbMetric: 397.5475 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 185/1000
2023-09-10 08:06:00.583 
Epoch 185/1000 
	 loss: 396.0859, MinusLogProbMetric: 396.0859, val_loss: 397.2539, val_MinusLogProbMetric: 397.2539

Epoch 185: val_loss improved from 397.54749 to 397.25391, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 396.0859 - MinusLogProbMetric: 396.0859 - val_loss: 397.2539 - val_MinusLogProbMetric: 397.2539 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 186/1000
2023-09-10 08:06:12.083 
Epoch 186/1000 
	 loss: 396.0463, MinusLogProbMetric: 396.0463, val_loss: 397.8478, val_MinusLogProbMetric: 397.8478

Epoch 186: val_loss did not improve from 397.25391
196/196 - 10s - loss: 396.0463 - MinusLogProbMetric: 396.0463 - val_loss: 397.8478 - val_MinusLogProbMetric: 397.8478 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 187/1000
2023-09-10 08:06:23.686 
Epoch 187/1000 
	 loss: 396.1031, MinusLogProbMetric: 396.1031, val_loss: 399.8137, val_MinusLogProbMetric: 399.8137

Epoch 187: val_loss did not improve from 397.25391
196/196 - 12s - loss: 396.1031 - MinusLogProbMetric: 396.1031 - val_loss: 399.8137 - val_MinusLogProbMetric: 399.8137 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 188/1000
2023-09-10 08:06:32.819 
Epoch 188/1000 
	 loss: 396.0888, MinusLogProbMetric: 396.0888, val_loss: 397.5856, val_MinusLogProbMetric: 397.5856

Epoch 188: val_loss did not improve from 397.25391
196/196 - 9s - loss: 396.0888 - MinusLogProbMetric: 396.0888 - val_loss: 397.5856 - val_MinusLogProbMetric: 397.5856 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 189/1000
2023-09-10 08:06:41.966 
Epoch 189/1000 
	 loss: 395.9970, MinusLogProbMetric: 395.9970, val_loss: 397.7094, val_MinusLogProbMetric: 397.7094

Epoch 189: val_loss did not improve from 397.25391
196/196 - 9s - loss: 395.9970 - MinusLogProbMetric: 395.9970 - val_loss: 397.7094 - val_MinusLogProbMetric: 397.7094 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 190/1000
2023-09-10 08:06:50.170 
Epoch 190/1000 
	 loss: 395.9272, MinusLogProbMetric: 395.9272, val_loss: 397.7713, val_MinusLogProbMetric: 397.7713

Epoch 190: val_loss did not improve from 397.25391
196/196 - 8s - loss: 395.9272 - MinusLogProbMetric: 395.9272 - val_loss: 397.7713 - val_MinusLogProbMetric: 397.7713 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 191/1000
2023-09-10 08:06:59.527 
Epoch 191/1000 
	 loss: 395.9482, MinusLogProbMetric: 395.9482, val_loss: 397.1131, val_MinusLogProbMetric: 397.1131

Epoch 191: val_loss improved from 397.25391 to 397.11307, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 395.9482 - MinusLogProbMetric: 395.9482 - val_loss: 397.1131 - val_MinusLogProbMetric: 397.1131 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 192/1000
2023-09-10 08:07:10.225 
Epoch 192/1000 
	 loss: 396.0198, MinusLogProbMetric: 396.0198, val_loss: 397.8239, val_MinusLogProbMetric: 397.8239

Epoch 192: val_loss did not improve from 397.11307
196/196 - 10s - loss: 396.0198 - MinusLogProbMetric: 396.0198 - val_loss: 397.8239 - val_MinusLogProbMetric: 397.8239 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 193/1000
2023-09-10 08:07:19.113 
Epoch 193/1000 
	 loss: 395.7644, MinusLogProbMetric: 395.7644, val_loss: 397.2657, val_MinusLogProbMetric: 397.2657

Epoch 193: val_loss did not improve from 397.11307
196/196 - 9s - loss: 395.7644 - MinusLogProbMetric: 395.7644 - val_loss: 397.2657 - val_MinusLogProbMetric: 397.2657 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 194/1000
2023-09-10 08:07:28.528 
Epoch 194/1000 
	 loss: 395.8332, MinusLogProbMetric: 395.8332, val_loss: 397.0595, val_MinusLogProbMetric: 397.0595

Epoch 194: val_loss improved from 397.11307 to 397.05954, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 395.8332 - MinusLogProbMetric: 395.8332 - val_loss: 397.0595 - val_MinusLogProbMetric: 397.0595 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 195/1000
2023-09-10 08:07:38.333 
Epoch 195/1000 
	 loss: 395.8997, MinusLogProbMetric: 395.8997, val_loss: 397.2353, val_MinusLogProbMetric: 397.2353

Epoch 195: val_loss did not improve from 397.05954
196/196 - 9s - loss: 395.8997 - MinusLogProbMetric: 395.8997 - val_loss: 397.2353 - val_MinusLogProbMetric: 397.2353 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 196/1000
2023-09-10 08:07:47.529 
Epoch 196/1000 
	 loss: 395.9004, MinusLogProbMetric: 395.9004, val_loss: 397.9893, val_MinusLogProbMetric: 397.9893

Epoch 196: val_loss did not improve from 397.05954
196/196 - 9s - loss: 395.9004 - MinusLogProbMetric: 395.9004 - val_loss: 397.9893 - val_MinusLogProbMetric: 397.9893 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 197/1000
2023-09-10 08:07:55.563 
Epoch 197/1000 
	 loss: 395.8190, MinusLogProbMetric: 395.8190, val_loss: 397.3499, val_MinusLogProbMetric: 397.3499

Epoch 197: val_loss did not improve from 397.05954
196/196 - 8s - loss: 395.8190 - MinusLogProbMetric: 395.8190 - val_loss: 397.3499 - val_MinusLogProbMetric: 397.3499 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 198/1000
2023-09-10 08:08:05.000 
Epoch 198/1000 
	 loss: 395.6730, MinusLogProbMetric: 395.6730, val_loss: 397.0866, val_MinusLogProbMetric: 397.0866

Epoch 198: val_loss did not improve from 397.05954
196/196 - 9s - loss: 395.6730 - MinusLogProbMetric: 395.6730 - val_loss: 397.0866 - val_MinusLogProbMetric: 397.0866 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 199/1000
2023-09-10 08:08:15.632 
Epoch 199/1000 
	 loss: 395.7757, MinusLogProbMetric: 395.7757, val_loss: 397.3185, val_MinusLogProbMetric: 397.3185

Epoch 199: val_loss did not improve from 397.05954
196/196 - 11s - loss: 395.7757 - MinusLogProbMetric: 395.7757 - val_loss: 397.3185 - val_MinusLogProbMetric: 397.3185 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 200/1000
2023-09-10 08:08:27.080 
Epoch 200/1000 
	 loss: 395.7509, MinusLogProbMetric: 395.7509, val_loss: 397.5289, val_MinusLogProbMetric: 397.5289

Epoch 200: val_loss did not improve from 397.05954
196/196 - 11s - loss: 395.7509 - MinusLogProbMetric: 395.7509 - val_loss: 397.5289 - val_MinusLogProbMetric: 397.5289 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 201/1000
2023-09-10 08:08:37.575 
Epoch 201/1000 
	 loss: 395.6307, MinusLogProbMetric: 395.6307, val_loss: 396.9516, val_MinusLogProbMetric: 396.9516

Epoch 201: val_loss improved from 397.05954 to 396.95157, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 395.6307 - MinusLogProbMetric: 395.6307 - val_loss: 396.9516 - val_MinusLogProbMetric: 396.9516 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 202/1000
2023-09-10 08:08:47.566 
Epoch 202/1000 
	 loss: 395.5710, MinusLogProbMetric: 395.5710, val_loss: 396.9874, val_MinusLogProbMetric: 396.9874

Epoch 202: val_loss did not improve from 396.95157
196/196 - 10s - loss: 395.5710 - MinusLogProbMetric: 395.5710 - val_loss: 396.9874 - val_MinusLogProbMetric: 396.9874 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 203/1000
2023-09-10 08:08:55.876 
Epoch 203/1000 
	 loss: 395.5041, MinusLogProbMetric: 395.5041, val_loss: 396.8305, val_MinusLogProbMetric: 396.8305

Epoch 203: val_loss improved from 396.95157 to 396.83051, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 395.5041 - MinusLogProbMetric: 395.5041 - val_loss: 396.8305 - val_MinusLogProbMetric: 396.8305 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 204/1000
2023-09-10 08:09:07.258 
Epoch 204/1000 
	 loss: 395.5072, MinusLogProbMetric: 395.5072, val_loss: 397.1793, val_MinusLogProbMetric: 397.1793

Epoch 204: val_loss did not improve from 396.83051
196/196 - 10s - loss: 395.5072 - MinusLogProbMetric: 395.5072 - val_loss: 397.1793 - val_MinusLogProbMetric: 397.1793 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 205/1000
2023-09-10 08:09:16.875 
Epoch 205/1000 
	 loss: 395.6207, MinusLogProbMetric: 395.6207, val_loss: 396.8937, val_MinusLogProbMetric: 396.8937

Epoch 205: val_loss did not improve from 396.83051
196/196 - 10s - loss: 395.6207 - MinusLogProbMetric: 395.6207 - val_loss: 396.8937 - val_MinusLogProbMetric: 396.8937 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 206/1000
2023-09-10 08:09:26.286 
Epoch 206/1000 
	 loss: 395.5881, MinusLogProbMetric: 395.5881, val_loss: 397.2223, val_MinusLogProbMetric: 397.2223

Epoch 206: val_loss did not improve from 396.83051
196/196 - 9s - loss: 395.5881 - MinusLogProbMetric: 395.5881 - val_loss: 397.2223 - val_MinusLogProbMetric: 397.2223 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 207/1000
2023-09-10 08:09:35.238 
Epoch 207/1000 
	 loss: 395.6044, MinusLogProbMetric: 395.6044, val_loss: 396.8243, val_MinusLogProbMetric: 396.8243

Epoch 207: val_loss improved from 396.83051 to 396.82434, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 395.6044 - MinusLogProbMetric: 395.6044 - val_loss: 396.8243 - val_MinusLogProbMetric: 396.8243 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 208/1000
2023-09-10 08:09:43.775 
Epoch 208/1000 
	 loss: 395.6027, MinusLogProbMetric: 395.6027, val_loss: 397.4021, val_MinusLogProbMetric: 397.4021

Epoch 208: val_loss did not improve from 396.82434
196/196 - 8s - loss: 395.6027 - MinusLogProbMetric: 395.6027 - val_loss: 397.4021 - val_MinusLogProbMetric: 397.4021 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 209/1000
2023-09-10 08:09:53.310 
Epoch 209/1000 
	 loss: 395.4319, MinusLogProbMetric: 395.4319, val_loss: 397.0565, val_MinusLogProbMetric: 397.0565

Epoch 209: val_loss did not improve from 396.82434
196/196 - 10s - loss: 395.4319 - MinusLogProbMetric: 395.4319 - val_loss: 397.0565 - val_MinusLogProbMetric: 397.0565 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 210/1000
2023-09-10 08:10:01.640 
Epoch 210/1000 
	 loss: 395.4467, MinusLogProbMetric: 395.4467, val_loss: 397.3293, val_MinusLogProbMetric: 397.3293

Epoch 210: val_loss did not improve from 396.82434
196/196 - 8s - loss: 395.4467 - MinusLogProbMetric: 395.4467 - val_loss: 397.3293 - val_MinusLogProbMetric: 397.3293 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 211/1000
2023-09-10 08:10:08.995 
Epoch 211/1000 
	 loss: 395.3292, MinusLogProbMetric: 395.3292, val_loss: 397.2086, val_MinusLogProbMetric: 397.2086

Epoch 211: val_loss did not improve from 396.82434
196/196 - 7s - loss: 395.3292 - MinusLogProbMetric: 395.3292 - val_loss: 397.2086 - val_MinusLogProbMetric: 397.2086 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 212/1000
2023-09-10 08:10:17.860 
Epoch 212/1000 
	 loss: 395.3875, MinusLogProbMetric: 395.3875, val_loss: 396.7470, val_MinusLogProbMetric: 396.7470

Epoch 212: val_loss improved from 396.82434 to 396.74701, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 395.3875 - MinusLogProbMetric: 395.3875 - val_loss: 396.7470 - val_MinusLogProbMetric: 396.7470 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 213/1000
2023-09-10 08:10:24.921 
Epoch 213/1000 
	 loss: 395.3309, MinusLogProbMetric: 395.3309, val_loss: 396.6890, val_MinusLogProbMetric: 396.6890

Epoch 213: val_loss improved from 396.74701 to 396.68900, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 395.3309 - MinusLogProbMetric: 395.3309 - val_loss: 396.6890 - val_MinusLogProbMetric: 396.6890 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 214/1000
2023-09-10 08:10:35.934 
Epoch 214/1000 
	 loss: 395.3418, MinusLogProbMetric: 395.3418, val_loss: 397.2084, val_MinusLogProbMetric: 397.2084

Epoch 214: val_loss did not improve from 396.68900
196/196 - 11s - loss: 395.3418 - MinusLogProbMetric: 395.3418 - val_loss: 397.2084 - val_MinusLogProbMetric: 397.2084 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 215/1000
2023-09-10 08:10:43.265 
Epoch 215/1000 
	 loss: 395.2970, MinusLogProbMetric: 395.2970, val_loss: 397.2020, val_MinusLogProbMetric: 397.2020

Epoch 215: val_loss did not improve from 396.68900
196/196 - 7s - loss: 395.2970 - MinusLogProbMetric: 395.2970 - val_loss: 397.2020 - val_MinusLogProbMetric: 397.2020 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 216/1000
2023-09-10 08:10:51.332 
Epoch 216/1000 
	 loss: 395.3124, MinusLogProbMetric: 395.3124, val_loss: 396.5037, val_MinusLogProbMetric: 396.5037

Epoch 216: val_loss improved from 396.68900 to 396.50366, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 395.3124 - MinusLogProbMetric: 395.3124 - val_loss: 396.5037 - val_MinusLogProbMetric: 396.5037 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 217/1000
2023-09-10 08:10:58.455 
Epoch 217/1000 
	 loss: 395.3158, MinusLogProbMetric: 395.3158, val_loss: 398.3282, val_MinusLogProbMetric: 398.3282

Epoch 217: val_loss did not improve from 396.50366
196/196 - 7s - loss: 395.3158 - MinusLogProbMetric: 395.3158 - val_loss: 398.3282 - val_MinusLogProbMetric: 398.3282 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 218/1000
2023-09-10 08:11:05.365 
Epoch 218/1000 
	 loss: 395.3290, MinusLogProbMetric: 395.3290, val_loss: 396.6968, val_MinusLogProbMetric: 396.6968

Epoch 218: val_loss did not improve from 396.50366
196/196 - 7s - loss: 395.3290 - MinusLogProbMetric: 395.3290 - val_loss: 396.6968 - val_MinusLogProbMetric: 396.6968 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 219/1000
2023-09-10 08:11:13.781 
Epoch 219/1000 
	 loss: 395.1433, MinusLogProbMetric: 395.1433, val_loss: 396.7193, val_MinusLogProbMetric: 396.7193

Epoch 219: val_loss did not improve from 396.50366
196/196 - 8s - loss: 395.1433 - MinusLogProbMetric: 395.1433 - val_loss: 396.7193 - val_MinusLogProbMetric: 396.7193 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 220/1000
2023-09-10 08:11:21.425 
Epoch 220/1000 
	 loss: 395.2776, MinusLogProbMetric: 395.2776, val_loss: 396.2775, val_MinusLogProbMetric: 396.2775

Epoch 220: val_loss improved from 396.50366 to 396.27750, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 395.2776 - MinusLogProbMetric: 395.2776 - val_loss: 396.2775 - val_MinusLogProbMetric: 396.2775 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 221/1000
2023-09-10 08:11:30.071 
Epoch 221/1000 
	 loss: 395.2744, MinusLogProbMetric: 395.2744, val_loss: 396.6760, val_MinusLogProbMetric: 396.6760

Epoch 221: val_loss did not improve from 396.27750
196/196 - 8s - loss: 395.2744 - MinusLogProbMetric: 395.2744 - val_loss: 396.6760 - val_MinusLogProbMetric: 396.6760 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 222/1000
2023-09-10 08:11:36.928 
Epoch 222/1000 
	 loss: 395.1474, MinusLogProbMetric: 395.1474, val_loss: 397.5074, val_MinusLogProbMetric: 397.5074

Epoch 222: val_loss did not improve from 396.27750
196/196 - 7s - loss: 395.1474 - MinusLogProbMetric: 395.1474 - val_loss: 397.5074 - val_MinusLogProbMetric: 397.5074 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 223/1000
2023-09-10 08:11:45.400 
Epoch 223/1000 
	 loss: 395.1449, MinusLogProbMetric: 395.1449, val_loss: 397.4543, val_MinusLogProbMetric: 397.4543

Epoch 223: val_loss did not improve from 396.27750
196/196 - 8s - loss: 395.1449 - MinusLogProbMetric: 395.1449 - val_loss: 397.4543 - val_MinusLogProbMetric: 397.4543 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 224/1000
2023-09-10 08:11:54.227 
Epoch 224/1000 
	 loss: 395.1369, MinusLogProbMetric: 395.1369, val_loss: 397.2950, val_MinusLogProbMetric: 397.2950

Epoch 224: val_loss did not improve from 396.27750
196/196 - 9s - loss: 395.1369 - MinusLogProbMetric: 395.1369 - val_loss: 397.2950 - val_MinusLogProbMetric: 397.2950 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 225/1000
2023-09-10 08:12:01.583 
Epoch 225/1000 
	 loss: 395.2196, MinusLogProbMetric: 395.2196, val_loss: 396.6263, val_MinusLogProbMetric: 396.6263

Epoch 225: val_loss did not improve from 396.27750
196/196 - 7s - loss: 395.2196 - MinusLogProbMetric: 395.2196 - val_loss: 396.6263 - val_MinusLogProbMetric: 396.6263 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 226/1000
2023-09-10 08:12:09.273 
Epoch 226/1000 
	 loss: 395.0958, MinusLogProbMetric: 395.0958, val_loss: 396.5672, val_MinusLogProbMetric: 396.5672

Epoch 226: val_loss did not improve from 396.27750
196/196 - 8s - loss: 395.0958 - MinusLogProbMetric: 395.0958 - val_loss: 396.5672 - val_MinusLogProbMetric: 396.5672 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 227/1000
2023-09-10 08:12:18.328 
Epoch 227/1000 
	 loss: 395.0279, MinusLogProbMetric: 395.0279, val_loss: 397.0800, val_MinusLogProbMetric: 397.0800

Epoch 227: val_loss did not improve from 396.27750
196/196 - 9s - loss: 395.0279 - MinusLogProbMetric: 395.0279 - val_loss: 397.0800 - val_MinusLogProbMetric: 397.0800 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 228/1000
2023-09-10 08:12:30.196 
Epoch 228/1000 
	 loss: 395.3719, MinusLogProbMetric: 395.3719, val_loss: 396.6866, val_MinusLogProbMetric: 396.6866

Epoch 228: val_loss did not improve from 396.27750
196/196 - 12s - loss: 395.3719 - MinusLogProbMetric: 395.3719 - val_loss: 396.6866 - val_MinusLogProbMetric: 396.6866 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 229/1000
2023-09-10 08:12:38.095 
Epoch 229/1000 
	 loss: 395.0542, MinusLogProbMetric: 395.0542, val_loss: 396.2173, val_MinusLogProbMetric: 396.2173

Epoch 229: val_loss improved from 396.27750 to 396.21729, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 395.0542 - MinusLogProbMetric: 395.0542 - val_loss: 396.2173 - val_MinusLogProbMetric: 396.2173 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 230/1000
2023-09-10 08:12:49.543 
Epoch 230/1000 
	 loss: 394.8857, MinusLogProbMetric: 394.8857, val_loss: 396.7591, val_MinusLogProbMetric: 396.7591

Epoch 230: val_loss did not improve from 396.21729
196/196 - 11s - loss: 394.8857 - MinusLogProbMetric: 394.8857 - val_loss: 396.7591 - val_MinusLogProbMetric: 396.7591 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 231/1000
2023-09-10 08:12:57.143 
Epoch 231/1000 
	 loss: 395.0327, MinusLogProbMetric: 395.0327, val_loss: 396.7641, val_MinusLogProbMetric: 396.7641

Epoch 231: val_loss did not improve from 396.21729
196/196 - 8s - loss: 395.0327 - MinusLogProbMetric: 395.0327 - val_loss: 396.7641 - val_MinusLogProbMetric: 396.7641 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 232/1000
2023-09-10 08:13:04.655 
Epoch 232/1000 
	 loss: 394.9915, MinusLogProbMetric: 394.9915, val_loss: 396.5932, val_MinusLogProbMetric: 396.5932

Epoch 232: val_loss did not improve from 396.21729
196/196 - 8s - loss: 394.9915 - MinusLogProbMetric: 394.9915 - val_loss: 396.5932 - val_MinusLogProbMetric: 396.5932 - lr: 1.6667e-04 - 8s/epoch - 38ms/step
Epoch 233/1000
2023-09-10 08:13:11.445 
Epoch 233/1000 
	 loss: 394.9059, MinusLogProbMetric: 394.9059, val_loss: 396.5300, val_MinusLogProbMetric: 396.5300

Epoch 233: val_loss did not improve from 396.21729
196/196 - 7s - loss: 394.9059 - MinusLogProbMetric: 394.9059 - val_loss: 396.5300 - val_MinusLogProbMetric: 396.5300 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 234/1000
2023-09-10 08:13:20.858 
Epoch 234/1000 
	 loss: 395.0785, MinusLogProbMetric: 395.0785, val_loss: 396.1109, val_MinusLogProbMetric: 396.1109

Epoch 234: val_loss improved from 396.21729 to 396.11087, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 395.0785 - MinusLogProbMetric: 395.0785 - val_loss: 396.1109 - val_MinusLogProbMetric: 396.1109 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 235/1000
2023-09-10 08:13:31.845 
Epoch 235/1000 
	 loss: 394.8280, MinusLogProbMetric: 394.8280, val_loss: 396.5834, val_MinusLogProbMetric: 396.5834

Epoch 235: val_loss did not improve from 396.11087
196/196 - 11s - loss: 394.8280 - MinusLogProbMetric: 394.8280 - val_loss: 396.5834 - val_MinusLogProbMetric: 396.5834 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 236/1000
2023-09-10 08:13:40.515 
Epoch 236/1000 
	 loss: 394.7294, MinusLogProbMetric: 394.7294, val_loss: 396.3417, val_MinusLogProbMetric: 396.3417

Epoch 236: val_loss did not improve from 396.11087
196/196 - 9s - loss: 394.7294 - MinusLogProbMetric: 394.7294 - val_loss: 396.3417 - val_MinusLogProbMetric: 396.3417 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 237/1000
2023-09-10 08:13:46.962 
Epoch 237/1000 
	 loss: 394.7797, MinusLogProbMetric: 394.7797, val_loss: 396.1483, val_MinusLogProbMetric: 396.1483

Epoch 237: val_loss did not improve from 396.11087
196/196 - 6s - loss: 394.7797 - MinusLogProbMetric: 394.7797 - val_loss: 396.1483 - val_MinusLogProbMetric: 396.1483 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 238/1000
2023-09-10 08:13:55.503 
Epoch 238/1000 
	 loss: 394.9684, MinusLogProbMetric: 394.9684, val_loss: 396.2073, val_MinusLogProbMetric: 396.2073

Epoch 238: val_loss did not improve from 396.11087
196/196 - 9s - loss: 394.9684 - MinusLogProbMetric: 394.9684 - val_loss: 396.2073 - val_MinusLogProbMetric: 396.2073 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 239/1000
2023-09-10 08:14:01.987 
Epoch 239/1000 
	 loss: 394.7746, MinusLogProbMetric: 394.7746, val_loss: 396.4179, val_MinusLogProbMetric: 396.4179

Epoch 239: val_loss did not improve from 396.11087
196/196 - 6s - loss: 394.7746 - MinusLogProbMetric: 394.7746 - val_loss: 396.4179 - val_MinusLogProbMetric: 396.4179 - lr: 1.6667e-04 - 6s/epoch - 33ms/step
Epoch 240/1000
2023-09-10 08:14:09.869 
Epoch 240/1000 
	 loss: 394.8648, MinusLogProbMetric: 394.8648, val_loss: 396.9363, val_MinusLogProbMetric: 396.9363

Epoch 240: val_loss did not improve from 396.11087
196/196 - 8s - loss: 394.8648 - MinusLogProbMetric: 394.8648 - val_loss: 396.9363 - val_MinusLogProbMetric: 396.9363 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 241/1000
2023-09-10 08:14:17.037 
Epoch 241/1000 
	 loss: 394.7708, MinusLogProbMetric: 394.7708, val_loss: 396.7490, val_MinusLogProbMetric: 396.7490

Epoch 241: val_loss did not improve from 396.11087
196/196 - 7s - loss: 394.7708 - MinusLogProbMetric: 394.7708 - val_loss: 396.7490 - val_MinusLogProbMetric: 396.7490 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 242/1000
2023-09-10 08:14:25.589 
Epoch 242/1000 
	 loss: 394.7405, MinusLogProbMetric: 394.7405, val_loss: 396.6610, val_MinusLogProbMetric: 396.6610

Epoch 242: val_loss did not improve from 396.11087
196/196 - 9s - loss: 394.7405 - MinusLogProbMetric: 394.7405 - val_loss: 396.6610 - val_MinusLogProbMetric: 396.6610 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 243/1000
2023-09-10 08:14:33.187 
Epoch 243/1000 
	 loss: 394.7075, MinusLogProbMetric: 394.7075, val_loss: 396.1169, val_MinusLogProbMetric: 396.1169

Epoch 243: val_loss did not improve from 396.11087
196/196 - 8s - loss: 394.7075 - MinusLogProbMetric: 394.7075 - val_loss: 396.1169 - val_MinusLogProbMetric: 396.1169 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 244/1000
2023-09-10 08:14:42.816 
Epoch 244/1000 
	 loss: 394.7481, MinusLogProbMetric: 394.7481, val_loss: 396.2764, val_MinusLogProbMetric: 396.2764

Epoch 244: val_loss did not improve from 396.11087
196/196 - 10s - loss: 394.7481 - MinusLogProbMetric: 394.7481 - val_loss: 396.2764 - val_MinusLogProbMetric: 396.2764 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 245/1000
2023-09-10 08:14:49.796 
Epoch 245/1000 
	 loss: 394.6244, MinusLogProbMetric: 394.6244, val_loss: 396.1806, val_MinusLogProbMetric: 396.1806

Epoch 245: val_loss did not improve from 396.11087
196/196 - 7s - loss: 394.6244 - MinusLogProbMetric: 394.6244 - val_loss: 396.1806 - val_MinusLogProbMetric: 396.1806 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 246/1000
2023-09-10 08:14:57.365 
Epoch 246/1000 
	 loss: 394.7761, MinusLogProbMetric: 394.7761, val_loss: 396.4212, val_MinusLogProbMetric: 396.4212

Epoch 246: val_loss did not improve from 396.11087
196/196 - 8s - loss: 394.7761 - MinusLogProbMetric: 394.7761 - val_loss: 396.4212 - val_MinusLogProbMetric: 396.4212 - lr: 1.6667e-04 - 8s/epoch - 38ms/step
Epoch 247/1000
2023-09-10 08:15:04.816 
Epoch 247/1000 
	 loss: 394.7232, MinusLogProbMetric: 394.7232, val_loss: 396.3500, val_MinusLogProbMetric: 396.3500

Epoch 247: val_loss did not improve from 396.11087
196/196 - 7s - loss: 394.7232 - MinusLogProbMetric: 394.7232 - val_loss: 396.3500 - val_MinusLogProbMetric: 396.3500 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 248/1000
2023-09-10 08:15:14.974 
Epoch 248/1000 
	 loss: 394.5000, MinusLogProbMetric: 394.5000, val_loss: 396.1056, val_MinusLogProbMetric: 396.1056

Epoch 248: val_loss improved from 396.11087 to 396.10562, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 394.5000 - MinusLogProbMetric: 394.5000 - val_loss: 396.1056 - val_MinusLogProbMetric: 396.1056 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 249/1000
2023-09-10 08:15:22.586 
Epoch 249/1000 
	 loss: 394.7939, MinusLogProbMetric: 394.7939, val_loss: 396.1461, val_MinusLogProbMetric: 396.1461

Epoch 249: val_loss did not improve from 396.10562
196/196 - 7s - loss: 394.7939 - MinusLogProbMetric: 394.7939 - val_loss: 396.1461 - val_MinusLogProbMetric: 396.1461 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 250/1000
2023-09-10 08:15:31.505 
Epoch 250/1000 
	 loss: 394.5351, MinusLogProbMetric: 394.5351, val_loss: 396.7930, val_MinusLogProbMetric: 396.7930

Epoch 250: val_loss did not improve from 396.10562
196/196 - 9s - loss: 394.5351 - MinusLogProbMetric: 394.5351 - val_loss: 396.7930 - val_MinusLogProbMetric: 396.7930 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 251/1000
2023-09-10 08:15:38.612 
Epoch 251/1000 
	 loss: 394.5916, MinusLogProbMetric: 394.5916, val_loss: 396.6691, val_MinusLogProbMetric: 396.6691

Epoch 251: val_loss did not improve from 396.10562
196/196 - 7s - loss: 394.5916 - MinusLogProbMetric: 394.5916 - val_loss: 396.6691 - val_MinusLogProbMetric: 396.6691 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 252/1000
2023-09-10 08:15:46.139 
Epoch 252/1000 
	 loss: 394.5627, MinusLogProbMetric: 394.5627, val_loss: 395.9260, val_MinusLogProbMetric: 395.9260

Epoch 252: val_loss improved from 396.10562 to 395.92599, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 394.5627 - MinusLogProbMetric: 394.5627 - val_loss: 395.9260 - val_MinusLogProbMetric: 395.9260 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 253/1000
2023-09-10 08:15:55.668 
Epoch 253/1000 
	 loss: 394.5279, MinusLogProbMetric: 394.5279, val_loss: 396.4768, val_MinusLogProbMetric: 396.4768

Epoch 253: val_loss did not improve from 395.92599
196/196 - 9s - loss: 394.5279 - MinusLogProbMetric: 394.5279 - val_loss: 396.4768 - val_MinusLogProbMetric: 396.4768 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 254/1000
2023-09-10 08:16:02.705 
Epoch 254/1000 
	 loss: 394.5774, MinusLogProbMetric: 394.5774, val_loss: 395.5797, val_MinusLogProbMetric: 395.5797

Epoch 254: val_loss improved from 395.92599 to 395.57974, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 394.5774 - MinusLogProbMetric: 394.5774 - val_loss: 395.5797 - val_MinusLogProbMetric: 395.5797 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 255/1000
2023-09-10 08:16:11.306 
Epoch 255/1000 
	 loss: 394.5766, MinusLogProbMetric: 394.5766, val_loss: 396.1895, val_MinusLogProbMetric: 396.1895

Epoch 255: val_loss did not improve from 395.57974
196/196 - 8s - loss: 394.5766 - MinusLogProbMetric: 394.5766 - val_loss: 396.1895 - val_MinusLogProbMetric: 396.1895 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 256/1000
2023-09-10 08:16:19.189 
Epoch 256/1000 
	 loss: 394.5938, MinusLogProbMetric: 394.5938, val_loss: 395.9990, val_MinusLogProbMetric: 395.9990

Epoch 256: val_loss did not improve from 395.57974
196/196 - 8s - loss: 394.5938 - MinusLogProbMetric: 394.5938 - val_loss: 395.9990 - val_MinusLogProbMetric: 395.9990 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 257/1000
2023-09-10 08:16:27.361 
Epoch 257/1000 
	 loss: 394.4248, MinusLogProbMetric: 394.4248, val_loss: 395.8330, val_MinusLogProbMetric: 395.8330

Epoch 257: val_loss did not improve from 395.57974
196/196 - 8s - loss: 394.4248 - MinusLogProbMetric: 394.4248 - val_loss: 395.8330 - val_MinusLogProbMetric: 395.8330 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 258/1000
2023-09-10 08:16:35.598 
Epoch 258/1000 
	 loss: 394.4120, MinusLogProbMetric: 394.4120, val_loss: 395.9969, val_MinusLogProbMetric: 395.9969

Epoch 258: val_loss did not improve from 395.57974
196/196 - 8s - loss: 394.4120 - MinusLogProbMetric: 394.4120 - val_loss: 395.9969 - val_MinusLogProbMetric: 395.9969 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 259/1000
2023-09-10 08:16:45.290 
Epoch 259/1000 
	 loss: 394.4260, MinusLogProbMetric: 394.4260, val_loss: 395.8695, val_MinusLogProbMetric: 395.8695

Epoch 259: val_loss did not improve from 395.57974
196/196 - 10s - loss: 394.4260 - MinusLogProbMetric: 394.4260 - val_loss: 395.8695 - val_MinusLogProbMetric: 395.8695 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 260/1000
2023-09-10 08:16:52.782 
Epoch 260/1000 
	 loss: 394.4761, MinusLogProbMetric: 394.4761, val_loss: 395.6586, val_MinusLogProbMetric: 395.6586

Epoch 260: val_loss did not improve from 395.57974
196/196 - 7s - loss: 394.4761 - MinusLogProbMetric: 394.4761 - val_loss: 395.6586 - val_MinusLogProbMetric: 395.6586 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 261/1000
2023-09-10 08:17:02.731 
Epoch 261/1000 
	 loss: 394.4188, MinusLogProbMetric: 394.4188, val_loss: 398.1696, val_MinusLogProbMetric: 398.1696

Epoch 261: val_loss did not improve from 395.57974
196/196 - 10s - loss: 394.4188 - MinusLogProbMetric: 394.4188 - val_loss: 398.1696 - val_MinusLogProbMetric: 398.1696 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 262/1000
2023-09-10 08:17:10.489 
Epoch 262/1000 
	 loss: 394.6016, MinusLogProbMetric: 394.6016, val_loss: 395.8911, val_MinusLogProbMetric: 395.8911

Epoch 262: val_loss did not improve from 395.57974
196/196 - 8s - loss: 394.6016 - MinusLogProbMetric: 394.6016 - val_loss: 395.8911 - val_MinusLogProbMetric: 395.8911 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 263/1000
2023-09-10 08:17:19.228 
Epoch 263/1000 
	 loss: 394.5322, MinusLogProbMetric: 394.5322, val_loss: 396.0180, val_MinusLogProbMetric: 396.0180

Epoch 263: val_loss did not improve from 395.57974
196/196 - 9s - loss: 394.5322 - MinusLogProbMetric: 394.5322 - val_loss: 396.0180 - val_MinusLogProbMetric: 396.0180 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 264/1000
2023-09-10 08:17:29.989 
Epoch 264/1000 
	 loss: 394.4057, MinusLogProbMetric: 394.4057, val_loss: 396.1976, val_MinusLogProbMetric: 396.1976

Epoch 264: val_loss did not improve from 395.57974
196/196 - 11s - loss: 394.4057 - MinusLogProbMetric: 394.4057 - val_loss: 396.1976 - val_MinusLogProbMetric: 396.1976 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 265/1000
2023-09-10 08:17:38.238 
Epoch 265/1000 
	 loss: 394.3712, MinusLogProbMetric: 394.3712, val_loss: 396.0261, val_MinusLogProbMetric: 396.0261

Epoch 265: val_loss did not improve from 395.57974
196/196 - 8s - loss: 394.3712 - MinusLogProbMetric: 394.3712 - val_loss: 396.0261 - val_MinusLogProbMetric: 396.0261 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 266/1000
2023-09-10 08:17:47.042 
Epoch 266/1000 
	 loss: 394.4893, MinusLogProbMetric: 394.4893, val_loss: 395.5346, val_MinusLogProbMetric: 395.5346

Epoch 266: val_loss improved from 395.57974 to 395.53458, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 394.4893 - MinusLogProbMetric: 394.4893 - val_loss: 395.5346 - val_MinusLogProbMetric: 395.5346 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 267/1000
2023-09-10 08:17:59.178 
Epoch 267/1000 
	 loss: 394.3921, MinusLogProbMetric: 394.3921, val_loss: 395.6364, val_MinusLogProbMetric: 395.6364

Epoch 267: val_loss did not improve from 395.53458
196/196 - 12s - loss: 394.3921 - MinusLogProbMetric: 394.3921 - val_loss: 395.6364 - val_MinusLogProbMetric: 395.6364 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 268/1000
2023-09-10 08:18:10.349 
Epoch 268/1000 
	 loss: 394.4185, MinusLogProbMetric: 394.4185, val_loss: 395.6242, val_MinusLogProbMetric: 395.6242

Epoch 268: val_loss did not improve from 395.53458
196/196 - 11s - loss: 394.4185 - MinusLogProbMetric: 394.4185 - val_loss: 395.6242 - val_MinusLogProbMetric: 395.6242 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 269/1000
2023-09-10 08:18:20.648 
Epoch 269/1000 
	 loss: 394.2632, MinusLogProbMetric: 394.2632, val_loss: 395.4814, val_MinusLogProbMetric: 395.4814

Epoch 269: val_loss improved from 395.53458 to 395.48135, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 394.2632 - MinusLogProbMetric: 394.2632 - val_loss: 395.4814 - val_MinusLogProbMetric: 395.4814 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 270/1000
2023-09-10 08:18:33.629 
Epoch 270/1000 
	 loss: 394.2505, MinusLogProbMetric: 394.2505, val_loss: 395.9030, val_MinusLogProbMetric: 395.9030

Epoch 270: val_loss did not improve from 395.48135
196/196 - 13s - loss: 394.2505 - MinusLogProbMetric: 394.2505 - val_loss: 395.9030 - val_MinusLogProbMetric: 395.9030 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 271/1000
2023-09-10 08:18:44.726 
Epoch 271/1000 
	 loss: 394.3966, MinusLogProbMetric: 394.3966, val_loss: 395.9686, val_MinusLogProbMetric: 395.9686

Epoch 271: val_loss did not improve from 395.48135
196/196 - 11s - loss: 394.3966 - MinusLogProbMetric: 394.3966 - val_loss: 395.9686 - val_MinusLogProbMetric: 395.9686 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 272/1000
2023-09-10 08:18:54.507 
Epoch 272/1000 
	 loss: 394.1613, MinusLogProbMetric: 394.1613, val_loss: 395.4967, val_MinusLogProbMetric: 395.4967

Epoch 272: val_loss did not improve from 395.48135
196/196 - 10s - loss: 394.1613 - MinusLogProbMetric: 394.1613 - val_loss: 395.4967 - val_MinusLogProbMetric: 395.4967 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 273/1000
2023-09-10 08:19:06.806 
Epoch 273/1000 
	 loss: 394.2553, MinusLogProbMetric: 394.2553, val_loss: 395.5699, val_MinusLogProbMetric: 395.5699

Epoch 273: val_loss did not improve from 395.48135
196/196 - 12s - loss: 394.2553 - MinusLogProbMetric: 394.2553 - val_loss: 395.5699 - val_MinusLogProbMetric: 395.5699 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 274/1000
2023-09-10 08:19:17.970 
Epoch 274/1000 
	 loss: 394.1958, MinusLogProbMetric: 394.1958, val_loss: 395.5869, val_MinusLogProbMetric: 395.5869

Epoch 274: val_loss did not improve from 395.48135
196/196 - 11s - loss: 394.1958 - MinusLogProbMetric: 394.1958 - val_loss: 395.5869 - val_MinusLogProbMetric: 395.5869 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 275/1000
2023-09-10 08:19:29.181 
Epoch 275/1000 
	 loss: 394.1154, MinusLogProbMetric: 394.1154, val_loss: 395.8940, val_MinusLogProbMetric: 395.8940

Epoch 275: val_loss did not improve from 395.48135
196/196 - 11s - loss: 394.1154 - MinusLogProbMetric: 394.1154 - val_loss: 395.8940 - val_MinusLogProbMetric: 395.8940 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 276/1000
2023-09-10 08:19:41.468 
Epoch 276/1000 
	 loss: 394.1680, MinusLogProbMetric: 394.1680, val_loss: 395.6176, val_MinusLogProbMetric: 395.6176

Epoch 276: val_loss did not improve from 395.48135
196/196 - 12s - loss: 394.1680 - MinusLogProbMetric: 394.1680 - val_loss: 395.6176 - val_MinusLogProbMetric: 395.6176 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 277/1000
2023-09-10 08:19:51.354 
Epoch 277/1000 
	 loss: 394.1677, MinusLogProbMetric: 394.1677, val_loss: 396.0172, val_MinusLogProbMetric: 396.0172

Epoch 277: val_loss did not improve from 395.48135
196/196 - 10s - loss: 394.1677 - MinusLogProbMetric: 394.1677 - val_loss: 396.0172 - val_MinusLogProbMetric: 396.0172 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 278/1000
2023-09-10 08:20:02.107 
Epoch 278/1000 
	 loss: 394.0663, MinusLogProbMetric: 394.0663, val_loss: 395.7294, val_MinusLogProbMetric: 395.7294

Epoch 278: val_loss did not improve from 395.48135
196/196 - 11s - loss: 394.0663 - MinusLogProbMetric: 394.0663 - val_loss: 395.7294 - val_MinusLogProbMetric: 395.7294 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 279/1000
2023-09-10 08:20:13.666 
Epoch 279/1000 
	 loss: 394.1862, MinusLogProbMetric: 394.1862, val_loss: 396.1331, val_MinusLogProbMetric: 396.1331

Epoch 279: val_loss did not improve from 395.48135
196/196 - 12s - loss: 394.1862 - MinusLogProbMetric: 394.1862 - val_loss: 396.1331 - val_MinusLogProbMetric: 396.1331 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 280/1000
2023-09-10 08:20:25.524 
Epoch 280/1000 
	 loss: 394.2410, MinusLogProbMetric: 394.2410, val_loss: 397.9997, val_MinusLogProbMetric: 397.9997

Epoch 280: val_loss did not improve from 395.48135
196/196 - 12s - loss: 394.2410 - MinusLogProbMetric: 394.2410 - val_loss: 397.9997 - val_MinusLogProbMetric: 397.9997 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 281/1000
2023-09-10 08:20:37.210 
Epoch 281/1000 
	 loss: 394.1579, MinusLogProbMetric: 394.1579, val_loss: 395.5872, val_MinusLogProbMetric: 395.5872

Epoch 281: val_loss did not improve from 395.48135
196/196 - 12s - loss: 394.1579 - MinusLogProbMetric: 394.1579 - val_loss: 395.5872 - val_MinusLogProbMetric: 395.5872 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 282/1000
2023-09-10 08:20:49.429 
Epoch 282/1000 
	 loss: 393.9723, MinusLogProbMetric: 393.9723, val_loss: 395.7044, val_MinusLogProbMetric: 395.7044

Epoch 282: val_loss did not improve from 395.48135
196/196 - 12s - loss: 393.9723 - MinusLogProbMetric: 393.9723 - val_loss: 395.7044 - val_MinusLogProbMetric: 395.7044 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 283/1000
2023-09-10 08:20:59.070 
Epoch 283/1000 
	 loss: 394.0184, MinusLogProbMetric: 394.0184, val_loss: 395.1539, val_MinusLogProbMetric: 395.1539

Epoch 283: val_loss improved from 395.48135 to 395.15393, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 394.0184 - MinusLogProbMetric: 394.0184 - val_loss: 395.1539 - val_MinusLogProbMetric: 395.1539 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 284/1000
2023-09-10 08:21:07.797 
Epoch 284/1000 
	 loss: 393.9956, MinusLogProbMetric: 393.9956, val_loss: 395.7164, val_MinusLogProbMetric: 395.7164

Epoch 284: val_loss did not improve from 395.15393
196/196 - 8s - loss: 393.9956 - MinusLogProbMetric: 393.9956 - val_loss: 395.7164 - val_MinusLogProbMetric: 395.7164 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 285/1000
2023-09-10 08:21:17.827 
Epoch 285/1000 
	 loss: 394.0255, MinusLogProbMetric: 394.0255, val_loss: 395.4625, val_MinusLogProbMetric: 395.4625

Epoch 285: val_loss did not improve from 395.15393
196/196 - 10s - loss: 394.0255 - MinusLogProbMetric: 394.0255 - val_loss: 395.4625 - val_MinusLogProbMetric: 395.4625 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 286/1000
2023-09-10 08:21:26.389 
Epoch 286/1000 
	 loss: 393.9755, MinusLogProbMetric: 393.9755, val_loss: 396.5151, val_MinusLogProbMetric: 396.5151

Epoch 286: val_loss did not improve from 395.15393
196/196 - 9s - loss: 393.9755 - MinusLogProbMetric: 393.9755 - val_loss: 396.5151 - val_MinusLogProbMetric: 396.5151 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 287/1000
2023-09-10 08:21:35.122 
Epoch 287/1000 
	 loss: 394.0320, MinusLogProbMetric: 394.0320, val_loss: 395.4187, val_MinusLogProbMetric: 395.4187

Epoch 287: val_loss did not improve from 395.15393
196/196 - 9s - loss: 394.0320 - MinusLogProbMetric: 394.0320 - val_loss: 395.4187 - val_MinusLogProbMetric: 395.4187 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 288/1000
2023-09-10 08:21:42.914 
Epoch 288/1000 
	 loss: 394.2206, MinusLogProbMetric: 394.2206, val_loss: 395.5332, val_MinusLogProbMetric: 395.5332

Epoch 288: val_loss did not improve from 395.15393
196/196 - 8s - loss: 394.2206 - MinusLogProbMetric: 394.2206 - val_loss: 395.5332 - val_MinusLogProbMetric: 395.5332 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 289/1000
2023-09-10 08:21:55.220 
Epoch 289/1000 
	 loss: 393.8489, MinusLogProbMetric: 393.8489, val_loss: 395.4580, val_MinusLogProbMetric: 395.4580

Epoch 289: val_loss did not improve from 395.15393
196/196 - 12s - loss: 393.8489 - MinusLogProbMetric: 393.8489 - val_loss: 395.4580 - val_MinusLogProbMetric: 395.4580 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 290/1000
2023-09-10 08:22:05.810 
Epoch 290/1000 
	 loss: 394.1125, MinusLogProbMetric: 394.1125, val_loss: 395.0588, val_MinusLogProbMetric: 395.0588

Epoch 290: val_loss improved from 395.15393 to 395.05878, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 394.1125 - MinusLogProbMetric: 394.1125 - val_loss: 395.0588 - val_MinusLogProbMetric: 395.0588 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 291/1000
2023-09-10 08:22:16.312 
Epoch 291/1000 
	 loss: 393.9981, MinusLogProbMetric: 393.9981, val_loss: 395.4893, val_MinusLogProbMetric: 395.4893

Epoch 291: val_loss did not improve from 395.05878
196/196 - 10s - loss: 393.9981 - MinusLogProbMetric: 393.9981 - val_loss: 395.4893 - val_MinusLogProbMetric: 395.4893 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 292/1000
2023-09-10 08:22:27.702 
Epoch 292/1000 
	 loss: 393.9521, MinusLogProbMetric: 393.9521, val_loss: 395.7306, val_MinusLogProbMetric: 395.7306

Epoch 292: val_loss did not improve from 395.05878
196/196 - 11s - loss: 393.9521 - MinusLogProbMetric: 393.9521 - val_loss: 395.7306 - val_MinusLogProbMetric: 395.7306 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 293/1000
2023-09-10 08:22:38.214 
Epoch 293/1000 
	 loss: 393.8274, MinusLogProbMetric: 393.8274, val_loss: 395.8562, val_MinusLogProbMetric: 395.8562

Epoch 293: val_loss did not improve from 395.05878
196/196 - 11s - loss: 393.8274 - MinusLogProbMetric: 393.8274 - val_loss: 395.8562 - val_MinusLogProbMetric: 395.8562 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 294/1000
2023-09-10 08:22:49.365 
Epoch 294/1000 
	 loss: 393.8440, MinusLogProbMetric: 393.8440, val_loss: 395.3957, val_MinusLogProbMetric: 395.3957

Epoch 294: val_loss did not improve from 395.05878
196/196 - 11s - loss: 393.8440 - MinusLogProbMetric: 393.8440 - val_loss: 395.3957 - val_MinusLogProbMetric: 395.3957 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 295/1000
2023-09-10 08:22:58.367 
Epoch 295/1000 
	 loss: 393.9671, MinusLogProbMetric: 393.9671, val_loss: 395.0881, val_MinusLogProbMetric: 395.0881

Epoch 295: val_loss did not improve from 395.05878
196/196 - 9s - loss: 393.9671 - MinusLogProbMetric: 393.9671 - val_loss: 395.0881 - val_MinusLogProbMetric: 395.0881 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 296/1000
2023-09-10 08:23:08.571 
Epoch 296/1000 
	 loss: 393.9516, MinusLogProbMetric: 393.9516, val_loss: 395.2459, val_MinusLogProbMetric: 395.2459

Epoch 296: val_loss did not improve from 395.05878
196/196 - 10s - loss: 393.9516 - MinusLogProbMetric: 393.9516 - val_loss: 395.2459 - val_MinusLogProbMetric: 395.2459 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 297/1000
2023-09-10 08:23:18.642 
Epoch 297/1000 
	 loss: 393.8732, MinusLogProbMetric: 393.8732, val_loss: 395.4075, val_MinusLogProbMetric: 395.4075

Epoch 297: val_loss did not improve from 395.05878
196/196 - 10s - loss: 393.8732 - MinusLogProbMetric: 393.8732 - val_loss: 395.4075 - val_MinusLogProbMetric: 395.4075 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 298/1000
2023-09-10 08:23:29.370 
Epoch 298/1000 
	 loss: 393.8544, MinusLogProbMetric: 393.8544, val_loss: 395.4980, val_MinusLogProbMetric: 395.4980

Epoch 298: val_loss did not improve from 395.05878
196/196 - 11s - loss: 393.8544 - MinusLogProbMetric: 393.8544 - val_loss: 395.4980 - val_MinusLogProbMetric: 395.4980 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 299/1000
2023-09-10 08:23:40.385 
Epoch 299/1000 
	 loss: 393.6868, MinusLogProbMetric: 393.6868, val_loss: 396.8535, val_MinusLogProbMetric: 396.8535

Epoch 299: val_loss did not improve from 395.05878
196/196 - 11s - loss: 393.6868 - MinusLogProbMetric: 393.6868 - val_loss: 396.8535 - val_MinusLogProbMetric: 396.8535 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 300/1000
2023-09-10 08:23:51.609 
Epoch 300/1000 
	 loss: 394.0926, MinusLogProbMetric: 394.0926, val_loss: 396.5334, val_MinusLogProbMetric: 396.5334

Epoch 300: val_loss did not improve from 395.05878
196/196 - 11s - loss: 394.0926 - MinusLogProbMetric: 394.0926 - val_loss: 396.5334 - val_MinusLogProbMetric: 396.5334 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 301/1000
2023-09-10 08:24:03.584 
Epoch 301/1000 
	 loss: 393.8808, MinusLogProbMetric: 393.8808, val_loss: 395.4472, val_MinusLogProbMetric: 395.4472

Epoch 301: val_loss did not improve from 395.05878
196/196 - 12s - loss: 393.8808 - MinusLogProbMetric: 393.8808 - val_loss: 395.4472 - val_MinusLogProbMetric: 395.4472 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 302/1000
2023-09-10 08:24:14.486 
Epoch 302/1000 
	 loss: 393.8995, MinusLogProbMetric: 393.8995, val_loss: 395.2547, val_MinusLogProbMetric: 395.2547

Epoch 302: val_loss did not improve from 395.05878
196/196 - 11s - loss: 393.8995 - MinusLogProbMetric: 393.8995 - val_loss: 395.2547 - val_MinusLogProbMetric: 395.2547 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 303/1000
2023-09-10 08:24:24.815 
Epoch 303/1000 
	 loss: 393.8126, MinusLogProbMetric: 393.8126, val_loss: 396.5440, val_MinusLogProbMetric: 396.5440

Epoch 303: val_loss did not improve from 395.05878
196/196 - 10s - loss: 393.8126 - MinusLogProbMetric: 393.8126 - val_loss: 396.5440 - val_MinusLogProbMetric: 396.5440 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 304/1000
2023-09-10 08:24:34.738 
Epoch 304/1000 
	 loss: 393.6946, MinusLogProbMetric: 393.6946, val_loss: 394.8403, val_MinusLogProbMetric: 394.8403

Epoch 304: val_loss improved from 395.05878 to 394.84027, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 393.6946 - MinusLogProbMetric: 393.6946 - val_loss: 394.8403 - val_MinusLogProbMetric: 394.8403 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 305/1000
2023-09-10 08:24:46.004 
Epoch 305/1000 
	 loss: 393.8256, MinusLogProbMetric: 393.8256, val_loss: 395.1493, val_MinusLogProbMetric: 395.1493

Epoch 305: val_loss did not improve from 394.84027
196/196 - 11s - loss: 393.8256 - MinusLogProbMetric: 393.8256 - val_loss: 395.1493 - val_MinusLogProbMetric: 395.1493 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 306/1000
2023-09-10 08:24:56.883 
Epoch 306/1000 
	 loss: 393.8310, MinusLogProbMetric: 393.8310, val_loss: 395.1964, val_MinusLogProbMetric: 395.1964

Epoch 306: val_loss did not improve from 394.84027
196/196 - 11s - loss: 393.8310 - MinusLogProbMetric: 393.8310 - val_loss: 395.1964 - val_MinusLogProbMetric: 395.1964 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 307/1000
2023-09-10 08:25:06.282 
Epoch 307/1000 
	 loss: 393.6335, MinusLogProbMetric: 393.6335, val_loss: 395.6710, val_MinusLogProbMetric: 395.6710

Epoch 307: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.6335 - MinusLogProbMetric: 393.6335 - val_loss: 395.6710 - val_MinusLogProbMetric: 395.6710 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 308/1000
2023-09-10 08:25:17.229 
Epoch 308/1000 
	 loss: 393.8286, MinusLogProbMetric: 393.8286, val_loss: 395.7576, val_MinusLogProbMetric: 395.7576

Epoch 308: val_loss did not improve from 394.84027
196/196 - 11s - loss: 393.8286 - MinusLogProbMetric: 393.8286 - val_loss: 395.7576 - val_MinusLogProbMetric: 395.7576 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 309/1000
2023-09-10 08:25:29.029 
Epoch 309/1000 
	 loss: 393.8319, MinusLogProbMetric: 393.8319, val_loss: 395.1293, val_MinusLogProbMetric: 395.1293

Epoch 309: val_loss did not improve from 394.84027
196/196 - 12s - loss: 393.8319 - MinusLogProbMetric: 393.8319 - val_loss: 395.1293 - val_MinusLogProbMetric: 395.1293 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 310/1000
2023-09-10 08:25:40.143 
Epoch 310/1000 
	 loss: 393.5592, MinusLogProbMetric: 393.5592, val_loss: 395.0499, val_MinusLogProbMetric: 395.0499

Epoch 310: val_loss did not improve from 394.84027
196/196 - 11s - loss: 393.5592 - MinusLogProbMetric: 393.5592 - val_loss: 395.0499 - val_MinusLogProbMetric: 395.0499 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 311/1000
2023-09-10 08:25:52.042 
Epoch 311/1000 
	 loss: 393.7385, MinusLogProbMetric: 393.7385, val_loss: 394.9641, val_MinusLogProbMetric: 394.9641

Epoch 311: val_loss did not improve from 394.84027
196/196 - 12s - loss: 393.7385 - MinusLogProbMetric: 393.7385 - val_loss: 394.9641 - val_MinusLogProbMetric: 394.9641 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 312/1000
2023-09-10 08:26:01.817 
Epoch 312/1000 
	 loss: 393.7881, MinusLogProbMetric: 393.7881, val_loss: 395.0451, val_MinusLogProbMetric: 395.0451

Epoch 312: val_loss did not improve from 394.84027
196/196 - 10s - loss: 393.7881 - MinusLogProbMetric: 393.7881 - val_loss: 395.0451 - val_MinusLogProbMetric: 395.0451 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 313/1000
2023-09-10 08:26:10.007 
Epoch 313/1000 
	 loss: 393.6439, MinusLogProbMetric: 393.6439, val_loss: 395.3615, val_MinusLogProbMetric: 395.3615

Epoch 313: val_loss did not improve from 394.84027
196/196 - 8s - loss: 393.6439 - MinusLogProbMetric: 393.6439 - val_loss: 395.3615 - val_MinusLogProbMetric: 395.3615 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 314/1000
2023-09-10 08:26:20.146 
Epoch 314/1000 
	 loss: 393.5278, MinusLogProbMetric: 393.5278, val_loss: 395.0387, val_MinusLogProbMetric: 395.0387

Epoch 314: val_loss did not improve from 394.84027
196/196 - 10s - loss: 393.5278 - MinusLogProbMetric: 393.5278 - val_loss: 395.0387 - val_MinusLogProbMetric: 395.0387 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 315/1000
2023-09-10 08:26:28.625 
Epoch 315/1000 
	 loss: 393.5948, MinusLogProbMetric: 393.5948, val_loss: 396.3458, val_MinusLogProbMetric: 396.3458

Epoch 315: val_loss did not improve from 394.84027
196/196 - 8s - loss: 393.5948 - MinusLogProbMetric: 393.5948 - val_loss: 396.3458 - val_MinusLogProbMetric: 396.3458 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 316/1000
2023-09-10 08:26:37.235 
Epoch 316/1000 
	 loss: 393.6800, MinusLogProbMetric: 393.6800, val_loss: 395.0777, val_MinusLogProbMetric: 395.0777

Epoch 316: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.6800 - MinusLogProbMetric: 393.6800 - val_loss: 395.0777 - val_MinusLogProbMetric: 395.0777 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 317/1000
2023-09-10 08:26:45.563 
Epoch 317/1000 
	 loss: 393.5875, MinusLogProbMetric: 393.5875, val_loss: 395.7968, val_MinusLogProbMetric: 395.7968

Epoch 317: val_loss did not improve from 394.84027
196/196 - 8s - loss: 393.5875 - MinusLogProbMetric: 393.5875 - val_loss: 395.7968 - val_MinusLogProbMetric: 395.7968 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 318/1000
2023-09-10 08:26:55.025 
Epoch 318/1000 
	 loss: 393.6949, MinusLogProbMetric: 393.6949, val_loss: 395.1452, val_MinusLogProbMetric: 395.1452

Epoch 318: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.6949 - MinusLogProbMetric: 393.6949 - val_loss: 395.1452 - val_MinusLogProbMetric: 395.1452 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 319/1000
2023-09-10 08:27:04.101 
Epoch 319/1000 
	 loss: 393.5292, MinusLogProbMetric: 393.5292, val_loss: 395.0569, val_MinusLogProbMetric: 395.0569

Epoch 319: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.5292 - MinusLogProbMetric: 393.5292 - val_loss: 395.0569 - val_MinusLogProbMetric: 395.0569 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 320/1000
2023-09-10 08:27:12.141 
Epoch 320/1000 
	 loss: 393.6054, MinusLogProbMetric: 393.6054, val_loss: 395.1315, val_MinusLogProbMetric: 395.1315

Epoch 320: val_loss did not improve from 394.84027
196/196 - 8s - loss: 393.6054 - MinusLogProbMetric: 393.6054 - val_loss: 395.1315 - val_MinusLogProbMetric: 395.1315 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 321/1000
2023-09-10 08:27:20.265 
Epoch 321/1000 
	 loss: 393.7899, MinusLogProbMetric: 393.7899, val_loss: 395.3869, val_MinusLogProbMetric: 395.3869

Epoch 321: val_loss did not improve from 394.84027
196/196 - 8s - loss: 393.7899 - MinusLogProbMetric: 393.7899 - val_loss: 395.3869 - val_MinusLogProbMetric: 395.3869 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 322/1000
2023-09-10 08:27:27.923 
Epoch 322/1000 
	 loss: 393.6911, MinusLogProbMetric: 393.6911, val_loss: 397.1584, val_MinusLogProbMetric: 397.1584

Epoch 322: val_loss did not improve from 394.84027
196/196 - 8s - loss: 393.6911 - MinusLogProbMetric: 393.6911 - val_loss: 397.1584 - val_MinusLogProbMetric: 397.1584 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 323/1000
2023-09-10 08:27:35.419 
Epoch 323/1000 
	 loss: 393.5880, MinusLogProbMetric: 393.5880, val_loss: 395.0758, val_MinusLogProbMetric: 395.0758

Epoch 323: val_loss did not improve from 394.84027
196/196 - 7s - loss: 393.5880 - MinusLogProbMetric: 393.5880 - val_loss: 395.0758 - val_MinusLogProbMetric: 395.0758 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 324/1000
2023-09-10 08:27:46.287 
Epoch 324/1000 
	 loss: 393.5669, MinusLogProbMetric: 393.5669, val_loss: 395.3129, val_MinusLogProbMetric: 395.3129

Epoch 324: val_loss did not improve from 394.84027
196/196 - 11s - loss: 393.5669 - MinusLogProbMetric: 393.5669 - val_loss: 395.3129 - val_MinusLogProbMetric: 395.3129 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 325/1000
2023-09-10 08:27:55.040 
Epoch 325/1000 
	 loss: 393.7203, MinusLogProbMetric: 393.7203, val_loss: 395.2973, val_MinusLogProbMetric: 395.2973

Epoch 325: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.7203 - MinusLogProbMetric: 393.7203 - val_loss: 395.2973 - val_MinusLogProbMetric: 395.2973 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 326/1000
2023-09-10 08:28:05.975 
Epoch 326/1000 
	 loss: 393.8662, MinusLogProbMetric: 393.8662, val_loss: 395.2017, val_MinusLogProbMetric: 395.2017

Epoch 326: val_loss did not improve from 394.84027
196/196 - 11s - loss: 393.8662 - MinusLogProbMetric: 393.8662 - val_loss: 395.2017 - val_MinusLogProbMetric: 395.2017 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 327/1000
2023-09-10 08:28:13.845 
Epoch 327/1000 
	 loss: 393.4431, MinusLogProbMetric: 393.4431, val_loss: 395.5930, val_MinusLogProbMetric: 395.5930

Epoch 327: val_loss did not improve from 394.84027
196/196 - 8s - loss: 393.4431 - MinusLogProbMetric: 393.4431 - val_loss: 395.5930 - val_MinusLogProbMetric: 395.5930 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 328/1000
2023-09-10 08:28:25.145 
Epoch 328/1000 
	 loss: 393.6448, MinusLogProbMetric: 393.6448, val_loss: 395.1322, val_MinusLogProbMetric: 395.1322

Epoch 328: val_loss did not improve from 394.84027
196/196 - 11s - loss: 393.6448 - MinusLogProbMetric: 393.6448 - val_loss: 395.1322 - val_MinusLogProbMetric: 395.1322 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 329/1000
2023-09-10 08:28:34.477 
Epoch 329/1000 
	 loss: 393.6371, MinusLogProbMetric: 393.6371, val_loss: 395.3552, val_MinusLogProbMetric: 395.3552

Epoch 329: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.6371 - MinusLogProbMetric: 393.6371 - val_loss: 395.3552 - val_MinusLogProbMetric: 395.3552 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 330/1000
2023-09-10 08:28:43.249 
Epoch 330/1000 
	 loss: 393.5147, MinusLogProbMetric: 393.5147, val_loss: 395.6550, val_MinusLogProbMetric: 395.6550

Epoch 330: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.5147 - MinusLogProbMetric: 393.5147 - val_loss: 395.6550 - val_MinusLogProbMetric: 395.6550 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 331/1000
2023-09-10 08:28:52.996 
Epoch 331/1000 
	 loss: 393.3385, MinusLogProbMetric: 393.3385, val_loss: 394.8950, val_MinusLogProbMetric: 394.8950

Epoch 331: val_loss did not improve from 394.84027
196/196 - 10s - loss: 393.3385 - MinusLogProbMetric: 393.3385 - val_loss: 394.8950 - val_MinusLogProbMetric: 394.8950 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 332/1000
2023-09-10 08:29:02.897 
Epoch 332/1000 
	 loss: 393.3077, MinusLogProbMetric: 393.3077, val_loss: 395.0675, val_MinusLogProbMetric: 395.0675

Epoch 332: val_loss did not improve from 394.84027
196/196 - 10s - loss: 393.3077 - MinusLogProbMetric: 393.3077 - val_loss: 395.0675 - val_MinusLogProbMetric: 395.0675 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 333/1000
2023-09-10 08:29:11.667 
Epoch 333/1000 
	 loss: 393.4644, MinusLogProbMetric: 393.4644, val_loss: 394.9277, val_MinusLogProbMetric: 394.9277

Epoch 333: val_loss did not improve from 394.84027
196/196 - 9s - loss: 393.4644 - MinusLogProbMetric: 393.4644 - val_loss: 394.9277 - val_MinusLogProbMetric: 394.9277 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 334/1000
2023-09-10 08:29:20.352 
Epoch 334/1000 
	 loss: 393.3146, MinusLogProbMetric: 393.3146, val_loss: 394.6271, val_MinusLogProbMetric: 394.6271

Epoch 334: val_loss improved from 394.84027 to 394.62708, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 393.3146 - MinusLogProbMetric: 393.3146 - val_loss: 394.6271 - val_MinusLogProbMetric: 394.6271 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 335/1000
2023-09-10 08:29:31.264 
Epoch 335/1000 
	 loss: 393.4113, MinusLogProbMetric: 393.4113, val_loss: 394.6854, val_MinusLogProbMetric: 394.6854

Epoch 335: val_loss did not improve from 394.62708
196/196 - 9s - loss: 393.4113 - MinusLogProbMetric: 393.4113 - val_loss: 394.6854 - val_MinusLogProbMetric: 394.6854 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 336/1000
2023-09-10 08:29:41.629 
Epoch 336/1000 
	 loss: 393.5334, MinusLogProbMetric: 393.5334, val_loss: 394.9585, val_MinusLogProbMetric: 394.9585

Epoch 336: val_loss did not improve from 394.62708
196/196 - 10s - loss: 393.5334 - MinusLogProbMetric: 393.5334 - val_loss: 394.9585 - val_MinusLogProbMetric: 394.9585 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 337/1000
2023-09-10 08:29:51.357 
Epoch 337/1000 
	 loss: 393.3600, MinusLogProbMetric: 393.3600, val_loss: 394.7472, val_MinusLogProbMetric: 394.7472

Epoch 337: val_loss did not improve from 394.62708
196/196 - 10s - loss: 393.3600 - MinusLogProbMetric: 393.3600 - val_loss: 394.7472 - val_MinusLogProbMetric: 394.7472 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 338/1000
2023-09-10 08:30:00.908 
Epoch 338/1000 
	 loss: 393.4808, MinusLogProbMetric: 393.4808, val_loss: 394.6861, val_MinusLogProbMetric: 394.6861

Epoch 338: val_loss did not improve from 394.62708
196/196 - 10s - loss: 393.4808 - MinusLogProbMetric: 393.4808 - val_loss: 394.6861 - val_MinusLogProbMetric: 394.6861 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 339/1000
2023-09-10 08:30:09.850 
Epoch 339/1000 
	 loss: 393.3145, MinusLogProbMetric: 393.3145, val_loss: 395.3944, val_MinusLogProbMetric: 395.3944

Epoch 339: val_loss did not improve from 394.62708
196/196 - 9s - loss: 393.3145 - MinusLogProbMetric: 393.3145 - val_loss: 395.3944 - val_MinusLogProbMetric: 395.3944 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 340/1000
2023-09-10 08:30:18.576 
Epoch 340/1000 
	 loss: 393.2661, MinusLogProbMetric: 393.2661, val_loss: 395.1208, val_MinusLogProbMetric: 395.1208

Epoch 340: val_loss did not improve from 394.62708
196/196 - 9s - loss: 393.2661 - MinusLogProbMetric: 393.2661 - val_loss: 395.1208 - val_MinusLogProbMetric: 395.1208 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 341/1000
2023-09-10 08:30:26.918 
Epoch 341/1000 
	 loss: 393.3497, MinusLogProbMetric: 393.3497, val_loss: 394.7563, val_MinusLogProbMetric: 394.7563

Epoch 341: val_loss did not improve from 394.62708
196/196 - 8s - loss: 393.3497 - MinusLogProbMetric: 393.3497 - val_loss: 394.7563 - val_MinusLogProbMetric: 394.7563 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 342/1000
2023-09-10 08:30:36.877 
Epoch 342/1000 
	 loss: 393.2479, MinusLogProbMetric: 393.2479, val_loss: 394.8987, val_MinusLogProbMetric: 394.8987

Epoch 342: val_loss did not improve from 394.62708
196/196 - 10s - loss: 393.2479 - MinusLogProbMetric: 393.2479 - val_loss: 394.8987 - val_MinusLogProbMetric: 394.8987 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 343/1000
2023-09-10 08:30:43.706 
Epoch 343/1000 
	 loss: 393.3136, MinusLogProbMetric: 393.3136, val_loss: 395.3091, val_MinusLogProbMetric: 395.3091

Epoch 343: val_loss did not improve from 394.62708
196/196 - 7s - loss: 393.3136 - MinusLogProbMetric: 393.3136 - val_loss: 395.3091 - val_MinusLogProbMetric: 395.3091 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 344/1000
2023-09-10 08:30:52.820 
Epoch 344/1000 
	 loss: 393.4366, MinusLogProbMetric: 393.4366, val_loss: 394.7071, val_MinusLogProbMetric: 394.7071

Epoch 344: val_loss did not improve from 394.62708
196/196 - 9s - loss: 393.4366 - MinusLogProbMetric: 393.4366 - val_loss: 394.7071 - val_MinusLogProbMetric: 394.7071 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 345/1000
2023-09-10 08:30:59.752 
Epoch 345/1000 
	 loss: 393.2196, MinusLogProbMetric: 393.2196, val_loss: 394.4251, val_MinusLogProbMetric: 394.4251

Epoch 345: val_loss improved from 394.62708 to 394.42514, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 393.2196 - MinusLogProbMetric: 393.2196 - val_loss: 394.4251 - val_MinusLogProbMetric: 394.4251 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 346/1000
2023-09-10 08:31:08.382 
Epoch 346/1000 
	 loss: 393.3456, MinusLogProbMetric: 393.3456, val_loss: 395.2004, val_MinusLogProbMetric: 395.2004

Epoch 346: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.3456 - MinusLogProbMetric: 393.3456 - val_loss: 395.2004 - val_MinusLogProbMetric: 395.2004 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 347/1000
2023-09-10 08:31:16.855 
Epoch 347/1000 
	 loss: 393.1322, MinusLogProbMetric: 393.1322, val_loss: 394.6889, val_MinusLogProbMetric: 394.6889

Epoch 347: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.1322 - MinusLogProbMetric: 393.1322 - val_loss: 394.6889 - val_MinusLogProbMetric: 394.6889 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 348/1000
2023-09-10 08:31:23.476 
Epoch 348/1000 
	 loss: 393.2319, MinusLogProbMetric: 393.2319, val_loss: 394.4501, val_MinusLogProbMetric: 394.4501

Epoch 348: val_loss did not improve from 394.42514
196/196 - 7s - loss: 393.2319 - MinusLogProbMetric: 393.2319 - val_loss: 394.4501 - val_MinusLogProbMetric: 394.4501 - lr: 1.6667e-04 - 7s/epoch - 34ms/step
Epoch 349/1000
2023-09-10 08:31:31.581 
Epoch 349/1000 
	 loss: 393.3148, MinusLogProbMetric: 393.3148, val_loss: 395.3433, val_MinusLogProbMetric: 395.3433

Epoch 349: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.3148 - MinusLogProbMetric: 393.3148 - val_loss: 395.3433 - val_MinusLogProbMetric: 395.3433 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 350/1000
2023-09-10 08:31:39.479 
Epoch 350/1000 
	 loss: 393.2200, MinusLogProbMetric: 393.2200, val_loss: 395.0766, val_MinusLogProbMetric: 395.0766

Epoch 350: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.2200 - MinusLogProbMetric: 393.2200 - val_loss: 395.0766 - val_MinusLogProbMetric: 395.0766 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 351/1000
2023-09-10 08:31:46.359 
Epoch 351/1000 
	 loss: 393.2627, MinusLogProbMetric: 393.2627, val_loss: 394.9075, val_MinusLogProbMetric: 394.9075

Epoch 351: val_loss did not improve from 394.42514
196/196 - 7s - loss: 393.2627 - MinusLogProbMetric: 393.2627 - val_loss: 394.9075 - val_MinusLogProbMetric: 394.9075 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 352/1000
2023-09-10 08:31:54.728 
Epoch 352/1000 
	 loss: 393.2789, MinusLogProbMetric: 393.2789, val_loss: 394.6326, val_MinusLogProbMetric: 394.6326

Epoch 352: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.2789 - MinusLogProbMetric: 393.2789 - val_loss: 394.6326 - val_MinusLogProbMetric: 394.6326 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 353/1000
2023-09-10 08:32:01.749 
Epoch 353/1000 
	 loss: 393.1777, MinusLogProbMetric: 393.1777, val_loss: 394.8765, val_MinusLogProbMetric: 394.8765

Epoch 353: val_loss did not improve from 394.42514
196/196 - 7s - loss: 393.1777 - MinusLogProbMetric: 393.1777 - val_loss: 394.8765 - val_MinusLogProbMetric: 394.8765 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 354/1000
2023-09-10 08:32:09.181 
Epoch 354/1000 
	 loss: 393.1199, MinusLogProbMetric: 393.1199, val_loss: 394.6914, val_MinusLogProbMetric: 394.6914

Epoch 354: val_loss did not improve from 394.42514
196/196 - 7s - loss: 393.1199 - MinusLogProbMetric: 393.1199 - val_loss: 394.6914 - val_MinusLogProbMetric: 394.6914 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 355/1000
2023-09-10 08:32:17.528 
Epoch 355/1000 
	 loss: 393.2492, MinusLogProbMetric: 393.2492, val_loss: 396.0741, val_MinusLogProbMetric: 396.0741

Epoch 355: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.2492 - MinusLogProbMetric: 393.2492 - val_loss: 396.0741 - val_MinusLogProbMetric: 396.0741 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 356/1000
2023-09-10 08:32:27.289 
Epoch 356/1000 
	 loss: 393.4012, MinusLogProbMetric: 393.4012, val_loss: 394.7977, val_MinusLogProbMetric: 394.7977

Epoch 356: val_loss did not improve from 394.42514
196/196 - 10s - loss: 393.4012 - MinusLogProbMetric: 393.4012 - val_loss: 394.7977 - val_MinusLogProbMetric: 394.7977 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 357/1000
2023-09-10 08:32:35.425 
Epoch 357/1000 
	 loss: 393.1184, MinusLogProbMetric: 393.1184, val_loss: 395.0526, val_MinusLogProbMetric: 395.0526

Epoch 357: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.1184 - MinusLogProbMetric: 393.1184 - val_loss: 395.0526 - val_MinusLogProbMetric: 395.0526 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 358/1000
2023-09-10 08:32:44.806 
Epoch 358/1000 
	 loss: 393.1072, MinusLogProbMetric: 393.1072, val_loss: 394.6623, val_MinusLogProbMetric: 394.6623

Epoch 358: val_loss did not improve from 394.42514
196/196 - 9s - loss: 393.1072 - MinusLogProbMetric: 393.1072 - val_loss: 394.6623 - val_MinusLogProbMetric: 394.6623 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 359/1000
2023-09-10 08:32:51.908 
Epoch 359/1000 
	 loss: 393.0883, MinusLogProbMetric: 393.0883, val_loss: 394.9471, val_MinusLogProbMetric: 394.9471

Epoch 359: val_loss did not improve from 394.42514
196/196 - 7s - loss: 393.0883 - MinusLogProbMetric: 393.0883 - val_loss: 394.9471 - val_MinusLogProbMetric: 394.9471 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 360/1000
2023-09-10 08:33:00.519 
Epoch 360/1000 
	 loss: 393.1165, MinusLogProbMetric: 393.1165, val_loss: 395.0058, val_MinusLogProbMetric: 395.0058

Epoch 360: val_loss did not improve from 394.42514
196/196 - 9s - loss: 393.1165 - MinusLogProbMetric: 393.1165 - val_loss: 395.0058 - val_MinusLogProbMetric: 395.0058 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 361/1000
2023-09-10 08:33:09.496 
Epoch 361/1000 
	 loss: 393.0685, MinusLogProbMetric: 393.0685, val_loss: 395.3694, val_MinusLogProbMetric: 395.3694

Epoch 361: val_loss did not improve from 394.42514
196/196 - 9s - loss: 393.0685 - MinusLogProbMetric: 393.0685 - val_loss: 395.3694 - val_MinusLogProbMetric: 395.3694 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 362/1000
2023-09-10 08:33:18.730 
Epoch 362/1000 
	 loss: 393.1125, MinusLogProbMetric: 393.1125, val_loss: 394.6491, val_MinusLogProbMetric: 394.6491

Epoch 362: val_loss did not improve from 394.42514
196/196 - 9s - loss: 393.1125 - MinusLogProbMetric: 393.1125 - val_loss: 394.6491 - val_MinusLogProbMetric: 394.6491 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 363/1000
2023-09-10 08:33:26.427 
Epoch 363/1000 
	 loss: 393.1010, MinusLogProbMetric: 393.1010, val_loss: 394.8198, val_MinusLogProbMetric: 394.8198

Epoch 363: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.1010 - MinusLogProbMetric: 393.1010 - val_loss: 394.8198 - val_MinusLogProbMetric: 394.8198 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 364/1000
2023-09-10 08:33:35.379 
Epoch 364/1000 
	 loss: 393.1252, MinusLogProbMetric: 393.1252, val_loss: 395.2467, val_MinusLogProbMetric: 395.2467

Epoch 364: val_loss did not improve from 394.42514
196/196 - 9s - loss: 393.1252 - MinusLogProbMetric: 393.1252 - val_loss: 395.2467 - val_MinusLogProbMetric: 395.2467 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 365/1000
2023-09-10 08:33:42.646 
Epoch 365/1000 
	 loss: 393.1701, MinusLogProbMetric: 393.1701, val_loss: 394.7583, val_MinusLogProbMetric: 394.7583

Epoch 365: val_loss did not improve from 394.42514
196/196 - 7s - loss: 393.1701 - MinusLogProbMetric: 393.1701 - val_loss: 394.7583 - val_MinusLogProbMetric: 394.7583 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 366/1000
2023-09-10 08:33:50.442 
Epoch 366/1000 
	 loss: 393.1118, MinusLogProbMetric: 393.1118, val_loss: 394.5729, val_MinusLogProbMetric: 394.5729

Epoch 366: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.1118 - MinusLogProbMetric: 393.1118 - val_loss: 394.5729 - val_MinusLogProbMetric: 394.5729 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 367/1000
2023-09-10 08:33:57.872 
Epoch 367/1000 
	 loss: 393.0275, MinusLogProbMetric: 393.0275, val_loss: 395.3165, val_MinusLogProbMetric: 395.3165

Epoch 367: val_loss did not improve from 394.42514
196/196 - 7s - loss: 393.0275 - MinusLogProbMetric: 393.0275 - val_loss: 395.3165 - val_MinusLogProbMetric: 395.3165 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 368/1000
2023-09-10 08:34:06.586 
Epoch 368/1000 
	 loss: 393.2167, MinusLogProbMetric: 393.2167, val_loss: 394.9455, val_MinusLogProbMetric: 394.9455

Epoch 368: val_loss did not improve from 394.42514
196/196 - 9s - loss: 393.2167 - MinusLogProbMetric: 393.2167 - val_loss: 394.9455 - val_MinusLogProbMetric: 394.9455 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 369/1000
2023-09-10 08:34:14.175 
Epoch 369/1000 
	 loss: 393.0483, MinusLogProbMetric: 393.0483, val_loss: 394.6884, val_MinusLogProbMetric: 394.6884

Epoch 369: val_loss did not improve from 394.42514
196/196 - 8s - loss: 393.0483 - MinusLogProbMetric: 393.0483 - val_loss: 394.6884 - val_MinusLogProbMetric: 394.6884 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 370/1000
2023-09-10 08:34:23.772 
Epoch 370/1000 
	 loss: 393.0446, MinusLogProbMetric: 393.0446, val_loss: 394.9580, val_MinusLogProbMetric: 394.9580

Epoch 370: val_loss did not improve from 394.42514
196/196 - 10s - loss: 393.0446 - MinusLogProbMetric: 393.0446 - val_loss: 394.9580 - val_MinusLogProbMetric: 394.9580 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 371/1000
2023-09-10 08:34:31.993 
Epoch 371/1000 
	 loss: 392.9717, MinusLogProbMetric: 392.9717, val_loss: 394.6020, val_MinusLogProbMetric: 394.6020

Epoch 371: val_loss did not improve from 394.42514
196/196 - 8s - loss: 392.9717 - MinusLogProbMetric: 392.9717 - val_loss: 394.6020 - val_MinusLogProbMetric: 394.6020 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 372/1000
2023-09-10 08:34:40.885 
Epoch 372/1000 
	 loss: 393.1144, MinusLogProbMetric: 393.1144, val_loss: 394.8711, val_MinusLogProbMetric: 394.8711

Epoch 372: val_loss did not improve from 394.42514
196/196 - 9s - loss: 393.1144 - MinusLogProbMetric: 393.1144 - val_loss: 394.8711 - val_MinusLogProbMetric: 394.8711 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 373/1000
2023-09-10 08:34:49.051 
Epoch 373/1000 
	 loss: 392.9991, MinusLogProbMetric: 392.9991, val_loss: 394.6617, val_MinusLogProbMetric: 394.6617

Epoch 373: val_loss did not improve from 394.42514
196/196 - 8s - loss: 392.9991 - MinusLogProbMetric: 392.9991 - val_loss: 394.6617 - val_MinusLogProbMetric: 394.6617 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 374/1000
2023-09-10 08:34:57.570 
Epoch 374/1000 
	 loss: 392.9942, MinusLogProbMetric: 392.9942, val_loss: 394.5735, val_MinusLogProbMetric: 394.5735

Epoch 374: val_loss did not improve from 394.42514
196/196 - 9s - loss: 392.9942 - MinusLogProbMetric: 392.9942 - val_loss: 394.5735 - val_MinusLogProbMetric: 394.5735 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 375/1000
2023-09-10 08:35:06.909 
Epoch 375/1000 
	 loss: 392.9014, MinusLogProbMetric: 392.9014, val_loss: 394.2421, val_MinusLogProbMetric: 394.2421

Epoch 375: val_loss improved from 394.42514 to 394.24213, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 392.9014 - MinusLogProbMetric: 392.9014 - val_loss: 394.2421 - val_MinusLogProbMetric: 394.2421 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 376/1000
2023-09-10 08:35:15.338 
Epoch 376/1000 
	 loss: 393.2426, MinusLogProbMetric: 393.2426, val_loss: 394.3986, val_MinusLogProbMetric: 394.3986

Epoch 376: val_loss did not improve from 394.24213
196/196 - 8s - loss: 393.2426 - MinusLogProbMetric: 393.2426 - val_loss: 394.3986 - val_MinusLogProbMetric: 394.3986 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 377/1000
2023-09-10 08:35:23.923 
Epoch 377/1000 
	 loss: 392.8207, MinusLogProbMetric: 392.8207, val_loss: 394.1822, val_MinusLogProbMetric: 394.1822

Epoch 377: val_loss improved from 394.24213 to 394.18219, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 392.8207 - MinusLogProbMetric: 392.8207 - val_loss: 394.1822 - val_MinusLogProbMetric: 394.1822 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 378/1000
2023-09-10 08:35:34.561 
Epoch 378/1000 
	 loss: 392.8830, MinusLogProbMetric: 392.8830, val_loss: 394.5248, val_MinusLogProbMetric: 394.5248

Epoch 378: val_loss did not improve from 394.18219
196/196 - 10s - loss: 392.8830 - MinusLogProbMetric: 392.8830 - val_loss: 394.5248 - val_MinusLogProbMetric: 394.5248 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 379/1000
2023-09-10 08:35:41.899 
Epoch 379/1000 
	 loss: 393.0537, MinusLogProbMetric: 393.0537, val_loss: 395.7401, val_MinusLogProbMetric: 395.7401

Epoch 379: val_loss did not improve from 394.18219
196/196 - 7s - loss: 393.0537 - MinusLogProbMetric: 393.0537 - val_loss: 395.7401 - val_MinusLogProbMetric: 395.7401 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 380/1000
2023-09-10 08:35:51.872 
Epoch 380/1000 
	 loss: 392.9474, MinusLogProbMetric: 392.9474, val_loss: 394.3162, val_MinusLogProbMetric: 394.3162

Epoch 380: val_loss did not improve from 394.18219
196/196 - 10s - loss: 392.9474 - MinusLogProbMetric: 392.9474 - val_loss: 394.3162 - val_MinusLogProbMetric: 394.3162 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 381/1000
2023-09-10 08:36:00.670 
Epoch 381/1000 
	 loss: 392.9955, MinusLogProbMetric: 392.9955, val_loss: 395.3821, val_MinusLogProbMetric: 395.3821

Epoch 381: val_loss did not improve from 394.18219
196/196 - 9s - loss: 392.9955 - MinusLogProbMetric: 392.9955 - val_loss: 395.3821 - val_MinusLogProbMetric: 395.3821 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 382/1000
2023-09-10 08:36:09.907 
Epoch 382/1000 
	 loss: 392.8898, MinusLogProbMetric: 392.8898, val_loss: 395.0482, val_MinusLogProbMetric: 395.0482

Epoch 382: val_loss did not improve from 394.18219
196/196 - 9s - loss: 392.8898 - MinusLogProbMetric: 392.8898 - val_loss: 395.0482 - val_MinusLogProbMetric: 395.0482 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 383/1000
2023-09-10 08:36:18.309 
Epoch 383/1000 
	 loss: 392.9919, MinusLogProbMetric: 392.9919, val_loss: 394.3435, val_MinusLogProbMetric: 394.3435

Epoch 383: val_loss did not improve from 394.18219
196/196 - 8s - loss: 392.9919 - MinusLogProbMetric: 392.9919 - val_loss: 394.3435 - val_MinusLogProbMetric: 394.3435 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 384/1000
2023-09-10 08:36:27.129 
Epoch 384/1000 
	 loss: 392.9307, MinusLogProbMetric: 392.9307, val_loss: 394.1284, val_MinusLogProbMetric: 394.1284

Epoch 384: val_loss improved from 394.18219 to 394.12839, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 392.9307 - MinusLogProbMetric: 392.9307 - val_loss: 394.1284 - val_MinusLogProbMetric: 394.1284 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 385/1000
2023-09-10 08:36:34.970 
Epoch 385/1000 
	 loss: 392.7576, MinusLogProbMetric: 392.7576, val_loss: 394.3833, val_MinusLogProbMetric: 394.3833

Epoch 385: val_loss did not improve from 394.12839
196/196 - 8s - loss: 392.7576 - MinusLogProbMetric: 392.7576 - val_loss: 394.3833 - val_MinusLogProbMetric: 394.3833 - lr: 1.6667e-04 - 8s/epoch - 38ms/step
Epoch 386/1000
2023-09-10 08:36:43.370 
Epoch 386/1000 
	 loss: 392.8195, MinusLogProbMetric: 392.8195, val_loss: 394.6967, val_MinusLogProbMetric: 394.6967

Epoch 386: val_loss did not improve from 394.12839
196/196 - 8s - loss: 392.8195 - MinusLogProbMetric: 392.8195 - val_loss: 394.6967 - val_MinusLogProbMetric: 394.6967 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 387/1000
2023-09-10 08:36:50.782 
Epoch 387/1000 
	 loss: 392.7706, MinusLogProbMetric: 392.7706, val_loss: 394.2314, val_MinusLogProbMetric: 394.2314

Epoch 387: val_loss did not improve from 394.12839
196/196 - 7s - loss: 392.7706 - MinusLogProbMetric: 392.7706 - val_loss: 394.2314 - val_MinusLogProbMetric: 394.2314 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 388/1000
2023-09-10 08:37:01.049 
Epoch 388/1000 
	 loss: 392.9202, MinusLogProbMetric: 392.9202, val_loss: 395.1058, val_MinusLogProbMetric: 395.1058

Epoch 388: val_loss did not improve from 394.12839
196/196 - 10s - loss: 392.9202 - MinusLogProbMetric: 392.9202 - val_loss: 395.1058 - val_MinusLogProbMetric: 395.1058 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 389/1000
2023-09-10 08:37:10.454 
Epoch 389/1000 
	 loss: 392.8860, MinusLogProbMetric: 392.8860, val_loss: 394.2452, val_MinusLogProbMetric: 394.2452

Epoch 389: val_loss did not improve from 394.12839
196/196 - 9s - loss: 392.8860 - MinusLogProbMetric: 392.8860 - val_loss: 394.2452 - val_MinusLogProbMetric: 394.2452 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 390/1000
2023-09-10 08:37:21.589 
Epoch 390/1000 
	 loss: 392.8850, MinusLogProbMetric: 392.8850, val_loss: 394.2257, val_MinusLogProbMetric: 394.2257

Epoch 390: val_loss did not improve from 394.12839
196/196 - 11s - loss: 392.8850 - MinusLogProbMetric: 392.8850 - val_loss: 394.2257 - val_MinusLogProbMetric: 394.2257 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 391/1000
2023-09-10 08:37:30.908 
Epoch 391/1000 
	 loss: 392.7998, MinusLogProbMetric: 392.7998, val_loss: 394.7380, val_MinusLogProbMetric: 394.7380

Epoch 391: val_loss did not improve from 394.12839
196/196 - 9s - loss: 392.7998 - MinusLogProbMetric: 392.7998 - val_loss: 394.7380 - val_MinusLogProbMetric: 394.7380 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 392/1000
2023-09-10 08:37:39.384 
Epoch 392/1000 
	 loss: 392.9334, MinusLogProbMetric: 392.9334, val_loss: 395.7275, val_MinusLogProbMetric: 395.7275

Epoch 392: val_loss did not improve from 394.12839
196/196 - 8s - loss: 392.9334 - MinusLogProbMetric: 392.9334 - val_loss: 395.7275 - val_MinusLogProbMetric: 395.7275 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 393/1000
2023-09-10 08:37:48.406 
Epoch 393/1000 
	 loss: 393.0980, MinusLogProbMetric: 393.0980, val_loss: 395.4303, val_MinusLogProbMetric: 395.4303

Epoch 393: val_loss did not improve from 394.12839
196/196 - 9s - loss: 393.0980 - MinusLogProbMetric: 393.0980 - val_loss: 395.4303 - val_MinusLogProbMetric: 395.4303 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 394/1000
2023-09-10 08:37:56.378 
Epoch 394/1000 
	 loss: 392.8224, MinusLogProbMetric: 392.8224, val_loss: 394.8132, val_MinusLogProbMetric: 394.8132

Epoch 394: val_loss did not improve from 394.12839
196/196 - 8s - loss: 392.8224 - MinusLogProbMetric: 392.8224 - val_loss: 394.8132 - val_MinusLogProbMetric: 394.8132 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 395/1000
2023-09-10 08:38:08.155 
Epoch 395/1000 
	 loss: 392.8330, MinusLogProbMetric: 392.8330, val_loss: 394.2245, val_MinusLogProbMetric: 394.2245

Epoch 395: val_loss did not improve from 394.12839
196/196 - 12s - loss: 392.8330 - MinusLogProbMetric: 392.8330 - val_loss: 394.2245 - val_MinusLogProbMetric: 394.2245 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 396/1000
2023-09-10 08:38:19.153 
Epoch 396/1000 
	 loss: 392.6966, MinusLogProbMetric: 392.6966, val_loss: 394.0884, val_MinusLogProbMetric: 394.0884

Epoch 396: val_loss improved from 394.12839 to 394.08838, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 392.6966 - MinusLogProbMetric: 392.6966 - val_loss: 394.0884 - val_MinusLogProbMetric: 394.0884 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 397/1000
2023-09-10 08:38:29.606 
Epoch 397/1000 
	 loss: 392.8067, MinusLogProbMetric: 392.8067, val_loss: 394.3561, val_MinusLogProbMetric: 394.3561

Epoch 397: val_loss did not improve from 394.08838
196/196 - 10s - loss: 392.8067 - MinusLogProbMetric: 392.8067 - val_loss: 394.3561 - val_MinusLogProbMetric: 394.3561 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 398/1000
2023-09-10 08:38:40.289 
Epoch 398/1000 
	 loss: 392.9474, MinusLogProbMetric: 392.9474, val_loss: 394.5391, val_MinusLogProbMetric: 394.5391

Epoch 398: val_loss did not improve from 394.08838
196/196 - 11s - loss: 392.9474 - MinusLogProbMetric: 392.9474 - val_loss: 394.5391 - val_MinusLogProbMetric: 394.5391 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 399/1000
2023-09-10 08:38:48.539 
Epoch 399/1000 
	 loss: 392.6273, MinusLogProbMetric: 392.6273, val_loss: 394.7349, val_MinusLogProbMetric: 394.7349

Epoch 399: val_loss did not improve from 394.08838
196/196 - 8s - loss: 392.6273 - MinusLogProbMetric: 392.6273 - val_loss: 394.7349 - val_MinusLogProbMetric: 394.7349 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 400/1000
2023-09-10 08:39:00.172 
Epoch 400/1000 
	 loss: 392.8302, MinusLogProbMetric: 392.8302, val_loss: 394.0959, val_MinusLogProbMetric: 394.0959

Epoch 400: val_loss did not improve from 394.08838
196/196 - 12s - loss: 392.8302 - MinusLogProbMetric: 392.8302 - val_loss: 394.0959 - val_MinusLogProbMetric: 394.0959 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 401/1000
2023-09-10 08:39:10.400 
Epoch 401/1000 
	 loss: 392.9722, MinusLogProbMetric: 392.9722, val_loss: 394.5405, val_MinusLogProbMetric: 394.5405

Epoch 401: val_loss did not improve from 394.08838
196/196 - 10s - loss: 392.9722 - MinusLogProbMetric: 392.9722 - val_loss: 394.5405 - val_MinusLogProbMetric: 394.5405 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 402/1000
2023-09-10 08:39:19.151 
Epoch 402/1000 
	 loss: 392.7949, MinusLogProbMetric: 392.7949, val_loss: 394.1261, val_MinusLogProbMetric: 394.1261

Epoch 402: val_loss did not improve from 394.08838
196/196 - 9s - loss: 392.7949 - MinusLogProbMetric: 392.7949 - val_loss: 394.1261 - val_MinusLogProbMetric: 394.1261 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 403/1000
2023-09-10 08:39:29.717 
Epoch 403/1000 
	 loss: 392.8087, MinusLogProbMetric: 392.8087, val_loss: 394.3941, val_MinusLogProbMetric: 394.3941

Epoch 403: val_loss did not improve from 394.08838
196/196 - 11s - loss: 392.8087 - MinusLogProbMetric: 392.8087 - val_loss: 394.3941 - val_MinusLogProbMetric: 394.3941 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 404/1000
2023-09-10 08:39:39.899 
Epoch 404/1000 
	 loss: 392.6656, MinusLogProbMetric: 392.6656, val_loss: 394.6714, val_MinusLogProbMetric: 394.6714

Epoch 404: val_loss did not improve from 394.08838
196/196 - 10s - loss: 392.6656 - MinusLogProbMetric: 392.6656 - val_loss: 394.6714 - val_MinusLogProbMetric: 394.6714 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 405/1000
2023-09-10 08:39:49.155 
Epoch 405/1000 
	 loss: 392.7029, MinusLogProbMetric: 392.7029, val_loss: 394.6344, val_MinusLogProbMetric: 394.6344

Epoch 405: val_loss did not improve from 394.08838
196/196 - 9s - loss: 392.7029 - MinusLogProbMetric: 392.7029 - val_loss: 394.6344 - val_MinusLogProbMetric: 394.6344 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 406/1000
2023-09-10 08:39:58.662 
Epoch 406/1000 
	 loss: 392.7934, MinusLogProbMetric: 392.7934, val_loss: 394.3988, val_MinusLogProbMetric: 394.3988

Epoch 406: val_loss did not improve from 394.08838
196/196 - 10s - loss: 392.7934 - MinusLogProbMetric: 392.7934 - val_loss: 394.3988 - val_MinusLogProbMetric: 394.3988 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 407/1000
2023-09-10 08:40:07.210 
Epoch 407/1000 
	 loss: 392.7056, MinusLogProbMetric: 392.7056, val_loss: 393.9685, val_MinusLogProbMetric: 393.9685

Epoch 407: val_loss improved from 394.08838 to 393.96848, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 392.7056 - MinusLogProbMetric: 392.7056 - val_loss: 393.9685 - val_MinusLogProbMetric: 393.9685 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 408/1000
2023-09-10 08:40:17.684 
Epoch 408/1000 
	 loss: 392.7144, MinusLogProbMetric: 392.7144, val_loss: 394.0463, val_MinusLogProbMetric: 394.0463

Epoch 408: val_loss did not improve from 393.96848
196/196 - 10s - loss: 392.7144 - MinusLogProbMetric: 392.7144 - val_loss: 394.0463 - val_MinusLogProbMetric: 394.0463 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 409/1000
2023-09-10 08:40:25.152 
Epoch 409/1000 
	 loss: 392.5815, MinusLogProbMetric: 392.5815, val_loss: 394.3265, val_MinusLogProbMetric: 394.3265

Epoch 409: val_loss did not improve from 393.96848
196/196 - 7s - loss: 392.5815 - MinusLogProbMetric: 392.5815 - val_loss: 394.3265 - val_MinusLogProbMetric: 394.3265 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 410/1000
2023-09-10 08:40:32.690 
Epoch 410/1000 
	 loss: 392.9412, MinusLogProbMetric: 392.9412, val_loss: 394.0690, val_MinusLogProbMetric: 394.0690

Epoch 410: val_loss did not improve from 393.96848
196/196 - 8s - loss: 392.9412 - MinusLogProbMetric: 392.9412 - val_loss: 394.0690 - val_MinusLogProbMetric: 394.0690 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 411/1000
2023-09-10 08:40:42.396 
Epoch 411/1000 
	 loss: 392.6994, MinusLogProbMetric: 392.6994, val_loss: 395.0063, val_MinusLogProbMetric: 395.0063

Epoch 411: val_loss did not improve from 393.96848
196/196 - 10s - loss: 392.6994 - MinusLogProbMetric: 392.6994 - val_loss: 395.0063 - val_MinusLogProbMetric: 395.0063 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 412/1000
2023-09-10 08:40:54.289 
Epoch 412/1000 
	 loss: 392.7137, MinusLogProbMetric: 392.7137, val_loss: 394.5839, val_MinusLogProbMetric: 394.5839

Epoch 412: val_loss did not improve from 393.96848
196/196 - 12s - loss: 392.7137 - MinusLogProbMetric: 392.7137 - val_loss: 394.5839 - val_MinusLogProbMetric: 394.5839 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 413/1000
2023-09-10 08:41:04.389 
Epoch 413/1000 
	 loss: 392.6280, MinusLogProbMetric: 392.6280, val_loss: 394.2963, val_MinusLogProbMetric: 394.2963

Epoch 413: val_loss did not improve from 393.96848
196/196 - 10s - loss: 392.6280 - MinusLogProbMetric: 392.6280 - val_loss: 394.2963 - val_MinusLogProbMetric: 394.2963 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 414/1000
2023-09-10 08:41:12.536 
Epoch 414/1000 
	 loss: 392.5192, MinusLogProbMetric: 392.5192, val_loss: 394.5257, val_MinusLogProbMetric: 394.5257

Epoch 414: val_loss did not improve from 393.96848
196/196 - 8s - loss: 392.5192 - MinusLogProbMetric: 392.5192 - val_loss: 394.5257 - val_MinusLogProbMetric: 394.5257 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 415/1000
2023-09-10 08:41:20.963 
Epoch 415/1000 
	 loss: 392.7437, MinusLogProbMetric: 392.7437, val_loss: 394.3385, val_MinusLogProbMetric: 394.3385

Epoch 415: val_loss did not improve from 393.96848
196/196 - 8s - loss: 392.7437 - MinusLogProbMetric: 392.7437 - val_loss: 394.3385 - val_MinusLogProbMetric: 394.3385 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 416/1000
2023-09-10 08:41:31.565 
Epoch 416/1000 
	 loss: 392.4948, MinusLogProbMetric: 392.4948, val_loss: 394.6246, val_MinusLogProbMetric: 394.6246

Epoch 416: val_loss did not improve from 393.96848
196/196 - 11s - loss: 392.4948 - MinusLogProbMetric: 392.4948 - val_loss: 394.6246 - val_MinusLogProbMetric: 394.6246 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 417/1000
2023-09-10 08:41:40.839 
Epoch 417/1000 
	 loss: 392.7282, MinusLogProbMetric: 392.7282, val_loss: 394.2244, val_MinusLogProbMetric: 394.2244

Epoch 417: val_loss did not improve from 393.96848
196/196 - 9s - loss: 392.7282 - MinusLogProbMetric: 392.7282 - val_loss: 394.2244 - val_MinusLogProbMetric: 394.2244 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 418/1000
2023-09-10 08:41:50.572 
Epoch 418/1000 
	 loss: 392.6200, MinusLogProbMetric: 392.6200, val_loss: 394.3788, val_MinusLogProbMetric: 394.3788

Epoch 418: val_loss did not improve from 393.96848
196/196 - 10s - loss: 392.6200 - MinusLogProbMetric: 392.6200 - val_loss: 394.3788 - val_MinusLogProbMetric: 394.3788 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 419/1000
2023-09-10 08:42:00.310 
Epoch 419/1000 
	 loss: 392.8062, MinusLogProbMetric: 392.8062, val_loss: 394.4175, val_MinusLogProbMetric: 394.4175

Epoch 419: val_loss did not improve from 393.96848
196/196 - 10s - loss: 392.8062 - MinusLogProbMetric: 392.8062 - val_loss: 394.4175 - val_MinusLogProbMetric: 394.4175 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 420/1000
2023-09-10 08:42:10.725 
Epoch 420/1000 
	 loss: 392.6512, MinusLogProbMetric: 392.6512, val_loss: 395.0639, val_MinusLogProbMetric: 395.0639

Epoch 420: val_loss did not improve from 393.96848
196/196 - 10s - loss: 392.6512 - MinusLogProbMetric: 392.6512 - val_loss: 395.0639 - val_MinusLogProbMetric: 395.0639 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 421/1000
2023-09-10 08:42:21.549 
Epoch 421/1000 
	 loss: 392.4995, MinusLogProbMetric: 392.4995, val_loss: 393.9127, val_MinusLogProbMetric: 393.9127

Epoch 421: val_loss improved from 393.96848 to 393.91269, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 392.4995 - MinusLogProbMetric: 392.4995 - val_loss: 393.9127 - val_MinusLogProbMetric: 393.9127 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 422/1000
2023-09-10 08:42:29.757 
Epoch 422/1000 
	 loss: 392.6030, MinusLogProbMetric: 392.6030, val_loss: 394.1630, val_MinusLogProbMetric: 394.1630

Epoch 422: val_loss did not improve from 393.91269
196/196 - 8s - loss: 392.6030 - MinusLogProbMetric: 392.6030 - val_loss: 394.1630 - val_MinusLogProbMetric: 394.1630 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 423/1000
2023-09-10 08:42:39.381 
Epoch 423/1000 
	 loss: 392.6397, MinusLogProbMetric: 392.6397, val_loss: 394.4464, val_MinusLogProbMetric: 394.4464

Epoch 423: val_loss did not improve from 393.91269
196/196 - 10s - loss: 392.6397 - MinusLogProbMetric: 392.6397 - val_loss: 394.4464 - val_MinusLogProbMetric: 394.4464 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 424/1000
2023-09-10 08:42:47.984 
Epoch 424/1000 
	 loss: 392.4220, MinusLogProbMetric: 392.4220, val_loss: 394.0791, val_MinusLogProbMetric: 394.0791

Epoch 424: val_loss did not improve from 393.91269
196/196 - 9s - loss: 392.4220 - MinusLogProbMetric: 392.4220 - val_loss: 394.0791 - val_MinusLogProbMetric: 394.0791 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 425/1000
2023-09-10 08:42:56.379 
Epoch 425/1000 
	 loss: 392.4609, MinusLogProbMetric: 392.4609, val_loss: 393.9750, val_MinusLogProbMetric: 393.9750

Epoch 425: val_loss did not improve from 393.91269
196/196 - 8s - loss: 392.4609 - MinusLogProbMetric: 392.4609 - val_loss: 393.9750 - val_MinusLogProbMetric: 393.9750 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 426/1000
2023-09-10 08:43:06.272 
Epoch 426/1000 
	 loss: 392.5974, MinusLogProbMetric: 392.5974, val_loss: 394.6463, val_MinusLogProbMetric: 394.6463

Epoch 426: val_loss did not improve from 393.91269
196/196 - 10s - loss: 392.5974 - MinusLogProbMetric: 392.5974 - val_loss: 394.6463 - val_MinusLogProbMetric: 394.6463 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 427/1000
2023-09-10 08:43:16.135 
Epoch 427/1000 
	 loss: 392.6671, MinusLogProbMetric: 392.6671, val_loss: 395.3631, val_MinusLogProbMetric: 395.3631

Epoch 427: val_loss did not improve from 393.91269
196/196 - 10s - loss: 392.6671 - MinusLogProbMetric: 392.6671 - val_loss: 395.3631 - val_MinusLogProbMetric: 395.3631 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 428/1000
2023-09-10 08:43:26.828 
Epoch 428/1000 
	 loss: 392.4964, MinusLogProbMetric: 392.4964, val_loss: 394.2571, val_MinusLogProbMetric: 394.2571

Epoch 428: val_loss did not improve from 393.91269
196/196 - 11s - loss: 392.4964 - MinusLogProbMetric: 392.4964 - val_loss: 394.2571 - val_MinusLogProbMetric: 394.2571 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 429/1000
2023-09-10 08:43:36.085 
Epoch 429/1000 
	 loss: 392.6736, MinusLogProbMetric: 392.6736, val_loss: 394.3916, val_MinusLogProbMetric: 394.3916

Epoch 429: val_loss did not improve from 393.91269
196/196 - 9s - loss: 392.6736 - MinusLogProbMetric: 392.6736 - val_loss: 394.3916 - val_MinusLogProbMetric: 394.3916 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 430/1000
2023-09-10 08:43:47.216 
Epoch 430/1000 
	 loss: 392.5737, MinusLogProbMetric: 392.5737, val_loss: 393.9317, val_MinusLogProbMetric: 393.9317

Epoch 430: val_loss did not improve from 393.91269
196/196 - 11s - loss: 392.5737 - MinusLogProbMetric: 392.5737 - val_loss: 393.9317 - val_MinusLogProbMetric: 393.9317 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 431/1000
2023-09-10 08:43:58.237 
Epoch 431/1000 
	 loss: 392.4249, MinusLogProbMetric: 392.4249, val_loss: 394.1078, val_MinusLogProbMetric: 394.1078

Epoch 431: val_loss did not improve from 393.91269
196/196 - 11s - loss: 392.4249 - MinusLogProbMetric: 392.4249 - val_loss: 394.1078 - val_MinusLogProbMetric: 394.1078 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 432/1000
2023-09-10 08:44:06.865 
Epoch 432/1000 
	 loss: 392.5145, MinusLogProbMetric: 392.5145, val_loss: 394.3362, val_MinusLogProbMetric: 394.3362

Epoch 432: val_loss did not improve from 393.91269
196/196 - 9s - loss: 392.5145 - MinusLogProbMetric: 392.5145 - val_loss: 394.3362 - val_MinusLogProbMetric: 394.3362 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 433/1000
2023-09-10 08:44:18.615 
Epoch 433/1000 
	 loss: 392.6441, MinusLogProbMetric: 392.6441, val_loss: 393.8850, val_MinusLogProbMetric: 393.8850

Epoch 433: val_loss improved from 393.91269 to 393.88504, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 392.6441 - MinusLogProbMetric: 392.6441 - val_loss: 393.8850 - val_MinusLogProbMetric: 393.8850 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 434/1000
2023-09-10 08:44:30.175 
Epoch 434/1000 
	 loss: 392.5086, MinusLogProbMetric: 392.5086, val_loss: 393.9657, val_MinusLogProbMetric: 393.9657

Epoch 434: val_loss did not improve from 393.88504
196/196 - 11s - loss: 392.5086 - MinusLogProbMetric: 392.5086 - val_loss: 393.9657 - val_MinusLogProbMetric: 393.9657 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 435/1000
2023-09-10 08:44:40.447 
Epoch 435/1000 
	 loss: 392.6054, MinusLogProbMetric: 392.6054, val_loss: 393.9160, val_MinusLogProbMetric: 393.9160

Epoch 435: val_loss did not improve from 393.88504
196/196 - 10s - loss: 392.6054 - MinusLogProbMetric: 392.6054 - val_loss: 393.9160 - val_MinusLogProbMetric: 393.9160 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 436/1000
2023-09-10 08:44:49.188 
Epoch 436/1000 
	 loss: 392.5245, MinusLogProbMetric: 392.5245, val_loss: 393.8123, val_MinusLogProbMetric: 393.8123

Epoch 436: val_loss improved from 393.88504 to 393.81235, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 392.5245 - MinusLogProbMetric: 392.5245 - val_loss: 393.8123 - val_MinusLogProbMetric: 393.8123 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 437/1000
2023-09-10 08:44:57.798 
Epoch 437/1000 
	 loss: 392.3658, MinusLogProbMetric: 392.3658, val_loss: 394.4655, val_MinusLogProbMetric: 394.4655

Epoch 437: val_loss did not improve from 393.81235
196/196 - 8s - loss: 392.3658 - MinusLogProbMetric: 392.3658 - val_loss: 394.4655 - val_MinusLogProbMetric: 394.4655 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 438/1000
2023-09-10 08:45:07.269 
Epoch 438/1000 
	 loss: 392.7489, MinusLogProbMetric: 392.7489, val_loss: 394.1515, val_MinusLogProbMetric: 394.1515

Epoch 438: val_loss did not improve from 393.81235
196/196 - 9s - loss: 392.7489 - MinusLogProbMetric: 392.7489 - val_loss: 394.1515 - val_MinusLogProbMetric: 394.1515 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 439/1000
2023-09-10 08:45:18.026 
Epoch 439/1000 
	 loss: 392.4810, MinusLogProbMetric: 392.4810, val_loss: 393.8976, val_MinusLogProbMetric: 393.8976

Epoch 439: val_loss did not improve from 393.81235
196/196 - 11s - loss: 392.4810 - MinusLogProbMetric: 392.4810 - val_loss: 393.8976 - val_MinusLogProbMetric: 393.8976 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 440/1000
2023-09-10 08:45:27.946 
Epoch 440/1000 
	 loss: 392.2583, MinusLogProbMetric: 392.2583, val_loss: 394.2863, val_MinusLogProbMetric: 394.2863

Epoch 440: val_loss did not improve from 393.81235
196/196 - 10s - loss: 392.2583 - MinusLogProbMetric: 392.2583 - val_loss: 394.2863 - val_MinusLogProbMetric: 394.2863 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 441/1000
2023-09-10 08:45:39.042 
Epoch 441/1000 
	 loss: 392.3651, MinusLogProbMetric: 392.3651, val_loss: 394.1526, val_MinusLogProbMetric: 394.1526

Epoch 441: val_loss did not improve from 393.81235
196/196 - 11s - loss: 392.3651 - MinusLogProbMetric: 392.3651 - val_loss: 394.1526 - val_MinusLogProbMetric: 394.1526 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 442/1000
2023-09-10 08:45:49.572 
Epoch 442/1000 
	 loss: 392.4948, MinusLogProbMetric: 392.4948, val_loss: 393.8584, val_MinusLogProbMetric: 393.8584

Epoch 442: val_loss did not improve from 393.81235
196/196 - 11s - loss: 392.4948 - MinusLogProbMetric: 392.4948 - val_loss: 393.8584 - val_MinusLogProbMetric: 393.8584 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 443/1000
2023-09-10 08:45:59.147 
Epoch 443/1000 
	 loss: 392.4516, MinusLogProbMetric: 392.4516, val_loss: 394.6142, val_MinusLogProbMetric: 394.6142

Epoch 443: val_loss did not improve from 393.81235
196/196 - 10s - loss: 392.4516 - MinusLogProbMetric: 392.4516 - val_loss: 394.6142 - val_MinusLogProbMetric: 394.6142 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 444/1000
2023-09-10 08:46:06.865 
Epoch 444/1000 
	 loss: 392.5667, MinusLogProbMetric: 392.5667, val_loss: 394.1063, val_MinusLogProbMetric: 394.1063

Epoch 444: val_loss did not improve from 393.81235
196/196 - 8s - loss: 392.5667 - MinusLogProbMetric: 392.5667 - val_loss: 394.1063 - val_MinusLogProbMetric: 394.1063 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 445/1000
2023-09-10 08:46:18.838 
Epoch 445/1000 
	 loss: 392.3233, MinusLogProbMetric: 392.3233, val_loss: 393.8876, val_MinusLogProbMetric: 393.8876

Epoch 445: val_loss did not improve from 393.81235
196/196 - 12s - loss: 392.3233 - MinusLogProbMetric: 392.3233 - val_loss: 393.8876 - val_MinusLogProbMetric: 393.8876 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 446/1000
2023-09-10 08:46:28.107 
Epoch 446/1000 
	 loss: 392.3485, MinusLogProbMetric: 392.3485, val_loss: 394.0933, val_MinusLogProbMetric: 394.0933

Epoch 446: val_loss did not improve from 393.81235
196/196 - 9s - loss: 392.3485 - MinusLogProbMetric: 392.3485 - val_loss: 394.0933 - val_MinusLogProbMetric: 394.0933 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 447/1000
2023-09-10 08:46:40.108 
Epoch 447/1000 
	 loss: 392.3910, MinusLogProbMetric: 392.3910, val_loss: 394.4685, val_MinusLogProbMetric: 394.4685

Epoch 447: val_loss did not improve from 393.81235
196/196 - 12s - loss: 392.3910 - MinusLogProbMetric: 392.3910 - val_loss: 394.4685 - val_MinusLogProbMetric: 394.4685 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 448/1000
2023-09-10 08:46:51.373 
Epoch 448/1000 
	 loss: 392.5144, MinusLogProbMetric: 392.5144, val_loss: 393.8111, val_MinusLogProbMetric: 393.8111

Epoch 448: val_loss improved from 393.81235 to 393.81113, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 392.5144 - MinusLogProbMetric: 392.5144 - val_loss: 393.8111 - val_MinusLogProbMetric: 393.8111 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 449/1000
2023-09-10 08:47:00.954 
Epoch 449/1000 
	 loss: 392.3738, MinusLogProbMetric: 392.3738, val_loss: 393.8841, val_MinusLogProbMetric: 393.8841

Epoch 449: val_loss did not improve from 393.81113
196/196 - 9s - loss: 392.3738 - MinusLogProbMetric: 392.3738 - val_loss: 393.8841 - val_MinusLogProbMetric: 393.8841 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 450/1000
2023-09-10 08:47:10.485 
Epoch 450/1000 
	 loss: 392.3440, MinusLogProbMetric: 392.3440, val_loss: 394.3393, val_MinusLogProbMetric: 394.3393

Epoch 450: val_loss did not improve from 393.81113
196/196 - 10s - loss: 392.3440 - MinusLogProbMetric: 392.3440 - val_loss: 394.3393 - val_MinusLogProbMetric: 394.3393 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 451/1000
2023-09-10 08:47:19.255 
Epoch 451/1000 
	 loss: 392.3222, MinusLogProbMetric: 392.3222, val_loss: 394.3053, val_MinusLogProbMetric: 394.3053

Epoch 451: val_loss did not improve from 393.81113
196/196 - 9s - loss: 392.3222 - MinusLogProbMetric: 392.3222 - val_loss: 394.3053 - val_MinusLogProbMetric: 394.3053 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 452/1000
2023-09-10 08:47:27.860 
Epoch 452/1000 
	 loss: 392.2581, MinusLogProbMetric: 392.2581, val_loss: 394.4922, val_MinusLogProbMetric: 394.4922

Epoch 452: val_loss did not improve from 393.81113
196/196 - 9s - loss: 392.2581 - MinusLogProbMetric: 392.2581 - val_loss: 394.4922 - val_MinusLogProbMetric: 394.4922 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 453/1000
2023-09-10 08:47:37.072 
Epoch 453/1000 
	 loss: 392.2376, MinusLogProbMetric: 392.2376, val_loss: 393.6348, val_MinusLogProbMetric: 393.6348

Epoch 453: val_loss improved from 393.81113 to 393.63483, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 392.2376 - MinusLogProbMetric: 392.2376 - val_loss: 393.6348 - val_MinusLogProbMetric: 393.6348 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 454/1000
2023-09-10 08:47:46.826 
Epoch 454/1000 
	 loss: 392.3088, MinusLogProbMetric: 392.3088, val_loss: 394.1110, val_MinusLogProbMetric: 394.1110

Epoch 454: val_loss did not improve from 393.63483
196/196 - 9s - loss: 392.3088 - MinusLogProbMetric: 392.3088 - val_loss: 394.1110 - val_MinusLogProbMetric: 394.1110 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 455/1000
2023-09-10 08:47:56.361 
Epoch 455/1000 
	 loss: 392.2762, MinusLogProbMetric: 392.2762, val_loss: 393.5917, val_MinusLogProbMetric: 393.5917

Epoch 455: val_loss improved from 393.63483 to 393.59171, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 392.2762 - MinusLogProbMetric: 392.2762 - val_loss: 393.5917 - val_MinusLogProbMetric: 393.5917 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 456/1000
2023-09-10 08:48:06.371 
Epoch 456/1000 
	 loss: 392.4315, MinusLogProbMetric: 392.4315, val_loss: 393.6767, val_MinusLogProbMetric: 393.6767

Epoch 456: val_loss did not improve from 393.59171
196/196 - 10s - loss: 392.4315 - MinusLogProbMetric: 392.4315 - val_loss: 393.6767 - val_MinusLogProbMetric: 393.6767 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 457/1000
2023-09-10 08:48:14.662 
Epoch 457/1000 
	 loss: 392.1697, MinusLogProbMetric: 392.1697, val_loss: 394.2839, val_MinusLogProbMetric: 394.2839

Epoch 457: val_loss did not improve from 393.59171
196/196 - 8s - loss: 392.1697 - MinusLogProbMetric: 392.1697 - val_loss: 394.2839 - val_MinusLogProbMetric: 394.2839 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 458/1000
2023-09-10 08:48:22.130 
Epoch 458/1000 
	 loss: 392.1217, MinusLogProbMetric: 392.1217, val_loss: 394.0644, val_MinusLogProbMetric: 394.0644

Epoch 458: val_loss did not improve from 393.59171
196/196 - 7s - loss: 392.1217 - MinusLogProbMetric: 392.1217 - val_loss: 394.0644 - val_MinusLogProbMetric: 394.0644 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 459/1000
2023-09-10 08:48:30.461 
Epoch 459/1000 
	 loss: 392.2797, MinusLogProbMetric: 392.2797, val_loss: 394.1019, val_MinusLogProbMetric: 394.1019

Epoch 459: val_loss did not improve from 393.59171
196/196 - 8s - loss: 392.2797 - MinusLogProbMetric: 392.2797 - val_loss: 394.1019 - val_MinusLogProbMetric: 394.1019 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 460/1000
2023-09-10 08:48:37.606 
Epoch 460/1000 
	 loss: 392.3298, MinusLogProbMetric: 392.3298, val_loss: 394.1245, val_MinusLogProbMetric: 394.1245

Epoch 460: val_loss did not improve from 393.59171
196/196 - 7s - loss: 392.3298 - MinusLogProbMetric: 392.3298 - val_loss: 394.1245 - val_MinusLogProbMetric: 394.1245 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 461/1000
2023-09-10 08:48:46.496 
Epoch 461/1000 
	 loss: 392.1930, MinusLogProbMetric: 392.1930, val_loss: 394.0097, val_MinusLogProbMetric: 394.0097

Epoch 461: val_loss did not improve from 393.59171
196/196 - 9s - loss: 392.1930 - MinusLogProbMetric: 392.1930 - val_loss: 394.0097 - val_MinusLogProbMetric: 394.0097 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 462/1000
2023-09-10 08:48:54.735 
Epoch 462/1000 
	 loss: 392.2698, MinusLogProbMetric: 392.2698, val_loss: 393.8511, val_MinusLogProbMetric: 393.8511

Epoch 462: val_loss did not improve from 393.59171
196/196 - 8s - loss: 392.2698 - MinusLogProbMetric: 392.2698 - val_loss: 393.8511 - val_MinusLogProbMetric: 393.8511 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 463/1000
2023-09-10 08:49:05.560 
Epoch 463/1000 
	 loss: 392.2783, MinusLogProbMetric: 392.2783, val_loss: 394.7921, val_MinusLogProbMetric: 394.7921

Epoch 463: val_loss did not improve from 393.59171
196/196 - 11s - loss: 392.2783 - MinusLogProbMetric: 392.2783 - val_loss: 394.7921 - val_MinusLogProbMetric: 394.7921 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 464/1000
2023-09-10 08:49:13.159 
Epoch 464/1000 
	 loss: 392.2689, MinusLogProbMetric: 392.2689, val_loss: 393.7984, val_MinusLogProbMetric: 393.7984

Epoch 464: val_loss did not improve from 393.59171
196/196 - 8s - loss: 392.2689 - MinusLogProbMetric: 392.2689 - val_loss: 393.7984 - val_MinusLogProbMetric: 393.7984 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 465/1000
2023-09-10 08:49:21.272 
Epoch 465/1000 
	 loss: 392.2552, MinusLogProbMetric: 392.2552, val_loss: 394.5116, val_MinusLogProbMetric: 394.5116

Epoch 465: val_loss did not improve from 393.59171
196/196 - 8s - loss: 392.2552 - MinusLogProbMetric: 392.2552 - val_loss: 394.5116 - val_MinusLogProbMetric: 394.5116 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 466/1000
2023-09-10 08:49:28.375 
Epoch 466/1000 
	 loss: 392.3854, MinusLogProbMetric: 392.3854, val_loss: 395.1756, val_MinusLogProbMetric: 395.1756

Epoch 466: val_loss did not improve from 393.59171
196/196 - 7s - loss: 392.3854 - MinusLogProbMetric: 392.3854 - val_loss: 395.1756 - val_MinusLogProbMetric: 395.1756 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 467/1000
2023-09-10 08:49:37.368 
Epoch 467/1000 
	 loss: 392.1234, MinusLogProbMetric: 392.1234, val_loss: 394.0325, val_MinusLogProbMetric: 394.0325

Epoch 467: val_loss did not improve from 393.59171
196/196 - 9s - loss: 392.1234 - MinusLogProbMetric: 392.1234 - val_loss: 394.0325 - val_MinusLogProbMetric: 394.0325 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 468/1000
2023-09-10 08:49:45.110 
Epoch 468/1000 
	 loss: 392.2984, MinusLogProbMetric: 392.2984, val_loss: 393.9534, val_MinusLogProbMetric: 393.9534

Epoch 468: val_loss did not improve from 393.59171
196/196 - 8s - loss: 392.2984 - MinusLogProbMetric: 392.2984 - val_loss: 393.9534 - val_MinusLogProbMetric: 393.9534 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 469/1000
2023-09-10 08:49:54.804 
Epoch 469/1000 
	 loss: 392.1591, MinusLogProbMetric: 392.1591, val_loss: 393.7728, val_MinusLogProbMetric: 393.7728

Epoch 469: val_loss did not improve from 393.59171
196/196 - 10s - loss: 392.1591 - MinusLogProbMetric: 392.1591 - val_loss: 393.7728 - val_MinusLogProbMetric: 393.7728 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 470/1000
2023-09-10 08:50:04.717 
Epoch 470/1000 
	 loss: 392.0948, MinusLogProbMetric: 392.0948, val_loss: 394.1219, val_MinusLogProbMetric: 394.1219

Epoch 470: val_loss did not improve from 393.59171
196/196 - 10s - loss: 392.0948 - MinusLogProbMetric: 392.0948 - val_loss: 394.1219 - val_MinusLogProbMetric: 394.1219 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 471/1000
2023-09-10 08:50:14.328 
Epoch 471/1000 
	 loss: 392.1354, MinusLogProbMetric: 392.1354, val_loss: 393.7381, val_MinusLogProbMetric: 393.7381

Epoch 471: val_loss did not improve from 393.59171
196/196 - 10s - loss: 392.1354 - MinusLogProbMetric: 392.1354 - val_loss: 393.7381 - val_MinusLogProbMetric: 393.7381 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 472/1000
2023-09-10 08:50:21.572 
Epoch 472/1000 
	 loss: 391.9877, MinusLogProbMetric: 391.9877, val_loss: 393.8972, val_MinusLogProbMetric: 393.8972

Epoch 472: val_loss did not improve from 393.59171
196/196 - 7s - loss: 391.9877 - MinusLogProbMetric: 391.9877 - val_loss: 393.8972 - val_MinusLogProbMetric: 393.8972 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 473/1000
2023-09-10 08:50:30.000 
Epoch 473/1000 
	 loss: 392.3572, MinusLogProbMetric: 392.3572, val_loss: 394.1763, val_MinusLogProbMetric: 394.1763

Epoch 473: val_loss did not improve from 393.59171
196/196 - 8s - loss: 392.3572 - MinusLogProbMetric: 392.3572 - val_loss: 394.1763 - val_MinusLogProbMetric: 394.1763 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 474/1000
2023-09-10 08:50:39.051 
Epoch 474/1000 
	 loss: 392.2705, MinusLogProbMetric: 392.2705, val_loss: 394.7960, val_MinusLogProbMetric: 394.7960

Epoch 474: val_loss did not improve from 393.59171
196/196 - 9s - loss: 392.2705 - MinusLogProbMetric: 392.2705 - val_loss: 394.7960 - val_MinusLogProbMetric: 394.7960 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 475/1000
2023-09-10 08:50:49.187 
Epoch 475/1000 
	 loss: 392.3361, MinusLogProbMetric: 392.3361, val_loss: 394.1069, val_MinusLogProbMetric: 394.1069

Epoch 475: val_loss did not improve from 393.59171
196/196 - 10s - loss: 392.3361 - MinusLogProbMetric: 392.3361 - val_loss: 394.1069 - val_MinusLogProbMetric: 394.1069 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 476/1000
2023-09-10 08:50:57.580 
Epoch 476/1000 
	 loss: 392.1027, MinusLogProbMetric: 392.1027, val_loss: 393.5000, val_MinusLogProbMetric: 393.5000

Epoch 476: val_loss improved from 393.59171 to 393.50003, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 392.1027 - MinusLogProbMetric: 392.1027 - val_loss: 393.5000 - val_MinusLogProbMetric: 393.5000 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 477/1000
2023-09-10 08:51:05.386 
Epoch 477/1000 
	 loss: 392.1871, MinusLogProbMetric: 392.1871, val_loss: 393.8099, val_MinusLogProbMetric: 393.8099

Epoch 477: val_loss did not improve from 393.50003
196/196 - 7s - loss: 392.1871 - MinusLogProbMetric: 392.1871 - val_loss: 393.8099 - val_MinusLogProbMetric: 393.8099 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 478/1000
2023-09-10 08:51:12.654 
Epoch 478/1000 
	 loss: 392.1326, MinusLogProbMetric: 392.1326, val_loss: 393.4290, val_MinusLogProbMetric: 393.4290

Epoch 478: val_loss improved from 393.50003 to 393.42905, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 392.1326 - MinusLogProbMetric: 392.1326 - val_loss: 393.4290 - val_MinusLogProbMetric: 393.4290 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 479/1000
2023-09-10 08:51:23.772 
Epoch 479/1000 
	 loss: 392.0604, MinusLogProbMetric: 392.0604, val_loss: 393.9831, val_MinusLogProbMetric: 393.9831

Epoch 479: val_loss did not improve from 393.42905
196/196 - 10s - loss: 392.0604 - MinusLogProbMetric: 392.0604 - val_loss: 393.9831 - val_MinusLogProbMetric: 393.9831 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 480/1000
2023-09-10 08:51:30.616 
Epoch 480/1000 
	 loss: 392.1448, MinusLogProbMetric: 392.1448, val_loss: 393.8463, val_MinusLogProbMetric: 393.8463

Epoch 480: val_loss did not improve from 393.42905
196/196 - 7s - loss: 392.1448 - MinusLogProbMetric: 392.1448 - val_loss: 393.8463 - val_MinusLogProbMetric: 393.8463 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 481/1000
2023-09-10 08:51:40.245 
Epoch 481/1000 
	 loss: 392.2170, MinusLogProbMetric: 392.2170, val_loss: 395.7897, val_MinusLogProbMetric: 395.7897

Epoch 481: val_loss did not improve from 393.42905
196/196 - 10s - loss: 392.2170 - MinusLogProbMetric: 392.2170 - val_loss: 395.7897 - val_MinusLogProbMetric: 395.7897 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 482/1000
2023-09-10 08:51:49.186 
Epoch 482/1000 
	 loss: 391.9826, MinusLogProbMetric: 391.9826, val_loss: 394.0913, val_MinusLogProbMetric: 394.0913

Epoch 482: val_loss did not improve from 393.42905
196/196 - 9s - loss: 391.9826 - MinusLogProbMetric: 391.9826 - val_loss: 394.0913 - val_MinusLogProbMetric: 394.0913 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 483/1000
2023-09-10 08:51:58.013 
Epoch 483/1000 
	 loss: 392.0657, MinusLogProbMetric: 392.0657, val_loss: 394.4235, val_MinusLogProbMetric: 394.4235

Epoch 483: val_loss did not improve from 393.42905
196/196 - 9s - loss: 392.0657 - MinusLogProbMetric: 392.0657 - val_loss: 394.4235 - val_MinusLogProbMetric: 394.4235 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 484/1000
2023-09-10 08:52:05.809 
Epoch 484/1000 
	 loss: 392.4163, MinusLogProbMetric: 392.4163, val_loss: 393.6844, val_MinusLogProbMetric: 393.6844

Epoch 484: val_loss did not improve from 393.42905
196/196 - 8s - loss: 392.4163 - MinusLogProbMetric: 392.4163 - val_loss: 393.6844 - val_MinusLogProbMetric: 393.6844 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 485/1000
2023-09-10 08:52:12.882 
Epoch 485/1000 
	 loss: 391.9856, MinusLogProbMetric: 391.9856, val_loss: 393.7251, val_MinusLogProbMetric: 393.7251

Epoch 485: val_loss did not improve from 393.42905
196/196 - 7s - loss: 391.9856 - MinusLogProbMetric: 391.9856 - val_loss: 393.7251 - val_MinusLogProbMetric: 393.7251 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 486/1000
2023-09-10 08:52:20.394 
Epoch 486/1000 
	 loss: 392.0830, MinusLogProbMetric: 392.0830, val_loss: 394.1494, val_MinusLogProbMetric: 394.1494

Epoch 486: val_loss did not improve from 393.42905
196/196 - 7s - loss: 392.0830 - MinusLogProbMetric: 392.0830 - val_loss: 394.1494 - val_MinusLogProbMetric: 394.1494 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 487/1000
2023-09-10 08:52:29.920 
Epoch 487/1000 
	 loss: 392.1178, MinusLogProbMetric: 392.1178, val_loss: 393.8290, val_MinusLogProbMetric: 393.8290

Epoch 487: val_loss did not improve from 393.42905
196/196 - 10s - loss: 392.1178 - MinusLogProbMetric: 392.1178 - val_loss: 393.8290 - val_MinusLogProbMetric: 393.8290 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 488/1000
2023-09-10 08:52:39.244 
Epoch 488/1000 
	 loss: 392.1318, MinusLogProbMetric: 392.1318, val_loss: 393.2490, val_MinusLogProbMetric: 393.2490

Epoch 488: val_loss improved from 393.42905 to 393.24902, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 392.1318 - MinusLogProbMetric: 392.1318 - val_loss: 393.2490 - val_MinusLogProbMetric: 393.2490 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 489/1000
2023-09-10 08:52:50.862 
Epoch 489/1000 
	 loss: 392.0560, MinusLogProbMetric: 392.0560, val_loss: 397.6601, val_MinusLogProbMetric: 397.6601

Epoch 489: val_loss did not improve from 393.24902
196/196 - 11s - loss: 392.0560 - MinusLogProbMetric: 392.0560 - val_loss: 397.6601 - val_MinusLogProbMetric: 397.6601 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 490/1000
2023-09-10 08:53:01.825 
Epoch 490/1000 
	 loss: 392.2298, MinusLogProbMetric: 392.2298, val_loss: 394.1427, val_MinusLogProbMetric: 394.1427

Epoch 490: val_loss did not improve from 393.24902
196/196 - 11s - loss: 392.2298 - MinusLogProbMetric: 392.2298 - val_loss: 394.1427 - val_MinusLogProbMetric: 394.1427 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 491/1000
2023-09-10 08:53:11.075 
Epoch 491/1000 
	 loss: 392.3773, MinusLogProbMetric: 392.3773, val_loss: 393.5339, val_MinusLogProbMetric: 393.5339

Epoch 491: val_loss did not improve from 393.24902
196/196 - 9s - loss: 392.3773 - MinusLogProbMetric: 392.3773 - val_loss: 393.5339 - val_MinusLogProbMetric: 393.5339 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 492/1000
2023-09-10 08:53:21.010 
Epoch 492/1000 
	 loss: 391.9659, MinusLogProbMetric: 391.9659, val_loss: 393.9482, val_MinusLogProbMetric: 393.9482

Epoch 492: val_loss did not improve from 393.24902
196/196 - 10s - loss: 391.9659 - MinusLogProbMetric: 391.9659 - val_loss: 393.9482 - val_MinusLogProbMetric: 393.9482 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 493/1000
2023-09-10 08:53:29.965 
Epoch 493/1000 
	 loss: 391.9945, MinusLogProbMetric: 391.9945, val_loss: 394.5901, val_MinusLogProbMetric: 394.5901

Epoch 493: val_loss did not improve from 393.24902
196/196 - 9s - loss: 391.9945 - MinusLogProbMetric: 391.9945 - val_loss: 394.5901 - val_MinusLogProbMetric: 394.5901 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 494/1000
2023-09-10 08:53:39.038 
Epoch 494/1000 
	 loss: 392.3747, MinusLogProbMetric: 392.3747, val_loss: 393.8216, val_MinusLogProbMetric: 393.8216

Epoch 494: val_loss did not improve from 393.24902
196/196 - 9s - loss: 392.3747 - MinusLogProbMetric: 392.3747 - val_loss: 393.8216 - val_MinusLogProbMetric: 393.8216 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 495/1000
2023-09-10 08:53:49.168 
Epoch 495/1000 
	 loss: 392.1040, MinusLogProbMetric: 392.1040, val_loss: 393.8451, val_MinusLogProbMetric: 393.8451

Epoch 495: val_loss did not improve from 393.24902
196/196 - 10s - loss: 392.1040 - MinusLogProbMetric: 392.1040 - val_loss: 393.8451 - val_MinusLogProbMetric: 393.8451 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 496/1000
2023-09-10 08:53:59.405 
Epoch 496/1000 
	 loss: 391.8748, MinusLogProbMetric: 391.8748, val_loss: 393.4599, val_MinusLogProbMetric: 393.4599

Epoch 496: val_loss did not improve from 393.24902
196/196 - 10s - loss: 391.8748 - MinusLogProbMetric: 391.8748 - val_loss: 393.4599 - val_MinusLogProbMetric: 393.4599 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 497/1000
2023-09-10 08:54:06.719 
Epoch 497/1000 
	 loss: 392.0822, MinusLogProbMetric: 392.0822, val_loss: 393.5663, val_MinusLogProbMetric: 393.5663

Epoch 497: val_loss did not improve from 393.24902
196/196 - 7s - loss: 392.0822 - MinusLogProbMetric: 392.0822 - val_loss: 393.5663 - val_MinusLogProbMetric: 393.5663 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 498/1000
2023-09-10 08:54:14.409 
Epoch 498/1000 
	 loss: 391.8255, MinusLogProbMetric: 391.8255, val_loss: 394.0949, val_MinusLogProbMetric: 394.0949

Epoch 498: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.8255 - MinusLogProbMetric: 391.8255 - val_loss: 394.0949 - val_MinusLogProbMetric: 394.0949 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 499/1000
2023-09-10 08:54:24.465 
Epoch 499/1000 
	 loss: 391.9045, MinusLogProbMetric: 391.9045, val_loss: 393.7954, val_MinusLogProbMetric: 393.7954

Epoch 499: val_loss did not improve from 393.24902
196/196 - 10s - loss: 391.9045 - MinusLogProbMetric: 391.9045 - val_loss: 393.7954 - val_MinusLogProbMetric: 393.7954 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 500/1000
2023-09-10 08:54:32.630 
Epoch 500/1000 
	 loss: 391.8896, MinusLogProbMetric: 391.8896, val_loss: 393.4238, val_MinusLogProbMetric: 393.4238

Epoch 500: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.8896 - MinusLogProbMetric: 391.8896 - val_loss: 393.4238 - val_MinusLogProbMetric: 393.4238 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 501/1000
2023-09-10 08:54:40.522 
Epoch 501/1000 
	 loss: 392.0237, MinusLogProbMetric: 392.0237, val_loss: 393.2800, val_MinusLogProbMetric: 393.2800

Epoch 501: val_loss did not improve from 393.24902
196/196 - 8s - loss: 392.0237 - MinusLogProbMetric: 392.0237 - val_loss: 393.2800 - val_MinusLogProbMetric: 393.2800 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 502/1000
2023-09-10 08:54:51.007 
Epoch 502/1000 
	 loss: 391.8174, MinusLogProbMetric: 391.8174, val_loss: 393.6273, val_MinusLogProbMetric: 393.6273

Epoch 502: val_loss did not improve from 393.24902
196/196 - 10s - loss: 391.8174 - MinusLogProbMetric: 391.8174 - val_loss: 393.6273 - val_MinusLogProbMetric: 393.6273 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 503/1000
2023-09-10 08:54:58.371 
Epoch 503/1000 
	 loss: 391.8701, MinusLogProbMetric: 391.8701, val_loss: 393.9657, val_MinusLogProbMetric: 393.9657

Epoch 503: val_loss did not improve from 393.24902
196/196 - 7s - loss: 391.8701 - MinusLogProbMetric: 391.8701 - val_loss: 393.9657 - val_MinusLogProbMetric: 393.9657 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 504/1000
2023-09-10 08:55:05.946 
Epoch 504/1000 
	 loss: 391.9025, MinusLogProbMetric: 391.9025, val_loss: 393.7092, val_MinusLogProbMetric: 393.7092

Epoch 504: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.9025 - MinusLogProbMetric: 391.9025 - val_loss: 393.7092 - val_MinusLogProbMetric: 393.7092 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 505/1000
2023-09-10 08:55:13.514 
Epoch 505/1000 
	 loss: 392.0772, MinusLogProbMetric: 392.0772, val_loss: 394.3122, val_MinusLogProbMetric: 394.3122

Epoch 505: val_loss did not improve from 393.24902
196/196 - 8s - loss: 392.0772 - MinusLogProbMetric: 392.0772 - val_loss: 394.3122 - val_MinusLogProbMetric: 394.3122 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 506/1000
2023-09-10 08:55:20.856 
Epoch 506/1000 
	 loss: 391.9113, MinusLogProbMetric: 391.9113, val_loss: 394.3158, val_MinusLogProbMetric: 394.3158

Epoch 506: val_loss did not improve from 393.24902
196/196 - 7s - loss: 391.9113 - MinusLogProbMetric: 391.9113 - val_loss: 394.3158 - val_MinusLogProbMetric: 394.3158 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 507/1000
2023-09-10 08:55:29.085 
Epoch 507/1000 
	 loss: 392.1056, MinusLogProbMetric: 392.1056, val_loss: 393.8134, val_MinusLogProbMetric: 393.8134

Epoch 507: val_loss did not improve from 393.24902
196/196 - 8s - loss: 392.1056 - MinusLogProbMetric: 392.1056 - val_loss: 393.8134 - val_MinusLogProbMetric: 393.8134 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 508/1000
2023-09-10 08:55:37.430 
Epoch 508/1000 
	 loss: 391.9497, MinusLogProbMetric: 391.9497, val_loss: 394.5034, val_MinusLogProbMetric: 394.5034

Epoch 508: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.9497 - MinusLogProbMetric: 391.9497 - val_loss: 394.5034 - val_MinusLogProbMetric: 394.5034 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 509/1000
2023-09-10 08:55:45.169 
Epoch 509/1000 
	 loss: 392.0477, MinusLogProbMetric: 392.0477, val_loss: 393.8825, val_MinusLogProbMetric: 393.8825

Epoch 509: val_loss did not improve from 393.24902
196/196 - 8s - loss: 392.0477 - MinusLogProbMetric: 392.0477 - val_loss: 393.8825 - val_MinusLogProbMetric: 393.8825 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 510/1000
2023-09-10 08:55:54.733 
Epoch 510/1000 
	 loss: 391.8281, MinusLogProbMetric: 391.8281, val_loss: 393.3853, val_MinusLogProbMetric: 393.3853

Epoch 510: val_loss did not improve from 393.24902
196/196 - 10s - loss: 391.8281 - MinusLogProbMetric: 391.8281 - val_loss: 393.3853 - val_MinusLogProbMetric: 393.3853 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 511/1000
2023-09-10 08:56:02.459 
Epoch 511/1000 
	 loss: 391.7253, MinusLogProbMetric: 391.7253, val_loss: 393.6496, val_MinusLogProbMetric: 393.6496

Epoch 511: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.7253 - MinusLogProbMetric: 391.7253 - val_loss: 393.6496 - val_MinusLogProbMetric: 393.6496 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 512/1000
2023-09-10 08:56:10.164 
Epoch 512/1000 
	 loss: 391.9112, MinusLogProbMetric: 391.9112, val_loss: 393.7281, val_MinusLogProbMetric: 393.7281

Epoch 512: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.9112 - MinusLogProbMetric: 391.9112 - val_loss: 393.7281 - val_MinusLogProbMetric: 393.7281 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 513/1000
2023-09-10 08:56:17.384 
Epoch 513/1000 
	 loss: 391.9776, MinusLogProbMetric: 391.9776, val_loss: 393.9351, val_MinusLogProbMetric: 393.9351

Epoch 513: val_loss did not improve from 393.24902
196/196 - 7s - loss: 391.9776 - MinusLogProbMetric: 391.9776 - val_loss: 393.9351 - val_MinusLogProbMetric: 393.9351 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 514/1000
2023-09-10 08:56:24.555 
Epoch 514/1000 
	 loss: 392.0816, MinusLogProbMetric: 392.0816, val_loss: 393.8565, val_MinusLogProbMetric: 393.8565

Epoch 514: val_loss did not improve from 393.24902
196/196 - 7s - loss: 392.0816 - MinusLogProbMetric: 392.0816 - val_loss: 393.8565 - val_MinusLogProbMetric: 393.8565 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 515/1000
2023-09-10 08:56:31.518 
Epoch 515/1000 
	 loss: 391.7503, MinusLogProbMetric: 391.7503, val_loss: 393.3621, val_MinusLogProbMetric: 393.3621

Epoch 515: val_loss did not improve from 393.24902
196/196 - 7s - loss: 391.7503 - MinusLogProbMetric: 391.7503 - val_loss: 393.3621 - val_MinusLogProbMetric: 393.3621 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 516/1000
2023-09-10 08:56:38.572 
Epoch 516/1000 
	 loss: 391.9615, MinusLogProbMetric: 391.9615, val_loss: 393.6409, val_MinusLogProbMetric: 393.6409

Epoch 516: val_loss did not improve from 393.24902
196/196 - 7s - loss: 391.9615 - MinusLogProbMetric: 391.9615 - val_loss: 393.6409 - val_MinusLogProbMetric: 393.6409 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 517/1000
2023-09-10 08:56:46.266 
Epoch 517/1000 
	 loss: 391.7183, MinusLogProbMetric: 391.7183, val_loss: 393.8891, val_MinusLogProbMetric: 393.8891

Epoch 517: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.7183 - MinusLogProbMetric: 391.7183 - val_loss: 393.8891 - val_MinusLogProbMetric: 393.8891 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 518/1000
2023-09-10 08:56:54.185 
Epoch 518/1000 
	 loss: 391.8977, MinusLogProbMetric: 391.8977, val_loss: 393.5520, val_MinusLogProbMetric: 393.5520

Epoch 518: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.8977 - MinusLogProbMetric: 391.8977 - val_loss: 393.5520 - val_MinusLogProbMetric: 393.5520 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 519/1000
2023-09-10 08:57:02.008 
Epoch 519/1000 
	 loss: 391.8545, MinusLogProbMetric: 391.8545, val_loss: 393.7274, val_MinusLogProbMetric: 393.7274

Epoch 519: val_loss did not improve from 393.24902
196/196 - 8s - loss: 391.8545 - MinusLogProbMetric: 391.8545 - val_loss: 393.7274 - val_MinusLogProbMetric: 393.7274 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 520/1000
2023-09-10 08:57:09.105 
Epoch 520/1000 
	 loss: 391.9831, MinusLogProbMetric: 391.9831, val_loss: 393.4957, val_MinusLogProbMetric: 393.4957

Epoch 520: val_loss did not improve from 393.24902
196/196 - 7s - loss: 391.9831 - MinusLogProbMetric: 391.9831 - val_loss: 393.4957 - val_MinusLogProbMetric: 393.4957 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 521/1000
2023-09-10 08:57:16.808 
Epoch 521/1000 
	 loss: 392.0119, MinusLogProbMetric: 392.0119, val_loss: 393.2159, val_MinusLogProbMetric: 393.2159

Epoch 521: val_loss improved from 393.24902 to 393.21591, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 392.0119 - MinusLogProbMetric: 392.0119 - val_loss: 393.2159 - val_MinusLogProbMetric: 393.2159 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 522/1000
2023-09-10 08:57:24.166 
Epoch 522/1000 
	 loss: 391.9385, MinusLogProbMetric: 391.9385, val_loss: 393.6102, val_MinusLogProbMetric: 393.6102

Epoch 522: val_loss did not improve from 393.21591
196/196 - 7s - loss: 391.9385 - MinusLogProbMetric: 391.9385 - val_loss: 393.6102 - val_MinusLogProbMetric: 393.6102 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 523/1000
2023-09-10 08:57:31.431 
Epoch 523/1000 
	 loss: 391.9601, MinusLogProbMetric: 391.9601, val_loss: 393.8293, val_MinusLogProbMetric: 393.8293

Epoch 523: val_loss did not improve from 393.21591
196/196 - 7s - loss: 391.9601 - MinusLogProbMetric: 391.9601 - val_loss: 393.8293 - val_MinusLogProbMetric: 393.8293 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 524/1000
2023-09-10 08:57:39.475 
Epoch 524/1000 
	 loss: 391.8345, MinusLogProbMetric: 391.8345, val_loss: 393.3053, val_MinusLogProbMetric: 393.3053

Epoch 524: val_loss did not improve from 393.21591
196/196 - 8s - loss: 391.8345 - MinusLogProbMetric: 391.8345 - val_loss: 393.3053 - val_MinusLogProbMetric: 393.3053 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 525/1000
2023-09-10 08:57:46.542 
Epoch 525/1000 
	 loss: 391.8670, MinusLogProbMetric: 391.8670, val_loss: 393.5988, val_MinusLogProbMetric: 393.5988

Epoch 525: val_loss did not improve from 393.21591
196/196 - 7s - loss: 391.8670 - MinusLogProbMetric: 391.8670 - val_loss: 393.5988 - val_MinusLogProbMetric: 393.5988 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 526/1000
2023-09-10 08:57:53.604 
Epoch 526/1000 
	 loss: 391.7545, MinusLogProbMetric: 391.7545, val_loss: 393.3750, val_MinusLogProbMetric: 393.3750

Epoch 526: val_loss did not improve from 393.21591
196/196 - 7s - loss: 391.7545 - MinusLogProbMetric: 391.7545 - val_loss: 393.3750 - val_MinusLogProbMetric: 393.3750 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 527/1000
2023-09-10 08:58:01.045 
Epoch 527/1000 
	 loss: 391.7742, MinusLogProbMetric: 391.7742, val_loss: 394.2396, val_MinusLogProbMetric: 394.2396

Epoch 527: val_loss did not improve from 393.21591
196/196 - 7s - loss: 391.7742 - MinusLogProbMetric: 391.7742 - val_loss: 394.2396 - val_MinusLogProbMetric: 394.2396 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 528/1000
2023-09-10 08:58:08.576 
Epoch 528/1000 
	 loss: 391.8254, MinusLogProbMetric: 391.8254, val_loss: 393.3914, val_MinusLogProbMetric: 393.3914

Epoch 528: val_loss did not improve from 393.21591
196/196 - 8s - loss: 391.8254 - MinusLogProbMetric: 391.8254 - val_loss: 393.3914 - val_MinusLogProbMetric: 393.3914 - lr: 1.6667e-04 - 8s/epoch - 38ms/step
Epoch 529/1000
2023-09-10 08:58:15.527 
Epoch 529/1000 
	 loss: 391.7425, MinusLogProbMetric: 391.7425, val_loss: 393.9253, val_MinusLogProbMetric: 393.9253

Epoch 529: val_loss did not improve from 393.21591
196/196 - 7s - loss: 391.7425 - MinusLogProbMetric: 391.7425 - val_loss: 393.9253 - val_MinusLogProbMetric: 393.9253 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 530/1000
2023-09-10 08:58:22.325 
Epoch 530/1000 
	 loss: 391.7742, MinusLogProbMetric: 391.7742, val_loss: 394.0054, val_MinusLogProbMetric: 394.0054

Epoch 530: val_loss did not improve from 393.21591
196/196 - 7s - loss: 391.7742 - MinusLogProbMetric: 391.7742 - val_loss: 394.0054 - val_MinusLogProbMetric: 394.0054 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 531/1000
2023-09-10 08:58:31.609 
Epoch 531/1000 
	 loss: 391.6582, MinusLogProbMetric: 391.6582, val_loss: 393.6657, val_MinusLogProbMetric: 393.6657

Epoch 531: val_loss did not improve from 393.21591
196/196 - 9s - loss: 391.6582 - MinusLogProbMetric: 391.6582 - val_loss: 393.6657 - val_MinusLogProbMetric: 393.6657 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 532/1000
2023-09-10 08:58:42.549 
Epoch 532/1000 
	 loss: 392.0206, MinusLogProbMetric: 392.0206, val_loss: 393.8415, val_MinusLogProbMetric: 393.8415

Epoch 532: val_loss did not improve from 393.21591
196/196 - 11s - loss: 392.0206 - MinusLogProbMetric: 392.0206 - val_loss: 393.8415 - val_MinusLogProbMetric: 393.8415 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 533/1000
2023-09-10 08:58:52.217 
Epoch 533/1000 
	 loss: 391.6625, MinusLogProbMetric: 391.6625, val_loss: 393.1965, val_MinusLogProbMetric: 393.1965

Epoch 533: val_loss improved from 393.21591 to 393.19647, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 391.6625 - MinusLogProbMetric: 391.6625 - val_loss: 393.1965 - val_MinusLogProbMetric: 393.1965 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 534/1000
2023-09-10 08:59:02.129 
Epoch 534/1000 
	 loss: 391.6907, MinusLogProbMetric: 391.6907, val_loss: 393.7188, val_MinusLogProbMetric: 393.7188

Epoch 534: val_loss did not improve from 393.19647
196/196 - 10s - loss: 391.6907 - MinusLogProbMetric: 391.6907 - val_loss: 393.7188 - val_MinusLogProbMetric: 393.7188 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 535/1000
2023-09-10 08:59:11.284 
Epoch 535/1000 
	 loss: 392.1020, MinusLogProbMetric: 392.1020, val_loss: 393.3975, val_MinusLogProbMetric: 393.3975

Epoch 535: val_loss did not improve from 393.19647
196/196 - 9s - loss: 392.1020 - MinusLogProbMetric: 392.1020 - val_loss: 393.3975 - val_MinusLogProbMetric: 393.3975 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 536/1000
2023-09-10 08:59:18.863 
Epoch 536/1000 
	 loss: 391.7906, MinusLogProbMetric: 391.7906, val_loss: 393.6688, val_MinusLogProbMetric: 393.6688

Epoch 536: val_loss did not improve from 393.19647
196/196 - 8s - loss: 391.7906 - MinusLogProbMetric: 391.7906 - val_loss: 393.6688 - val_MinusLogProbMetric: 393.6688 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 537/1000
2023-09-10 08:59:27.568 
Epoch 537/1000 
	 loss: 391.8179, MinusLogProbMetric: 391.8179, val_loss: 394.1837, val_MinusLogProbMetric: 394.1837

Epoch 537: val_loss did not improve from 393.19647
196/196 - 9s - loss: 391.8179 - MinusLogProbMetric: 391.8179 - val_loss: 394.1837 - val_MinusLogProbMetric: 394.1837 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 538/1000
2023-09-10 08:59:34.768 
Epoch 538/1000 
	 loss: 391.9494, MinusLogProbMetric: 391.9494, val_loss: 394.0623, val_MinusLogProbMetric: 394.0623

Epoch 538: val_loss did not improve from 393.19647
196/196 - 7s - loss: 391.9494 - MinusLogProbMetric: 391.9494 - val_loss: 394.0623 - val_MinusLogProbMetric: 394.0623 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 539/1000
2023-09-10 08:59:42.292 
Epoch 539/1000 
	 loss: 391.8818, MinusLogProbMetric: 391.8818, val_loss: 393.5689, val_MinusLogProbMetric: 393.5689

Epoch 539: val_loss did not improve from 393.19647
196/196 - 8s - loss: 391.8818 - MinusLogProbMetric: 391.8818 - val_loss: 393.5689 - val_MinusLogProbMetric: 393.5689 - lr: 1.6667e-04 - 8s/epoch - 38ms/step
Epoch 540/1000
2023-09-10 08:59:50.728 
Epoch 540/1000 
	 loss: 391.6456, MinusLogProbMetric: 391.6456, val_loss: 394.2465, val_MinusLogProbMetric: 394.2465

Epoch 540: val_loss did not improve from 393.19647
196/196 - 8s - loss: 391.6456 - MinusLogProbMetric: 391.6456 - val_loss: 394.2465 - val_MinusLogProbMetric: 394.2465 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 541/1000
2023-09-10 09:00:01.039 
Epoch 541/1000 
	 loss: 391.6982, MinusLogProbMetric: 391.6982, val_loss: 393.8502, val_MinusLogProbMetric: 393.8502

Epoch 541: val_loss did not improve from 393.19647
196/196 - 10s - loss: 391.6982 - MinusLogProbMetric: 391.6982 - val_loss: 393.8502 - val_MinusLogProbMetric: 393.8502 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 542/1000
2023-09-10 09:00:08.806 
Epoch 542/1000 
	 loss: 391.6364, MinusLogProbMetric: 391.6364, val_loss: 393.3391, val_MinusLogProbMetric: 393.3391

Epoch 542: val_loss did not improve from 393.19647
196/196 - 8s - loss: 391.6364 - MinusLogProbMetric: 391.6364 - val_loss: 393.3391 - val_MinusLogProbMetric: 393.3391 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 543/1000
2023-09-10 09:00:16.969 
Epoch 543/1000 
	 loss: 391.8338, MinusLogProbMetric: 391.8338, val_loss: 393.5043, val_MinusLogProbMetric: 393.5043

Epoch 543: val_loss did not improve from 393.19647
196/196 - 8s - loss: 391.8338 - MinusLogProbMetric: 391.8338 - val_loss: 393.5043 - val_MinusLogProbMetric: 393.5043 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 544/1000
2023-09-10 09:00:24.144 
Epoch 544/1000 
	 loss: 391.7172, MinusLogProbMetric: 391.7172, val_loss: 394.6689, val_MinusLogProbMetric: 394.6689

Epoch 544: val_loss did not improve from 393.19647
196/196 - 7s - loss: 391.7172 - MinusLogProbMetric: 391.7172 - val_loss: 394.6689 - val_MinusLogProbMetric: 394.6689 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 545/1000
2023-09-10 09:00:32.467 
Epoch 545/1000 
	 loss: 391.6742, MinusLogProbMetric: 391.6742, val_loss: 393.7107, val_MinusLogProbMetric: 393.7107

Epoch 545: val_loss did not improve from 393.19647
196/196 - 8s - loss: 391.6742 - MinusLogProbMetric: 391.6742 - val_loss: 393.7107 - val_MinusLogProbMetric: 393.7107 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 546/1000
2023-09-10 09:00:39.382 
Epoch 546/1000 
	 loss: 391.7502, MinusLogProbMetric: 391.7502, val_loss: 393.2457, val_MinusLogProbMetric: 393.2457

Epoch 546: val_loss did not improve from 393.19647
196/196 - 7s - loss: 391.7502 - MinusLogProbMetric: 391.7502 - val_loss: 393.2457 - val_MinusLogProbMetric: 393.2457 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 547/1000
2023-09-10 09:00:46.330 
Epoch 547/1000 
	 loss: 391.5574, MinusLogProbMetric: 391.5574, val_loss: 394.5842, val_MinusLogProbMetric: 394.5842

Epoch 547: val_loss did not improve from 393.19647
196/196 - 7s - loss: 391.5574 - MinusLogProbMetric: 391.5574 - val_loss: 394.5842 - val_MinusLogProbMetric: 394.5842 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 548/1000
2023-09-10 09:00:55.100 
Epoch 548/1000 
	 loss: 391.7891, MinusLogProbMetric: 391.7891, val_loss: 393.2087, val_MinusLogProbMetric: 393.2087

Epoch 548: val_loss did not improve from 393.19647
196/196 - 9s - loss: 391.7891 - MinusLogProbMetric: 391.7891 - val_loss: 393.2087 - val_MinusLogProbMetric: 393.2087 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 549/1000
2023-09-10 09:01:02.138 
Epoch 549/1000 
	 loss: 391.6606, MinusLogProbMetric: 391.6606, val_loss: 393.0740, val_MinusLogProbMetric: 393.0740

Epoch 549: val_loss improved from 393.19647 to 393.07397, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 391.6606 - MinusLogProbMetric: 391.6606 - val_loss: 393.0740 - val_MinusLogProbMetric: 393.0740 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 550/1000
2023-09-10 09:01:12.974 
Epoch 550/1000 
	 loss: 391.6876, MinusLogProbMetric: 391.6876, val_loss: 393.0586, val_MinusLogProbMetric: 393.0586

Epoch 550: val_loss improved from 393.07397 to 393.05859, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 391.6876 - MinusLogProbMetric: 391.6876 - val_loss: 393.0586 - val_MinusLogProbMetric: 393.0586 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 551/1000
2023-09-10 09:01:20.930 
Epoch 551/1000 
	 loss: 391.6401, MinusLogProbMetric: 391.6401, val_loss: 393.7920, val_MinusLogProbMetric: 393.7920

Epoch 551: val_loss did not improve from 393.05859
196/196 - 8s - loss: 391.6401 - MinusLogProbMetric: 391.6401 - val_loss: 393.7920 - val_MinusLogProbMetric: 393.7920 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 552/1000
2023-09-10 09:01:29.125 
Epoch 552/1000 
	 loss: 391.6099, MinusLogProbMetric: 391.6099, val_loss: 395.9442, val_MinusLogProbMetric: 395.9442

Epoch 552: val_loss did not improve from 393.05859
196/196 - 8s - loss: 391.6099 - MinusLogProbMetric: 391.6099 - val_loss: 395.9442 - val_MinusLogProbMetric: 395.9442 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 553/1000
2023-09-10 09:01:36.323 
Epoch 553/1000 
	 loss: 391.7372, MinusLogProbMetric: 391.7372, val_loss: 393.1080, val_MinusLogProbMetric: 393.1080

Epoch 553: val_loss did not improve from 393.05859
196/196 - 7s - loss: 391.7372 - MinusLogProbMetric: 391.7372 - val_loss: 393.1080 - val_MinusLogProbMetric: 393.1080 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 554/1000
2023-09-10 09:01:46.103 
Epoch 554/1000 
	 loss: 391.6343, MinusLogProbMetric: 391.6343, val_loss: 394.2575, val_MinusLogProbMetric: 394.2575

Epoch 554: val_loss did not improve from 393.05859
196/196 - 10s - loss: 391.6343 - MinusLogProbMetric: 391.6343 - val_loss: 394.2575 - val_MinusLogProbMetric: 394.2575 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 555/1000
2023-09-10 09:01:56.448 
Epoch 555/1000 
	 loss: 391.8222, MinusLogProbMetric: 391.8222, val_loss: 393.4844, val_MinusLogProbMetric: 393.4844

Epoch 555: val_loss did not improve from 393.05859
196/196 - 10s - loss: 391.8222 - MinusLogProbMetric: 391.8222 - val_loss: 393.4844 - val_MinusLogProbMetric: 393.4844 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 556/1000
2023-09-10 09:02:06.217 
Epoch 556/1000 
	 loss: 391.6801, MinusLogProbMetric: 391.6801, val_loss: 393.2871, val_MinusLogProbMetric: 393.2871

Epoch 556: val_loss did not improve from 393.05859
196/196 - 10s - loss: 391.6801 - MinusLogProbMetric: 391.6801 - val_loss: 393.2871 - val_MinusLogProbMetric: 393.2871 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 557/1000
2023-09-10 09:02:18.182 
Epoch 557/1000 
	 loss: 391.7042, MinusLogProbMetric: 391.7042, val_loss: 393.1909, val_MinusLogProbMetric: 393.1909

Epoch 557: val_loss did not improve from 393.05859
196/196 - 12s - loss: 391.7042 - MinusLogProbMetric: 391.7042 - val_loss: 393.1909 - val_MinusLogProbMetric: 393.1909 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 558/1000
2023-09-10 09:02:29.200 
Epoch 558/1000 
	 loss: 391.6014, MinusLogProbMetric: 391.6014, val_loss: 393.1113, val_MinusLogProbMetric: 393.1113

Epoch 558: val_loss did not improve from 393.05859
196/196 - 11s - loss: 391.6014 - MinusLogProbMetric: 391.6014 - val_loss: 393.1113 - val_MinusLogProbMetric: 393.1113 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 559/1000
2023-09-10 09:02:37.486 
Epoch 559/1000 
	 loss: 391.5560, MinusLogProbMetric: 391.5560, val_loss: 393.3962, val_MinusLogProbMetric: 393.3962

Epoch 559: val_loss did not improve from 393.05859
196/196 - 8s - loss: 391.5560 - MinusLogProbMetric: 391.5560 - val_loss: 393.3962 - val_MinusLogProbMetric: 393.3962 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 560/1000
2023-09-10 09:02:47.853 
Epoch 560/1000 
	 loss: 391.4541, MinusLogProbMetric: 391.4541, val_loss: 393.5752, val_MinusLogProbMetric: 393.5752

Epoch 560: val_loss did not improve from 393.05859
196/196 - 10s - loss: 391.4541 - MinusLogProbMetric: 391.4541 - val_loss: 393.5752 - val_MinusLogProbMetric: 393.5752 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 561/1000
2023-09-10 09:02:55.513 
Epoch 561/1000 
	 loss: 391.6463, MinusLogProbMetric: 391.6463, val_loss: 393.4713, val_MinusLogProbMetric: 393.4713

Epoch 561: val_loss did not improve from 393.05859
196/196 - 8s - loss: 391.6463 - MinusLogProbMetric: 391.6463 - val_loss: 393.4713 - val_MinusLogProbMetric: 393.4713 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 562/1000
2023-09-10 09:03:04.774 
Epoch 562/1000 
	 loss: 391.5430, MinusLogProbMetric: 391.5430, val_loss: 393.0767, val_MinusLogProbMetric: 393.0767

Epoch 562: val_loss did not improve from 393.05859
196/196 - 9s - loss: 391.5430 - MinusLogProbMetric: 391.5430 - val_loss: 393.0767 - val_MinusLogProbMetric: 393.0767 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 563/1000
2023-09-10 09:03:12.876 
Epoch 563/1000 
	 loss: 391.5799, MinusLogProbMetric: 391.5799, val_loss: 393.6536, val_MinusLogProbMetric: 393.6536

Epoch 563: val_loss did not improve from 393.05859
196/196 - 8s - loss: 391.5799 - MinusLogProbMetric: 391.5799 - val_loss: 393.6536 - val_MinusLogProbMetric: 393.6536 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 564/1000
2023-09-10 09:03:21.644 
Epoch 564/1000 
	 loss: 391.6534, MinusLogProbMetric: 391.6534, val_loss: 392.9225, val_MinusLogProbMetric: 392.9225

Epoch 564: val_loss improved from 393.05859 to 392.92245, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 391.6534 - MinusLogProbMetric: 391.6534 - val_loss: 392.9225 - val_MinusLogProbMetric: 392.9225 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 565/1000
2023-09-10 09:03:30.043 
Epoch 565/1000 
	 loss: 391.6338, MinusLogProbMetric: 391.6338, val_loss: 393.0857, val_MinusLogProbMetric: 393.0857

Epoch 565: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.6338 - MinusLogProbMetric: 391.6338 - val_loss: 393.0857 - val_MinusLogProbMetric: 393.0857 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 566/1000
2023-09-10 09:03:39.449 
Epoch 566/1000 
	 loss: 391.6344, MinusLogProbMetric: 391.6344, val_loss: 393.6430, val_MinusLogProbMetric: 393.6430

Epoch 566: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.6344 - MinusLogProbMetric: 391.6344 - val_loss: 393.6430 - val_MinusLogProbMetric: 393.6430 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 567/1000
2023-09-10 09:03:48.025 
Epoch 567/1000 
	 loss: 391.5975, MinusLogProbMetric: 391.5975, val_loss: 393.2995, val_MinusLogProbMetric: 393.2995

Epoch 567: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.5975 - MinusLogProbMetric: 391.5975 - val_loss: 393.2995 - val_MinusLogProbMetric: 393.2995 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 568/1000
2023-09-10 09:03:56.928 
Epoch 568/1000 
	 loss: 391.6065, MinusLogProbMetric: 391.6065, val_loss: 393.2433, val_MinusLogProbMetric: 393.2433

Epoch 568: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.6065 - MinusLogProbMetric: 391.6065 - val_loss: 393.2433 - val_MinusLogProbMetric: 393.2433 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 569/1000
2023-09-10 09:04:03.817 
Epoch 569/1000 
	 loss: 391.7150, MinusLogProbMetric: 391.7150, val_loss: 393.3953, val_MinusLogProbMetric: 393.3953

Epoch 569: val_loss did not improve from 392.92245
196/196 - 7s - loss: 391.7150 - MinusLogProbMetric: 391.7150 - val_loss: 393.3953 - val_MinusLogProbMetric: 393.3953 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 570/1000
2023-09-10 09:04:13.216 
Epoch 570/1000 
	 loss: 391.4989, MinusLogProbMetric: 391.4989, val_loss: 393.2888, val_MinusLogProbMetric: 393.2888

Epoch 570: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.4989 - MinusLogProbMetric: 391.4989 - val_loss: 393.2888 - val_MinusLogProbMetric: 393.2888 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 571/1000
2023-09-10 09:04:22.331 
Epoch 571/1000 
	 loss: 391.6492, MinusLogProbMetric: 391.6492, val_loss: 393.4760, val_MinusLogProbMetric: 393.4760

Epoch 571: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.6492 - MinusLogProbMetric: 391.6492 - val_loss: 393.4760 - val_MinusLogProbMetric: 393.4760 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 572/1000
2023-09-10 09:04:30.468 
Epoch 572/1000 
	 loss: 391.6640, MinusLogProbMetric: 391.6640, val_loss: 393.2677, val_MinusLogProbMetric: 393.2677

Epoch 572: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.6640 - MinusLogProbMetric: 391.6640 - val_loss: 393.2677 - val_MinusLogProbMetric: 393.2677 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 573/1000
2023-09-10 09:04:38.356 
Epoch 573/1000 
	 loss: 391.5318, MinusLogProbMetric: 391.5318, val_loss: 393.1590, val_MinusLogProbMetric: 393.1590

Epoch 573: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.5318 - MinusLogProbMetric: 391.5318 - val_loss: 393.1590 - val_MinusLogProbMetric: 393.1590 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 574/1000
2023-09-10 09:04:48.130 
Epoch 574/1000 
	 loss: 391.7084, MinusLogProbMetric: 391.7084, val_loss: 393.6682, val_MinusLogProbMetric: 393.6682

Epoch 574: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.7084 - MinusLogProbMetric: 391.7084 - val_loss: 393.6682 - val_MinusLogProbMetric: 393.6682 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 575/1000
2023-09-10 09:04:55.988 
Epoch 575/1000 
	 loss: 391.6153, MinusLogProbMetric: 391.6153, val_loss: 393.7014, val_MinusLogProbMetric: 393.7014

Epoch 575: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.6153 - MinusLogProbMetric: 391.6153 - val_loss: 393.7014 - val_MinusLogProbMetric: 393.7014 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 576/1000
2023-09-10 09:05:03.929 
Epoch 576/1000 
	 loss: 391.7006, MinusLogProbMetric: 391.7006, val_loss: 393.1215, val_MinusLogProbMetric: 393.1215

Epoch 576: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.7006 - MinusLogProbMetric: 391.7006 - val_loss: 393.1215 - val_MinusLogProbMetric: 393.1215 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 577/1000
2023-09-10 09:05:12.935 
Epoch 577/1000 
	 loss: 391.3700, MinusLogProbMetric: 391.3700, val_loss: 393.2615, val_MinusLogProbMetric: 393.2615

Epoch 577: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.3700 - MinusLogProbMetric: 391.3700 - val_loss: 393.2615 - val_MinusLogProbMetric: 393.2615 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 578/1000
2023-09-10 09:05:19.713 
Epoch 578/1000 
	 loss: 391.6904, MinusLogProbMetric: 391.6904, val_loss: 393.4665, val_MinusLogProbMetric: 393.4665

Epoch 578: val_loss did not improve from 392.92245
196/196 - 7s - loss: 391.6904 - MinusLogProbMetric: 391.6904 - val_loss: 393.4665 - val_MinusLogProbMetric: 393.4665 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 579/1000
2023-09-10 09:05:28.656 
Epoch 579/1000 
	 loss: 391.3383, MinusLogProbMetric: 391.3383, val_loss: 393.2676, val_MinusLogProbMetric: 393.2676

Epoch 579: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.3383 - MinusLogProbMetric: 391.3383 - val_loss: 393.2676 - val_MinusLogProbMetric: 393.2676 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 580/1000
2023-09-10 09:05:36.411 
Epoch 580/1000 
	 loss: 391.3743, MinusLogProbMetric: 391.3743, val_loss: 393.4290, val_MinusLogProbMetric: 393.4290

Epoch 580: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.3743 - MinusLogProbMetric: 391.3743 - val_loss: 393.4290 - val_MinusLogProbMetric: 393.4290 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 581/1000
2023-09-10 09:05:45.685 
Epoch 581/1000 
	 loss: 391.4654, MinusLogProbMetric: 391.4654, val_loss: 393.1097, val_MinusLogProbMetric: 393.1097

Epoch 581: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.4654 - MinusLogProbMetric: 391.4654 - val_loss: 393.1097 - val_MinusLogProbMetric: 393.1097 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 582/1000
2023-09-10 09:05:53.743 
Epoch 582/1000 
	 loss: 391.4218, MinusLogProbMetric: 391.4218, val_loss: 393.1742, val_MinusLogProbMetric: 393.1742

Epoch 582: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.4218 - MinusLogProbMetric: 391.4218 - val_loss: 393.1742 - val_MinusLogProbMetric: 393.1742 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 583/1000
2023-09-10 09:06:02.667 
Epoch 583/1000 
	 loss: 391.5909, MinusLogProbMetric: 391.5909, val_loss: 393.4375, val_MinusLogProbMetric: 393.4375

Epoch 583: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.5909 - MinusLogProbMetric: 391.5909 - val_loss: 393.4375 - val_MinusLogProbMetric: 393.4375 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 584/1000
2023-09-10 09:06:10.602 
Epoch 584/1000 
	 loss: 391.4897, MinusLogProbMetric: 391.4897, val_loss: 393.0627, val_MinusLogProbMetric: 393.0627

Epoch 584: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.4897 - MinusLogProbMetric: 391.4897 - val_loss: 393.0627 - val_MinusLogProbMetric: 393.0627 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 585/1000
2023-09-10 09:06:17.767 
Epoch 585/1000 
	 loss: 391.5583, MinusLogProbMetric: 391.5583, val_loss: 393.2791, val_MinusLogProbMetric: 393.2791

Epoch 585: val_loss did not improve from 392.92245
196/196 - 7s - loss: 391.5583 - MinusLogProbMetric: 391.5583 - val_loss: 393.2791 - val_MinusLogProbMetric: 393.2791 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 586/1000
2023-09-10 09:06:26.951 
Epoch 586/1000 
	 loss: 391.4667, MinusLogProbMetric: 391.4667, val_loss: 394.1067, val_MinusLogProbMetric: 394.1067

Epoch 586: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.4667 - MinusLogProbMetric: 391.4667 - val_loss: 394.1067 - val_MinusLogProbMetric: 394.1067 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 587/1000
2023-09-10 09:06:33.849 
Epoch 587/1000 
	 loss: 391.5648, MinusLogProbMetric: 391.5648, val_loss: 392.9405, val_MinusLogProbMetric: 392.9405

Epoch 587: val_loss did not improve from 392.92245
196/196 - 7s - loss: 391.5648 - MinusLogProbMetric: 391.5648 - val_loss: 392.9405 - val_MinusLogProbMetric: 392.9405 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 588/1000
2023-09-10 09:06:46.050 
Epoch 588/1000 
	 loss: 391.7944, MinusLogProbMetric: 391.7944, val_loss: 393.1164, val_MinusLogProbMetric: 393.1164

Epoch 588: val_loss did not improve from 392.92245
196/196 - 12s - loss: 391.7944 - MinusLogProbMetric: 391.7944 - val_loss: 393.1164 - val_MinusLogProbMetric: 393.1164 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 589/1000
2023-09-10 09:06:55.726 
Epoch 589/1000 
	 loss: 391.5246, MinusLogProbMetric: 391.5246, val_loss: 393.6930, val_MinusLogProbMetric: 393.6930

Epoch 589: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.5246 - MinusLogProbMetric: 391.5246 - val_loss: 393.6930 - val_MinusLogProbMetric: 393.6930 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 590/1000
2023-09-10 09:07:03.119 
Epoch 590/1000 
	 loss: 391.4424, MinusLogProbMetric: 391.4424, val_loss: 393.2491, val_MinusLogProbMetric: 393.2491

Epoch 590: val_loss did not improve from 392.92245
196/196 - 7s - loss: 391.4424 - MinusLogProbMetric: 391.4424 - val_loss: 393.2491 - val_MinusLogProbMetric: 393.2491 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 591/1000
2023-09-10 09:07:14.714 
Epoch 591/1000 
	 loss: 391.4725, MinusLogProbMetric: 391.4725, val_loss: 394.4428, val_MinusLogProbMetric: 394.4428

Epoch 591: val_loss did not improve from 392.92245
196/196 - 12s - loss: 391.4725 - MinusLogProbMetric: 391.4725 - val_loss: 394.4428 - val_MinusLogProbMetric: 394.4428 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 592/1000
2023-09-10 09:07:22.071 
Epoch 592/1000 
	 loss: 391.4995, MinusLogProbMetric: 391.4995, val_loss: 394.0945, val_MinusLogProbMetric: 394.0945

Epoch 592: val_loss did not improve from 392.92245
196/196 - 7s - loss: 391.4995 - MinusLogProbMetric: 391.4995 - val_loss: 394.0945 - val_MinusLogProbMetric: 394.0945 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 593/1000
2023-09-10 09:07:33.397 
Epoch 593/1000 
	 loss: 391.3749, MinusLogProbMetric: 391.3749, val_loss: 393.3209, val_MinusLogProbMetric: 393.3209

Epoch 593: val_loss did not improve from 392.92245
196/196 - 11s - loss: 391.3749 - MinusLogProbMetric: 391.3749 - val_loss: 393.3209 - val_MinusLogProbMetric: 393.3209 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 594/1000
2023-09-10 09:07:42.546 
Epoch 594/1000 
	 loss: 391.4876, MinusLogProbMetric: 391.4876, val_loss: 393.9281, val_MinusLogProbMetric: 393.9281

Epoch 594: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.4876 - MinusLogProbMetric: 391.4876 - val_loss: 393.9281 - val_MinusLogProbMetric: 393.9281 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 595/1000
2023-09-10 09:07:51.500 
Epoch 595/1000 
	 loss: 391.3076, MinusLogProbMetric: 391.3076, val_loss: 393.5850, val_MinusLogProbMetric: 393.5850

Epoch 595: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.3076 - MinusLogProbMetric: 391.3076 - val_loss: 393.5850 - val_MinusLogProbMetric: 393.5850 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 596/1000
2023-09-10 09:08:02.638 
Epoch 596/1000 
	 loss: 391.4631, MinusLogProbMetric: 391.4631, val_loss: 393.0797, val_MinusLogProbMetric: 393.0797

Epoch 596: val_loss did not improve from 392.92245
196/196 - 11s - loss: 391.4631 - MinusLogProbMetric: 391.4631 - val_loss: 393.0797 - val_MinusLogProbMetric: 393.0797 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 597/1000
2023-09-10 09:08:12.619 
Epoch 597/1000 
	 loss: 391.4892, MinusLogProbMetric: 391.4892, val_loss: 393.1360, val_MinusLogProbMetric: 393.1360

Epoch 597: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.4892 - MinusLogProbMetric: 391.4892 - val_loss: 393.1360 - val_MinusLogProbMetric: 393.1360 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 598/1000
2023-09-10 09:08:21.698 
Epoch 598/1000 
	 loss: 391.5434, MinusLogProbMetric: 391.5434, val_loss: 393.0630, val_MinusLogProbMetric: 393.0630

Epoch 598: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.5434 - MinusLogProbMetric: 391.5434 - val_loss: 393.0630 - val_MinusLogProbMetric: 393.0630 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 599/1000
2023-09-10 09:08:31.273 
Epoch 599/1000 
	 loss: 391.6664, MinusLogProbMetric: 391.6664, val_loss: 393.2694, val_MinusLogProbMetric: 393.2694

Epoch 599: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.6664 - MinusLogProbMetric: 391.6664 - val_loss: 393.2694 - val_MinusLogProbMetric: 393.2694 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 600/1000
2023-09-10 09:08:40.998 
Epoch 600/1000 
	 loss: 391.4406, MinusLogProbMetric: 391.4406, val_loss: 393.2743, val_MinusLogProbMetric: 393.2743

Epoch 600: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.4406 - MinusLogProbMetric: 391.4406 - val_loss: 393.2743 - val_MinusLogProbMetric: 393.2743 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 601/1000
2023-09-10 09:08:51.064 
Epoch 601/1000 
	 loss: 391.3552, MinusLogProbMetric: 391.3552, val_loss: 393.2505, val_MinusLogProbMetric: 393.2505

Epoch 601: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.3552 - MinusLogProbMetric: 391.3552 - val_loss: 393.2505 - val_MinusLogProbMetric: 393.2505 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 602/1000
2023-09-10 09:09:01.168 
Epoch 602/1000 
	 loss: 391.2223, MinusLogProbMetric: 391.2223, val_loss: 393.4538, val_MinusLogProbMetric: 393.4538

Epoch 602: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.2223 - MinusLogProbMetric: 391.2223 - val_loss: 393.4538 - val_MinusLogProbMetric: 393.4538 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 603/1000
2023-09-10 09:09:10.525 
Epoch 603/1000 
	 loss: 391.2455, MinusLogProbMetric: 391.2455, val_loss: 393.3205, val_MinusLogProbMetric: 393.3205

Epoch 603: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.2455 - MinusLogProbMetric: 391.2455 - val_loss: 393.3205 - val_MinusLogProbMetric: 393.3205 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 604/1000
2023-09-10 09:09:21.173 
Epoch 604/1000 
	 loss: 391.3611, MinusLogProbMetric: 391.3611, val_loss: 393.7357, val_MinusLogProbMetric: 393.7357

Epoch 604: val_loss did not improve from 392.92245
196/196 - 11s - loss: 391.3611 - MinusLogProbMetric: 391.3611 - val_loss: 393.7357 - val_MinusLogProbMetric: 393.7357 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 605/1000
2023-09-10 09:09:31.365 
Epoch 605/1000 
	 loss: 391.6225, MinusLogProbMetric: 391.6225, val_loss: 393.2790, val_MinusLogProbMetric: 393.2790

Epoch 605: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.6225 - MinusLogProbMetric: 391.6225 - val_loss: 393.2790 - val_MinusLogProbMetric: 393.2790 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 606/1000
2023-09-10 09:09:40.858 
Epoch 606/1000 
	 loss: 391.4383, MinusLogProbMetric: 391.4383, val_loss: 393.1311, val_MinusLogProbMetric: 393.1311

Epoch 606: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.4383 - MinusLogProbMetric: 391.4383 - val_loss: 393.1311 - val_MinusLogProbMetric: 393.1311 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 607/1000
2023-09-10 09:09:51.725 
Epoch 607/1000 
	 loss: 391.5126, MinusLogProbMetric: 391.5126, val_loss: 393.7961, val_MinusLogProbMetric: 393.7961

Epoch 607: val_loss did not improve from 392.92245
196/196 - 11s - loss: 391.5126 - MinusLogProbMetric: 391.5126 - val_loss: 393.7961 - val_MinusLogProbMetric: 393.7961 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 608/1000
2023-09-10 09:10:00.535 
Epoch 608/1000 
	 loss: 391.5095, MinusLogProbMetric: 391.5095, val_loss: 393.0834, val_MinusLogProbMetric: 393.0834

Epoch 608: val_loss did not improve from 392.92245
196/196 - 9s - loss: 391.5095 - MinusLogProbMetric: 391.5095 - val_loss: 393.0834 - val_MinusLogProbMetric: 393.0834 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 609/1000
2023-09-10 09:10:11.365 
Epoch 609/1000 
	 loss: 391.2521, MinusLogProbMetric: 391.2521, val_loss: 393.1137, val_MinusLogProbMetric: 393.1137

Epoch 609: val_loss did not improve from 392.92245
196/196 - 11s - loss: 391.2521 - MinusLogProbMetric: 391.2521 - val_loss: 393.1137 - val_MinusLogProbMetric: 393.1137 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 610/1000
2023-09-10 09:10:19.622 
Epoch 610/1000 
	 loss: 391.2177, MinusLogProbMetric: 391.2177, val_loss: 393.3183, val_MinusLogProbMetric: 393.3183

Epoch 610: val_loss did not improve from 392.92245
196/196 - 8s - loss: 391.2177 - MinusLogProbMetric: 391.2177 - val_loss: 393.3183 - val_MinusLogProbMetric: 393.3183 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 611/1000
2023-09-10 09:10:29.698 
Epoch 611/1000 
	 loss: 391.2190, MinusLogProbMetric: 391.2190, val_loss: 392.9971, val_MinusLogProbMetric: 392.9971

Epoch 611: val_loss did not improve from 392.92245
196/196 - 10s - loss: 391.2190 - MinusLogProbMetric: 391.2190 - val_loss: 392.9971 - val_MinusLogProbMetric: 392.9971 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 612/1000
2023-09-10 09:10:39.463 
Epoch 612/1000 
	 loss: 391.3274, MinusLogProbMetric: 391.3274, val_loss: 392.8391, val_MinusLogProbMetric: 392.8391

Epoch 612: val_loss improved from 392.92245 to 392.83911, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 391.3274 - MinusLogProbMetric: 391.3274 - val_loss: 392.8391 - val_MinusLogProbMetric: 392.8391 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 613/1000
2023-09-10 09:10:49.324 
Epoch 613/1000 
	 loss: 391.5519, MinusLogProbMetric: 391.5519, val_loss: 393.3149, val_MinusLogProbMetric: 393.3149

Epoch 613: val_loss did not improve from 392.83911
196/196 - 10s - loss: 391.5519 - MinusLogProbMetric: 391.5519 - val_loss: 393.3149 - val_MinusLogProbMetric: 393.3149 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 614/1000
2023-09-10 09:10:56.363 
Epoch 614/1000 
	 loss: 391.4383, MinusLogProbMetric: 391.4383, val_loss: 393.3434, val_MinusLogProbMetric: 393.3434

Epoch 614: val_loss did not improve from 392.83911
196/196 - 7s - loss: 391.4383 - MinusLogProbMetric: 391.4383 - val_loss: 393.3434 - val_MinusLogProbMetric: 393.3434 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 615/1000
2023-09-10 09:11:05.187 
Epoch 615/1000 
	 loss: 391.1173, MinusLogProbMetric: 391.1173, val_loss: 392.9325, val_MinusLogProbMetric: 392.9325

Epoch 615: val_loss did not improve from 392.83911
196/196 - 9s - loss: 391.1173 - MinusLogProbMetric: 391.1173 - val_loss: 392.9325 - val_MinusLogProbMetric: 392.9325 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 616/1000
2023-09-10 09:11:13.132 
Epoch 616/1000 
	 loss: 391.1367, MinusLogProbMetric: 391.1367, val_loss: 393.3372, val_MinusLogProbMetric: 393.3372

Epoch 616: val_loss did not improve from 392.83911
196/196 - 8s - loss: 391.1367 - MinusLogProbMetric: 391.1367 - val_loss: 393.3372 - val_MinusLogProbMetric: 393.3372 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 617/1000
2023-09-10 09:11:24.055 
Epoch 617/1000 
	 loss: 391.2143, MinusLogProbMetric: 391.2143, val_loss: 392.8609, val_MinusLogProbMetric: 392.8609

Epoch 617: val_loss did not improve from 392.83911
196/196 - 11s - loss: 391.2143 - MinusLogProbMetric: 391.2143 - val_loss: 392.8609 - val_MinusLogProbMetric: 392.8609 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 618/1000
2023-09-10 09:11:34.957 
Epoch 618/1000 
	 loss: 391.3032, MinusLogProbMetric: 391.3032, val_loss: 392.9193, val_MinusLogProbMetric: 392.9193

Epoch 618: val_loss did not improve from 392.83911
196/196 - 11s - loss: 391.3032 - MinusLogProbMetric: 391.3032 - val_loss: 392.9193 - val_MinusLogProbMetric: 392.9193 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 619/1000
2023-09-10 09:11:42.621 
Epoch 619/1000 
	 loss: 391.2244, MinusLogProbMetric: 391.2244, val_loss: 393.3826, val_MinusLogProbMetric: 393.3826

Epoch 619: val_loss did not improve from 392.83911
196/196 - 8s - loss: 391.2244 - MinusLogProbMetric: 391.2244 - val_loss: 393.3826 - val_MinusLogProbMetric: 393.3826 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 620/1000
2023-09-10 09:11:50.373 
Epoch 620/1000 
	 loss: 391.3370, MinusLogProbMetric: 391.3370, val_loss: 393.3741, val_MinusLogProbMetric: 393.3741

Epoch 620: val_loss did not improve from 392.83911
196/196 - 8s - loss: 391.3370 - MinusLogProbMetric: 391.3370 - val_loss: 393.3741 - val_MinusLogProbMetric: 393.3741 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 621/1000
2023-09-10 09:12:01.299 
Epoch 621/1000 
	 loss: 391.4163, MinusLogProbMetric: 391.4163, val_loss: 393.0048, val_MinusLogProbMetric: 393.0048

Epoch 621: val_loss did not improve from 392.83911
196/196 - 11s - loss: 391.4163 - MinusLogProbMetric: 391.4163 - val_loss: 393.0048 - val_MinusLogProbMetric: 393.0048 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 622/1000
2023-09-10 09:12:11.858 
Epoch 622/1000 
	 loss: 391.4406, MinusLogProbMetric: 391.4406, val_loss: 393.4595, val_MinusLogProbMetric: 393.4595

Epoch 622: val_loss did not improve from 392.83911
196/196 - 11s - loss: 391.4406 - MinusLogProbMetric: 391.4406 - val_loss: 393.4595 - val_MinusLogProbMetric: 393.4595 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 623/1000
2023-09-10 09:12:18.741 
Epoch 623/1000 
	 loss: 391.2211, MinusLogProbMetric: 391.2211, val_loss: 392.9872, val_MinusLogProbMetric: 392.9872

Epoch 623: val_loss did not improve from 392.83911
196/196 - 7s - loss: 391.2211 - MinusLogProbMetric: 391.2211 - val_loss: 392.9872 - val_MinusLogProbMetric: 392.9872 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 624/1000
2023-09-10 09:12:28.382 
Epoch 624/1000 
	 loss: 391.4459, MinusLogProbMetric: 391.4459, val_loss: 393.2167, val_MinusLogProbMetric: 393.2167

Epoch 624: val_loss did not improve from 392.83911
196/196 - 10s - loss: 391.4459 - MinusLogProbMetric: 391.4459 - val_loss: 393.2167 - val_MinusLogProbMetric: 393.2167 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 625/1000
2023-09-10 09:12:35.468 
Epoch 625/1000 
	 loss: 391.4038, MinusLogProbMetric: 391.4038, val_loss: 393.0051, val_MinusLogProbMetric: 393.0051

Epoch 625: val_loss did not improve from 392.83911
196/196 - 7s - loss: 391.4038 - MinusLogProbMetric: 391.4038 - val_loss: 393.0051 - val_MinusLogProbMetric: 393.0051 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 626/1000
2023-09-10 09:12:42.436 
Epoch 626/1000 
	 loss: 391.2693, MinusLogProbMetric: 391.2693, val_loss: 393.2521, val_MinusLogProbMetric: 393.2521

Epoch 626: val_loss did not improve from 392.83911
196/196 - 7s - loss: 391.2693 - MinusLogProbMetric: 391.2693 - val_loss: 393.2521 - val_MinusLogProbMetric: 393.2521 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 627/1000
2023-09-10 09:12:51.794 
Epoch 627/1000 
	 loss: 391.3368, MinusLogProbMetric: 391.3368, val_loss: 393.6389, val_MinusLogProbMetric: 393.6389

Epoch 627: val_loss did not improve from 392.83911
196/196 - 9s - loss: 391.3368 - MinusLogProbMetric: 391.3368 - val_loss: 393.6389 - val_MinusLogProbMetric: 393.6389 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 628/1000
2023-09-10 09:12:59.279 
Epoch 628/1000 
	 loss: 391.2133, MinusLogProbMetric: 391.2133, val_loss: 394.1146, val_MinusLogProbMetric: 394.1146

Epoch 628: val_loss did not improve from 392.83911
196/196 - 7s - loss: 391.2133 - MinusLogProbMetric: 391.2133 - val_loss: 394.1146 - val_MinusLogProbMetric: 394.1146 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 629/1000
2023-09-10 09:13:07.889 
Epoch 629/1000 
	 loss: 391.3009, MinusLogProbMetric: 391.3009, val_loss: 394.7935, val_MinusLogProbMetric: 394.7935

Epoch 629: val_loss did not improve from 392.83911
196/196 - 9s - loss: 391.3009 - MinusLogProbMetric: 391.3009 - val_loss: 394.7935 - val_MinusLogProbMetric: 394.7935 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 630/1000
2023-09-10 09:13:15.506 
Epoch 630/1000 
	 loss: 391.3453, MinusLogProbMetric: 391.3453, val_loss: 393.4195, val_MinusLogProbMetric: 393.4195

Epoch 630: val_loss did not improve from 392.83911
196/196 - 8s - loss: 391.3453 - MinusLogProbMetric: 391.3453 - val_loss: 393.4195 - val_MinusLogProbMetric: 393.4195 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 631/1000
2023-09-10 09:13:24.111 
Epoch 631/1000 
	 loss: 391.2704, MinusLogProbMetric: 391.2704, val_loss: 393.2361, val_MinusLogProbMetric: 393.2361

Epoch 631: val_loss did not improve from 392.83911
196/196 - 9s - loss: 391.2704 - MinusLogProbMetric: 391.2704 - val_loss: 393.2361 - val_MinusLogProbMetric: 393.2361 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 632/1000
2023-09-10 09:13:30.902 
Epoch 632/1000 
	 loss: 391.1577, MinusLogProbMetric: 391.1577, val_loss: 393.0110, val_MinusLogProbMetric: 393.0110

Epoch 632: val_loss did not improve from 392.83911
196/196 - 7s - loss: 391.1577 - MinusLogProbMetric: 391.1577 - val_loss: 393.0110 - val_MinusLogProbMetric: 393.0110 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 633/1000
2023-09-10 09:13:39.825 
Epoch 633/1000 
	 loss: 391.3144, MinusLogProbMetric: 391.3144, val_loss: 394.0578, val_MinusLogProbMetric: 394.0578

Epoch 633: val_loss did not improve from 392.83911
196/196 - 9s - loss: 391.3144 - MinusLogProbMetric: 391.3144 - val_loss: 394.0578 - val_MinusLogProbMetric: 394.0578 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 634/1000
2023-09-10 09:13:49.390 
Epoch 634/1000 
	 loss: 391.1967, MinusLogProbMetric: 391.1967, val_loss: 393.0829, val_MinusLogProbMetric: 393.0829

Epoch 634: val_loss did not improve from 392.83911
196/196 - 10s - loss: 391.1967 - MinusLogProbMetric: 391.1967 - val_loss: 393.0829 - val_MinusLogProbMetric: 393.0829 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 635/1000
2023-09-10 09:13:59.836 
Epoch 635/1000 
	 loss: 391.1419, MinusLogProbMetric: 391.1419, val_loss: 392.9365, val_MinusLogProbMetric: 392.9365

Epoch 635: val_loss did not improve from 392.83911
196/196 - 10s - loss: 391.1419 - MinusLogProbMetric: 391.1419 - val_loss: 392.9365 - val_MinusLogProbMetric: 392.9365 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 636/1000
2023-09-10 09:14:10.610 
Epoch 636/1000 
	 loss: 391.2961, MinusLogProbMetric: 391.2961, val_loss: 394.4491, val_MinusLogProbMetric: 394.4491

Epoch 636: val_loss did not improve from 392.83911
196/196 - 11s - loss: 391.2961 - MinusLogProbMetric: 391.2961 - val_loss: 394.4491 - val_MinusLogProbMetric: 394.4491 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 637/1000
2023-09-10 09:14:19.378 
Epoch 637/1000 
	 loss: 391.3789, MinusLogProbMetric: 391.3789, val_loss: 394.1320, val_MinusLogProbMetric: 394.1320

Epoch 637: val_loss did not improve from 392.83911
196/196 - 9s - loss: 391.3789 - MinusLogProbMetric: 391.3789 - val_loss: 394.1320 - val_MinusLogProbMetric: 394.1320 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 638/1000
2023-09-10 09:14:30.474 
Epoch 638/1000 
	 loss: 391.1659, MinusLogProbMetric: 391.1659, val_loss: 392.6588, val_MinusLogProbMetric: 392.6588

Epoch 638: val_loss improved from 392.83911 to 392.65881, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 391.1659 - MinusLogProbMetric: 391.1659 - val_loss: 392.6588 - val_MinusLogProbMetric: 392.6588 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 639/1000
2023-09-10 09:14:38.293 
Epoch 639/1000 
	 loss: 391.1930, MinusLogProbMetric: 391.1930, val_loss: 392.8555, val_MinusLogProbMetric: 392.8555

Epoch 639: val_loss did not improve from 392.65881
196/196 - 7s - loss: 391.1930 - MinusLogProbMetric: 391.1930 - val_loss: 392.8555 - val_MinusLogProbMetric: 392.8555 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 640/1000
2023-09-10 09:14:47.139 
Epoch 640/1000 
	 loss: 391.5300, MinusLogProbMetric: 391.5300, val_loss: 393.3502, val_MinusLogProbMetric: 393.3502

Epoch 640: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.5300 - MinusLogProbMetric: 391.5300 - val_loss: 393.3502 - val_MinusLogProbMetric: 393.3502 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 641/1000
2023-09-10 09:14:55.057 
Epoch 641/1000 
	 loss: 391.4323, MinusLogProbMetric: 391.4323, val_loss: 396.5716, val_MinusLogProbMetric: 396.5716

Epoch 641: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.4323 - MinusLogProbMetric: 391.4323 - val_loss: 396.5716 - val_MinusLogProbMetric: 396.5716 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 642/1000
2023-09-10 09:15:06.256 
Epoch 642/1000 
	 loss: 391.2761, MinusLogProbMetric: 391.2761, val_loss: 393.1213, val_MinusLogProbMetric: 393.1213

Epoch 642: val_loss did not improve from 392.65881
196/196 - 11s - loss: 391.2761 - MinusLogProbMetric: 391.2761 - val_loss: 393.1213 - val_MinusLogProbMetric: 393.1213 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 643/1000
2023-09-10 09:15:16.157 
Epoch 643/1000 
	 loss: 391.0784, MinusLogProbMetric: 391.0784, val_loss: 393.2729, val_MinusLogProbMetric: 393.2729

Epoch 643: val_loss did not improve from 392.65881
196/196 - 10s - loss: 391.0784 - MinusLogProbMetric: 391.0784 - val_loss: 393.2729 - val_MinusLogProbMetric: 393.2729 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 644/1000
2023-09-10 09:15:23.416 
Epoch 644/1000 
	 loss: 391.4731, MinusLogProbMetric: 391.4731, val_loss: 393.7217, val_MinusLogProbMetric: 393.7217

Epoch 644: val_loss did not improve from 392.65881
196/196 - 7s - loss: 391.4731 - MinusLogProbMetric: 391.4731 - val_loss: 393.7217 - val_MinusLogProbMetric: 393.7217 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 645/1000
2023-09-10 09:15:32.297 
Epoch 645/1000 
	 loss: 391.2122, MinusLogProbMetric: 391.2122, val_loss: 393.9637, val_MinusLogProbMetric: 393.9637

Epoch 645: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.2122 - MinusLogProbMetric: 391.2122 - val_loss: 393.9637 - val_MinusLogProbMetric: 393.9637 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 646/1000
2023-09-10 09:15:41.234 
Epoch 646/1000 
	 loss: 391.1165, MinusLogProbMetric: 391.1165, val_loss: 393.0521, val_MinusLogProbMetric: 393.0521

Epoch 646: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.1165 - MinusLogProbMetric: 391.1165 - val_loss: 393.0521 - val_MinusLogProbMetric: 393.0521 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 647/1000
2023-09-10 09:15:50.238 
Epoch 647/1000 
	 loss: 391.1171, MinusLogProbMetric: 391.1171, val_loss: 392.7326, val_MinusLogProbMetric: 392.7326

Epoch 647: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.1171 - MinusLogProbMetric: 391.1171 - val_loss: 392.7326 - val_MinusLogProbMetric: 392.7326 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 648/1000
2023-09-10 09:15:58.277 
Epoch 648/1000 
	 loss: 390.9933, MinusLogProbMetric: 390.9933, val_loss: 393.0251, val_MinusLogProbMetric: 393.0251

Epoch 648: val_loss did not improve from 392.65881
196/196 - 8s - loss: 390.9933 - MinusLogProbMetric: 390.9933 - val_loss: 393.0251 - val_MinusLogProbMetric: 393.0251 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 649/1000
2023-09-10 09:16:05.770 
Epoch 649/1000 
	 loss: 391.1145, MinusLogProbMetric: 391.1145, val_loss: 393.0301, val_MinusLogProbMetric: 393.0301

Epoch 649: val_loss did not improve from 392.65881
196/196 - 7s - loss: 391.1145 - MinusLogProbMetric: 391.1145 - val_loss: 393.0301 - val_MinusLogProbMetric: 393.0301 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 650/1000
2023-09-10 09:16:13.391 
Epoch 650/1000 
	 loss: 391.2520, MinusLogProbMetric: 391.2520, val_loss: 392.6795, val_MinusLogProbMetric: 392.6795

Epoch 650: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.2520 - MinusLogProbMetric: 391.2520 - val_loss: 392.6795 - val_MinusLogProbMetric: 392.6795 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 651/1000
2023-09-10 09:16:21.098 
Epoch 651/1000 
	 loss: 391.0829, MinusLogProbMetric: 391.0829, val_loss: 392.8229, val_MinusLogProbMetric: 392.8229

Epoch 651: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.0829 - MinusLogProbMetric: 391.0829 - val_loss: 392.8229 - val_MinusLogProbMetric: 392.8229 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 652/1000
2023-09-10 09:16:29.104 
Epoch 652/1000 
	 loss: 391.5664, MinusLogProbMetric: 391.5664, val_loss: 392.9531, val_MinusLogProbMetric: 392.9531

Epoch 652: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.5664 - MinusLogProbMetric: 391.5664 - val_loss: 392.9531 - val_MinusLogProbMetric: 392.9531 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 653/1000
2023-09-10 09:16:36.715 
Epoch 653/1000 
	 loss: 390.9316, MinusLogProbMetric: 390.9316, val_loss: 392.7867, val_MinusLogProbMetric: 392.7867

Epoch 653: val_loss did not improve from 392.65881
196/196 - 8s - loss: 390.9316 - MinusLogProbMetric: 390.9316 - val_loss: 392.7867 - val_MinusLogProbMetric: 392.7867 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 654/1000
2023-09-10 09:16:44.811 
Epoch 654/1000 
	 loss: 391.0638, MinusLogProbMetric: 391.0638, val_loss: 392.7311, val_MinusLogProbMetric: 392.7311

Epoch 654: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.0638 - MinusLogProbMetric: 391.0638 - val_loss: 392.7311 - val_MinusLogProbMetric: 392.7311 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 655/1000
2023-09-10 09:16:53.979 
Epoch 655/1000 
	 loss: 390.9717, MinusLogProbMetric: 390.9717, val_loss: 393.1895, val_MinusLogProbMetric: 393.1895

Epoch 655: val_loss did not improve from 392.65881
196/196 - 9s - loss: 390.9717 - MinusLogProbMetric: 390.9717 - val_loss: 393.1895 - val_MinusLogProbMetric: 393.1895 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 656/1000
2023-09-10 09:17:02.137 
Epoch 656/1000 
	 loss: 391.0324, MinusLogProbMetric: 391.0324, val_loss: 393.2864, val_MinusLogProbMetric: 393.2864

Epoch 656: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.0324 - MinusLogProbMetric: 391.0324 - val_loss: 393.2864 - val_MinusLogProbMetric: 393.2864 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 657/1000
2023-09-10 09:17:10.443 
Epoch 657/1000 
	 loss: 391.0009, MinusLogProbMetric: 391.0009, val_loss: 393.0950, val_MinusLogProbMetric: 393.0950

Epoch 657: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.0009 - MinusLogProbMetric: 391.0009 - val_loss: 393.0950 - val_MinusLogProbMetric: 393.0950 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 658/1000
2023-09-10 09:17:18.755 
Epoch 658/1000 
	 loss: 390.8956, MinusLogProbMetric: 390.8956, val_loss: 392.9725, val_MinusLogProbMetric: 392.9725

Epoch 658: val_loss did not improve from 392.65881
196/196 - 8s - loss: 390.8956 - MinusLogProbMetric: 390.8956 - val_loss: 392.9725 - val_MinusLogProbMetric: 392.9725 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 659/1000
2023-09-10 09:17:27.224 
Epoch 659/1000 
	 loss: 391.0504, MinusLogProbMetric: 391.0504, val_loss: 393.0699, val_MinusLogProbMetric: 393.0699

Epoch 659: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.0504 - MinusLogProbMetric: 391.0504 - val_loss: 393.0699 - val_MinusLogProbMetric: 393.0699 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 660/1000
2023-09-10 09:17:35.735 
Epoch 660/1000 
	 loss: 390.8384, MinusLogProbMetric: 390.8384, val_loss: 392.6624, val_MinusLogProbMetric: 392.6624

Epoch 660: val_loss did not improve from 392.65881
196/196 - 8s - loss: 390.8384 - MinusLogProbMetric: 390.8384 - val_loss: 392.6624 - val_MinusLogProbMetric: 392.6624 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 661/1000
2023-09-10 09:17:44.444 
Epoch 661/1000 
	 loss: 391.3760, MinusLogProbMetric: 391.3760, val_loss: 393.9640, val_MinusLogProbMetric: 393.9640

Epoch 661: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.3760 - MinusLogProbMetric: 391.3760 - val_loss: 393.9640 - val_MinusLogProbMetric: 393.9640 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 662/1000
2023-09-10 09:17:52.873 
Epoch 662/1000 
	 loss: 391.0600, MinusLogProbMetric: 391.0600, val_loss: 395.7474, val_MinusLogProbMetric: 395.7474

Epoch 662: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.0600 - MinusLogProbMetric: 391.0600 - val_loss: 395.7474 - val_MinusLogProbMetric: 395.7474 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 663/1000
2023-09-10 09:18:02.309 
Epoch 663/1000 
	 loss: 391.0821, MinusLogProbMetric: 391.0821, val_loss: 392.8138, val_MinusLogProbMetric: 392.8138

Epoch 663: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.0821 - MinusLogProbMetric: 391.0821 - val_loss: 392.8138 - val_MinusLogProbMetric: 392.8138 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 664/1000
2023-09-10 09:18:11.149 
Epoch 664/1000 
	 loss: 391.2520, MinusLogProbMetric: 391.2520, val_loss: 393.1140, val_MinusLogProbMetric: 393.1140

Epoch 664: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.2520 - MinusLogProbMetric: 391.2520 - val_loss: 393.1140 - val_MinusLogProbMetric: 393.1140 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 665/1000
2023-09-10 09:18:19.501 
Epoch 665/1000 
	 loss: 391.2339, MinusLogProbMetric: 391.2339, val_loss: 393.2503, val_MinusLogProbMetric: 393.2503

Epoch 665: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.2339 - MinusLogProbMetric: 391.2339 - val_loss: 393.2503 - val_MinusLogProbMetric: 393.2503 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 666/1000
2023-09-10 09:18:28.544 
Epoch 666/1000 
	 loss: 390.8040, MinusLogProbMetric: 390.8040, val_loss: 392.9678, val_MinusLogProbMetric: 392.9678

Epoch 666: val_loss did not improve from 392.65881
196/196 - 9s - loss: 390.8040 - MinusLogProbMetric: 390.8040 - val_loss: 392.9678 - val_MinusLogProbMetric: 392.9678 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 667/1000
2023-09-10 09:18:39.526 
Epoch 667/1000 
	 loss: 391.0925, MinusLogProbMetric: 391.0925, val_loss: 392.8714, val_MinusLogProbMetric: 392.8714

Epoch 667: val_loss did not improve from 392.65881
196/196 - 11s - loss: 391.0925 - MinusLogProbMetric: 391.0925 - val_loss: 392.8714 - val_MinusLogProbMetric: 392.8714 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 668/1000
2023-09-10 09:18:50.818 
Epoch 668/1000 
	 loss: 391.1187, MinusLogProbMetric: 391.1187, val_loss: 392.8562, val_MinusLogProbMetric: 392.8562

Epoch 668: val_loss did not improve from 392.65881
196/196 - 11s - loss: 391.1187 - MinusLogProbMetric: 391.1187 - val_loss: 392.8562 - val_MinusLogProbMetric: 392.8562 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 669/1000
2023-09-10 09:19:00.216 
Epoch 669/1000 
	 loss: 391.2138, MinusLogProbMetric: 391.2138, val_loss: 392.8028, val_MinusLogProbMetric: 392.8028

Epoch 669: val_loss did not improve from 392.65881
196/196 - 9s - loss: 391.2138 - MinusLogProbMetric: 391.2138 - val_loss: 392.8028 - val_MinusLogProbMetric: 392.8028 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 670/1000
2023-09-10 09:19:08.627 
Epoch 670/1000 
	 loss: 391.2344, MinusLogProbMetric: 391.2344, val_loss: 392.8129, val_MinusLogProbMetric: 392.8129

Epoch 670: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.2344 - MinusLogProbMetric: 391.2344 - val_loss: 392.8129 - val_MinusLogProbMetric: 392.8129 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 671/1000
2023-09-10 09:19:15.858 
Epoch 671/1000 
	 loss: 391.0499, MinusLogProbMetric: 391.0499, val_loss: 393.0519, val_MinusLogProbMetric: 393.0519

Epoch 671: val_loss did not improve from 392.65881
196/196 - 7s - loss: 391.0499 - MinusLogProbMetric: 391.0499 - val_loss: 393.0519 - val_MinusLogProbMetric: 393.0519 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 672/1000
2023-09-10 09:19:24.355 
Epoch 672/1000 
	 loss: 391.3292, MinusLogProbMetric: 391.3292, val_loss: 392.7941, val_MinusLogProbMetric: 392.7941

Epoch 672: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.3292 - MinusLogProbMetric: 391.3292 - val_loss: 392.7941 - val_MinusLogProbMetric: 392.7941 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 673/1000
2023-09-10 09:19:32.012 
Epoch 673/1000 
	 loss: 391.1546, MinusLogProbMetric: 391.1546, val_loss: 393.0323, val_MinusLogProbMetric: 393.0323

Epoch 673: val_loss did not improve from 392.65881
196/196 - 8s - loss: 391.1546 - MinusLogProbMetric: 391.1546 - val_loss: 393.0323 - val_MinusLogProbMetric: 393.0323 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 674/1000
2023-09-10 09:19:40.582 
Epoch 674/1000 
	 loss: 391.1590, MinusLogProbMetric: 391.1590, val_loss: 392.5657, val_MinusLogProbMetric: 392.5657

Epoch 674: val_loss improved from 392.65881 to 392.56573, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 391.1590 - MinusLogProbMetric: 391.1590 - val_loss: 392.5657 - val_MinusLogProbMetric: 392.5657 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 675/1000
2023-09-10 09:19:49.249 
Epoch 675/1000 
	 loss: 391.1801, MinusLogProbMetric: 391.1801, val_loss: 392.8768, val_MinusLogProbMetric: 392.8768

Epoch 675: val_loss did not improve from 392.56573
196/196 - 8s - loss: 391.1801 - MinusLogProbMetric: 391.1801 - val_loss: 392.8768 - val_MinusLogProbMetric: 392.8768 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 676/1000
2023-09-10 09:19:58.721 
Epoch 676/1000 
	 loss: 391.1935, MinusLogProbMetric: 391.1935, val_loss: 393.0343, val_MinusLogProbMetric: 393.0343

Epoch 676: val_loss did not improve from 392.56573
196/196 - 9s - loss: 391.1935 - MinusLogProbMetric: 391.1935 - val_loss: 393.0343 - val_MinusLogProbMetric: 393.0343 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 677/1000
2023-09-10 09:20:06.965 
Epoch 677/1000 
	 loss: 390.9679, MinusLogProbMetric: 390.9679, val_loss: 393.0302, val_MinusLogProbMetric: 393.0302

Epoch 677: val_loss did not improve from 392.56573
196/196 - 8s - loss: 390.9679 - MinusLogProbMetric: 390.9679 - val_loss: 393.0302 - val_MinusLogProbMetric: 393.0302 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 678/1000
2023-09-10 09:20:15.758 
Epoch 678/1000 
	 loss: 391.1507, MinusLogProbMetric: 391.1507, val_loss: 393.0084, val_MinusLogProbMetric: 393.0084

Epoch 678: val_loss did not improve from 392.56573
196/196 - 9s - loss: 391.1507 - MinusLogProbMetric: 391.1507 - val_loss: 393.0084 - val_MinusLogProbMetric: 393.0084 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 679/1000
2023-09-10 09:20:22.731 
Epoch 679/1000 
	 loss: 391.0504, MinusLogProbMetric: 391.0504, val_loss: 392.4966, val_MinusLogProbMetric: 392.4966

Epoch 679: val_loss improved from 392.56573 to 392.49664, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 391.0504 - MinusLogProbMetric: 391.0504 - val_loss: 392.4966 - val_MinusLogProbMetric: 392.4966 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 680/1000
2023-09-10 09:20:32.268 
Epoch 680/1000 
	 loss: 390.9155, MinusLogProbMetric: 390.9155, val_loss: 393.2596, val_MinusLogProbMetric: 393.2596

Epoch 680: val_loss did not improve from 392.49664
196/196 - 9s - loss: 390.9155 - MinusLogProbMetric: 390.9155 - val_loss: 393.2596 - val_MinusLogProbMetric: 393.2596 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 681/1000
2023-09-10 09:20:40.221 
Epoch 681/1000 
	 loss: 390.9160, MinusLogProbMetric: 390.9160, val_loss: 393.0415, val_MinusLogProbMetric: 393.0415

Epoch 681: val_loss did not improve from 392.49664
196/196 - 8s - loss: 390.9160 - MinusLogProbMetric: 390.9160 - val_loss: 393.0415 - val_MinusLogProbMetric: 393.0415 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 682/1000
2023-09-10 09:20:48.566 
Epoch 682/1000 
	 loss: 390.9248, MinusLogProbMetric: 390.9248, val_loss: 393.7263, val_MinusLogProbMetric: 393.7263

Epoch 682: val_loss did not improve from 392.49664
196/196 - 8s - loss: 390.9248 - MinusLogProbMetric: 390.9248 - val_loss: 393.7263 - val_MinusLogProbMetric: 393.7263 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 683/1000
2023-09-10 09:20:57.571 
Epoch 683/1000 
	 loss: 391.0378, MinusLogProbMetric: 391.0378, val_loss: 393.3040, val_MinusLogProbMetric: 393.3040

Epoch 683: val_loss did not improve from 392.49664
196/196 - 9s - loss: 391.0378 - MinusLogProbMetric: 391.0378 - val_loss: 393.3040 - val_MinusLogProbMetric: 393.3040 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 684/1000
2023-09-10 09:21:05.310 
Epoch 684/1000 
	 loss: 390.9145, MinusLogProbMetric: 390.9145, val_loss: 392.6751, val_MinusLogProbMetric: 392.6751

Epoch 684: val_loss did not improve from 392.49664
196/196 - 8s - loss: 390.9145 - MinusLogProbMetric: 390.9145 - val_loss: 392.6751 - val_MinusLogProbMetric: 392.6751 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 685/1000
2023-09-10 09:21:12.296 
Epoch 685/1000 
	 loss: 391.0602, MinusLogProbMetric: 391.0602, val_loss: 392.8417, val_MinusLogProbMetric: 392.8417

Epoch 685: val_loss did not improve from 392.49664
196/196 - 7s - loss: 391.0602 - MinusLogProbMetric: 391.0602 - val_loss: 392.8417 - val_MinusLogProbMetric: 392.8417 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 686/1000
2023-09-10 09:21:20.673 
Epoch 686/1000 
	 loss: 390.9841, MinusLogProbMetric: 390.9841, val_loss: 392.5723, val_MinusLogProbMetric: 392.5723

Epoch 686: val_loss did not improve from 392.49664
196/196 - 8s - loss: 390.9841 - MinusLogProbMetric: 390.9841 - val_loss: 392.5723 - val_MinusLogProbMetric: 392.5723 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 687/1000
2023-09-10 09:21:30.518 
Epoch 687/1000 
	 loss: 390.9885, MinusLogProbMetric: 390.9885, val_loss: 393.0891, val_MinusLogProbMetric: 393.0891

Epoch 687: val_loss did not improve from 392.49664
196/196 - 10s - loss: 390.9885 - MinusLogProbMetric: 390.9885 - val_loss: 393.0891 - val_MinusLogProbMetric: 393.0891 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 688/1000
2023-09-10 09:21:40.464 
Epoch 688/1000 
	 loss: 391.1130, MinusLogProbMetric: 391.1130, val_loss: 393.7654, val_MinusLogProbMetric: 393.7654

Epoch 688: val_loss did not improve from 392.49664
196/196 - 10s - loss: 391.1130 - MinusLogProbMetric: 391.1130 - val_loss: 393.7654 - val_MinusLogProbMetric: 393.7654 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 689/1000
2023-09-10 09:21:49.508 
Epoch 689/1000 
	 loss: 391.0092, MinusLogProbMetric: 391.0092, val_loss: 392.9450, val_MinusLogProbMetric: 392.9450

Epoch 689: val_loss did not improve from 392.49664
196/196 - 9s - loss: 391.0092 - MinusLogProbMetric: 391.0092 - val_loss: 392.9450 - val_MinusLogProbMetric: 392.9450 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 690/1000
2023-09-10 09:21:58.571 
Epoch 690/1000 
	 loss: 390.9538, MinusLogProbMetric: 390.9538, val_loss: 393.0979, val_MinusLogProbMetric: 393.0979

Epoch 690: val_loss did not improve from 392.49664
196/196 - 9s - loss: 390.9538 - MinusLogProbMetric: 390.9538 - val_loss: 393.0979 - val_MinusLogProbMetric: 393.0979 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 691/1000
2023-09-10 09:22:06.769 
Epoch 691/1000 
	 loss: 390.8719, MinusLogProbMetric: 390.8719, val_loss: 392.5877, val_MinusLogProbMetric: 392.5877

Epoch 691: val_loss did not improve from 392.49664
196/196 - 8s - loss: 390.8719 - MinusLogProbMetric: 390.8719 - val_loss: 392.5877 - val_MinusLogProbMetric: 392.5877 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 692/1000
2023-09-10 09:22:16.556 
Epoch 692/1000 
	 loss: 391.1550, MinusLogProbMetric: 391.1550, val_loss: 393.0277, val_MinusLogProbMetric: 393.0277

Epoch 692: val_loss did not improve from 392.49664
196/196 - 10s - loss: 391.1550 - MinusLogProbMetric: 391.1550 - val_loss: 393.0277 - val_MinusLogProbMetric: 393.0277 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 693/1000
2023-09-10 09:22:25.302 
Epoch 693/1000 
	 loss: 390.8401, MinusLogProbMetric: 390.8401, val_loss: 392.6961, val_MinusLogProbMetric: 392.6961

Epoch 693: val_loss did not improve from 392.49664
196/196 - 9s - loss: 390.8401 - MinusLogProbMetric: 390.8401 - val_loss: 392.6961 - val_MinusLogProbMetric: 392.6961 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 694/1000
2023-09-10 09:22:34.020 
Epoch 694/1000 
	 loss: 390.7781, MinusLogProbMetric: 390.7781, val_loss: 393.1611, val_MinusLogProbMetric: 393.1611

Epoch 694: val_loss did not improve from 392.49664
196/196 - 9s - loss: 390.7781 - MinusLogProbMetric: 390.7781 - val_loss: 393.1611 - val_MinusLogProbMetric: 393.1611 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 695/1000
2023-09-10 09:22:44.249 
Epoch 695/1000 
	 loss: 390.9262, MinusLogProbMetric: 390.9262, val_loss: 393.1542, val_MinusLogProbMetric: 393.1542

Epoch 695: val_loss did not improve from 392.49664
196/196 - 10s - loss: 390.9262 - MinusLogProbMetric: 390.9262 - val_loss: 393.1542 - val_MinusLogProbMetric: 393.1542 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 696/1000
2023-09-10 09:22:54.319 
Epoch 696/1000 
	 loss: 390.8691, MinusLogProbMetric: 390.8691, val_loss: 393.0867, val_MinusLogProbMetric: 393.0867

Epoch 696: val_loss did not improve from 392.49664
196/196 - 10s - loss: 390.8691 - MinusLogProbMetric: 390.8691 - val_loss: 393.0867 - val_MinusLogProbMetric: 393.0867 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 697/1000
2023-09-10 09:23:03.212 
Epoch 697/1000 
	 loss: 391.2475, MinusLogProbMetric: 391.2475, val_loss: 392.8381, val_MinusLogProbMetric: 392.8381

Epoch 697: val_loss did not improve from 392.49664
196/196 - 9s - loss: 391.2475 - MinusLogProbMetric: 391.2475 - val_loss: 392.8381 - val_MinusLogProbMetric: 392.8381 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 698/1000
2023-09-10 09:23:13.224 
Epoch 698/1000 
	 loss: 390.7750, MinusLogProbMetric: 390.7750, val_loss: 392.4947, val_MinusLogProbMetric: 392.4947

Epoch 698: val_loss improved from 392.49664 to 392.49472, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 390.7750 - MinusLogProbMetric: 390.7750 - val_loss: 392.4947 - val_MinusLogProbMetric: 392.4947 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 699/1000
2023-09-10 09:23:23.386 
Epoch 699/1000 
	 loss: 390.9757, MinusLogProbMetric: 390.9757, val_loss: 392.7167, val_MinusLogProbMetric: 392.7167

Epoch 699: val_loss did not improve from 392.49472
196/196 - 10s - loss: 390.9757 - MinusLogProbMetric: 390.9757 - val_loss: 392.7167 - val_MinusLogProbMetric: 392.7167 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 700/1000
2023-09-10 09:23:33.738 
Epoch 700/1000 
	 loss: 390.9426, MinusLogProbMetric: 390.9426, val_loss: 393.6121, val_MinusLogProbMetric: 393.6121

Epoch 700: val_loss did not improve from 392.49472
196/196 - 10s - loss: 390.9426 - MinusLogProbMetric: 390.9426 - val_loss: 393.6121 - val_MinusLogProbMetric: 393.6121 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 701/1000
2023-09-10 09:23:43.295 
Epoch 701/1000 
	 loss: 391.0099, MinusLogProbMetric: 391.0099, val_loss: 393.1464, val_MinusLogProbMetric: 393.1464

Epoch 701: val_loss did not improve from 392.49472
196/196 - 10s - loss: 391.0099 - MinusLogProbMetric: 391.0099 - val_loss: 393.1464 - val_MinusLogProbMetric: 393.1464 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 702/1000
2023-09-10 09:23:52.398 
Epoch 702/1000 
	 loss: 390.8407, MinusLogProbMetric: 390.8407, val_loss: 392.9221, val_MinusLogProbMetric: 392.9221

Epoch 702: val_loss did not improve from 392.49472
196/196 - 9s - loss: 390.8407 - MinusLogProbMetric: 390.8407 - val_loss: 392.9221 - val_MinusLogProbMetric: 392.9221 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 703/1000
2023-09-10 09:24:04.218 
Epoch 703/1000 
	 loss: 391.5771, MinusLogProbMetric: 391.5771, val_loss: 392.4961, val_MinusLogProbMetric: 392.4961

Epoch 703: val_loss did not improve from 392.49472
196/196 - 12s - loss: 391.5771 - MinusLogProbMetric: 391.5771 - val_loss: 392.4961 - val_MinusLogProbMetric: 392.4961 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 704/1000
2023-09-10 09:24:15.921 
Epoch 704/1000 
	 loss: 391.0622, MinusLogProbMetric: 391.0622, val_loss: 392.8043, val_MinusLogProbMetric: 392.8043

Epoch 704: val_loss did not improve from 392.49472
196/196 - 12s - loss: 391.0622 - MinusLogProbMetric: 391.0622 - val_loss: 392.8043 - val_MinusLogProbMetric: 392.8043 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 705/1000
2023-09-10 09:24:27.100 
Epoch 705/1000 
	 loss: 391.0824, MinusLogProbMetric: 391.0824, val_loss: 393.1099, val_MinusLogProbMetric: 393.1099

Epoch 705: val_loss did not improve from 392.49472
196/196 - 11s - loss: 391.0824 - MinusLogProbMetric: 391.0824 - val_loss: 393.1099 - val_MinusLogProbMetric: 393.1099 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 706/1000
2023-09-10 09:24:36.746 
Epoch 706/1000 
	 loss: 390.7283, MinusLogProbMetric: 390.7283, val_loss: 393.1408, val_MinusLogProbMetric: 393.1408

Epoch 706: val_loss did not improve from 392.49472
196/196 - 10s - loss: 390.7283 - MinusLogProbMetric: 390.7283 - val_loss: 393.1408 - val_MinusLogProbMetric: 393.1408 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 707/1000
2023-09-10 09:24:47.241 
Epoch 707/1000 
	 loss: 391.0937, MinusLogProbMetric: 391.0937, val_loss: 392.4943, val_MinusLogProbMetric: 392.4943

Epoch 707: val_loss improved from 392.49472 to 392.49432, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 391.0937 - MinusLogProbMetric: 391.0937 - val_loss: 392.4943 - val_MinusLogProbMetric: 392.4943 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 708/1000
2023-09-10 09:24:56.721 
Epoch 708/1000 
	 loss: 390.8411, MinusLogProbMetric: 390.8411, val_loss: 392.7281, val_MinusLogProbMetric: 392.7281

Epoch 708: val_loss did not improve from 392.49432
196/196 - 9s - loss: 390.8411 - MinusLogProbMetric: 390.8411 - val_loss: 392.7281 - val_MinusLogProbMetric: 392.7281 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 709/1000
2023-09-10 09:25:06.141 
Epoch 709/1000 
	 loss: 390.8936, MinusLogProbMetric: 390.8936, val_loss: 392.7115, val_MinusLogProbMetric: 392.7115

Epoch 709: val_loss did not improve from 392.49432
196/196 - 9s - loss: 390.8936 - MinusLogProbMetric: 390.8936 - val_loss: 392.7115 - val_MinusLogProbMetric: 392.7115 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 710/1000
2023-09-10 09:25:15.746 
Epoch 710/1000 
	 loss: 391.0392, MinusLogProbMetric: 391.0392, val_loss: 392.9772, val_MinusLogProbMetric: 392.9772

Epoch 710: val_loss did not improve from 392.49432
196/196 - 10s - loss: 391.0392 - MinusLogProbMetric: 391.0392 - val_loss: 392.9772 - val_MinusLogProbMetric: 392.9772 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 711/1000
2023-09-10 09:25:27.109 
Epoch 711/1000 
	 loss: 391.0956, MinusLogProbMetric: 391.0956, val_loss: 392.8669, val_MinusLogProbMetric: 392.8669

Epoch 711: val_loss did not improve from 392.49432
196/196 - 11s - loss: 391.0956 - MinusLogProbMetric: 391.0956 - val_loss: 392.8669 - val_MinusLogProbMetric: 392.8669 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 712/1000
2023-09-10 09:25:40.079 
Epoch 712/1000 
	 loss: 390.9324, MinusLogProbMetric: 390.9324, val_loss: 393.1836, val_MinusLogProbMetric: 393.1836

Epoch 712: val_loss did not improve from 392.49432
196/196 - 13s - loss: 390.9324 - MinusLogProbMetric: 390.9324 - val_loss: 393.1836 - val_MinusLogProbMetric: 393.1836 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 713/1000
2023-09-10 09:25:49.689 
Epoch 713/1000 
	 loss: 390.6967, MinusLogProbMetric: 390.6967, val_loss: 393.5130, val_MinusLogProbMetric: 393.5130

Epoch 713: val_loss did not improve from 392.49432
196/196 - 10s - loss: 390.6967 - MinusLogProbMetric: 390.6967 - val_loss: 393.5130 - val_MinusLogProbMetric: 393.5130 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 714/1000
2023-09-10 09:26:00.994 
Epoch 714/1000 
	 loss: 390.7410, MinusLogProbMetric: 390.7410, val_loss: 392.3525, val_MinusLogProbMetric: 392.3525

Epoch 714: val_loss improved from 392.49432 to 392.35251, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 390.7410 - MinusLogProbMetric: 390.7410 - val_loss: 392.3525 - val_MinusLogProbMetric: 392.3525 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 715/1000
2023-09-10 09:26:09.088 
Epoch 715/1000 
	 loss: 390.7800, MinusLogProbMetric: 390.7800, val_loss: 392.6439, val_MinusLogProbMetric: 392.6439

Epoch 715: val_loss did not improve from 392.35251
196/196 - 8s - loss: 390.7800 - MinusLogProbMetric: 390.7800 - val_loss: 392.6439 - val_MinusLogProbMetric: 392.6439 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 716/1000
2023-09-10 09:26:18.180 
Epoch 716/1000 
	 loss: 390.7580, MinusLogProbMetric: 390.7580, val_loss: 392.9421, val_MinusLogProbMetric: 392.9421

Epoch 716: val_loss did not improve from 392.35251
196/196 - 9s - loss: 390.7580 - MinusLogProbMetric: 390.7580 - val_loss: 392.9421 - val_MinusLogProbMetric: 392.9421 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 717/1000
2023-09-10 09:26:27.272 
Epoch 717/1000 
	 loss: 390.9666, MinusLogProbMetric: 390.9666, val_loss: 393.6050, val_MinusLogProbMetric: 393.6050

Epoch 717: val_loss did not improve from 392.35251
196/196 - 9s - loss: 390.9666 - MinusLogProbMetric: 390.9666 - val_loss: 393.6050 - val_MinusLogProbMetric: 393.6050 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 718/1000
2023-09-10 09:26:35.457 
Epoch 718/1000 
	 loss: 390.7957, MinusLogProbMetric: 390.7957, val_loss: 395.4949, val_MinusLogProbMetric: 395.4949

Epoch 718: val_loss did not improve from 392.35251
196/196 - 8s - loss: 390.7957 - MinusLogProbMetric: 390.7957 - val_loss: 395.4949 - val_MinusLogProbMetric: 395.4949 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 719/1000
2023-09-10 09:26:42.531 
Epoch 719/1000 
	 loss: 390.7804, MinusLogProbMetric: 390.7804, val_loss: 393.0515, val_MinusLogProbMetric: 393.0515

Epoch 719: val_loss did not improve from 392.35251
196/196 - 7s - loss: 390.7804 - MinusLogProbMetric: 390.7804 - val_loss: 393.0515 - val_MinusLogProbMetric: 393.0515 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 720/1000
2023-09-10 09:26:49.755 
Epoch 720/1000 
	 loss: 390.8957, MinusLogProbMetric: 390.8957, val_loss: 392.4718, val_MinusLogProbMetric: 392.4718

Epoch 720: val_loss did not improve from 392.35251
196/196 - 7s - loss: 390.8957 - MinusLogProbMetric: 390.8957 - val_loss: 392.4718 - val_MinusLogProbMetric: 392.4718 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 721/1000
2023-09-10 09:26:58.522 
Epoch 721/1000 
	 loss: 390.9305, MinusLogProbMetric: 390.9305, val_loss: 392.7537, val_MinusLogProbMetric: 392.7537

Epoch 721: val_loss did not improve from 392.35251
196/196 - 9s - loss: 390.9305 - MinusLogProbMetric: 390.9305 - val_loss: 392.7537 - val_MinusLogProbMetric: 392.7537 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 722/1000
2023-09-10 09:27:05.225 
Epoch 722/1000 
	 loss: 390.9328, MinusLogProbMetric: 390.9328, val_loss: 393.4449, val_MinusLogProbMetric: 393.4449

Epoch 722: val_loss did not improve from 392.35251
196/196 - 7s - loss: 390.9328 - MinusLogProbMetric: 390.9328 - val_loss: 393.4449 - val_MinusLogProbMetric: 393.4449 - lr: 1.6667e-04 - 7s/epoch - 34ms/step
Epoch 723/1000
2023-09-10 09:27:13.171 
Epoch 723/1000 
	 loss: 390.8827, MinusLogProbMetric: 390.8827, val_loss: 393.5089, val_MinusLogProbMetric: 393.5089

Epoch 723: val_loss did not improve from 392.35251
196/196 - 8s - loss: 390.8827 - MinusLogProbMetric: 390.8827 - val_loss: 393.5089 - val_MinusLogProbMetric: 393.5089 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 724/1000
2023-09-10 09:27:20.133 
Epoch 724/1000 
	 loss: 390.7518, MinusLogProbMetric: 390.7518, val_loss: 392.8342, val_MinusLogProbMetric: 392.8342

Epoch 724: val_loss did not improve from 392.35251
196/196 - 7s - loss: 390.7518 - MinusLogProbMetric: 390.7518 - val_loss: 392.8342 - val_MinusLogProbMetric: 392.8342 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 725/1000
2023-09-10 09:27:27.013 
Epoch 725/1000 
	 loss: 390.9082, MinusLogProbMetric: 390.9082, val_loss: 392.7046, val_MinusLogProbMetric: 392.7046

Epoch 725: val_loss did not improve from 392.35251
196/196 - 7s - loss: 390.9082 - MinusLogProbMetric: 390.9082 - val_loss: 392.7046 - val_MinusLogProbMetric: 392.7046 - lr: 1.6667e-04 - 7s/epoch - 35ms/step
Epoch 726/1000
2023-09-10 09:27:34.376 
Epoch 726/1000 
	 loss: 390.6651, MinusLogProbMetric: 390.6651, val_loss: 393.9227, val_MinusLogProbMetric: 393.9227

Epoch 726: val_loss did not improve from 392.35251
196/196 - 7s - loss: 390.6651 - MinusLogProbMetric: 390.6651 - val_loss: 393.9227 - val_MinusLogProbMetric: 393.9227 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 727/1000
2023-09-10 09:27:41.945 
Epoch 727/1000 
	 loss: 390.6881, MinusLogProbMetric: 390.6881, val_loss: 393.0617, val_MinusLogProbMetric: 393.0617

Epoch 727: val_loss did not improve from 392.35251
196/196 - 8s - loss: 390.6881 - MinusLogProbMetric: 390.6881 - val_loss: 393.0617 - val_MinusLogProbMetric: 393.0617 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 728/1000
2023-09-10 09:27:50.956 
Epoch 728/1000 
	 loss: 390.7330, MinusLogProbMetric: 390.7330, val_loss: 392.8977, val_MinusLogProbMetric: 392.8977

Epoch 728: val_loss did not improve from 392.35251
196/196 - 9s - loss: 390.7330 - MinusLogProbMetric: 390.7330 - val_loss: 392.8977 - val_MinusLogProbMetric: 392.8977 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 729/1000
2023-09-10 09:27:58.689 
Epoch 729/1000 
	 loss: 391.1048, MinusLogProbMetric: 391.1048, val_loss: 393.9847, val_MinusLogProbMetric: 393.9847

Epoch 729: val_loss did not improve from 392.35251
196/196 - 8s - loss: 391.1048 - MinusLogProbMetric: 391.1048 - val_loss: 393.9847 - val_MinusLogProbMetric: 393.9847 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 730/1000
2023-09-10 09:28:06.319 
Epoch 730/1000 
	 loss: 390.7718, MinusLogProbMetric: 390.7718, val_loss: 392.5305, val_MinusLogProbMetric: 392.5305

Epoch 730: val_loss did not improve from 392.35251
196/196 - 8s - loss: 390.7718 - MinusLogProbMetric: 390.7718 - val_loss: 392.5305 - val_MinusLogProbMetric: 392.5305 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 731/1000
2023-09-10 09:28:14.878 
Epoch 731/1000 
	 loss: 390.6766, MinusLogProbMetric: 390.6766, val_loss: 392.4805, val_MinusLogProbMetric: 392.4805

Epoch 731: val_loss did not improve from 392.35251
196/196 - 9s - loss: 390.6766 - MinusLogProbMetric: 390.6766 - val_loss: 392.4805 - val_MinusLogProbMetric: 392.4805 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 732/1000
2023-09-10 09:28:23.625 
Epoch 732/1000 
	 loss: 390.7545, MinusLogProbMetric: 390.7545, val_loss: 392.4588, val_MinusLogProbMetric: 392.4588

Epoch 732: val_loss did not improve from 392.35251
196/196 - 9s - loss: 390.7545 - MinusLogProbMetric: 390.7545 - val_loss: 392.4588 - val_MinusLogProbMetric: 392.4588 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 733/1000
2023-09-10 09:28:35.014 
Epoch 733/1000 
	 loss: 390.8477, MinusLogProbMetric: 390.8477, val_loss: 392.3585, val_MinusLogProbMetric: 392.3585

Epoch 733: val_loss did not improve from 392.35251
196/196 - 11s - loss: 390.8477 - MinusLogProbMetric: 390.8477 - val_loss: 392.3585 - val_MinusLogProbMetric: 392.3585 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 734/1000
2023-09-10 09:28:45.800 
Epoch 734/1000 
	 loss: 390.8768, MinusLogProbMetric: 390.8768, val_loss: 392.9065, val_MinusLogProbMetric: 392.9065

Epoch 734: val_loss did not improve from 392.35251
196/196 - 11s - loss: 390.8768 - MinusLogProbMetric: 390.8768 - val_loss: 392.9065 - val_MinusLogProbMetric: 392.9065 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 735/1000
2023-09-10 09:28:56.616 
Epoch 735/1000 
	 loss: 390.7964, MinusLogProbMetric: 390.7964, val_loss: 392.5512, val_MinusLogProbMetric: 392.5512

Epoch 735: val_loss did not improve from 392.35251
196/196 - 11s - loss: 390.7964 - MinusLogProbMetric: 390.7964 - val_loss: 392.5512 - val_MinusLogProbMetric: 392.5512 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 736/1000
2023-09-10 09:29:07.113 
Epoch 736/1000 
	 loss: 390.8068, MinusLogProbMetric: 390.8068, val_loss: 392.8807, val_MinusLogProbMetric: 392.8807

Epoch 736: val_loss did not improve from 392.35251
196/196 - 10s - loss: 390.8068 - MinusLogProbMetric: 390.8068 - val_loss: 392.8807 - val_MinusLogProbMetric: 392.8807 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 737/1000
2023-09-10 09:29:16.471 
Epoch 737/1000 
	 loss: 391.0246, MinusLogProbMetric: 391.0246, val_loss: 393.8712, val_MinusLogProbMetric: 393.8712

Epoch 737: val_loss did not improve from 392.35251
196/196 - 9s - loss: 391.0246 - MinusLogProbMetric: 391.0246 - val_loss: 393.8712 - val_MinusLogProbMetric: 393.8712 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 738/1000
2023-09-10 09:29:26.855 
Epoch 738/1000 
	 loss: 390.8378, MinusLogProbMetric: 390.8378, val_loss: 392.3921, val_MinusLogProbMetric: 392.3921

Epoch 738: val_loss did not improve from 392.35251
196/196 - 10s - loss: 390.8378 - MinusLogProbMetric: 390.8378 - val_loss: 392.3921 - val_MinusLogProbMetric: 392.3921 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 739/1000
2023-09-10 09:29:35.614 
Epoch 739/1000 
	 loss: 390.9663, MinusLogProbMetric: 390.9663, val_loss: 393.6034, val_MinusLogProbMetric: 393.6034

Epoch 739: val_loss did not improve from 392.35251
196/196 - 9s - loss: 390.9663 - MinusLogProbMetric: 390.9663 - val_loss: 393.6034 - val_MinusLogProbMetric: 393.6034 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 740/1000
2023-09-10 09:29:46.901 
Epoch 740/1000 
	 loss: 390.8168, MinusLogProbMetric: 390.8168, val_loss: 392.5392, val_MinusLogProbMetric: 392.5392

Epoch 740: val_loss did not improve from 392.35251
196/196 - 11s - loss: 390.8168 - MinusLogProbMetric: 390.8168 - val_loss: 392.5392 - val_MinusLogProbMetric: 392.5392 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 741/1000
2023-09-10 09:29:54.953 
Epoch 741/1000 
	 loss: 390.7831, MinusLogProbMetric: 390.7831, val_loss: 392.2596, val_MinusLogProbMetric: 392.2596

Epoch 741: val_loss improved from 392.35251 to 392.25964, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 390.7831 - MinusLogProbMetric: 390.7831 - val_loss: 392.2596 - val_MinusLogProbMetric: 392.2596 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 742/1000
2023-09-10 09:30:05.126 
Epoch 742/1000 
	 loss: 390.5544, MinusLogProbMetric: 390.5544, val_loss: 394.8305, val_MinusLogProbMetric: 394.8305

Epoch 742: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.5544 - MinusLogProbMetric: 390.5544 - val_loss: 394.8305 - val_MinusLogProbMetric: 394.8305 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 743/1000
2023-09-10 09:30:12.891 
Epoch 743/1000 
	 loss: 390.5409, MinusLogProbMetric: 390.5409, val_loss: 392.9073, val_MinusLogProbMetric: 392.9073

Epoch 743: val_loss did not improve from 392.25964
196/196 - 8s - loss: 390.5409 - MinusLogProbMetric: 390.5409 - val_loss: 392.9073 - val_MinusLogProbMetric: 392.9073 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 744/1000
2023-09-10 09:30:21.921 
Epoch 744/1000 
	 loss: 390.5396, MinusLogProbMetric: 390.5396, val_loss: 392.7540, val_MinusLogProbMetric: 392.7540

Epoch 744: val_loss did not improve from 392.25964
196/196 - 9s - loss: 390.5396 - MinusLogProbMetric: 390.5396 - val_loss: 392.7540 - val_MinusLogProbMetric: 392.7540 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 745/1000
2023-09-10 09:30:29.606 
Epoch 745/1000 
	 loss: 390.7281, MinusLogProbMetric: 390.7281, val_loss: 392.6554, val_MinusLogProbMetric: 392.6554

Epoch 745: val_loss did not improve from 392.25964
196/196 - 8s - loss: 390.7281 - MinusLogProbMetric: 390.7281 - val_loss: 392.6554 - val_MinusLogProbMetric: 392.6554 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 746/1000
2023-09-10 09:30:41.688 
Epoch 746/1000 
	 loss: 390.7756, MinusLogProbMetric: 390.7756, val_loss: 394.7386, val_MinusLogProbMetric: 394.7386

Epoch 746: val_loss did not improve from 392.25964
196/196 - 12s - loss: 390.7756 - MinusLogProbMetric: 390.7756 - val_loss: 394.7386 - val_MinusLogProbMetric: 394.7386 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 747/1000
2023-09-10 09:30:51.669 
Epoch 747/1000 
	 loss: 390.8379, MinusLogProbMetric: 390.8379, val_loss: 393.0948, val_MinusLogProbMetric: 393.0948

Epoch 747: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.8379 - MinusLogProbMetric: 390.8379 - val_loss: 393.0948 - val_MinusLogProbMetric: 393.0948 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 748/1000
2023-09-10 09:31:03.079 
Epoch 748/1000 
	 loss: 390.6651, MinusLogProbMetric: 390.6651, val_loss: 392.2942, val_MinusLogProbMetric: 392.2942

Epoch 748: val_loss did not improve from 392.25964
196/196 - 11s - loss: 390.6651 - MinusLogProbMetric: 390.6651 - val_loss: 392.2942 - val_MinusLogProbMetric: 392.2942 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 749/1000
2023-09-10 09:31:13.143 
Epoch 749/1000 
	 loss: 390.5729, MinusLogProbMetric: 390.5729, val_loss: 393.0486, val_MinusLogProbMetric: 393.0486

Epoch 749: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.5729 - MinusLogProbMetric: 390.5729 - val_loss: 393.0486 - val_MinusLogProbMetric: 393.0486 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 750/1000
2023-09-10 09:31:21.953 
Epoch 750/1000 
	 loss: 390.6933, MinusLogProbMetric: 390.6933, val_loss: 392.8976, val_MinusLogProbMetric: 392.8976

Epoch 750: val_loss did not improve from 392.25964
196/196 - 9s - loss: 390.6933 - MinusLogProbMetric: 390.6933 - val_loss: 392.8976 - val_MinusLogProbMetric: 392.8976 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 751/1000
2023-09-10 09:31:31.452 
Epoch 751/1000 
	 loss: 390.7824, MinusLogProbMetric: 390.7824, val_loss: 395.8366, val_MinusLogProbMetric: 395.8366

Epoch 751: val_loss did not improve from 392.25964
196/196 - 9s - loss: 390.7824 - MinusLogProbMetric: 390.7824 - val_loss: 395.8366 - val_MinusLogProbMetric: 395.8366 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 752/1000
2023-09-10 09:31:43.047 
Epoch 752/1000 
	 loss: 390.8602, MinusLogProbMetric: 390.8602, val_loss: 392.5020, val_MinusLogProbMetric: 392.5020

Epoch 752: val_loss did not improve from 392.25964
196/196 - 12s - loss: 390.8602 - MinusLogProbMetric: 390.8602 - val_loss: 392.5020 - val_MinusLogProbMetric: 392.5020 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 753/1000
2023-09-10 09:31:52.589 
Epoch 753/1000 
	 loss: 390.9026, MinusLogProbMetric: 390.9026, val_loss: 392.4292, val_MinusLogProbMetric: 392.4292

Epoch 753: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.9026 - MinusLogProbMetric: 390.9026 - val_loss: 392.4292 - val_MinusLogProbMetric: 392.4292 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 754/1000
2023-09-10 09:32:02.136 
Epoch 754/1000 
	 loss: 390.7491, MinusLogProbMetric: 390.7491, val_loss: 393.3199, val_MinusLogProbMetric: 393.3199

Epoch 754: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.7491 - MinusLogProbMetric: 390.7491 - val_loss: 393.3199 - val_MinusLogProbMetric: 393.3199 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 755/1000
2023-09-10 09:32:09.612 
Epoch 755/1000 
	 loss: 390.8674, MinusLogProbMetric: 390.8674, val_loss: 392.5763, val_MinusLogProbMetric: 392.5763

Epoch 755: val_loss did not improve from 392.25964
196/196 - 7s - loss: 390.8674 - MinusLogProbMetric: 390.8674 - val_loss: 392.5763 - val_MinusLogProbMetric: 392.5763 - lr: 1.6667e-04 - 7s/epoch - 38ms/step
Epoch 756/1000
2023-09-10 09:32:19.588 
Epoch 756/1000 
	 loss: 390.6094, MinusLogProbMetric: 390.6094, val_loss: 392.7714, val_MinusLogProbMetric: 392.7714

Epoch 756: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.6094 - MinusLogProbMetric: 390.6094 - val_loss: 392.7714 - val_MinusLogProbMetric: 392.7714 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 757/1000
2023-09-10 09:32:28.973 
Epoch 757/1000 
	 loss: 390.7623, MinusLogProbMetric: 390.7623, val_loss: 392.6505, val_MinusLogProbMetric: 392.6505

Epoch 757: val_loss did not improve from 392.25964
196/196 - 9s - loss: 390.7623 - MinusLogProbMetric: 390.7623 - val_loss: 392.6505 - val_MinusLogProbMetric: 392.6505 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 758/1000
2023-09-10 09:32:40.617 
Epoch 758/1000 
	 loss: 390.7592, MinusLogProbMetric: 390.7592, val_loss: 392.2675, val_MinusLogProbMetric: 392.2675

Epoch 758: val_loss did not improve from 392.25964
196/196 - 12s - loss: 390.7592 - MinusLogProbMetric: 390.7592 - val_loss: 392.2675 - val_MinusLogProbMetric: 392.2675 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 759/1000
2023-09-10 09:32:50.979 
Epoch 759/1000 
	 loss: 390.7108, MinusLogProbMetric: 390.7108, val_loss: 392.3198, val_MinusLogProbMetric: 392.3198

Epoch 759: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.7108 - MinusLogProbMetric: 390.7108 - val_loss: 392.3198 - val_MinusLogProbMetric: 392.3198 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 760/1000
2023-09-10 09:32:58.648 
Epoch 760/1000 
	 loss: 390.6331, MinusLogProbMetric: 390.6331, val_loss: 394.8251, val_MinusLogProbMetric: 394.8251

Epoch 760: val_loss did not improve from 392.25964
196/196 - 8s - loss: 390.6331 - MinusLogProbMetric: 390.6331 - val_loss: 394.8251 - val_MinusLogProbMetric: 394.8251 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 761/1000
2023-09-10 09:33:07.227 
Epoch 761/1000 
	 loss: 390.7727, MinusLogProbMetric: 390.7727, val_loss: 392.5343, val_MinusLogProbMetric: 392.5343

Epoch 761: val_loss did not improve from 392.25964
196/196 - 9s - loss: 390.7727 - MinusLogProbMetric: 390.7727 - val_loss: 392.5343 - val_MinusLogProbMetric: 392.5343 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 762/1000
2023-09-10 09:33:16.523 
Epoch 762/1000 
	 loss: 390.6736, MinusLogProbMetric: 390.6736, val_loss: 392.3440, val_MinusLogProbMetric: 392.3440

Epoch 762: val_loss did not improve from 392.25964
196/196 - 9s - loss: 390.6736 - MinusLogProbMetric: 390.6736 - val_loss: 392.3440 - val_MinusLogProbMetric: 392.3440 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 763/1000
2023-09-10 09:33:24.840 
Epoch 763/1000 
	 loss: 390.6260, MinusLogProbMetric: 390.6260, val_loss: 392.7370, val_MinusLogProbMetric: 392.7370

Epoch 763: val_loss did not improve from 392.25964
196/196 - 8s - loss: 390.6260 - MinusLogProbMetric: 390.6260 - val_loss: 392.7370 - val_MinusLogProbMetric: 392.7370 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 764/1000
2023-09-10 09:33:35.060 
Epoch 764/1000 
	 loss: 390.6797, MinusLogProbMetric: 390.6797, val_loss: 392.3229, val_MinusLogProbMetric: 392.3229

Epoch 764: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.6797 - MinusLogProbMetric: 390.6797 - val_loss: 392.3229 - val_MinusLogProbMetric: 392.3229 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 765/1000
2023-09-10 09:33:44.938 
Epoch 765/1000 
	 loss: 390.8785, MinusLogProbMetric: 390.8785, val_loss: 393.9899, val_MinusLogProbMetric: 393.9899

Epoch 765: val_loss did not improve from 392.25964
196/196 - 10s - loss: 390.8785 - MinusLogProbMetric: 390.8785 - val_loss: 393.9899 - val_MinusLogProbMetric: 393.9899 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 766/1000
2023-09-10 09:33:52.823 
Epoch 766/1000 
	 loss: 390.6963, MinusLogProbMetric: 390.6963, val_loss: 392.2865, val_MinusLogProbMetric: 392.2865

Epoch 766: val_loss did not improve from 392.25964
196/196 - 8s - loss: 390.6963 - MinusLogProbMetric: 390.6963 - val_loss: 392.2865 - val_MinusLogProbMetric: 392.2865 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 767/1000
2023-09-10 09:34:02.139 
Epoch 767/1000 
	 loss: 390.7320, MinusLogProbMetric: 390.7320, val_loss: 393.1384, val_MinusLogProbMetric: 393.1384

Epoch 767: val_loss did not improve from 392.25964
196/196 - 9s - loss: 390.7320 - MinusLogProbMetric: 390.7320 - val_loss: 393.1384 - val_MinusLogProbMetric: 393.1384 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 768/1000
2023-09-10 09:34:09.973 
Epoch 768/1000 
	 loss: 390.7523, MinusLogProbMetric: 390.7523, val_loss: 392.5905, val_MinusLogProbMetric: 392.5905

Epoch 768: val_loss did not improve from 392.25964
196/196 - 8s - loss: 390.7523 - MinusLogProbMetric: 390.7523 - val_loss: 392.5905 - val_MinusLogProbMetric: 392.5905 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 769/1000
2023-09-10 09:34:19.955 
Epoch 769/1000 
	 loss: 390.5234, MinusLogProbMetric: 390.5234, val_loss: 392.2570, val_MinusLogProbMetric: 392.2570

Epoch 769: val_loss improved from 392.25964 to 392.25696, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 390.5234 - MinusLogProbMetric: 390.5234 - val_loss: 392.2570 - val_MinusLogProbMetric: 392.2570 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 770/1000
2023-09-10 09:34:29.029 
Epoch 770/1000 
	 loss: 391.1035, MinusLogProbMetric: 391.1035, val_loss: 393.2245, val_MinusLogProbMetric: 393.2245

Epoch 770: val_loss did not improve from 392.25696
196/196 - 9s - loss: 391.1035 - MinusLogProbMetric: 391.1035 - val_loss: 393.2245 - val_MinusLogProbMetric: 393.2245 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 771/1000
2023-09-10 09:34:38.573 
Epoch 771/1000 
	 loss: 390.6323, MinusLogProbMetric: 390.6323, val_loss: 392.3831, val_MinusLogProbMetric: 392.3831

Epoch 771: val_loss did not improve from 392.25696
196/196 - 10s - loss: 390.6323 - MinusLogProbMetric: 390.6323 - val_loss: 392.3831 - val_MinusLogProbMetric: 392.3831 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 772/1000
2023-09-10 09:34:49.505 
Epoch 772/1000 
	 loss: 390.5943, MinusLogProbMetric: 390.5943, val_loss: 392.3899, val_MinusLogProbMetric: 392.3899

Epoch 772: val_loss did not improve from 392.25696
196/196 - 11s - loss: 390.5943 - MinusLogProbMetric: 390.5943 - val_loss: 392.3899 - val_MinusLogProbMetric: 392.3899 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 773/1000
2023-09-10 09:34:58.435 
Epoch 773/1000 
	 loss: 390.4287, MinusLogProbMetric: 390.4287, val_loss: 392.2907, val_MinusLogProbMetric: 392.2907

Epoch 773: val_loss did not improve from 392.25696
196/196 - 9s - loss: 390.4287 - MinusLogProbMetric: 390.4287 - val_loss: 392.2907 - val_MinusLogProbMetric: 392.2907 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 774/1000
2023-09-10 09:35:08.748 
Epoch 774/1000 
	 loss: 390.4412, MinusLogProbMetric: 390.4412, val_loss: 392.3999, val_MinusLogProbMetric: 392.3999

Epoch 774: val_loss did not improve from 392.25696
196/196 - 10s - loss: 390.4412 - MinusLogProbMetric: 390.4412 - val_loss: 392.3999 - val_MinusLogProbMetric: 392.3999 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 775/1000
2023-09-10 09:35:16.392 
Epoch 775/1000 
	 loss: 390.6099, MinusLogProbMetric: 390.6099, val_loss: 394.0430, val_MinusLogProbMetric: 394.0430

Epoch 775: val_loss did not improve from 392.25696
196/196 - 8s - loss: 390.6099 - MinusLogProbMetric: 390.6099 - val_loss: 394.0430 - val_MinusLogProbMetric: 394.0430 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 776/1000
2023-09-10 09:35:24.756 
Epoch 776/1000 
	 loss: 390.5305, MinusLogProbMetric: 390.5305, val_loss: 392.5283, val_MinusLogProbMetric: 392.5283

Epoch 776: val_loss did not improve from 392.25696
196/196 - 8s - loss: 390.5305 - MinusLogProbMetric: 390.5305 - val_loss: 392.5283 - val_MinusLogProbMetric: 392.5283 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 777/1000
2023-09-10 09:35:34.387 
Epoch 777/1000 
	 loss: 390.6358, MinusLogProbMetric: 390.6358, val_loss: 392.7039, val_MinusLogProbMetric: 392.7039

Epoch 777: val_loss did not improve from 392.25696
196/196 - 10s - loss: 390.6358 - MinusLogProbMetric: 390.6358 - val_loss: 392.7039 - val_MinusLogProbMetric: 392.7039 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 778/1000
2023-09-10 09:35:44.294 
Epoch 778/1000 
	 loss: 390.4391, MinusLogProbMetric: 390.4391, val_loss: 392.2503, val_MinusLogProbMetric: 392.2503

Epoch 778: val_loss improved from 392.25696 to 392.25031, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 390.4391 - MinusLogProbMetric: 390.4391 - val_loss: 392.2503 - val_MinusLogProbMetric: 392.2503 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 779/1000
2023-09-10 09:35:52.037 
Epoch 779/1000 
	 loss: 390.9234, MinusLogProbMetric: 390.9234, val_loss: 392.3859, val_MinusLogProbMetric: 392.3859

Epoch 779: val_loss did not improve from 392.25031
196/196 - 7s - loss: 390.9234 - MinusLogProbMetric: 390.9234 - val_loss: 392.3859 - val_MinusLogProbMetric: 392.3859 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 780/1000
2023-09-10 09:36:02.107 
Epoch 780/1000 
	 loss: 390.5482, MinusLogProbMetric: 390.5482, val_loss: 393.4275, val_MinusLogProbMetric: 393.4275

Epoch 780: val_loss did not improve from 392.25031
196/196 - 10s - loss: 390.5482 - MinusLogProbMetric: 390.5482 - val_loss: 393.4275 - val_MinusLogProbMetric: 393.4275 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 781/1000
2023-09-10 09:36:12.671 
Epoch 781/1000 
	 loss: 390.7622, MinusLogProbMetric: 390.7622, val_loss: 392.7356, val_MinusLogProbMetric: 392.7356

Epoch 781: val_loss did not improve from 392.25031
196/196 - 11s - loss: 390.7622 - MinusLogProbMetric: 390.7622 - val_loss: 392.7356 - val_MinusLogProbMetric: 392.7356 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 782/1000
2023-09-10 09:36:20.208 
Epoch 782/1000 
	 loss: 390.6868, MinusLogProbMetric: 390.6868, val_loss: 392.9315, val_MinusLogProbMetric: 392.9315

Epoch 782: val_loss did not improve from 392.25031
196/196 - 8s - loss: 390.6868 - MinusLogProbMetric: 390.6868 - val_loss: 392.9315 - val_MinusLogProbMetric: 392.9315 - lr: 1.6667e-04 - 8s/epoch - 38ms/step
Epoch 783/1000
2023-09-10 09:36:28.182 
Epoch 783/1000 
	 loss: 390.5439, MinusLogProbMetric: 390.5439, val_loss: 392.4911, val_MinusLogProbMetric: 392.4911

Epoch 783: val_loss did not improve from 392.25031
196/196 - 8s - loss: 390.5439 - MinusLogProbMetric: 390.5439 - val_loss: 392.4911 - val_MinusLogProbMetric: 392.4911 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 784/1000
2023-09-10 09:36:37.664 
Epoch 784/1000 
	 loss: 390.4155, MinusLogProbMetric: 390.4155, val_loss: 392.8740, val_MinusLogProbMetric: 392.8740

Epoch 784: val_loss did not improve from 392.25031
196/196 - 9s - loss: 390.4155 - MinusLogProbMetric: 390.4155 - val_loss: 392.8740 - val_MinusLogProbMetric: 392.8740 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 785/1000
2023-09-10 09:36:46.460 
Epoch 785/1000 
	 loss: 390.5414, MinusLogProbMetric: 390.5414, val_loss: 392.5700, val_MinusLogProbMetric: 392.5700

Epoch 785: val_loss did not improve from 392.25031
196/196 - 9s - loss: 390.5414 - MinusLogProbMetric: 390.5414 - val_loss: 392.5700 - val_MinusLogProbMetric: 392.5700 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 786/1000
2023-09-10 09:36:54.009 
Epoch 786/1000 
	 loss: 390.5416, MinusLogProbMetric: 390.5416, val_loss: 392.4141, val_MinusLogProbMetric: 392.4141

Epoch 786: val_loss did not improve from 392.25031
196/196 - 8s - loss: 390.5416 - MinusLogProbMetric: 390.5416 - val_loss: 392.4141 - val_MinusLogProbMetric: 392.4141 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 787/1000
2023-09-10 09:37:02.528 
Epoch 787/1000 
	 loss: 390.6018, MinusLogProbMetric: 390.6018, val_loss: 393.5937, val_MinusLogProbMetric: 393.5937

Epoch 787: val_loss did not improve from 392.25031
196/196 - 8s - loss: 390.6018 - MinusLogProbMetric: 390.6018 - val_loss: 393.5937 - val_MinusLogProbMetric: 393.5937 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 788/1000
2023-09-10 09:37:11.184 
Epoch 788/1000 
	 loss: 390.5505, MinusLogProbMetric: 390.5505, val_loss: 393.1123, val_MinusLogProbMetric: 393.1123

Epoch 788: val_loss did not improve from 392.25031
196/196 - 9s - loss: 390.5505 - MinusLogProbMetric: 390.5505 - val_loss: 393.1123 - val_MinusLogProbMetric: 393.1123 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 789/1000
2023-09-10 09:37:19.865 
Epoch 789/1000 
	 loss: 390.6584, MinusLogProbMetric: 390.6584, val_loss: 392.0390, val_MinusLogProbMetric: 392.0390

Epoch 789: val_loss improved from 392.25031 to 392.03903, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 390.6584 - MinusLogProbMetric: 390.6584 - val_loss: 392.0390 - val_MinusLogProbMetric: 392.0390 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 790/1000
2023-09-10 09:37:28.850 
Epoch 790/1000 
	 loss: 390.5796, MinusLogProbMetric: 390.5796, val_loss: 392.2159, val_MinusLogProbMetric: 392.2159

Epoch 790: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5796 - MinusLogProbMetric: 390.5796 - val_loss: 392.2159 - val_MinusLogProbMetric: 392.2159 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 791/1000
2023-09-10 09:37:35.906 
Epoch 791/1000 
	 loss: 390.7982, MinusLogProbMetric: 390.7982, val_loss: 392.4863, val_MinusLogProbMetric: 392.4863

Epoch 791: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.7982 - MinusLogProbMetric: 390.7982 - val_loss: 392.4863 - val_MinusLogProbMetric: 392.4863 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 792/1000
2023-09-10 09:37:44.813 
Epoch 792/1000 
	 loss: 390.3924, MinusLogProbMetric: 390.3924, val_loss: 392.5426, val_MinusLogProbMetric: 392.5426

Epoch 792: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.3924 - MinusLogProbMetric: 390.3924 - val_loss: 392.5426 - val_MinusLogProbMetric: 392.5426 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 793/1000
2023-09-10 09:37:55.993 
Epoch 793/1000 
	 loss: 390.4360, MinusLogProbMetric: 390.4360, val_loss: 392.4492, val_MinusLogProbMetric: 392.4492

Epoch 793: val_loss did not improve from 392.03903
196/196 - 11s - loss: 390.4360 - MinusLogProbMetric: 390.4360 - val_loss: 392.4492 - val_MinusLogProbMetric: 392.4492 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 794/1000
2023-09-10 09:38:03.536 
Epoch 794/1000 
	 loss: 390.5826, MinusLogProbMetric: 390.5826, val_loss: 393.3623, val_MinusLogProbMetric: 393.3623

Epoch 794: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.5826 - MinusLogProbMetric: 390.5826 - val_loss: 393.3623 - val_MinusLogProbMetric: 393.3623 - lr: 1.6667e-04 - 8s/epoch - 38ms/step
Epoch 795/1000
2023-09-10 09:38:11.273 
Epoch 795/1000 
	 loss: 390.6079, MinusLogProbMetric: 390.6079, val_loss: 392.7554, val_MinusLogProbMetric: 392.7554

Epoch 795: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.6079 - MinusLogProbMetric: 390.6079 - val_loss: 392.7554 - val_MinusLogProbMetric: 392.7554 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 796/1000
2023-09-10 09:38:18.998 
Epoch 796/1000 
	 loss: 390.6012, MinusLogProbMetric: 390.6012, val_loss: 392.9493, val_MinusLogProbMetric: 392.9493

Epoch 796: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.6012 - MinusLogProbMetric: 390.6012 - val_loss: 392.9493 - val_MinusLogProbMetric: 392.9493 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 797/1000
2023-09-10 09:38:26.048 
Epoch 797/1000 
	 loss: 390.5508, MinusLogProbMetric: 390.5508, val_loss: 392.2133, val_MinusLogProbMetric: 392.2133

Epoch 797: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.5508 - MinusLogProbMetric: 390.5508 - val_loss: 392.2133 - val_MinusLogProbMetric: 392.2133 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 798/1000
2023-09-10 09:38:34.769 
Epoch 798/1000 
	 loss: 390.4699, MinusLogProbMetric: 390.4699, val_loss: 395.0076, val_MinusLogProbMetric: 395.0076

Epoch 798: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.4699 - MinusLogProbMetric: 390.4699 - val_loss: 395.0076 - val_MinusLogProbMetric: 395.0076 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 799/1000
2023-09-10 09:38:43.609 
Epoch 799/1000 
	 loss: 390.5878, MinusLogProbMetric: 390.5878, val_loss: 392.6961, val_MinusLogProbMetric: 392.6961

Epoch 799: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5878 - MinusLogProbMetric: 390.5878 - val_loss: 392.6961 - val_MinusLogProbMetric: 392.6961 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 800/1000
2023-09-10 09:38:52.839 
Epoch 800/1000 
	 loss: 390.5947, MinusLogProbMetric: 390.5947, val_loss: 392.4019, val_MinusLogProbMetric: 392.4019

Epoch 800: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5947 - MinusLogProbMetric: 390.5947 - val_loss: 392.4019 - val_MinusLogProbMetric: 392.4019 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 801/1000
2023-09-10 09:39:00.840 
Epoch 801/1000 
	 loss: 390.4843, MinusLogProbMetric: 390.4843, val_loss: 392.4410, val_MinusLogProbMetric: 392.4410

Epoch 801: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.4843 - MinusLogProbMetric: 390.4843 - val_loss: 392.4410 - val_MinusLogProbMetric: 392.4410 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 802/1000
2023-09-10 09:39:09.497 
Epoch 802/1000 
	 loss: 390.4312, MinusLogProbMetric: 390.4312, val_loss: 392.8632, val_MinusLogProbMetric: 392.8632

Epoch 802: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.4312 - MinusLogProbMetric: 390.4312 - val_loss: 392.8632 - val_MinusLogProbMetric: 392.8632 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 803/1000
2023-09-10 09:39:16.828 
Epoch 803/1000 
	 loss: 390.5934, MinusLogProbMetric: 390.5934, val_loss: 393.7094, val_MinusLogProbMetric: 393.7094

Epoch 803: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.5934 - MinusLogProbMetric: 390.5934 - val_loss: 393.7094 - val_MinusLogProbMetric: 393.7094 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 804/1000
2023-09-10 09:39:26.016 
Epoch 804/1000 
	 loss: 390.7102, MinusLogProbMetric: 390.7102, val_loss: 394.9637, val_MinusLogProbMetric: 394.9637

Epoch 804: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.7102 - MinusLogProbMetric: 390.7102 - val_loss: 394.9637 - val_MinusLogProbMetric: 394.9637 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 805/1000
2023-09-10 09:39:33.845 
Epoch 805/1000 
	 loss: 390.5948, MinusLogProbMetric: 390.5948, val_loss: 393.1907, val_MinusLogProbMetric: 393.1907

Epoch 805: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.5948 - MinusLogProbMetric: 390.5948 - val_loss: 393.1907 - val_MinusLogProbMetric: 393.1907 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 806/1000
2023-09-10 09:39:41.957 
Epoch 806/1000 
	 loss: 390.4975, MinusLogProbMetric: 390.4975, val_loss: 392.3293, val_MinusLogProbMetric: 392.3293

Epoch 806: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.4975 - MinusLogProbMetric: 390.4975 - val_loss: 392.3293 - val_MinusLogProbMetric: 392.3293 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 807/1000
2023-09-10 09:39:50.091 
Epoch 807/1000 
	 loss: 390.7048, MinusLogProbMetric: 390.7048, val_loss: 392.8692, val_MinusLogProbMetric: 392.8692

Epoch 807: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.7048 - MinusLogProbMetric: 390.7048 - val_loss: 392.8692 - val_MinusLogProbMetric: 392.8692 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 808/1000
2023-09-10 09:39:57.823 
Epoch 808/1000 
	 loss: 390.9105, MinusLogProbMetric: 390.9105, val_loss: 394.3906, val_MinusLogProbMetric: 394.3906

Epoch 808: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.9105 - MinusLogProbMetric: 390.9105 - val_loss: 394.3906 - val_MinusLogProbMetric: 394.3906 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 809/1000
2023-09-10 09:40:05.631 
Epoch 809/1000 
	 loss: 390.5787, MinusLogProbMetric: 390.5787, val_loss: 393.5129, val_MinusLogProbMetric: 393.5129

Epoch 809: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.5787 - MinusLogProbMetric: 390.5787 - val_loss: 393.5129 - val_MinusLogProbMetric: 393.5129 - lr: 1.6667e-04 - 8s/epoch - 40ms/step
Epoch 810/1000
2023-09-10 09:40:14.662 
Epoch 810/1000 
	 loss: 390.5402, MinusLogProbMetric: 390.5402, val_loss: 393.5413, val_MinusLogProbMetric: 393.5413

Epoch 810: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5402 - MinusLogProbMetric: 390.5402 - val_loss: 393.5413 - val_MinusLogProbMetric: 393.5413 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 811/1000
2023-09-10 09:40:22.845 
Epoch 811/1000 
	 loss: 390.3904, MinusLogProbMetric: 390.3904, val_loss: 392.7520, val_MinusLogProbMetric: 392.7520

Epoch 811: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.3904 - MinusLogProbMetric: 390.3904 - val_loss: 392.7520 - val_MinusLogProbMetric: 392.7520 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 812/1000
2023-09-10 09:40:30.851 
Epoch 812/1000 
	 loss: 390.6061, MinusLogProbMetric: 390.6061, val_loss: 392.1734, val_MinusLogProbMetric: 392.1734

Epoch 812: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.6061 - MinusLogProbMetric: 390.6061 - val_loss: 392.1734 - val_MinusLogProbMetric: 392.1734 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 813/1000
2023-09-10 09:40:38.098 
Epoch 813/1000 
	 loss: 390.3463, MinusLogProbMetric: 390.3463, val_loss: 393.7173, val_MinusLogProbMetric: 393.7173

Epoch 813: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.3463 - MinusLogProbMetric: 390.3463 - val_loss: 393.7173 - val_MinusLogProbMetric: 393.7173 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 814/1000
2023-09-10 09:40:45.089 
Epoch 814/1000 
	 loss: 390.4870, MinusLogProbMetric: 390.4870, val_loss: 392.4124, val_MinusLogProbMetric: 392.4124

Epoch 814: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.4870 - MinusLogProbMetric: 390.4870 - val_loss: 392.4124 - val_MinusLogProbMetric: 392.4124 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 815/1000
2023-09-10 09:40:54.737 
Epoch 815/1000 
	 loss: 390.3542, MinusLogProbMetric: 390.3542, val_loss: 394.1790, val_MinusLogProbMetric: 394.1790

Epoch 815: val_loss did not improve from 392.03903
196/196 - 10s - loss: 390.3542 - MinusLogProbMetric: 390.3542 - val_loss: 394.1790 - val_MinusLogProbMetric: 394.1790 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 816/1000
2023-09-10 09:41:04.387 
Epoch 816/1000 
	 loss: 390.7293, MinusLogProbMetric: 390.7293, val_loss: 392.2036, val_MinusLogProbMetric: 392.2036

Epoch 816: val_loss did not improve from 392.03903
196/196 - 10s - loss: 390.7293 - MinusLogProbMetric: 390.7293 - val_loss: 392.2036 - val_MinusLogProbMetric: 392.2036 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 817/1000
2023-09-10 09:41:12.119 
Epoch 817/1000 
	 loss: 390.5070, MinusLogProbMetric: 390.5070, val_loss: 392.1410, val_MinusLogProbMetric: 392.1410

Epoch 817: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.5070 - MinusLogProbMetric: 390.5070 - val_loss: 392.1410 - val_MinusLogProbMetric: 392.1410 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 818/1000
2023-09-10 09:41:20.603 
Epoch 818/1000 
	 loss: 390.4435, MinusLogProbMetric: 390.4435, val_loss: 392.8732, val_MinusLogProbMetric: 392.8732

Epoch 818: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.4435 - MinusLogProbMetric: 390.4435 - val_loss: 392.8732 - val_MinusLogProbMetric: 392.8732 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 819/1000
2023-09-10 09:41:27.905 
Epoch 819/1000 
	 loss: 390.3097, MinusLogProbMetric: 390.3097, val_loss: 393.4402, val_MinusLogProbMetric: 393.4402

Epoch 819: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.3097 - MinusLogProbMetric: 390.3097 - val_loss: 393.4402 - val_MinusLogProbMetric: 393.4402 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 820/1000
2023-09-10 09:41:37.162 
Epoch 820/1000 
	 loss: 390.5253, MinusLogProbMetric: 390.5253, val_loss: 392.1371, val_MinusLogProbMetric: 392.1371

Epoch 820: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5253 - MinusLogProbMetric: 390.5253 - val_loss: 392.1371 - val_MinusLogProbMetric: 392.1371 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 821/1000
2023-09-10 09:41:46.117 
Epoch 821/1000 
	 loss: 390.5099, MinusLogProbMetric: 390.5099, val_loss: 393.6822, val_MinusLogProbMetric: 393.6822

Epoch 821: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5099 - MinusLogProbMetric: 390.5099 - val_loss: 393.6822 - val_MinusLogProbMetric: 393.6822 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 822/1000
2023-09-10 09:41:55.016 
Epoch 822/1000 
	 loss: 390.3427, MinusLogProbMetric: 390.3427, val_loss: 392.6423, val_MinusLogProbMetric: 392.6423

Epoch 822: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.3427 - MinusLogProbMetric: 390.3427 - val_loss: 392.6423 - val_MinusLogProbMetric: 392.6423 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 823/1000
2023-09-10 09:42:02.619 
Epoch 823/1000 
	 loss: 390.3517, MinusLogProbMetric: 390.3517, val_loss: 392.7950, val_MinusLogProbMetric: 392.7950

Epoch 823: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.3517 - MinusLogProbMetric: 390.3517 - val_loss: 392.7950 - val_MinusLogProbMetric: 392.7950 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 824/1000
2023-09-10 09:42:11.184 
Epoch 824/1000 
	 loss: 390.4536, MinusLogProbMetric: 390.4536, val_loss: 392.6942, val_MinusLogProbMetric: 392.6942

Epoch 824: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.4536 - MinusLogProbMetric: 390.4536 - val_loss: 392.6942 - val_MinusLogProbMetric: 392.6942 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 825/1000
2023-09-10 09:42:18.760 
Epoch 825/1000 
	 loss: 390.6999, MinusLogProbMetric: 390.6999, val_loss: 393.0792, val_MinusLogProbMetric: 393.0792

Epoch 825: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.6999 - MinusLogProbMetric: 390.6999 - val_loss: 393.0792 - val_MinusLogProbMetric: 393.0792 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 826/1000
2023-09-10 09:42:27.614 
Epoch 826/1000 
	 loss: 390.4670, MinusLogProbMetric: 390.4670, val_loss: 392.2349, val_MinusLogProbMetric: 392.2349

Epoch 826: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.4670 - MinusLogProbMetric: 390.4670 - val_loss: 392.2349 - val_MinusLogProbMetric: 392.2349 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 827/1000
2023-09-10 09:42:36.534 
Epoch 827/1000 
	 loss: 390.3204, MinusLogProbMetric: 390.3204, val_loss: 392.4255, val_MinusLogProbMetric: 392.4255

Epoch 827: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.3204 - MinusLogProbMetric: 390.3204 - val_loss: 392.4255 - val_MinusLogProbMetric: 392.4255 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 828/1000
2023-09-10 09:42:46.942 
Epoch 828/1000 
	 loss: 390.2608, MinusLogProbMetric: 390.2608, val_loss: 392.3612, val_MinusLogProbMetric: 392.3612

Epoch 828: val_loss did not improve from 392.03903
196/196 - 10s - loss: 390.2608 - MinusLogProbMetric: 390.2608 - val_loss: 392.3612 - val_MinusLogProbMetric: 392.3612 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 829/1000
2023-09-10 09:42:54.504 
Epoch 829/1000 
	 loss: 390.3549, MinusLogProbMetric: 390.3549, val_loss: 392.4944, val_MinusLogProbMetric: 392.4944

Epoch 829: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.3549 - MinusLogProbMetric: 390.3549 - val_loss: 392.4944 - val_MinusLogProbMetric: 392.4944 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 830/1000
2023-09-10 09:43:03.121 
Epoch 830/1000 
	 loss: 390.3720, MinusLogProbMetric: 390.3720, val_loss: 392.9111, val_MinusLogProbMetric: 392.9111

Epoch 830: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.3720 - MinusLogProbMetric: 390.3720 - val_loss: 392.9111 - val_MinusLogProbMetric: 392.9111 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 831/1000
2023-09-10 09:43:11.097 
Epoch 831/1000 
	 loss: 390.5748, MinusLogProbMetric: 390.5748, val_loss: 392.5480, val_MinusLogProbMetric: 392.5480

Epoch 831: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.5748 - MinusLogProbMetric: 390.5748 - val_loss: 392.5480 - val_MinusLogProbMetric: 392.5480 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 832/1000
2023-09-10 09:43:19.908 
Epoch 832/1000 
	 loss: 390.6054, MinusLogProbMetric: 390.6054, val_loss: 392.1532, val_MinusLogProbMetric: 392.1532

Epoch 832: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.6054 - MinusLogProbMetric: 390.6054 - val_loss: 392.1532 - val_MinusLogProbMetric: 392.1532 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 833/1000
2023-09-10 09:43:28.456 
Epoch 833/1000 
	 loss: 390.4002, MinusLogProbMetric: 390.4002, val_loss: 392.5601, val_MinusLogProbMetric: 392.5601

Epoch 833: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.4002 - MinusLogProbMetric: 390.4002 - val_loss: 392.5601 - val_MinusLogProbMetric: 392.5601 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 834/1000
2023-09-10 09:43:37.412 
Epoch 834/1000 
	 loss: 390.5376, MinusLogProbMetric: 390.5376, val_loss: 392.7437, val_MinusLogProbMetric: 392.7437

Epoch 834: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5376 - MinusLogProbMetric: 390.5376 - val_loss: 392.7437 - val_MinusLogProbMetric: 392.7437 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 835/1000
2023-09-10 09:43:44.485 
Epoch 835/1000 
	 loss: 390.2732, MinusLogProbMetric: 390.2732, val_loss: 392.6004, val_MinusLogProbMetric: 392.6004

Epoch 835: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.2732 - MinusLogProbMetric: 390.2732 - val_loss: 392.6004 - val_MinusLogProbMetric: 392.6004 - lr: 1.6667e-04 - 7s/epoch - 36ms/step
Epoch 836/1000
2023-09-10 09:43:52.722 
Epoch 836/1000 
	 loss: 390.2871, MinusLogProbMetric: 390.2871, val_loss: 392.1885, val_MinusLogProbMetric: 392.1885

Epoch 836: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.2871 - MinusLogProbMetric: 390.2871 - val_loss: 392.1885 - val_MinusLogProbMetric: 392.1885 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 837/1000
2023-09-10 09:44:01.273 
Epoch 837/1000 
	 loss: 390.5417, MinusLogProbMetric: 390.5417, val_loss: 392.8410, val_MinusLogProbMetric: 392.8410

Epoch 837: val_loss did not improve from 392.03903
196/196 - 9s - loss: 390.5417 - MinusLogProbMetric: 390.5417 - val_loss: 392.8410 - val_MinusLogProbMetric: 392.8410 - lr: 1.6667e-04 - 9s/epoch - 43ms/step
Epoch 838/1000
2023-09-10 09:44:09.755 
Epoch 838/1000 
	 loss: 390.4107, MinusLogProbMetric: 390.4107, val_loss: 393.2602, val_MinusLogProbMetric: 393.2602

Epoch 838: val_loss did not improve from 392.03903
196/196 - 8s - loss: 390.4107 - MinusLogProbMetric: 390.4107 - val_loss: 393.2602 - val_MinusLogProbMetric: 393.2602 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 839/1000
2023-09-10 09:44:16.922 
Epoch 839/1000 
	 loss: 390.4106, MinusLogProbMetric: 390.4106, val_loss: 392.6854, val_MinusLogProbMetric: 392.6854

Epoch 839: val_loss did not improve from 392.03903
196/196 - 7s - loss: 390.4106 - MinusLogProbMetric: 390.4106 - val_loss: 392.6854 - val_MinusLogProbMetric: 392.6854 - lr: 1.6667e-04 - 7s/epoch - 37ms/step
Epoch 840/1000
2023-09-10 09:44:23.738 
Epoch 840/1000 
	 loss: 389.4813, MinusLogProbMetric: 389.4813, val_loss: 391.4972, val_MinusLogProbMetric: 391.4972

Epoch 840: val_loss improved from 392.03903 to 391.49716, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 7s - loss: 389.4813 - MinusLogProbMetric: 389.4813 - val_loss: 391.4972 - val_MinusLogProbMetric: 391.4972 - lr: 8.3333e-05 - 7s/epoch - 37ms/step
Epoch 841/1000
2023-09-10 09:44:32.244 
Epoch 841/1000 
	 loss: 389.4161, MinusLogProbMetric: 389.4161, val_loss: 391.4284, val_MinusLogProbMetric: 391.4284

Epoch 841: val_loss improved from 391.49716 to 391.42841, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 389.4161 - MinusLogProbMetric: 389.4161 - val_loss: 391.4284 - val_MinusLogProbMetric: 391.4284 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 842/1000
2023-09-10 09:44:39.410 
Epoch 842/1000 
	 loss: 389.3878, MinusLogProbMetric: 389.3878, val_loss: 391.5501, val_MinusLogProbMetric: 391.5501

Epoch 842: val_loss did not improve from 391.42841
196/196 - 7s - loss: 389.3878 - MinusLogProbMetric: 389.3878 - val_loss: 391.5501 - val_MinusLogProbMetric: 391.5501 - lr: 8.3333e-05 - 7s/epoch - 35ms/step
Epoch 843/1000
2023-09-10 09:44:47.455 
Epoch 843/1000 
	 loss: 389.4402, MinusLogProbMetric: 389.4402, val_loss: 391.4824, val_MinusLogProbMetric: 391.4824

Epoch 843: val_loss did not improve from 391.42841
196/196 - 8s - loss: 389.4402 - MinusLogProbMetric: 389.4402 - val_loss: 391.4824 - val_MinusLogProbMetric: 391.4824 - lr: 8.3333e-05 - 8s/epoch - 41ms/step
Epoch 844/1000
2023-09-10 09:44:54.639 
Epoch 844/1000 
	 loss: 389.3672, MinusLogProbMetric: 389.3672, val_loss: 391.4096, val_MinusLogProbMetric: 391.4096

Epoch 844: val_loss improved from 391.42841 to 391.40958, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 8s - loss: 389.3672 - MinusLogProbMetric: 389.3672 - val_loss: 391.4096 - val_MinusLogProbMetric: 391.4096 - lr: 8.3333e-05 - 8s/epoch - 39ms/step
Epoch 845/1000
2023-09-10 09:45:03.607 
Epoch 845/1000 
	 loss: 389.3817, MinusLogProbMetric: 389.3817, val_loss: 391.4499, val_MinusLogProbMetric: 391.4499

Epoch 845: val_loss did not improve from 391.40958
196/196 - 9s - loss: 389.3817 - MinusLogProbMetric: 389.3817 - val_loss: 391.4499 - val_MinusLogProbMetric: 391.4499 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 846/1000
2023-09-10 09:45:12.435 
Epoch 846/1000 
	 loss: 389.4383, MinusLogProbMetric: 389.4383, val_loss: 391.5986, val_MinusLogProbMetric: 391.5986

Epoch 846: val_loss did not improve from 391.40958
196/196 - 9s - loss: 389.4383 - MinusLogProbMetric: 389.4383 - val_loss: 391.5986 - val_MinusLogProbMetric: 391.5986 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 847/1000
2023-09-10 09:45:20.899 
Epoch 847/1000 
	 loss: 389.3620, MinusLogProbMetric: 389.3620, val_loss: 391.3844, val_MinusLogProbMetric: 391.3844

Epoch 847: val_loss improved from 391.40958 to 391.38443, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 389.3620 - MinusLogProbMetric: 389.3620 - val_loss: 391.3844 - val_MinusLogProbMetric: 391.3844 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 848/1000
2023-09-10 09:45:27.989 
Epoch 848/1000 
	 loss: 389.3730, MinusLogProbMetric: 389.3730, val_loss: 391.4206, val_MinusLogProbMetric: 391.4206

Epoch 848: val_loss did not improve from 391.38443
196/196 - 7s - loss: 389.3730 - MinusLogProbMetric: 389.3730 - val_loss: 391.4206 - val_MinusLogProbMetric: 391.4206 - lr: 8.3333e-05 - 7s/epoch - 35ms/step
Epoch 849/1000
2023-09-10 09:45:36.500 
Epoch 849/1000 
	 loss: 389.3651, MinusLogProbMetric: 389.3651, val_loss: 391.4612, val_MinusLogProbMetric: 391.4612

Epoch 849: val_loss did not improve from 391.38443
196/196 - 8s - loss: 389.3651 - MinusLogProbMetric: 389.3651 - val_loss: 391.4612 - val_MinusLogProbMetric: 391.4612 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 850/1000
2023-09-10 09:45:44.127 
Epoch 850/1000 
	 loss: 389.4696, MinusLogProbMetric: 389.4696, val_loss: 391.5119, val_MinusLogProbMetric: 391.5119

Epoch 850: val_loss did not improve from 391.38443
196/196 - 8s - loss: 389.4696 - MinusLogProbMetric: 389.4696 - val_loss: 391.5119 - val_MinusLogProbMetric: 391.5119 - lr: 8.3333e-05 - 8s/epoch - 39ms/step
Epoch 851/1000
2023-09-10 09:45:52.897 
Epoch 851/1000 
	 loss: 389.4551, MinusLogProbMetric: 389.4551, val_loss: 391.6878, val_MinusLogProbMetric: 391.6878

Epoch 851: val_loss did not improve from 391.38443
196/196 - 9s - loss: 389.4551 - MinusLogProbMetric: 389.4551 - val_loss: 391.6878 - val_MinusLogProbMetric: 391.6878 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 852/1000
2023-09-10 09:46:01.008 
Epoch 852/1000 
	 loss: 389.4720, MinusLogProbMetric: 389.4720, val_loss: 391.4854, val_MinusLogProbMetric: 391.4854

Epoch 852: val_loss did not improve from 391.38443
196/196 - 8s - loss: 389.4720 - MinusLogProbMetric: 389.4720 - val_loss: 391.4854 - val_MinusLogProbMetric: 391.4854 - lr: 8.3333e-05 - 8s/epoch - 41ms/step
Epoch 853/1000
2023-09-10 09:46:12.379 
Epoch 853/1000 
	 loss: 389.4251, MinusLogProbMetric: 389.4251, val_loss: 391.9033, val_MinusLogProbMetric: 391.9033

Epoch 853: val_loss did not improve from 391.38443
196/196 - 11s - loss: 389.4251 - MinusLogProbMetric: 389.4251 - val_loss: 391.9033 - val_MinusLogProbMetric: 391.9033 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 854/1000
2023-09-10 09:46:19.711 
Epoch 854/1000 
	 loss: 389.3707, MinusLogProbMetric: 389.3707, val_loss: 391.4748, val_MinusLogProbMetric: 391.4748

Epoch 854: val_loss did not improve from 391.38443
196/196 - 7s - loss: 389.3707 - MinusLogProbMetric: 389.3707 - val_loss: 391.4748 - val_MinusLogProbMetric: 391.4748 - lr: 8.3333e-05 - 7s/epoch - 37ms/step
Epoch 855/1000
2023-09-10 09:46:30.146 
Epoch 855/1000 
	 loss: 389.3612, MinusLogProbMetric: 389.3612, val_loss: 391.6353, val_MinusLogProbMetric: 391.6353

Epoch 855: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.3612 - MinusLogProbMetric: 389.3612 - val_loss: 391.6353 - val_MinusLogProbMetric: 391.6353 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 856/1000
2023-09-10 09:46:37.851 
Epoch 856/1000 
	 loss: 389.3653, MinusLogProbMetric: 389.3653, val_loss: 391.4669, val_MinusLogProbMetric: 391.4669

Epoch 856: val_loss did not improve from 391.38443
196/196 - 8s - loss: 389.3653 - MinusLogProbMetric: 389.3653 - val_loss: 391.4669 - val_MinusLogProbMetric: 391.4669 - lr: 8.3333e-05 - 8s/epoch - 39ms/step
Epoch 857/1000
2023-09-10 09:46:47.486 
Epoch 857/1000 
	 loss: 389.3293, MinusLogProbMetric: 389.3293, val_loss: 391.6048, val_MinusLogProbMetric: 391.6048

Epoch 857: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.3293 - MinusLogProbMetric: 389.3293 - val_loss: 391.6048 - val_MinusLogProbMetric: 391.6048 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 858/1000
2023-09-10 09:46:57.474 
Epoch 858/1000 
	 loss: 389.3932, MinusLogProbMetric: 389.3932, val_loss: 391.7550, val_MinusLogProbMetric: 391.7550

Epoch 858: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.3932 - MinusLogProbMetric: 389.3932 - val_loss: 391.7550 - val_MinusLogProbMetric: 391.7550 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 859/1000
2023-09-10 09:47:08.290 
Epoch 859/1000 
	 loss: 389.3699, MinusLogProbMetric: 389.3699, val_loss: 391.5069, val_MinusLogProbMetric: 391.5069

Epoch 859: val_loss did not improve from 391.38443
196/196 - 11s - loss: 389.3699 - MinusLogProbMetric: 389.3699 - val_loss: 391.5069 - val_MinusLogProbMetric: 391.5069 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 860/1000
2023-09-10 09:47:16.263 
Epoch 860/1000 
	 loss: 389.3570, MinusLogProbMetric: 389.3570, val_loss: 391.7616, val_MinusLogProbMetric: 391.7616

Epoch 860: val_loss did not improve from 391.38443
196/196 - 8s - loss: 389.3570 - MinusLogProbMetric: 389.3570 - val_loss: 391.7616 - val_MinusLogProbMetric: 391.7616 - lr: 8.3333e-05 - 8s/epoch - 41ms/step
Epoch 861/1000
2023-09-10 09:47:24.625 
Epoch 861/1000 
	 loss: 389.3739, MinusLogProbMetric: 389.3739, val_loss: 391.6845, val_MinusLogProbMetric: 391.6845

Epoch 861: val_loss did not improve from 391.38443
196/196 - 8s - loss: 389.3739 - MinusLogProbMetric: 389.3739 - val_loss: 391.6845 - val_MinusLogProbMetric: 391.6845 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 862/1000
2023-09-10 09:47:34.455 
Epoch 862/1000 
	 loss: 389.3086, MinusLogProbMetric: 389.3086, val_loss: 391.5808, val_MinusLogProbMetric: 391.5808

Epoch 862: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.3086 - MinusLogProbMetric: 389.3086 - val_loss: 391.5808 - val_MinusLogProbMetric: 391.5808 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 863/1000
2023-09-10 09:47:43.384 
Epoch 863/1000 
	 loss: 389.3051, MinusLogProbMetric: 389.3051, val_loss: 391.7452, val_MinusLogProbMetric: 391.7452

Epoch 863: val_loss did not improve from 391.38443
196/196 - 9s - loss: 389.3051 - MinusLogProbMetric: 389.3051 - val_loss: 391.7452 - val_MinusLogProbMetric: 391.7452 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 864/1000
2023-09-10 09:47:54.479 
Epoch 864/1000 
	 loss: 389.4036, MinusLogProbMetric: 389.4036, val_loss: 391.6000, val_MinusLogProbMetric: 391.6000

Epoch 864: val_loss did not improve from 391.38443
196/196 - 11s - loss: 389.4036 - MinusLogProbMetric: 389.4036 - val_loss: 391.6000 - val_MinusLogProbMetric: 391.6000 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 865/1000
2023-09-10 09:48:04.234 
Epoch 865/1000 
	 loss: 389.3878, MinusLogProbMetric: 389.3878, val_loss: 391.8649, val_MinusLogProbMetric: 391.8649

Epoch 865: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.3878 - MinusLogProbMetric: 389.3878 - val_loss: 391.8649 - val_MinusLogProbMetric: 391.8649 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 866/1000
2023-09-10 09:48:15.360 
Epoch 866/1000 
	 loss: 389.4348, MinusLogProbMetric: 389.4348, val_loss: 391.6319, val_MinusLogProbMetric: 391.6319

Epoch 866: val_loss did not improve from 391.38443
196/196 - 11s - loss: 389.4348 - MinusLogProbMetric: 389.4348 - val_loss: 391.6319 - val_MinusLogProbMetric: 391.6319 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 867/1000
2023-09-10 09:48:26.244 
Epoch 867/1000 
	 loss: 389.6295, MinusLogProbMetric: 389.6295, val_loss: 391.5901, val_MinusLogProbMetric: 391.5901

Epoch 867: val_loss did not improve from 391.38443
196/196 - 11s - loss: 389.6295 - MinusLogProbMetric: 389.6295 - val_loss: 391.5901 - val_MinusLogProbMetric: 391.5901 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 868/1000
2023-09-10 09:48:36.334 
Epoch 868/1000 
	 loss: 389.6022, MinusLogProbMetric: 389.6022, val_loss: 392.0503, val_MinusLogProbMetric: 392.0503

Epoch 868: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.6022 - MinusLogProbMetric: 389.6022 - val_loss: 392.0503 - val_MinusLogProbMetric: 392.0503 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 869/1000
2023-09-10 09:48:46.529 
Epoch 869/1000 
	 loss: 389.4804, MinusLogProbMetric: 389.4804, val_loss: 391.6058, val_MinusLogProbMetric: 391.6058

Epoch 869: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.4804 - MinusLogProbMetric: 389.4804 - val_loss: 391.6058 - val_MinusLogProbMetric: 391.6058 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 870/1000
2023-09-10 09:48:58.045 
Epoch 870/1000 
	 loss: 389.3364, MinusLogProbMetric: 389.3364, val_loss: 391.6538, val_MinusLogProbMetric: 391.6538

Epoch 870: val_loss did not improve from 391.38443
196/196 - 11s - loss: 389.3364 - MinusLogProbMetric: 389.3364 - val_loss: 391.6538 - val_MinusLogProbMetric: 391.6538 - lr: 8.3333e-05 - 11s/epoch - 59ms/step
Epoch 871/1000
2023-09-10 09:49:10.072 
Epoch 871/1000 
	 loss: 389.3299, MinusLogProbMetric: 389.3299, val_loss: 391.5180, val_MinusLogProbMetric: 391.5180

Epoch 871: val_loss did not improve from 391.38443
196/196 - 12s - loss: 389.3299 - MinusLogProbMetric: 389.3299 - val_loss: 391.5180 - val_MinusLogProbMetric: 391.5180 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 872/1000
2023-09-10 09:49:20.707 
Epoch 872/1000 
	 loss: 389.3662, MinusLogProbMetric: 389.3662, val_loss: 391.6979, val_MinusLogProbMetric: 391.6979

Epoch 872: val_loss did not improve from 391.38443
196/196 - 11s - loss: 389.3662 - MinusLogProbMetric: 389.3662 - val_loss: 391.6979 - val_MinusLogProbMetric: 391.6979 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 873/1000
2023-09-10 09:49:31.041 
Epoch 873/1000 
	 loss: 389.3114, MinusLogProbMetric: 389.3114, val_loss: 391.4224, val_MinusLogProbMetric: 391.4224

Epoch 873: val_loss did not improve from 391.38443
196/196 - 10s - loss: 389.3114 - MinusLogProbMetric: 389.3114 - val_loss: 391.4224 - val_MinusLogProbMetric: 391.4224 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 874/1000
2023-09-10 09:49:38.381 
Epoch 874/1000 
	 loss: 389.3157, MinusLogProbMetric: 389.3157, val_loss: 391.6417, val_MinusLogProbMetric: 391.6417

Epoch 874: val_loss did not improve from 391.38443
196/196 - 7s - loss: 389.3157 - MinusLogProbMetric: 389.3157 - val_loss: 391.6417 - val_MinusLogProbMetric: 391.6417 - lr: 8.3333e-05 - 7s/epoch - 37ms/step
Epoch 875/1000
2023-09-10 09:49:46.925 
Epoch 875/1000 
	 loss: 389.3055, MinusLogProbMetric: 389.3055, val_loss: 391.3778, val_MinusLogProbMetric: 391.3778

Epoch 875: val_loss improved from 391.38443 to 391.37778, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 389.3055 - MinusLogProbMetric: 389.3055 - val_loss: 391.3778 - val_MinusLogProbMetric: 391.3778 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 876/1000
2023-09-10 09:49:58.165 
Epoch 876/1000 
	 loss: 389.2722, MinusLogProbMetric: 389.2722, val_loss: 391.5795, val_MinusLogProbMetric: 391.5795

Epoch 876: val_loss did not improve from 391.37778
196/196 - 11s - loss: 389.2722 - MinusLogProbMetric: 389.2722 - val_loss: 391.5795 - val_MinusLogProbMetric: 391.5795 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 877/1000
2023-09-10 09:50:05.450 
Epoch 877/1000 
	 loss: 389.3099, MinusLogProbMetric: 389.3099, val_loss: 392.1213, val_MinusLogProbMetric: 392.1213

Epoch 877: val_loss did not improve from 391.37778
196/196 - 7s - loss: 389.3099 - MinusLogProbMetric: 389.3099 - val_loss: 392.1213 - val_MinusLogProbMetric: 392.1213 - lr: 8.3333e-05 - 7s/epoch - 37ms/step
Epoch 878/1000
2023-09-10 09:50:15.362 
Epoch 878/1000 
	 loss: 389.3431, MinusLogProbMetric: 389.3431, val_loss: 391.6904, val_MinusLogProbMetric: 391.6904

Epoch 878: val_loss did not improve from 391.37778
196/196 - 10s - loss: 389.3431 - MinusLogProbMetric: 389.3431 - val_loss: 391.6904 - val_MinusLogProbMetric: 391.6904 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 879/1000
2023-09-10 09:50:26.749 
Epoch 879/1000 
	 loss: 389.2970, MinusLogProbMetric: 389.2970, val_loss: 391.3141, val_MinusLogProbMetric: 391.3141

Epoch 879: val_loss improved from 391.37778 to 391.31415, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 389.2970 - MinusLogProbMetric: 389.2970 - val_loss: 391.3141 - val_MinusLogProbMetric: 391.3141 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 880/1000
2023-09-10 09:50:37.998 
Epoch 880/1000 
	 loss: 389.2351, MinusLogProbMetric: 389.2351, val_loss: 391.4734, val_MinusLogProbMetric: 391.4734

Epoch 880: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.2351 - MinusLogProbMetric: 389.2351 - val_loss: 391.4734 - val_MinusLogProbMetric: 391.4734 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 881/1000
2023-09-10 09:50:48.168 
Epoch 881/1000 
	 loss: 389.2826, MinusLogProbMetric: 389.2826, val_loss: 391.4872, val_MinusLogProbMetric: 391.4872

Epoch 881: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.2826 - MinusLogProbMetric: 389.2826 - val_loss: 391.4872 - val_MinusLogProbMetric: 391.4872 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 882/1000
2023-09-10 09:50:57.458 
Epoch 882/1000 
	 loss: 389.3246, MinusLogProbMetric: 389.3246, val_loss: 391.5565, val_MinusLogProbMetric: 391.5565

Epoch 882: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3246 - MinusLogProbMetric: 389.3246 - val_loss: 391.5565 - val_MinusLogProbMetric: 391.5565 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 883/1000
2023-09-10 09:51:07.969 
Epoch 883/1000 
	 loss: 389.4059, MinusLogProbMetric: 389.4059, val_loss: 391.6935, val_MinusLogProbMetric: 391.6935

Epoch 883: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.4059 - MinusLogProbMetric: 389.4059 - val_loss: 391.6935 - val_MinusLogProbMetric: 391.6935 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 884/1000
2023-09-10 09:51:16.076 
Epoch 884/1000 
	 loss: 389.3586, MinusLogProbMetric: 389.3586, val_loss: 391.4471, val_MinusLogProbMetric: 391.4471

Epoch 884: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.3586 - MinusLogProbMetric: 389.3586 - val_loss: 391.4471 - val_MinusLogProbMetric: 391.4471 - lr: 8.3333e-05 - 8s/epoch - 41ms/step
Epoch 885/1000
2023-09-10 09:51:27.541 
Epoch 885/1000 
	 loss: 389.3210, MinusLogProbMetric: 389.3210, val_loss: 391.5678, val_MinusLogProbMetric: 391.5678

Epoch 885: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.3210 - MinusLogProbMetric: 389.3210 - val_loss: 391.5678 - val_MinusLogProbMetric: 391.5678 - lr: 8.3333e-05 - 11s/epoch - 59ms/step
Epoch 886/1000
2023-09-10 09:51:38.188 
Epoch 886/1000 
	 loss: 389.3083, MinusLogProbMetric: 389.3083, val_loss: 391.5282, val_MinusLogProbMetric: 391.5282

Epoch 886: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.3083 - MinusLogProbMetric: 389.3083 - val_loss: 391.5282 - val_MinusLogProbMetric: 391.5282 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 887/1000
2023-09-10 09:51:46.860 
Epoch 887/1000 
	 loss: 389.2662, MinusLogProbMetric: 389.2662, val_loss: 391.4003, val_MinusLogProbMetric: 391.4003

Epoch 887: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.2662 - MinusLogProbMetric: 389.2662 - val_loss: 391.4003 - val_MinusLogProbMetric: 391.4003 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 888/1000
2023-09-10 09:51:58.078 
Epoch 888/1000 
	 loss: 389.2421, MinusLogProbMetric: 389.2421, val_loss: 391.3436, val_MinusLogProbMetric: 391.3436

Epoch 888: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.2421 - MinusLogProbMetric: 389.2421 - val_loss: 391.3436 - val_MinusLogProbMetric: 391.3436 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 889/1000
2023-09-10 09:52:06.549 
Epoch 889/1000 
	 loss: 389.2345, MinusLogProbMetric: 389.2345, val_loss: 391.3148, val_MinusLogProbMetric: 391.3148

Epoch 889: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.2345 - MinusLogProbMetric: 389.2345 - val_loss: 391.3148 - val_MinusLogProbMetric: 391.3148 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 890/1000
2023-09-10 09:52:17.967 
Epoch 890/1000 
	 loss: 389.3181, MinusLogProbMetric: 389.3181, val_loss: 391.4857, val_MinusLogProbMetric: 391.4857

Epoch 890: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.3181 - MinusLogProbMetric: 389.3181 - val_loss: 391.4857 - val_MinusLogProbMetric: 391.4857 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 891/1000
2023-09-10 09:52:27.136 
Epoch 891/1000 
	 loss: 389.3227, MinusLogProbMetric: 389.3227, val_loss: 391.3973, val_MinusLogProbMetric: 391.3973

Epoch 891: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3227 - MinusLogProbMetric: 389.3227 - val_loss: 391.3973 - val_MinusLogProbMetric: 391.3973 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 892/1000
2023-09-10 09:52:36.283 
Epoch 892/1000 
	 loss: 389.2726, MinusLogProbMetric: 389.2726, val_loss: 391.4008, val_MinusLogProbMetric: 391.4008

Epoch 892: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.2726 - MinusLogProbMetric: 389.2726 - val_loss: 391.4008 - val_MinusLogProbMetric: 391.4008 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 893/1000
2023-09-10 09:52:46.664 
Epoch 893/1000 
	 loss: 389.4214, MinusLogProbMetric: 389.4214, val_loss: 391.9202, val_MinusLogProbMetric: 391.9202

Epoch 893: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.4214 - MinusLogProbMetric: 389.4214 - val_loss: 391.9202 - val_MinusLogProbMetric: 391.9202 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 894/1000
2023-09-10 09:52:55.711 
Epoch 894/1000 
	 loss: 389.3336, MinusLogProbMetric: 389.3336, val_loss: 391.3511, val_MinusLogProbMetric: 391.3511

Epoch 894: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3336 - MinusLogProbMetric: 389.3336 - val_loss: 391.3511 - val_MinusLogProbMetric: 391.3511 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 895/1000
2023-09-10 09:53:05.071 
Epoch 895/1000 
	 loss: 389.3987, MinusLogProbMetric: 389.3987, val_loss: 391.4394, val_MinusLogProbMetric: 391.4394

Epoch 895: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3987 - MinusLogProbMetric: 389.3987 - val_loss: 391.4394 - val_MinusLogProbMetric: 391.4394 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 896/1000
2023-09-10 09:53:14.760 
Epoch 896/1000 
	 loss: 389.3035, MinusLogProbMetric: 389.3035, val_loss: 391.4231, val_MinusLogProbMetric: 391.4231

Epoch 896: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.3035 - MinusLogProbMetric: 389.3035 - val_loss: 391.4231 - val_MinusLogProbMetric: 391.4231 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 897/1000
2023-09-10 09:53:24.102 
Epoch 897/1000 
	 loss: 389.3110, MinusLogProbMetric: 389.3110, val_loss: 391.3335, val_MinusLogProbMetric: 391.3335

Epoch 897: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3110 - MinusLogProbMetric: 389.3110 - val_loss: 391.3335 - val_MinusLogProbMetric: 391.3335 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 898/1000
2023-09-10 09:53:32.434 
Epoch 898/1000 
	 loss: 389.3553, MinusLogProbMetric: 389.3553, val_loss: 391.4651, val_MinusLogProbMetric: 391.4651

Epoch 898: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.3553 - MinusLogProbMetric: 389.3553 - val_loss: 391.4651 - val_MinusLogProbMetric: 391.4651 - lr: 8.3333e-05 - 8s/epoch - 42ms/step
Epoch 899/1000
2023-09-10 09:53:43.144 
Epoch 899/1000 
	 loss: 389.3405, MinusLogProbMetric: 389.3405, val_loss: 391.4692, val_MinusLogProbMetric: 391.4692

Epoch 899: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.3405 - MinusLogProbMetric: 389.3405 - val_loss: 391.4692 - val_MinusLogProbMetric: 391.4692 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 900/1000
2023-09-10 09:53:53.888 
Epoch 900/1000 
	 loss: 389.2237, MinusLogProbMetric: 389.2237, val_loss: 391.5339, val_MinusLogProbMetric: 391.5339

Epoch 900: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.2237 - MinusLogProbMetric: 389.2237 - val_loss: 391.5339 - val_MinusLogProbMetric: 391.5339 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 901/1000
2023-09-10 09:54:01.530 
Epoch 901/1000 
	 loss: 389.3270, MinusLogProbMetric: 389.3270, val_loss: 391.8914, val_MinusLogProbMetric: 391.8914

Epoch 901: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.3270 - MinusLogProbMetric: 389.3270 - val_loss: 391.8914 - val_MinusLogProbMetric: 391.8914 - lr: 8.3333e-05 - 8s/epoch - 39ms/step
Epoch 902/1000
2023-09-10 09:54:10.170 
Epoch 902/1000 
	 loss: 389.3478, MinusLogProbMetric: 389.3478, val_loss: 391.8833, val_MinusLogProbMetric: 391.8833

Epoch 902: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3478 - MinusLogProbMetric: 389.3478 - val_loss: 391.8833 - val_MinusLogProbMetric: 391.8833 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 903/1000
2023-09-10 09:54:19.111 
Epoch 903/1000 
	 loss: 389.3321, MinusLogProbMetric: 389.3321, val_loss: 391.6389, val_MinusLogProbMetric: 391.6389

Epoch 903: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3321 - MinusLogProbMetric: 389.3321 - val_loss: 391.6389 - val_MinusLogProbMetric: 391.6389 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 904/1000
2023-09-10 09:54:28.748 
Epoch 904/1000 
	 loss: 389.4118, MinusLogProbMetric: 389.4118, val_loss: 391.8173, val_MinusLogProbMetric: 391.8173

Epoch 904: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.4118 - MinusLogProbMetric: 389.4118 - val_loss: 391.8173 - val_MinusLogProbMetric: 391.8173 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 905/1000
2023-09-10 09:54:38.203 
Epoch 905/1000 
	 loss: 389.3600, MinusLogProbMetric: 389.3600, val_loss: 391.3675, val_MinusLogProbMetric: 391.3675

Epoch 905: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3600 - MinusLogProbMetric: 389.3600 - val_loss: 391.3675 - val_MinusLogProbMetric: 391.3675 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 906/1000
2023-09-10 09:54:48.020 
Epoch 906/1000 
	 loss: 389.2468, MinusLogProbMetric: 389.2468, val_loss: 392.1868, val_MinusLogProbMetric: 392.1868

Epoch 906: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.2468 - MinusLogProbMetric: 389.2468 - val_loss: 392.1868 - val_MinusLogProbMetric: 392.1868 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 907/1000
2023-09-10 09:54:59.286 
Epoch 907/1000 
	 loss: 389.3468, MinusLogProbMetric: 389.3468, val_loss: 391.5541, val_MinusLogProbMetric: 391.5541

Epoch 907: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.3468 - MinusLogProbMetric: 389.3468 - val_loss: 391.5541 - val_MinusLogProbMetric: 391.5541 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 908/1000
2023-09-10 09:55:10.782 
Epoch 908/1000 
	 loss: 389.2740, MinusLogProbMetric: 389.2740, val_loss: 391.3779, val_MinusLogProbMetric: 391.3779

Epoch 908: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.2740 - MinusLogProbMetric: 389.2740 - val_loss: 391.3779 - val_MinusLogProbMetric: 391.3779 - lr: 8.3333e-05 - 11s/epoch - 59ms/step
Epoch 909/1000
2023-09-10 09:55:18.598 
Epoch 909/1000 
	 loss: 389.2563, MinusLogProbMetric: 389.2563, val_loss: 391.4108, val_MinusLogProbMetric: 391.4108

Epoch 909: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.2563 - MinusLogProbMetric: 389.2563 - val_loss: 391.4108 - val_MinusLogProbMetric: 391.4108 - lr: 8.3333e-05 - 8s/epoch - 40ms/step
Epoch 910/1000
2023-09-10 09:55:29.276 
Epoch 910/1000 
	 loss: 389.3572, MinusLogProbMetric: 389.3572, val_loss: 391.4579, val_MinusLogProbMetric: 391.4579

Epoch 910: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.3572 - MinusLogProbMetric: 389.3572 - val_loss: 391.4579 - val_MinusLogProbMetric: 391.4579 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 911/1000
2023-09-10 09:55:37.192 
Epoch 911/1000 
	 loss: 389.2704, MinusLogProbMetric: 389.2704, val_loss: 391.6494, val_MinusLogProbMetric: 391.6494

Epoch 911: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.2704 - MinusLogProbMetric: 389.2704 - val_loss: 391.6494 - val_MinusLogProbMetric: 391.6494 - lr: 8.3333e-05 - 8s/epoch - 40ms/step
Epoch 912/1000
2023-09-10 09:55:46.919 
Epoch 912/1000 
	 loss: 389.3983, MinusLogProbMetric: 389.3983, val_loss: 391.4652, val_MinusLogProbMetric: 391.4652

Epoch 912: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.3983 - MinusLogProbMetric: 389.3983 - val_loss: 391.4652 - val_MinusLogProbMetric: 391.4652 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 913/1000
2023-09-10 09:55:55.555 
Epoch 913/1000 
	 loss: 389.2846, MinusLogProbMetric: 389.2846, val_loss: 391.3932, val_MinusLogProbMetric: 391.3932

Epoch 913: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.2846 - MinusLogProbMetric: 389.2846 - val_loss: 391.3932 - val_MinusLogProbMetric: 391.3932 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 914/1000
2023-09-10 09:56:05.395 
Epoch 914/1000 
	 loss: 389.6104, MinusLogProbMetric: 389.6104, val_loss: 391.8842, val_MinusLogProbMetric: 391.8842

Epoch 914: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.6104 - MinusLogProbMetric: 389.6104 - val_loss: 391.8842 - val_MinusLogProbMetric: 391.8842 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 915/1000
2023-09-10 09:56:13.492 
Epoch 915/1000 
	 loss: 389.5668, MinusLogProbMetric: 389.5668, val_loss: 391.5018, val_MinusLogProbMetric: 391.5018

Epoch 915: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.5668 - MinusLogProbMetric: 389.5668 - val_loss: 391.5018 - val_MinusLogProbMetric: 391.5018 - lr: 8.3333e-05 - 8s/epoch - 41ms/step
Epoch 916/1000
2023-09-10 09:56:24.304 
Epoch 916/1000 
	 loss: 389.3456, MinusLogProbMetric: 389.3456, val_loss: 391.4505, val_MinusLogProbMetric: 391.4505

Epoch 916: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.3456 - MinusLogProbMetric: 389.3456 - val_loss: 391.4505 - val_MinusLogProbMetric: 391.4505 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 917/1000
2023-09-10 09:56:36.078 
Epoch 917/1000 
	 loss: 389.3205, MinusLogProbMetric: 389.3205, val_loss: 391.4919, val_MinusLogProbMetric: 391.4919

Epoch 917: val_loss did not improve from 391.31415
196/196 - 12s - loss: 389.3205 - MinusLogProbMetric: 389.3205 - val_loss: 391.4919 - val_MinusLogProbMetric: 391.4919 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 918/1000
2023-09-10 09:56:44.562 
Epoch 918/1000 
	 loss: 389.4298, MinusLogProbMetric: 389.4298, val_loss: 391.7187, val_MinusLogProbMetric: 391.7187

Epoch 918: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.4298 - MinusLogProbMetric: 389.4298 - val_loss: 391.7187 - val_MinusLogProbMetric: 391.7187 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 919/1000
2023-09-10 09:56:53.539 
Epoch 919/1000 
	 loss: 389.5583, MinusLogProbMetric: 389.5583, val_loss: 391.4888, val_MinusLogProbMetric: 391.4888

Epoch 919: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.5583 - MinusLogProbMetric: 389.5583 - val_loss: 391.4888 - val_MinusLogProbMetric: 391.4888 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 920/1000
2023-09-10 09:57:01.925 
Epoch 920/1000 
	 loss: 389.3692, MinusLogProbMetric: 389.3692, val_loss: 391.6285, val_MinusLogProbMetric: 391.6285

Epoch 920: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.3692 - MinusLogProbMetric: 389.3692 - val_loss: 391.6285 - val_MinusLogProbMetric: 391.6285 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 921/1000
2023-09-10 09:57:10.126 
Epoch 921/1000 
	 loss: 389.2284, MinusLogProbMetric: 389.2284, val_loss: 391.3948, val_MinusLogProbMetric: 391.3948

Epoch 921: val_loss did not improve from 391.31415
196/196 - 8s - loss: 389.2284 - MinusLogProbMetric: 389.2284 - val_loss: 391.3948 - val_MinusLogProbMetric: 391.3948 - lr: 8.3333e-05 - 8s/epoch - 42ms/step
Epoch 922/1000
2023-09-10 09:57:17.435 
Epoch 922/1000 
	 loss: 389.1927, MinusLogProbMetric: 389.1927, val_loss: 391.6453, val_MinusLogProbMetric: 391.6453

Epoch 922: val_loss did not improve from 391.31415
196/196 - 7s - loss: 389.1927 - MinusLogProbMetric: 389.1927 - val_loss: 391.6453 - val_MinusLogProbMetric: 391.6453 - lr: 8.3333e-05 - 7s/epoch - 37ms/step
Epoch 923/1000
2023-09-10 09:57:26.392 
Epoch 923/1000 
	 loss: 389.2348, MinusLogProbMetric: 389.2348, val_loss: 391.3615, val_MinusLogProbMetric: 391.3615

Epoch 923: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.2348 - MinusLogProbMetric: 389.2348 - val_loss: 391.3615 - val_MinusLogProbMetric: 391.3615 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 924/1000
2023-09-10 09:57:35.451 
Epoch 924/1000 
	 loss: 389.1720, MinusLogProbMetric: 389.1720, val_loss: 391.6121, val_MinusLogProbMetric: 391.6121

Epoch 924: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.1720 - MinusLogProbMetric: 389.1720 - val_loss: 391.6121 - val_MinusLogProbMetric: 391.6121 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 925/1000
2023-09-10 09:57:46.279 
Epoch 925/1000 
	 loss: 389.2182, MinusLogProbMetric: 389.2182, val_loss: 391.5152, val_MinusLogProbMetric: 391.5152

Epoch 925: val_loss did not improve from 391.31415
196/196 - 11s - loss: 389.2182 - MinusLogProbMetric: 389.2182 - val_loss: 391.5152 - val_MinusLogProbMetric: 391.5152 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 926/1000
2023-09-10 09:57:55.246 
Epoch 926/1000 
	 loss: 389.1528, MinusLogProbMetric: 389.1528, val_loss: 391.3175, val_MinusLogProbMetric: 391.3175

Epoch 926: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.1528 - MinusLogProbMetric: 389.1528 - val_loss: 391.3175 - val_MinusLogProbMetric: 391.3175 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 927/1000
2023-09-10 09:58:05.393 
Epoch 927/1000 
	 loss: 389.1565, MinusLogProbMetric: 389.1565, val_loss: 391.3604, val_MinusLogProbMetric: 391.3604

Epoch 927: val_loss did not improve from 391.31415
196/196 - 10s - loss: 389.1565 - MinusLogProbMetric: 389.1565 - val_loss: 391.3604 - val_MinusLogProbMetric: 391.3604 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 928/1000
2023-09-10 09:58:14.318 
Epoch 928/1000 
	 loss: 389.3562, MinusLogProbMetric: 389.3562, val_loss: 391.4003, val_MinusLogProbMetric: 391.4003

Epoch 928: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.3562 - MinusLogProbMetric: 389.3562 - val_loss: 391.4003 - val_MinusLogProbMetric: 391.4003 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 929/1000
2023-09-10 09:58:23.538 
Epoch 929/1000 
	 loss: 389.1749, MinusLogProbMetric: 389.1749, val_loss: 391.4053, val_MinusLogProbMetric: 391.4053

Epoch 929: val_loss did not improve from 391.31415
196/196 - 9s - loss: 389.1749 - MinusLogProbMetric: 389.1749 - val_loss: 391.4053 - val_MinusLogProbMetric: 391.4053 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 930/1000
2023-09-10 09:58:33.809 
Epoch 930/1000 
	 loss: 388.8723, MinusLogProbMetric: 388.8723, val_loss: 391.0259, val_MinusLogProbMetric: 391.0259

Epoch 930: val_loss improved from 391.31415 to 391.02588, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 388.8723 - MinusLogProbMetric: 388.8723 - val_loss: 391.0259 - val_MinusLogProbMetric: 391.0259 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 931/1000
2023-09-10 09:58:42.646 
Epoch 931/1000 
	 loss: 388.8553, MinusLogProbMetric: 388.8553, val_loss: 391.0537, val_MinusLogProbMetric: 391.0537

Epoch 931: val_loss did not improve from 391.02588
196/196 - 9s - loss: 388.8553 - MinusLogProbMetric: 388.8553 - val_loss: 391.0537 - val_MinusLogProbMetric: 391.0537 - lr: 4.1667e-05 - 9s/epoch - 44ms/step
Epoch 932/1000
2023-09-10 09:58:52.465 
Epoch 932/1000 
	 loss: 388.8488, MinusLogProbMetric: 388.8488, val_loss: 391.0988, val_MinusLogProbMetric: 391.0988

Epoch 932: val_loss did not improve from 391.02588
196/196 - 10s - loss: 388.8488 - MinusLogProbMetric: 388.8488 - val_loss: 391.0988 - val_MinusLogProbMetric: 391.0988 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 933/1000
2023-09-10 09:59:00.205 
Epoch 933/1000 
	 loss: 388.8383, MinusLogProbMetric: 388.8383, val_loss: 391.1285, val_MinusLogProbMetric: 391.1285

Epoch 933: val_loss did not improve from 391.02588
196/196 - 8s - loss: 388.8383 - MinusLogProbMetric: 388.8383 - val_loss: 391.1285 - val_MinusLogProbMetric: 391.1285 - lr: 4.1667e-05 - 8s/epoch - 39ms/step
Epoch 934/1000
2023-09-10 09:59:08.742 
Epoch 934/1000 
	 loss: 388.8523, MinusLogProbMetric: 388.8523, val_loss: 391.0414, val_MinusLogProbMetric: 391.0414

Epoch 934: val_loss did not improve from 391.02588
196/196 - 9s - loss: 388.8523 - MinusLogProbMetric: 388.8523 - val_loss: 391.0414 - val_MinusLogProbMetric: 391.0414 - lr: 4.1667e-05 - 9s/epoch - 43ms/step
Epoch 935/1000
2023-09-10 09:59:16.579 
Epoch 935/1000 
	 loss: 388.8605, MinusLogProbMetric: 388.8605, val_loss: 391.1045, val_MinusLogProbMetric: 391.1045

Epoch 935: val_loss did not improve from 391.02588
196/196 - 8s - loss: 388.8605 - MinusLogProbMetric: 388.8605 - val_loss: 391.1045 - val_MinusLogProbMetric: 391.1045 - lr: 4.1667e-05 - 8s/epoch - 40ms/step
Epoch 936/1000
2023-09-10 09:59:25.709 
Epoch 936/1000 
	 loss: 388.8511, MinusLogProbMetric: 388.8511, val_loss: 391.0355, val_MinusLogProbMetric: 391.0355

Epoch 936: val_loss did not improve from 391.02588
196/196 - 9s - loss: 388.8511 - MinusLogProbMetric: 388.8511 - val_loss: 391.0355 - val_MinusLogProbMetric: 391.0355 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 937/1000
2023-09-10 09:59:33.194 
Epoch 937/1000 
	 loss: 388.8405, MinusLogProbMetric: 388.8405, val_loss: 391.0807, val_MinusLogProbMetric: 391.0807

Epoch 937: val_loss did not improve from 391.02588
196/196 - 7s - loss: 388.8405 - MinusLogProbMetric: 388.8405 - val_loss: 391.0807 - val_MinusLogProbMetric: 391.0807 - lr: 4.1667e-05 - 7s/epoch - 38ms/step
Epoch 938/1000
2023-09-10 09:59:41.708 
Epoch 938/1000 
	 loss: 388.8654, MinusLogProbMetric: 388.8654, val_loss: 391.1336, val_MinusLogProbMetric: 391.1336

Epoch 938: val_loss did not improve from 391.02588
196/196 - 9s - loss: 388.8654 - MinusLogProbMetric: 388.8654 - val_loss: 391.1336 - val_MinusLogProbMetric: 391.1336 - lr: 4.1667e-05 - 9s/epoch - 43ms/step
Epoch 939/1000
2023-09-10 09:59:50.356 
Epoch 939/1000 
	 loss: 388.8900, MinusLogProbMetric: 388.8900, val_loss: 391.1371, val_MinusLogProbMetric: 391.1371

Epoch 939: val_loss did not improve from 391.02588
196/196 - 9s - loss: 388.8900 - MinusLogProbMetric: 388.8900 - val_loss: 391.1371 - val_MinusLogProbMetric: 391.1371 - lr: 4.1667e-05 - 9s/epoch - 44ms/step
Epoch 940/1000
2023-09-10 09:59:58.586 
Epoch 940/1000 
	 loss: 388.9062, MinusLogProbMetric: 388.9062, val_loss: 391.2177, val_MinusLogProbMetric: 391.2177

Epoch 940: val_loss did not improve from 391.02588
196/196 - 8s - loss: 388.9062 - MinusLogProbMetric: 388.9062 - val_loss: 391.2177 - val_MinusLogProbMetric: 391.2177 - lr: 4.1667e-05 - 8s/epoch - 42ms/step
Epoch 941/1000
2023-09-10 10:00:06.171 
Epoch 941/1000 
	 loss: 388.9060, MinusLogProbMetric: 388.9060, val_loss: 391.0699, val_MinusLogProbMetric: 391.0699

Epoch 941: val_loss did not improve from 391.02588
196/196 - 8s - loss: 388.9060 - MinusLogProbMetric: 388.9060 - val_loss: 391.0699 - val_MinusLogProbMetric: 391.0699 - lr: 4.1667e-05 - 8s/epoch - 39ms/step
Epoch 942/1000
2023-09-10 10:00:14.599 
Epoch 942/1000 
	 loss: 388.8513, MinusLogProbMetric: 388.8513, val_loss: 391.3371, val_MinusLogProbMetric: 391.3371

Epoch 942: val_loss did not improve from 391.02588
196/196 - 8s - loss: 388.8513 - MinusLogProbMetric: 388.8513 - val_loss: 391.3371 - val_MinusLogProbMetric: 391.3371 - lr: 4.1667e-05 - 8s/epoch - 43ms/step
Epoch 943/1000
2023-09-10 10:00:22.457 
Epoch 943/1000 
	 loss: 388.8636, MinusLogProbMetric: 388.8636, val_loss: 391.1388, val_MinusLogProbMetric: 391.1388

Epoch 943: val_loss did not improve from 391.02588
196/196 - 8s - loss: 388.8636 - MinusLogProbMetric: 388.8636 - val_loss: 391.1388 - val_MinusLogProbMetric: 391.1388 - lr: 4.1667e-05 - 8s/epoch - 40ms/step
Epoch 944/1000
2023-09-10 10:00:31.406 
Epoch 944/1000 
	 loss: 388.8602, MinusLogProbMetric: 388.8602, val_loss: 391.0656, val_MinusLogProbMetric: 391.0656

Epoch 944: val_loss did not improve from 391.02588
196/196 - 9s - loss: 388.8602 - MinusLogProbMetric: 388.8602 - val_loss: 391.0656 - val_MinusLogProbMetric: 391.0656 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 945/1000
2023-09-10 10:00:41.107 
Epoch 945/1000 
	 loss: 388.8375, MinusLogProbMetric: 388.8375, val_loss: 391.1353, val_MinusLogProbMetric: 391.1353

Epoch 945: val_loss did not improve from 391.02588
196/196 - 10s - loss: 388.8375 - MinusLogProbMetric: 388.8375 - val_loss: 391.1353 - val_MinusLogProbMetric: 391.1353 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 946/1000
2023-09-10 10:00:52.779 
Epoch 946/1000 
	 loss: 388.8558, MinusLogProbMetric: 388.8558, val_loss: 391.0395, val_MinusLogProbMetric: 391.0395

Epoch 946: val_loss did not improve from 391.02588
196/196 - 12s - loss: 388.8558 - MinusLogProbMetric: 388.8558 - val_loss: 391.0395 - val_MinusLogProbMetric: 391.0395 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 947/1000
2023-09-10 10:01:01.414 
Epoch 947/1000 
	 loss: 388.8182, MinusLogProbMetric: 388.8182, val_loss: 391.0244, val_MinusLogProbMetric: 391.0244

Epoch 947: val_loss improved from 391.02588 to 391.02444, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 388.8182 - MinusLogProbMetric: 388.8182 - val_loss: 391.0244 - val_MinusLogProbMetric: 391.0244 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 948/1000
2023-09-10 10:01:12.313 
Epoch 948/1000 
	 loss: 388.8417, MinusLogProbMetric: 388.8417, val_loss: 391.0930, val_MinusLogProbMetric: 391.0930

Epoch 948: val_loss did not improve from 391.02444
196/196 - 10s - loss: 388.8417 - MinusLogProbMetric: 388.8417 - val_loss: 391.0930 - val_MinusLogProbMetric: 391.0930 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 949/1000
2023-09-10 10:01:24.058 
Epoch 949/1000 
	 loss: 388.8235, MinusLogProbMetric: 388.8235, val_loss: 391.0991, val_MinusLogProbMetric: 391.0991

Epoch 949: val_loss did not improve from 391.02444
196/196 - 12s - loss: 388.8235 - MinusLogProbMetric: 388.8235 - val_loss: 391.0991 - val_MinusLogProbMetric: 391.0991 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 950/1000
2023-09-10 10:01:32.470 
Epoch 950/1000 
	 loss: 388.8713, MinusLogProbMetric: 388.8713, val_loss: 391.0689, val_MinusLogProbMetric: 391.0689

Epoch 950: val_loss did not improve from 391.02444
196/196 - 8s - loss: 388.8713 - MinusLogProbMetric: 388.8713 - val_loss: 391.0689 - val_MinusLogProbMetric: 391.0689 - lr: 4.1667e-05 - 8s/epoch - 43ms/step
Epoch 951/1000
2023-09-10 10:01:44.411 
Epoch 951/1000 
	 loss: 388.8336, MinusLogProbMetric: 388.8336, val_loss: 391.0741, val_MinusLogProbMetric: 391.0741

Epoch 951: val_loss did not improve from 391.02444
196/196 - 12s - loss: 388.8336 - MinusLogProbMetric: 388.8336 - val_loss: 391.0741 - val_MinusLogProbMetric: 391.0741 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 952/1000
2023-09-10 10:01:55.287 
Epoch 952/1000 
	 loss: 388.8468, MinusLogProbMetric: 388.8468, val_loss: 391.0290, val_MinusLogProbMetric: 391.0290

Epoch 952: val_loss did not improve from 391.02444
196/196 - 11s - loss: 388.8468 - MinusLogProbMetric: 388.8468 - val_loss: 391.0290 - val_MinusLogProbMetric: 391.0290 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 953/1000
2023-09-10 10:02:04.817 
Epoch 953/1000 
	 loss: 388.9095, MinusLogProbMetric: 388.9095, val_loss: 391.0427, val_MinusLogProbMetric: 391.0427

Epoch 953: val_loss did not improve from 391.02444
196/196 - 10s - loss: 388.9095 - MinusLogProbMetric: 388.9095 - val_loss: 391.0427 - val_MinusLogProbMetric: 391.0427 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 954/1000
2023-09-10 10:02:15.047 
Epoch 954/1000 
	 loss: 388.8912, MinusLogProbMetric: 388.8912, val_loss: 391.1328, val_MinusLogProbMetric: 391.1328

Epoch 954: val_loss did not improve from 391.02444
196/196 - 10s - loss: 388.8912 - MinusLogProbMetric: 388.8912 - val_loss: 391.1328 - val_MinusLogProbMetric: 391.1328 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 955/1000
2023-09-10 10:02:23.131 
Epoch 955/1000 
	 loss: 388.9046, MinusLogProbMetric: 388.9046, val_loss: 391.0435, val_MinusLogProbMetric: 391.0435

Epoch 955: val_loss did not improve from 391.02444
196/196 - 8s - loss: 388.9046 - MinusLogProbMetric: 388.9046 - val_loss: 391.0435 - val_MinusLogProbMetric: 391.0435 - lr: 4.1667e-05 - 8s/epoch - 41ms/step
Epoch 956/1000
2023-09-10 10:02:31.593 
Epoch 956/1000 
	 loss: 388.8213, MinusLogProbMetric: 388.8213, val_loss: 391.0209, val_MinusLogProbMetric: 391.0209

Epoch 956: val_loss improved from 391.02444 to 391.02090, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 388.8213 - MinusLogProbMetric: 388.8213 - val_loss: 391.0209 - val_MinusLogProbMetric: 391.0209 - lr: 4.1667e-05 - 9s/epoch - 45ms/step
Epoch 957/1000
2023-09-10 10:02:39.709 
Epoch 957/1000 
	 loss: 388.8702, MinusLogProbMetric: 388.8702, val_loss: 391.0830, val_MinusLogProbMetric: 391.0830

Epoch 957: val_loss did not improve from 391.02090
196/196 - 8s - loss: 388.8702 - MinusLogProbMetric: 388.8702 - val_loss: 391.0830 - val_MinusLogProbMetric: 391.0830 - lr: 4.1667e-05 - 8s/epoch - 39ms/step
Epoch 958/1000
2023-09-10 10:02:50.079 
Epoch 958/1000 
	 loss: 388.9200, MinusLogProbMetric: 388.9200, val_loss: 391.1031, val_MinusLogProbMetric: 391.1031

Epoch 958: val_loss did not improve from 391.02090
196/196 - 10s - loss: 388.9200 - MinusLogProbMetric: 388.9200 - val_loss: 391.1031 - val_MinusLogProbMetric: 391.1031 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 959/1000
2023-09-10 10:02:58.752 
Epoch 959/1000 
	 loss: 388.9160, MinusLogProbMetric: 388.9160, val_loss: 391.0100, val_MinusLogProbMetric: 391.0100

Epoch 959: val_loss improved from 391.02090 to 391.01004, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 9s - loss: 388.9160 - MinusLogProbMetric: 388.9160 - val_loss: 391.0100 - val_MinusLogProbMetric: 391.0100 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 960/1000
2023-09-10 10:03:09.065 
Epoch 960/1000 
	 loss: 388.8956, MinusLogProbMetric: 388.8956, val_loss: 391.1176, val_MinusLogProbMetric: 391.1176

Epoch 960: val_loss did not improve from 391.01004
196/196 - 10s - loss: 388.8956 - MinusLogProbMetric: 388.8956 - val_loss: 391.1176 - val_MinusLogProbMetric: 391.1176 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 961/1000
2023-09-10 10:03:18.584 
Epoch 961/1000 
	 loss: 388.8665, MinusLogProbMetric: 388.8665, val_loss: 391.1644, val_MinusLogProbMetric: 391.1644

Epoch 961: val_loss did not improve from 391.01004
196/196 - 10s - loss: 388.8665 - MinusLogProbMetric: 388.8665 - val_loss: 391.1644 - val_MinusLogProbMetric: 391.1644 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 962/1000
2023-09-10 10:03:27.771 
Epoch 962/1000 
	 loss: 388.8596, MinusLogProbMetric: 388.8596, val_loss: 391.1604, val_MinusLogProbMetric: 391.1604

Epoch 962: val_loss did not improve from 391.01004
196/196 - 9s - loss: 388.8596 - MinusLogProbMetric: 388.8596 - val_loss: 391.1604 - val_MinusLogProbMetric: 391.1604 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 963/1000
2023-09-10 10:03:37.895 
Epoch 963/1000 
	 loss: 388.8608, MinusLogProbMetric: 388.8608, val_loss: 391.1005, val_MinusLogProbMetric: 391.1005

Epoch 963: val_loss did not improve from 391.01004
196/196 - 10s - loss: 388.8608 - MinusLogProbMetric: 388.8608 - val_loss: 391.1005 - val_MinusLogProbMetric: 391.1005 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 964/1000
2023-09-10 10:03:46.061 
Epoch 964/1000 
	 loss: 388.8448, MinusLogProbMetric: 388.8448, val_loss: 391.0321, val_MinusLogProbMetric: 391.0321

Epoch 964: val_loss did not improve from 391.01004
196/196 - 8s - loss: 388.8448 - MinusLogProbMetric: 388.8448 - val_loss: 391.0321 - val_MinusLogProbMetric: 391.0321 - lr: 4.1667e-05 - 8s/epoch - 42ms/step
Epoch 965/1000
2023-09-10 10:03:53.712 
Epoch 965/1000 
	 loss: 388.8519, MinusLogProbMetric: 388.8519, val_loss: 391.0863, val_MinusLogProbMetric: 391.0863

Epoch 965: val_loss did not improve from 391.01004
196/196 - 8s - loss: 388.8519 - MinusLogProbMetric: 388.8519 - val_loss: 391.0863 - val_MinusLogProbMetric: 391.0863 - lr: 4.1667e-05 - 8s/epoch - 39ms/step
Epoch 966/1000
2023-09-10 10:04:04.425 
Epoch 966/1000 
	 loss: 388.8454, MinusLogProbMetric: 388.8454, val_loss: 391.1745, val_MinusLogProbMetric: 391.1745

Epoch 966: val_loss did not improve from 391.01004
196/196 - 11s - loss: 388.8454 - MinusLogProbMetric: 388.8454 - val_loss: 391.1745 - val_MinusLogProbMetric: 391.1745 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 967/1000
2023-09-10 10:04:14.698 
Epoch 967/1000 
	 loss: 388.9332, MinusLogProbMetric: 388.9332, val_loss: 391.0869, val_MinusLogProbMetric: 391.0869

Epoch 967: val_loss did not improve from 391.01004
196/196 - 10s - loss: 388.9332 - MinusLogProbMetric: 388.9332 - val_loss: 391.0869 - val_MinusLogProbMetric: 391.0869 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 968/1000
2023-09-10 10:04:24.361 
Epoch 968/1000 
	 loss: 388.8641, MinusLogProbMetric: 388.8641, val_loss: 391.1298, val_MinusLogProbMetric: 391.1298

Epoch 968: val_loss did not improve from 391.01004
196/196 - 10s - loss: 388.8641 - MinusLogProbMetric: 388.8641 - val_loss: 391.1298 - val_MinusLogProbMetric: 391.1298 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 969/1000
2023-09-10 10:04:33.956 
Epoch 969/1000 
	 loss: 388.8359, MinusLogProbMetric: 388.8359, val_loss: 391.0387, val_MinusLogProbMetric: 391.0387

Epoch 969: val_loss did not improve from 391.01004
196/196 - 10s - loss: 388.8359 - MinusLogProbMetric: 388.8359 - val_loss: 391.0387 - val_MinusLogProbMetric: 391.0387 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 970/1000
2023-09-10 10:04:44.006 
Epoch 970/1000 
	 loss: 388.8441, MinusLogProbMetric: 388.8441, val_loss: 391.0644, val_MinusLogProbMetric: 391.0644

Epoch 970: val_loss did not improve from 391.01004
196/196 - 10s - loss: 388.8441 - MinusLogProbMetric: 388.8441 - val_loss: 391.0644 - val_MinusLogProbMetric: 391.0644 - lr: 4.1667e-05 - 10s/epoch - 51ms/step
Epoch 971/1000
2023-09-10 10:04:55.744 
Epoch 971/1000 
	 loss: 388.8047, MinusLogProbMetric: 388.8047, val_loss: 391.0002, val_MinusLogProbMetric: 391.0002

Epoch 971: val_loss improved from 391.01004 to 391.00015, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 388.8047 - MinusLogProbMetric: 388.8047 - val_loss: 391.0002 - val_MinusLogProbMetric: 391.0002 - lr: 4.1667e-05 - 12s/epoch - 62ms/step
Epoch 972/1000
2023-09-10 10:05:07.306 
Epoch 972/1000 
	 loss: 388.7954, MinusLogProbMetric: 388.7954, val_loss: 391.0739, val_MinusLogProbMetric: 391.0739

Epoch 972: val_loss did not improve from 391.00015
196/196 - 11s - loss: 388.7954 - MinusLogProbMetric: 388.7954 - val_loss: 391.0739 - val_MinusLogProbMetric: 391.0739 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 973/1000
2023-09-10 10:05:16.319 
Epoch 973/1000 
	 loss: 388.8085, MinusLogProbMetric: 388.8085, val_loss: 391.0673, val_MinusLogProbMetric: 391.0673

Epoch 973: val_loss did not improve from 391.00015
196/196 - 9s - loss: 388.8085 - MinusLogProbMetric: 388.8085 - val_loss: 391.0673 - val_MinusLogProbMetric: 391.0673 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 974/1000
2023-09-10 10:05:26.836 
Epoch 974/1000 
	 loss: 388.8130, MinusLogProbMetric: 388.8130, val_loss: 391.0247, val_MinusLogProbMetric: 391.0247

Epoch 974: val_loss did not improve from 391.00015
196/196 - 10s - loss: 388.8130 - MinusLogProbMetric: 388.8130 - val_loss: 391.0247 - val_MinusLogProbMetric: 391.0247 - lr: 4.1667e-05 - 10s/epoch - 54ms/step
Epoch 975/1000
2023-09-10 10:05:35.821 
Epoch 975/1000 
	 loss: 388.8156, MinusLogProbMetric: 388.8156, val_loss: 391.0227, val_MinusLogProbMetric: 391.0227

Epoch 975: val_loss did not improve from 391.00015
196/196 - 9s - loss: 388.8156 - MinusLogProbMetric: 388.8156 - val_loss: 391.0227 - val_MinusLogProbMetric: 391.0227 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 976/1000
2023-09-10 10:05:45.826 
Epoch 976/1000 
	 loss: 388.7820, MinusLogProbMetric: 388.7820, val_loss: 390.9884, val_MinusLogProbMetric: 390.9884

Epoch 976: val_loss improved from 391.00015 to 390.98837, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 10s - loss: 388.7820 - MinusLogProbMetric: 388.7820 - val_loss: 390.9884 - val_MinusLogProbMetric: 390.9884 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 977/1000
2023-09-10 10:05:55.615 
Epoch 977/1000 
	 loss: 388.8067, MinusLogProbMetric: 388.8067, val_loss: 391.1095, val_MinusLogProbMetric: 391.1095

Epoch 977: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.8067 - MinusLogProbMetric: 388.8067 - val_loss: 391.1095 - val_MinusLogProbMetric: 391.1095 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 978/1000
2023-09-10 10:06:07.112 
Epoch 978/1000 
	 loss: 388.8193, MinusLogProbMetric: 388.8193, val_loss: 391.1227, val_MinusLogProbMetric: 391.1227

Epoch 978: val_loss did not improve from 390.98837
196/196 - 12s - loss: 388.8193 - MinusLogProbMetric: 388.8193 - val_loss: 391.1227 - val_MinusLogProbMetric: 391.1227 - lr: 4.1667e-05 - 12s/epoch - 59ms/step
Epoch 979/1000
2023-09-10 10:06:18.522 
Epoch 979/1000 
	 loss: 388.8427, MinusLogProbMetric: 388.8427, val_loss: 391.0720, val_MinusLogProbMetric: 391.0720

Epoch 979: val_loss did not improve from 390.98837
196/196 - 11s - loss: 388.8427 - MinusLogProbMetric: 388.8427 - val_loss: 391.0720 - val_MinusLogProbMetric: 391.0720 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 980/1000
2023-09-10 10:06:28.212 
Epoch 980/1000 
	 loss: 388.8488, MinusLogProbMetric: 388.8488, val_loss: 391.0757, val_MinusLogProbMetric: 391.0757

Epoch 980: val_loss did not improve from 390.98837
196/196 - 10s - loss: 388.8488 - MinusLogProbMetric: 388.8488 - val_loss: 391.0757 - val_MinusLogProbMetric: 391.0757 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 981/1000
2023-09-10 10:06:37.438 
Epoch 981/1000 
	 loss: 388.8919, MinusLogProbMetric: 388.8919, val_loss: 391.2258, val_MinusLogProbMetric: 391.2258

Epoch 981: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.8919 - MinusLogProbMetric: 388.8919 - val_loss: 391.2258 - val_MinusLogProbMetric: 391.2258 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 982/1000
2023-09-10 10:06:49.387 
Epoch 982/1000 
	 loss: 388.8506, MinusLogProbMetric: 388.8506, val_loss: 391.0856, val_MinusLogProbMetric: 391.0856

Epoch 982: val_loss did not improve from 390.98837
196/196 - 12s - loss: 388.8506 - MinusLogProbMetric: 388.8506 - val_loss: 391.0856 - val_MinusLogProbMetric: 391.0856 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 983/1000
2023-09-10 10:06:58.282 
Epoch 983/1000 
	 loss: 388.8021, MinusLogProbMetric: 388.8021, val_loss: 390.9916, val_MinusLogProbMetric: 390.9916

Epoch 983: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.8021 - MinusLogProbMetric: 388.8021 - val_loss: 390.9916 - val_MinusLogProbMetric: 390.9916 - lr: 4.1667e-05 - 9s/epoch - 45ms/step
Epoch 984/1000
2023-09-10 10:07:08.022 
Epoch 984/1000 
	 loss: 388.8321, MinusLogProbMetric: 388.8321, val_loss: 391.0528, val_MinusLogProbMetric: 391.0528

Epoch 984: val_loss did not improve from 390.98837
196/196 - 10s - loss: 388.8321 - MinusLogProbMetric: 388.8321 - val_loss: 391.0528 - val_MinusLogProbMetric: 391.0528 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 985/1000
2023-09-10 10:07:19.547 
Epoch 985/1000 
	 loss: 388.8353, MinusLogProbMetric: 388.8353, val_loss: 391.0133, val_MinusLogProbMetric: 391.0133

Epoch 985: val_loss did not improve from 390.98837
196/196 - 12s - loss: 388.8353 - MinusLogProbMetric: 388.8353 - val_loss: 391.0133 - val_MinusLogProbMetric: 391.0133 - lr: 4.1667e-05 - 12s/epoch - 59ms/step
Epoch 986/1000
2023-09-10 10:07:31.911 
Epoch 986/1000 
	 loss: 388.8000, MinusLogProbMetric: 388.8000, val_loss: 391.1164, val_MinusLogProbMetric: 391.1164

Epoch 986: val_loss did not improve from 390.98837
196/196 - 12s - loss: 388.8000 - MinusLogProbMetric: 388.8000 - val_loss: 391.1164 - val_MinusLogProbMetric: 391.1164 - lr: 4.1667e-05 - 12s/epoch - 63ms/step
Epoch 987/1000
2023-09-10 10:07:40.928 
Epoch 987/1000 
	 loss: 388.7783, MinusLogProbMetric: 388.7783, val_loss: 391.0345, val_MinusLogProbMetric: 391.0345

Epoch 987: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.7783 - MinusLogProbMetric: 388.7783 - val_loss: 391.0345 - val_MinusLogProbMetric: 391.0345 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 988/1000
2023-09-10 10:07:50.312 
Epoch 988/1000 
	 loss: 388.7840, MinusLogProbMetric: 388.7840, val_loss: 391.0313, val_MinusLogProbMetric: 391.0313

Epoch 988: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.7840 - MinusLogProbMetric: 388.7840 - val_loss: 391.0313 - val_MinusLogProbMetric: 391.0313 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 989/1000
2023-09-10 10:07:59.125 
Epoch 989/1000 
	 loss: 388.7801, MinusLogProbMetric: 388.7801, val_loss: 391.0577, val_MinusLogProbMetric: 391.0577

Epoch 989: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.7801 - MinusLogProbMetric: 388.7801 - val_loss: 391.0577 - val_MinusLogProbMetric: 391.0577 - lr: 4.1667e-05 - 9s/epoch - 45ms/step
Epoch 990/1000
2023-09-10 10:08:08.629 
Epoch 990/1000 
	 loss: 388.7817, MinusLogProbMetric: 388.7817, val_loss: 391.0874, val_MinusLogProbMetric: 391.0874

Epoch 990: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.7817 - MinusLogProbMetric: 388.7817 - val_loss: 391.0874 - val_MinusLogProbMetric: 391.0874 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 991/1000
2023-09-10 10:08:18.103 
Epoch 991/1000 
	 loss: 388.8488, MinusLogProbMetric: 388.8488, val_loss: 391.1660, val_MinusLogProbMetric: 391.1660

Epoch 991: val_loss did not improve from 390.98837
196/196 - 9s - loss: 388.8488 - MinusLogProbMetric: 388.8488 - val_loss: 391.1660 - val_MinusLogProbMetric: 391.1660 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 992/1000
2023-09-10 10:08:29.073 
Epoch 992/1000 
	 loss: 388.9001, MinusLogProbMetric: 388.9001, val_loss: 390.9697, val_MinusLogProbMetric: 390.9697

Epoch 992: val_loss improved from 390.98837 to 390.96967, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 11s - loss: 388.9001 - MinusLogProbMetric: 388.9001 - val_loss: 390.9697 - val_MinusLogProbMetric: 390.9697 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 993/1000
2023-09-10 10:08:39.971 
Epoch 993/1000 
	 loss: 388.8034, MinusLogProbMetric: 388.8034, val_loss: 391.1386, val_MinusLogProbMetric: 391.1386

Epoch 993: val_loss did not improve from 390.96967
196/196 - 11s - loss: 388.8034 - MinusLogProbMetric: 388.8034 - val_loss: 391.1386 - val_MinusLogProbMetric: 391.1386 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 994/1000
2023-09-10 10:08:49.404 
Epoch 994/1000 
	 loss: 388.8081, MinusLogProbMetric: 388.8081, val_loss: 390.9863, val_MinusLogProbMetric: 390.9863

Epoch 994: val_loss did not improve from 390.96967
196/196 - 9s - loss: 388.8081 - MinusLogProbMetric: 388.8081 - val_loss: 390.9863 - val_MinusLogProbMetric: 390.9863 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 995/1000
2023-09-10 10:09:00.463 
Epoch 995/1000 
	 loss: 388.8366, MinusLogProbMetric: 388.8366, val_loss: 390.9569, val_MinusLogProbMetric: 390.9569

Epoch 995: val_loss improved from 390.96967 to 390.95688, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_334/weights/best_weights.h5
196/196 - 12s - loss: 388.8366 - MinusLogProbMetric: 388.8366 - val_loss: 390.9569 - val_MinusLogProbMetric: 390.9569 - lr: 4.1667e-05 - 12s/epoch - 59ms/step
Epoch 996/1000
2023-09-10 10:09:12.276 
Epoch 996/1000 
	 loss: 388.7953, MinusLogProbMetric: 388.7953, val_loss: 391.0196, val_MinusLogProbMetric: 391.0196

Epoch 996: val_loss did not improve from 390.95688
196/196 - 11s - loss: 388.7953 - MinusLogProbMetric: 388.7953 - val_loss: 391.0196 - val_MinusLogProbMetric: 391.0196 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 997/1000
2023-09-10 10:09:22.007 
Epoch 997/1000 
	 loss: 388.8040, MinusLogProbMetric: 388.8040, val_loss: 391.0414, val_MinusLogProbMetric: 391.0414

Epoch 997: val_loss did not improve from 390.95688
196/196 - 10s - loss: 388.8040 - MinusLogProbMetric: 388.8040 - val_loss: 391.0414 - val_MinusLogProbMetric: 391.0414 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 998/1000
2023-09-10 10:09:32.131 
Epoch 998/1000 
	 loss: 388.8121, MinusLogProbMetric: 388.8121, val_loss: 390.9984, val_MinusLogProbMetric: 390.9984

Epoch 998: val_loss did not improve from 390.95688
196/196 - 10s - loss: 388.8121 - MinusLogProbMetric: 388.8121 - val_loss: 390.9984 - val_MinusLogProbMetric: 390.9984 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 999/1000
2023-09-10 10:09:40.370 
Epoch 999/1000 
	 loss: 388.8110, MinusLogProbMetric: 388.8110, val_loss: 391.2139, val_MinusLogProbMetric: 391.2139

Epoch 999: val_loss did not improve from 390.95688
196/196 - 8s - loss: 388.8110 - MinusLogProbMetric: 388.8110 - val_loss: 391.2139 - val_MinusLogProbMetric: 391.2139 - lr: 4.1667e-05 - 8s/epoch - 42ms/step
Epoch 1000/1000
2023-09-10 10:09:51.187 
Epoch 1000/1000 
	 loss: 388.7795, MinusLogProbMetric: 388.7795, val_loss: 391.0062, val_MinusLogProbMetric: 391.0062

Epoch 1000: val_loss did not improve from 390.95688
196/196 - 11s - loss: 388.7795 - MinusLogProbMetric: 388.7795 - val_loss: 391.0062 - val_MinusLogProbMetric: 391.0062 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 2881.6834402659442 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 3359.179620729992 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2895.7664129399927 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3149.1147803450003 seconds.
Training succeeded with seed 440.
Model trained in 9210.91 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 12387.25 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 12388.01 s.
===========
Run 334/360 done in 21833.75 s.
===========

Directory ../../results/MAFN_new/run_335/ already exists.
Skipping it.
===========
Run 335/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_336/ already exists.
Skipping it.
===========
Run 336/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_337/ already exists.
Skipping it.
===========
Run 337/360 already exists. Skipping it.
===========

===========
Generating train data for run 338.
===========
Train data generated in 3.50 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_338/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_338/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_338/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_338
self.data_kwargs: {'seed': 520}
self.x_data: [[6.0386963  0.30078053 4.582872   ... 4.9010735  5.585139   5.0534396 ]
 [7.9469204  4.5061865  5.2455854  ... 2.9358454  8.744124   6.9367347 ]
 [8.143589   4.4823375  5.2392807  ... 3.0099165  8.623259   7.0103106 ]
 ...
 [8.140467   4.6205688  5.2538304  ... 5.1522036  8.523501   6.461891  ]
 [5.550299   8.4923     5.931979   ... 9.995682   1.7941611  6.8577833 ]
 [7.7436986  5.02466    5.1777496  ... 2.148604   8.593714   7.418009  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_46 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_5 (LogProbLa  (None,)                  4509200   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,509,200
Trainable params: 4,509,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_5/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_5'")
self.model: <keras.engine.functional.Functional object at 0x7f193c351bd0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f1db897f3a0>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f1db897f3a0>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f1db8a0f220>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f1db8a0c880>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f193c39b610>, <keras.callbacks.ModelCheckpoint object at 0x7f193c399630>, <keras.callbacks.EarlyStopping object at 0x7f193c39b970>, <keras.callbacks.ReduceLROnPlateau object at 0x7f1db8a0c280>, <keras.callbacks.TerminateOnNaN object at 0x7f1db8a0f190>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
No weights found in ../../results/MAFN_new/run_338/weights/best_weights.h5. Training from scratch.
No history found. Generating new history.
===============
Running 338/360 with hyperparameters:
timestamp = 2023-09-10 13:36:27.654541
ndims = 1000
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 4509200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.001...
Train first sample: [ 6.0386963   0.30078053  4.582872    7.656263    0.50402063  8.927606
  5.0806236   0.7069437   3.2612228   9.222077    5.8550296   0.7950525
  3.7572262   5.421181   -0.42896372  5.3715286   5.0170646   4.5275445
  6.268279    8.342493    2.4881694   7.7397876   7.198324   10.337882
  7.1367445   7.992043    3.640705    1.6190335   9.687809   -0.10210621
  4.3673606   0.5702325   9.0355015   9.576009    7.180074    2.9750605
  2.7969558   2.6438603   1.315014    5.2577987   1.5748067   3.07832
  6.905322    7.2643003   0.31143492  3.629692    6.198628    9.935606
  4.738879    9.644313    2.6127305  -0.2701767   4.573748    2.6033232
  8.31127     2.847469    3.1219404   8.036686    8.350981    5.1923842
  7.0816703   3.7841296   0.439943    0.31411228  5.105436    0.16452146
  0.37245148  8.840347    7.522216    2.485342   -0.04555227  9.480491
  3.3716009   2.2168918   5.8693147   1.2792552   2.5388308   9.7780695
  6.3509502   5.2145343   4.668051    7.835037    0.81844634  9.829676
  8.602084    6.4478574   1.8822466   8.708197    9.9343      5.2983065
  4.648863    1.7545191   7.5778584   7.992651    1.2489895   7.932429
  0.19842413 10.670638    6.7138567   5.5415473   2.8593335   8.939356
  1.8772883   8.274395    9.729145    7.7069526   4.83206     0.20179847
  4.5409455   4.72331     2.8598065   4.388705    3.542864    1.3279399
  4.2783537   2.6017168   5.7597165   0.7641455   9.5386305   9.114207
  5.246056    8.810347    9.548426    1.1960151   4.535228    9.936641
 10.11391     6.0469294   1.2320046   5.771403    0.03692677  1.7631103
  9.768336    4.6296864   6.3364687   2.3349156   9.236544    8.197755
  3.2024207   7.716959    2.077003    4.211735    2.1907134   7.0612254
  1.2628212   4.2821627   1.9289484   4.29324     4.816094    7.6030316
  0.34979546  7.054235    2.5239222   2.5584276   7.064572    9.337272
  4.1277614   8.632163    1.1907344   7.2465253   7.3629594   1.4210125
  3.8094866   8.687733    1.3656402   0.28611335  5.895154    4.691248
  7.848699    8.486627    2.7608519   4.164383    5.0772963   6.1176133
 10.264451    6.3248825   3.0036852   2.4301364   9.323013    1.1239512
  6.9529996   8.971375    6.7585683   4.1878514   2.5465474   3.7158139
  7.954454    6.121273    8.889866    8.739019   10.887082    9.803803
  2.4961972   3.7658646   4.353828    5.831876    6.706101    2.2424636
  0.4813192   4.0677247   2.7481353   8.85868     8.81974     8.779158
  6.5635395   3.1331716   5.4378457   8.115037    0.15877736  7.7527685
 -0.23714772  9.2626095   7.987624    0.7620828   6.501852    3.2839687
  1.7200415   1.1543069   7.17581     5.3241725   9.85193    10.548408
 10.603701    2.2370188   9.374007    3.4676795   4.4167695   7.9351892
  2.2672663   5.607824    2.2299185   0.88661635  1.2501802   4.0727944
 -0.12534815  4.24075     6.864432    4.1316953   0.98898524  1.0468978
  2.6923618   1.5284702   9.68549     2.6858997   8.196742    5.9775615
  6.107674    3.8373623   9.739576    3.8176546   7.881323    5.9619036
  4.809063    9.994005    6.06644     0.60921174  5.0061116   8.33161
  7.0547867   8.514869    2.0673354   7.7308583   4.0995107   5.0039496
 10.610853    9.848376    8.120186    4.446167    8.818996    6.304151
  3.6133528   0.34783545  8.203926    4.955636    8.081435    7.584287
  7.8737516   3.389564    7.996908    6.0786796   4.5982037   7.0935416
  0.92889404  1.281023    2.9661057   9.792753    1.4344769   3.2898872
  1.1154623   3.3197548   4.133613    9.714192    7.8477564   3.915498
 -0.54802597  8.3167515   6.381558    1.8454669  11.718771    1.0781447
  8.230542    2.993074    4.4022226   7.81114     6.1109514   8.33177
  6.2205343   0.9577046   9.167438    7.7908244   7.120584    1.3328398
  3.1939583   1.6910427   8.12919     6.4541216   7.9364567  10.26773
  7.809719   10.104616    6.0293574   0.40289783 -0.560338    3.7847402
  7.9600444   9.035484   10.840271    1.0387208  -0.19058862  8.854946
  3.0963922   5.0594854  10.279567    5.074058    6.6726894   3.9883325
  7.652588    4.496253    3.0499647   2.3702488   2.5340867   3.782253
  6.6244855   9.641262    7.137413    6.8682413   1.8626316   4.317209
  4.4707828   6.841525    2.992224    2.4876325   3.3212593   7.333737
  5.75945     0.32461804  0.8335988   3.4026284   8.618828    6.705712
  6.8725452   7.33386     2.8872874   5.3803415   5.1434884   6.246975
  9.339241    0.6288371   8.414895    6.5827723   5.714417    7.4871626
  9.453507    0.7600125   1.494343    7.271453   -0.10680145  4.284081
  3.0645723   2.7818801   6.7562222   0.9355258   8.759254    4.4485765
  4.9456024   5.2843823   6.5932875   3.4578905   0.32452983  3.0972865
  0.45848465  5.198651    2.197647    9.560289    9.731855    6.5005336
  6.619211   10.057005    8.876658    8.295638    3.1194568   3.6742027
  2.26406     5.3983374   9.887169    9.133878    1.5052447   1.7451565
  8.9965925   5.319445    2.527405    6.8142905   6.4233      1.2479438
  4.035429    0.24714679  2.1173966   1.830858    1.9078584   7.0054536
  0.5009528   0.8397763   2.0496254   2.9811964   2.9665575   3.3201675
  7.2900653   9.622518    4.901422    7.8189707   3.9295015   0.91512156
  4.572243    3.2736297   4.8408017   7.065958    4.651118    9.0410385
  8.961053    5.5870433   5.2621417   1.1291223   3.93055     6.9391193
  3.508282    0.4460107   9.179407    7.387717    4.650465    8.17948
  7.53271     5.0031796   8.804058    9.204221    3.6460009   7.006398
  5.8495746   5.197357    9.277365    2.9547234  10.355085    8.981658
  5.367272    8.041138    7.377086    7.5142937   4.0544214   2.2740157
  6.749342    8.733181   -1.1557603   6.3426285   4.84659     8.766928
  2.8006268   4.1529183   4.987336    0.13959682  6.5040164   8.188027
  1.676772    2.4030275   0.5443996   9.24266     5.4919004   9.14114
  5.4362607   7.7436833   3.4114141   2.927477    3.843325    6.4828835
  2.9296427   9.1742115   8.056144   -0.09604371  2.0134284   1.6318083
  0.04543668  2.690591    4.990765    8.81346     2.1004107   4.4873705
 10.513251    7.137761    7.6034775   5.209668    9.811113    5.6359825
  0.19526497  2.564422    4.0089235   6.4994254   7.695936    4.1304693
  7.2958503   8.454953    2.967984    9.869264    7.2374787   8.593143
  5.7742076   7.5300508   7.2095394   7.823381    2.118999    5.039945
  4.053479    9.185997    0.9152442  10.862353    8.841984    0.75618994
  4.901044    7.2554336   7.1853967   9.084257    8.29529     4.220908
  5.8150444   7.7635503   1.2401824   1.3507668   4.54757     3.457343
  7.9834795   5.028612    3.85299     8.574433    8.163936   10.616821
  8.4081      4.1708117   1.2379287   8.800616    1.4772482   4.080577
  8.428701   10.380288    6.389518    6.8510385   0.61914694  4.0696154
  6.8948746   3.383478    0.4705223   3.009568    2.6594605   3.048335
  5.988357    7.1357174   3.261515    4.0008183   0.27625528 -0.3875654
  2.6110508   6.7222776   4.8376966   7.503794    6.6424117   8.686342
  7.1706657   9.419308    7.926278    6.2358265   6.0555067  -0.70361733
 10.064413    1.4912657   8.07811     7.900392    4.8439436   2.0139859
  1.0714337   7.2137423   4.526915    6.6356516   9.933811    1.5130765
  9.312532    3.7438834   3.550579    9.596389    9.815127    1.7642053
  7.4918814  -0.49520278  6.4749107   9.756271    7.145049    4.039104
  3.7851322   4.082335    6.1268287   8.183756    9.32123     0.28198594
  2.5236871  -0.31258178  2.2504802   3.5232162   4.9025984   6.3538814
  7.8291597   9.178961   10.243786    7.067563    8.285971    9.500681
  3.5682902   8.450219    0.17376387  0.216589    2.7681222   4.1601896
  6.1601834   1.706507    6.643297    7.9561872   1.7723906   4.5958123
  5.858561    4.6678243   8.187405    9.715012    8.1015      0.45350024
  7.7912116   0.77989995  2.3104167   1.3162912   1.205177    5.248102
  6.7170506   5.558635    9.548942    2.291232    7.7552695   8.649344
  5.677332    4.394188    6.64837     4.7241607   5.719767    3.967581
  4.259147    7.17209     1.0130833   1.7905484   8.393191    7.4030704
  2.735002    2.5851526   9.099808    7.8557224   6.1393533   2.1640992
  0.7774042   4.113809    6.8772874   9.341514    7.624882   -0.15643695
  2.3431437   3.3053102   1.6893227   7.5518737   7.47631     5.387754
  9.710713    1.6661869   8.289583    1.1974262   3.0808344   7.3471923
  0.8228001   5.6459312   3.6627483   7.2736874   8.484636    7.5182805
  6.5065517   0.4700985   2.234543    5.2005877   3.5432315   2.8302953
  2.0971265   9.56212     3.0628858   4.7415     -0.44130558  9.013574
  1.085037    3.311532    2.5385356   8.806095    2.0905962   7.8503737
  8.578108    9.528165    0.590898    1.9645467   7.9985986   1.753687
  3.172571    1.6611466   1.8709267   4.7864184   1.3145969   3.1479964
  4.083562    0.2390917   3.327033    0.9105044   6.7123947   7.861191
  7.02552     0.75634694  5.9596577   8.067755    2.4828937   7.6143017
  8.580062    7.3855762  -0.04546678  0.0738206   1.8115419   2.7274795
  6.6129613   3.8759396   6.692868    3.7261245   1.3076189   3.1666129
  9.223293    9.462051    2.376804    7.5547466   2.749257    8.444417
  1.3476957   6.958887    0.12667698  9.694718    6.407499    8.479325
  5.627874    4.950144    6.2193155   5.3255057   4.9456944   8.290707
  0.8348843   2.2261314   4.1954646   3.6872017   0.73160475  8.504263
  7.791428    5.3747725   9.8119135   0.7039877   7.6769605   2.5379546
  3.694837    2.045665    7.2654924   0.12175488  7.247275    7.029465
  0.6658832   8.352133    5.5662146   9.030525    7.8712974   5.6255913
  8.1955      3.5710793   4.832326    5.828453   10.745017    1.85231
 -0.526502    3.3114655   4.8024893   0.62556016  4.9190855   9.197764
  6.527681    8.61912     9.540909    9.433219    7.9817605   5.9839487
  4.9048758   0.6134869   5.948723   10.432518    8.046861    3.3048022
  1.5137587   7.991438    7.427192    9.765905    8.476495    5.9867887
  1.0616344   5.6400924   2.9184952   5.1216874   2.580817    8.646928
  7.5732      4.096987    6.089647    4.3319507   8.435398    2.1281555
  7.02788     9.129615    1.7530978   1.3687971   7.042738    7.6120076
  4.263667    6.845998    3.1399002   4.1320887   1.0887251   3.7039056
  2.7662733   3.7930636   9.0424595   1.3231362   3.5029469   6.702694
  9.477917    0.9764585   9.146437    0.77568066  5.0711017   4.2204366
  1.9013925   3.6039436   4.875466    8.647586    9.651502    6.2052207
  8.608539    6.7567143   3.158669    1.8811914   4.3497324   5.161394
  0.6098187   1.152159    6.051886    1.3697395   8.290108    2.6722713
  2.2818537   0.9584924   9.105338    1.0756454   1.5344902   8.241914
  2.561514    6.2516336   7.197662    6.6100316   8.612244    7.1160245
  1.4579626   5.4742584   6.604126    8.5800705   0.06284574  7.271172
  9.004775    7.700049    5.588264    4.5855756   4.7795944   7.2477436
  8.905804    6.081058    9.249524    7.4357276   0.8587049   4.7164693
  2.8504999   3.989924    3.8770769   2.9917765   5.714236    6.905015
  2.6859546   1.846874    0.41534102  4.812243    1.8113589  -0.9216505
  9.0558815   4.663535    1.0859932   8.355898    7.844323    4.0918174
  0.6433816   1.5224574   4.468763    8.928121    1.204919    8.635436
 -0.03399917  4.6824536   6.482672    0.5008905   5.682656    8.837162
  2.072514    7.1392884   6.1446853   2.1056101   0.07073235  0.26507834
  5.238253    9.371503    6.251286    7.188611    5.0308127   6.007279
  1.024926    8.809044    7.712478   10.019146    2.5657964   3.195103
  0.9103755   9.777725    7.5711966   3.4351816   5.4496226   4.112291
  1.660826    1.7369623   9.639072    2.935317    9.930944    0.73487484
  5.733989    1.3034487   0.502199    5.5747876   1.0674012   8.124411
  7.0287094   2.9280264   9.545342    7.30834     2.6214435   7.561452
  7.846946    1.3374016   3.65282     3.05842     6.171471    8.9460125
  1.6092017   8.305956   -0.07000089  6.6192155   4.523222    7.941383
  7.4171886   4.9010735   5.585139    5.0534396 ]
Epoch 1/1000
2023-09-10 13:37:19.624 
Epoch 1/1000 
	 loss: 1887.1626, MinusLogProbMetric: 1887.1626, val_loss: 664.5519, val_MinusLogProbMetric: 664.5519

Epoch 1: val_loss improved from inf to 664.55188, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 52s - loss: 1887.1626 - MinusLogProbMetric: 1887.1626 - val_loss: 664.5519 - val_MinusLogProbMetric: 664.5519 - lr: 0.0010 - 52s/epoch - 265ms/step
Epoch 2/1000
2023-09-10 13:37:29.994 
Epoch 2/1000 
	 loss: 584.0355, MinusLogProbMetric: 584.0355, val_loss: 531.2743, val_MinusLogProbMetric: 531.2743

Epoch 2: val_loss improved from 664.55188 to 531.27429, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 584.0355 - MinusLogProbMetric: 584.0355 - val_loss: 531.2743 - val_MinusLogProbMetric: 531.2743 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 3/1000
2023-09-10 13:37:42.807 
Epoch 3/1000 
	 loss: 523.9564, MinusLogProbMetric: 523.9564, val_loss: 597.8170, val_MinusLogProbMetric: 597.8170

Epoch 3: val_loss did not improve from 531.27429
196/196 - 13s - loss: 523.9564 - MinusLogProbMetric: 523.9564 - val_loss: 597.8170 - val_MinusLogProbMetric: 597.8170 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 4/1000
2023-09-10 13:37:52.711 
Epoch 4/1000 
	 loss: 502.2465, MinusLogProbMetric: 502.2465, val_loss: 482.0569, val_MinusLogProbMetric: 482.0569

Epoch 4: val_loss improved from 531.27429 to 482.05688, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 502.2465 - MinusLogProbMetric: 502.2465 - val_loss: 482.0569 - val_MinusLogProbMetric: 482.0569 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 5/1000
2023-09-10 13:38:04.143 
Epoch 5/1000 
	 loss: 490.3664, MinusLogProbMetric: 490.3664, val_loss: 481.5989, val_MinusLogProbMetric: 481.5989

Epoch 5: val_loss improved from 482.05688 to 481.59894, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 490.3664 - MinusLogProbMetric: 490.3664 - val_loss: 481.5989 - val_MinusLogProbMetric: 481.5989 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 6/1000
2023-09-10 13:38:13.724 
Epoch 6/1000 
	 loss: 606.1262, MinusLogProbMetric: 606.1262, val_loss: 532.4869, val_MinusLogProbMetric: 532.4869

Epoch 6: val_loss did not improve from 481.59894
196/196 - 9s - loss: 606.1262 - MinusLogProbMetric: 606.1262 - val_loss: 532.4869 - val_MinusLogProbMetric: 532.4869 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 7/1000
2023-09-10 13:38:24.182 
Epoch 7/1000 
	 loss: 486.0067, MinusLogProbMetric: 486.0067, val_loss: 473.9755, val_MinusLogProbMetric: 473.9755

Epoch 7: val_loss improved from 481.59894 to 473.97546, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 486.0067 - MinusLogProbMetric: 486.0067 - val_loss: 473.9755 - val_MinusLogProbMetric: 473.9755 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 8/1000
2023-09-10 13:38:33.622 
Epoch 8/1000 
	 loss: 468.4606, MinusLogProbMetric: 468.4606, val_loss: 474.9249, val_MinusLogProbMetric: 474.9249

Epoch 8: val_loss did not improve from 473.97546
196/196 - 9s - loss: 468.4606 - MinusLogProbMetric: 468.4606 - val_loss: 474.9249 - val_MinusLogProbMetric: 474.9249 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 9/1000
2023-09-10 13:38:44.844 
Epoch 9/1000 
	 loss: 457.1823, MinusLogProbMetric: 457.1823, val_loss: 468.3533, val_MinusLogProbMetric: 468.3533

Epoch 9: val_loss improved from 473.97546 to 468.35327, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 457.1823 - MinusLogProbMetric: 457.1823 - val_loss: 468.3533 - val_MinusLogProbMetric: 468.3533 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 10/1000
2023-09-10 13:38:55.436 
Epoch 10/1000 
	 loss: 457.1643, MinusLogProbMetric: 457.1643, val_loss: 454.8018, val_MinusLogProbMetric: 454.8018

Epoch 10: val_loss improved from 468.35327 to 454.80176, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 457.1643 - MinusLogProbMetric: 457.1643 - val_loss: 454.8018 - val_MinusLogProbMetric: 454.8018 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 11/1000
2023-09-10 13:39:05.310 
Epoch 11/1000 
	 loss: 459.9820, MinusLogProbMetric: 459.9820, val_loss: 443.4830, val_MinusLogProbMetric: 443.4830

Epoch 11: val_loss improved from 454.80176 to 443.48300, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 459.9820 - MinusLogProbMetric: 459.9820 - val_loss: 443.4830 - val_MinusLogProbMetric: 443.4830 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 12/1000
2023-09-10 13:39:16.031 
Epoch 12/1000 
	 loss: 453.5341, MinusLogProbMetric: 453.5341, val_loss: 443.9976, val_MinusLogProbMetric: 443.9976

Epoch 12: val_loss did not improve from 443.48300
196/196 - 10s - loss: 453.5341 - MinusLogProbMetric: 453.5341 - val_loss: 443.9976 - val_MinusLogProbMetric: 443.9976 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 13/1000
2023-09-10 13:39:25.660 
Epoch 13/1000 
	 loss: 450.8212, MinusLogProbMetric: 450.8212, val_loss: 435.3937, val_MinusLogProbMetric: 435.3937

Epoch 13: val_loss improved from 443.48300 to 435.39368, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 450.8212 - MinusLogProbMetric: 450.8212 - val_loss: 435.3937 - val_MinusLogProbMetric: 435.3937 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 14/1000
2023-09-10 13:39:37.488 
Epoch 14/1000 
	 loss: 448.7606, MinusLogProbMetric: 448.7606, val_loss: 447.7732, val_MinusLogProbMetric: 447.7732

Epoch 14: val_loss did not improve from 435.39368
196/196 - 12s - loss: 448.7606 - MinusLogProbMetric: 448.7606 - val_loss: 447.7732 - val_MinusLogProbMetric: 447.7732 - lr: 0.0010 - 12s/epoch - 59ms/step
Epoch 15/1000
2023-09-10 13:39:47.289 
Epoch 15/1000 
	 loss: 446.7696, MinusLogProbMetric: 446.7696, val_loss: 449.3022, val_MinusLogProbMetric: 449.3022

Epoch 15: val_loss did not improve from 435.39368
196/196 - 10s - loss: 446.7696 - MinusLogProbMetric: 446.7696 - val_loss: 449.3022 - val_MinusLogProbMetric: 449.3022 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 16/1000
2023-09-10 13:39:59.635 
Epoch 16/1000 
	 loss: 444.2206, MinusLogProbMetric: 444.2206, val_loss: 434.0002, val_MinusLogProbMetric: 434.0002

Epoch 16: val_loss improved from 435.39368 to 434.00024, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 13s - loss: 444.2206 - MinusLogProbMetric: 444.2206 - val_loss: 434.0002 - val_MinusLogProbMetric: 434.0002 - lr: 0.0010 - 13s/epoch - 64ms/step
Epoch 17/1000
2023-09-10 13:40:09.089 
Epoch 17/1000 
	 loss: 441.2486, MinusLogProbMetric: 441.2486, val_loss: 434.7252, val_MinusLogProbMetric: 434.7252

Epoch 17: val_loss did not improve from 434.00024
196/196 - 9s - loss: 441.2486 - MinusLogProbMetric: 441.2486 - val_loss: 434.7252 - val_MinusLogProbMetric: 434.7252 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 18/1000
2023-09-10 13:40:19.809 
Epoch 18/1000 
	 loss: 436.0922, MinusLogProbMetric: 436.0922, val_loss: 442.8858, val_MinusLogProbMetric: 442.8858

Epoch 18: val_loss did not improve from 434.00024
196/196 - 11s - loss: 436.0922 - MinusLogProbMetric: 436.0922 - val_loss: 442.8858 - val_MinusLogProbMetric: 442.8858 - lr: 0.0010 - 11s/epoch - 55ms/step
Epoch 19/1000
2023-09-10 13:40:31.027 
Epoch 19/1000 
	 loss: 439.9194, MinusLogProbMetric: 439.9194, val_loss: 441.4523, val_MinusLogProbMetric: 441.4523

Epoch 19: val_loss did not improve from 434.00024
196/196 - 11s - loss: 439.9194 - MinusLogProbMetric: 439.9194 - val_loss: 441.4523 - val_MinusLogProbMetric: 441.4523 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 20/1000
2023-09-10 13:40:40.537 
Epoch 20/1000 
	 loss: 434.8078, MinusLogProbMetric: 434.8078, val_loss: 427.2945, val_MinusLogProbMetric: 427.2945

Epoch 20: val_loss improved from 434.00024 to 427.29446, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 434.8078 - MinusLogProbMetric: 434.8078 - val_loss: 427.2945 - val_MinusLogProbMetric: 427.2945 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 21/1000
2023-09-10 13:40:51.909 
Epoch 21/1000 
	 loss: 431.9131, MinusLogProbMetric: 431.9131, val_loss: 438.9560, val_MinusLogProbMetric: 438.9560

Epoch 21: val_loss did not improve from 427.29446
196/196 - 11s - loss: 431.9131 - MinusLogProbMetric: 431.9131 - val_loss: 438.9560 - val_MinusLogProbMetric: 438.9560 - lr: 0.0010 - 11s/epoch - 56ms/step
Epoch 22/1000
2023-09-10 13:41:02.164 
Epoch 22/1000 
	 loss: 429.7170, MinusLogProbMetric: 429.7170, val_loss: 428.3145, val_MinusLogProbMetric: 428.3145

Epoch 22: val_loss did not improve from 427.29446
196/196 - 10s - loss: 429.7170 - MinusLogProbMetric: 429.7170 - val_loss: 428.3145 - val_MinusLogProbMetric: 428.3145 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 23/1000
2023-09-10 13:41:13.428 
Epoch 23/1000 
	 loss: 428.2941, MinusLogProbMetric: 428.2941, val_loss: 440.8874, val_MinusLogProbMetric: 440.8874

Epoch 23: val_loss did not improve from 427.29446
196/196 - 11s - loss: 428.2941 - MinusLogProbMetric: 428.2941 - val_loss: 440.8874 - val_MinusLogProbMetric: 440.8874 - lr: 0.0010 - 11s/epoch - 58ms/step
Epoch 24/1000
2023-09-10 13:41:23.209 
Epoch 24/1000 
	 loss: 429.5756, MinusLogProbMetric: 429.5756, val_loss: 427.9208, val_MinusLogProbMetric: 427.9208

Epoch 24: val_loss did not improve from 427.29446
196/196 - 10s - loss: 429.5756 - MinusLogProbMetric: 429.5756 - val_loss: 427.9208 - val_MinusLogProbMetric: 427.9208 - lr: 0.0010 - 10s/epoch - 50ms/step
Epoch 25/1000
2023-09-10 13:41:33.780 
Epoch 25/1000 
	 loss: 429.0039, MinusLogProbMetric: 429.0039, val_loss: 428.6444, val_MinusLogProbMetric: 428.6444

Epoch 25: val_loss did not improve from 427.29446
196/196 - 11s - loss: 429.0039 - MinusLogProbMetric: 429.0039 - val_loss: 428.6444 - val_MinusLogProbMetric: 428.6444 - lr: 0.0010 - 11s/epoch - 54ms/step
Epoch 26/1000
2023-09-10 13:41:44.253 
Epoch 26/1000 
	 loss: 431.3176, MinusLogProbMetric: 431.3176, val_loss: 429.6241, val_MinusLogProbMetric: 429.6241

Epoch 26: val_loss did not improve from 427.29446
196/196 - 10s - loss: 431.3176 - MinusLogProbMetric: 431.3176 - val_loss: 429.6241 - val_MinusLogProbMetric: 429.6241 - lr: 0.0010 - 10s/epoch - 53ms/step
Epoch 27/1000
2023-09-10 13:41:52.845 
Epoch 27/1000 
	 loss: 426.7923, MinusLogProbMetric: 426.7923, val_loss: 424.5098, val_MinusLogProbMetric: 424.5098

Epoch 27: val_loss improved from 427.29446 to 424.50980, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 426.7923 - MinusLogProbMetric: 426.7923 - val_loss: 424.5098 - val_MinusLogProbMetric: 424.5098 - lr: 0.0010 - 9s/epoch - 47ms/step
Epoch 28/1000
2023-09-10 13:42:04.285 
Epoch 28/1000 
	 loss: 425.1284, MinusLogProbMetric: 425.1284, val_loss: 419.1399, val_MinusLogProbMetric: 419.1399

Epoch 28: val_loss improved from 424.50980 to 419.13989, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 425.1284 - MinusLogProbMetric: 425.1284 - val_loss: 419.1399 - val_MinusLogProbMetric: 419.1399 - lr: 0.0010 - 11s/epoch - 57ms/step
Epoch 29/1000
2023-09-10 13:42:13.603 
Epoch 29/1000 
	 loss: 423.9515, MinusLogProbMetric: 423.9515, val_loss: 425.5097, val_MinusLogProbMetric: 425.5097

Epoch 29: val_loss did not improve from 419.13989
196/196 - 9s - loss: 423.9515 - MinusLogProbMetric: 423.9515 - val_loss: 425.5097 - val_MinusLogProbMetric: 425.5097 - lr: 0.0010 - 9s/epoch - 46ms/step
Epoch 30/1000
2023-09-10 13:42:23.718 
Epoch 30/1000 
	 loss: 424.5844, MinusLogProbMetric: 424.5844, val_loss: 421.9794, val_MinusLogProbMetric: 421.9794

Epoch 30: val_loss did not improve from 419.13989
196/196 - 10s - loss: 424.5844 - MinusLogProbMetric: 424.5844 - val_loss: 421.9794 - val_MinusLogProbMetric: 421.9794 - lr: 0.0010 - 10s/epoch - 51ms/step
Epoch 31/1000
2023-09-10 13:42:33.367 
Epoch 31/1000 
	 loss: 424.9767, MinusLogProbMetric: 424.9767, val_loss: 420.1508, val_MinusLogProbMetric: 420.1508

Epoch 31: val_loss did not improve from 419.13989
196/196 - 10s - loss: 424.9767 - MinusLogProbMetric: 424.9767 - val_loss: 420.1508 - val_MinusLogProbMetric: 420.1508 - lr: 0.0010 - 10s/epoch - 49ms/step
Epoch 32/1000
2023-09-10 13:42:42.710 
Epoch 32/1000 
	 loss: 421.1952, MinusLogProbMetric: 421.1952, val_loss: 418.2376, val_MinusLogProbMetric: 418.2376

Epoch 32: val_loss improved from 419.13989 to 418.23761, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 421.1952 - MinusLogProbMetric: 421.1952 - val_loss: 418.2376 - val_MinusLogProbMetric: 418.2376 - lr: 0.0010 - 10s/epoch - 52ms/step
Epoch 33/1000
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Batch 139: Invalid loss, terminating training
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
Warning: The fraction of NaNs in loss is above threshold. Loss will be NaN.
2023-09-10 13:42:50.269 
Epoch 33/1000 
	 loss: inf, MinusLogProbMetric: 342958637056.0000, val_loss: nan, val_MinusLogProbMetric: nan

Epoch 33: val_loss did not improve from 418.23761
196/196 - 7s - loss: inf - MinusLogProbMetric: 342958637056.0000 - val_loss: nan - val_MinusLogProbMetric: nan - lr: 0.0010 - 7s/epoch - 34ms/step
The loss history contains Inf values.
Training failed: trying again with seed 105132 and lr 0.0003333333333333333.
===========
Generating train data for run 338.
===========
Train data generated in 2.19 s.

Building Trainer NFObject.


--------------- Debub info ---------------
Initializing Trainer with following parameters:
base_distribution: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
x_data_train shape: (100000, 1000)
y_data_train shape: (100000, 0)
io_kwargs: {'results_path': '../../results/MAFN_new/run_338/', 'load_weights': True, 'load_results': True}
data_kwargs: {'seed': 520}
compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}
callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MAFN_new/run_338/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}

--------------- Debub info ---------------
Defined attributes:
self.base_dist: tfp.distributions.Sample("SampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.flow: tfp.bijectors._Chain("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])
self.nf_dist: tfp.distributions._TransformedDistribution("chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal", batch_shape=[], event_shape=[1000], dtype=float32)
self.io_kwargs: {'results_path': '../../results/MAFN_new/run_338/', 'load_weights': True, 'load_results': True}
self.results_path: ../../results/MAFN_new/run_338
self.data_kwargs: {'seed': 520}
self.x_data: [[6.0386963  0.30078053 4.582872   ... 4.9010735  5.585139   5.0534396 ]
 [7.9469204  4.5061865  5.2455854  ... 2.9358454  8.744124   6.9367347 ]
 [8.143589   4.4823375  5.2392807  ... 3.0099165  8.623259   7.0103106 ]
 ...
 [8.140467   4.6205688  5.2538304  ... 5.1522036  8.523501   6.461891  ]
 [5.550299   8.4923     5.931979   ... 9.995682   1.7941611  6.8577833 ]
 [7.7436986  5.02466    5.1777496  ... 2.148604   8.593714   7.418009  ]]
self.y_data: []
self.ndims: 1000
Model defined.
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_52 (InputLayer)       [(None, 1000)]            0         
                                                                 
 log_prob_layer_6 (LogProbLa  (None,)                  4509200   
 yer)                                                            
                                                                 
=================================================================
Total params: 4,509,200
Trainable params: 4,509,200
Non-trainable params: 0
_________________________________________________________________
Model summary:  None
self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer_6/chain_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flow_of_permute_of_masked_autoregressive_flowSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description="created by layer 'log_prob_layer_6'")
self.model: <keras.engine.functional.Functional object at 0x7f191c7c9cf0>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
optimizer: <keras.optimizers.adam.Adam object at 0x7f191c7b2c20>
type(optimizer): <class 'keras.optimizers.adam.Adam'>
self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.0003333333333333333, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}
self.optimizer: <keras.optimizers.adam.Adam object at 0x7f191c7b2c20>
self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}
self.loss: <Trainer.MinusLogProbLoss object at 0x7f197c194a00>
self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]
self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f191c75d510>]
self.compile_kwargs: {}
self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]
self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f191c75d9f0>, <keras.callbacks.ModelCheckpoint object at 0x7f191c75dab0>, <keras.callbacks.EarlyStopping object at 0x7f191c75dd20>, <keras.callbacks.ReduceLROnPlateau object at 0x7f191c75dd50>, <keras.callbacks.TerminateOnNaN object at 0x7f191c75d990>]
self.fit_kwargs: {'batch_size': 512, 'epochs': 1000, 'validation_data': (array([[ 6.1938453 ,  0.533144  ,  4.8263674 , ...,  4.486572  ,
         6.023426  ,  7.1273623 ],
       [ 7.585662  ,  4.7953405 ,  5.2079363 , ...,  2.9872682 ,
         8.320559  ,  6.9911246 ],
       [ 5.966249  , -0.30219892,  4.8852797 , ...,  4.988506  ,
         6.203924  ,  5.582959  ],
       ...,
       [ 7.967994  ,  4.477745  ,  5.2694697 , ...,  2.879139  ,
         7.399321  ,  6.960496  ],
       [ 6.5566854 ,  0.02881634,  4.848876  , ...,  5.0976205 ,
         6.4114294 ,  3.5750432 ],
       [ 8.147113  ,  4.715337  ,  5.2998085 , ...,  4.052641  ,
         8.0347185 ,  6.6445417 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}
self.is_compiled: False
self.training_time: 0.0
self.history: {}
Model successfully compiled.
Found and loaded existing weights.
No history found. Generating new history.
===============
Running 338/360 with hyperparameters:
timestamp = 2023-09-10 13:42:56.096736
ndims = 1000
seed_train = 520
nsamples_train = 100000
nsamples_val = 30000
nsamples_test = 100000
bijector = MAFN
nbijectors = 5
spline_knots = --
range_min = -5
hidden_layers = 256-256-256
trainable_parameters = 4509200
epochs_input = 1000
batch_size = 512
activation = relu
training_device = NVIDIA A40
===============

Training model with initial learning rate 0.0003333333333333333...
Train first sample: [ 6.0386963   0.30078053  4.582872    7.656263    0.50402063  8.927606
  5.0806236   0.7069437   3.2612228   9.222077    5.8550296   0.7950525
  3.7572262   5.421181   -0.42896372  5.3715286   5.0170646   4.5275445
  6.268279    8.342493    2.4881694   7.7397876   7.198324   10.337882
  7.1367445   7.992043    3.640705    1.6190335   9.687809   -0.10210621
  4.3673606   0.5702325   9.0355015   9.576009    7.180074    2.9750605
  2.7969558   2.6438603   1.315014    5.2577987   1.5748067   3.07832
  6.905322    7.2643003   0.31143492  3.629692    6.198628    9.935606
  4.738879    9.644313    2.6127305  -0.2701767   4.573748    2.6033232
  8.31127     2.847469    3.1219404   8.036686    8.350981    5.1923842
  7.0816703   3.7841296   0.439943    0.31411228  5.105436    0.16452146
  0.37245148  8.840347    7.522216    2.485342   -0.04555227  9.480491
  3.3716009   2.2168918   5.8693147   1.2792552   2.5388308   9.7780695
  6.3509502   5.2145343   4.668051    7.835037    0.81844634  9.829676
  8.602084    6.4478574   1.8822466   8.708197    9.9343      5.2983065
  4.648863    1.7545191   7.5778584   7.992651    1.2489895   7.932429
  0.19842413 10.670638    6.7138567   5.5415473   2.8593335   8.939356
  1.8772883   8.274395    9.729145    7.7069526   4.83206     0.20179847
  4.5409455   4.72331     2.8598065   4.388705    3.542864    1.3279399
  4.2783537   2.6017168   5.7597165   0.7641455   9.5386305   9.114207
  5.246056    8.810347    9.548426    1.1960151   4.535228    9.936641
 10.11391     6.0469294   1.2320046   5.771403    0.03692677  1.7631103
  9.768336    4.6296864   6.3364687   2.3349156   9.236544    8.197755
  3.2024207   7.716959    2.077003    4.211735    2.1907134   7.0612254
  1.2628212   4.2821627   1.9289484   4.29324     4.816094    7.6030316
  0.34979546  7.054235    2.5239222   2.5584276   7.064572    9.337272
  4.1277614   8.632163    1.1907344   7.2465253   7.3629594   1.4210125
  3.8094866   8.687733    1.3656402   0.28611335  5.895154    4.691248
  7.848699    8.486627    2.7608519   4.164383    5.0772963   6.1176133
 10.264451    6.3248825   3.0036852   2.4301364   9.323013    1.1239512
  6.9529996   8.971375    6.7585683   4.1878514   2.5465474   3.7158139
  7.954454    6.121273    8.889866    8.739019   10.887082    9.803803
  2.4961972   3.7658646   4.353828    5.831876    6.706101    2.2424636
  0.4813192   4.0677247   2.7481353   8.85868     8.81974     8.779158
  6.5635395   3.1331716   5.4378457   8.115037    0.15877736  7.7527685
 -0.23714772  9.2626095   7.987624    0.7620828   6.501852    3.2839687
  1.7200415   1.1543069   7.17581     5.3241725   9.85193    10.548408
 10.603701    2.2370188   9.374007    3.4676795   4.4167695   7.9351892
  2.2672663   5.607824    2.2299185   0.88661635  1.2501802   4.0727944
 -0.12534815  4.24075     6.864432    4.1316953   0.98898524  1.0468978
  2.6923618   1.5284702   9.68549     2.6858997   8.196742    5.9775615
  6.107674    3.8373623   9.739576    3.8176546   7.881323    5.9619036
  4.809063    9.994005    6.06644     0.60921174  5.0061116   8.33161
  7.0547867   8.514869    2.0673354   7.7308583   4.0995107   5.0039496
 10.610853    9.848376    8.120186    4.446167    8.818996    6.304151
  3.6133528   0.34783545  8.203926    4.955636    8.081435    7.584287
  7.8737516   3.389564    7.996908    6.0786796   4.5982037   7.0935416
  0.92889404  1.281023    2.9661057   9.792753    1.4344769   3.2898872
  1.1154623   3.3197548   4.133613    9.714192    7.8477564   3.915498
 -0.54802597  8.3167515   6.381558    1.8454669  11.718771    1.0781447
  8.230542    2.993074    4.4022226   7.81114     6.1109514   8.33177
  6.2205343   0.9577046   9.167438    7.7908244   7.120584    1.3328398
  3.1939583   1.6910427   8.12919     6.4541216   7.9364567  10.26773
  7.809719   10.104616    6.0293574   0.40289783 -0.560338    3.7847402
  7.9600444   9.035484   10.840271    1.0387208  -0.19058862  8.854946
  3.0963922   5.0594854  10.279567    5.074058    6.6726894   3.9883325
  7.652588    4.496253    3.0499647   2.3702488   2.5340867   3.782253
  6.6244855   9.641262    7.137413    6.8682413   1.8626316   4.317209
  4.4707828   6.841525    2.992224    2.4876325   3.3212593   7.333737
  5.75945     0.32461804  0.8335988   3.4026284   8.618828    6.705712
  6.8725452   7.33386     2.8872874   5.3803415   5.1434884   6.246975
  9.339241    0.6288371   8.414895    6.5827723   5.714417    7.4871626
  9.453507    0.7600125   1.494343    7.271453   -0.10680145  4.284081
  3.0645723   2.7818801   6.7562222   0.9355258   8.759254    4.4485765
  4.9456024   5.2843823   6.5932875   3.4578905   0.32452983  3.0972865
  0.45848465  5.198651    2.197647    9.560289    9.731855    6.5005336
  6.619211   10.057005    8.876658    8.295638    3.1194568   3.6742027
  2.26406     5.3983374   9.887169    9.133878    1.5052447   1.7451565
  8.9965925   5.319445    2.527405    6.8142905   6.4233      1.2479438
  4.035429    0.24714679  2.1173966   1.830858    1.9078584   7.0054536
  0.5009528   0.8397763   2.0496254   2.9811964   2.9665575   3.3201675
  7.2900653   9.622518    4.901422    7.8189707   3.9295015   0.91512156
  4.572243    3.2736297   4.8408017   7.065958    4.651118    9.0410385
  8.961053    5.5870433   5.2621417   1.1291223   3.93055     6.9391193
  3.508282    0.4460107   9.179407    7.387717    4.650465    8.17948
  7.53271     5.0031796   8.804058    9.204221    3.6460009   7.006398
  5.8495746   5.197357    9.277365    2.9547234  10.355085    8.981658
  5.367272    8.041138    7.377086    7.5142937   4.0544214   2.2740157
  6.749342    8.733181   -1.1557603   6.3426285   4.84659     8.766928
  2.8006268   4.1529183   4.987336    0.13959682  6.5040164   8.188027
  1.676772    2.4030275   0.5443996   9.24266     5.4919004   9.14114
  5.4362607   7.7436833   3.4114141   2.927477    3.843325    6.4828835
  2.9296427   9.1742115   8.056144   -0.09604371  2.0134284   1.6318083
  0.04543668  2.690591    4.990765    8.81346     2.1004107   4.4873705
 10.513251    7.137761    7.6034775   5.209668    9.811113    5.6359825
  0.19526497  2.564422    4.0089235   6.4994254   7.695936    4.1304693
  7.2958503   8.454953    2.967984    9.869264    7.2374787   8.593143
  5.7742076   7.5300508   7.2095394   7.823381    2.118999    5.039945
  4.053479    9.185997    0.9152442  10.862353    8.841984    0.75618994
  4.901044    7.2554336   7.1853967   9.084257    8.29529     4.220908
  5.8150444   7.7635503   1.2401824   1.3507668   4.54757     3.457343
  7.9834795   5.028612    3.85299     8.574433    8.163936   10.616821
  8.4081      4.1708117   1.2379287   8.800616    1.4772482   4.080577
  8.428701   10.380288    6.389518    6.8510385   0.61914694  4.0696154
  6.8948746   3.383478    0.4705223   3.009568    2.6594605   3.048335
  5.988357    7.1357174   3.261515    4.0008183   0.27625528 -0.3875654
  2.6110508   6.7222776   4.8376966   7.503794    6.6424117   8.686342
  7.1706657   9.419308    7.926278    6.2358265   6.0555067  -0.70361733
 10.064413    1.4912657   8.07811     7.900392    4.8439436   2.0139859
  1.0714337   7.2137423   4.526915    6.6356516   9.933811    1.5130765
  9.312532    3.7438834   3.550579    9.596389    9.815127    1.7642053
  7.4918814  -0.49520278  6.4749107   9.756271    7.145049    4.039104
  3.7851322   4.082335    6.1268287   8.183756    9.32123     0.28198594
  2.5236871  -0.31258178  2.2504802   3.5232162   4.9025984   6.3538814
  7.8291597   9.178961   10.243786    7.067563    8.285971    9.500681
  3.5682902   8.450219    0.17376387  0.216589    2.7681222   4.1601896
  6.1601834   1.706507    6.643297    7.9561872   1.7723906   4.5958123
  5.858561    4.6678243   8.187405    9.715012    8.1015      0.45350024
  7.7912116   0.77989995  2.3104167   1.3162912   1.205177    5.248102
  6.7170506   5.558635    9.548942    2.291232    7.7552695   8.649344
  5.677332    4.394188    6.64837     4.7241607   5.719767    3.967581
  4.259147    7.17209     1.0130833   1.7905484   8.393191    7.4030704
  2.735002    2.5851526   9.099808    7.8557224   6.1393533   2.1640992
  0.7774042   4.113809    6.8772874   9.341514    7.624882   -0.15643695
  2.3431437   3.3053102   1.6893227   7.5518737   7.47631     5.387754
  9.710713    1.6661869   8.289583    1.1974262   3.0808344   7.3471923
  0.8228001   5.6459312   3.6627483   7.2736874   8.484636    7.5182805
  6.5065517   0.4700985   2.234543    5.2005877   3.5432315   2.8302953
  2.0971265   9.56212     3.0628858   4.7415     -0.44130558  9.013574
  1.085037    3.311532    2.5385356   8.806095    2.0905962   7.8503737
  8.578108    9.528165    0.590898    1.9645467   7.9985986   1.753687
  3.172571    1.6611466   1.8709267   4.7864184   1.3145969   3.1479964
  4.083562    0.2390917   3.327033    0.9105044   6.7123947   7.861191
  7.02552     0.75634694  5.9596577   8.067755    2.4828937   7.6143017
  8.580062    7.3855762  -0.04546678  0.0738206   1.8115419   2.7274795
  6.6129613   3.8759396   6.692868    3.7261245   1.3076189   3.1666129
  9.223293    9.462051    2.376804    7.5547466   2.749257    8.444417
  1.3476957   6.958887    0.12667698  9.694718    6.407499    8.479325
  5.627874    4.950144    6.2193155   5.3255057   4.9456944   8.290707
  0.8348843   2.2261314   4.1954646   3.6872017   0.73160475  8.504263
  7.791428    5.3747725   9.8119135   0.7039877   7.6769605   2.5379546
  3.694837    2.045665    7.2654924   0.12175488  7.247275    7.029465
  0.6658832   8.352133    5.5662146   9.030525    7.8712974   5.6255913
  8.1955      3.5710793   4.832326    5.828453   10.745017    1.85231
 -0.526502    3.3114655   4.8024893   0.62556016  4.9190855   9.197764
  6.527681    8.61912     9.540909    9.433219    7.9817605   5.9839487
  4.9048758   0.6134869   5.948723   10.432518    8.046861    3.3048022
  1.5137587   7.991438    7.427192    9.765905    8.476495    5.9867887
  1.0616344   5.6400924   2.9184952   5.1216874   2.580817    8.646928
  7.5732      4.096987    6.089647    4.3319507   8.435398    2.1281555
  7.02788     9.129615    1.7530978   1.3687971   7.042738    7.6120076
  4.263667    6.845998    3.1399002   4.1320887   1.0887251   3.7039056
  2.7662733   3.7930636   9.0424595   1.3231362   3.5029469   6.702694
  9.477917    0.9764585   9.146437    0.77568066  5.0711017   4.2204366
  1.9013925   3.6039436   4.875466    8.647586    9.651502    6.2052207
  8.608539    6.7567143   3.158669    1.8811914   4.3497324   5.161394
  0.6098187   1.152159    6.051886    1.3697395   8.290108    2.6722713
  2.2818537   0.9584924   9.105338    1.0756454   1.5344902   8.241914
  2.561514    6.2516336   7.197662    6.6100316   8.612244    7.1160245
  1.4579626   5.4742584   6.604126    8.5800705   0.06284574  7.271172
  9.004775    7.700049    5.588264    4.5855756   4.7795944   7.2477436
  8.905804    6.081058    9.249524    7.4357276   0.8587049   4.7164693
  2.8504999   3.989924    3.8770769   2.9917765   5.714236    6.905015
  2.6859546   1.846874    0.41534102  4.812243    1.8113589  -0.9216505
  9.0558815   4.663535    1.0859932   8.355898    7.844323    4.0918174
  0.6433816   1.5224574   4.468763    8.928121    1.204919    8.635436
 -0.03399917  4.6824536   6.482672    0.5008905   5.682656    8.837162
  2.072514    7.1392884   6.1446853   2.1056101   0.07073235  0.26507834
  5.238253    9.371503    6.251286    7.188611    5.0308127   6.007279
  1.024926    8.809044    7.712478   10.019146    2.5657964   3.195103
  0.9103755   9.777725    7.5711966   3.4351816   5.4496226   4.112291
  1.660826    1.7369623   9.639072    2.935317    9.930944    0.73487484
  5.733989    1.3034487   0.502199    5.5747876   1.0674012   8.124411
  7.0287094   2.9280264   9.545342    7.30834     2.6214435   7.561452
  7.846946    1.3374016   3.65282     3.05842     6.171471    8.9460125
  1.6092017   8.305956   -0.07000089  6.6192155   4.523222    7.941383
  7.4171886   4.9010735   5.585139    5.0534396 ]
Epoch 1/1000
2023-09-10 13:43:47.045 
Epoch 1/1000 
	 loss: 446.0674, MinusLogProbMetric: 446.0674, val_loss: 411.4600, val_MinusLogProbMetric: 411.4600

Epoch 1: val_loss improved from inf to 411.45996, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 52s - loss: 446.0674 - MinusLogProbMetric: 446.0674 - val_loss: 411.4600 - val_MinusLogProbMetric: 411.4600 - lr: 3.3333e-04 - 52s/epoch - 264ms/step
Epoch 2/1000
2023-09-10 13:43:58.833 
Epoch 2/1000 
	 loss: 409.4760, MinusLogProbMetric: 409.4760, val_loss: 410.2760, val_MinusLogProbMetric: 410.2760

Epoch 2: val_loss improved from 411.45996 to 410.27600, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 409.4760 - MinusLogProbMetric: 409.4760 - val_loss: 410.2760 - val_MinusLogProbMetric: 410.2760 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 3/1000
2023-09-10 13:44:08.766 
Epoch 3/1000 
	 loss: 409.1288, MinusLogProbMetric: 409.1288, val_loss: 409.4032, val_MinusLogProbMetric: 409.4032

Epoch 3: val_loss improved from 410.27600 to 409.40320, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 409.1288 - MinusLogProbMetric: 409.1288 - val_loss: 409.4032 - val_MinusLogProbMetric: 409.4032 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 4/1000
2023-09-10 13:44:19.651 
Epoch 4/1000 
	 loss: 409.5720, MinusLogProbMetric: 409.5720, val_loss: 409.2421, val_MinusLogProbMetric: 409.2421

Epoch 4: val_loss improved from 409.40320 to 409.24213, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 409.5720 - MinusLogProbMetric: 409.5720 - val_loss: 409.2421 - val_MinusLogProbMetric: 409.2421 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 5/1000
2023-09-10 13:44:29.353 
Epoch 5/1000 
	 loss: 408.7240, MinusLogProbMetric: 408.7240, val_loss: 410.5759, val_MinusLogProbMetric: 410.5759

Epoch 5: val_loss did not improve from 409.24213
196/196 - 9s - loss: 408.7240 - MinusLogProbMetric: 408.7240 - val_loss: 410.5759 - val_MinusLogProbMetric: 410.5759 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 6/1000
2023-09-10 13:44:38.998 
Epoch 6/1000 
	 loss: 408.6805, MinusLogProbMetric: 408.6805, val_loss: 408.5546, val_MinusLogProbMetric: 408.5546

Epoch 6: val_loss improved from 409.24213 to 408.55457, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 408.6805 - MinusLogProbMetric: 408.6805 - val_loss: 408.5546 - val_MinusLogProbMetric: 408.5546 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 7/1000
2023-09-10 13:44:50.307 
Epoch 7/1000 
	 loss: 409.0107, MinusLogProbMetric: 409.0107, val_loss: 408.7149, val_MinusLogProbMetric: 408.7149

Epoch 7: val_loss did not improve from 408.55457
196/196 - 10s - loss: 409.0107 - MinusLogProbMetric: 409.0107 - val_loss: 408.7149 - val_MinusLogProbMetric: 408.7149 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 8/1000
2023-09-10 13:44:59.312 
Epoch 8/1000 
	 loss: 407.9343, MinusLogProbMetric: 407.9343, val_loss: 408.1090, val_MinusLogProbMetric: 408.1090

Epoch 8: val_loss improved from 408.55457 to 408.10898, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 407.9343 - MinusLogProbMetric: 407.9343 - val_loss: 408.1090 - val_MinusLogProbMetric: 408.1090 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 9/1000
2023-09-10 13:45:11.171 
Epoch 9/1000 
	 loss: 407.8637, MinusLogProbMetric: 407.8637, val_loss: 407.4255, val_MinusLogProbMetric: 407.4255

Epoch 9: val_loss improved from 408.10898 to 407.42551, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 407.8637 - MinusLogProbMetric: 407.8637 - val_loss: 407.4255 - val_MinusLogProbMetric: 407.4255 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 10/1000
2023-09-10 13:45:21.085 
Epoch 10/1000 
	 loss: 407.6457, MinusLogProbMetric: 407.6457, val_loss: 408.8266, val_MinusLogProbMetric: 408.8266

Epoch 10: val_loss did not improve from 407.42551
196/196 - 9s - loss: 407.6457 - MinusLogProbMetric: 407.6457 - val_loss: 408.8266 - val_MinusLogProbMetric: 408.8266 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 11/1000
2023-09-10 13:45:34.250 
Epoch 11/1000 
	 loss: 407.3451, MinusLogProbMetric: 407.3451, val_loss: 407.3253, val_MinusLogProbMetric: 407.3253

Epoch 11: val_loss improved from 407.42551 to 407.32526, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 14s - loss: 407.3451 - MinusLogProbMetric: 407.3451 - val_loss: 407.3253 - val_MinusLogProbMetric: 407.3253 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 12/1000
2023-09-10 13:45:46.503 
Epoch 12/1000 
	 loss: 407.2038, MinusLogProbMetric: 407.2038, val_loss: 414.4082, val_MinusLogProbMetric: 414.4082

Epoch 12: val_loss did not improve from 407.32526
196/196 - 12s - loss: 407.2038 - MinusLogProbMetric: 407.2038 - val_loss: 414.4082 - val_MinusLogProbMetric: 414.4082 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 13/1000
2023-09-10 13:45:55.917 
Epoch 13/1000 
	 loss: 406.8438, MinusLogProbMetric: 406.8438, val_loss: 407.6966, val_MinusLogProbMetric: 407.6966

Epoch 13: val_loss did not improve from 407.32526
196/196 - 9s - loss: 406.8438 - MinusLogProbMetric: 406.8438 - val_loss: 407.6966 - val_MinusLogProbMetric: 407.6966 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 14/1000
2023-09-10 13:46:06.947 
Epoch 14/1000 
	 loss: 406.8147, MinusLogProbMetric: 406.8147, val_loss: 405.5747, val_MinusLogProbMetric: 405.5747

Epoch 14: val_loss improved from 407.32526 to 405.57468, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 406.8147 - MinusLogProbMetric: 406.8147 - val_loss: 405.5747 - val_MinusLogProbMetric: 405.5747 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 15/1000
2023-09-10 13:46:16.004 
Epoch 15/1000 
	 loss: 406.3571, MinusLogProbMetric: 406.3571, val_loss: 406.3281, val_MinusLogProbMetric: 406.3281

Epoch 15: val_loss did not improve from 405.57468
196/196 - 9s - loss: 406.3571 - MinusLogProbMetric: 406.3571 - val_loss: 406.3281 - val_MinusLogProbMetric: 406.3281 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 16/1000
2023-09-10 13:46:25.063 
Epoch 16/1000 
	 loss: 406.7426, MinusLogProbMetric: 406.7426, val_loss: 405.0271, val_MinusLogProbMetric: 405.0271

Epoch 16: val_loss improved from 405.57468 to 405.02713, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 406.7426 - MinusLogProbMetric: 406.7426 - val_loss: 405.0271 - val_MinusLogProbMetric: 405.0271 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 17/1000
2023-09-10 13:46:35.525 
Epoch 17/1000 
	 loss: 405.8083, MinusLogProbMetric: 405.8083, val_loss: 407.4230, val_MinusLogProbMetric: 407.4230

Epoch 17: val_loss did not improve from 405.02713
196/196 - 10s - loss: 405.8083 - MinusLogProbMetric: 405.8083 - val_loss: 407.4230 - val_MinusLogProbMetric: 407.4230 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 18/1000
2023-09-10 13:46:44.099 
Epoch 18/1000 
	 loss: 406.0003, MinusLogProbMetric: 406.0003, val_loss: 406.6203, val_MinusLogProbMetric: 406.6203

Epoch 18: val_loss did not improve from 405.02713
196/196 - 9s - loss: 406.0003 - MinusLogProbMetric: 406.0003 - val_loss: 406.6203 - val_MinusLogProbMetric: 406.6203 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 19/1000
2023-09-10 13:46:54.673 
Epoch 19/1000 
	 loss: 405.4104, MinusLogProbMetric: 405.4104, val_loss: 405.5019, val_MinusLogProbMetric: 405.5019

Epoch 19: val_loss did not improve from 405.02713
196/196 - 11s - loss: 405.4104 - MinusLogProbMetric: 405.4104 - val_loss: 405.5019 - val_MinusLogProbMetric: 405.5019 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 20/1000
2023-09-10 13:47:03.895 
Epoch 20/1000 
	 loss: 405.2538, MinusLogProbMetric: 405.2538, val_loss: 405.0594, val_MinusLogProbMetric: 405.0594

Epoch 20: val_loss did not improve from 405.02713
196/196 - 9s - loss: 405.2538 - MinusLogProbMetric: 405.2538 - val_loss: 405.0594 - val_MinusLogProbMetric: 405.0594 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 21/1000
2023-09-10 13:47:12.729 
Epoch 21/1000 
	 loss: 405.5320, MinusLogProbMetric: 405.5320, val_loss: 404.8559, val_MinusLogProbMetric: 404.8559

Epoch 21: val_loss improved from 405.02713 to 404.85593, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 405.5320 - MinusLogProbMetric: 405.5320 - val_loss: 404.8559 - val_MinusLogProbMetric: 404.8559 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 22/1000
2023-09-10 13:47:24.884 
Epoch 22/1000 
	 loss: 404.8186, MinusLogProbMetric: 404.8186, val_loss: 412.4795, val_MinusLogProbMetric: 412.4795

Epoch 22: val_loss did not improve from 404.85593
196/196 - 11s - loss: 404.8186 - MinusLogProbMetric: 404.8186 - val_loss: 412.4795 - val_MinusLogProbMetric: 412.4795 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 23/1000
2023-09-10 13:47:35.338 
Epoch 23/1000 
	 loss: 405.0560, MinusLogProbMetric: 405.0560, val_loss: 407.4502, val_MinusLogProbMetric: 407.4502

Epoch 23: val_loss did not improve from 404.85593
196/196 - 10s - loss: 405.0560 - MinusLogProbMetric: 405.0560 - val_loss: 407.4502 - val_MinusLogProbMetric: 407.4502 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 24/1000
2023-09-10 13:47:46.451 
Epoch 24/1000 
	 loss: 404.1942, MinusLogProbMetric: 404.1942, val_loss: 403.9693, val_MinusLogProbMetric: 403.9693

Epoch 24: val_loss improved from 404.85593 to 403.96930, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 404.1942 - MinusLogProbMetric: 404.1942 - val_loss: 403.9693 - val_MinusLogProbMetric: 403.9693 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 25/1000
2023-09-10 13:47:57.309 
Epoch 25/1000 
	 loss: 404.4932, MinusLogProbMetric: 404.4932, val_loss: 403.6814, val_MinusLogProbMetric: 403.6814

Epoch 25: val_loss improved from 403.96930 to 403.68140, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 404.4932 - MinusLogProbMetric: 404.4932 - val_loss: 403.6814 - val_MinusLogProbMetric: 403.6814 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 26/1000
2023-09-10 13:48:08.681 
Epoch 26/1000 
	 loss: 403.9482, MinusLogProbMetric: 403.9482, val_loss: 405.8929, val_MinusLogProbMetric: 405.8929

Epoch 26: val_loss did not improve from 403.68140
196/196 - 11s - loss: 403.9482 - MinusLogProbMetric: 403.9482 - val_loss: 405.8929 - val_MinusLogProbMetric: 405.8929 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 27/1000
2023-09-10 13:48:17.907 
Epoch 27/1000 
	 loss: 404.0742, MinusLogProbMetric: 404.0742, val_loss: 405.2029, val_MinusLogProbMetric: 405.2029

Epoch 27: val_loss did not improve from 403.68140
196/196 - 9s - loss: 404.0742 - MinusLogProbMetric: 404.0742 - val_loss: 405.2029 - val_MinusLogProbMetric: 405.2029 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 28/1000
2023-09-10 13:48:27.858 
Epoch 28/1000 
	 loss: 403.8977, MinusLogProbMetric: 403.8977, val_loss: 403.9525, val_MinusLogProbMetric: 403.9525

Epoch 28: val_loss did not improve from 403.68140
196/196 - 10s - loss: 403.8977 - MinusLogProbMetric: 403.8977 - val_loss: 403.9525 - val_MinusLogProbMetric: 403.9525 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 29/1000
2023-09-10 13:48:37.811 
Epoch 29/1000 
	 loss: 403.9791, MinusLogProbMetric: 403.9791, val_loss: 406.2623, val_MinusLogProbMetric: 406.2623

Epoch 29: val_loss did not improve from 403.68140
196/196 - 10s - loss: 403.9791 - MinusLogProbMetric: 403.9791 - val_loss: 406.2623 - val_MinusLogProbMetric: 406.2623 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 30/1000
2023-09-10 13:48:47.590 
Epoch 30/1000 
	 loss: 403.5656, MinusLogProbMetric: 403.5656, val_loss: 405.0327, val_MinusLogProbMetric: 405.0327

Epoch 30: val_loss did not improve from 403.68140
196/196 - 10s - loss: 403.5656 - MinusLogProbMetric: 403.5656 - val_loss: 405.0327 - val_MinusLogProbMetric: 405.0327 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 31/1000
2023-09-10 13:48:56.708 
Epoch 31/1000 
	 loss: 403.5615, MinusLogProbMetric: 403.5615, val_loss: 404.9248, val_MinusLogProbMetric: 404.9248

Epoch 31: val_loss did not improve from 403.68140
196/196 - 9s - loss: 403.5615 - MinusLogProbMetric: 403.5615 - val_loss: 404.9248 - val_MinusLogProbMetric: 404.9248 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 32/1000
2023-09-10 13:49:08.196 
Epoch 32/1000 
	 loss: 403.2224, MinusLogProbMetric: 403.2224, val_loss: 404.4779, val_MinusLogProbMetric: 404.4779

Epoch 32: val_loss did not improve from 403.68140
196/196 - 12s - loss: 403.2224 - MinusLogProbMetric: 403.2224 - val_loss: 404.4779 - val_MinusLogProbMetric: 404.4779 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 33/1000
2023-09-10 13:49:17.636 
Epoch 33/1000 
	 loss: 405.6919, MinusLogProbMetric: 405.6919, val_loss: 424.3026, val_MinusLogProbMetric: 424.3026

Epoch 33: val_loss did not improve from 403.68140
196/196 - 9s - loss: 405.6919 - MinusLogProbMetric: 405.6919 - val_loss: 424.3026 - val_MinusLogProbMetric: 424.3026 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 34/1000
2023-09-10 13:49:28.749 
Epoch 34/1000 
	 loss: 403.2918, MinusLogProbMetric: 403.2918, val_loss: 404.2818, val_MinusLogProbMetric: 404.2818

Epoch 34: val_loss did not improve from 403.68140
196/196 - 11s - loss: 403.2918 - MinusLogProbMetric: 403.2918 - val_loss: 404.2818 - val_MinusLogProbMetric: 404.2818 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 35/1000
2023-09-10 13:49:38.189 
Epoch 35/1000 
	 loss: 402.8585, MinusLogProbMetric: 402.8585, val_loss: 404.7805, val_MinusLogProbMetric: 404.7805

Epoch 35: val_loss did not improve from 403.68140
196/196 - 9s - loss: 402.8585 - MinusLogProbMetric: 402.8585 - val_loss: 404.7805 - val_MinusLogProbMetric: 404.7805 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 36/1000
2023-09-10 13:49:50.199 
Epoch 36/1000 
	 loss: 402.7980, MinusLogProbMetric: 402.7980, val_loss: 407.9741, val_MinusLogProbMetric: 407.9741

Epoch 36: val_loss did not improve from 403.68140
196/196 - 12s - loss: 402.7980 - MinusLogProbMetric: 402.7980 - val_loss: 407.9741 - val_MinusLogProbMetric: 407.9741 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 37/1000
2023-09-10 13:49:59.427 
Epoch 37/1000 
	 loss: 403.3420, MinusLogProbMetric: 403.3420, val_loss: 403.9737, val_MinusLogProbMetric: 403.9737

Epoch 37: val_loss did not improve from 403.68140
196/196 - 9s - loss: 403.3420 - MinusLogProbMetric: 403.3420 - val_loss: 403.9737 - val_MinusLogProbMetric: 403.9737 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 38/1000
2023-09-10 13:50:09.365 
Epoch 38/1000 
	 loss: 402.7201, MinusLogProbMetric: 402.7201, val_loss: 403.2379, val_MinusLogProbMetric: 403.2379

Epoch 38: val_loss improved from 403.68140 to 403.23785, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 402.7201 - MinusLogProbMetric: 402.7201 - val_loss: 403.2379 - val_MinusLogProbMetric: 403.2379 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 39/1000
2023-09-10 13:50:20.202 
Epoch 39/1000 
	 loss: 402.1178, MinusLogProbMetric: 402.1178, val_loss: 402.8310, val_MinusLogProbMetric: 402.8310

Epoch 39: val_loss improved from 403.23785 to 402.83096, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 402.1178 - MinusLogProbMetric: 402.1178 - val_loss: 402.8310 - val_MinusLogProbMetric: 402.8310 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 40/1000
2023-09-10 13:50:29.379 
Epoch 40/1000 
	 loss: 401.9721, MinusLogProbMetric: 401.9721, val_loss: 404.6407, val_MinusLogProbMetric: 404.6407

Epoch 40: val_loss did not improve from 402.83096
196/196 - 9s - loss: 401.9721 - MinusLogProbMetric: 401.9721 - val_loss: 404.6407 - val_MinusLogProbMetric: 404.6407 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 41/1000
2023-09-10 13:50:40.809 
Epoch 41/1000 
	 loss: 401.8446, MinusLogProbMetric: 401.8446, val_loss: 406.1377, val_MinusLogProbMetric: 406.1377

Epoch 41: val_loss did not improve from 402.83096
196/196 - 11s - loss: 401.8446 - MinusLogProbMetric: 401.8446 - val_loss: 406.1377 - val_MinusLogProbMetric: 406.1377 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 42/1000
2023-09-10 13:50:49.945 
Epoch 42/1000 
	 loss: 401.9570, MinusLogProbMetric: 401.9570, val_loss: 404.1412, val_MinusLogProbMetric: 404.1412

Epoch 42: val_loss did not improve from 402.83096
196/196 - 9s - loss: 401.9570 - MinusLogProbMetric: 401.9570 - val_loss: 404.1412 - val_MinusLogProbMetric: 404.1412 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 43/1000
2023-09-10 13:51:01.549 
Epoch 43/1000 
	 loss: 401.8378, MinusLogProbMetric: 401.8378, val_loss: 406.7170, val_MinusLogProbMetric: 406.7170

Epoch 43: val_loss did not improve from 402.83096
196/196 - 12s - loss: 401.8378 - MinusLogProbMetric: 401.8378 - val_loss: 406.7170 - val_MinusLogProbMetric: 406.7170 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 44/1000
2023-09-10 13:51:09.950 
Epoch 44/1000 
	 loss: 401.5847, MinusLogProbMetric: 401.5847, val_loss: 404.2076, val_MinusLogProbMetric: 404.2076

Epoch 44: val_loss did not improve from 402.83096
196/196 - 8s - loss: 401.5847 - MinusLogProbMetric: 401.5847 - val_loss: 404.2076 - val_MinusLogProbMetric: 404.2076 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 45/1000
2023-09-10 13:51:20.075 
Epoch 45/1000 
	 loss: 401.9996, MinusLogProbMetric: 401.9996, val_loss: 403.9683, val_MinusLogProbMetric: 403.9683

Epoch 45: val_loss did not improve from 402.83096
196/196 - 10s - loss: 401.9996 - MinusLogProbMetric: 401.9996 - val_loss: 403.9683 - val_MinusLogProbMetric: 403.9683 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 46/1000
2023-09-10 13:51:28.706 
Epoch 46/1000 
	 loss: 401.4515, MinusLogProbMetric: 401.4515, val_loss: 403.7332, val_MinusLogProbMetric: 403.7332

Epoch 46: val_loss did not improve from 402.83096
196/196 - 9s - loss: 401.4515 - MinusLogProbMetric: 401.4515 - val_loss: 403.7332 - val_MinusLogProbMetric: 403.7332 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 47/1000
2023-09-10 13:51:39.787 
Epoch 47/1000 
	 loss: 401.0112, MinusLogProbMetric: 401.0112, val_loss: 401.2952, val_MinusLogProbMetric: 401.2952

Epoch 47: val_loss improved from 402.83096 to 401.29517, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 401.0112 - MinusLogProbMetric: 401.0112 - val_loss: 401.2952 - val_MinusLogProbMetric: 401.2952 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 48/1000
2023-09-10 13:51:49.849 
Epoch 48/1000 
	 loss: 401.2368, MinusLogProbMetric: 401.2368, val_loss: 402.6009, val_MinusLogProbMetric: 402.6009

Epoch 48: val_loss did not improve from 401.29517
196/196 - 9s - loss: 401.2368 - MinusLogProbMetric: 401.2368 - val_loss: 402.6009 - val_MinusLogProbMetric: 402.6009 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 49/1000
2023-09-10 13:51:58.233 
Epoch 49/1000 
	 loss: 401.2440, MinusLogProbMetric: 401.2440, val_loss: 401.7002, val_MinusLogProbMetric: 401.7002

Epoch 49: val_loss did not improve from 401.29517
196/196 - 8s - loss: 401.2440 - MinusLogProbMetric: 401.2440 - val_loss: 401.7002 - val_MinusLogProbMetric: 401.7002 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 50/1000
2023-09-10 13:52:09.086 
Epoch 50/1000 
	 loss: 400.6841, MinusLogProbMetric: 400.6841, val_loss: 402.4706, val_MinusLogProbMetric: 402.4706

Epoch 50: val_loss did not improve from 401.29517
196/196 - 11s - loss: 400.6841 - MinusLogProbMetric: 400.6841 - val_loss: 402.4706 - val_MinusLogProbMetric: 402.4706 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 51/1000
2023-09-10 13:52:17.919 
Epoch 51/1000 
	 loss: 2488.1587, MinusLogProbMetric: 2488.1587, val_loss: 1017.0223, val_MinusLogProbMetric: 1017.0223

Epoch 51: val_loss did not improve from 401.29517
196/196 - 9s - loss: 2488.1587 - MinusLogProbMetric: 2488.1587 - val_loss: 1017.0223 - val_MinusLogProbMetric: 1017.0223 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 52/1000
2023-09-10 13:52:28.581 
Epoch 52/1000 
	 loss: 558.8669, MinusLogProbMetric: 558.8669, val_loss: 462.8228, val_MinusLogProbMetric: 462.8228

Epoch 52: val_loss did not improve from 401.29517
196/196 - 11s - loss: 558.8669 - MinusLogProbMetric: 558.8669 - val_loss: 462.8228 - val_MinusLogProbMetric: 462.8228 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 53/1000
2023-09-10 13:52:39.527 
Epoch 53/1000 
	 loss: 452.0448, MinusLogProbMetric: 452.0448, val_loss: 447.3582, val_MinusLogProbMetric: 447.3582

Epoch 53: val_loss did not improve from 401.29517
196/196 - 11s - loss: 452.0448 - MinusLogProbMetric: 452.0448 - val_loss: 447.3582 - val_MinusLogProbMetric: 447.3582 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 54/1000
2023-09-10 13:52:51.159 
Epoch 54/1000 
	 loss: 441.5797, MinusLogProbMetric: 441.5797, val_loss: 439.7427, val_MinusLogProbMetric: 439.7427

Epoch 54: val_loss did not improve from 401.29517
196/196 - 12s - loss: 441.5797 - MinusLogProbMetric: 441.5797 - val_loss: 439.7427 - val_MinusLogProbMetric: 439.7427 - lr: 3.3333e-04 - 12s/epoch - 59ms/step
Epoch 55/1000
2023-09-10 13:53:00.803 
Epoch 55/1000 
	 loss: 435.8714, MinusLogProbMetric: 435.8714, val_loss: 434.5662, val_MinusLogProbMetric: 434.5662

Epoch 55: val_loss did not improve from 401.29517
196/196 - 10s - loss: 435.8714 - MinusLogProbMetric: 435.8714 - val_loss: 434.5662 - val_MinusLogProbMetric: 434.5662 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 56/1000
2023-09-10 13:53:11.673 
Epoch 56/1000 
	 loss: 431.7158, MinusLogProbMetric: 431.7158, val_loss: 430.9284, val_MinusLogProbMetric: 430.9284

Epoch 56: val_loss did not improve from 401.29517
196/196 - 11s - loss: 431.7158 - MinusLogProbMetric: 431.7158 - val_loss: 430.9284 - val_MinusLogProbMetric: 430.9284 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 57/1000
2023-09-10 13:53:21.998 
Epoch 57/1000 
	 loss: 428.4678, MinusLogProbMetric: 428.4678, val_loss: 428.7619, val_MinusLogProbMetric: 428.7619

Epoch 57: val_loss did not improve from 401.29517
196/196 - 10s - loss: 428.4678 - MinusLogProbMetric: 428.4678 - val_loss: 428.7619 - val_MinusLogProbMetric: 428.7619 - lr: 3.3333e-04 - 10s/epoch - 53ms/step
Epoch 58/1000
2023-09-10 13:53:32.939 
Epoch 58/1000 
	 loss: 426.1660, MinusLogProbMetric: 426.1660, val_loss: 426.6390, val_MinusLogProbMetric: 426.6390

Epoch 58: val_loss did not improve from 401.29517
196/196 - 11s - loss: 426.1660 - MinusLogProbMetric: 426.1660 - val_loss: 426.6390 - val_MinusLogProbMetric: 426.6390 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 59/1000
2023-09-10 13:53:42.066 
Epoch 59/1000 
	 loss: 423.9225, MinusLogProbMetric: 423.9225, val_loss: 424.0035, val_MinusLogProbMetric: 424.0035

Epoch 59: val_loss did not improve from 401.29517
196/196 - 9s - loss: 423.9225 - MinusLogProbMetric: 423.9225 - val_loss: 424.0035 - val_MinusLogProbMetric: 424.0035 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 60/1000
2023-09-10 13:53:50.782 
Epoch 60/1000 
	 loss: 422.0350, MinusLogProbMetric: 422.0350, val_loss: 422.0629, val_MinusLogProbMetric: 422.0629

Epoch 60: val_loss did not improve from 401.29517
196/196 - 9s - loss: 422.0350 - MinusLogProbMetric: 422.0350 - val_loss: 422.0629 - val_MinusLogProbMetric: 422.0629 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 61/1000
2023-09-10 13:54:01.705 
Epoch 61/1000 
	 loss: 420.5665, MinusLogProbMetric: 420.5665, val_loss: 420.3171, val_MinusLogProbMetric: 420.3171

Epoch 61: val_loss did not improve from 401.29517
196/196 - 11s - loss: 420.5665 - MinusLogProbMetric: 420.5665 - val_loss: 420.3171 - val_MinusLogProbMetric: 420.3171 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 62/1000
2023-09-10 13:54:10.621 
Epoch 62/1000 
	 loss: 419.3820, MinusLogProbMetric: 419.3820, val_loss: 419.1385, val_MinusLogProbMetric: 419.1385

Epoch 62: val_loss did not improve from 401.29517
196/196 - 9s - loss: 419.3820 - MinusLogProbMetric: 419.3820 - val_loss: 419.1385 - val_MinusLogProbMetric: 419.1385 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 63/1000
2023-09-10 13:54:19.690 
Epoch 63/1000 
	 loss: 417.9515, MinusLogProbMetric: 417.9515, val_loss: 418.9393, val_MinusLogProbMetric: 418.9393

Epoch 63: val_loss did not improve from 401.29517
196/196 - 9s - loss: 417.9515 - MinusLogProbMetric: 417.9515 - val_loss: 418.9393 - val_MinusLogProbMetric: 418.9393 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 64/1000
2023-09-10 13:54:30.845 
Epoch 64/1000 
	 loss: 416.7881, MinusLogProbMetric: 416.7881, val_loss: 419.6425, val_MinusLogProbMetric: 419.6425

Epoch 64: val_loss did not improve from 401.29517
196/196 - 11s - loss: 416.7881 - MinusLogProbMetric: 416.7881 - val_loss: 419.6425 - val_MinusLogProbMetric: 419.6425 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 65/1000
2023-09-10 13:54:40.122 
Epoch 65/1000 
	 loss: 416.1137, MinusLogProbMetric: 416.1137, val_loss: 417.3093, val_MinusLogProbMetric: 417.3093

Epoch 65: val_loss did not improve from 401.29517
196/196 - 9s - loss: 416.1137 - MinusLogProbMetric: 416.1137 - val_loss: 417.3093 - val_MinusLogProbMetric: 417.3093 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 66/1000
2023-09-10 13:54:49.816 
Epoch 66/1000 
	 loss: 415.1013, MinusLogProbMetric: 415.1013, val_loss: 415.9014, val_MinusLogProbMetric: 415.9014

Epoch 66: val_loss did not improve from 401.29517
196/196 - 10s - loss: 415.1013 - MinusLogProbMetric: 415.1013 - val_loss: 415.9014 - val_MinusLogProbMetric: 415.9014 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 67/1000
2023-09-10 13:54:59.404 
Epoch 67/1000 
	 loss: 414.6698, MinusLogProbMetric: 414.6698, val_loss: 415.0665, val_MinusLogProbMetric: 415.0665

Epoch 67: val_loss did not improve from 401.29517
196/196 - 10s - loss: 414.6698 - MinusLogProbMetric: 414.6698 - val_loss: 415.0665 - val_MinusLogProbMetric: 415.0665 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 68/1000
2023-09-10 13:55:08.968 
Epoch 68/1000 
	 loss: 413.7584, MinusLogProbMetric: 413.7584, val_loss: 415.1995, val_MinusLogProbMetric: 415.1995

Epoch 68: val_loss did not improve from 401.29517
196/196 - 10s - loss: 413.7584 - MinusLogProbMetric: 413.7584 - val_loss: 415.1995 - val_MinusLogProbMetric: 415.1995 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 69/1000
2023-09-10 13:55:17.741 
Epoch 69/1000 
	 loss: 413.2177, MinusLogProbMetric: 413.2177, val_loss: 414.2390, val_MinusLogProbMetric: 414.2390

Epoch 69: val_loss did not improve from 401.29517
196/196 - 9s - loss: 413.2177 - MinusLogProbMetric: 413.2177 - val_loss: 414.2390 - val_MinusLogProbMetric: 414.2390 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 70/1000
2023-09-10 13:55:27.034 
Epoch 70/1000 
	 loss: 412.5457, MinusLogProbMetric: 412.5457, val_loss: 413.1044, val_MinusLogProbMetric: 413.1044

Epoch 70: val_loss did not improve from 401.29517
196/196 - 9s - loss: 412.5457 - MinusLogProbMetric: 412.5457 - val_loss: 413.1044 - val_MinusLogProbMetric: 413.1044 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 71/1000
2023-09-10 13:55:36.867 
Epoch 71/1000 
	 loss: 411.9827, MinusLogProbMetric: 411.9827, val_loss: 412.7077, val_MinusLogProbMetric: 412.7077

Epoch 71: val_loss did not improve from 401.29517
196/196 - 10s - loss: 411.9827 - MinusLogProbMetric: 411.9827 - val_loss: 412.7077 - val_MinusLogProbMetric: 412.7077 - lr: 3.3333e-04 - 10s/epoch - 50ms/step
Epoch 72/1000
2023-09-10 13:55:45.528 
Epoch 72/1000 
	 loss: 411.6151, MinusLogProbMetric: 411.6151, val_loss: 412.1610, val_MinusLogProbMetric: 412.1610

Epoch 72: val_loss did not improve from 401.29517
196/196 - 9s - loss: 411.6151 - MinusLogProbMetric: 411.6151 - val_loss: 412.1610 - val_MinusLogProbMetric: 412.1610 - lr: 3.3333e-04 - 9s/epoch - 44ms/step
Epoch 73/1000
2023-09-10 13:55:55.216 
Epoch 73/1000 
	 loss: 411.1024, MinusLogProbMetric: 411.1024, val_loss: 412.0591, val_MinusLogProbMetric: 412.0591

Epoch 73: val_loss did not improve from 401.29517
196/196 - 10s - loss: 411.1024 - MinusLogProbMetric: 411.1024 - val_loss: 412.0591 - val_MinusLogProbMetric: 412.0591 - lr: 3.3333e-04 - 10s/epoch - 49ms/step
Epoch 74/1000
2023-09-10 13:56:03.530 
Epoch 74/1000 
	 loss: 410.5466, MinusLogProbMetric: 410.5466, val_loss: 411.4692, val_MinusLogProbMetric: 411.4692

Epoch 74: val_loss did not improve from 401.29517
196/196 - 8s - loss: 410.5466 - MinusLogProbMetric: 410.5466 - val_loss: 411.4692 - val_MinusLogProbMetric: 411.4692 - lr: 3.3333e-04 - 8s/epoch - 42ms/step
Epoch 75/1000
2023-09-10 13:56:12.227 
Epoch 75/1000 
	 loss: 410.0424, MinusLogProbMetric: 410.0424, val_loss: 411.5330, val_MinusLogProbMetric: 411.5330

Epoch 75: val_loss did not improve from 401.29517
196/196 - 9s - loss: 410.0424 - MinusLogProbMetric: 410.0424 - val_loss: 411.5330 - val_MinusLogProbMetric: 411.5330 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 76/1000
2023-09-10 13:56:24.292 
Epoch 76/1000 
	 loss: 409.7929, MinusLogProbMetric: 409.7929, val_loss: 410.2751, val_MinusLogProbMetric: 410.2751

Epoch 76: val_loss did not improve from 401.29517
196/196 - 12s - loss: 409.7929 - MinusLogProbMetric: 409.7929 - val_loss: 410.2751 - val_MinusLogProbMetric: 410.2751 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 77/1000
2023-09-10 13:56:33.684 
Epoch 77/1000 
	 loss: 409.3620, MinusLogProbMetric: 409.3620, val_loss: 410.7561, val_MinusLogProbMetric: 410.7561

Epoch 77: val_loss did not improve from 401.29517
196/196 - 9s - loss: 409.3620 - MinusLogProbMetric: 409.3620 - val_loss: 410.7561 - val_MinusLogProbMetric: 410.7561 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 78/1000
2023-09-10 13:56:47.412 
Epoch 78/1000 
	 loss: 409.0738, MinusLogProbMetric: 409.0738, val_loss: 411.1259, val_MinusLogProbMetric: 411.1259

Epoch 78: val_loss did not improve from 401.29517
196/196 - 14s - loss: 409.0738 - MinusLogProbMetric: 409.0738 - val_loss: 411.1259 - val_MinusLogProbMetric: 411.1259 - lr: 3.3333e-04 - 14s/epoch - 70ms/step
Epoch 79/1000
2023-09-10 13:56:56.178 
Epoch 79/1000 
	 loss: 408.8639, MinusLogProbMetric: 408.8639, val_loss: 410.7659, val_MinusLogProbMetric: 410.7659

Epoch 79: val_loss did not improve from 401.29517
196/196 - 9s - loss: 408.8639 - MinusLogProbMetric: 408.8639 - val_loss: 410.7659 - val_MinusLogProbMetric: 410.7659 - lr: 3.3333e-04 - 9s/epoch - 45ms/step
Epoch 80/1000
2023-09-10 13:57:06.781 
Epoch 80/1000 
	 loss: 408.3245, MinusLogProbMetric: 408.3245, val_loss: 409.8752, val_MinusLogProbMetric: 409.8752

Epoch 80: val_loss did not improve from 401.29517
196/196 - 11s - loss: 408.3245 - MinusLogProbMetric: 408.3245 - val_loss: 409.8752 - val_MinusLogProbMetric: 409.8752 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 81/1000
2023-09-10 13:57:16.208 
Epoch 81/1000 
	 loss: 408.1456, MinusLogProbMetric: 408.1456, val_loss: 409.9490, val_MinusLogProbMetric: 409.9490

Epoch 81: val_loss did not improve from 401.29517
196/196 - 9s - loss: 408.1456 - MinusLogProbMetric: 408.1456 - val_loss: 409.9490 - val_MinusLogProbMetric: 409.9490 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 82/1000
2023-09-10 13:57:27.239 
Epoch 82/1000 
	 loss: 407.7798, MinusLogProbMetric: 407.7798, val_loss: 408.8799, val_MinusLogProbMetric: 408.8799

Epoch 82: val_loss did not improve from 401.29517
196/196 - 11s - loss: 407.7798 - MinusLogProbMetric: 407.7798 - val_loss: 408.8799 - val_MinusLogProbMetric: 408.8799 - lr: 3.3333e-04 - 11s/epoch - 56ms/step
Epoch 83/1000
2023-09-10 13:57:37.373 
Epoch 83/1000 
	 loss: 407.5690, MinusLogProbMetric: 407.5690, val_loss: 408.9371, val_MinusLogProbMetric: 408.9371

Epoch 83: val_loss did not improve from 401.29517
196/196 - 10s - loss: 407.5690 - MinusLogProbMetric: 407.5690 - val_loss: 408.9371 - val_MinusLogProbMetric: 408.9371 - lr: 3.3333e-04 - 10s/epoch - 52ms/step
Epoch 84/1000
2023-09-10 13:57:45.747 
Epoch 84/1000 
	 loss: 407.6207, MinusLogProbMetric: 407.6207, val_loss: 410.1632, val_MinusLogProbMetric: 410.1632

Epoch 84: val_loss did not improve from 401.29517
196/196 - 8s - loss: 407.6207 - MinusLogProbMetric: 407.6207 - val_loss: 410.1632 - val_MinusLogProbMetric: 410.1632 - lr: 3.3333e-04 - 8s/epoch - 43ms/step
Epoch 85/1000
2023-09-10 13:57:56.249 
Epoch 85/1000 
	 loss: 407.2205, MinusLogProbMetric: 407.2205, val_loss: 408.3746, val_MinusLogProbMetric: 408.3746

Epoch 85: val_loss did not improve from 401.29517
196/196 - 10s - loss: 407.2205 - MinusLogProbMetric: 407.2205 - val_loss: 408.3746 - val_MinusLogProbMetric: 408.3746 - lr: 3.3333e-04 - 10s/epoch - 54ms/step
Epoch 86/1000
2023-09-10 13:58:05.683 
Epoch 86/1000 
	 loss: 406.7277, MinusLogProbMetric: 406.7277, val_loss: 407.1660, val_MinusLogProbMetric: 407.1660

Epoch 86: val_loss did not improve from 401.29517
196/196 - 9s - loss: 406.7277 - MinusLogProbMetric: 406.7277 - val_loss: 407.1660 - val_MinusLogProbMetric: 407.1660 - lr: 3.3333e-04 - 9s/epoch - 48ms/step
Epoch 87/1000
2023-09-10 13:58:16.545 
Epoch 87/1000 
	 loss: 406.5404, MinusLogProbMetric: 406.5404, val_loss: 408.5441, val_MinusLogProbMetric: 408.5441

Epoch 87: val_loss did not improve from 401.29517
196/196 - 11s - loss: 406.5404 - MinusLogProbMetric: 406.5404 - val_loss: 408.5441 - val_MinusLogProbMetric: 408.5441 - lr: 3.3333e-04 - 11s/epoch - 55ms/step
Epoch 88/1000
2023-09-10 13:58:27.188 
Epoch 88/1000 
	 loss: 406.3585, MinusLogProbMetric: 406.3585, val_loss: 407.8429, val_MinusLogProbMetric: 407.8429

Epoch 88: val_loss did not improve from 401.29517
196/196 - 11s - loss: 406.3585 - MinusLogProbMetric: 406.3585 - val_loss: 407.8429 - val_MinusLogProbMetric: 407.8429 - lr: 3.3333e-04 - 11s/epoch - 54ms/step
Epoch 89/1000
2023-09-10 13:58:38.292 
Epoch 89/1000 
	 loss: 406.1666, MinusLogProbMetric: 406.1666, val_loss: 406.2661, val_MinusLogProbMetric: 406.2661

Epoch 89: val_loss did not improve from 401.29517
196/196 - 11s - loss: 406.1666 - MinusLogProbMetric: 406.1666 - val_loss: 406.2661 - val_MinusLogProbMetric: 406.2661 - lr: 3.3333e-04 - 11s/epoch - 57ms/step
Epoch 90/1000
2023-09-10 13:58:48.290 
Epoch 90/1000 
	 loss: 405.9892, MinusLogProbMetric: 405.9892, val_loss: 408.6712, val_MinusLogProbMetric: 408.6712

Epoch 90: val_loss did not improve from 401.29517
196/196 - 10s - loss: 405.9892 - MinusLogProbMetric: 405.9892 - val_loss: 408.6712 - val_MinusLogProbMetric: 408.6712 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 91/1000
2023-09-10 13:58:58.267 
Epoch 91/1000 
	 loss: 405.7114, MinusLogProbMetric: 405.7114, val_loss: 406.7141, val_MinusLogProbMetric: 406.7141

Epoch 91: val_loss did not improve from 401.29517
196/196 - 10s - loss: 405.7114 - MinusLogProbMetric: 405.7114 - val_loss: 406.7141 - val_MinusLogProbMetric: 406.7141 - lr: 3.3333e-04 - 10s/epoch - 51ms/step
Epoch 92/1000
2023-09-10 13:59:07.564 
Epoch 92/1000 
	 loss: 405.5558, MinusLogProbMetric: 405.5558, val_loss: 406.8345, val_MinusLogProbMetric: 406.8345

Epoch 92: val_loss did not improve from 401.29517
196/196 - 9s - loss: 405.5558 - MinusLogProbMetric: 405.5558 - val_loss: 406.8345 - val_MinusLogProbMetric: 406.8345 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 93/1000
2023-09-10 13:59:16.628 
Epoch 93/1000 
	 loss: 405.2032, MinusLogProbMetric: 405.2032, val_loss: 405.9618, val_MinusLogProbMetric: 405.9618

Epoch 93: val_loss did not improve from 401.29517
196/196 - 9s - loss: 405.2032 - MinusLogProbMetric: 405.2032 - val_loss: 405.9618 - val_MinusLogProbMetric: 405.9618 - lr: 3.3333e-04 - 9s/epoch - 46ms/step
Epoch 94/1000
2023-09-10 13:59:28.608 
Epoch 94/1000 
	 loss: 405.0448, MinusLogProbMetric: 405.0448, val_loss: 405.9842, val_MinusLogProbMetric: 405.9842

Epoch 94: val_loss did not improve from 401.29517
196/196 - 12s - loss: 405.0448 - MinusLogProbMetric: 405.0448 - val_loss: 405.9842 - val_MinusLogProbMetric: 405.9842 - lr: 3.3333e-04 - 12s/epoch - 61ms/step
Epoch 95/1000
2023-09-10 13:59:37.934 
Epoch 95/1000 
	 loss: 404.9834, MinusLogProbMetric: 404.9834, val_loss: 409.7199, val_MinusLogProbMetric: 409.7199

Epoch 95: val_loss did not improve from 401.29517
196/196 - 9s - loss: 404.9834 - MinusLogProbMetric: 404.9834 - val_loss: 409.7199 - val_MinusLogProbMetric: 409.7199 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 96/1000
2023-09-10 13:59:49.289 
Epoch 96/1000 
	 loss: 404.8239, MinusLogProbMetric: 404.8239, val_loss: 405.9755, val_MinusLogProbMetric: 405.9755

Epoch 96: val_loss did not improve from 401.29517
196/196 - 11s - loss: 404.8239 - MinusLogProbMetric: 404.8239 - val_loss: 405.9755 - val_MinusLogProbMetric: 405.9755 - lr: 3.3333e-04 - 11s/epoch - 58ms/step
Epoch 97/1000
2023-09-10 13:59:58.564 
Epoch 97/1000 
	 loss: 404.8426, MinusLogProbMetric: 404.8426, val_loss: 405.0829, val_MinusLogProbMetric: 405.0829

Epoch 97: val_loss did not improve from 401.29517
196/196 - 9s - loss: 404.8426 - MinusLogProbMetric: 404.8426 - val_loss: 405.0829 - val_MinusLogProbMetric: 405.0829 - lr: 3.3333e-04 - 9s/epoch - 47ms/step
Epoch 98/1000
2023-09-10 14:00:07.664 
Epoch 98/1000 
	 loss: 402.6469, MinusLogProbMetric: 402.6469, val_loss: 403.6472, val_MinusLogProbMetric: 403.6472

Epoch 98: val_loss did not improve from 401.29517
196/196 - 9s - loss: 402.6469 - MinusLogProbMetric: 402.6469 - val_loss: 403.6472 - val_MinusLogProbMetric: 403.6472 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 99/1000
2023-09-10 14:00:18.585 
Epoch 99/1000 
	 loss: 402.5676, MinusLogProbMetric: 402.5676, val_loss: 403.6443, val_MinusLogProbMetric: 403.6443

Epoch 99: val_loss did not improve from 401.29517
196/196 - 11s - loss: 402.5676 - MinusLogProbMetric: 402.5676 - val_loss: 403.6443 - val_MinusLogProbMetric: 403.6443 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 100/1000
2023-09-10 14:00:28.750 
Epoch 100/1000 
	 loss: 402.5497, MinusLogProbMetric: 402.5497, val_loss: 403.6531, val_MinusLogProbMetric: 403.6531

Epoch 100: val_loss did not improve from 401.29517
196/196 - 10s - loss: 402.5497 - MinusLogProbMetric: 402.5497 - val_loss: 403.6531 - val_MinusLogProbMetric: 403.6531 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 101/1000
2023-09-10 14:00:40.668 
Epoch 101/1000 
	 loss: 402.4781, MinusLogProbMetric: 402.4781, val_loss: 403.3658, val_MinusLogProbMetric: 403.3658

Epoch 101: val_loss did not improve from 401.29517
196/196 - 12s - loss: 402.4781 - MinusLogProbMetric: 402.4781 - val_loss: 403.3658 - val_MinusLogProbMetric: 403.3658 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 102/1000
2023-09-10 14:00:49.888 
Epoch 102/1000 
	 loss: 402.3101, MinusLogProbMetric: 402.3101, val_loss: 403.3901, val_MinusLogProbMetric: 403.3901

Epoch 102: val_loss did not improve from 401.29517
196/196 - 9s - loss: 402.3101 - MinusLogProbMetric: 402.3101 - val_loss: 403.3901 - val_MinusLogProbMetric: 403.3901 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 103/1000
2023-09-10 14:01:00.410 
Epoch 103/1000 
	 loss: 402.3150, MinusLogProbMetric: 402.3150, val_loss: 403.4485, val_MinusLogProbMetric: 403.4485

Epoch 103: val_loss did not improve from 401.29517
196/196 - 11s - loss: 402.3150 - MinusLogProbMetric: 402.3150 - val_loss: 403.4485 - val_MinusLogProbMetric: 403.4485 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 104/1000
2023-09-10 14:01:11.017 
Epoch 104/1000 
	 loss: 402.2325, MinusLogProbMetric: 402.2325, val_loss: 403.1056, val_MinusLogProbMetric: 403.1056

Epoch 104: val_loss did not improve from 401.29517
196/196 - 11s - loss: 402.2325 - MinusLogProbMetric: 402.2325 - val_loss: 403.1056 - val_MinusLogProbMetric: 403.1056 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 105/1000
2023-09-10 14:01:19.770 
Epoch 105/1000 
	 loss: 402.0896, MinusLogProbMetric: 402.0896, val_loss: 403.7527, val_MinusLogProbMetric: 403.7527

Epoch 105: val_loss did not improve from 401.29517
196/196 - 9s - loss: 402.0896 - MinusLogProbMetric: 402.0896 - val_loss: 403.7527 - val_MinusLogProbMetric: 403.7527 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 106/1000
2023-09-10 14:01:31.061 
Epoch 106/1000 
	 loss: 401.9870, MinusLogProbMetric: 401.9870, val_loss: 403.0945, val_MinusLogProbMetric: 403.0945

Epoch 106: val_loss did not improve from 401.29517
196/196 - 11s - loss: 401.9870 - MinusLogProbMetric: 401.9870 - val_loss: 403.0945 - val_MinusLogProbMetric: 403.0945 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 107/1000
2023-09-10 14:01:40.519 
Epoch 107/1000 
	 loss: 402.0174, MinusLogProbMetric: 402.0174, val_loss: 402.8714, val_MinusLogProbMetric: 402.8714

Epoch 107: val_loss did not improve from 401.29517
196/196 - 9s - loss: 402.0174 - MinusLogProbMetric: 402.0174 - val_loss: 402.8714 - val_MinusLogProbMetric: 402.8714 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 108/1000
2023-09-10 14:01:51.924 
Epoch 108/1000 
	 loss: 401.8547, MinusLogProbMetric: 401.8547, val_loss: 402.5910, val_MinusLogProbMetric: 402.5910

Epoch 108: val_loss did not improve from 401.29517
196/196 - 11s - loss: 401.8547 - MinusLogProbMetric: 401.8547 - val_loss: 402.5910 - val_MinusLogProbMetric: 402.5910 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 109/1000
2023-09-10 14:01:59.545 
Epoch 109/1000 
	 loss: 401.8222, MinusLogProbMetric: 401.8222, val_loss: 402.7126, val_MinusLogProbMetric: 402.7126

Epoch 109: val_loss did not improve from 401.29517
196/196 - 8s - loss: 401.8222 - MinusLogProbMetric: 401.8222 - val_loss: 402.7126 - val_MinusLogProbMetric: 402.7126 - lr: 1.6667e-04 - 8s/epoch - 39ms/step
Epoch 110/1000
2023-09-10 14:02:08.617 
Epoch 110/1000 
	 loss: 401.6744, MinusLogProbMetric: 401.6744, val_loss: 403.0624, val_MinusLogProbMetric: 403.0624

Epoch 110: val_loss did not improve from 401.29517
196/196 - 9s - loss: 401.6744 - MinusLogProbMetric: 401.6744 - val_loss: 403.0624 - val_MinusLogProbMetric: 403.0624 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 111/1000
2023-09-10 14:02:18.677 
Epoch 111/1000 
	 loss: 401.6860, MinusLogProbMetric: 401.6860, val_loss: 402.8066, val_MinusLogProbMetric: 402.8066

Epoch 111: val_loss did not improve from 401.29517
196/196 - 10s - loss: 401.6860 - MinusLogProbMetric: 401.6860 - val_loss: 402.8066 - val_MinusLogProbMetric: 402.8066 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 112/1000
2023-09-10 14:02:28.745 
Epoch 112/1000 
	 loss: 401.5313, MinusLogProbMetric: 401.5313, val_loss: 402.3061, val_MinusLogProbMetric: 402.3061

Epoch 112: val_loss did not improve from 401.29517
196/196 - 10s - loss: 401.5313 - MinusLogProbMetric: 401.5313 - val_loss: 402.3061 - val_MinusLogProbMetric: 402.3061 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 113/1000
2023-09-10 14:02:41.725 
Epoch 113/1000 
	 loss: 401.5629, MinusLogProbMetric: 401.5629, val_loss: 402.6598, val_MinusLogProbMetric: 402.6598

Epoch 113: val_loss did not improve from 401.29517
196/196 - 13s - loss: 401.5629 - MinusLogProbMetric: 401.5629 - val_loss: 402.6598 - val_MinusLogProbMetric: 402.6598 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 114/1000
2023-09-10 14:02:50.752 
Epoch 114/1000 
	 loss: 401.4248, MinusLogProbMetric: 401.4248, val_loss: 402.5536, val_MinusLogProbMetric: 402.5536

Epoch 114: val_loss did not improve from 401.29517
196/196 - 9s - loss: 401.4248 - MinusLogProbMetric: 401.4248 - val_loss: 402.5536 - val_MinusLogProbMetric: 402.5536 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 115/1000
2023-09-10 14:02:59.641 
Epoch 115/1000 
	 loss: 401.4184, MinusLogProbMetric: 401.4184, val_loss: 402.2955, val_MinusLogProbMetric: 402.2955

Epoch 115: val_loss did not improve from 401.29517
196/196 - 9s - loss: 401.4184 - MinusLogProbMetric: 401.4184 - val_loss: 402.2955 - val_MinusLogProbMetric: 402.2955 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 116/1000
2023-09-10 14:03:09.697 
Epoch 116/1000 
	 loss: 401.3161, MinusLogProbMetric: 401.3161, val_loss: 402.9956, val_MinusLogProbMetric: 402.9956

Epoch 116: val_loss did not improve from 401.29517
196/196 - 10s - loss: 401.3161 - MinusLogProbMetric: 401.3161 - val_loss: 402.9956 - val_MinusLogProbMetric: 402.9956 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 117/1000
2023-09-10 14:03:18.642 
Epoch 117/1000 
	 loss: 401.2796, MinusLogProbMetric: 401.2796, val_loss: 402.2743, val_MinusLogProbMetric: 402.2743

Epoch 117: val_loss did not improve from 401.29517
196/196 - 9s - loss: 401.2796 - MinusLogProbMetric: 401.2796 - val_loss: 402.2743 - val_MinusLogProbMetric: 402.2743 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 118/1000
2023-09-10 14:03:28.998 
Epoch 118/1000 
	 loss: 401.0523, MinusLogProbMetric: 401.0523, val_loss: 402.2203, val_MinusLogProbMetric: 402.2203

Epoch 118: val_loss did not improve from 401.29517
196/196 - 10s - loss: 401.0523 - MinusLogProbMetric: 401.0523 - val_loss: 402.2203 - val_MinusLogProbMetric: 402.2203 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 119/1000
2023-09-10 14:03:38.129 
Epoch 119/1000 
	 loss: 401.2122, MinusLogProbMetric: 401.2122, val_loss: 402.4926, val_MinusLogProbMetric: 402.4926

Epoch 119: val_loss did not improve from 401.29517
196/196 - 9s - loss: 401.2122 - MinusLogProbMetric: 401.2122 - val_loss: 402.4926 - val_MinusLogProbMetric: 402.4926 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 120/1000
2023-09-10 14:03:48.848 
Epoch 120/1000 
	 loss: 401.0375, MinusLogProbMetric: 401.0375, val_loss: 402.0203, val_MinusLogProbMetric: 402.0203

Epoch 120: val_loss did not improve from 401.29517
196/196 - 11s - loss: 401.0375 - MinusLogProbMetric: 401.0375 - val_loss: 402.0203 - val_MinusLogProbMetric: 402.0203 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 121/1000
2023-09-10 14:04:00.681 
Epoch 121/1000 
	 loss: 400.9333, MinusLogProbMetric: 400.9333, val_loss: 402.0172, val_MinusLogProbMetric: 402.0172

Epoch 121: val_loss did not improve from 401.29517
196/196 - 12s - loss: 400.9333 - MinusLogProbMetric: 400.9333 - val_loss: 402.0172 - val_MinusLogProbMetric: 402.0172 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 122/1000
2023-09-10 14:04:10.705 
Epoch 122/1000 
	 loss: 400.8852, MinusLogProbMetric: 400.8852, val_loss: 402.0793, val_MinusLogProbMetric: 402.0793

Epoch 122: val_loss did not improve from 401.29517
196/196 - 10s - loss: 400.8852 - MinusLogProbMetric: 400.8852 - val_loss: 402.0793 - val_MinusLogProbMetric: 402.0793 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 123/1000
2023-09-10 14:04:21.527 
Epoch 123/1000 
	 loss: 400.7466, MinusLogProbMetric: 400.7466, val_loss: 401.7796, val_MinusLogProbMetric: 401.7796

Epoch 123: val_loss did not improve from 401.29517
196/196 - 11s - loss: 400.7466 - MinusLogProbMetric: 400.7466 - val_loss: 401.7796 - val_MinusLogProbMetric: 401.7796 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 124/1000
2023-09-10 14:04:31.948 
Epoch 124/1000 
	 loss: 400.7386, MinusLogProbMetric: 400.7386, val_loss: 402.0100, val_MinusLogProbMetric: 402.0100

Epoch 124: val_loss did not improve from 401.29517
196/196 - 10s - loss: 400.7386 - MinusLogProbMetric: 400.7386 - val_loss: 402.0100 - val_MinusLogProbMetric: 402.0100 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 125/1000
2023-09-10 14:04:42.010 
Epoch 125/1000 
	 loss: 400.7033, MinusLogProbMetric: 400.7033, val_loss: 401.8002, val_MinusLogProbMetric: 401.8002

Epoch 125: val_loss did not improve from 401.29517
196/196 - 10s - loss: 400.7033 - MinusLogProbMetric: 400.7033 - val_loss: 401.8002 - val_MinusLogProbMetric: 401.8002 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 126/1000
2023-09-10 14:04:50.868 
Epoch 126/1000 
	 loss: 400.6686, MinusLogProbMetric: 400.6686, val_loss: 401.7497, val_MinusLogProbMetric: 401.7497

Epoch 126: val_loss did not improve from 401.29517
196/196 - 9s - loss: 400.6686 - MinusLogProbMetric: 400.6686 - val_loss: 401.7497 - val_MinusLogProbMetric: 401.7497 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 127/1000
2023-09-10 14:05:01.802 
Epoch 127/1000 
	 loss: 400.5406, MinusLogProbMetric: 400.5406, val_loss: 401.3013, val_MinusLogProbMetric: 401.3013

Epoch 127: val_loss did not improve from 401.29517
196/196 - 11s - loss: 400.5406 - MinusLogProbMetric: 400.5406 - val_loss: 401.3013 - val_MinusLogProbMetric: 401.3013 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 128/1000
2023-09-10 14:05:11.161 
Epoch 128/1000 
	 loss: 400.5184, MinusLogProbMetric: 400.5184, val_loss: 401.5319, val_MinusLogProbMetric: 401.5319

Epoch 128: val_loss did not improve from 401.29517
196/196 - 9s - loss: 400.5184 - MinusLogProbMetric: 400.5184 - val_loss: 401.5319 - val_MinusLogProbMetric: 401.5319 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 129/1000
2023-09-10 14:05:22.337 
Epoch 129/1000 
	 loss: 400.6650, MinusLogProbMetric: 400.6650, val_loss: 401.3903, val_MinusLogProbMetric: 401.3903

Epoch 129: val_loss did not improve from 401.29517
196/196 - 11s - loss: 400.6650 - MinusLogProbMetric: 400.6650 - val_loss: 401.3903 - val_MinusLogProbMetric: 401.3903 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 130/1000
2023-09-10 14:05:33.543 
Epoch 130/1000 
	 loss: 400.3856, MinusLogProbMetric: 400.3856, val_loss: 401.3324, val_MinusLogProbMetric: 401.3324

Epoch 130: val_loss did not improve from 401.29517
196/196 - 11s - loss: 400.3856 - MinusLogProbMetric: 400.3856 - val_loss: 401.3324 - val_MinusLogProbMetric: 401.3324 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 131/1000
2023-09-10 14:05:43.460 
Epoch 131/1000 
	 loss: 400.2832, MinusLogProbMetric: 400.2832, val_loss: 401.3366, val_MinusLogProbMetric: 401.3366

Epoch 131: val_loss did not improve from 401.29517
196/196 - 10s - loss: 400.2832 - MinusLogProbMetric: 400.2832 - val_loss: 401.3366 - val_MinusLogProbMetric: 401.3366 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 132/1000
2023-09-10 14:05:54.986 
Epoch 132/1000 
	 loss: 400.1953, MinusLogProbMetric: 400.1953, val_loss: 401.1194, val_MinusLogProbMetric: 401.1194

Epoch 132: val_loss improved from 401.29517 to 401.11935, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 400.1953 - MinusLogProbMetric: 400.1953 - val_loss: 401.1194 - val_MinusLogProbMetric: 401.1194 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 133/1000
2023-09-10 14:06:05.117 
Epoch 133/1000 
	 loss: 400.1348, MinusLogProbMetric: 400.1348, val_loss: 401.1301, val_MinusLogProbMetric: 401.1301

Epoch 133: val_loss did not improve from 401.11935
196/196 - 10s - loss: 400.1348 - MinusLogProbMetric: 400.1348 - val_loss: 401.1301 - val_MinusLogProbMetric: 401.1301 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 134/1000
2023-09-10 14:06:15.427 
Epoch 134/1000 
	 loss: 400.0724, MinusLogProbMetric: 400.0724, val_loss: 400.7904, val_MinusLogProbMetric: 400.7904

Epoch 134: val_loss improved from 401.11935 to 400.79044, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 400.0724 - MinusLogProbMetric: 400.0724 - val_loss: 400.7904 - val_MinusLogProbMetric: 400.7904 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 135/1000
2023-09-10 14:06:25.553 
Epoch 135/1000 
	 loss: 400.1629, MinusLogProbMetric: 400.1629, val_loss: 404.8333, val_MinusLogProbMetric: 404.8333

Epoch 135: val_loss did not improve from 400.79044
196/196 - 10s - loss: 400.1629 - MinusLogProbMetric: 400.1629 - val_loss: 404.8333 - val_MinusLogProbMetric: 404.8333 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 136/1000
2023-09-10 14:06:34.755 
Epoch 136/1000 
	 loss: 400.0623, MinusLogProbMetric: 400.0623, val_loss: 400.7421, val_MinusLogProbMetric: 400.7421

Epoch 136: val_loss improved from 400.79044 to 400.74210, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 400.0623 - MinusLogProbMetric: 400.0623 - val_loss: 400.7421 - val_MinusLogProbMetric: 400.7421 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 137/1000
2023-09-10 14:06:45.820 
Epoch 137/1000 
	 loss: 399.9036, MinusLogProbMetric: 399.9036, val_loss: 401.7819, val_MinusLogProbMetric: 401.7819

Epoch 137: val_loss did not improve from 400.74210
196/196 - 11s - loss: 399.9036 - MinusLogProbMetric: 399.9036 - val_loss: 401.7819 - val_MinusLogProbMetric: 401.7819 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 138/1000
2023-09-10 14:06:55.006 
Epoch 138/1000 
	 loss: 399.8410, MinusLogProbMetric: 399.8410, val_loss: 401.1123, val_MinusLogProbMetric: 401.1123

Epoch 138: val_loss did not improve from 400.74210
196/196 - 9s - loss: 399.8410 - MinusLogProbMetric: 399.8410 - val_loss: 401.1123 - val_MinusLogProbMetric: 401.1123 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 139/1000
2023-09-10 14:07:06.816 
Epoch 139/1000 
	 loss: 399.9071, MinusLogProbMetric: 399.9071, val_loss: 401.5852, val_MinusLogProbMetric: 401.5852

Epoch 139: val_loss did not improve from 400.74210
196/196 - 12s - loss: 399.9071 - MinusLogProbMetric: 399.9071 - val_loss: 401.5852 - val_MinusLogProbMetric: 401.5852 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 140/1000
2023-09-10 14:07:16.344 
Epoch 140/1000 
	 loss: 399.6953, MinusLogProbMetric: 399.6953, val_loss: 400.9846, val_MinusLogProbMetric: 400.9846

Epoch 140: val_loss did not improve from 400.74210
196/196 - 10s - loss: 399.6953 - MinusLogProbMetric: 399.6953 - val_loss: 400.9846 - val_MinusLogProbMetric: 400.9846 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 141/1000
2023-09-10 14:07:26.173 
Epoch 141/1000 
	 loss: 399.9031, MinusLogProbMetric: 399.9031, val_loss: 400.3512, val_MinusLogProbMetric: 400.3512

Epoch 141: val_loss improved from 400.74210 to 400.35117, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 399.9031 - MinusLogProbMetric: 399.9031 - val_loss: 400.3512 - val_MinusLogProbMetric: 400.3512 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 142/1000
2023-09-10 14:07:37.073 
Epoch 142/1000 
	 loss: 399.6464, MinusLogProbMetric: 399.6464, val_loss: 401.7146, val_MinusLogProbMetric: 401.7146

Epoch 142: val_loss did not improve from 400.35117
196/196 - 10s - loss: 399.6464 - MinusLogProbMetric: 399.6464 - val_loss: 401.7146 - val_MinusLogProbMetric: 401.7146 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 143/1000
2023-09-10 14:07:46.486 
Epoch 143/1000 
	 loss: 399.6062, MinusLogProbMetric: 399.6062, val_loss: 400.7398, val_MinusLogProbMetric: 400.7398

Epoch 143: val_loss did not improve from 400.35117
196/196 - 9s - loss: 399.6062 - MinusLogProbMetric: 399.6062 - val_loss: 400.7398 - val_MinusLogProbMetric: 400.7398 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 144/1000
2023-09-10 14:07:55.929 
Epoch 144/1000 
	 loss: 399.5941, MinusLogProbMetric: 399.5941, val_loss: 400.6389, val_MinusLogProbMetric: 400.6389

Epoch 144: val_loss did not improve from 400.35117
196/196 - 9s - loss: 399.5941 - MinusLogProbMetric: 399.5941 - val_loss: 400.6389 - val_MinusLogProbMetric: 400.6389 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 145/1000
2023-09-10 14:08:05.826 
Epoch 145/1000 
	 loss: 399.7113, MinusLogProbMetric: 399.7113, val_loss: 400.4915, val_MinusLogProbMetric: 400.4915

Epoch 145: val_loss did not improve from 400.35117
196/196 - 10s - loss: 399.7113 - MinusLogProbMetric: 399.7113 - val_loss: 400.4915 - val_MinusLogProbMetric: 400.4915 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 146/1000
2023-09-10 14:08:14.731 
Epoch 146/1000 
	 loss: 399.4145, MinusLogProbMetric: 399.4145, val_loss: 400.5568, val_MinusLogProbMetric: 400.5568

Epoch 146: val_loss did not improve from 400.35117
196/196 - 9s - loss: 399.4145 - MinusLogProbMetric: 399.4145 - val_loss: 400.5568 - val_MinusLogProbMetric: 400.5568 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 147/1000
2023-09-10 14:08:25.346 
Epoch 147/1000 
	 loss: 399.3939, MinusLogProbMetric: 399.3939, val_loss: 400.7709, val_MinusLogProbMetric: 400.7709

Epoch 147: val_loss did not improve from 400.35117
196/196 - 11s - loss: 399.3939 - MinusLogProbMetric: 399.3939 - val_loss: 400.7709 - val_MinusLogProbMetric: 400.7709 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 148/1000
2023-09-10 14:08:34.069 
Epoch 148/1000 
	 loss: 399.2807, MinusLogProbMetric: 399.2807, val_loss: 401.3498, val_MinusLogProbMetric: 401.3498

Epoch 148: val_loss did not improve from 400.35117
196/196 - 9s - loss: 399.2807 - MinusLogProbMetric: 399.2807 - val_loss: 401.3498 - val_MinusLogProbMetric: 401.3498 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 149/1000
2023-09-10 14:08:43.688 
Epoch 149/1000 
	 loss: 399.2979, MinusLogProbMetric: 399.2979, val_loss: 400.5550, val_MinusLogProbMetric: 400.5550

Epoch 149: val_loss did not improve from 400.35117
196/196 - 10s - loss: 399.2979 - MinusLogProbMetric: 399.2979 - val_loss: 400.5550 - val_MinusLogProbMetric: 400.5550 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 150/1000
2023-09-10 14:08:54.120 
Epoch 150/1000 
	 loss: 399.2468, MinusLogProbMetric: 399.2468, val_loss: 401.3014, val_MinusLogProbMetric: 401.3014

Epoch 150: val_loss did not improve from 400.35117
196/196 - 10s - loss: 399.2468 - MinusLogProbMetric: 399.2468 - val_loss: 401.3014 - val_MinusLogProbMetric: 401.3014 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 151/1000
2023-09-10 14:09:03.230 
Epoch 151/1000 
	 loss: 399.2795, MinusLogProbMetric: 399.2795, val_loss: 401.1756, val_MinusLogProbMetric: 401.1756

Epoch 151: val_loss did not improve from 400.35117
196/196 - 9s - loss: 399.2795 - MinusLogProbMetric: 399.2795 - val_loss: 401.1756 - val_MinusLogProbMetric: 401.1756 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 152/1000
2023-09-10 14:09:14.032 
Epoch 152/1000 
	 loss: 399.2119, MinusLogProbMetric: 399.2119, val_loss: 400.0102, val_MinusLogProbMetric: 400.0102

Epoch 152: val_loss improved from 400.35117 to 400.01016, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 399.2119 - MinusLogProbMetric: 399.2119 - val_loss: 400.0102 - val_MinusLogProbMetric: 400.0102 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 153/1000
2023-09-10 14:09:23.758 
Epoch 153/1000 
	 loss: 399.0299, MinusLogProbMetric: 399.0299, val_loss: 400.7440, val_MinusLogProbMetric: 400.7440

Epoch 153: val_loss did not improve from 400.01016
196/196 - 9s - loss: 399.0299 - MinusLogProbMetric: 399.0299 - val_loss: 400.7440 - val_MinusLogProbMetric: 400.7440 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 154/1000
2023-09-10 14:09:32.918 
Epoch 154/1000 
	 loss: 399.1333, MinusLogProbMetric: 399.1333, val_loss: 400.5245, val_MinusLogProbMetric: 400.5245

Epoch 154: val_loss did not improve from 400.01016
196/196 - 9s - loss: 399.1333 - MinusLogProbMetric: 399.1333 - val_loss: 400.5245 - val_MinusLogProbMetric: 400.5245 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 155/1000
2023-09-10 14:09:43.332 
Epoch 155/1000 
	 loss: 398.9487, MinusLogProbMetric: 398.9487, val_loss: 401.6808, val_MinusLogProbMetric: 401.6808

Epoch 155: val_loss did not improve from 400.01016
196/196 - 10s - loss: 398.9487 - MinusLogProbMetric: 398.9487 - val_loss: 401.6808 - val_MinusLogProbMetric: 401.6808 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 156/1000
2023-09-10 14:09:52.252 
Epoch 156/1000 
	 loss: 399.0348, MinusLogProbMetric: 399.0348, val_loss: 399.8664, val_MinusLogProbMetric: 399.8664

Epoch 156: val_loss improved from 400.01016 to 399.86639, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 399.0348 - MinusLogProbMetric: 399.0348 - val_loss: 399.8664 - val_MinusLogProbMetric: 399.8664 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 157/1000
2023-09-10 14:10:03.371 
Epoch 157/1000 
	 loss: 398.8690, MinusLogProbMetric: 398.8690, val_loss: 399.8870, val_MinusLogProbMetric: 399.8870

Epoch 157: val_loss did not improve from 399.86639
196/196 - 11s - loss: 398.8690 - MinusLogProbMetric: 398.8690 - val_loss: 399.8870 - val_MinusLogProbMetric: 399.8870 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 158/1000
2023-09-10 14:10:13.010 
Epoch 158/1000 
	 loss: 398.8191, MinusLogProbMetric: 398.8191, val_loss: 399.5872, val_MinusLogProbMetric: 399.5872

Epoch 158: val_loss improved from 399.86639 to 399.58716, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 398.8191 - MinusLogProbMetric: 398.8191 - val_loss: 399.5872 - val_MinusLogProbMetric: 399.5872 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 159/1000
2023-09-10 14:10:22.133 
Epoch 159/1000 
	 loss: 399.0555, MinusLogProbMetric: 399.0555, val_loss: 400.1594, val_MinusLogProbMetric: 400.1594

Epoch 159: val_loss did not improve from 399.58716
196/196 - 9s - loss: 399.0555 - MinusLogProbMetric: 399.0555 - val_loss: 400.1594 - val_MinusLogProbMetric: 400.1594 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 160/1000
2023-09-10 14:10:33.905 
Epoch 160/1000 
	 loss: 398.6992, MinusLogProbMetric: 398.6992, val_loss: 399.3809, val_MinusLogProbMetric: 399.3809

Epoch 160: val_loss improved from 399.58716 to 399.38086, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 398.6992 - MinusLogProbMetric: 398.6992 - val_loss: 399.3809 - val_MinusLogProbMetric: 399.3809 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 161/1000
2023-09-10 14:10:43.134 
Epoch 161/1000 
	 loss: 398.6375, MinusLogProbMetric: 398.6375, val_loss: 400.0402, val_MinusLogProbMetric: 400.0402

Epoch 161: val_loss did not improve from 399.38086
196/196 - 9s - loss: 398.6375 - MinusLogProbMetric: 398.6375 - val_loss: 400.0402 - val_MinusLogProbMetric: 400.0402 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 162/1000
2023-09-10 14:10:53.888 
Epoch 162/1000 
	 loss: 398.6986, MinusLogProbMetric: 398.6986, val_loss: 399.6723, val_MinusLogProbMetric: 399.6723

Epoch 162: val_loss did not improve from 399.38086
196/196 - 11s - loss: 398.6986 - MinusLogProbMetric: 398.6986 - val_loss: 399.6723 - val_MinusLogProbMetric: 399.6723 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 163/1000
2023-09-10 14:11:03.513 
Epoch 163/1000 
	 loss: 398.4762, MinusLogProbMetric: 398.4762, val_loss: 399.5739, val_MinusLogProbMetric: 399.5739

Epoch 163: val_loss did not improve from 399.38086
196/196 - 10s - loss: 398.4762 - MinusLogProbMetric: 398.4762 - val_loss: 399.5739 - val_MinusLogProbMetric: 399.5739 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 164/1000
2023-09-10 14:11:13.314 
Epoch 164/1000 
	 loss: 398.6684, MinusLogProbMetric: 398.6684, val_loss: 399.6999, val_MinusLogProbMetric: 399.6999

Epoch 164: val_loss did not improve from 399.38086
196/196 - 10s - loss: 398.6684 - MinusLogProbMetric: 398.6684 - val_loss: 399.6999 - val_MinusLogProbMetric: 399.6999 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 165/1000
2023-09-10 14:11:24.405 
Epoch 165/1000 
	 loss: 398.4906, MinusLogProbMetric: 398.4906, val_loss: 407.8089, val_MinusLogProbMetric: 407.8089

Epoch 165: val_loss did not improve from 399.38086
196/196 - 11s - loss: 398.4906 - MinusLogProbMetric: 398.4906 - val_loss: 407.8089 - val_MinusLogProbMetric: 407.8089 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 166/1000
2023-09-10 14:11:34.882 
Epoch 166/1000 
	 loss: 398.5968, MinusLogProbMetric: 398.5968, val_loss: 399.9778, val_MinusLogProbMetric: 399.9778

Epoch 166: val_loss did not improve from 399.38086
196/196 - 10s - loss: 398.5968 - MinusLogProbMetric: 398.5968 - val_loss: 399.9778 - val_MinusLogProbMetric: 399.9778 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 167/1000
2023-09-10 14:11:45.828 
Epoch 167/1000 
	 loss: 398.5252, MinusLogProbMetric: 398.5252, val_loss: 400.0037, val_MinusLogProbMetric: 400.0037

Epoch 167: val_loss did not improve from 399.38086
196/196 - 11s - loss: 398.5252 - MinusLogProbMetric: 398.5252 - val_loss: 400.0037 - val_MinusLogProbMetric: 400.0037 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 168/1000
2023-09-10 14:11:55.862 
Epoch 168/1000 
	 loss: 398.3904, MinusLogProbMetric: 398.3904, val_loss: 399.8003, val_MinusLogProbMetric: 399.8003

Epoch 168: val_loss did not improve from 399.38086
196/196 - 10s - loss: 398.3904 - MinusLogProbMetric: 398.3904 - val_loss: 399.8003 - val_MinusLogProbMetric: 399.8003 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 169/1000
2023-09-10 14:12:05.246 
Epoch 169/1000 
	 loss: 398.3634, MinusLogProbMetric: 398.3634, val_loss: 400.4555, val_MinusLogProbMetric: 400.4555

Epoch 169: val_loss did not improve from 399.38086
196/196 - 9s - loss: 398.3634 - MinusLogProbMetric: 398.3634 - val_loss: 400.4555 - val_MinusLogProbMetric: 400.4555 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 170/1000
2023-09-10 14:12:15.908 
Epoch 170/1000 
	 loss: 398.4410, MinusLogProbMetric: 398.4410, val_loss: 399.7527, val_MinusLogProbMetric: 399.7527

Epoch 170: val_loss did not improve from 399.38086
196/196 - 11s - loss: 398.4410 - MinusLogProbMetric: 398.4410 - val_loss: 399.7527 - val_MinusLogProbMetric: 399.7527 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 171/1000
2023-09-10 14:12:26.209 
Epoch 171/1000 
	 loss: 398.2717, MinusLogProbMetric: 398.2717, val_loss: 399.0262, val_MinusLogProbMetric: 399.0262

Epoch 171: val_loss improved from 399.38086 to 399.02621, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 398.2717 - MinusLogProbMetric: 398.2717 - val_loss: 399.0262 - val_MinusLogProbMetric: 399.0262 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 172/1000
2023-09-10 14:12:36.884 
Epoch 172/1000 
	 loss: 398.3334, MinusLogProbMetric: 398.3334, val_loss: 399.6012, val_MinusLogProbMetric: 399.6012

Epoch 172: val_loss did not improve from 399.02621
196/196 - 10s - loss: 398.3334 - MinusLogProbMetric: 398.3334 - val_loss: 399.6012 - val_MinusLogProbMetric: 399.6012 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 173/1000
2023-09-10 14:12:46.901 
Epoch 173/1000 
	 loss: 398.2124, MinusLogProbMetric: 398.2124, val_loss: 399.1701, val_MinusLogProbMetric: 399.1701

Epoch 173: val_loss did not improve from 399.02621
196/196 - 10s - loss: 398.2124 - MinusLogProbMetric: 398.2124 - val_loss: 399.1701 - val_MinusLogProbMetric: 399.1701 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 174/1000
2023-09-10 14:12:58.029 
Epoch 174/1000 
	 loss: 398.2976, MinusLogProbMetric: 398.2976, val_loss: 399.2201, val_MinusLogProbMetric: 399.2201

Epoch 174: val_loss did not improve from 399.02621
196/196 - 11s - loss: 398.2976 - MinusLogProbMetric: 398.2976 - val_loss: 399.2201 - val_MinusLogProbMetric: 399.2201 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 175/1000
2023-09-10 14:13:08.650 
Epoch 175/1000 
	 loss: 397.9463, MinusLogProbMetric: 397.9463, val_loss: 398.8961, val_MinusLogProbMetric: 398.8961

Epoch 175: val_loss improved from 399.02621 to 398.89609, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 397.9463 - MinusLogProbMetric: 397.9463 - val_loss: 398.8961 - val_MinusLogProbMetric: 398.8961 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 176/1000
2023-09-10 14:13:19.479 
Epoch 176/1000 
	 loss: 398.2588, MinusLogProbMetric: 398.2588, val_loss: 398.9459, val_MinusLogProbMetric: 398.9459

Epoch 176: val_loss did not improve from 398.89609
196/196 - 10s - loss: 398.2588 - MinusLogProbMetric: 398.2588 - val_loss: 398.9459 - val_MinusLogProbMetric: 398.9459 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 177/1000
2023-09-10 14:13:29.847 
Epoch 177/1000 
	 loss: 397.9044, MinusLogProbMetric: 397.9044, val_loss: 400.2256, val_MinusLogProbMetric: 400.2256

Epoch 177: val_loss did not improve from 398.89609
196/196 - 10s - loss: 397.9044 - MinusLogProbMetric: 397.9044 - val_loss: 400.2256 - val_MinusLogProbMetric: 400.2256 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 178/1000
2023-09-10 14:13:38.793 
Epoch 178/1000 
	 loss: 398.1352, MinusLogProbMetric: 398.1352, val_loss: 400.1403, val_MinusLogProbMetric: 400.1403

Epoch 178: val_loss did not improve from 398.89609
196/196 - 9s - loss: 398.1352 - MinusLogProbMetric: 398.1352 - val_loss: 400.1403 - val_MinusLogProbMetric: 400.1403 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 179/1000
2023-09-10 14:13:49.363 
Epoch 179/1000 
	 loss: 398.0003, MinusLogProbMetric: 398.0003, val_loss: 399.5285, val_MinusLogProbMetric: 399.5285

Epoch 179: val_loss did not improve from 398.89609
196/196 - 11s - loss: 398.0003 - MinusLogProbMetric: 398.0003 - val_loss: 399.5285 - val_MinusLogProbMetric: 399.5285 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 180/1000
2023-09-10 14:13:58.083 
Epoch 180/1000 
	 loss: 397.9551, MinusLogProbMetric: 397.9551, val_loss: 400.8768, val_MinusLogProbMetric: 400.8768

Epoch 180: val_loss did not improve from 398.89609
196/196 - 9s - loss: 397.9551 - MinusLogProbMetric: 397.9551 - val_loss: 400.8768 - val_MinusLogProbMetric: 400.8768 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 181/1000
2023-09-10 14:14:06.796 
Epoch 181/1000 
	 loss: 397.8549, MinusLogProbMetric: 397.8549, val_loss: 399.2478, val_MinusLogProbMetric: 399.2478

Epoch 181: val_loss did not improve from 398.89609
196/196 - 9s - loss: 397.8549 - MinusLogProbMetric: 397.8549 - val_loss: 399.2478 - val_MinusLogProbMetric: 399.2478 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 182/1000
2023-09-10 14:14:17.929 
Epoch 182/1000 
	 loss: 397.8767, MinusLogProbMetric: 397.8767, val_loss: 400.2766, val_MinusLogProbMetric: 400.2766

Epoch 182: val_loss did not improve from 398.89609
196/196 - 11s - loss: 397.8767 - MinusLogProbMetric: 397.8767 - val_loss: 400.2766 - val_MinusLogProbMetric: 400.2766 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 183/1000
2023-09-10 14:14:26.713 
Epoch 183/1000 
	 loss: 398.0213, MinusLogProbMetric: 398.0213, val_loss: 398.8352, val_MinusLogProbMetric: 398.8352

Epoch 183: val_loss improved from 398.89609 to 398.83521, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 398.0213 - MinusLogProbMetric: 398.0213 - val_loss: 398.8352 - val_MinusLogProbMetric: 398.8352 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 184/1000
2023-09-10 14:14:38.013 
Epoch 184/1000 
	 loss: 397.6918, MinusLogProbMetric: 397.6918, val_loss: 398.6415, val_MinusLogProbMetric: 398.6415

Epoch 184: val_loss improved from 398.83521 to 398.64151, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 397.6918 - MinusLogProbMetric: 397.6918 - val_loss: 398.6415 - val_MinusLogProbMetric: 398.6415 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 185/1000
2023-09-10 14:14:47.495 
Epoch 185/1000 
	 loss: 397.8523, MinusLogProbMetric: 397.8523, val_loss: 399.1263, val_MinusLogProbMetric: 399.1263

Epoch 185: val_loss did not improve from 398.64151
196/196 - 9s - loss: 397.8523 - MinusLogProbMetric: 397.8523 - val_loss: 399.1263 - val_MinusLogProbMetric: 399.1263 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 186/1000
2023-09-10 14:14:57.681 
Epoch 186/1000 
	 loss: 397.8397, MinusLogProbMetric: 397.8397, val_loss: 399.3952, val_MinusLogProbMetric: 399.3952

Epoch 186: val_loss did not improve from 398.64151
196/196 - 10s - loss: 397.8397 - MinusLogProbMetric: 397.8397 - val_loss: 399.3952 - val_MinusLogProbMetric: 399.3952 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 187/1000
2023-09-10 14:15:09.084 
Epoch 187/1000 
	 loss: 397.4956, MinusLogProbMetric: 397.4956, val_loss: 398.7159, val_MinusLogProbMetric: 398.7159

Epoch 187: val_loss did not improve from 398.64151
196/196 - 11s - loss: 397.4956 - MinusLogProbMetric: 397.4956 - val_loss: 398.7159 - val_MinusLogProbMetric: 398.7159 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 188/1000
2023-09-10 14:15:18.117 
Epoch 188/1000 
	 loss: 397.7747, MinusLogProbMetric: 397.7747, val_loss: 398.4225, val_MinusLogProbMetric: 398.4225

Epoch 188: val_loss improved from 398.64151 to 398.42245, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 397.7747 - MinusLogProbMetric: 397.7747 - val_loss: 398.4225 - val_MinusLogProbMetric: 398.4225 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 189/1000
2023-09-10 14:15:29.167 
Epoch 189/1000 
	 loss: 397.5816, MinusLogProbMetric: 397.5816, val_loss: 398.5663, val_MinusLogProbMetric: 398.5663

Epoch 189: val_loss did not improve from 398.42245
196/196 - 11s - loss: 397.5816 - MinusLogProbMetric: 397.5816 - val_loss: 398.5663 - val_MinusLogProbMetric: 398.5663 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 190/1000
2023-09-10 14:15:38.117 
Epoch 190/1000 
	 loss: 397.5928, MinusLogProbMetric: 397.5928, val_loss: 399.2926, val_MinusLogProbMetric: 399.2926

Epoch 190: val_loss did not improve from 398.42245
196/196 - 9s - loss: 397.5928 - MinusLogProbMetric: 397.5928 - val_loss: 399.2926 - val_MinusLogProbMetric: 399.2926 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 191/1000
2023-09-10 14:15:48.962 
Epoch 191/1000 
	 loss: 397.4690, MinusLogProbMetric: 397.4690, val_loss: 398.3841, val_MinusLogProbMetric: 398.3841

Epoch 191: val_loss improved from 398.42245 to 398.38409, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 397.4690 - MinusLogProbMetric: 397.4690 - val_loss: 398.3841 - val_MinusLogProbMetric: 398.3841 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 192/1000
2023-09-10 14:15:58.824 
Epoch 192/1000 
	 loss: 397.4289, MinusLogProbMetric: 397.4289, val_loss: 398.4690, val_MinusLogProbMetric: 398.4690

Epoch 192: val_loss did not improve from 398.38409
196/196 - 10s - loss: 397.4289 - MinusLogProbMetric: 397.4289 - val_loss: 398.4690 - val_MinusLogProbMetric: 398.4690 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 193/1000
2023-09-10 14:16:09.127 
Epoch 193/1000 
	 loss: 397.5875, MinusLogProbMetric: 397.5875, val_loss: 398.4477, val_MinusLogProbMetric: 398.4477

Epoch 193: val_loss did not improve from 398.38409
196/196 - 10s - loss: 397.5875 - MinusLogProbMetric: 397.5875 - val_loss: 398.4477 - val_MinusLogProbMetric: 398.4477 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 194/1000
2023-09-10 14:16:18.167 
Epoch 194/1000 
	 loss: 397.3818, MinusLogProbMetric: 397.3818, val_loss: 399.4063, val_MinusLogProbMetric: 399.4063

Epoch 194: val_loss did not improve from 398.38409
196/196 - 9s - loss: 397.3818 - MinusLogProbMetric: 397.3818 - val_loss: 399.4063 - val_MinusLogProbMetric: 399.4063 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 195/1000
2023-09-10 14:16:27.590 
Epoch 195/1000 
	 loss: 397.3568, MinusLogProbMetric: 397.3568, val_loss: 399.9322, val_MinusLogProbMetric: 399.9322

Epoch 195: val_loss did not improve from 398.38409
196/196 - 9s - loss: 397.3568 - MinusLogProbMetric: 397.3568 - val_loss: 399.9322 - val_MinusLogProbMetric: 399.9322 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 196/1000
2023-09-10 14:16:38.677 
Epoch 196/1000 
	 loss: 397.5182, MinusLogProbMetric: 397.5182, val_loss: 398.0598, val_MinusLogProbMetric: 398.0598

Epoch 196: val_loss improved from 398.38409 to 398.05984, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 397.5182 - MinusLogProbMetric: 397.5182 - val_loss: 398.0598 - val_MinusLogProbMetric: 398.0598 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 197/1000
2023-09-10 14:16:48.871 
Epoch 197/1000 
	 loss: 397.5631, MinusLogProbMetric: 397.5631, val_loss: 398.3078, val_MinusLogProbMetric: 398.3078

Epoch 197: val_loss did not improve from 398.05984
196/196 - 10s - loss: 397.5631 - MinusLogProbMetric: 397.5631 - val_loss: 398.3078 - val_MinusLogProbMetric: 398.3078 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 198/1000
2023-09-10 14:16:58.163 
Epoch 198/1000 
	 loss: 397.2952, MinusLogProbMetric: 397.2952, val_loss: 398.6244, val_MinusLogProbMetric: 398.6244

Epoch 198: val_loss did not improve from 398.05984
196/196 - 9s - loss: 397.2952 - MinusLogProbMetric: 397.2952 - val_loss: 398.6244 - val_MinusLogProbMetric: 398.6244 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 199/1000
2023-09-10 14:17:08.731 
Epoch 199/1000 
	 loss: 397.3069, MinusLogProbMetric: 397.3069, val_loss: 399.1176, val_MinusLogProbMetric: 399.1176

Epoch 199: val_loss did not improve from 398.05984
196/196 - 11s - loss: 397.3069 - MinusLogProbMetric: 397.3069 - val_loss: 399.1176 - val_MinusLogProbMetric: 399.1176 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 200/1000
2023-09-10 14:17:18.984 
Epoch 200/1000 
	 loss: 397.2635, MinusLogProbMetric: 397.2635, val_loss: 398.6625, val_MinusLogProbMetric: 398.6625

Epoch 200: val_loss did not improve from 398.05984
196/196 - 10s - loss: 397.2635 - MinusLogProbMetric: 397.2635 - val_loss: 398.6625 - val_MinusLogProbMetric: 398.6625 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 201/1000
2023-09-10 14:17:29.161 
Epoch 201/1000 
	 loss: 397.2179, MinusLogProbMetric: 397.2179, val_loss: 398.3200, val_MinusLogProbMetric: 398.3200

Epoch 201: val_loss did not improve from 398.05984
196/196 - 10s - loss: 397.2179 - MinusLogProbMetric: 397.2179 - val_loss: 398.3200 - val_MinusLogProbMetric: 398.3200 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 202/1000
2023-09-10 14:17:39.067 
Epoch 202/1000 
	 loss: 397.1677, MinusLogProbMetric: 397.1677, val_loss: 397.8706, val_MinusLogProbMetric: 397.8706

Epoch 202: val_loss improved from 398.05984 to 397.87061, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 397.1677 - MinusLogProbMetric: 397.1677 - val_loss: 397.8706 - val_MinusLogProbMetric: 397.8706 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 203/1000
2023-09-10 14:17:47.894 
Epoch 203/1000 
	 loss: 397.1022, MinusLogProbMetric: 397.1022, val_loss: 398.1607, val_MinusLogProbMetric: 398.1607

Epoch 203: val_loss did not improve from 397.87061
196/196 - 9s - loss: 397.1022 - MinusLogProbMetric: 397.1022 - val_loss: 398.1607 - val_MinusLogProbMetric: 398.1607 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 204/1000
2023-09-10 14:17:58.797 
Epoch 204/1000 
	 loss: 396.9402, MinusLogProbMetric: 396.9402, val_loss: 398.3044, val_MinusLogProbMetric: 398.3044

Epoch 204: val_loss did not improve from 397.87061
196/196 - 11s - loss: 396.9402 - MinusLogProbMetric: 396.9402 - val_loss: 398.3044 - val_MinusLogProbMetric: 398.3044 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 205/1000
2023-09-10 14:18:08.432 
Epoch 205/1000 
	 loss: 397.1103, MinusLogProbMetric: 397.1103, val_loss: 399.4098, val_MinusLogProbMetric: 399.4098

Epoch 205: val_loss did not improve from 397.87061
196/196 - 10s - loss: 397.1103 - MinusLogProbMetric: 397.1103 - val_loss: 399.4098 - val_MinusLogProbMetric: 399.4098 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 206/1000
2023-09-10 14:18:19.667 
Epoch 206/1000 
	 loss: 397.0125, MinusLogProbMetric: 397.0125, val_loss: 398.3668, val_MinusLogProbMetric: 398.3668

Epoch 206: val_loss did not improve from 397.87061
196/196 - 11s - loss: 397.0125 - MinusLogProbMetric: 397.0125 - val_loss: 398.3668 - val_MinusLogProbMetric: 398.3668 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 207/1000
2023-09-10 14:18:28.340 
Epoch 207/1000 
	 loss: 396.9117, MinusLogProbMetric: 396.9117, val_loss: 398.3583, val_MinusLogProbMetric: 398.3583

Epoch 207: val_loss did not improve from 397.87061
196/196 - 9s - loss: 396.9117 - MinusLogProbMetric: 396.9117 - val_loss: 398.3583 - val_MinusLogProbMetric: 398.3583 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 208/1000
2023-09-10 14:18:37.226 
Epoch 208/1000 
	 loss: 396.8911, MinusLogProbMetric: 396.8911, val_loss: 397.8742, val_MinusLogProbMetric: 397.8742

Epoch 208: val_loss did not improve from 397.87061
196/196 - 9s - loss: 396.8911 - MinusLogProbMetric: 396.8911 - val_loss: 397.8742 - val_MinusLogProbMetric: 397.8742 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 209/1000
2023-09-10 14:18:48.070 
Epoch 209/1000 
	 loss: 397.2022, MinusLogProbMetric: 397.2022, val_loss: 397.7610, val_MinusLogProbMetric: 397.7610

Epoch 209: val_loss improved from 397.87061 to 397.76105, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 397.2022 - MinusLogProbMetric: 397.2022 - val_loss: 397.7610 - val_MinusLogProbMetric: 397.7610 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 210/1000
2023-09-10 14:18:58.547 
Epoch 210/1000 
	 loss: 396.8095, MinusLogProbMetric: 396.8095, val_loss: 398.4914, val_MinusLogProbMetric: 398.4914

Epoch 210: val_loss did not improve from 397.76105
196/196 - 10s - loss: 396.8095 - MinusLogProbMetric: 396.8095 - val_loss: 398.4914 - val_MinusLogProbMetric: 398.4914 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 211/1000
2023-09-10 14:19:09.827 
Epoch 211/1000 
	 loss: 396.9257, MinusLogProbMetric: 396.9257, val_loss: 397.9112, val_MinusLogProbMetric: 397.9112

Epoch 211: val_loss did not improve from 397.76105
196/196 - 11s - loss: 396.9257 - MinusLogProbMetric: 396.9257 - val_loss: 397.9112 - val_MinusLogProbMetric: 397.9112 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 212/1000
2023-09-10 14:19:19.290 
Epoch 212/1000 
	 loss: 396.6457, MinusLogProbMetric: 396.6457, val_loss: 397.6288, val_MinusLogProbMetric: 397.6288

Epoch 212: val_loss improved from 397.76105 to 397.62875, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 396.6457 - MinusLogProbMetric: 396.6457 - val_loss: 397.6288 - val_MinusLogProbMetric: 397.6288 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 213/1000
2023-09-10 14:19:29.622 
Epoch 213/1000 
	 loss: 397.0791, MinusLogProbMetric: 397.0791, val_loss: 397.6429, val_MinusLogProbMetric: 397.6429

Epoch 213: val_loss did not improve from 397.62875
196/196 - 10s - loss: 397.0791 - MinusLogProbMetric: 397.0791 - val_loss: 397.6429 - val_MinusLogProbMetric: 397.6429 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 214/1000
2023-09-10 14:19:40.648 
Epoch 214/1000 
	 loss: 396.6301, MinusLogProbMetric: 396.6301, val_loss: 397.7074, val_MinusLogProbMetric: 397.7074

Epoch 214: val_loss did not improve from 397.62875
196/196 - 11s - loss: 396.6301 - MinusLogProbMetric: 396.6301 - val_loss: 397.7074 - val_MinusLogProbMetric: 397.7074 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 215/1000
2023-09-10 14:19:50.415 
Epoch 215/1000 
	 loss: 396.7034, MinusLogProbMetric: 396.7034, val_loss: 397.6240, val_MinusLogProbMetric: 397.6240

Epoch 215: val_loss improved from 397.62875 to 397.62396, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 396.7034 - MinusLogProbMetric: 396.7034 - val_loss: 397.6240 - val_MinusLogProbMetric: 397.6240 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 216/1000
2023-09-10 14:20:00.305 
Epoch 216/1000 
	 loss: 396.7061, MinusLogProbMetric: 396.7061, val_loss: 398.1073, val_MinusLogProbMetric: 398.1073

Epoch 216: val_loss did not improve from 397.62396
196/196 - 9s - loss: 396.7061 - MinusLogProbMetric: 396.7061 - val_loss: 398.1073 - val_MinusLogProbMetric: 398.1073 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 217/1000
2023-09-10 14:20:09.796 
Epoch 217/1000 
	 loss: 396.7459, MinusLogProbMetric: 396.7459, val_loss: 397.4115, val_MinusLogProbMetric: 397.4115

Epoch 217: val_loss improved from 397.62396 to 397.41150, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 396.7459 - MinusLogProbMetric: 396.7459 - val_loss: 397.4115 - val_MinusLogProbMetric: 397.4115 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 218/1000
2023-09-10 14:20:20.105 
Epoch 218/1000 
	 loss: 396.7591, MinusLogProbMetric: 396.7591, val_loss: 398.4059, val_MinusLogProbMetric: 398.4059

Epoch 218: val_loss did not improve from 397.41150
196/196 - 10s - loss: 396.7591 - MinusLogProbMetric: 396.7591 - val_loss: 398.4059 - val_MinusLogProbMetric: 398.4059 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 219/1000
2023-09-10 14:20:30.531 
Epoch 219/1000 
	 loss: 396.3802, MinusLogProbMetric: 396.3802, val_loss: 397.5842, val_MinusLogProbMetric: 397.5842

Epoch 219: val_loss did not improve from 397.41150
196/196 - 10s - loss: 396.3802 - MinusLogProbMetric: 396.3802 - val_loss: 397.5842 - val_MinusLogProbMetric: 397.5842 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 220/1000
2023-09-10 14:20:39.275 
Epoch 220/1000 
	 loss: 396.5261, MinusLogProbMetric: 396.5261, val_loss: 401.4754, val_MinusLogProbMetric: 401.4754

Epoch 220: val_loss did not improve from 397.41150
196/196 - 9s - loss: 396.5261 - MinusLogProbMetric: 396.5261 - val_loss: 401.4754 - val_MinusLogProbMetric: 401.4754 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 221/1000
2023-09-10 14:20:48.470 
Epoch 221/1000 
	 loss: 396.5440, MinusLogProbMetric: 396.5440, val_loss: 397.5502, val_MinusLogProbMetric: 397.5502

Epoch 221: val_loss did not improve from 397.41150
196/196 - 9s - loss: 396.5440 - MinusLogProbMetric: 396.5440 - val_loss: 397.5502 - val_MinusLogProbMetric: 397.5502 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 222/1000
2023-09-10 14:20:59.401 
Epoch 222/1000 
	 loss: 396.6233, MinusLogProbMetric: 396.6233, val_loss: 397.7511, val_MinusLogProbMetric: 397.7511

Epoch 222: val_loss did not improve from 397.41150
196/196 - 11s - loss: 396.6233 - MinusLogProbMetric: 396.6233 - val_loss: 397.7511 - val_MinusLogProbMetric: 397.7511 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 223/1000
2023-09-10 14:21:07.952 
Epoch 223/1000 
	 loss: 396.5689, MinusLogProbMetric: 396.5689, val_loss: 398.3237, val_MinusLogProbMetric: 398.3237

Epoch 223: val_loss did not improve from 397.41150
196/196 - 9s - loss: 396.5689 - MinusLogProbMetric: 396.5689 - val_loss: 398.3237 - val_MinusLogProbMetric: 398.3237 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 224/1000
2023-09-10 14:21:19.229 
Epoch 224/1000 
	 loss: 396.5527, MinusLogProbMetric: 396.5527, val_loss: 397.7274, val_MinusLogProbMetric: 397.7274

Epoch 224: val_loss did not improve from 397.41150
196/196 - 11s - loss: 396.5527 - MinusLogProbMetric: 396.5527 - val_loss: 397.7274 - val_MinusLogProbMetric: 397.7274 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 225/1000
2023-09-10 14:21:28.968 
Epoch 225/1000 
	 loss: 396.3336, MinusLogProbMetric: 396.3336, val_loss: 397.0873, val_MinusLogProbMetric: 397.0873

Epoch 225: val_loss improved from 397.41150 to 397.08734, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 396.3336 - MinusLogProbMetric: 396.3336 - val_loss: 397.0873 - val_MinusLogProbMetric: 397.0873 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 226/1000
2023-09-10 14:21:40.273 
Epoch 226/1000 
	 loss: 396.3551, MinusLogProbMetric: 396.3551, val_loss: 397.1039, val_MinusLogProbMetric: 397.1039

Epoch 226: val_loss did not improve from 397.08734
196/196 - 11s - loss: 396.3551 - MinusLogProbMetric: 396.3551 - val_loss: 397.1039 - val_MinusLogProbMetric: 397.1039 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 227/1000
2023-09-10 14:21:50.202 
Epoch 227/1000 
	 loss: 396.4577, MinusLogProbMetric: 396.4577, val_loss: 397.2914, val_MinusLogProbMetric: 397.2914

Epoch 227: val_loss did not improve from 397.08734
196/196 - 10s - loss: 396.4577 - MinusLogProbMetric: 396.4577 - val_loss: 397.2914 - val_MinusLogProbMetric: 397.2914 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 228/1000
2023-09-10 14:22:00.788 
Epoch 228/1000 
	 loss: 396.3194, MinusLogProbMetric: 396.3194, val_loss: 397.3122, val_MinusLogProbMetric: 397.3122

Epoch 228: val_loss did not improve from 397.08734
196/196 - 11s - loss: 396.3194 - MinusLogProbMetric: 396.3194 - val_loss: 397.3122 - val_MinusLogProbMetric: 397.3122 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 229/1000
2023-09-10 14:22:09.669 
Epoch 229/1000 
	 loss: 396.4362, MinusLogProbMetric: 396.4362, val_loss: 397.2648, val_MinusLogProbMetric: 397.2648

Epoch 229: val_loss did not improve from 397.08734
196/196 - 9s - loss: 396.4362 - MinusLogProbMetric: 396.4362 - val_loss: 397.2648 - val_MinusLogProbMetric: 397.2648 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 230/1000
2023-09-10 14:22:15.891 
Epoch 230/1000 
	 loss: 396.3250, MinusLogProbMetric: 396.3250, val_loss: 397.0518, val_MinusLogProbMetric: 397.0518

Epoch 230: val_loss improved from 397.08734 to 397.05182, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 7s - loss: 396.3250 - MinusLogProbMetric: 396.3250 - val_loss: 397.0518 - val_MinusLogProbMetric: 397.0518 - lr: 1.6667e-04 - 7s/epoch - 33ms/step
Epoch 231/1000
2023-09-10 14:22:25.958 
Epoch 231/1000 
	 loss: 396.3386, MinusLogProbMetric: 396.3386, val_loss: 396.9141, val_MinusLogProbMetric: 396.9141

Epoch 231: val_loss improved from 397.05182 to 396.91412, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 396.3386 - MinusLogProbMetric: 396.3386 - val_loss: 396.9141 - val_MinusLogProbMetric: 396.9141 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 232/1000
2023-09-10 14:22:35.009 
Epoch 232/1000 
	 loss: 396.1739, MinusLogProbMetric: 396.1739, val_loss: 397.5044, val_MinusLogProbMetric: 397.5044

Epoch 232: val_loss did not improve from 396.91412
196/196 - 9s - loss: 396.1739 - MinusLogProbMetric: 396.1739 - val_loss: 397.5044 - val_MinusLogProbMetric: 397.5044 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 233/1000
2023-09-10 14:22:44.931 
Epoch 233/1000 
	 loss: 396.3246, MinusLogProbMetric: 396.3246, val_loss: 397.4069, val_MinusLogProbMetric: 397.4069

Epoch 233: val_loss did not improve from 396.91412
196/196 - 10s - loss: 396.3246 - MinusLogProbMetric: 396.3246 - val_loss: 397.4069 - val_MinusLogProbMetric: 397.4069 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 234/1000
2023-09-10 14:22:53.673 
Epoch 234/1000 
	 loss: 396.2003, MinusLogProbMetric: 396.2003, val_loss: 397.8032, val_MinusLogProbMetric: 397.8032

Epoch 234: val_loss did not improve from 396.91412
196/196 - 9s - loss: 396.2003 - MinusLogProbMetric: 396.2003 - val_loss: 397.8032 - val_MinusLogProbMetric: 397.8032 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 235/1000
2023-09-10 14:23:04.228 
Epoch 235/1000 
	 loss: 396.2372, MinusLogProbMetric: 396.2372, val_loss: 397.1500, val_MinusLogProbMetric: 397.1500

Epoch 235: val_loss did not improve from 396.91412
196/196 - 11s - loss: 396.2372 - MinusLogProbMetric: 396.2372 - val_loss: 397.1500 - val_MinusLogProbMetric: 397.1500 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 236/1000
2023-09-10 14:23:13.107 
Epoch 236/1000 
	 loss: 396.1553, MinusLogProbMetric: 396.1553, val_loss: 398.0121, val_MinusLogProbMetric: 398.0121

Epoch 236: val_loss did not improve from 396.91412
196/196 - 9s - loss: 396.1553 - MinusLogProbMetric: 396.1553 - val_loss: 398.0121 - val_MinusLogProbMetric: 398.0121 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 237/1000
2023-09-10 14:23:22.888 
Epoch 237/1000 
	 loss: 396.0914, MinusLogProbMetric: 396.0914, val_loss: 397.6408, val_MinusLogProbMetric: 397.6408

Epoch 237: val_loss did not improve from 396.91412
196/196 - 10s - loss: 396.0914 - MinusLogProbMetric: 396.0914 - val_loss: 397.6408 - val_MinusLogProbMetric: 397.6408 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 238/1000
2023-09-10 14:23:33.023 
Epoch 238/1000 
	 loss: 396.3118, MinusLogProbMetric: 396.3118, val_loss: 400.1912, val_MinusLogProbMetric: 400.1912

Epoch 238: val_loss did not improve from 396.91412
196/196 - 10s - loss: 396.3118 - MinusLogProbMetric: 396.3118 - val_loss: 400.1912 - val_MinusLogProbMetric: 400.1912 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 239/1000
2023-09-10 14:23:44.008 
Epoch 239/1000 
	 loss: 396.2202, MinusLogProbMetric: 396.2202, val_loss: 397.4995, val_MinusLogProbMetric: 397.4995

Epoch 239: val_loss did not improve from 396.91412
196/196 - 11s - loss: 396.2202 - MinusLogProbMetric: 396.2202 - val_loss: 397.4995 - val_MinusLogProbMetric: 397.4995 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 240/1000
2023-09-10 14:23:57.286 
Epoch 240/1000 
	 loss: 395.9303, MinusLogProbMetric: 395.9303, val_loss: 397.0746, val_MinusLogProbMetric: 397.0746

Epoch 240: val_loss did not improve from 396.91412
196/196 - 13s - loss: 395.9303 - MinusLogProbMetric: 395.9303 - val_loss: 397.0746 - val_MinusLogProbMetric: 397.0746 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 241/1000
2023-09-10 14:24:09.969 
Epoch 241/1000 
	 loss: 396.1829, MinusLogProbMetric: 396.1829, val_loss: 397.7111, val_MinusLogProbMetric: 397.7111

Epoch 241: val_loss did not improve from 396.91412
196/196 - 13s - loss: 396.1829 - MinusLogProbMetric: 396.1829 - val_loss: 397.7111 - val_MinusLogProbMetric: 397.7111 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 242/1000
2023-09-10 14:24:22.629 
Epoch 242/1000 
	 loss: 395.9838, MinusLogProbMetric: 395.9838, val_loss: 397.7242, val_MinusLogProbMetric: 397.7242

Epoch 242: val_loss did not improve from 396.91412
196/196 - 13s - loss: 395.9838 - MinusLogProbMetric: 395.9838 - val_loss: 397.7242 - val_MinusLogProbMetric: 397.7242 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 243/1000
2023-09-10 14:24:33.900 
Epoch 243/1000 
	 loss: 395.9586, MinusLogProbMetric: 395.9586, val_loss: 397.4264, val_MinusLogProbMetric: 397.4264

Epoch 243: val_loss did not improve from 396.91412
196/196 - 11s - loss: 395.9586 - MinusLogProbMetric: 395.9586 - val_loss: 397.4264 - val_MinusLogProbMetric: 397.4264 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 244/1000
2023-09-10 14:24:44.188 
Epoch 244/1000 
	 loss: 395.9788, MinusLogProbMetric: 395.9788, val_loss: 396.8080, val_MinusLogProbMetric: 396.8080

Epoch 244: val_loss improved from 396.91412 to 396.80795, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 395.9788 - MinusLogProbMetric: 395.9788 - val_loss: 396.8080 - val_MinusLogProbMetric: 396.8080 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 245/1000
2023-09-10 14:24:54.387 
Epoch 245/1000 
	 loss: 395.9260, MinusLogProbMetric: 395.9260, val_loss: 397.2984, val_MinusLogProbMetric: 397.2984

Epoch 245: val_loss did not improve from 396.80795
196/196 - 10s - loss: 395.9260 - MinusLogProbMetric: 395.9260 - val_loss: 397.2984 - val_MinusLogProbMetric: 397.2984 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 246/1000
2023-09-10 14:25:06.769 
Epoch 246/1000 
	 loss: 395.9102, MinusLogProbMetric: 395.9102, val_loss: 397.3958, val_MinusLogProbMetric: 397.3958

Epoch 246: val_loss did not improve from 396.80795
196/196 - 12s - loss: 395.9102 - MinusLogProbMetric: 395.9102 - val_loss: 397.3958 - val_MinusLogProbMetric: 397.3958 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 247/1000
2023-09-10 14:25:18.477 
Epoch 247/1000 
	 loss: 395.9515, MinusLogProbMetric: 395.9515, val_loss: 397.7278, val_MinusLogProbMetric: 397.7278

Epoch 247: val_loss did not improve from 396.80795
196/196 - 12s - loss: 395.9515 - MinusLogProbMetric: 395.9515 - val_loss: 397.7278 - val_MinusLogProbMetric: 397.7278 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 248/1000
2023-09-10 14:25:29.524 
Epoch 248/1000 
	 loss: 395.7377, MinusLogProbMetric: 395.7377, val_loss: 397.3015, val_MinusLogProbMetric: 397.3015

Epoch 248: val_loss did not improve from 396.80795
196/196 - 11s - loss: 395.7377 - MinusLogProbMetric: 395.7377 - val_loss: 397.3015 - val_MinusLogProbMetric: 397.3015 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 249/1000
2023-09-10 14:25:39.288 
Epoch 249/1000 
	 loss: 395.9381, MinusLogProbMetric: 395.9381, val_loss: 396.9927, val_MinusLogProbMetric: 396.9927

Epoch 249: val_loss did not improve from 396.80795
196/196 - 10s - loss: 395.9381 - MinusLogProbMetric: 395.9381 - val_loss: 396.9927 - val_MinusLogProbMetric: 396.9927 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 250/1000
2023-09-10 14:25:50.829 
Epoch 250/1000 
	 loss: 395.7917, MinusLogProbMetric: 395.7917, val_loss: 398.4590, val_MinusLogProbMetric: 398.4590

Epoch 250: val_loss did not improve from 396.80795
196/196 - 12s - loss: 395.7917 - MinusLogProbMetric: 395.7917 - val_loss: 398.4590 - val_MinusLogProbMetric: 398.4590 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 251/1000
2023-09-10 14:26:02.110 
Epoch 251/1000 
	 loss: 395.6580, MinusLogProbMetric: 395.6580, val_loss: 398.4639, val_MinusLogProbMetric: 398.4639

Epoch 251: val_loss did not improve from 396.80795
196/196 - 11s - loss: 395.6580 - MinusLogProbMetric: 395.6580 - val_loss: 398.4639 - val_MinusLogProbMetric: 398.4639 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 252/1000
2023-09-10 14:26:13.487 
Epoch 252/1000 
	 loss: 395.7138, MinusLogProbMetric: 395.7138, val_loss: 396.3686, val_MinusLogProbMetric: 396.3686

Epoch 252: val_loss improved from 396.80795 to 396.36859, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 395.7138 - MinusLogProbMetric: 395.7138 - val_loss: 396.3686 - val_MinusLogProbMetric: 396.3686 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 253/1000
2023-09-10 14:26:23.540 
Epoch 253/1000 
	 loss: 395.9156, MinusLogProbMetric: 395.9156, val_loss: 397.6378, val_MinusLogProbMetric: 397.6378

Epoch 253: val_loss did not improve from 396.36859
196/196 - 10s - loss: 395.9156 - MinusLogProbMetric: 395.9156 - val_loss: 397.6378 - val_MinusLogProbMetric: 397.6378 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 254/1000
2023-09-10 14:26:34.206 
Epoch 254/1000 
	 loss: 395.8239, MinusLogProbMetric: 395.8239, val_loss: 396.3704, val_MinusLogProbMetric: 396.3704

Epoch 254: val_loss did not improve from 396.36859
196/196 - 11s - loss: 395.8239 - MinusLogProbMetric: 395.8239 - val_loss: 396.3704 - val_MinusLogProbMetric: 396.3704 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 255/1000
2023-09-10 14:26:44.502 
Epoch 255/1000 
	 loss: 395.5775, MinusLogProbMetric: 395.5775, val_loss: 396.4635, val_MinusLogProbMetric: 396.4635

Epoch 255: val_loss did not improve from 396.36859
196/196 - 10s - loss: 395.5775 - MinusLogProbMetric: 395.5775 - val_loss: 396.4635 - val_MinusLogProbMetric: 396.4635 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 256/1000
2023-09-10 14:26:55.888 
Epoch 256/1000 
	 loss: 396.2019, MinusLogProbMetric: 396.2019, val_loss: 396.4641, val_MinusLogProbMetric: 396.4641

Epoch 256: val_loss did not improve from 396.36859
196/196 - 11s - loss: 396.2019 - MinusLogProbMetric: 396.2019 - val_loss: 396.4641 - val_MinusLogProbMetric: 396.4641 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 257/1000
2023-09-10 14:27:06.053 
Epoch 257/1000 
	 loss: 395.4991, MinusLogProbMetric: 395.4991, val_loss: 396.9635, val_MinusLogProbMetric: 396.9635

Epoch 257: val_loss did not improve from 396.36859
196/196 - 10s - loss: 395.4991 - MinusLogProbMetric: 395.4991 - val_loss: 396.9635 - val_MinusLogProbMetric: 396.9635 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 258/1000
2023-09-10 14:27:15.103 
Epoch 258/1000 
	 loss: 395.6429, MinusLogProbMetric: 395.6429, val_loss: 396.7625, val_MinusLogProbMetric: 396.7625

Epoch 258: val_loss did not improve from 396.36859
196/196 - 9s - loss: 395.6429 - MinusLogProbMetric: 395.6429 - val_loss: 396.7625 - val_MinusLogProbMetric: 396.7625 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 259/1000
2023-09-10 14:27:27.368 
Epoch 259/1000 
	 loss: 395.6230, MinusLogProbMetric: 395.6230, val_loss: 397.3110, val_MinusLogProbMetric: 397.3110

Epoch 259: val_loss did not improve from 396.36859
196/196 - 12s - loss: 395.6230 - MinusLogProbMetric: 395.6230 - val_loss: 397.3110 - val_MinusLogProbMetric: 397.3110 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 260/1000
2023-09-10 14:27:39.622 
Epoch 260/1000 
	 loss: 395.4641, MinusLogProbMetric: 395.4641, val_loss: 398.4773, val_MinusLogProbMetric: 398.4773

Epoch 260: val_loss did not improve from 396.36859
196/196 - 12s - loss: 395.4641 - MinusLogProbMetric: 395.4641 - val_loss: 398.4773 - val_MinusLogProbMetric: 398.4773 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 261/1000
2023-09-10 14:27:50.193 
Epoch 261/1000 
	 loss: 395.6140, MinusLogProbMetric: 395.6140, val_loss: 396.5389, val_MinusLogProbMetric: 396.5389

Epoch 261: val_loss did not improve from 396.36859
196/196 - 11s - loss: 395.6140 - MinusLogProbMetric: 395.6140 - val_loss: 396.5389 - val_MinusLogProbMetric: 396.5389 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 262/1000
2023-09-10 14:28:01.057 
Epoch 262/1000 
	 loss: 395.4956, MinusLogProbMetric: 395.4956, val_loss: 397.1846, val_MinusLogProbMetric: 397.1846

Epoch 262: val_loss did not improve from 396.36859
196/196 - 11s - loss: 395.4956 - MinusLogProbMetric: 395.4956 - val_loss: 397.1846 - val_MinusLogProbMetric: 397.1846 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 263/1000
2023-09-10 14:28:10.524 
Epoch 263/1000 
	 loss: 395.3987, MinusLogProbMetric: 395.3987, val_loss: 396.4940, val_MinusLogProbMetric: 396.4940

Epoch 263: val_loss did not improve from 396.36859
196/196 - 9s - loss: 395.3987 - MinusLogProbMetric: 395.3987 - val_loss: 396.4940 - val_MinusLogProbMetric: 396.4940 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 264/1000
2023-09-10 14:28:21.891 
Epoch 264/1000 
	 loss: 395.4193, MinusLogProbMetric: 395.4193, val_loss: 396.9541, val_MinusLogProbMetric: 396.9541

Epoch 264: val_loss did not improve from 396.36859
196/196 - 11s - loss: 395.4193 - MinusLogProbMetric: 395.4193 - val_loss: 396.9541 - val_MinusLogProbMetric: 396.9541 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 265/1000
2023-09-10 14:28:31.749 
Epoch 265/1000 
	 loss: 395.2674, MinusLogProbMetric: 395.2674, val_loss: 396.6437, val_MinusLogProbMetric: 396.6437

Epoch 265: val_loss did not improve from 396.36859
196/196 - 10s - loss: 395.2674 - MinusLogProbMetric: 395.2674 - val_loss: 396.6437 - val_MinusLogProbMetric: 396.6437 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 266/1000
2023-09-10 14:28:44.792 
Epoch 266/1000 
	 loss: 395.4518, MinusLogProbMetric: 395.4518, val_loss: 396.4632, val_MinusLogProbMetric: 396.4632

Epoch 266: val_loss did not improve from 396.36859
196/196 - 13s - loss: 395.4518 - MinusLogProbMetric: 395.4518 - val_loss: 396.4632 - val_MinusLogProbMetric: 396.4632 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 267/1000
2023-09-10 14:28:56.078 
Epoch 267/1000 
	 loss: 395.4639, MinusLogProbMetric: 395.4639, val_loss: 398.1623, val_MinusLogProbMetric: 398.1623

Epoch 267: val_loss did not improve from 396.36859
196/196 - 11s - loss: 395.4639 - MinusLogProbMetric: 395.4639 - val_loss: 398.1623 - val_MinusLogProbMetric: 398.1623 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 268/1000
2023-09-10 14:29:08.440 
Epoch 268/1000 
	 loss: 395.4828, MinusLogProbMetric: 395.4828, val_loss: 396.6951, val_MinusLogProbMetric: 396.6951

Epoch 268: val_loss did not improve from 396.36859
196/196 - 12s - loss: 395.4828 - MinusLogProbMetric: 395.4828 - val_loss: 396.6951 - val_MinusLogProbMetric: 396.6951 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 269/1000
2023-09-10 14:29:18.387 
Epoch 269/1000 
	 loss: 395.3029, MinusLogProbMetric: 395.3029, val_loss: 397.1106, val_MinusLogProbMetric: 397.1106

Epoch 269: val_loss did not improve from 396.36859
196/196 - 10s - loss: 395.3029 - MinusLogProbMetric: 395.3029 - val_loss: 397.1106 - val_MinusLogProbMetric: 397.1106 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 270/1000
2023-09-10 14:29:29.634 
Epoch 270/1000 
	 loss: 395.3275, MinusLogProbMetric: 395.3275, val_loss: 397.1925, val_MinusLogProbMetric: 397.1925

Epoch 270: val_loss did not improve from 396.36859
196/196 - 11s - loss: 395.3275 - MinusLogProbMetric: 395.3275 - val_loss: 397.1925 - val_MinusLogProbMetric: 397.1925 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 271/1000
2023-09-10 14:29:40.514 
Epoch 271/1000 
	 loss: 395.2626, MinusLogProbMetric: 395.2626, val_loss: 396.0722, val_MinusLogProbMetric: 396.0722

Epoch 271: val_loss improved from 396.36859 to 396.07224, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 395.2626 - MinusLogProbMetric: 395.2626 - val_loss: 396.0722 - val_MinusLogProbMetric: 396.0722 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 272/1000
2023-09-10 14:29:52.521 
Epoch 272/1000 
	 loss: 395.3948, MinusLogProbMetric: 395.3948, val_loss: 397.0535, val_MinusLogProbMetric: 397.0535

Epoch 272: val_loss did not improve from 396.07224
196/196 - 12s - loss: 395.3948 - MinusLogProbMetric: 395.3948 - val_loss: 397.0535 - val_MinusLogProbMetric: 397.0535 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 273/1000
2023-09-10 14:30:03.648 
Epoch 273/1000 
	 loss: 395.5479, MinusLogProbMetric: 395.5479, val_loss: 396.0249, val_MinusLogProbMetric: 396.0249

Epoch 273: val_loss improved from 396.07224 to 396.02490, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 395.5479 - MinusLogProbMetric: 395.5479 - val_loss: 396.0249 - val_MinusLogProbMetric: 396.0249 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 274/1000
2023-09-10 14:30:15.217 
Epoch 274/1000 
	 loss: 395.0531, MinusLogProbMetric: 395.0531, val_loss: 396.3998, val_MinusLogProbMetric: 396.3998

Epoch 274: val_loss did not improve from 396.02490
196/196 - 11s - loss: 395.0531 - MinusLogProbMetric: 395.0531 - val_loss: 396.3998 - val_MinusLogProbMetric: 396.3998 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 275/1000
2023-09-10 14:30:26.479 
Epoch 275/1000 
	 loss: 395.2686, MinusLogProbMetric: 395.2686, val_loss: 397.2717, val_MinusLogProbMetric: 397.2717

Epoch 275: val_loss did not improve from 396.02490
196/196 - 11s - loss: 395.2686 - MinusLogProbMetric: 395.2686 - val_loss: 397.2717 - val_MinusLogProbMetric: 397.2717 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 276/1000
2023-09-10 14:30:37.641 
Epoch 276/1000 
	 loss: 395.3500, MinusLogProbMetric: 395.3500, val_loss: 397.3899, val_MinusLogProbMetric: 397.3899

Epoch 276: val_loss did not improve from 396.02490
196/196 - 11s - loss: 395.3500 - MinusLogProbMetric: 395.3500 - val_loss: 397.3899 - val_MinusLogProbMetric: 397.3899 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 277/1000
2023-09-10 14:30:50.059 
Epoch 277/1000 
	 loss: 395.2474, MinusLogProbMetric: 395.2474, val_loss: 397.4236, val_MinusLogProbMetric: 397.4236

Epoch 277: val_loss did not improve from 396.02490
196/196 - 12s - loss: 395.2474 - MinusLogProbMetric: 395.2474 - val_loss: 397.4236 - val_MinusLogProbMetric: 397.4236 - lr: 1.6667e-04 - 12s/epoch - 63ms/step
Epoch 278/1000
2023-09-10 14:30:59.337 
Epoch 278/1000 
	 loss: 395.1801, MinusLogProbMetric: 395.1801, val_loss: 396.1057, val_MinusLogProbMetric: 396.1057

Epoch 278: val_loss did not improve from 396.02490
196/196 - 9s - loss: 395.1801 - MinusLogProbMetric: 395.1801 - val_loss: 396.1057 - val_MinusLogProbMetric: 396.1057 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 279/1000
2023-09-10 14:31:09.122 
Epoch 279/1000 
	 loss: 395.0820, MinusLogProbMetric: 395.0820, val_loss: 396.4964, val_MinusLogProbMetric: 396.4964

Epoch 279: val_loss did not improve from 396.02490
196/196 - 10s - loss: 395.0820 - MinusLogProbMetric: 395.0820 - val_loss: 396.4964 - val_MinusLogProbMetric: 396.4964 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 280/1000
2023-09-10 14:31:21.462 
Epoch 280/1000 
	 loss: 395.1765, MinusLogProbMetric: 395.1765, val_loss: 395.7983, val_MinusLogProbMetric: 395.7983

Epoch 280: val_loss improved from 396.02490 to 395.79831, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 13s - loss: 395.1765 - MinusLogProbMetric: 395.1765 - val_loss: 395.7983 - val_MinusLogProbMetric: 395.7983 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 281/1000
2023-09-10 14:31:32.428 
Epoch 281/1000 
	 loss: 395.0844, MinusLogProbMetric: 395.0844, val_loss: 396.4426, val_MinusLogProbMetric: 396.4426

Epoch 281: val_loss did not improve from 395.79831
196/196 - 11s - loss: 395.0844 - MinusLogProbMetric: 395.0844 - val_loss: 396.4426 - val_MinusLogProbMetric: 396.4426 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 282/1000
2023-09-10 14:31:42.894 
Epoch 282/1000 
	 loss: 395.2883, MinusLogProbMetric: 395.2883, val_loss: 396.9761, val_MinusLogProbMetric: 396.9761

Epoch 282: val_loss did not improve from 395.79831
196/196 - 10s - loss: 395.2883 - MinusLogProbMetric: 395.2883 - val_loss: 396.9761 - val_MinusLogProbMetric: 396.9761 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 283/1000
2023-09-10 14:31:53.591 
Epoch 283/1000 
	 loss: 394.7957, MinusLogProbMetric: 394.7957, val_loss: 395.5635, val_MinusLogProbMetric: 395.5635

Epoch 283: val_loss improved from 395.79831 to 395.56351, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 12s - loss: 394.7957 - MinusLogProbMetric: 394.7957 - val_loss: 395.5635 - val_MinusLogProbMetric: 395.5635 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 284/1000
2023-09-10 14:32:04.852 
Epoch 284/1000 
	 loss: 395.2180, MinusLogProbMetric: 395.2180, val_loss: 395.8679, val_MinusLogProbMetric: 395.8679

Epoch 284: val_loss did not improve from 395.56351
196/196 - 10s - loss: 395.2180 - MinusLogProbMetric: 395.2180 - val_loss: 395.8679 - val_MinusLogProbMetric: 395.8679 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 285/1000
2023-09-10 14:32:13.794 
Epoch 285/1000 
	 loss: 395.0752, MinusLogProbMetric: 395.0752, val_loss: 395.9653, val_MinusLogProbMetric: 395.9653

Epoch 285: val_loss did not improve from 395.56351
196/196 - 9s - loss: 395.0752 - MinusLogProbMetric: 395.0752 - val_loss: 395.9653 - val_MinusLogProbMetric: 395.9653 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 286/1000
2023-09-10 14:32:24.011 
Epoch 286/1000 
	 loss: 395.1733, MinusLogProbMetric: 395.1733, val_loss: 396.8603, val_MinusLogProbMetric: 396.8603

Epoch 286: val_loss did not improve from 395.56351
196/196 - 10s - loss: 395.1733 - MinusLogProbMetric: 395.1733 - val_loss: 396.8603 - val_MinusLogProbMetric: 396.8603 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 287/1000
2023-09-10 14:32:34.663 
Epoch 287/1000 
	 loss: 394.9190, MinusLogProbMetric: 394.9190, val_loss: 395.9381, val_MinusLogProbMetric: 395.9381

Epoch 287: val_loss did not improve from 395.56351
196/196 - 11s - loss: 394.9190 - MinusLogProbMetric: 394.9190 - val_loss: 395.9381 - val_MinusLogProbMetric: 395.9381 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 288/1000
2023-09-10 14:32:46.103 
Epoch 288/1000 
	 loss: 395.1065, MinusLogProbMetric: 395.1065, val_loss: 396.4313, val_MinusLogProbMetric: 396.4313

Epoch 288: val_loss did not improve from 395.56351
196/196 - 11s - loss: 395.1065 - MinusLogProbMetric: 395.1065 - val_loss: 396.4313 - val_MinusLogProbMetric: 396.4313 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 289/1000
2023-09-10 14:32:55.904 
Epoch 289/1000 
	 loss: 394.8834, MinusLogProbMetric: 394.8834, val_loss: 395.8859, val_MinusLogProbMetric: 395.8859

Epoch 289: val_loss did not improve from 395.56351
196/196 - 10s - loss: 394.8834 - MinusLogProbMetric: 394.8834 - val_loss: 395.8859 - val_MinusLogProbMetric: 395.8859 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 290/1000
2023-09-10 14:33:06.582 
Epoch 290/1000 
	 loss: 395.1131, MinusLogProbMetric: 395.1131, val_loss: 396.1449, val_MinusLogProbMetric: 396.1449

Epoch 290: val_loss did not improve from 395.56351
196/196 - 11s - loss: 395.1131 - MinusLogProbMetric: 395.1131 - val_loss: 396.1449 - val_MinusLogProbMetric: 396.1449 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 291/1000
2023-09-10 14:33:16.141 
Epoch 291/1000 
	 loss: 394.9247, MinusLogProbMetric: 394.9247, val_loss: 396.1978, val_MinusLogProbMetric: 396.1978

Epoch 291: val_loss did not improve from 395.56351
196/196 - 10s - loss: 394.9247 - MinusLogProbMetric: 394.9247 - val_loss: 396.1978 - val_MinusLogProbMetric: 396.1978 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 292/1000
2023-09-10 14:33:28.110 
Epoch 292/1000 
	 loss: 394.9820, MinusLogProbMetric: 394.9820, val_loss: 396.2181, val_MinusLogProbMetric: 396.2181

Epoch 292: val_loss did not improve from 395.56351
196/196 - 12s - loss: 394.9820 - MinusLogProbMetric: 394.9820 - val_loss: 396.2181 - val_MinusLogProbMetric: 396.2181 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 293/1000
2023-09-10 14:33:37.920 
Epoch 293/1000 
	 loss: 394.9702, MinusLogProbMetric: 394.9702, val_loss: 396.2839, val_MinusLogProbMetric: 396.2839

Epoch 293: val_loss did not improve from 395.56351
196/196 - 10s - loss: 394.9702 - MinusLogProbMetric: 394.9702 - val_loss: 396.2839 - val_MinusLogProbMetric: 396.2839 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 294/1000
2023-09-10 14:33:49.206 
Epoch 294/1000 
	 loss: 394.9502, MinusLogProbMetric: 394.9502, val_loss: 396.2738, val_MinusLogProbMetric: 396.2738

Epoch 294: val_loss did not improve from 395.56351
196/196 - 11s - loss: 394.9502 - MinusLogProbMetric: 394.9502 - val_loss: 396.2738 - val_MinusLogProbMetric: 396.2738 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 295/1000
2023-09-10 14:33:59.347 
Epoch 295/1000 
	 loss: 394.8939, MinusLogProbMetric: 394.8939, val_loss: 397.0462, val_MinusLogProbMetric: 397.0462

Epoch 295: val_loss did not improve from 395.56351
196/196 - 10s - loss: 394.8939 - MinusLogProbMetric: 394.8939 - val_loss: 397.0462 - val_MinusLogProbMetric: 397.0462 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 296/1000
2023-09-10 14:34:12.082 
Epoch 296/1000 
	 loss: 394.8083, MinusLogProbMetric: 394.8083, val_loss: 395.5097, val_MinusLogProbMetric: 395.5097

Epoch 296: val_loss improved from 395.56351 to 395.50967, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 13s - loss: 394.8083 - MinusLogProbMetric: 394.8083 - val_loss: 395.5097 - val_MinusLogProbMetric: 395.5097 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 297/1000
2023-09-10 14:34:21.408 
Epoch 297/1000 
	 loss: 394.9776, MinusLogProbMetric: 394.9776, val_loss: 395.9650, val_MinusLogProbMetric: 395.9650

Epoch 297: val_loss did not improve from 395.50967
196/196 - 9s - loss: 394.9776 - MinusLogProbMetric: 394.9776 - val_loss: 395.9650 - val_MinusLogProbMetric: 395.9650 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 298/1000
2023-09-10 14:34:32.466 
Epoch 298/1000 
	 loss: 394.7994, MinusLogProbMetric: 394.7994, val_loss: 396.4782, val_MinusLogProbMetric: 396.4782

Epoch 298: val_loss did not improve from 395.50967
196/196 - 11s - loss: 394.7994 - MinusLogProbMetric: 394.7994 - val_loss: 396.4782 - val_MinusLogProbMetric: 396.4782 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 299/1000
2023-09-10 14:34:43.522 
Epoch 299/1000 
	 loss: 394.9274, MinusLogProbMetric: 394.9274, val_loss: 396.0799, val_MinusLogProbMetric: 396.0799

Epoch 299: val_loss did not improve from 395.50967
196/196 - 11s - loss: 394.9274 - MinusLogProbMetric: 394.9274 - val_loss: 396.0799 - val_MinusLogProbMetric: 396.0799 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 300/1000
2023-09-10 14:34:56.008 
Epoch 300/1000 
	 loss: 394.6061, MinusLogProbMetric: 394.6061, val_loss: 396.1220, val_MinusLogProbMetric: 396.1220

Epoch 300: val_loss did not improve from 395.50967
196/196 - 12s - loss: 394.6061 - MinusLogProbMetric: 394.6061 - val_loss: 396.1220 - val_MinusLogProbMetric: 396.1220 - lr: 1.6667e-04 - 12s/epoch - 64ms/step
Epoch 301/1000
2023-09-10 14:35:04.295 
Epoch 301/1000 
	 loss: 395.1238, MinusLogProbMetric: 395.1238, val_loss: 398.8803, val_MinusLogProbMetric: 398.8803

Epoch 301: val_loss did not improve from 395.50967
196/196 - 8s - loss: 395.1238 - MinusLogProbMetric: 395.1238 - val_loss: 398.8803 - val_MinusLogProbMetric: 398.8803 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 302/1000
2023-09-10 14:35:17.702 
Epoch 302/1000 
	 loss: 394.5986, MinusLogProbMetric: 394.5986, val_loss: 396.4751, val_MinusLogProbMetric: 396.4751

Epoch 302: val_loss did not improve from 395.50967
196/196 - 13s - loss: 394.5986 - MinusLogProbMetric: 394.5986 - val_loss: 396.4751 - val_MinusLogProbMetric: 396.4751 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 303/1000
2023-09-10 14:35:27.762 
Epoch 303/1000 
	 loss: 394.6831, MinusLogProbMetric: 394.6831, val_loss: 395.9658, val_MinusLogProbMetric: 395.9658

Epoch 303: val_loss did not improve from 395.50967
196/196 - 10s - loss: 394.6831 - MinusLogProbMetric: 394.6831 - val_loss: 395.9658 - val_MinusLogProbMetric: 395.9658 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 304/1000
2023-09-10 14:35:39.493 
Epoch 304/1000 
	 loss: 394.5803, MinusLogProbMetric: 394.5803, val_loss: 395.8424, val_MinusLogProbMetric: 395.8424

Epoch 304: val_loss did not improve from 395.50967
196/196 - 12s - loss: 394.5803 - MinusLogProbMetric: 394.5803 - val_loss: 395.8424 - val_MinusLogProbMetric: 395.8424 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 305/1000
2023-09-10 14:35:49.371 
Epoch 305/1000 
	 loss: 394.7272, MinusLogProbMetric: 394.7272, val_loss: 396.3296, val_MinusLogProbMetric: 396.3296

Epoch 305: val_loss did not improve from 395.50967
196/196 - 10s - loss: 394.7272 - MinusLogProbMetric: 394.7272 - val_loss: 396.3296 - val_MinusLogProbMetric: 396.3296 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 306/1000
2023-09-10 14:36:01.246 
Epoch 306/1000 
	 loss: 394.8829, MinusLogProbMetric: 394.8829, val_loss: 395.7615, val_MinusLogProbMetric: 395.7615

Epoch 306: val_loss did not improve from 395.50967
196/196 - 12s - loss: 394.8829 - MinusLogProbMetric: 394.8829 - val_loss: 395.7615 - val_MinusLogProbMetric: 395.7615 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 307/1000
2023-09-10 14:36:12.178 
Epoch 307/1000 
	 loss: 394.5890, MinusLogProbMetric: 394.5890, val_loss: 396.2437, val_MinusLogProbMetric: 396.2437

Epoch 307: val_loss did not improve from 395.50967
196/196 - 11s - loss: 394.5890 - MinusLogProbMetric: 394.5890 - val_loss: 396.2437 - val_MinusLogProbMetric: 396.2437 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 308/1000
2023-09-10 14:36:24.941 
Epoch 308/1000 
	 loss: 394.4830, MinusLogProbMetric: 394.4830, val_loss: 396.3189, val_MinusLogProbMetric: 396.3189

Epoch 308: val_loss did not improve from 395.50967
196/196 - 13s - loss: 394.4830 - MinusLogProbMetric: 394.4830 - val_loss: 396.3189 - val_MinusLogProbMetric: 396.3189 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 309/1000
2023-09-10 14:36:38.353 
Epoch 309/1000 
	 loss: 394.5080, MinusLogProbMetric: 394.5080, val_loss: 395.7819, val_MinusLogProbMetric: 395.7819

Epoch 309: val_loss did not improve from 395.50967
196/196 - 13s - loss: 394.5080 - MinusLogProbMetric: 394.5080 - val_loss: 395.7819 - val_MinusLogProbMetric: 395.7819 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 310/1000
2023-09-10 14:36:49.354 
Epoch 310/1000 
	 loss: 394.5480, MinusLogProbMetric: 394.5480, val_loss: 395.9980, val_MinusLogProbMetric: 395.9980

Epoch 310: val_loss did not improve from 395.50967
196/196 - 11s - loss: 394.5480 - MinusLogProbMetric: 394.5480 - val_loss: 395.9980 - val_MinusLogProbMetric: 395.9980 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 311/1000
2023-09-10 14:37:00.328 
Epoch 311/1000 
	 loss: 394.5827, MinusLogProbMetric: 394.5827, val_loss: 396.1540, val_MinusLogProbMetric: 396.1540

Epoch 311: val_loss did not improve from 395.50967
196/196 - 11s - loss: 394.5827 - MinusLogProbMetric: 394.5827 - val_loss: 396.1540 - val_MinusLogProbMetric: 396.1540 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 312/1000
2023-09-10 14:37:10.340 
Epoch 312/1000 
	 loss: 394.5955, MinusLogProbMetric: 394.5955, val_loss: 395.9304, val_MinusLogProbMetric: 395.9304

Epoch 312: val_loss did not improve from 395.50967
196/196 - 10s - loss: 394.5955 - MinusLogProbMetric: 394.5955 - val_loss: 395.9304 - val_MinusLogProbMetric: 395.9304 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 313/1000
2023-09-10 14:37:20.156 
Epoch 313/1000 
	 loss: 394.6021, MinusLogProbMetric: 394.6021, val_loss: 396.0551, val_MinusLogProbMetric: 396.0551

Epoch 313: val_loss did not improve from 395.50967
196/196 - 10s - loss: 394.6021 - MinusLogProbMetric: 394.6021 - val_loss: 396.0551 - val_MinusLogProbMetric: 396.0551 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 314/1000
2023-09-10 14:37:31.162 
Epoch 314/1000 
	 loss: 394.4578, MinusLogProbMetric: 394.4578, val_loss: 396.6383, val_MinusLogProbMetric: 396.6383

Epoch 314: val_loss did not improve from 395.50967
196/196 - 11s - loss: 394.4578 - MinusLogProbMetric: 394.4578 - val_loss: 396.6383 - val_MinusLogProbMetric: 396.6383 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 315/1000
2023-09-10 14:37:42.948 
Epoch 315/1000 
	 loss: 394.5027, MinusLogProbMetric: 394.5027, val_loss: 398.0090, val_MinusLogProbMetric: 398.0090

Epoch 315: val_loss did not improve from 395.50967
196/196 - 12s - loss: 394.5027 - MinusLogProbMetric: 394.5027 - val_loss: 398.0090 - val_MinusLogProbMetric: 398.0090 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 316/1000
2023-09-10 14:37:53.225 
Epoch 316/1000 
	 loss: 394.8164, MinusLogProbMetric: 394.8164, val_loss: 396.0191, val_MinusLogProbMetric: 396.0191

Epoch 316: val_loss did not improve from 395.50967
196/196 - 10s - loss: 394.8164 - MinusLogProbMetric: 394.8164 - val_loss: 396.0191 - val_MinusLogProbMetric: 396.0191 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 317/1000
2023-09-10 14:38:03.819 
Epoch 317/1000 
	 loss: 394.4284, MinusLogProbMetric: 394.4284, val_loss: 395.1602, val_MinusLogProbMetric: 395.1602

Epoch 317: val_loss improved from 395.50967 to 395.16019, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 394.4284 - MinusLogProbMetric: 394.4284 - val_loss: 395.1602 - val_MinusLogProbMetric: 395.1602 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 318/1000
2023-09-10 14:38:17.231 
Epoch 318/1000 
	 loss: 394.5084, MinusLogProbMetric: 394.5084, val_loss: 395.4266, val_MinusLogProbMetric: 395.4266

Epoch 318: val_loss did not improve from 395.16019
196/196 - 13s - loss: 394.5084 - MinusLogProbMetric: 394.5084 - val_loss: 395.4266 - val_MinusLogProbMetric: 395.4266 - lr: 1.6667e-04 - 13s/epoch - 67ms/step
Epoch 319/1000
2023-09-10 14:38:28.918 
Epoch 319/1000 
	 loss: 394.5442, MinusLogProbMetric: 394.5442, val_loss: 395.7031, val_MinusLogProbMetric: 395.7031

Epoch 319: val_loss did not improve from 395.16019
196/196 - 12s - loss: 394.5442 - MinusLogProbMetric: 394.5442 - val_loss: 395.7031 - val_MinusLogProbMetric: 395.7031 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 320/1000
2023-09-10 14:38:40.460 
Epoch 320/1000 
	 loss: 394.4664, MinusLogProbMetric: 394.4664, val_loss: 395.3366, val_MinusLogProbMetric: 395.3366

Epoch 320: val_loss did not improve from 395.16019
196/196 - 12s - loss: 394.4664 - MinusLogProbMetric: 394.4664 - val_loss: 395.3366 - val_MinusLogProbMetric: 395.3366 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 321/1000
2023-09-10 14:38:49.354 
Epoch 321/1000 
	 loss: 394.3269, MinusLogProbMetric: 394.3269, val_loss: 396.0061, val_MinusLogProbMetric: 396.0061

Epoch 321: val_loss did not improve from 395.16019
196/196 - 9s - loss: 394.3269 - MinusLogProbMetric: 394.3269 - val_loss: 396.0061 - val_MinusLogProbMetric: 396.0061 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 322/1000
2023-09-10 14:39:02.124 
Epoch 322/1000 
	 loss: 394.4106, MinusLogProbMetric: 394.4106, val_loss: 395.5637, val_MinusLogProbMetric: 395.5637

Epoch 322: val_loss did not improve from 395.16019
196/196 - 13s - loss: 394.4106 - MinusLogProbMetric: 394.4106 - val_loss: 395.5637 - val_MinusLogProbMetric: 395.5637 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 323/1000
2023-09-10 14:39:14.687 
Epoch 323/1000 
	 loss: 394.2674, MinusLogProbMetric: 394.2674, val_loss: 395.7519, val_MinusLogProbMetric: 395.7519

Epoch 323: val_loss did not improve from 395.16019
196/196 - 13s - loss: 394.2674 - MinusLogProbMetric: 394.2674 - val_loss: 395.7519 - val_MinusLogProbMetric: 395.7519 - lr: 1.6667e-04 - 13s/epoch - 64ms/step
Epoch 324/1000
2023-09-10 14:39:28.874 
Epoch 324/1000 
	 loss: 394.4061, MinusLogProbMetric: 394.4061, val_loss: 395.2761, val_MinusLogProbMetric: 395.2761

Epoch 324: val_loss did not improve from 395.16019
196/196 - 14s - loss: 394.4061 - MinusLogProbMetric: 394.4061 - val_loss: 395.2761 - val_MinusLogProbMetric: 395.2761 - lr: 1.6667e-04 - 14s/epoch - 72ms/step
Epoch 325/1000
2023-09-10 14:39:38.906 
Epoch 325/1000 
	 loss: 394.6096, MinusLogProbMetric: 394.6096, val_loss: 395.5303, val_MinusLogProbMetric: 395.5303

Epoch 325: val_loss did not improve from 395.16019
196/196 - 10s - loss: 394.6096 - MinusLogProbMetric: 394.6096 - val_loss: 395.5303 - val_MinusLogProbMetric: 395.5303 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 326/1000
2023-09-10 14:39:48.705 
Epoch 326/1000 
	 loss: 394.3629, MinusLogProbMetric: 394.3629, val_loss: 395.6505, val_MinusLogProbMetric: 395.6505

Epoch 326: val_loss did not improve from 395.16019
196/196 - 10s - loss: 394.3629 - MinusLogProbMetric: 394.3629 - val_loss: 395.6505 - val_MinusLogProbMetric: 395.6505 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 327/1000
2023-09-10 14:39:58.608 
Epoch 327/1000 
	 loss: 394.2815, MinusLogProbMetric: 394.2815, val_loss: 395.0216, val_MinusLogProbMetric: 395.0216

Epoch 327: val_loss improved from 395.16019 to 395.02164, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 394.2815 - MinusLogProbMetric: 394.2815 - val_loss: 395.0216 - val_MinusLogProbMetric: 395.0216 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 328/1000
2023-09-10 14:40:11.602 
Epoch 328/1000 
	 loss: 394.2406, MinusLogProbMetric: 394.2406, val_loss: 395.1277, val_MinusLogProbMetric: 395.1277

Epoch 328: val_loss did not improve from 395.02164
196/196 - 13s - loss: 394.2406 - MinusLogProbMetric: 394.2406 - val_loss: 395.1277 - val_MinusLogProbMetric: 395.1277 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 329/1000
2023-09-10 14:40:23.649 
Epoch 329/1000 
	 loss: 394.4531, MinusLogProbMetric: 394.4531, val_loss: 397.0241, val_MinusLogProbMetric: 397.0241

Epoch 329: val_loss did not improve from 395.02164
196/196 - 12s - loss: 394.4531 - MinusLogProbMetric: 394.4531 - val_loss: 397.0241 - val_MinusLogProbMetric: 397.0241 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 330/1000
2023-09-10 14:40:34.163 
Epoch 330/1000 
	 loss: 394.2151, MinusLogProbMetric: 394.2151, val_loss: 396.1015, val_MinusLogProbMetric: 396.1015

Epoch 330: val_loss did not improve from 395.02164
196/196 - 10s - loss: 394.2151 - MinusLogProbMetric: 394.2151 - val_loss: 396.1015 - val_MinusLogProbMetric: 396.1015 - lr: 1.6667e-04 - 10s/epoch - 54ms/step
Epoch 331/1000
2023-09-10 14:40:43.472 
Epoch 331/1000 
	 loss: 394.4189, MinusLogProbMetric: 394.4189, val_loss: 394.8865, val_MinusLogProbMetric: 394.8865

Epoch 331: val_loss improved from 395.02164 to 394.88654, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 394.4189 - MinusLogProbMetric: 394.4189 - val_loss: 394.8865 - val_MinusLogProbMetric: 394.8865 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 332/1000
2023-09-10 14:40:55.208 
Epoch 332/1000 
	 loss: 394.3140, MinusLogProbMetric: 394.3140, val_loss: 395.7613, val_MinusLogProbMetric: 395.7613

Epoch 332: val_loss did not improve from 394.88654
196/196 - 11s - loss: 394.3140 - MinusLogProbMetric: 394.3140 - val_loss: 395.7613 - val_MinusLogProbMetric: 395.7613 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 333/1000
2023-09-10 14:41:04.248 
Epoch 333/1000 
	 loss: 394.1059, MinusLogProbMetric: 394.1059, val_loss: 397.3961, val_MinusLogProbMetric: 397.3961

Epoch 333: val_loss did not improve from 394.88654
196/196 - 9s - loss: 394.1059 - MinusLogProbMetric: 394.1059 - val_loss: 397.3961 - val_MinusLogProbMetric: 397.3961 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 334/1000
2023-09-10 14:41:15.709 
Epoch 334/1000 
	 loss: 394.3421, MinusLogProbMetric: 394.3421, val_loss: 395.5047, val_MinusLogProbMetric: 395.5047

Epoch 334: val_loss did not improve from 394.88654
196/196 - 11s - loss: 394.3421 - MinusLogProbMetric: 394.3421 - val_loss: 395.5047 - val_MinusLogProbMetric: 395.5047 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 335/1000
2023-09-10 14:41:26.202 
Epoch 335/1000 
	 loss: 394.1884, MinusLogProbMetric: 394.1884, val_loss: 395.3903, val_MinusLogProbMetric: 395.3903

Epoch 335: val_loss did not improve from 394.88654
196/196 - 10s - loss: 394.1884 - MinusLogProbMetric: 394.1884 - val_loss: 395.3903 - val_MinusLogProbMetric: 395.3903 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 336/1000
2023-09-10 14:41:37.637 
Epoch 336/1000 
	 loss: 394.3838, MinusLogProbMetric: 394.3838, val_loss: 396.5013, val_MinusLogProbMetric: 396.5013

Epoch 336: val_loss did not improve from 394.88654
196/196 - 11s - loss: 394.3838 - MinusLogProbMetric: 394.3838 - val_loss: 396.5013 - val_MinusLogProbMetric: 396.5013 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 337/1000
2023-09-10 14:41:47.681 
Epoch 337/1000 
	 loss: 394.0391, MinusLogProbMetric: 394.0391, val_loss: 396.1583, val_MinusLogProbMetric: 396.1583

Epoch 337: val_loss did not improve from 394.88654
196/196 - 10s - loss: 394.0391 - MinusLogProbMetric: 394.0391 - val_loss: 396.1583 - val_MinusLogProbMetric: 396.1583 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 338/1000
2023-09-10 14:41:59.446 
Epoch 338/1000 
	 loss: 394.3502, MinusLogProbMetric: 394.3502, val_loss: 395.0060, val_MinusLogProbMetric: 395.0060

Epoch 338: val_loss did not improve from 394.88654
196/196 - 12s - loss: 394.3502 - MinusLogProbMetric: 394.3502 - val_loss: 395.0060 - val_MinusLogProbMetric: 395.0060 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 339/1000
2023-09-10 14:42:12.183 
Epoch 339/1000 
	 loss: 394.3140, MinusLogProbMetric: 394.3140, val_loss: 395.0325, val_MinusLogProbMetric: 395.0325

Epoch 339: val_loss did not improve from 394.88654
196/196 - 13s - loss: 394.3140 - MinusLogProbMetric: 394.3140 - val_loss: 395.0325 - val_MinusLogProbMetric: 395.0325 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 340/1000
2023-09-10 14:42:21.017 
Epoch 340/1000 
	 loss: 394.1042, MinusLogProbMetric: 394.1042, val_loss: 395.1531, val_MinusLogProbMetric: 395.1531

Epoch 340: val_loss did not improve from 394.88654
196/196 - 9s - loss: 394.1042 - MinusLogProbMetric: 394.1042 - val_loss: 395.1531 - val_MinusLogProbMetric: 395.1531 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 341/1000
2023-09-10 14:42:30.722 
Epoch 341/1000 
	 loss: 394.0299, MinusLogProbMetric: 394.0299, val_loss: 394.7480, val_MinusLogProbMetric: 394.7480

Epoch 341: val_loss improved from 394.88654 to 394.74796, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 394.0299 - MinusLogProbMetric: 394.0299 - val_loss: 394.7480 - val_MinusLogProbMetric: 394.7480 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 342/1000
2023-09-10 14:42:42.504 
Epoch 342/1000 
	 loss: 394.1313, MinusLogProbMetric: 394.1313, val_loss: 395.7654, val_MinusLogProbMetric: 395.7654

Epoch 342: val_loss did not improve from 394.74796
196/196 - 11s - loss: 394.1313 - MinusLogProbMetric: 394.1313 - val_loss: 395.7654 - val_MinusLogProbMetric: 395.7654 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 343/1000
2023-09-10 14:42:54.419 
Epoch 343/1000 
	 loss: 394.0404, MinusLogProbMetric: 394.0404, val_loss: 395.2008, val_MinusLogProbMetric: 395.2008

Epoch 343: val_loss did not improve from 394.74796
196/196 - 12s - loss: 394.0404 - MinusLogProbMetric: 394.0404 - val_loss: 395.2008 - val_MinusLogProbMetric: 395.2008 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 344/1000
2023-09-10 14:43:04.775 
Epoch 344/1000 
	 loss: 394.0463, MinusLogProbMetric: 394.0463, val_loss: 395.5164, val_MinusLogProbMetric: 395.5164

Epoch 344: val_loss did not improve from 394.74796
196/196 - 10s - loss: 394.0463 - MinusLogProbMetric: 394.0463 - val_loss: 395.5164 - val_MinusLogProbMetric: 395.5164 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 345/1000
2023-09-10 14:43:16.478 
Epoch 345/1000 
	 loss: 394.3010, MinusLogProbMetric: 394.3010, val_loss: 395.1565, val_MinusLogProbMetric: 395.1565

Epoch 345: val_loss did not improve from 394.74796
196/196 - 12s - loss: 394.3010 - MinusLogProbMetric: 394.3010 - val_loss: 395.1565 - val_MinusLogProbMetric: 395.1565 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 346/1000
2023-09-10 14:43:27.946 
Epoch 346/1000 
	 loss: 393.8827, MinusLogProbMetric: 393.8827, val_loss: 395.1790, val_MinusLogProbMetric: 395.1790

Epoch 346: val_loss did not improve from 394.74796
196/196 - 11s - loss: 393.8827 - MinusLogProbMetric: 393.8827 - val_loss: 395.1790 - val_MinusLogProbMetric: 395.1790 - lr: 1.6667e-04 - 11s/epoch - 59ms/step
Epoch 347/1000
2023-09-10 14:43:40.643 
Epoch 347/1000 
	 loss: 394.0426, MinusLogProbMetric: 394.0426, val_loss: 394.9728, val_MinusLogProbMetric: 394.9728

Epoch 347: val_loss did not improve from 394.74796
196/196 - 13s - loss: 394.0426 - MinusLogProbMetric: 394.0426 - val_loss: 394.9728 - val_MinusLogProbMetric: 394.9728 - lr: 1.6667e-04 - 13s/epoch - 65ms/step
Epoch 348/1000
2023-09-10 14:43:52.295 
Epoch 348/1000 
	 loss: 393.9721, MinusLogProbMetric: 393.9721, val_loss: 395.4697, val_MinusLogProbMetric: 395.4697

Epoch 348: val_loss did not improve from 394.74796
196/196 - 12s - loss: 393.9721 - MinusLogProbMetric: 393.9721 - val_loss: 395.4697 - val_MinusLogProbMetric: 395.4697 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 349/1000
2023-09-10 14:44:03.264 
Epoch 349/1000 
	 loss: 394.0185, MinusLogProbMetric: 394.0185, val_loss: 395.2867, val_MinusLogProbMetric: 395.2867

Epoch 349: val_loss did not improve from 394.74796
196/196 - 11s - loss: 394.0185 - MinusLogProbMetric: 394.0185 - val_loss: 395.2867 - val_MinusLogProbMetric: 395.2867 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 350/1000
2023-09-10 14:44:14.219 
Epoch 350/1000 
	 loss: 394.0299, MinusLogProbMetric: 394.0299, val_loss: 395.2783, val_MinusLogProbMetric: 395.2783

Epoch 350: val_loss did not improve from 394.74796
196/196 - 11s - loss: 394.0299 - MinusLogProbMetric: 394.0299 - val_loss: 395.2783 - val_MinusLogProbMetric: 395.2783 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 351/1000
2023-09-10 14:44:25.764 
Epoch 351/1000 
	 loss: 394.0691, MinusLogProbMetric: 394.0691, val_loss: 396.6816, val_MinusLogProbMetric: 396.6816

Epoch 351: val_loss did not improve from 394.74796
196/196 - 12s - loss: 394.0691 - MinusLogProbMetric: 394.0691 - val_loss: 396.6816 - val_MinusLogProbMetric: 396.6816 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 352/1000
2023-09-10 14:44:36.240 
Epoch 352/1000 
	 loss: 393.9578, MinusLogProbMetric: 393.9578, val_loss: 395.5594, val_MinusLogProbMetric: 395.5594

Epoch 352: val_loss did not improve from 394.74796
196/196 - 10s - loss: 393.9578 - MinusLogProbMetric: 393.9578 - val_loss: 395.5594 - val_MinusLogProbMetric: 395.5594 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 353/1000
2023-09-10 14:44:46.009 
Epoch 353/1000 
	 loss: 394.3930, MinusLogProbMetric: 394.3930, val_loss: 395.8571, val_MinusLogProbMetric: 395.8571

Epoch 353: val_loss did not improve from 394.74796
196/196 - 10s - loss: 394.3930 - MinusLogProbMetric: 394.3930 - val_loss: 395.8571 - val_MinusLogProbMetric: 395.8571 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 354/1000
2023-09-10 14:44:58.228 
Epoch 354/1000 
	 loss: 394.0661, MinusLogProbMetric: 394.0661, val_loss: 397.2224, val_MinusLogProbMetric: 397.2224

Epoch 354: val_loss did not improve from 394.74796
196/196 - 12s - loss: 394.0661 - MinusLogProbMetric: 394.0661 - val_loss: 397.2224 - val_MinusLogProbMetric: 397.2224 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 355/1000
2023-09-10 14:45:08.328 
Epoch 355/1000 
	 loss: 394.1232, MinusLogProbMetric: 394.1232, val_loss: 395.6893, val_MinusLogProbMetric: 395.6893

Epoch 355: val_loss did not improve from 394.74796
196/196 - 10s - loss: 394.1232 - MinusLogProbMetric: 394.1232 - val_loss: 395.6893 - val_MinusLogProbMetric: 395.6893 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 356/1000
2023-09-10 14:45:18.418 
Epoch 356/1000 
	 loss: 393.9197, MinusLogProbMetric: 393.9197, val_loss: 395.6179, val_MinusLogProbMetric: 395.6179

Epoch 356: val_loss did not improve from 394.74796
196/196 - 10s - loss: 393.9197 - MinusLogProbMetric: 393.9197 - val_loss: 395.6179 - val_MinusLogProbMetric: 395.6179 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 357/1000
2023-09-10 14:45:29.760 
Epoch 357/1000 
	 loss: 393.8316, MinusLogProbMetric: 393.8316, val_loss: 394.9350, val_MinusLogProbMetric: 394.9350

Epoch 357: val_loss did not improve from 394.74796
196/196 - 11s - loss: 393.8316 - MinusLogProbMetric: 393.8316 - val_loss: 394.9350 - val_MinusLogProbMetric: 394.9350 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 358/1000
2023-09-10 14:45:40.122 
Epoch 358/1000 
	 loss: 394.0088, MinusLogProbMetric: 394.0088, val_loss: 395.7298, val_MinusLogProbMetric: 395.7298

Epoch 358: val_loss did not improve from 394.74796
196/196 - 10s - loss: 394.0088 - MinusLogProbMetric: 394.0088 - val_loss: 395.7298 - val_MinusLogProbMetric: 395.7298 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 359/1000
2023-09-10 14:45:50.302 
Epoch 359/1000 
	 loss: 394.0282, MinusLogProbMetric: 394.0282, val_loss: 394.5801, val_MinusLogProbMetric: 394.5801

Epoch 359: val_loss improved from 394.74796 to 394.58008, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 394.0282 - MinusLogProbMetric: 394.0282 - val_loss: 394.5801 - val_MinusLogProbMetric: 394.5801 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 360/1000
2023-09-10 14:46:02.807 
Epoch 360/1000 
	 loss: 394.0077, MinusLogProbMetric: 394.0077, val_loss: 395.8543, val_MinusLogProbMetric: 395.8543

Epoch 360: val_loss did not improve from 394.58008
196/196 - 12s - loss: 394.0077 - MinusLogProbMetric: 394.0077 - val_loss: 395.8543 - val_MinusLogProbMetric: 395.8543 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 361/1000
2023-09-10 14:46:12.588 
Epoch 361/1000 
	 loss: 393.9764, MinusLogProbMetric: 393.9764, val_loss: 394.9740, val_MinusLogProbMetric: 394.9740

Epoch 361: val_loss did not improve from 394.58008
196/196 - 10s - loss: 393.9764 - MinusLogProbMetric: 393.9764 - val_loss: 394.9740 - val_MinusLogProbMetric: 394.9740 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 362/1000
2023-09-10 14:46:24.748 
Epoch 362/1000 
	 loss: 393.8241, MinusLogProbMetric: 393.8241, val_loss: 395.8595, val_MinusLogProbMetric: 395.8595

Epoch 362: val_loss did not improve from 394.58008
196/196 - 12s - loss: 393.8241 - MinusLogProbMetric: 393.8241 - val_loss: 395.8595 - val_MinusLogProbMetric: 395.8595 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 363/1000
2023-09-10 14:46:34.172 
Epoch 363/1000 
	 loss: 393.9064, MinusLogProbMetric: 393.9064, val_loss: 394.8829, val_MinusLogProbMetric: 394.8829

Epoch 363: val_loss did not improve from 394.58008
196/196 - 9s - loss: 393.9064 - MinusLogProbMetric: 393.9064 - val_loss: 394.8829 - val_MinusLogProbMetric: 394.8829 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 364/1000
2023-09-10 14:46:47.168 
Epoch 364/1000 
	 loss: 393.8395, MinusLogProbMetric: 393.8395, val_loss: 394.7267, val_MinusLogProbMetric: 394.7267

Epoch 364: val_loss did not improve from 394.58008
196/196 - 13s - loss: 393.8395 - MinusLogProbMetric: 393.8395 - val_loss: 394.7267 - val_MinusLogProbMetric: 394.7267 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 365/1000
2023-09-10 14:46:56.168 
Epoch 365/1000 
	 loss: 393.8001, MinusLogProbMetric: 393.8001, val_loss: 395.5102, val_MinusLogProbMetric: 395.5102

Epoch 365: val_loss did not improve from 394.58008
196/196 - 9s - loss: 393.8001 - MinusLogProbMetric: 393.8001 - val_loss: 395.5102 - val_MinusLogProbMetric: 395.5102 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 366/1000
2023-09-10 14:47:07.142 
Epoch 366/1000 
	 loss: 393.8186, MinusLogProbMetric: 393.8186, val_loss: 395.0507, val_MinusLogProbMetric: 395.0507

Epoch 366: val_loss did not improve from 394.58008
196/196 - 11s - loss: 393.8186 - MinusLogProbMetric: 393.8186 - val_loss: 395.0507 - val_MinusLogProbMetric: 395.0507 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 367/1000
2023-09-10 14:47:15.928 
Epoch 367/1000 
	 loss: 393.7957, MinusLogProbMetric: 393.7957, val_loss: 394.5825, val_MinusLogProbMetric: 394.5825

Epoch 367: val_loss did not improve from 394.58008
196/196 - 9s - loss: 393.7957 - MinusLogProbMetric: 393.7957 - val_loss: 394.5825 - val_MinusLogProbMetric: 394.5825 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 368/1000
2023-09-10 14:47:26.596 
Epoch 368/1000 
	 loss: 393.8723, MinusLogProbMetric: 393.8723, val_loss: 396.2816, val_MinusLogProbMetric: 396.2816

Epoch 368: val_loss did not improve from 394.58008
196/196 - 11s - loss: 393.8723 - MinusLogProbMetric: 393.8723 - val_loss: 396.2816 - val_MinusLogProbMetric: 396.2816 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 369/1000
2023-09-10 14:47:36.650 
Epoch 369/1000 
	 loss: 393.8069, MinusLogProbMetric: 393.8069, val_loss: 395.0012, val_MinusLogProbMetric: 395.0012

Epoch 369: val_loss did not improve from 394.58008
196/196 - 10s - loss: 393.8069 - MinusLogProbMetric: 393.8069 - val_loss: 395.0012 - val_MinusLogProbMetric: 395.0012 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 370/1000
2023-09-10 14:47:51.448 
Epoch 370/1000 
	 loss: 393.8234, MinusLogProbMetric: 393.8234, val_loss: 395.1169, val_MinusLogProbMetric: 395.1169

Epoch 370: val_loss did not improve from 394.58008
196/196 - 15s - loss: 393.8234 - MinusLogProbMetric: 393.8234 - val_loss: 395.1169 - val_MinusLogProbMetric: 395.1169 - lr: 1.6667e-04 - 15s/epoch - 75ms/step
Epoch 371/1000
2023-09-10 14:48:04.826 
Epoch 371/1000 
	 loss: 393.6805, MinusLogProbMetric: 393.6805, val_loss: 396.5082, val_MinusLogProbMetric: 396.5082

Epoch 371: val_loss did not improve from 394.58008
196/196 - 13s - loss: 393.6805 - MinusLogProbMetric: 393.6805 - val_loss: 396.5082 - val_MinusLogProbMetric: 396.5082 - lr: 1.6667e-04 - 13s/epoch - 68ms/step
Epoch 372/1000
2023-09-10 14:48:15.088 
Epoch 372/1000 
	 loss: 393.7792, MinusLogProbMetric: 393.7792, val_loss: 394.6535, val_MinusLogProbMetric: 394.6535

Epoch 372: val_loss did not improve from 394.58008
196/196 - 10s - loss: 393.7792 - MinusLogProbMetric: 393.7792 - val_loss: 394.6535 - val_MinusLogProbMetric: 394.6535 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 373/1000
2023-09-10 14:48:26.371 
Epoch 373/1000 
	 loss: 393.8847, MinusLogProbMetric: 393.8847, val_loss: 394.9711, val_MinusLogProbMetric: 394.9711

Epoch 373: val_loss did not improve from 394.58008
196/196 - 11s - loss: 393.8847 - MinusLogProbMetric: 393.8847 - val_loss: 394.9711 - val_MinusLogProbMetric: 394.9711 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 374/1000
2023-09-10 14:48:37.091 
Epoch 374/1000 
	 loss: 393.9850, MinusLogProbMetric: 393.9850, val_loss: 394.7042, val_MinusLogProbMetric: 394.7042

Epoch 374: val_loss did not improve from 394.58008
196/196 - 11s - loss: 393.9850 - MinusLogProbMetric: 393.9850 - val_loss: 394.7042 - val_MinusLogProbMetric: 394.7042 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 375/1000
2023-09-10 14:48:49.666 
Epoch 375/1000 
	 loss: 393.5974, MinusLogProbMetric: 393.5974, val_loss: 395.3031, val_MinusLogProbMetric: 395.3031

Epoch 375: val_loss did not improve from 394.58008
196/196 - 13s - loss: 393.5974 - MinusLogProbMetric: 393.5974 - val_loss: 395.3031 - val_MinusLogProbMetric: 395.3031 - lr: 1.6667e-04 - 13s/epoch - 64ms/step
Epoch 376/1000
2023-09-10 14:49:01.368 
Epoch 376/1000 
	 loss: 393.7247, MinusLogProbMetric: 393.7247, val_loss: 397.0427, val_MinusLogProbMetric: 397.0427

Epoch 376: val_loss did not improve from 394.58008
196/196 - 12s - loss: 393.7247 - MinusLogProbMetric: 393.7247 - val_loss: 397.0427 - val_MinusLogProbMetric: 397.0427 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 377/1000
2023-09-10 14:49:11.583 
Epoch 377/1000 
	 loss: 393.7203, MinusLogProbMetric: 393.7203, val_loss: 394.6493, val_MinusLogProbMetric: 394.6493

Epoch 377: val_loss did not improve from 394.58008
196/196 - 10s - loss: 393.7203 - MinusLogProbMetric: 393.7203 - val_loss: 394.6493 - val_MinusLogProbMetric: 394.6493 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 378/1000
2023-09-10 14:49:23.808 
Epoch 378/1000 
	 loss: 393.7746, MinusLogProbMetric: 393.7746, val_loss: 394.7124, val_MinusLogProbMetric: 394.7124

Epoch 378: val_loss did not improve from 394.58008
196/196 - 12s - loss: 393.7746 - MinusLogProbMetric: 393.7746 - val_loss: 394.7124 - val_MinusLogProbMetric: 394.7124 - lr: 1.6667e-04 - 12s/epoch - 62ms/step
Epoch 379/1000
2023-09-10 14:49:34.908 
Epoch 379/1000 
	 loss: 393.7341, MinusLogProbMetric: 393.7341, val_loss: 396.3015, val_MinusLogProbMetric: 396.3015

Epoch 379: val_loss did not improve from 394.58008
196/196 - 11s - loss: 393.7341 - MinusLogProbMetric: 393.7341 - val_loss: 396.3015 - val_MinusLogProbMetric: 396.3015 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 380/1000
2023-09-10 14:49:45.478 
Epoch 380/1000 
	 loss: 393.8782, MinusLogProbMetric: 393.8782, val_loss: 395.7029, val_MinusLogProbMetric: 395.7029

Epoch 380: val_loss did not improve from 394.58008
196/196 - 11s - loss: 393.8782 - MinusLogProbMetric: 393.8782 - val_loss: 395.7029 - val_MinusLogProbMetric: 395.7029 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 381/1000
2023-09-10 14:49:54.883 
Epoch 381/1000 
	 loss: 393.7814, MinusLogProbMetric: 393.7814, val_loss: 394.7431, val_MinusLogProbMetric: 394.7431

Epoch 381: val_loss did not improve from 394.58008
196/196 - 9s - loss: 393.7814 - MinusLogProbMetric: 393.7814 - val_loss: 394.7431 - val_MinusLogProbMetric: 394.7431 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 382/1000
2023-09-10 14:50:04.200 
Epoch 382/1000 
	 loss: 393.5056, MinusLogProbMetric: 393.5056, val_loss: 395.4333, val_MinusLogProbMetric: 395.4333

Epoch 382: val_loss did not improve from 394.58008
196/196 - 9s - loss: 393.5056 - MinusLogProbMetric: 393.5056 - val_loss: 395.4333 - val_MinusLogProbMetric: 395.4333 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 383/1000
2023-09-10 14:50:16.142 
Epoch 383/1000 
	 loss: 393.5248, MinusLogProbMetric: 393.5248, val_loss: 394.9441, val_MinusLogProbMetric: 394.9441

Epoch 383: val_loss did not improve from 394.58008
196/196 - 12s - loss: 393.5248 - MinusLogProbMetric: 393.5248 - val_loss: 394.9441 - val_MinusLogProbMetric: 394.9441 - lr: 1.6667e-04 - 12s/epoch - 61ms/step
Epoch 384/1000
2023-09-10 14:50:26.838 
Epoch 384/1000 
	 loss: 393.6245, MinusLogProbMetric: 393.6245, val_loss: 395.9520, val_MinusLogProbMetric: 395.9520

Epoch 384: val_loss did not improve from 394.58008
196/196 - 11s - loss: 393.6245 - MinusLogProbMetric: 393.6245 - val_loss: 395.9520 - val_MinusLogProbMetric: 395.9520 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 385/1000
2023-09-10 14:50:36.863 
Epoch 385/1000 
	 loss: 393.5699, MinusLogProbMetric: 393.5699, val_loss: 395.1333, val_MinusLogProbMetric: 395.1333

Epoch 385: val_loss did not improve from 394.58008
196/196 - 10s - loss: 393.5699 - MinusLogProbMetric: 393.5699 - val_loss: 395.1333 - val_MinusLogProbMetric: 395.1333 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 386/1000
2023-09-10 14:50:47.001 
Epoch 386/1000 
	 loss: 393.8207, MinusLogProbMetric: 393.8207, val_loss: 395.1342, val_MinusLogProbMetric: 395.1342

Epoch 386: val_loss did not improve from 394.58008
196/196 - 10s - loss: 393.8207 - MinusLogProbMetric: 393.8207 - val_loss: 395.1342 - val_MinusLogProbMetric: 395.1342 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 387/1000
2023-09-10 14:50:56.211 
Epoch 387/1000 
	 loss: 393.5563, MinusLogProbMetric: 393.5563, val_loss: 396.2345, val_MinusLogProbMetric: 396.2345

Epoch 387: val_loss did not improve from 394.58008
196/196 - 9s - loss: 393.5563 - MinusLogProbMetric: 393.5563 - val_loss: 396.2345 - val_MinusLogProbMetric: 396.2345 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 388/1000
2023-09-10 14:51:08.800 
Epoch 388/1000 
	 loss: 393.2900, MinusLogProbMetric: 393.2900, val_loss: 394.5277, val_MinusLogProbMetric: 394.5277

Epoch 388: val_loss improved from 394.58008 to 394.52771, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 13s - loss: 393.2900 - MinusLogProbMetric: 393.2900 - val_loss: 394.5277 - val_MinusLogProbMetric: 394.5277 - lr: 1.6667e-04 - 13s/epoch - 66ms/step
Epoch 389/1000
2023-09-10 14:51:18.680 
Epoch 389/1000 
	 loss: 393.8210, MinusLogProbMetric: 393.8210, val_loss: 394.5818, val_MinusLogProbMetric: 394.5818

Epoch 389: val_loss did not improve from 394.52771
196/196 - 10s - loss: 393.8210 - MinusLogProbMetric: 393.8210 - val_loss: 394.5818 - val_MinusLogProbMetric: 394.5818 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 390/1000
2023-09-10 14:51:30.364 
Epoch 390/1000 
	 loss: 393.5189, MinusLogProbMetric: 393.5189, val_loss: 395.7970, val_MinusLogProbMetric: 395.7970

Epoch 390: val_loss did not improve from 394.52771
196/196 - 12s - loss: 393.5189 - MinusLogProbMetric: 393.5189 - val_loss: 395.7970 - val_MinusLogProbMetric: 395.7970 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 391/1000
2023-09-10 14:51:40.273 
Epoch 391/1000 
	 loss: 393.2505, MinusLogProbMetric: 393.2505, val_loss: 394.5797, val_MinusLogProbMetric: 394.5797

Epoch 391: val_loss did not improve from 394.52771
196/196 - 10s - loss: 393.2505 - MinusLogProbMetric: 393.2505 - val_loss: 394.5797 - val_MinusLogProbMetric: 394.5797 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 392/1000
2023-09-10 14:51:49.731 
Epoch 392/1000 
	 loss: 393.7862, MinusLogProbMetric: 393.7862, val_loss: 394.9069, val_MinusLogProbMetric: 394.9069

Epoch 392: val_loss did not improve from 394.52771
196/196 - 9s - loss: 393.7862 - MinusLogProbMetric: 393.7862 - val_loss: 394.9069 - val_MinusLogProbMetric: 394.9069 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 393/1000
2023-09-10 14:51:58.588 
Epoch 393/1000 
	 loss: 393.5632, MinusLogProbMetric: 393.5632, val_loss: 394.6764, val_MinusLogProbMetric: 394.6764

Epoch 393: val_loss did not improve from 394.52771
196/196 - 9s - loss: 393.5632 - MinusLogProbMetric: 393.5632 - val_loss: 394.6764 - val_MinusLogProbMetric: 394.6764 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 394/1000
2023-09-10 14:52:07.939 
Epoch 394/1000 
	 loss: 393.3725, MinusLogProbMetric: 393.3725, val_loss: 394.8915, val_MinusLogProbMetric: 394.8915

Epoch 394: val_loss did not improve from 394.52771
196/196 - 9s - loss: 393.3725 - MinusLogProbMetric: 393.3725 - val_loss: 394.8915 - val_MinusLogProbMetric: 394.8915 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 395/1000
2023-09-10 14:52:17.639 
Epoch 395/1000 
	 loss: 393.4032, MinusLogProbMetric: 393.4032, val_loss: 394.6133, val_MinusLogProbMetric: 394.6133

Epoch 395: val_loss did not improve from 394.52771
196/196 - 10s - loss: 393.4032 - MinusLogProbMetric: 393.4032 - val_loss: 394.6133 - val_MinusLogProbMetric: 394.6133 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 396/1000
2023-09-10 14:52:26.221 
Epoch 396/1000 
	 loss: 393.5497, MinusLogProbMetric: 393.5497, val_loss: 394.7443, val_MinusLogProbMetric: 394.7443

Epoch 396: val_loss did not improve from 394.52771
196/196 - 9s - loss: 393.5497 - MinusLogProbMetric: 393.5497 - val_loss: 394.7443 - val_MinusLogProbMetric: 394.7443 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 397/1000
2023-09-10 14:52:37.759 
Epoch 397/1000 
	 loss: 393.3616, MinusLogProbMetric: 393.3616, val_loss: 394.7824, val_MinusLogProbMetric: 394.7824

Epoch 397: val_loss did not improve from 394.52771
196/196 - 12s - loss: 393.3616 - MinusLogProbMetric: 393.3616 - val_loss: 394.7824 - val_MinusLogProbMetric: 394.7824 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 398/1000
2023-09-10 14:52:48.229 
Epoch 398/1000 
	 loss: 393.6940, MinusLogProbMetric: 393.6940, val_loss: 394.2047, val_MinusLogProbMetric: 394.2047

Epoch 398: val_loss improved from 394.52771 to 394.20471, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 393.6940 - MinusLogProbMetric: 393.6940 - val_loss: 394.2047 - val_MinusLogProbMetric: 394.2047 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 399/1000
2023-09-10 14:52:59.602 
Epoch 399/1000 
	 loss: 393.3444, MinusLogProbMetric: 393.3444, val_loss: 394.4484, val_MinusLogProbMetric: 394.4484

Epoch 399: val_loss did not improve from 394.20471
196/196 - 11s - loss: 393.3444 - MinusLogProbMetric: 393.3444 - val_loss: 394.4484 - val_MinusLogProbMetric: 394.4484 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 400/1000
2023-09-10 14:53:10.310 
Epoch 400/1000 
	 loss: 393.6943, MinusLogProbMetric: 393.6943, val_loss: 395.7142, val_MinusLogProbMetric: 395.7142

Epoch 400: val_loss did not improve from 394.20471
196/196 - 11s - loss: 393.6943 - MinusLogProbMetric: 393.6943 - val_loss: 395.7142 - val_MinusLogProbMetric: 395.7142 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 401/1000
2023-09-10 14:53:20.950 
Epoch 401/1000 
	 loss: 393.5974, MinusLogProbMetric: 393.5974, val_loss: 394.0619, val_MinusLogProbMetric: 394.0619

Epoch 401: val_loss improved from 394.20471 to 394.06192, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 393.5974 - MinusLogProbMetric: 393.5974 - val_loss: 394.0619 - val_MinusLogProbMetric: 394.0619 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 402/1000
2023-09-10 14:53:30.241 
Epoch 402/1000 
	 loss: 393.4418, MinusLogProbMetric: 393.4418, val_loss: 394.8525, val_MinusLogProbMetric: 394.8525

Epoch 402: val_loss did not improve from 394.06192
196/196 - 9s - loss: 393.4418 - MinusLogProbMetric: 393.4418 - val_loss: 394.8525 - val_MinusLogProbMetric: 394.8525 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 403/1000
2023-09-10 14:53:40.541 
Epoch 403/1000 
	 loss: 393.5251, MinusLogProbMetric: 393.5251, val_loss: 394.4620, val_MinusLogProbMetric: 394.4620

Epoch 403: val_loss did not improve from 394.06192
196/196 - 10s - loss: 393.5251 - MinusLogProbMetric: 393.5251 - val_loss: 394.4620 - val_MinusLogProbMetric: 394.4620 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 404/1000
2023-09-10 14:53:49.929 
Epoch 404/1000 
	 loss: 393.2746, MinusLogProbMetric: 393.2746, val_loss: 399.6119, val_MinusLogProbMetric: 399.6119

Epoch 404: val_loss did not improve from 394.06192
196/196 - 9s - loss: 393.2746 - MinusLogProbMetric: 393.2746 - val_loss: 399.6119 - val_MinusLogProbMetric: 399.6119 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 405/1000
2023-09-10 14:54:01.398 
Epoch 405/1000 
	 loss: 393.1716, MinusLogProbMetric: 393.1716, val_loss: 395.1263, val_MinusLogProbMetric: 395.1263

Epoch 405: val_loss did not improve from 394.06192
196/196 - 11s - loss: 393.1716 - MinusLogProbMetric: 393.1716 - val_loss: 395.1263 - val_MinusLogProbMetric: 395.1263 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 406/1000
2023-09-10 14:54:11.200 
Epoch 406/1000 
	 loss: 393.3880, MinusLogProbMetric: 393.3880, val_loss: 395.5826, val_MinusLogProbMetric: 395.5826

Epoch 406: val_loss did not improve from 394.06192
196/196 - 10s - loss: 393.3880 - MinusLogProbMetric: 393.3880 - val_loss: 395.5826 - val_MinusLogProbMetric: 395.5826 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 407/1000
2023-09-10 14:54:21.278 
Epoch 407/1000 
	 loss: 393.4556, MinusLogProbMetric: 393.4556, val_loss: 394.7688, val_MinusLogProbMetric: 394.7688

Epoch 407: val_loss did not improve from 394.06192
196/196 - 10s - loss: 393.4556 - MinusLogProbMetric: 393.4556 - val_loss: 394.7688 - val_MinusLogProbMetric: 394.7688 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 408/1000
2023-09-10 14:54:30.473 
Epoch 408/1000 
	 loss: 393.2336, MinusLogProbMetric: 393.2336, val_loss: 394.0562, val_MinusLogProbMetric: 394.0562

Epoch 408: val_loss improved from 394.06192 to 394.05621, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 393.2336 - MinusLogProbMetric: 393.2336 - val_loss: 394.0562 - val_MinusLogProbMetric: 394.0562 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 409/1000
2023-09-10 14:54:40.063 
Epoch 409/1000 
	 loss: 393.2692, MinusLogProbMetric: 393.2692, val_loss: 395.7896, val_MinusLogProbMetric: 395.7896

Epoch 409: val_loss did not improve from 394.05621
196/196 - 9s - loss: 393.2692 - MinusLogProbMetric: 393.2692 - val_loss: 395.7896 - val_MinusLogProbMetric: 395.7896 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 410/1000
2023-09-10 14:54:51.026 
Epoch 410/1000 
	 loss: 393.5572, MinusLogProbMetric: 393.5572, val_loss: 394.6271, val_MinusLogProbMetric: 394.6271

Epoch 410: val_loss did not improve from 394.05621
196/196 - 11s - loss: 393.5572 - MinusLogProbMetric: 393.5572 - val_loss: 394.6271 - val_MinusLogProbMetric: 394.6271 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 411/1000
2023-09-10 14:55:00.123 
Epoch 411/1000 
	 loss: 393.3573, MinusLogProbMetric: 393.3573, val_loss: 394.9983, val_MinusLogProbMetric: 394.9983

Epoch 411: val_loss did not improve from 394.05621
196/196 - 9s - loss: 393.3573 - MinusLogProbMetric: 393.3573 - val_loss: 394.9983 - val_MinusLogProbMetric: 394.9983 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 412/1000
2023-09-10 14:55:09.973 
Epoch 412/1000 
	 loss: 393.3254, MinusLogProbMetric: 393.3254, val_loss: 394.8764, val_MinusLogProbMetric: 394.8764

Epoch 412: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.3254 - MinusLogProbMetric: 393.3254 - val_loss: 394.8764 - val_MinusLogProbMetric: 394.8764 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 413/1000
2023-09-10 14:55:18.489 
Epoch 413/1000 
	 loss: 393.6080, MinusLogProbMetric: 393.6080, val_loss: 395.3240, val_MinusLogProbMetric: 395.3240

Epoch 413: val_loss did not improve from 394.05621
196/196 - 9s - loss: 393.6080 - MinusLogProbMetric: 393.6080 - val_loss: 395.3240 - val_MinusLogProbMetric: 395.3240 - lr: 1.6667e-04 - 9s/epoch - 43ms/step
Epoch 414/1000
2023-09-10 14:55:28.518 
Epoch 414/1000 
	 loss: 393.4106, MinusLogProbMetric: 393.4106, val_loss: 394.7637, val_MinusLogProbMetric: 394.7637

Epoch 414: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.4106 - MinusLogProbMetric: 393.4106 - val_loss: 394.7637 - val_MinusLogProbMetric: 394.7637 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 415/1000
2023-09-10 14:55:38.920 
Epoch 415/1000 
	 loss: 393.1913, MinusLogProbMetric: 393.1913, val_loss: 394.9619, val_MinusLogProbMetric: 394.9619

Epoch 415: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.1913 - MinusLogProbMetric: 393.1913 - val_loss: 394.9619 - val_MinusLogProbMetric: 394.9619 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 416/1000
2023-09-10 14:55:49.944 
Epoch 416/1000 
	 loss: 393.2222, MinusLogProbMetric: 393.2222, val_loss: 395.7504, val_MinusLogProbMetric: 395.7504

Epoch 416: val_loss did not improve from 394.05621
196/196 - 11s - loss: 393.2222 - MinusLogProbMetric: 393.2222 - val_loss: 395.7504 - val_MinusLogProbMetric: 395.7504 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 417/1000
2023-09-10 14:55:59.941 
Epoch 417/1000 
	 loss: 393.4124, MinusLogProbMetric: 393.4124, val_loss: 394.7871, val_MinusLogProbMetric: 394.7871

Epoch 417: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.4124 - MinusLogProbMetric: 393.4124 - val_loss: 394.7871 - val_MinusLogProbMetric: 394.7871 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 418/1000
2023-09-10 14:56:11.049 
Epoch 418/1000 
	 loss: 392.9824, MinusLogProbMetric: 392.9824, val_loss: 394.9370, val_MinusLogProbMetric: 394.9370

Epoch 418: val_loss did not improve from 394.05621
196/196 - 11s - loss: 392.9824 - MinusLogProbMetric: 392.9824 - val_loss: 394.9370 - val_MinusLogProbMetric: 394.9370 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 419/1000
2023-09-10 14:56:21.030 
Epoch 419/1000 
	 loss: 393.2355, MinusLogProbMetric: 393.2355, val_loss: 394.6811, val_MinusLogProbMetric: 394.6811

Epoch 419: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.2355 - MinusLogProbMetric: 393.2355 - val_loss: 394.6811 - val_MinusLogProbMetric: 394.6811 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 420/1000
2023-09-10 14:56:31.122 
Epoch 420/1000 
	 loss: 393.1671, MinusLogProbMetric: 393.1671, val_loss: 394.2897, val_MinusLogProbMetric: 394.2897

Epoch 420: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.1671 - MinusLogProbMetric: 393.1671 - val_loss: 394.2897 - val_MinusLogProbMetric: 394.2897 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 421/1000
2023-09-10 14:56:40.539 
Epoch 421/1000 
	 loss: 393.1211, MinusLogProbMetric: 393.1211, val_loss: 394.3453, val_MinusLogProbMetric: 394.3453

Epoch 421: val_loss did not improve from 394.05621
196/196 - 9s - loss: 393.1211 - MinusLogProbMetric: 393.1211 - val_loss: 394.3453 - val_MinusLogProbMetric: 394.3453 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 422/1000
2023-09-10 14:56:49.139 
Epoch 422/1000 
	 loss: 393.2635, MinusLogProbMetric: 393.2635, val_loss: 394.2157, val_MinusLogProbMetric: 394.2157

Epoch 422: val_loss did not improve from 394.05621
196/196 - 9s - loss: 393.2635 - MinusLogProbMetric: 393.2635 - val_loss: 394.2157 - val_MinusLogProbMetric: 394.2157 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 423/1000
2023-09-10 14:57:01.673 
Epoch 423/1000 
	 loss: 393.5353, MinusLogProbMetric: 393.5353, val_loss: 395.6226, val_MinusLogProbMetric: 395.6226

Epoch 423: val_loss did not improve from 394.05621
196/196 - 13s - loss: 393.5353 - MinusLogProbMetric: 393.5353 - val_loss: 395.6226 - val_MinusLogProbMetric: 395.6226 - lr: 1.6667e-04 - 13s/epoch - 64ms/step
Epoch 424/1000
2023-09-10 14:57:13.046 
Epoch 424/1000 
	 loss: 393.2965, MinusLogProbMetric: 393.2965, val_loss: 395.2095, val_MinusLogProbMetric: 395.2095

Epoch 424: val_loss did not improve from 394.05621
196/196 - 11s - loss: 393.2965 - MinusLogProbMetric: 393.2965 - val_loss: 395.2095 - val_MinusLogProbMetric: 395.2095 - lr: 1.6667e-04 - 11s/epoch - 58ms/step
Epoch 425/1000
2023-09-10 14:57:23.098 
Epoch 425/1000 
	 loss: 393.4118, MinusLogProbMetric: 393.4118, val_loss: 396.6720, val_MinusLogProbMetric: 396.6720

Epoch 425: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.4118 - MinusLogProbMetric: 393.4118 - val_loss: 396.6720 - val_MinusLogProbMetric: 396.6720 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 426/1000
2023-09-10 14:57:33.149 
Epoch 426/1000 
	 loss: 393.0835, MinusLogProbMetric: 393.0835, val_loss: 395.0600, val_MinusLogProbMetric: 395.0600

Epoch 426: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.0835 - MinusLogProbMetric: 393.0835 - val_loss: 395.0600 - val_MinusLogProbMetric: 395.0600 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 427/1000
2023-09-10 14:57:44.319 
Epoch 427/1000 
	 loss: 393.1696, MinusLogProbMetric: 393.1696, val_loss: 394.2166, val_MinusLogProbMetric: 394.2166

Epoch 427: val_loss did not improve from 394.05621
196/196 - 11s - loss: 393.1696 - MinusLogProbMetric: 393.1696 - val_loss: 394.2166 - val_MinusLogProbMetric: 394.2166 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 428/1000
2023-09-10 14:57:53.707 
Epoch 428/1000 
	 loss: 393.1178, MinusLogProbMetric: 393.1178, val_loss: 394.0563, val_MinusLogProbMetric: 394.0563

Epoch 428: val_loss did not improve from 394.05621
196/196 - 9s - loss: 393.1178 - MinusLogProbMetric: 393.1178 - val_loss: 394.0563 - val_MinusLogProbMetric: 394.0563 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 429/1000
2023-09-10 14:58:03.651 
Epoch 429/1000 
	 loss: 393.2252, MinusLogProbMetric: 393.2252, val_loss: 395.0664, val_MinusLogProbMetric: 395.0664

Epoch 429: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.2252 - MinusLogProbMetric: 393.2252 - val_loss: 395.0664 - val_MinusLogProbMetric: 395.0664 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 430/1000
2023-09-10 14:58:13.936 
Epoch 430/1000 
	 loss: 393.2374, MinusLogProbMetric: 393.2374, val_loss: 394.0739, val_MinusLogProbMetric: 394.0739

Epoch 430: val_loss did not improve from 394.05621
196/196 - 10s - loss: 393.2374 - MinusLogProbMetric: 393.2374 - val_loss: 394.0739 - val_MinusLogProbMetric: 394.0739 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 431/1000
2023-09-10 14:58:24.465 
Epoch 431/1000 
	 loss: 393.1021, MinusLogProbMetric: 393.1021, val_loss: 396.0886, val_MinusLogProbMetric: 396.0886

Epoch 431: val_loss did not improve from 394.05621
196/196 - 11s - loss: 393.1021 - MinusLogProbMetric: 393.1021 - val_loss: 396.0886 - val_MinusLogProbMetric: 396.0886 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 432/1000
2023-09-10 14:58:34.136 
Epoch 432/1000 
	 loss: 392.8930, MinusLogProbMetric: 392.8930, val_loss: 393.9182, val_MinusLogProbMetric: 393.9182

Epoch 432: val_loss improved from 394.05621 to 393.91824, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 392.8930 - MinusLogProbMetric: 392.8930 - val_loss: 393.9182 - val_MinusLogProbMetric: 393.9182 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 433/1000
2023-09-10 14:58:44.525 
Epoch 433/1000 
	 loss: 393.4012, MinusLogProbMetric: 393.4012, val_loss: 394.6407, val_MinusLogProbMetric: 394.6407

Epoch 433: val_loss did not improve from 393.91824
196/196 - 10s - loss: 393.4012 - MinusLogProbMetric: 393.4012 - val_loss: 394.6407 - val_MinusLogProbMetric: 394.6407 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 434/1000
2023-09-10 14:58:53.788 
Epoch 434/1000 
	 loss: 393.0013, MinusLogProbMetric: 393.0013, val_loss: 396.2348, val_MinusLogProbMetric: 396.2348

Epoch 434: val_loss did not improve from 393.91824
196/196 - 9s - loss: 393.0013 - MinusLogProbMetric: 393.0013 - val_loss: 396.2348 - val_MinusLogProbMetric: 396.2348 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 435/1000
2023-09-10 14:59:03.528 
Epoch 435/1000 
	 loss: 393.1020, MinusLogProbMetric: 393.1020, val_loss: 394.5943, val_MinusLogProbMetric: 394.5943

Epoch 435: val_loss did not improve from 393.91824
196/196 - 10s - loss: 393.1020 - MinusLogProbMetric: 393.1020 - val_loss: 394.5943 - val_MinusLogProbMetric: 394.5943 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 436/1000
2023-09-10 14:59:11.994 
Epoch 436/1000 
	 loss: 393.4042, MinusLogProbMetric: 393.4042, val_loss: 394.2807, val_MinusLogProbMetric: 394.2807

Epoch 436: val_loss did not improve from 393.91824
196/196 - 8s - loss: 393.4042 - MinusLogProbMetric: 393.4042 - val_loss: 394.2807 - val_MinusLogProbMetric: 394.2807 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 437/1000
2023-09-10 14:59:22.712 
Epoch 437/1000 
	 loss: 393.1692, MinusLogProbMetric: 393.1692, val_loss: 395.7965, val_MinusLogProbMetric: 395.7965

Epoch 437: val_loss did not improve from 393.91824
196/196 - 11s - loss: 393.1692 - MinusLogProbMetric: 393.1692 - val_loss: 395.7965 - val_MinusLogProbMetric: 395.7965 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 438/1000
2023-09-10 14:59:32.890 
Epoch 438/1000 
	 loss: 393.0591, MinusLogProbMetric: 393.0591, val_loss: 394.4462, val_MinusLogProbMetric: 394.4462

Epoch 438: val_loss did not improve from 393.91824
196/196 - 10s - loss: 393.0591 - MinusLogProbMetric: 393.0591 - val_loss: 394.4462 - val_MinusLogProbMetric: 394.4462 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 439/1000
2023-09-10 14:59:44.738 
Epoch 439/1000 
	 loss: 392.8553, MinusLogProbMetric: 392.8553, val_loss: 395.0863, val_MinusLogProbMetric: 395.0863

Epoch 439: val_loss did not improve from 393.91824
196/196 - 12s - loss: 392.8553 - MinusLogProbMetric: 392.8553 - val_loss: 395.0863 - val_MinusLogProbMetric: 395.0863 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 440/1000
2023-09-10 14:59:56.370 
Epoch 440/1000 
	 loss: 392.9790, MinusLogProbMetric: 392.9790, val_loss: 393.9716, val_MinusLogProbMetric: 393.9716

Epoch 440: val_loss did not improve from 393.91824
196/196 - 12s - loss: 392.9790 - MinusLogProbMetric: 392.9790 - val_loss: 393.9716 - val_MinusLogProbMetric: 393.9716 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 441/1000
2023-09-10 15:00:06.938 
Epoch 441/1000 
	 loss: 392.9505, MinusLogProbMetric: 392.9505, val_loss: 394.5864, val_MinusLogProbMetric: 394.5864

Epoch 441: val_loss did not improve from 393.91824
196/196 - 11s - loss: 392.9505 - MinusLogProbMetric: 392.9505 - val_loss: 394.5864 - val_MinusLogProbMetric: 394.5864 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 442/1000
2023-09-10 15:00:16.371 
Epoch 442/1000 
	 loss: 393.0981, MinusLogProbMetric: 393.0981, val_loss: 397.9586, val_MinusLogProbMetric: 397.9586

Epoch 442: val_loss did not improve from 393.91824
196/196 - 9s - loss: 393.0981 - MinusLogProbMetric: 393.0981 - val_loss: 397.9586 - val_MinusLogProbMetric: 397.9586 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 443/1000
2023-09-10 15:00:26.598 
Epoch 443/1000 
	 loss: 393.1189, MinusLogProbMetric: 393.1189, val_loss: 394.5947, val_MinusLogProbMetric: 394.5947

Epoch 443: val_loss did not improve from 393.91824
196/196 - 10s - loss: 393.1189 - MinusLogProbMetric: 393.1189 - val_loss: 394.5947 - val_MinusLogProbMetric: 394.5947 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 444/1000
2023-09-10 15:00:36.089 
Epoch 444/1000 
	 loss: 393.1274, MinusLogProbMetric: 393.1274, val_loss: 394.6266, val_MinusLogProbMetric: 394.6266

Epoch 444: val_loss did not improve from 393.91824
196/196 - 9s - loss: 393.1274 - MinusLogProbMetric: 393.1274 - val_loss: 394.6266 - val_MinusLogProbMetric: 394.6266 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 445/1000
2023-09-10 15:00:45.912 
Epoch 445/1000 
	 loss: 393.1655, MinusLogProbMetric: 393.1655, val_loss: 394.5200, val_MinusLogProbMetric: 394.5200

Epoch 445: val_loss did not improve from 393.91824
196/196 - 10s - loss: 393.1655 - MinusLogProbMetric: 393.1655 - val_loss: 394.5200 - val_MinusLogProbMetric: 394.5200 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 446/1000
2023-09-10 15:00:54.969 
Epoch 446/1000 
	 loss: 392.9225, MinusLogProbMetric: 392.9225, val_loss: 398.8751, val_MinusLogProbMetric: 398.8751

Epoch 446: val_loss did not improve from 393.91824
196/196 - 9s - loss: 392.9225 - MinusLogProbMetric: 392.9225 - val_loss: 398.8751 - val_MinusLogProbMetric: 398.8751 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 447/1000
2023-09-10 15:01:04.881 
Epoch 447/1000 
	 loss: 393.1906, MinusLogProbMetric: 393.1906, val_loss: 393.6953, val_MinusLogProbMetric: 393.6953

Epoch 447: val_loss improved from 393.91824 to 393.69531, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 393.1906 - MinusLogProbMetric: 393.1906 - val_loss: 393.6953 - val_MinusLogProbMetric: 393.6953 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 448/1000
2023-09-10 15:01:17.183 
Epoch 448/1000 
	 loss: 392.8404, MinusLogProbMetric: 392.8404, val_loss: 396.9509, val_MinusLogProbMetric: 396.9509

Epoch 448: val_loss did not improve from 393.69531
196/196 - 12s - loss: 392.8404 - MinusLogProbMetric: 392.8404 - val_loss: 396.9509 - val_MinusLogProbMetric: 396.9509 - lr: 1.6667e-04 - 12s/epoch - 59ms/step
Epoch 449/1000
2023-09-10 15:01:27.742 
Epoch 449/1000 
	 loss: 393.2464, MinusLogProbMetric: 393.2464, val_loss: 394.6972, val_MinusLogProbMetric: 394.6972

Epoch 449: val_loss did not improve from 393.69531
196/196 - 11s - loss: 393.2464 - MinusLogProbMetric: 393.2464 - val_loss: 394.6972 - val_MinusLogProbMetric: 394.6972 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 450/1000
2023-09-10 15:01:38.206 
Epoch 450/1000 
	 loss: 392.7862, MinusLogProbMetric: 392.7862, val_loss: 394.2113, val_MinusLogProbMetric: 394.2113

Epoch 450: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.7862 - MinusLogProbMetric: 392.7862 - val_loss: 394.2113 - val_MinusLogProbMetric: 394.2113 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 451/1000
2023-09-10 15:01:48.696 
Epoch 451/1000 
	 loss: 392.9251, MinusLogProbMetric: 392.9251, val_loss: 394.7214, val_MinusLogProbMetric: 394.7214

Epoch 451: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.9251 - MinusLogProbMetric: 392.9251 - val_loss: 394.7214 - val_MinusLogProbMetric: 394.7214 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 452/1000
2023-09-10 15:01:57.961 
Epoch 452/1000 
	 loss: 392.8063, MinusLogProbMetric: 392.8063, val_loss: 394.8242, val_MinusLogProbMetric: 394.8242

Epoch 452: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.8063 - MinusLogProbMetric: 392.8063 - val_loss: 394.8242 - val_MinusLogProbMetric: 394.8242 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 453/1000
2023-09-10 15:02:07.477 
Epoch 453/1000 
	 loss: 393.1070, MinusLogProbMetric: 393.1070, val_loss: 394.9198, val_MinusLogProbMetric: 394.9198

Epoch 453: val_loss did not improve from 393.69531
196/196 - 10s - loss: 393.1070 - MinusLogProbMetric: 393.1070 - val_loss: 394.9198 - val_MinusLogProbMetric: 394.9198 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 454/1000
2023-09-10 15:02:17.130 
Epoch 454/1000 
	 loss: 392.7439, MinusLogProbMetric: 392.7439, val_loss: 394.4922, val_MinusLogProbMetric: 394.4922

Epoch 454: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.7439 - MinusLogProbMetric: 392.7439 - val_loss: 394.4922 - val_MinusLogProbMetric: 394.4922 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 455/1000
2023-09-10 15:02:25.277 
Epoch 455/1000 
	 loss: 392.9211, MinusLogProbMetric: 392.9211, val_loss: 394.0982, val_MinusLogProbMetric: 394.0982

Epoch 455: val_loss did not improve from 393.69531
196/196 - 8s - loss: 392.9211 - MinusLogProbMetric: 392.9211 - val_loss: 394.0982 - val_MinusLogProbMetric: 394.0982 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 456/1000
2023-09-10 15:02:36.167 
Epoch 456/1000 
	 loss: 392.9607, MinusLogProbMetric: 392.9607, val_loss: 394.9097, val_MinusLogProbMetric: 394.9097

Epoch 456: val_loss did not improve from 393.69531
196/196 - 11s - loss: 392.9607 - MinusLogProbMetric: 392.9607 - val_loss: 394.9097 - val_MinusLogProbMetric: 394.9097 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 457/1000
2023-09-10 15:02:45.185 
Epoch 457/1000 
	 loss: 392.7381, MinusLogProbMetric: 392.7381, val_loss: 394.2831, val_MinusLogProbMetric: 394.2831

Epoch 457: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.7381 - MinusLogProbMetric: 392.7381 - val_loss: 394.2831 - val_MinusLogProbMetric: 394.2831 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 458/1000
2023-09-10 15:02:55.714 
Epoch 458/1000 
	 loss: 393.0462, MinusLogProbMetric: 393.0462, val_loss: 397.0016, val_MinusLogProbMetric: 397.0016

Epoch 458: val_loss did not improve from 393.69531
196/196 - 11s - loss: 393.0462 - MinusLogProbMetric: 393.0462 - val_loss: 397.0016 - val_MinusLogProbMetric: 397.0016 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 459/1000
2023-09-10 15:03:05.239 
Epoch 459/1000 
	 loss: 393.1067, MinusLogProbMetric: 393.1067, val_loss: 394.0331, val_MinusLogProbMetric: 394.0331

Epoch 459: val_loss did not improve from 393.69531
196/196 - 10s - loss: 393.1067 - MinusLogProbMetric: 393.1067 - val_loss: 394.0331 - val_MinusLogProbMetric: 394.0331 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 460/1000
2023-09-10 15:03:14.811 
Epoch 460/1000 
	 loss: 392.8699, MinusLogProbMetric: 392.8699, val_loss: 393.7773, val_MinusLogProbMetric: 393.7773

Epoch 460: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.8699 - MinusLogProbMetric: 392.8699 - val_loss: 393.7773 - val_MinusLogProbMetric: 393.7773 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 461/1000
2023-09-10 15:03:23.696 
Epoch 461/1000 
	 loss: 392.8656, MinusLogProbMetric: 392.8656, val_loss: 395.1182, val_MinusLogProbMetric: 395.1182

Epoch 461: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.8656 - MinusLogProbMetric: 392.8656 - val_loss: 395.1182 - val_MinusLogProbMetric: 395.1182 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 462/1000
2023-09-10 15:03:33.662 
Epoch 462/1000 
	 loss: 392.9060, MinusLogProbMetric: 392.9060, val_loss: 394.4699, val_MinusLogProbMetric: 394.4699

Epoch 462: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.9060 - MinusLogProbMetric: 392.9060 - val_loss: 394.4699 - val_MinusLogProbMetric: 394.4699 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 463/1000
2023-09-10 15:03:43.607 
Epoch 463/1000 
	 loss: 392.8077, MinusLogProbMetric: 392.8077, val_loss: 394.6286, val_MinusLogProbMetric: 394.6286

Epoch 463: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.8077 - MinusLogProbMetric: 392.8077 - val_loss: 394.6286 - val_MinusLogProbMetric: 394.6286 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 464/1000
2023-09-10 15:03:54.731 
Epoch 464/1000 
	 loss: 393.0114, MinusLogProbMetric: 393.0114, val_loss: 393.9273, val_MinusLogProbMetric: 393.9273

Epoch 464: val_loss did not improve from 393.69531
196/196 - 11s - loss: 393.0114 - MinusLogProbMetric: 393.0114 - val_loss: 393.9273 - val_MinusLogProbMetric: 393.9273 - lr: 1.6667e-04 - 11s/epoch - 57ms/step
Epoch 465/1000
2023-09-10 15:04:03.000 
Epoch 465/1000 
	 loss: 392.9935, MinusLogProbMetric: 392.9935, val_loss: 393.8080, val_MinusLogProbMetric: 393.8080

Epoch 465: val_loss did not improve from 393.69531
196/196 - 8s - loss: 392.9935 - MinusLogProbMetric: 392.9935 - val_loss: 393.8080 - val_MinusLogProbMetric: 393.8080 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 466/1000
2023-09-10 15:04:13.827 
Epoch 466/1000 
	 loss: 392.6272, MinusLogProbMetric: 392.6272, val_loss: 394.0281, val_MinusLogProbMetric: 394.0281

Epoch 466: val_loss did not improve from 393.69531
196/196 - 11s - loss: 392.6272 - MinusLogProbMetric: 392.6272 - val_loss: 394.0281 - val_MinusLogProbMetric: 394.0281 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 467/1000
2023-09-10 15:04:22.186 
Epoch 467/1000 
	 loss: 393.1073, MinusLogProbMetric: 393.1073, val_loss: 394.1012, val_MinusLogProbMetric: 394.1012

Epoch 467: val_loss did not improve from 393.69531
196/196 - 8s - loss: 393.1073 - MinusLogProbMetric: 393.1073 - val_loss: 394.1012 - val_MinusLogProbMetric: 394.1012 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 468/1000
2023-09-10 15:04:32.377 
Epoch 468/1000 
	 loss: 392.7007, MinusLogProbMetric: 392.7007, val_loss: 393.9677, val_MinusLogProbMetric: 393.9677

Epoch 468: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.7007 - MinusLogProbMetric: 392.7007 - val_loss: 393.9677 - val_MinusLogProbMetric: 393.9677 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 469/1000
2023-09-10 15:04:41.750 
Epoch 469/1000 
	 loss: 392.7611, MinusLogProbMetric: 392.7611, val_loss: 395.3609, val_MinusLogProbMetric: 395.3609

Epoch 469: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.7611 - MinusLogProbMetric: 392.7611 - val_loss: 395.3609 - val_MinusLogProbMetric: 395.3609 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 470/1000
2023-09-10 15:04:51.441 
Epoch 470/1000 
	 loss: 392.5640, MinusLogProbMetric: 392.5640, val_loss: 394.4521, val_MinusLogProbMetric: 394.4521

Epoch 470: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.5640 - MinusLogProbMetric: 392.5640 - val_loss: 394.4521 - val_MinusLogProbMetric: 394.4521 - lr: 1.6667e-04 - 10s/epoch - 49ms/step
Epoch 471/1000
2023-09-10 15:05:00.258 
Epoch 471/1000 
	 loss: 392.8456, MinusLogProbMetric: 392.8456, val_loss: 394.3155, val_MinusLogProbMetric: 394.3155

Epoch 471: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.8456 - MinusLogProbMetric: 392.8456 - val_loss: 394.3155 - val_MinusLogProbMetric: 394.3155 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 472/1000
2023-09-10 15:05:08.253 
Epoch 472/1000 
	 loss: 392.7810, MinusLogProbMetric: 392.7810, val_loss: 395.1624, val_MinusLogProbMetric: 395.1624

Epoch 472: val_loss did not improve from 393.69531
196/196 - 8s - loss: 392.7810 - MinusLogProbMetric: 392.7810 - val_loss: 395.1624 - val_MinusLogProbMetric: 395.1624 - lr: 1.6667e-04 - 8s/epoch - 41ms/step
Epoch 473/1000
2023-09-10 15:05:18.628 
Epoch 473/1000 
	 loss: 392.9033, MinusLogProbMetric: 392.9033, val_loss: 395.2605, val_MinusLogProbMetric: 395.2605

Epoch 473: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.9033 - MinusLogProbMetric: 392.9033 - val_loss: 395.2605 - val_MinusLogProbMetric: 395.2605 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 474/1000
2023-09-10 15:05:27.349 
Epoch 474/1000 
	 loss: 392.7194, MinusLogProbMetric: 392.7194, val_loss: 395.1163, val_MinusLogProbMetric: 395.1163

Epoch 474: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.7194 - MinusLogProbMetric: 392.7194 - val_loss: 395.1163 - val_MinusLogProbMetric: 395.1163 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 475/1000
2023-09-10 15:05:37.718 
Epoch 475/1000 
	 loss: 392.8887, MinusLogProbMetric: 392.8887, val_loss: 394.1444, val_MinusLogProbMetric: 394.1444

Epoch 475: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.8887 - MinusLogProbMetric: 392.8887 - val_loss: 394.1444 - val_MinusLogProbMetric: 394.1444 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 476/1000
2023-09-10 15:05:46.705 
Epoch 476/1000 
	 loss: 392.6870, MinusLogProbMetric: 392.6870, val_loss: 394.1481, val_MinusLogProbMetric: 394.1481

Epoch 476: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.6870 - MinusLogProbMetric: 392.6870 - val_loss: 394.1481 - val_MinusLogProbMetric: 394.1481 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 477/1000
2023-09-10 15:05:56.845 
Epoch 477/1000 
	 loss: 392.7834, MinusLogProbMetric: 392.7834, val_loss: 394.0806, val_MinusLogProbMetric: 394.0806

Epoch 477: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.7834 - MinusLogProbMetric: 392.7834 - val_loss: 394.0806 - val_MinusLogProbMetric: 394.0806 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 478/1000
2023-09-10 15:06:05.018 
Epoch 478/1000 
	 loss: 392.9448, MinusLogProbMetric: 392.9448, val_loss: 393.7162, val_MinusLogProbMetric: 393.7162

Epoch 478: val_loss did not improve from 393.69531
196/196 - 8s - loss: 392.9448 - MinusLogProbMetric: 392.9448 - val_loss: 393.7162 - val_MinusLogProbMetric: 393.7162 - lr: 1.6667e-04 - 8s/epoch - 42ms/step
Epoch 479/1000
2023-09-10 15:06:15.100 
Epoch 479/1000 
	 loss: 392.7032, MinusLogProbMetric: 392.7032, val_loss: 394.4498, val_MinusLogProbMetric: 394.4498

Epoch 479: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.7032 - MinusLogProbMetric: 392.7032 - val_loss: 394.4498 - val_MinusLogProbMetric: 394.4498 - lr: 1.6667e-04 - 10s/epoch - 51ms/step
Epoch 480/1000
2023-09-10 15:06:23.616 
Epoch 480/1000 
	 loss: 393.0170, MinusLogProbMetric: 393.0170, val_loss: 394.4230, val_MinusLogProbMetric: 394.4230

Epoch 480: val_loss did not improve from 393.69531
196/196 - 9s - loss: 393.0170 - MinusLogProbMetric: 393.0170 - val_loss: 394.4230 - val_MinusLogProbMetric: 394.4230 - lr: 1.6667e-04 - 9s/epoch - 43ms/step
Epoch 481/1000
2023-09-10 15:06:34.437 
Epoch 481/1000 
	 loss: 392.6797, MinusLogProbMetric: 392.6797, val_loss: 393.7537, val_MinusLogProbMetric: 393.7537

Epoch 481: val_loss did not improve from 393.69531
196/196 - 11s - loss: 392.6797 - MinusLogProbMetric: 392.6797 - val_loss: 393.7537 - val_MinusLogProbMetric: 393.7537 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 482/1000
2023-09-10 15:06:44.549 
Epoch 482/1000 
	 loss: 392.5654, MinusLogProbMetric: 392.5654, val_loss: 394.6003, val_MinusLogProbMetric: 394.6003

Epoch 482: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.5654 - MinusLogProbMetric: 392.5654 - val_loss: 394.6003 - val_MinusLogProbMetric: 394.6003 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 483/1000
2023-09-10 15:06:55.581 
Epoch 483/1000 
	 loss: 392.6808, MinusLogProbMetric: 392.6808, val_loss: 393.8573, val_MinusLogProbMetric: 393.8573

Epoch 483: val_loss did not improve from 393.69531
196/196 - 11s - loss: 392.6808 - MinusLogProbMetric: 392.6808 - val_loss: 393.8573 - val_MinusLogProbMetric: 393.8573 - lr: 1.6667e-04 - 11s/epoch - 56ms/step
Epoch 484/1000
2023-09-10 15:07:04.226 
Epoch 484/1000 
	 loss: 392.7539, MinusLogProbMetric: 392.7539, val_loss: 393.9694, val_MinusLogProbMetric: 393.9694

Epoch 484: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.7539 - MinusLogProbMetric: 392.7539 - val_loss: 393.9694 - val_MinusLogProbMetric: 393.9694 - lr: 1.6667e-04 - 9s/epoch - 44ms/step
Epoch 485/1000
2023-09-10 15:07:13.264 
Epoch 485/1000 
	 loss: 392.4367, MinusLogProbMetric: 392.4367, val_loss: 394.2979, val_MinusLogProbMetric: 394.2979

Epoch 485: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.4367 - MinusLogProbMetric: 392.4367 - val_loss: 394.2979 - val_MinusLogProbMetric: 394.2979 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 486/1000
2023-09-10 15:07:23.573 
Epoch 486/1000 
	 loss: 392.5543, MinusLogProbMetric: 392.5543, val_loss: 393.8362, val_MinusLogProbMetric: 393.8362

Epoch 486: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.5543 - MinusLogProbMetric: 392.5543 - val_loss: 393.8362 - val_MinusLogProbMetric: 393.8362 - lr: 1.6667e-04 - 10s/epoch - 53ms/step
Epoch 487/1000
2023-09-10 15:07:32.615 
Epoch 487/1000 
	 loss: 392.7352, MinusLogProbMetric: 392.7352, val_loss: 394.1005, val_MinusLogProbMetric: 394.1005

Epoch 487: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.7352 - MinusLogProbMetric: 392.7352 - val_loss: 394.1005 - val_MinusLogProbMetric: 394.1005 - lr: 1.6667e-04 - 9s/epoch - 46ms/step
Epoch 488/1000
2023-09-10 15:07:43.172 
Epoch 488/1000 
	 loss: 392.5589, MinusLogProbMetric: 392.5589, val_loss: 394.0869, val_MinusLogProbMetric: 394.0869

Epoch 488: val_loss did not improve from 393.69531
196/196 - 11s - loss: 392.5589 - MinusLogProbMetric: 392.5589 - val_loss: 394.0869 - val_MinusLogProbMetric: 394.0869 - lr: 1.6667e-04 - 11s/epoch - 54ms/step
Epoch 489/1000
2023-09-10 15:07:52.326 
Epoch 489/1000 
	 loss: 392.7666, MinusLogProbMetric: 392.7666, val_loss: 395.1853, val_MinusLogProbMetric: 395.1853

Epoch 489: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.7666 - MinusLogProbMetric: 392.7666 - val_loss: 395.1853 - val_MinusLogProbMetric: 395.1853 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 490/1000
2023-09-10 15:08:01.537 
Epoch 490/1000 
	 loss: 392.6089, MinusLogProbMetric: 392.6089, val_loss: 393.8760, val_MinusLogProbMetric: 393.8760

Epoch 490: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.6089 - MinusLogProbMetric: 392.6089 - val_loss: 393.8760 - val_MinusLogProbMetric: 393.8760 - lr: 1.6667e-04 - 9s/epoch - 47ms/step
Epoch 491/1000
2023-09-10 15:08:11.260 
Epoch 491/1000 
	 loss: 392.7645, MinusLogProbMetric: 392.7645, val_loss: 397.0954, val_MinusLogProbMetric: 397.0954

Epoch 491: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.7645 - MinusLogProbMetric: 392.7645 - val_loss: 397.0954 - val_MinusLogProbMetric: 397.0954 - lr: 1.6667e-04 - 10s/epoch - 50ms/step
Epoch 492/1000
2023-09-10 15:08:22.953 
Epoch 492/1000 
	 loss: 392.5962, MinusLogProbMetric: 392.5962, val_loss: 394.0894, val_MinusLogProbMetric: 394.0894

Epoch 492: val_loss did not improve from 393.69531
196/196 - 12s - loss: 392.5962 - MinusLogProbMetric: 392.5962 - val_loss: 394.0894 - val_MinusLogProbMetric: 394.0894 - lr: 1.6667e-04 - 12s/epoch - 60ms/step
Epoch 493/1000
2023-09-10 15:08:31.376 
Epoch 493/1000 
	 loss: 392.8932, MinusLogProbMetric: 392.8932, val_loss: 393.8337, val_MinusLogProbMetric: 393.8337

Epoch 493: val_loss did not improve from 393.69531
196/196 - 8s - loss: 392.8932 - MinusLogProbMetric: 392.8932 - val_loss: 393.8337 - val_MinusLogProbMetric: 393.8337 - lr: 1.6667e-04 - 8s/epoch - 43ms/step
Epoch 494/1000
2023-09-10 15:08:42.061 
Epoch 494/1000 
	 loss: 392.4190, MinusLogProbMetric: 392.4190, val_loss: 393.9016, val_MinusLogProbMetric: 393.9016

Epoch 494: val_loss did not improve from 393.69531
196/196 - 11s - loss: 392.4190 - MinusLogProbMetric: 392.4190 - val_loss: 393.9016 - val_MinusLogProbMetric: 393.9016 - lr: 1.6667e-04 - 11s/epoch - 55ms/step
Epoch 495/1000
2023-09-10 15:08:50.848 
Epoch 495/1000 
	 loss: 392.7921, MinusLogProbMetric: 392.7921, val_loss: 394.3168, val_MinusLogProbMetric: 394.3168

Epoch 495: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.7921 - MinusLogProbMetric: 392.7921 - val_loss: 394.3168 - val_MinusLogProbMetric: 394.3168 - lr: 1.6667e-04 - 9s/epoch - 45ms/step
Epoch 496/1000
2023-09-10 15:09:00.988 
Epoch 496/1000 
	 loss: 392.5271, MinusLogProbMetric: 392.5271, val_loss: 394.6653, val_MinusLogProbMetric: 394.6653

Epoch 496: val_loss did not improve from 393.69531
196/196 - 10s - loss: 392.5271 - MinusLogProbMetric: 392.5271 - val_loss: 394.6653 - val_MinusLogProbMetric: 394.6653 - lr: 1.6667e-04 - 10s/epoch - 52ms/step
Epoch 497/1000
2023-09-10 15:09:10.324 
Epoch 497/1000 
	 loss: 392.5325, MinusLogProbMetric: 392.5325, val_loss: 393.8758, val_MinusLogProbMetric: 393.8758

Epoch 497: val_loss did not improve from 393.69531
196/196 - 9s - loss: 392.5325 - MinusLogProbMetric: 392.5325 - val_loss: 393.8758 - val_MinusLogProbMetric: 393.8758 - lr: 1.6667e-04 - 9s/epoch - 48ms/step
Epoch 498/1000
2023-09-10 15:09:20.282 
Epoch 498/1000 
	 loss: 391.2103, MinusLogProbMetric: 391.2103, val_loss: 392.8203, val_MinusLogProbMetric: 392.8203

Epoch 498: val_loss improved from 393.69531 to 392.82031, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 391.2103 - MinusLogProbMetric: 391.2103 - val_loss: 392.8203 - val_MinusLogProbMetric: 392.8203 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 499/1000
2023-09-10 15:09:30.492 
Epoch 499/1000 
	 loss: 391.1402, MinusLogProbMetric: 391.1402, val_loss: 392.7617, val_MinusLogProbMetric: 392.7617

Epoch 499: val_loss improved from 392.82031 to 392.76172, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 391.1402 - MinusLogProbMetric: 391.1402 - val_loss: 392.7617 - val_MinusLogProbMetric: 392.7617 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 500/1000
2023-09-10 15:09:40.393 
Epoch 500/1000 
	 loss: 391.0652, MinusLogProbMetric: 391.0652, val_loss: 393.0818, val_MinusLogProbMetric: 393.0818

Epoch 500: val_loss did not improve from 392.76172
196/196 - 10s - loss: 391.0652 - MinusLogProbMetric: 391.0652 - val_loss: 393.0818 - val_MinusLogProbMetric: 393.0818 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 501/1000
2023-09-10 15:09:49.415 
Epoch 501/1000 
	 loss: 391.2598, MinusLogProbMetric: 391.2598, val_loss: 394.2353, val_MinusLogProbMetric: 394.2353

Epoch 501: val_loss did not improve from 392.76172
196/196 - 9s - loss: 391.2598 - MinusLogProbMetric: 391.2598 - val_loss: 394.2353 - val_MinusLogProbMetric: 394.2353 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 502/1000
2023-09-10 15:09:57.575 
Epoch 502/1000 
	 loss: 391.3667, MinusLogProbMetric: 391.3667, val_loss: 393.1856, val_MinusLogProbMetric: 393.1856

Epoch 502: val_loss did not improve from 392.76172
196/196 - 8s - loss: 391.3667 - MinusLogProbMetric: 391.3667 - val_loss: 393.1856 - val_MinusLogProbMetric: 393.1856 - lr: 8.3333e-05 - 8s/epoch - 42ms/step
Epoch 503/1000
2023-09-10 15:10:07.379 
Epoch 503/1000 
	 loss: 391.2285, MinusLogProbMetric: 391.2285, val_loss: 392.7547, val_MinusLogProbMetric: 392.7547

Epoch 503: val_loss improved from 392.76172 to 392.75470, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 391.2285 - MinusLogProbMetric: 391.2285 - val_loss: 392.7547 - val_MinusLogProbMetric: 392.7547 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 504/1000
2023-09-10 15:10:16.340 
Epoch 504/1000 
	 loss: 391.1616, MinusLogProbMetric: 391.1616, val_loss: 392.7249, val_MinusLogProbMetric: 392.7249

Epoch 504: val_loss improved from 392.75470 to 392.72495, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 391.1616 - MinusLogProbMetric: 391.1616 - val_loss: 392.7249 - val_MinusLogProbMetric: 392.7249 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 505/1000
2023-09-10 15:10:26.564 
Epoch 505/1000 
	 loss: 391.1982, MinusLogProbMetric: 391.1982, val_loss: 393.7966, val_MinusLogProbMetric: 393.7966

Epoch 505: val_loss did not improve from 392.72495
196/196 - 10s - loss: 391.1982 - MinusLogProbMetric: 391.1982 - val_loss: 393.7966 - val_MinusLogProbMetric: 393.7966 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 506/1000
2023-09-10 15:10:37.188 
Epoch 506/1000 
	 loss: 391.2572, MinusLogProbMetric: 391.2572, val_loss: 392.7836, val_MinusLogProbMetric: 392.7836

Epoch 506: val_loss did not improve from 392.72495
196/196 - 11s - loss: 391.2572 - MinusLogProbMetric: 391.2572 - val_loss: 392.7836 - val_MinusLogProbMetric: 392.7836 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 507/1000
2023-09-10 15:10:47.445 
Epoch 507/1000 
	 loss: 391.1161, MinusLogProbMetric: 391.1161, val_loss: 392.7178, val_MinusLogProbMetric: 392.7178

Epoch 507: val_loss improved from 392.72495 to 392.71780, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 391.1161 - MinusLogProbMetric: 391.1161 - val_loss: 392.7178 - val_MinusLogProbMetric: 392.7178 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 508/1000
2023-09-10 15:10:57.172 
Epoch 508/1000 
	 loss: 391.4008, MinusLogProbMetric: 391.4008, val_loss: 392.9227, val_MinusLogProbMetric: 392.9227

Epoch 508: val_loss did not improve from 392.71780
196/196 - 9s - loss: 391.4008 - MinusLogProbMetric: 391.4008 - val_loss: 392.9227 - val_MinusLogProbMetric: 392.9227 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 509/1000
2023-09-10 15:11:06.394 
Epoch 509/1000 
	 loss: 391.0587, MinusLogProbMetric: 391.0587, val_loss: 392.6455, val_MinusLogProbMetric: 392.6455

Epoch 509: val_loss improved from 392.71780 to 392.64554, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 391.0587 - MinusLogProbMetric: 391.0587 - val_loss: 392.6455 - val_MinusLogProbMetric: 392.6455 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 510/1000
2023-09-10 15:11:15.224 
Epoch 510/1000 
	 loss: 391.1107, MinusLogProbMetric: 391.1107, val_loss: 392.6855, val_MinusLogProbMetric: 392.6855

Epoch 510: val_loss did not improve from 392.64554
196/196 - 8s - loss: 391.1107 - MinusLogProbMetric: 391.1107 - val_loss: 392.6855 - val_MinusLogProbMetric: 392.6855 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 511/1000
2023-09-10 15:11:25.388 
Epoch 511/1000 
	 loss: 391.4227, MinusLogProbMetric: 391.4227, val_loss: 393.2186, val_MinusLogProbMetric: 393.2186

Epoch 511: val_loss did not improve from 392.64554
196/196 - 10s - loss: 391.4227 - MinusLogProbMetric: 391.4227 - val_loss: 393.2186 - val_MinusLogProbMetric: 393.2186 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 512/1000
2023-09-10 15:11:33.335 
Epoch 512/1000 
	 loss: 391.1007, MinusLogProbMetric: 391.1007, val_loss: 392.7531, val_MinusLogProbMetric: 392.7531

Epoch 512: val_loss did not improve from 392.64554
196/196 - 8s - loss: 391.1007 - MinusLogProbMetric: 391.1007 - val_loss: 392.7531 - val_MinusLogProbMetric: 392.7531 - lr: 8.3333e-05 - 8s/epoch - 41ms/step
Epoch 513/1000
2023-09-10 15:11:43.649 
Epoch 513/1000 
	 loss: 391.1683, MinusLogProbMetric: 391.1683, val_loss: 392.9886, val_MinusLogProbMetric: 392.9886

Epoch 513: val_loss did not improve from 392.64554
196/196 - 10s - loss: 391.1683 - MinusLogProbMetric: 391.1683 - val_loss: 392.9886 - val_MinusLogProbMetric: 392.9886 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 514/1000
2023-09-10 15:11:52.741 
Epoch 514/1000 
	 loss: 391.1310, MinusLogProbMetric: 391.1310, val_loss: 393.1379, val_MinusLogProbMetric: 393.1379

Epoch 514: val_loss did not improve from 392.64554
196/196 - 9s - loss: 391.1310 - MinusLogProbMetric: 391.1310 - val_loss: 393.1379 - val_MinusLogProbMetric: 393.1379 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 515/1000
2023-09-10 15:12:04.405 
Epoch 515/1000 
	 loss: 391.2329, MinusLogProbMetric: 391.2329, val_loss: 393.3012, val_MinusLogProbMetric: 393.3012

Epoch 515: val_loss did not improve from 392.64554
196/196 - 12s - loss: 391.2329 - MinusLogProbMetric: 391.2329 - val_loss: 393.3012 - val_MinusLogProbMetric: 393.3012 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 516/1000
2023-09-10 15:12:12.966 
Epoch 516/1000 
	 loss: 391.3301, MinusLogProbMetric: 391.3301, val_loss: 393.0576, val_MinusLogProbMetric: 393.0576

Epoch 516: val_loss did not improve from 392.64554
196/196 - 9s - loss: 391.3301 - MinusLogProbMetric: 391.3301 - val_loss: 393.0576 - val_MinusLogProbMetric: 393.0576 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 517/1000
2023-09-10 15:12:22.900 
Epoch 517/1000 
	 loss: 391.2236, MinusLogProbMetric: 391.2236, val_loss: 393.3182, val_MinusLogProbMetric: 393.3182

Epoch 517: val_loss did not improve from 392.64554
196/196 - 10s - loss: 391.2236 - MinusLogProbMetric: 391.2236 - val_loss: 393.3182 - val_MinusLogProbMetric: 393.3182 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 518/1000
2023-09-10 15:12:31.464 
Epoch 518/1000 
	 loss: 391.3060, MinusLogProbMetric: 391.3060, val_loss: 392.9985, val_MinusLogProbMetric: 392.9985

Epoch 518: val_loss did not improve from 392.64554
196/196 - 9s - loss: 391.3060 - MinusLogProbMetric: 391.3060 - val_loss: 392.9985 - val_MinusLogProbMetric: 392.9985 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 519/1000
2023-09-10 15:12:42.668 
Epoch 519/1000 
	 loss: 391.1381, MinusLogProbMetric: 391.1381, val_loss: 392.7616, val_MinusLogProbMetric: 392.7616

Epoch 519: val_loss did not improve from 392.64554
196/196 - 11s - loss: 391.1381 - MinusLogProbMetric: 391.1381 - val_loss: 392.7616 - val_MinusLogProbMetric: 392.7616 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 520/1000
2023-09-10 15:12:51.694 
Epoch 520/1000 
	 loss: 391.2052, MinusLogProbMetric: 391.2052, val_loss: 392.8865, val_MinusLogProbMetric: 392.8865

Epoch 520: val_loss did not improve from 392.64554
196/196 - 9s - loss: 391.2052 - MinusLogProbMetric: 391.2052 - val_loss: 392.8865 - val_MinusLogProbMetric: 392.8865 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 521/1000
2023-09-10 15:13:01.031 
Epoch 521/1000 
	 loss: 391.0641, MinusLogProbMetric: 391.0641, val_loss: 392.5665, val_MinusLogProbMetric: 392.5665

Epoch 521: val_loss improved from 392.64554 to 392.56653, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 391.0641 - MinusLogProbMetric: 391.0641 - val_loss: 392.5665 - val_MinusLogProbMetric: 392.5665 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 522/1000
2023-09-10 15:13:10.629 
Epoch 522/1000 
	 loss: 390.9959, MinusLogProbMetric: 390.9959, val_loss: 393.6739, val_MinusLogProbMetric: 393.6739

Epoch 522: val_loss did not improve from 392.56653
196/196 - 9s - loss: 390.9959 - MinusLogProbMetric: 390.9959 - val_loss: 393.6739 - val_MinusLogProbMetric: 393.6739 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 523/1000
2023-09-10 15:13:20.217 
Epoch 523/1000 
	 loss: 391.2106, MinusLogProbMetric: 391.2106, val_loss: 392.6793, val_MinusLogProbMetric: 392.6793

Epoch 523: val_loss did not improve from 392.56653
196/196 - 10s - loss: 391.2106 - MinusLogProbMetric: 391.2106 - val_loss: 392.6793 - val_MinusLogProbMetric: 392.6793 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 524/1000
2023-09-10 15:13:29.537 
Epoch 524/1000 
	 loss: 391.1364, MinusLogProbMetric: 391.1364, val_loss: 392.6593, val_MinusLogProbMetric: 392.6593

Epoch 524: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.1364 - MinusLogProbMetric: 391.1364 - val_loss: 392.6593 - val_MinusLogProbMetric: 392.6593 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 525/1000
2023-09-10 15:13:38.374 
Epoch 525/1000 
	 loss: 391.1438, MinusLogProbMetric: 391.1438, val_loss: 393.0846, val_MinusLogProbMetric: 393.0846

Epoch 525: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.1438 - MinusLogProbMetric: 391.1438 - val_loss: 393.0846 - val_MinusLogProbMetric: 393.0846 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 526/1000
2023-09-10 15:13:50.813 
Epoch 526/1000 
	 loss: 390.9883, MinusLogProbMetric: 390.9883, val_loss: 392.7610, val_MinusLogProbMetric: 392.7610

Epoch 526: val_loss did not improve from 392.56653
196/196 - 12s - loss: 390.9883 - MinusLogProbMetric: 390.9883 - val_loss: 392.7610 - val_MinusLogProbMetric: 392.7610 - lr: 8.3333e-05 - 12s/epoch - 63ms/step
Epoch 527/1000
2023-09-10 15:13:59.484 
Epoch 527/1000 
	 loss: 391.0658, MinusLogProbMetric: 391.0658, val_loss: 392.8944, val_MinusLogProbMetric: 392.8944

Epoch 527: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.0658 - MinusLogProbMetric: 391.0658 - val_loss: 392.8944 - val_MinusLogProbMetric: 392.8944 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 528/1000
2023-09-10 15:14:10.970 
Epoch 528/1000 
	 loss: 391.1517, MinusLogProbMetric: 391.1517, val_loss: 392.7293, val_MinusLogProbMetric: 392.7293

Epoch 528: val_loss did not improve from 392.56653
196/196 - 11s - loss: 391.1517 - MinusLogProbMetric: 391.1517 - val_loss: 392.7293 - val_MinusLogProbMetric: 392.7293 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 529/1000
2023-09-10 15:14:21.943 
Epoch 529/1000 
	 loss: 391.1577, MinusLogProbMetric: 391.1577, val_loss: 393.2612, val_MinusLogProbMetric: 393.2612

Epoch 529: val_loss did not improve from 392.56653
196/196 - 11s - loss: 391.1577 - MinusLogProbMetric: 391.1577 - val_loss: 393.2612 - val_MinusLogProbMetric: 393.2612 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 530/1000
2023-09-10 15:14:30.811 
Epoch 530/1000 
	 loss: 391.1374, MinusLogProbMetric: 391.1374, val_loss: 392.6072, val_MinusLogProbMetric: 392.6072

Epoch 530: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.1374 - MinusLogProbMetric: 391.1374 - val_loss: 392.6072 - val_MinusLogProbMetric: 392.6072 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 531/1000
2023-09-10 15:14:40.791 
Epoch 531/1000 
	 loss: 391.0323, MinusLogProbMetric: 391.0323, val_loss: 392.9789, val_MinusLogProbMetric: 392.9789

Epoch 531: val_loss did not improve from 392.56653
196/196 - 10s - loss: 391.0323 - MinusLogProbMetric: 391.0323 - val_loss: 392.9789 - val_MinusLogProbMetric: 392.9789 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 532/1000
2023-09-10 15:14:49.556 
Epoch 532/1000 
	 loss: 391.0305, MinusLogProbMetric: 391.0305, val_loss: 392.5847, val_MinusLogProbMetric: 392.5847

Epoch 532: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.0305 - MinusLogProbMetric: 391.0305 - val_loss: 392.5847 - val_MinusLogProbMetric: 392.5847 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 533/1000
2023-09-10 15:14:58.463 
Epoch 533/1000 
	 loss: 391.2709, MinusLogProbMetric: 391.2709, val_loss: 392.6397, val_MinusLogProbMetric: 392.6397

Epoch 533: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.2709 - MinusLogProbMetric: 391.2709 - val_loss: 392.6397 - val_MinusLogProbMetric: 392.6397 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 534/1000
2023-09-10 15:15:08.286 
Epoch 534/1000 
	 loss: 391.0959, MinusLogProbMetric: 391.0959, val_loss: 393.7919, val_MinusLogProbMetric: 393.7919

Epoch 534: val_loss did not improve from 392.56653
196/196 - 10s - loss: 391.0959 - MinusLogProbMetric: 391.0959 - val_loss: 393.7919 - val_MinusLogProbMetric: 393.7919 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 535/1000
2023-09-10 15:15:17.188 
Epoch 535/1000 
	 loss: 391.0703, MinusLogProbMetric: 391.0703, val_loss: 392.6503, val_MinusLogProbMetric: 392.6503

Epoch 535: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.0703 - MinusLogProbMetric: 391.0703 - val_loss: 392.6503 - val_MinusLogProbMetric: 392.6503 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 536/1000
2023-09-10 15:15:27.243 
Epoch 536/1000 
	 loss: 391.1852, MinusLogProbMetric: 391.1852, val_loss: 393.4088, val_MinusLogProbMetric: 393.4088

Epoch 536: val_loss did not improve from 392.56653
196/196 - 10s - loss: 391.1852 - MinusLogProbMetric: 391.1852 - val_loss: 393.4088 - val_MinusLogProbMetric: 393.4088 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 537/1000
2023-09-10 15:15:36.494 
Epoch 537/1000 
	 loss: 391.0870, MinusLogProbMetric: 391.0870, val_loss: 393.0912, val_MinusLogProbMetric: 393.0912

Epoch 537: val_loss did not improve from 392.56653
196/196 - 9s - loss: 391.0870 - MinusLogProbMetric: 391.0870 - val_loss: 393.0912 - val_MinusLogProbMetric: 393.0912 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 538/1000
2023-09-10 15:15:47.099 
Epoch 538/1000 
	 loss: 391.1165, MinusLogProbMetric: 391.1165, val_loss: 394.2027, val_MinusLogProbMetric: 394.2027

Epoch 538: val_loss did not improve from 392.56653
196/196 - 11s - loss: 391.1165 - MinusLogProbMetric: 391.1165 - val_loss: 394.2027 - val_MinusLogProbMetric: 394.2027 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 539/1000
2023-09-10 15:15:56.616 
Epoch 539/1000 
	 loss: 391.1125, MinusLogProbMetric: 391.1125, val_loss: 393.3897, val_MinusLogProbMetric: 393.3897

Epoch 539: val_loss did not improve from 392.56653
196/196 - 10s - loss: 391.1125 - MinusLogProbMetric: 391.1125 - val_loss: 393.3897 - val_MinusLogProbMetric: 393.3897 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 540/1000
2023-09-10 15:16:07.869 
Epoch 540/1000 
	 loss: 391.0499, MinusLogProbMetric: 391.0499, val_loss: 392.6717, val_MinusLogProbMetric: 392.6717

Epoch 540: val_loss did not improve from 392.56653
196/196 - 11s - loss: 391.0499 - MinusLogProbMetric: 391.0499 - val_loss: 392.6717 - val_MinusLogProbMetric: 392.6717 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 541/1000
2023-09-10 15:16:18.264 
Epoch 541/1000 
	 loss: 391.0677, MinusLogProbMetric: 391.0677, val_loss: 392.9222, val_MinusLogProbMetric: 392.9222

Epoch 541: val_loss did not improve from 392.56653
196/196 - 10s - loss: 391.0677 - MinusLogProbMetric: 391.0677 - val_loss: 392.9222 - val_MinusLogProbMetric: 392.9222 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 542/1000
2023-09-10 15:16:29.419 
Epoch 542/1000 
	 loss: 391.0777, MinusLogProbMetric: 391.0777, val_loss: 393.4488, val_MinusLogProbMetric: 393.4488

Epoch 542: val_loss did not improve from 392.56653
196/196 - 11s - loss: 391.0777 - MinusLogProbMetric: 391.0777 - val_loss: 393.4488 - val_MinusLogProbMetric: 393.4488 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 543/1000
2023-09-10 15:16:39.028 
Epoch 543/1000 
	 loss: 391.0430, MinusLogProbMetric: 391.0430, val_loss: 393.0146, val_MinusLogProbMetric: 393.0146

Epoch 543: val_loss did not improve from 392.56653
196/196 - 10s - loss: 391.0430 - MinusLogProbMetric: 391.0430 - val_loss: 393.0146 - val_MinusLogProbMetric: 393.0146 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 544/1000
2023-09-10 15:16:50.051 
Epoch 544/1000 
	 loss: 390.9843, MinusLogProbMetric: 390.9843, val_loss: 392.8053, val_MinusLogProbMetric: 392.8053

Epoch 544: val_loss did not improve from 392.56653
196/196 - 11s - loss: 390.9843 - MinusLogProbMetric: 390.9843 - val_loss: 392.8053 - val_MinusLogProbMetric: 392.8053 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 545/1000
2023-09-10 15:17:00.003 
Epoch 545/1000 
	 loss: 390.9379, MinusLogProbMetric: 390.9379, val_loss: 392.5342, val_MinusLogProbMetric: 392.5342

Epoch 545: val_loss improved from 392.56653 to 392.53418, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 390.9379 - MinusLogProbMetric: 390.9379 - val_loss: 392.5342 - val_MinusLogProbMetric: 392.5342 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 546/1000
2023-09-10 15:17:11.511 
Epoch 546/1000 
	 loss: 391.1078, MinusLogProbMetric: 391.1078, val_loss: 392.7586, val_MinusLogProbMetric: 392.7586

Epoch 546: val_loss did not improve from 392.53418
196/196 - 11s - loss: 391.1078 - MinusLogProbMetric: 391.1078 - val_loss: 392.7586 - val_MinusLogProbMetric: 392.7586 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 547/1000
2023-09-10 15:17:21.965 
Epoch 547/1000 
	 loss: 391.0253, MinusLogProbMetric: 391.0253, val_loss: 392.4762, val_MinusLogProbMetric: 392.4762

Epoch 547: val_loss improved from 392.53418 to 392.47617, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 391.0253 - MinusLogProbMetric: 391.0253 - val_loss: 392.4762 - val_MinusLogProbMetric: 392.4762 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 548/1000
2023-09-10 15:17:32.732 
Epoch 548/1000 
	 loss: 391.0931, MinusLogProbMetric: 391.0931, val_loss: 392.8096, val_MinusLogProbMetric: 392.8096

Epoch 548: val_loss did not improve from 392.47617
196/196 - 10s - loss: 391.0931 - MinusLogProbMetric: 391.0931 - val_loss: 392.8096 - val_MinusLogProbMetric: 392.8096 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 549/1000
2023-09-10 15:17:41.573 
Epoch 549/1000 
	 loss: 391.1362, MinusLogProbMetric: 391.1362, val_loss: 392.5920, val_MinusLogProbMetric: 392.5920

Epoch 549: val_loss did not improve from 392.47617
196/196 - 9s - loss: 391.1362 - MinusLogProbMetric: 391.1362 - val_loss: 392.5920 - val_MinusLogProbMetric: 392.5920 - lr: 8.3333e-05 - 9s/epoch - 45ms/step
Epoch 550/1000
2023-09-10 15:17:54.444 
Epoch 550/1000 
	 loss: 390.9316, MinusLogProbMetric: 390.9316, val_loss: 392.5856, val_MinusLogProbMetric: 392.5856

Epoch 550: val_loss did not improve from 392.47617
196/196 - 13s - loss: 390.9316 - MinusLogProbMetric: 390.9316 - val_loss: 392.5856 - val_MinusLogProbMetric: 392.5856 - lr: 8.3333e-05 - 13s/epoch - 66ms/step
Epoch 551/1000
2023-09-10 15:18:04.557 
Epoch 551/1000 
	 loss: 390.9832, MinusLogProbMetric: 390.9832, val_loss: 392.5239, val_MinusLogProbMetric: 392.5239

Epoch 551: val_loss did not improve from 392.47617
196/196 - 10s - loss: 390.9832 - MinusLogProbMetric: 390.9832 - val_loss: 392.5239 - val_MinusLogProbMetric: 392.5239 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 552/1000
2023-09-10 15:18:14.415 
Epoch 552/1000 
	 loss: 391.0424, MinusLogProbMetric: 391.0424, val_loss: 392.5172, val_MinusLogProbMetric: 392.5172

Epoch 552: val_loss did not improve from 392.47617
196/196 - 10s - loss: 391.0424 - MinusLogProbMetric: 391.0424 - val_loss: 392.5172 - val_MinusLogProbMetric: 392.5172 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 553/1000
2023-09-10 15:18:23.097 
Epoch 553/1000 
	 loss: 391.0718, MinusLogProbMetric: 391.0718, val_loss: 395.3994, val_MinusLogProbMetric: 395.3994

Epoch 553: val_loss did not improve from 392.47617
196/196 - 9s - loss: 391.0718 - MinusLogProbMetric: 391.0718 - val_loss: 395.3994 - val_MinusLogProbMetric: 395.3994 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 554/1000
2023-09-10 15:18:35.889 
Epoch 554/1000 
	 loss: 391.0092, MinusLogProbMetric: 391.0092, val_loss: 393.0562, val_MinusLogProbMetric: 393.0562

Epoch 554: val_loss did not improve from 392.47617
196/196 - 13s - loss: 391.0092 - MinusLogProbMetric: 391.0092 - val_loss: 393.0562 - val_MinusLogProbMetric: 393.0562 - lr: 8.3333e-05 - 13s/epoch - 65ms/step
Epoch 555/1000
2023-09-10 15:18:44.537 
Epoch 555/1000 
	 loss: 390.8833, MinusLogProbMetric: 390.8833, val_loss: 392.8995, val_MinusLogProbMetric: 392.8995

Epoch 555: val_loss did not improve from 392.47617
196/196 - 9s - loss: 390.8833 - MinusLogProbMetric: 390.8833 - val_loss: 392.8995 - val_MinusLogProbMetric: 392.8995 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 556/1000
2023-09-10 15:18:55.184 
Epoch 556/1000 
	 loss: 391.0027, MinusLogProbMetric: 391.0027, val_loss: 393.3119, val_MinusLogProbMetric: 393.3119

Epoch 556: val_loss did not improve from 392.47617
196/196 - 11s - loss: 391.0027 - MinusLogProbMetric: 391.0027 - val_loss: 393.3119 - val_MinusLogProbMetric: 393.3119 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 557/1000
2023-09-10 15:19:03.635 
Epoch 557/1000 
	 loss: 391.1295, MinusLogProbMetric: 391.1295, val_loss: 393.0641, val_MinusLogProbMetric: 393.0641

Epoch 557: val_loss did not improve from 392.47617
196/196 - 8s - loss: 391.1295 - MinusLogProbMetric: 391.1295 - val_loss: 393.0641 - val_MinusLogProbMetric: 393.0641 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 558/1000
2023-09-10 15:19:14.821 
Epoch 558/1000 
	 loss: 391.0078, MinusLogProbMetric: 391.0078, val_loss: 393.1053, val_MinusLogProbMetric: 393.1053

Epoch 558: val_loss did not improve from 392.47617
196/196 - 11s - loss: 391.0078 - MinusLogProbMetric: 391.0078 - val_loss: 393.1053 - val_MinusLogProbMetric: 393.1053 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 559/1000
2023-09-10 15:19:23.373 
Epoch 559/1000 
	 loss: 390.8771, MinusLogProbMetric: 390.8771, val_loss: 393.3221, val_MinusLogProbMetric: 393.3221

Epoch 559: val_loss did not improve from 392.47617
196/196 - 9s - loss: 390.8771 - MinusLogProbMetric: 390.8771 - val_loss: 393.3221 - val_MinusLogProbMetric: 393.3221 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 560/1000
2023-09-10 15:19:32.909 
Epoch 560/1000 
	 loss: 391.0372, MinusLogProbMetric: 391.0372, val_loss: 392.3886, val_MinusLogProbMetric: 392.3886

Epoch 560: val_loss improved from 392.47617 to 392.38861, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 391.0372 - MinusLogProbMetric: 391.0372 - val_loss: 392.3886 - val_MinusLogProbMetric: 392.3886 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 561/1000
2023-09-10 15:19:42.904 
Epoch 561/1000 
	 loss: 391.0341, MinusLogProbMetric: 391.0341, val_loss: 392.8890, val_MinusLogProbMetric: 392.8890

Epoch 561: val_loss did not improve from 392.38861
196/196 - 9s - loss: 391.0341 - MinusLogProbMetric: 391.0341 - val_loss: 392.8890 - val_MinusLogProbMetric: 392.8890 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 562/1000
2023-09-10 15:19:53.577 
Epoch 562/1000 
	 loss: 391.0873, MinusLogProbMetric: 391.0873, val_loss: 393.0007, val_MinusLogProbMetric: 393.0007

Epoch 562: val_loss did not improve from 392.38861
196/196 - 11s - loss: 391.0873 - MinusLogProbMetric: 391.0873 - val_loss: 393.0007 - val_MinusLogProbMetric: 393.0007 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 563/1000
2023-09-10 15:20:04.333 
Epoch 563/1000 
	 loss: 391.0382, MinusLogProbMetric: 391.0382, val_loss: 392.6020, val_MinusLogProbMetric: 392.6020

Epoch 563: val_loss did not improve from 392.38861
196/196 - 11s - loss: 391.0382 - MinusLogProbMetric: 391.0382 - val_loss: 392.6020 - val_MinusLogProbMetric: 392.6020 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 564/1000
2023-09-10 15:20:14.334 
Epoch 564/1000 
	 loss: 391.0570, MinusLogProbMetric: 391.0570, val_loss: 392.7674, val_MinusLogProbMetric: 392.7674

Epoch 564: val_loss did not improve from 392.38861
196/196 - 10s - loss: 391.0570 - MinusLogProbMetric: 391.0570 - val_loss: 392.7674 - val_MinusLogProbMetric: 392.7674 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 565/1000
2023-09-10 15:20:22.710 
Epoch 565/1000 
	 loss: 391.0103, MinusLogProbMetric: 391.0103, val_loss: 392.8892, val_MinusLogProbMetric: 392.8892

Epoch 565: val_loss did not improve from 392.38861
196/196 - 8s - loss: 391.0103 - MinusLogProbMetric: 391.0103 - val_loss: 392.8892 - val_MinusLogProbMetric: 392.8892 - lr: 8.3333e-05 - 8s/epoch - 43ms/step
Epoch 566/1000
2023-09-10 15:20:32.357 
Epoch 566/1000 
	 loss: 390.9239, MinusLogProbMetric: 390.9239, val_loss: 392.5880, val_MinusLogProbMetric: 392.5880

Epoch 566: val_loss did not improve from 392.38861
196/196 - 10s - loss: 390.9239 - MinusLogProbMetric: 390.9239 - val_loss: 392.5880 - val_MinusLogProbMetric: 392.5880 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 567/1000
2023-09-10 15:20:41.406 
Epoch 567/1000 
	 loss: 390.9480, MinusLogProbMetric: 390.9480, val_loss: 392.6954, val_MinusLogProbMetric: 392.6954

Epoch 567: val_loss did not improve from 392.38861
196/196 - 9s - loss: 390.9480 - MinusLogProbMetric: 390.9480 - val_loss: 392.6954 - val_MinusLogProbMetric: 392.6954 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 568/1000
2023-09-10 15:20:50.573 
Epoch 568/1000 
	 loss: 390.9998, MinusLogProbMetric: 390.9998, val_loss: 393.3653, val_MinusLogProbMetric: 393.3653

Epoch 568: val_loss did not improve from 392.38861
196/196 - 9s - loss: 390.9998 - MinusLogProbMetric: 390.9998 - val_loss: 393.3653 - val_MinusLogProbMetric: 393.3653 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 569/1000
2023-09-10 15:21:02.166 
Epoch 569/1000 
	 loss: 390.8553, MinusLogProbMetric: 390.8553, val_loss: 392.9275, val_MinusLogProbMetric: 392.9275

Epoch 569: val_loss did not improve from 392.38861
196/196 - 12s - loss: 390.8553 - MinusLogProbMetric: 390.8553 - val_loss: 392.9275 - val_MinusLogProbMetric: 392.9275 - lr: 8.3333e-05 - 12s/epoch - 59ms/step
Epoch 570/1000
2023-09-10 15:21:12.578 
Epoch 570/1000 
	 loss: 390.8712, MinusLogProbMetric: 390.8712, val_loss: 392.6185, val_MinusLogProbMetric: 392.6185

Epoch 570: val_loss did not improve from 392.38861
196/196 - 10s - loss: 390.8712 - MinusLogProbMetric: 390.8712 - val_loss: 392.6185 - val_MinusLogProbMetric: 392.6185 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 571/1000
2023-09-10 15:21:22.048 
Epoch 571/1000 
	 loss: 390.7828, MinusLogProbMetric: 390.7828, val_loss: 392.4400, val_MinusLogProbMetric: 392.4400

Epoch 571: val_loss did not improve from 392.38861
196/196 - 9s - loss: 390.7828 - MinusLogProbMetric: 390.7828 - val_loss: 392.4400 - val_MinusLogProbMetric: 392.4400 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 572/1000
2023-09-10 15:21:32.545 
Epoch 572/1000 
	 loss: 390.9160, MinusLogProbMetric: 390.9160, val_loss: 392.7114, val_MinusLogProbMetric: 392.7114

Epoch 572: val_loss did not improve from 392.38861
196/196 - 10s - loss: 390.9160 - MinusLogProbMetric: 390.9160 - val_loss: 392.7114 - val_MinusLogProbMetric: 392.7114 - lr: 8.3333e-05 - 10s/epoch - 54ms/step
Epoch 573/1000
2023-09-10 15:21:41.863 
Epoch 573/1000 
	 loss: 390.9976, MinusLogProbMetric: 390.9976, val_loss: 392.2956, val_MinusLogProbMetric: 392.2956

Epoch 573: val_loss improved from 392.38861 to 392.29559, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 10s - loss: 390.9976 - MinusLogProbMetric: 390.9976 - val_loss: 392.2956 - val_MinusLogProbMetric: 392.2956 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 574/1000
2023-09-10 15:21:53.759 
Epoch 574/1000 
	 loss: 390.9210, MinusLogProbMetric: 390.9210, val_loss: 393.5746, val_MinusLogProbMetric: 393.5746

Epoch 574: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.9210 - MinusLogProbMetric: 390.9210 - val_loss: 393.5746 - val_MinusLogProbMetric: 393.5746 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 575/1000
2023-09-10 15:22:03.651 
Epoch 575/1000 
	 loss: 390.9173, MinusLogProbMetric: 390.9173, val_loss: 393.1585, val_MinusLogProbMetric: 393.1585

Epoch 575: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.9173 - MinusLogProbMetric: 390.9173 - val_loss: 393.1585 - val_MinusLogProbMetric: 393.1585 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 576/1000
2023-09-10 15:22:15.656 
Epoch 576/1000 
	 loss: 391.0354, MinusLogProbMetric: 391.0354, val_loss: 392.5174, val_MinusLogProbMetric: 392.5174

Epoch 576: val_loss did not improve from 392.29559
196/196 - 12s - loss: 391.0354 - MinusLogProbMetric: 391.0354 - val_loss: 392.5174 - val_MinusLogProbMetric: 392.5174 - lr: 8.3333e-05 - 12s/epoch - 61ms/step
Epoch 577/1000
2023-09-10 15:22:25.729 
Epoch 577/1000 
	 loss: 390.8677, MinusLogProbMetric: 390.8677, val_loss: 392.7703, val_MinusLogProbMetric: 392.7703

Epoch 577: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8677 - MinusLogProbMetric: 390.8677 - val_loss: 392.7703 - val_MinusLogProbMetric: 392.7703 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 578/1000
2023-09-10 15:22:36.606 
Epoch 578/1000 
	 loss: 390.8957, MinusLogProbMetric: 390.8957, val_loss: 392.4400, val_MinusLogProbMetric: 392.4400

Epoch 578: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.8957 - MinusLogProbMetric: 390.8957 - val_loss: 392.4400 - val_MinusLogProbMetric: 392.4400 - lr: 8.3333e-05 - 11s/epoch - 56ms/step
Epoch 579/1000
2023-09-10 15:22:46.451 
Epoch 579/1000 
	 loss: 390.8430, MinusLogProbMetric: 390.8430, val_loss: 393.0353, val_MinusLogProbMetric: 393.0353

Epoch 579: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8430 - MinusLogProbMetric: 390.8430 - val_loss: 393.0353 - val_MinusLogProbMetric: 393.0353 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 580/1000
2023-09-10 15:22:57.589 
Epoch 580/1000 
	 loss: 390.8077, MinusLogProbMetric: 390.8077, val_loss: 393.1240, val_MinusLogProbMetric: 393.1240

Epoch 580: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.8077 - MinusLogProbMetric: 390.8077 - val_loss: 393.1240 - val_MinusLogProbMetric: 393.1240 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 581/1000
2023-09-10 15:23:08.012 
Epoch 581/1000 
	 loss: 390.7557, MinusLogProbMetric: 390.7557, val_loss: 392.5298, val_MinusLogProbMetric: 392.5298

Epoch 581: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.7557 - MinusLogProbMetric: 390.7557 - val_loss: 392.5298 - val_MinusLogProbMetric: 392.5298 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 582/1000
2023-09-10 15:23:18.509 
Epoch 582/1000 
	 loss: 390.9129, MinusLogProbMetric: 390.9129, val_loss: 393.2806, val_MinusLogProbMetric: 393.2806

Epoch 582: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.9129 - MinusLogProbMetric: 390.9129 - val_loss: 393.2806 - val_MinusLogProbMetric: 393.2806 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 583/1000
2023-09-10 15:23:29.982 
Epoch 583/1000 
	 loss: 390.9388, MinusLogProbMetric: 390.9388, val_loss: 392.8585, val_MinusLogProbMetric: 392.8585

Epoch 583: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.9388 - MinusLogProbMetric: 390.9388 - val_loss: 392.8585 - val_MinusLogProbMetric: 392.8585 - lr: 8.3333e-05 - 11s/epoch - 58ms/step
Epoch 584/1000
2023-09-10 15:23:38.642 
Epoch 584/1000 
	 loss: 390.8979, MinusLogProbMetric: 390.8979, val_loss: 392.7099, val_MinusLogProbMetric: 392.7099

Epoch 584: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.8979 - MinusLogProbMetric: 390.8979 - val_loss: 392.7099 - val_MinusLogProbMetric: 392.7099 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 585/1000
2023-09-10 15:23:48.142 
Epoch 585/1000 
	 loss: 390.9497, MinusLogProbMetric: 390.9497, val_loss: 392.9418, val_MinusLogProbMetric: 392.9418

Epoch 585: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.9497 - MinusLogProbMetric: 390.9497 - val_loss: 392.9418 - val_MinusLogProbMetric: 392.9418 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 586/1000
2023-09-10 15:23:57.447 
Epoch 586/1000 
	 loss: 390.9893, MinusLogProbMetric: 390.9893, val_loss: 392.4881, val_MinusLogProbMetric: 392.4881

Epoch 586: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.9893 - MinusLogProbMetric: 390.9893 - val_loss: 392.4881 - val_MinusLogProbMetric: 392.4881 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 587/1000
2023-09-10 15:24:07.452 
Epoch 587/1000 
	 loss: 390.7958, MinusLogProbMetric: 390.7958, val_loss: 392.6114, val_MinusLogProbMetric: 392.6114

Epoch 587: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.7958 - MinusLogProbMetric: 390.7958 - val_loss: 392.6114 - val_MinusLogProbMetric: 392.6114 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 588/1000
2023-09-10 15:24:16.423 
Epoch 588/1000 
	 loss: 391.0414, MinusLogProbMetric: 391.0414, val_loss: 393.5740, val_MinusLogProbMetric: 393.5740

Epoch 588: val_loss did not improve from 392.29559
196/196 - 9s - loss: 391.0414 - MinusLogProbMetric: 391.0414 - val_loss: 393.5740 - val_MinusLogProbMetric: 393.5740 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 589/1000
2023-09-10 15:24:27.159 
Epoch 589/1000 
	 loss: 391.1538, MinusLogProbMetric: 391.1538, val_loss: 392.9729, val_MinusLogProbMetric: 392.9729

Epoch 589: val_loss did not improve from 392.29559
196/196 - 11s - loss: 391.1538 - MinusLogProbMetric: 391.1538 - val_loss: 392.9729 - val_MinusLogProbMetric: 392.9729 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 590/1000
2023-09-10 15:24:36.821 
Epoch 590/1000 
	 loss: 390.8680, MinusLogProbMetric: 390.8680, val_loss: 392.4329, val_MinusLogProbMetric: 392.4329

Epoch 590: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8680 - MinusLogProbMetric: 390.8680 - val_loss: 392.4329 - val_MinusLogProbMetric: 392.4329 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 591/1000
2023-09-10 15:24:46.076 
Epoch 591/1000 
	 loss: 391.0452, MinusLogProbMetric: 391.0452, val_loss: 392.5905, val_MinusLogProbMetric: 392.5905

Epoch 591: val_loss did not improve from 392.29559
196/196 - 9s - loss: 391.0452 - MinusLogProbMetric: 391.0452 - val_loss: 392.5905 - val_MinusLogProbMetric: 392.5905 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 592/1000
2023-09-10 15:24:56.609 
Epoch 592/1000 
	 loss: 390.8046, MinusLogProbMetric: 390.8046, val_loss: 394.0220, val_MinusLogProbMetric: 394.0220

Epoch 592: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.8046 - MinusLogProbMetric: 390.8046 - val_loss: 394.0220 - val_MinusLogProbMetric: 394.0220 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 593/1000
2023-09-10 15:25:07.067 
Epoch 593/1000 
	 loss: 390.9832, MinusLogProbMetric: 390.9832, val_loss: 392.7724, val_MinusLogProbMetric: 392.7724

Epoch 593: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.9832 - MinusLogProbMetric: 390.9832 - val_loss: 392.7724 - val_MinusLogProbMetric: 392.7724 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 594/1000
2023-09-10 15:25:16.164 
Epoch 594/1000 
	 loss: 390.8289, MinusLogProbMetric: 390.8289, val_loss: 393.0527, val_MinusLogProbMetric: 393.0527

Epoch 594: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.8289 - MinusLogProbMetric: 390.8289 - val_loss: 393.0527 - val_MinusLogProbMetric: 393.0527 - lr: 8.3333e-05 - 9s/epoch - 46ms/step
Epoch 595/1000
2023-09-10 15:25:26.349 
Epoch 595/1000 
	 loss: 390.7346, MinusLogProbMetric: 390.7346, val_loss: 392.8211, val_MinusLogProbMetric: 392.8211

Epoch 595: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.7346 - MinusLogProbMetric: 390.7346 - val_loss: 392.8211 - val_MinusLogProbMetric: 392.8211 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 596/1000
2023-09-10 15:25:35.587 
Epoch 596/1000 
	 loss: 391.1118, MinusLogProbMetric: 391.1118, val_loss: 393.1049, val_MinusLogProbMetric: 393.1049

Epoch 596: val_loss did not improve from 392.29559
196/196 - 9s - loss: 391.1118 - MinusLogProbMetric: 391.1118 - val_loss: 393.1049 - val_MinusLogProbMetric: 393.1049 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 597/1000
2023-09-10 15:25:47.374 
Epoch 597/1000 
	 loss: 390.7944, MinusLogProbMetric: 390.7944, val_loss: 393.3401, val_MinusLogProbMetric: 393.3401

Epoch 597: val_loss did not improve from 392.29559
196/196 - 12s - loss: 390.7944 - MinusLogProbMetric: 390.7944 - val_loss: 393.3401 - val_MinusLogProbMetric: 393.3401 - lr: 8.3333e-05 - 12s/epoch - 60ms/step
Epoch 598/1000
2023-09-10 15:25:56.748 
Epoch 598/1000 
	 loss: 390.7052, MinusLogProbMetric: 390.7052, val_loss: 392.5740, val_MinusLogProbMetric: 392.5740

Epoch 598: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.7052 - MinusLogProbMetric: 390.7052 - val_loss: 392.5740 - val_MinusLogProbMetric: 392.5740 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 599/1000
2023-09-10 15:26:07.061 
Epoch 599/1000 
	 loss: 390.8021, MinusLogProbMetric: 390.8021, val_loss: 392.4664, val_MinusLogProbMetric: 392.4664

Epoch 599: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8021 - MinusLogProbMetric: 390.8021 - val_loss: 392.4664 - val_MinusLogProbMetric: 392.4664 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 600/1000
2023-09-10 15:26:16.453 
Epoch 600/1000 
	 loss: 390.8653, MinusLogProbMetric: 390.8653, val_loss: 392.5499, val_MinusLogProbMetric: 392.5499

Epoch 600: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.8653 - MinusLogProbMetric: 390.8653 - val_loss: 392.5499 - val_MinusLogProbMetric: 392.5499 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 601/1000
2023-09-10 15:26:25.684 
Epoch 601/1000 
	 loss: 390.6783, MinusLogProbMetric: 390.6783, val_loss: 392.4076, val_MinusLogProbMetric: 392.4076

Epoch 601: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.6783 - MinusLogProbMetric: 390.6783 - val_loss: 392.4076 - val_MinusLogProbMetric: 392.4076 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 602/1000
2023-09-10 15:26:37.838 
Epoch 602/1000 
	 loss: 390.9254, MinusLogProbMetric: 390.9254, val_loss: 393.7529, val_MinusLogProbMetric: 393.7529

Epoch 602: val_loss did not improve from 392.29559
196/196 - 12s - loss: 390.9254 - MinusLogProbMetric: 390.9254 - val_loss: 393.7529 - val_MinusLogProbMetric: 393.7529 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 603/1000
2023-09-10 15:26:45.883 
Epoch 603/1000 
	 loss: 390.8563, MinusLogProbMetric: 390.8563, val_loss: 392.6650, val_MinusLogProbMetric: 392.6650

Epoch 603: val_loss did not improve from 392.29559
196/196 - 8s - loss: 390.8563 - MinusLogProbMetric: 390.8563 - val_loss: 392.6650 - val_MinusLogProbMetric: 392.6650 - lr: 8.3333e-05 - 8s/epoch - 41ms/step
Epoch 604/1000
2023-09-10 15:26:56.308 
Epoch 604/1000 
	 loss: 391.0255, MinusLogProbMetric: 391.0255, val_loss: 393.1686, val_MinusLogProbMetric: 393.1686

Epoch 604: val_loss did not improve from 392.29559
196/196 - 10s - loss: 391.0255 - MinusLogProbMetric: 391.0255 - val_loss: 393.1686 - val_MinusLogProbMetric: 393.1686 - lr: 8.3333e-05 - 10s/epoch - 53ms/step
Epoch 605/1000
2023-09-10 15:27:04.855 
Epoch 605/1000 
	 loss: 390.8750, MinusLogProbMetric: 390.8750, val_loss: 392.8316, val_MinusLogProbMetric: 392.8316

Epoch 605: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.8750 - MinusLogProbMetric: 390.8750 - val_loss: 392.8316 - val_MinusLogProbMetric: 392.8316 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 606/1000
2023-09-10 15:27:15.972 
Epoch 606/1000 
	 loss: 390.9333, MinusLogProbMetric: 390.9333, val_loss: 392.5042, val_MinusLogProbMetric: 392.5042

Epoch 606: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.9333 - MinusLogProbMetric: 390.9333 - val_loss: 392.5042 - val_MinusLogProbMetric: 392.5042 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 607/1000
2023-09-10 15:27:28.582 
Epoch 607/1000 
	 loss: 390.7673, MinusLogProbMetric: 390.7673, val_loss: 393.4077, val_MinusLogProbMetric: 393.4077

Epoch 607: val_loss did not improve from 392.29559
196/196 - 13s - loss: 390.7673 - MinusLogProbMetric: 390.7673 - val_loss: 393.4077 - val_MinusLogProbMetric: 393.4077 - lr: 8.3333e-05 - 13s/epoch - 64ms/step
Epoch 608/1000
2023-09-10 15:27:38.685 
Epoch 608/1000 
	 loss: 390.7038, MinusLogProbMetric: 390.7038, val_loss: 392.3913, val_MinusLogProbMetric: 392.3913

Epoch 608: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.7038 - MinusLogProbMetric: 390.7038 - val_loss: 392.3913 - val_MinusLogProbMetric: 392.3913 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 609/1000
2023-09-10 15:27:47.270 
Epoch 609/1000 
	 loss: 390.7799, MinusLogProbMetric: 390.7799, val_loss: 392.4322, val_MinusLogProbMetric: 392.4322

Epoch 609: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.7799 - MinusLogProbMetric: 390.7799 - val_loss: 392.4322 - val_MinusLogProbMetric: 392.4322 - lr: 8.3333e-05 - 9s/epoch - 44ms/step
Epoch 610/1000
2023-09-10 15:27:56.971 
Epoch 610/1000 
	 loss: 390.8602, MinusLogProbMetric: 390.8602, val_loss: 393.2278, val_MinusLogProbMetric: 393.2278

Epoch 610: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8602 - MinusLogProbMetric: 390.8602 - val_loss: 393.2278 - val_MinusLogProbMetric: 393.2278 - lr: 8.3333e-05 - 10s/epoch - 49ms/step
Epoch 611/1000
2023-09-10 15:28:06.210 
Epoch 611/1000 
	 loss: 390.9590, MinusLogProbMetric: 390.9590, val_loss: 392.5784, val_MinusLogProbMetric: 392.5784

Epoch 611: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.9590 - MinusLogProbMetric: 390.9590 - val_loss: 392.5784 - val_MinusLogProbMetric: 392.5784 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 612/1000
2023-09-10 15:28:16.988 
Epoch 612/1000 
	 loss: 390.7762, MinusLogProbMetric: 390.7762, val_loss: 392.5485, val_MinusLogProbMetric: 392.5485

Epoch 612: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.7762 - MinusLogProbMetric: 390.7762 - val_loss: 392.5485 - val_MinusLogProbMetric: 392.5485 - lr: 8.3333e-05 - 11s/epoch - 55ms/step
Epoch 613/1000
2023-09-10 15:28:26.876 
Epoch 613/1000 
	 loss: 390.9235, MinusLogProbMetric: 390.9235, val_loss: 392.5788, val_MinusLogProbMetric: 392.5788

Epoch 613: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.9235 - MinusLogProbMetric: 390.9235 - val_loss: 392.5788 - val_MinusLogProbMetric: 392.5788 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 614/1000
2023-09-10 15:28:36.697 
Epoch 614/1000 
	 loss: 390.7648, MinusLogProbMetric: 390.7648, val_loss: 393.0286, val_MinusLogProbMetric: 393.0286

Epoch 614: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.7648 - MinusLogProbMetric: 390.7648 - val_loss: 393.0286 - val_MinusLogProbMetric: 393.0286 - lr: 8.3333e-05 - 10s/epoch - 50ms/step
Epoch 615/1000
2023-09-10 15:28:46.647 
Epoch 615/1000 
	 loss: 390.8685, MinusLogProbMetric: 390.8685, val_loss: 392.4539, val_MinusLogProbMetric: 392.4539

Epoch 615: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8685 - MinusLogProbMetric: 390.8685 - val_loss: 392.4539 - val_MinusLogProbMetric: 392.4539 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 616/1000
2023-09-10 15:28:58.722 
Epoch 616/1000 
	 loss: 390.8143, MinusLogProbMetric: 390.8143, val_loss: 392.5522, val_MinusLogProbMetric: 392.5522

Epoch 616: val_loss did not improve from 392.29559
196/196 - 12s - loss: 390.8143 - MinusLogProbMetric: 390.8143 - val_loss: 392.5522 - val_MinusLogProbMetric: 392.5522 - lr: 8.3333e-05 - 12s/epoch - 62ms/step
Epoch 617/1000
2023-09-10 15:29:07.843 
Epoch 617/1000 
	 loss: 390.6501, MinusLogProbMetric: 390.6501, val_loss: 392.5478, val_MinusLogProbMetric: 392.5478

Epoch 617: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.6501 - MinusLogProbMetric: 390.6501 - val_loss: 392.5478 - val_MinusLogProbMetric: 392.5478 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 618/1000
2023-09-10 15:29:17.901 
Epoch 618/1000 
	 loss: 390.8316, MinusLogProbMetric: 390.8316, val_loss: 393.5981, val_MinusLogProbMetric: 393.5981

Epoch 618: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8316 - MinusLogProbMetric: 390.8316 - val_loss: 393.5981 - val_MinusLogProbMetric: 393.5981 - lr: 8.3333e-05 - 10s/epoch - 51ms/step
Epoch 619/1000
2023-09-10 15:29:27.126 
Epoch 619/1000 
	 loss: 390.7540, MinusLogProbMetric: 390.7540, val_loss: 392.8096, val_MinusLogProbMetric: 392.8096

Epoch 619: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.7540 - MinusLogProbMetric: 390.7540 - val_loss: 392.8096 - val_MinusLogProbMetric: 392.8096 - lr: 8.3333e-05 - 9s/epoch - 47ms/step
Epoch 620/1000
2023-09-10 15:29:36.471 
Epoch 620/1000 
	 loss: 390.8890, MinusLogProbMetric: 390.8890, val_loss: 392.5387, val_MinusLogProbMetric: 392.5387

Epoch 620: val_loss did not improve from 392.29559
196/196 - 9s - loss: 390.8890 - MinusLogProbMetric: 390.8890 - val_loss: 392.5387 - val_MinusLogProbMetric: 392.5387 - lr: 8.3333e-05 - 9s/epoch - 48ms/step
Epoch 621/1000
2023-09-10 15:29:47.093 
Epoch 621/1000 
	 loss: 390.7802, MinusLogProbMetric: 390.7802, val_loss: 393.0761, val_MinusLogProbMetric: 393.0761

Epoch 621: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.7802 - MinusLogProbMetric: 390.7802 - val_loss: 393.0761 - val_MinusLogProbMetric: 393.0761 - lr: 8.3333e-05 - 11s/epoch - 54ms/step
Epoch 622/1000
2023-09-10 15:29:57.218 
Epoch 622/1000 
	 loss: 390.8519, MinusLogProbMetric: 390.8519, val_loss: 392.7832, val_MinusLogProbMetric: 392.7832

Epoch 622: val_loss did not improve from 392.29559
196/196 - 10s - loss: 390.8519 - MinusLogProbMetric: 390.8519 - val_loss: 392.7832 - val_MinusLogProbMetric: 392.7832 - lr: 8.3333e-05 - 10s/epoch - 52ms/step
Epoch 623/1000
2023-09-10 15:30:08.352 
Epoch 623/1000 
	 loss: 390.8056, MinusLogProbMetric: 390.8056, val_loss: 392.7578, val_MinusLogProbMetric: 392.7578

Epoch 623: val_loss did not improve from 392.29559
196/196 - 11s - loss: 390.8056 - MinusLogProbMetric: 390.8056 - val_loss: 392.7578 - val_MinusLogProbMetric: 392.7578 - lr: 8.3333e-05 - 11s/epoch - 57ms/step
Epoch 624/1000
2023-09-10 15:30:17.013 
Epoch 624/1000 
	 loss: 390.1246, MinusLogProbMetric: 390.1246, val_loss: 391.9666, val_MinusLogProbMetric: 391.9666

Epoch 624: val_loss improved from 392.29559 to 391.96664, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 390.1246 - MinusLogProbMetric: 390.1246 - val_loss: 391.9666 - val_MinusLogProbMetric: 391.9666 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 625/1000
2023-09-10 15:30:26.547 
Epoch 625/1000 
	 loss: 390.0958, MinusLogProbMetric: 390.0958, val_loss: 391.9801, val_MinusLogProbMetric: 391.9801

Epoch 625: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0958 - MinusLogProbMetric: 390.0958 - val_loss: 391.9801 - val_MinusLogProbMetric: 391.9801 - lr: 4.1667e-05 - 9s/epoch - 45ms/step
Epoch 626/1000
2023-09-10 15:30:36.371 
Epoch 626/1000 
	 loss: 390.0977, MinusLogProbMetric: 390.0977, val_loss: 392.1227, val_MinusLogProbMetric: 392.1227

Epoch 626: val_loss did not improve from 391.96664
196/196 - 10s - loss: 390.0977 - MinusLogProbMetric: 390.0977 - val_loss: 392.1227 - val_MinusLogProbMetric: 392.1227 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 627/1000
2023-09-10 15:30:45.550 
Epoch 627/1000 
	 loss: 390.0918, MinusLogProbMetric: 390.0918, val_loss: 392.2527, val_MinusLogProbMetric: 392.2527

Epoch 627: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0918 - MinusLogProbMetric: 390.0918 - val_loss: 392.2527 - val_MinusLogProbMetric: 392.2527 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 628/1000
2023-09-10 15:30:55.306 
Epoch 628/1000 
	 loss: 390.0953, MinusLogProbMetric: 390.0953, val_loss: 392.1044, val_MinusLogProbMetric: 392.1044

Epoch 628: val_loss did not improve from 391.96664
196/196 - 10s - loss: 390.0953 - MinusLogProbMetric: 390.0953 - val_loss: 392.1044 - val_MinusLogProbMetric: 392.1044 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 629/1000
2023-09-10 15:31:03.790 
Epoch 629/1000 
	 loss: 390.1185, MinusLogProbMetric: 390.1185, val_loss: 392.4387, val_MinusLogProbMetric: 392.4387

Epoch 629: val_loss did not improve from 391.96664
196/196 - 8s - loss: 390.1185 - MinusLogProbMetric: 390.1185 - val_loss: 392.4387 - val_MinusLogProbMetric: 392.4387 - lr: 4.1667e-05 - 8s/epoch - 43ms/step
Epoch 630/1000
2023-09-10 15:31:12.746 
Epoch 630/1000 
	 loss: 390.0787, MinusLogProbMetric: 390.0787, val_loss: 392.0950, val_MinusLogProbMetric: 392.0950

Epoch 630: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0787 - MinusLogProbMetric: 390.0787 - val_loss: 392.0950 - val_MinusLogProbMetric: 392.0950 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 631/1000
2023-09-10 15:31:23.579 
Epoch 631/1000 
	 loss: 390.0609, MinusLogProbMetric: 390.0609, val_loss: 392.1524, val_MinusLogProbMetric: 392.1524

Epoch 631: val_loss did not improve from 391.96664
196/196 - 11s - loss: 390.0609 - MinusLogProbMetric: 390.0609 - val_loss: 392.1524 - val_MinusLogProbMetric: 392.1524 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 632/1000
2023-09-10 15:31:32.859 
Epoch 632/1000 
	 loss: 390.0838, MinusLogProbMetric: 390.0838, val_loss: 392.1676, val_MinusLogProbMetric: 392.1676

Epoch 632: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0838 - MinusLogProbMetric: 390.0838 - val_loss: 392.1676 - val_MinusLogProbMetric: 392.1676 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 633/1000
2023-09-10 15:31:41.493 
Epoch 633/1000 
	 loss: 390.0959, MinusLogProbMetric: 390.0959, val_loss: 392.1588, val_MinusLogProbMetric: 392.1588

Epoch 633: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0959 - MinusLogProbMetric: 390.0959 - val_loss: 392.1588 - val_MinusLogProbMetric: 392.1588 - lr: 4.1667e-05 - 9s/epoch - 44ms/step
Epoch 634/1000
2023-09-10 15:31:52.673 
Epoch 634/1000 
	 loss: 390.1332, MinusLogProbMetric: 390.1332, val_loss: 392.1302, val_MinusLogProbMetric: 392.1302

Epoch 634: val_loss did not improve from 391.96664
196/196 - 11s - loss: 390.1332 - MinusLogProbMetric: 390.1332 - val_loss: 392.1302 - val_MinusLogProbMetric: 392.1302 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 635/1000
2023-09-10 15:32:02.072 
Epoch 635/1000 
	 loss: 390.1147, MinusLogProbMetric: 390.1147, val_loss: 392.2605, val_MinusLogProbMetric: 392.2605

Epoch 635: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.1147 - MinusLogProbMetric: 390.1147 - val_loss: 392.2605 - val_MinusLogProbMetric: 392.2605 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 636/1000
2023-09-10 15:32:13.925 
Epoch 636/1000 
	 loss: 390.1348, MinusLogProbMetric: 390.1348, val_loss: 392.6041, val_MinusLogProbMetric: 392.6041

Epoch 636: val_loss did not improve from 391.96664
196/196 - 12s - loss: 390.1348 - MinusLogProbMetric: 390.1348 - val_loss: 392.6041 - val_MinusLogProbMetric: 392.6041 - lr: 4.1667e-05 - 12s/epoch - 60ms/step
Epoch 637/1000
2023-09-10 15:32:24.228 
Epoch 637/1000 
	 loss: 390.1387, MinusLogProbMetric: 390.1387, val_loss: 391.9729, val_MinusLogProbMetric: 391.9729

Epoch 637: val_loss did not improve from 391.96664
196/196 - 10s - loss: 390.1387 - MinusLogProbMetric: 390.1387 - val_loss: 391.9729 - val_MinusLogProbMetric: 391.9729 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 638/1000
2023-09-10 15:32:34.874 
Epoch 638/1000 
	 loss: 390.0592, MinusLogProbMetric: 390.0592, val_loss: 392.4419, val_MinusLogProbMetric: 392.4419

Epoch 638: val_loss did not improve from 391.96664
196/196 - 11s - loss: 390.0592 - MinusLogProbMetric: 390.0592 - val_loss: 392.4419 - val_MinusLogProbMetric: 392.4419 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 639/1000
2023-09-10 15:32:44.200 
Epoch 639/1000 
	 loss: 390.0562, MinusLogProbMetric: 390.0562, val_loss: 391.9885, val_MinusLogProbMetric: 391.9885

Epoch 639: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0562 - MinusLogProbMetric: 390.0562 - val_loss: 391.9885 - val_MinusLogProbMetric: 391.9885 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 640/1000
2023-09-10 15:32:53.705 
Epoch 640/1000 
	 loss: 390.0539, MinusLogProbMetric: 390.0539, val_loss: 392.1521, val_MinusLogProbMetric: 392.1521

Epoch 640: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0539 - MinusLogProbMetric: 390.0539 - val_loss: 392.1521 - val_MinusLogProbMetric: 392.1521 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 641/1000
2023-09-10 15:33:04.211 
Epoch 641/1000 
	 loss: 390.0342, MinusLogProbMetric: 390.0342, val_loss: 392.0366, val_MinusLogProbMetric: 392.0366

Epoch 641: val_loss did not improve from 391.96664
196/196 - 10s - loss: 390.0342 - MinusLogProbMetric: 390.0342 - val_loss: 392.0366 - val_MinusLogProbMetric: 392.0366 - lr: 4.1667e-05 - 10s/epoch - 54ms/step
Epoch 642/1000
2023-09-10 15:33:13.490 
Epoch 642/1000 
	 loss: 390.0669, MinusLogProbMetric: 390.0669, val_loss: 392.4108, val_MinusLogProbMetric: 392.4108

Epoch 642: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0669 - MinusLogProbMetric: 390.0669 - val_loss: 392.4108 - val_MinusLogProbMetric: 392.4108 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 643/1000
2023-09-10 15:33:25.448 
Epoch 643/1000 
	 loss: 390.0551, MinusLogProbMetric: 390.0551, val_loss: 392.2752, val_MinusLogProbMetric: 392.2752

Epoch 643: val_loss did not improve from 391.96664
196/196 - 12s - loss: 390.0551 - MinusLogProbMetric: 390.0551 - val_loss: 392.2752 - val_MinusLogProbMetric: 392.2752 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 644/1000
2023-09-10 15:33:34.776 
Epoch 644/1000 
	 loss: 390.0796, MinusLogProbMetric: 390.0796, val_loss: 391.9953, val_MinusLogProbMetric: 391.9953

Epoch 644: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0796 - MinusLogProbMetric: 390.0796 - val_loss: 391.9953 - val_MinusLogProbMetric: 391.9953 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 645/1000
2023-09-10 15:33:44.105 
Epoch 645/1000 
	 loss: 390.1026, MinusLogProbMetric: 390.1026, val_loss: 392.0702, val_MinusLogProbMetric: 392.0702

Epoch 645: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.1026 - MinusLogProbMetric: 390.1026 - val_loss: 392.0702 - val_MinusLogProbMetric: 392.0702 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 646/1000
2023-09-10 15:33:54.082 
Epoch 646/1000 
	 loss: 390.0958, MinusLogProbMetric: 390.0958, val_loss: 392.1758, val_MinusLogProbMetric: 392.1758

Epoch 646: val_loss did not improve from 391.96664
196/196 - 10s - loss: 390.0958 - MinusLogProbMetric: 390.0958 - val_loss: 392.1758 - val_MinusLogProbMetric: 392.1758 - lr: 4.1667e-05 - 10s/epoch - 51ms/step
Epoch 647/1000
2023-09-10 15:34:03.540 
Epoch 647/1000 
	 loss: 390.1622, MinusLogProbMetric: 390.1622, val_loss: 391.9764, val_MinusLogProbMetric: 391.9764

Epoch 647: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.1622 - MinusLogProbMetric: 390.1622 - val_loss: 391.9764 - val_MinusLogProbMetric: 391.9764 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 648/1000
2023-09-10 15:34:13.308 
Epoch 648/1000 
	 loss: 390.1778, MinusLogProbMetric: 390.1778, val_loss: 392.1621, val_MinusLogProbMetric: 392.1621

Epoch 648: val_loss did not improve from 391.96664
196/196 - 10s - loss: 390.1778 - MinusLogProbMetric: 390.1778 - val_loss: 392.1621 - val_MinusLogProbMetric: 392.1621 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 649/1000
2023-09-10 15:34:22.788 
Epoch 649/1000 
	 loss: 390.0874, MinusLogProbMetric: 390.0874, val_loss: 391.9971, val_MinusLogProbMetric: 391.9971

Epoch 649: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0874 - MinusLogProbMetric: 390.0874 - val_loss: 391.9971 - val_MinusLogProbMetric: 391.9971 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 650/1000
2023-09-10 15:34:33.320 
Epoch 650/1000 
	 loss: 389.9788, MinusLogProbMetric: 389.9788, val_loss: 392.3650, val_MinusLogProbMetric: 392.3650

Epoch 650: val_loss did not improve from 391.96664
196/196 - 11s - loss: 389.9788 - MinusLogProbMetric: 389.9788 - val_loss: 392.3650 - val_MinusLogProbMetric: 392.3650 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 651/1000
2023-09-10 15:34:42.820 
Epoch 651/1000 
	 loss: 390.0374, MinusLogProbMetric: 390.0374, val_loss: 391.9879, val_MinusLogProbMetric: 391.9879

Epoch 651: val_loss did not improve from 391.96664
196/196 - 10s - loss: 390.0374 - MinusLogProbMetric: 390.0374 - val_loss: 391.9879 - val_MinusLogProbMetric: 391.9879 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 652/1000
2023-09-10 15:34:53.646 
Epoch 652/1000 
	 loss: 390.0525, MinusLogProbMetric: 390.0525, val_loss: 392.0021, val_MinusLogProbMetric: 392.0021

Epoch 652: val_loss did not improve from 391.96664
196/196 - 11s - loss: 390.0525 - MinusLogProbMetric: 390.0525 - val_loss: 392.0021 - val_MinusLogProbMetric: 392.0021 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 653/1000
2023-09-10 15:35:02.810 
Epoch 653/1000 
	 loss: 390.0142, MinusLogProbMetric: 390.0142, val_loss: 392.0895, val_MinusLogProbMetric: 392.0895

Epoch 653: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0142 - MinusLogProbMetric: 390.0142 - val_loss: 392.0895 - val_MinusLogProbMetric: 392.0895 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 654/1000
2023-09-10 15:35:11.969 
Epoch 654/1000 
	 loss: 390.0444, MinusLogProbMetric: 390.0444, val_loss: 392.1467, val_MinusLogProbMetric: 392.1467

Epoch 654: val_loss did not improve from 391.96664
196/196 - 9s - loss: 390.0444 - MinusLogProbMetric: 390.0444 - val_loss: 392.1467 - val_MinusLogProbMetric: 392.1467 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 655/1000
2023-09-10 15:35:23.254 
Epoch 655/1000 
	 loss: 390.0089, MinusLogProbMetric: 390.0089, val_loss: 391.9800, val_MinusLogProbMetric: 391.9800

Epoch 655: val_loss did not improve from 391.96664
196/196 - 11s - loss: 390.0089 - MinusLogProbMetric: 390.0089 - val_loss: 391.9800 - val_MinusLogProbMetric: 391.9800 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 656/1000
2023-09-10 15:35:32.048 
Epoch 656/1000 
	 loss: 390.0450, MinusLogProbMetric: 390.0450, val_loss: 391.9071, val_MinusLogProbMetric: 391.9071

Epoch 656: val_loss improved from 391.96664 to 391.90710, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 390.0450 - MinusLogProbMetric: 390.0450 - val_loss: 391.9071 - val_MinusLogProbMetric: 391.9071 - lr: 4.1667e-05 - 9s/epoch - 47ms/step
Epoch 657/1000
2023-09-10 15:35:43.264 
Epoch 657/1000 
	 loss: 389.9988, MinusLogProbMetric: 389.9988, val_loss: 392.1367, val_MinusLogProbMetric: 392.1367

Epoch 657: val_loss did not improve from 391.90710
196/196 - 11s - loss: 389.9988 - MinusLogProbMetric: 389.9988 - val_loss: 392.1367 - val_MinusLogProbMetric: 392.1367 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 658/1000
2023-09-10 15:35:53.367 
Epoch 658/1000 
	 loss: 390.0014, MinusLogProbMetric: 390.0014, val_loss: 392.1127, val_MinusLogProbMetric: 392.1127

Epoch 658: val_loss did not improve from 391.90710
196/196 - 10s - loss: 390.0014 - MinusLogProbMetric: 390.0014 - val_loss: 392.1127 - val_MinusLogProbMetric: 392.1127 - lr: 4.1667e-05 - 10s/epoch - 51ms/step
Epoch 659/1000
2023-09-10 15:36:04.168 
Epoch 659/1000 
	 loss: 390.0201, MinusLogProbMetric: 390.0201, val_loss: 391.9037, val_MinusLogProbMetric: 391.9037

Epoch 659: val_loss improved from 391.90710 to 391.90366, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 11s - loss: 390.0201 - MinusLogProbMetric: 390.0201 - val_loss: 391.9037 - val_MinusLogProbMetric: 391.9037 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 660/1000
2023-09-10 15:36:15.102 
Epoch 660/1000 
	 loss: 390.0135, MinusLogProbMetric: 390.0135, val_loss: 392.4184, val_MinusLogProbMetric: 392.4184

Epoch 660: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0135 - MinusLogProbMetric: 390.0135 - val_loss: 392.4184 - val_MinusLogProbMetric: 392.4184 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 661/1000
2023-09-10 15:36:24.576 
Epoch 661/1000 
	 loss: 390.1062, MinusLogProbMetric: 390.1062, val_loss: 392.3769, val_MinusLogProbMetric: 392.3769

Epoch 661: val_loss did not improve from 391.90366
196/196 - 9s - loss: 390.1062 - MinusLogProbMetric: 390.1062 - val_loss: 392.3769 - val_MinusLogProbMetric: 392.3769 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 662/1000
2023-09-10 15:36:36.539 
Epoch 662/1000 
	 loss: 390.0180, MinusLogProbMetric: 390.0180, val_loss: 392.0734, val_MinusLogProbMetric: 392.0734

Epoch 662: val_loss did not improve from 391.90366
196/196 - 12s - loss: 390.0180 - MinusLogProbMetric: 390.0180 - val_loss: 392.0734 - val_MinusLogProbMetric: 392.0734 - lr: 4.1667e-05 - 12s/epoch - 61ms/step
Epoch 663/1000
2023-09-10 15:36:47.260 
Epoch 663/1000 
	 loss: 390.0240, MinusLogProbMetric: 390.0240, val_loss: 392.4269, val_MinusLogProbMetric: 392.4269

Epoch 663: val_loss did not improve from 391.90366
196/196 - 11s - loss: 390.0240 - MinusLogProbMetric: 390.0240 - val_loss: 392.4269 - val_MinusLogProbMetric: 392.4269 - lr: 4.1667e-05 - 11s/epoch - 55ms/step
Epoch 664/1000
2023-09-10 15:36:58.657 
Epoch 664/1000 
	 loss: 390.0122, MinusLogProbMetric: 390.0122, val_loss: 393.0288, val_MinusLogProbMetric: 393.0288

Epoch 664: val_loss did not improve from 391.90366
196/196 - 11s - loss: 390.0122 - MinusLogProbMetric: 390.0122 - val_loss: 393.0288 - val_MinusLogProbMetric: 393.0288 - lr: 4.1667e-05 - 11s/epoch - 58ms/step
Epoch 665/1000
2023-09-10 15:37:08.248 
Epoch 665/1000 
	 loss: 390.0865, MinusLogProbMetric: 390.0865, val_loss: 391.9442, val_MinusLogProbMetric: 391.9442

Epoch 665: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0865 - MinusLogProbMetric: 390.0865 - val_loss: 391.9442 - val_MinusLogProbMetric: 391.9442 - lr: 4.1667e-05 - 10s/epoch - 49ms/step
Epoch 666/1000
2023-09-10 15:37:18.061 
Epoch 666/1000 
	 loss: 390.0988, MinusLogProbMetric: 390.0988, val_loss: 392.1035, val_MinusLogProbMetric: 392.1035

Epoch 666: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0988 - MinusLogProbMetric: 390.0988 - val_loss: 392.1035 - val_MinusLogProbMetric: 392.1035 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 667/1000
2023-09-10 15:37:27.051 
Epoch 667/1000 
	 loss: 390.0708, MinusLogProbMetric: 390.0708, val_loss: 392.1763, val_MinusLogProbMetric: 392.1763

Epoch 667: val_loss did not improve from 391.90366
196/196 - 9s - loss: 390.0708 - MinusLogProbMetric: 390.0708 - val_loss: 392.1763 - val_MinusLogProbMetric: 392.1763 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 668/1000
2023-09-10 15:37:36.033 
Epoch 668/1000 
	 loss: 390.0942, MinusLogProbMetric: 390.0942, val_loss: 392.2161, val_MinusLogProbMetric: 392.2161

Epoch 668: val_loss did not improve from 391.90366
196/196 - 9s - loss: 390.0942 - MinusLogProbMetric: 390.0942 - val_loss: 392.2161 - val_MinusLogProbMetric: 392.2161 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 669/1000
2023-09-10 15:37:45.845 
Epoch 669/1000 
	 loss: 389.9944, MinusLogProbMetric: 389.9944, val_loss: 392.0323, val_MinusLogProbMetric: 392.0323

Epoch 669: val_loss did not improve from 391.90366
196/196 - 10s - loss: 389.9944 - MinusLogProbMetric: 389.9944 - val_loss: 392.0323 - val_MinusLogProbMetric: 392.0323 - lr: 4.1667e-05 - 10s/epoch - 50ms/step
Epoch 670/1000
2023-09-10 15:37:56.159 
Epoch 670/1000 
	 loss: 390.0002, MinusLogProbMetric: 390.0002, val_loss: 391.9959, val_MinusLogProbMetric: 391.9959

Epoch 670: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0002 - MinusLogProbMetric: 390.0002 - val_loss: 391.9959 - val_MinusLogProbMetric: 391.9959 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 671/1000
2023-09-10 15:38:06.813 
Epoch 671/1000 
	 loss: 389.9327, MinusLogProbMetric: 389.9327, val_loss: 392.0079, val_MinusLogProbMetric: 392.0079

Epoch 671: val_loss did not improve from 391.90366
196/196 - 11s - loss: 389.9327 - MinusLogProbMetric: 389.9327 - val_loss: 392.0079 - val_MinusLogProbMetric: 392.0079 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 672/1000
2023-09-10 15:38:16.139 
Epoch 672/1000 
	 loss: 390.0239, MinusLogProbMetric: 390.0239, val_loss: 392.1773, val_MinusLogProbMetric: 392.1773

Epoch 672: val_loss did not improve from 391.90366
196/196 - 9s - loss: 390.0239 - MinusLogProbMetric: 390.0239 - val_loss: 392.1773 - val_MinusLogProbMetric: 392.1773 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 673/1000
2023-09-10 15:38:25.646 
Epoch 673/1000 
	 loss: 390.0483, MinusLogProbMetric: 390.0483, val_loss: 392.0049, val_MinusLogProbMetric: 392.0049

Epoch 673: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0483 - MinusLogProbMetric: 390.0483 - val_loss: 392.0049 - val_MinusLogProbMetric: 392.0049 - lr: 4.1667e-05 - 10s/epoch - 48ms/step
Epoch 674/1000
2023-09-10 15:38:35.855 
Epoch 674/1000 
	 loss: 390.0147, MinusLogProbMetric: 390.0147, val_loss: 392.0578, val_MinusLogProbMetric: 392.0578

Epoch 674: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0147 - MinusLogProbMetric: 390.0147 - val_loss: 392.0578 - val_MinusLogProbMetric: 392.0578 - lr: 4.1667e-05 - 10s/epoch - 52ms/step
Epoch 675/1000
2023-09-10 15:38:46.872 
Epoch 675/1000 
	 loss: 389.9985, MinusLogProbMetric: 389.9985, val_loss: 392.1066, val_MinusLogProbMetric: 392.1066

Epoch 675: val_loss did not improve from 391.90366
196/196 - 11s - loss: 389.9985 - MinusLogProbMetric: 389.9985 - val_loss: 392.1066 - val_MinusLogProbMetric: 392.1066 - lr: 4.1667e-05 - 11s/epoch - 56ms/step
Epoch 676/1000
2023-09-10 15:38:56.841 
Epoch 676/1000 
	 loss: 390.0107, MinusLogProbMetric: 390.0107, val_loss: 392.2514, val_MinusLogProbMetric: 392.2514

Epoch 676: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0107 - MinusLogProbMetric: 390.0107 - val_loss: 392.2514 - val_MinusLogProbMetric: 392.2514 - lr: 4.1667e-05 - 10s/epoch - 51ms/step
Epoch 677/1000
2023-09-10 15:39:07.178 
Epoch 677/1000 
	 loss: 390.0516, MinusLogProbMetric: 390.0516, val_loss: 392.0351, val_MinusLogProbMetric: 392.0351

Epoch 677: val_loss did not improve from 391.90366
196/196 - 10s - loss: 390.0516 - MinusLogProbMetric: 390.0516 - val_loss: 392.0351 - val_MinusLogProbMetric: 392.0351 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 678/1000
2023-09-10 15:39:17.722 
Epoch 678/1000 
	 loss: 389.9861, MinusLogProbMetric: 389.9861, val_loss: 392.0563, val_MinusLogProbMetric: 392.0563

Epoch 678: val_loss did not improve from 391.90366
196/196 - 11s - loss: 389.9861 - MinusLogProbMetric: 389.9861 - val_loss: 392.0563 - val_MinusLogProbMetric: 392.0563 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 679/1000
2023-09-10 15:39:26.691 
Epoch 679/1000 
	 loss: 390.0321, MinusLogProbMetric: 390.0321, val_loss: 392.0116, val_MinusLogProbMetric: 392.0116

Epoch 679: val_loss did not improve from 391.90366
196/196 - 9s - loss: 390.0321 - MinusLogProbMetric: 390.0321 - val_loss: 392.0116 - val_MinusLogProbMetric: 392.0116 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 680/1000
2023-09-10 15:39:37.926 
Epoch 680/1000 
	 loss: 389.9613, MinusLogProbMetric: 389.9613, val_loss: 392.0588, val_MinusLogProbMetric: 392.0588

Epoch 680: val_loss did not improve from 391.90366
196/196 - 11s - loss: 389.9613 - MinusLogProbMetric: 389.9613 - val_loss: 392.0588 - val_MinusLogProbMetric: 392.0588 - lr: 4.1667e-05 - 11s/epoch - 57ms/step
Epoch 681/1000
2023-09-10 15:39:46.802 
Epoch 681/1000 
	 loss: 389.9635, MinusLogProbMetric: 389.9635, val_loss: 391.8942, val_MinusLogProbMetric: 391.8942

Epoch 681: val_loss improved from 391.90366 to 391.89423, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 9s - loss: 389.9635 - MinusLogProbMetric: 389.9635 - val_loss: 391.8942 - val_MinusLogProbMetric: 391.8942 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 682/1000
2023-09-10 15:39:56.754 
Epoch 682/1000 
	 loss: 389.9253, MinusLogProbMetric: 389.9253, val_loss: 391.9909, val_MinusLogProbMetric: 391.9909

Epoch 682: val_loss did not improve from 391.89423
196/196 - 9s - loss: 389.9253 - MinusLogProbMetric: 389.9253 - val_loss: 391.9909 - val_MinusLogProbMetric: 391.9909 - lr: 4.1667e-05 - 9s/epoch - 48ms/step
Epoch 683/1000
2023-09-10 15:40:07.312 
Epoch 683/1000 
	 loss: 389.9617, MinusLogProbMetric: 389.9617, val_loss: 392.2453, val_MinusLogProbMetric: 392.2453

Epoch 683: val_loss did not improve from 391.89423
196/196 - 11s - loss: 389.9617 - MinusLogProbMetric: 389.9617 - val_loss: 392.2453 - val_MinusLogProbMetric: 392.2453 - lr: 4.1667e-05 - 11s/epoch - 54ms/step
Epoch 684/1000
2023-09-10 15:40:16.331 
Epoch 684/1000 
	 loss: 389.9650, MinusLogProbMetric: 389.9650, val_loss: 392.1233, val_MinusLogProbMetric: 392.1233

Epoch 684: val_loss did not improve from 391.89423
196/196 - 9s - loss: 389.9650 - MinusLogProbMetric: 389.9650 - val_loss: 392.1233 - val_MinusLogProbMetric: 392.1233 - lr: 4.1667e-05 - 9s/epoch - 46ms/step
Epoch 685/1000
2023-09-10 15:40:26.740 
Epoch 685/1000 
	 loss: 389.9929, MinusLogProbMetric: 389.9929, val_loss: 392.2443, val_MinusLogProbMetric: 392.2443

Epoch 685: val_loss did not improve from 391.89423
196/196 - 10s - loss: 389.9929 - MinusLogProbMetric: 389.9929 - val_loss: 392.2443 - val_MinusLogProbMetric: 392.2443 - lr: 4.1667e-05 - 10s/epoch - 53ms/step
Epoch 686/1000
2023-09-10 15:40:41.445 
Epoch 686/1000 
	 loss: 389.9398, MinusLogProbMetric: 389.9398, val_loss: 392.0956, val_MinusLogProbMetric: 392.0956

Epoch 686: val_loss did not improve from 391.89423
196/196 - 15s - loss: 389.9398 - MinusLogProbMetric: 389.9398 - val_loss: 392.0956 - val_MinusLogProbMetric: 392.0956 - lr: 4.1667e-05 - 15s/epoch - 75ms/step
Epoch 687/1000
2023-09-10 15:40:58.781 
Epoch 687/1000 
	 loss: 389.9561, MinusLogProbMetric: 389.9561, val_loss: 392.0826, val_MinusLogProbMetric: 392.0826

Epoch 687: val_loss did not improve from 391.89423
196/196 - 17s - loss: 389.9561 - MinusLogProbMetric: 389.9561 - val_loss: 392.0826 - val_MinusLogProbMetric: 392.0826 - lr: 4.1667e-05 - 17s/epoch - 88ms/step
Epoch 688/1000
2023-09-10 15:41:15.292 
Epoch 688/1000 
	 loss: 389.9001, MinusLogProbMetric: 389.9001, val_loss: 392.0487, val_MinusLogProbMetric: 392.0487

Epoch 688: val_loss did not improve from 391.89423
196/196 - 17s - loss: 389.9001 - MinusLogProbMetric: 389.9001 - val_loss: 392.0487 - val_MinusLogProbMetric: 392.0487 - lr: 4.1667e-05 - 17s/epoch - 84ms/step
Epoch 689/1000
2023-09-10 15:41:30.650 
Epoch 689/1000 
	 loss: 389.9003, MinusLogProbMetric: 389.9003, val_loss: 392.0115, val_MinusLogProbMetric: 392.0115

Epoch 689: val_loss did not improve from 391.89423
196/196 - 15s - loss: 389.9003 - MinusLogProbMetric: 389.9003 - val_loss: 392.0115 - val_MinusLogProbMetric: 392.0115 - lr: 4.1667e-05 - 15s/epoch - 78ms/step
Epoch 690/1000
2023-09-10 15:41:48.765 
Epoch 690/1000 
	 loss: 389.8973, MinusLogProbMetric: 389.8973, val_loss: 391.9515, val_MinusLogProbMetric: 391.9515

Epoch 690: val_loss did not improve from 391.89423
196/196 - 18s - loss: 389.8973 - MinusLogProbMetric: 389.8973 - val_loss: 391.9515 - val_MinusLogProbMetric: 391.9515 - lr: 4.1667e-05 - 18s/epoch - 92ms/step
Epoch 691/1000
2023-09-10 15:42:05.688 
Epoch 691/1000 
	 loss: 389.9322, MinusLogProbMetric: 389.9322, val_loss: 391.9041, val_MinusLogProbMetric: 391.9041

Epoch 691: val_loss did not improve from 391.89423
196/196 - 17s - loss: 389.9322 - MinusLogProbMetric: 389.9322 - val_loss: 391.9041 - val_MinusLogProbMetric: 391.9041 - lr: 4.1667e-05 - 17s/epoch - 86ms/step
Epoch 692/1000
2023-09-10 15:42:22.949 
Epoch 692/1000 
	 loss: 389.9489, MinusLogProbMetric: 389.9489, val_loss: 392.1266, val_MinusLogProbMetric: 392.1266

Epoch 692: val_loss did not improve from 391.89423
196/196 - 17s - loss: 389.9489 - MinusLogProbMetric: 389.9489 - val_loss: 392.1266 - val_MinusLogProbMetric: 392.1266 - lr: 4.1667e-05 - 17s/epoch - 88ms/step
Epoch 693/1000
2023-09-10 15:42:41.146 
Epoch 693/1000 
	 loss: 389.9379, MinusLogProbMetric: 389.9379, val_loss: 392.0295, val_MinusLogProbMetric: 392.0295

Epoch 693: val_loss did not improve from 391.89423
196/196 - 18s - loss: 389.9379 - MinusLogProbMetric: 389.9379 - val_loss: 392.0295 - val_MinusLogProbMetric: 392.0295 - lr: 4.1667e-05 - 18s/epoch - 93ms/step
Epoch 694/1000
2023-09-10 15:43:00.722 
Epoch 694/1000 
	 loss: 389.9283, MinusLogProbMetric: 389.9283, val_loss: 392.1595, val_MinusLogProbMetric: 392.1595

Epoch 694: val_loss did not improve from 391.89423
196/196 - 20s - loss: 389.9283 - MinusLogProbMetric: 389.9283 - val_loss: 392.1595 - val_MinusLogProbMetric: 392.1595 - lr: 4.1667e-05 - 20s/epoch - 100ms/step
Epoch 695/1000
2023-09-10 15:43:17.628 
Epoch 695/1000 
	 loss: 390.0075, MinusLogProbMetric: 390.0075, val_loss: 392.0516, val_MinusLogProbMetric: 392.0516

Epoch 695: val_loss did not improve from 391.89423
196/196 - 17s - loss: 390.0075 - MinusLogProbMetric: 390.0075 - val_loss: 392.0516 - val_MinusLogProbMetric: 392.0516 - lr: 4.1667e-05 - 17s/epoch - 86ms/step
Epoch 696/1000
2023-09-10 15:43:37.956 
Epoch 696/1000 
	 loss: 389.8956, MinusLogProbMetric: 389.8956, val_loss: 392.0527, val_MinusLogProbMetric: 392.0527

Epoch 696: val_loss did not improve from 391.89423
196/196 - 20s - loss: 389.8956 - MinusLogProbMetric: 389.8956 - val_loss: 392.0527 - val_MinusLogProbMetric: 392.0527 - lr: 4.1667e-05 - 20s/epoch - 104ms/step
Epoch 697/1000
2023-09-10 15:44:00.900 
Epoch 697/1000 
	 loss: 389.9099, MinusLogProbMetric: 389.9099, val_loss: 391.9699, val_MinusLogProbMetric: 391.9699

Epoch 697: val_loss did not improve from 391.89423
196/196 - 23s - loss: 389.9099 - MinusLogProbMetric: 389.9099 - val_loss: 391.9699 - val_MinusLogProbMetric: 391.9699 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 698/1000
2023-09-10 15:44:17.593 
Epoch 698/1000 
	 loss: 389.8870, MinusLogProbMetric: 389.8870, val_loss: 392.0513, val_MinusLogProbMetric: 392.0513

Epoch 698: val_loss did not improve from 391.89423
196/196 - 17s - loss: 389.8870 - MinusLogProbMetric: 389.8870 - val_loss: 392.0513 - val_MinusLogProbMetric: 392.0513 - lr: 4.1667e-05 - 17s/epoch - 85ms/step
Epoch 699/1000
2023-09-10 15:44:37.164 
Epoch 699/1000 
	 loss: 389.9367, MinusLogProbMetric: 389.9367, val_loss: 392.3247, val_MinusLogProbMetric: 392.3247

Epoch 699: val_loss did not improve from 391.89423
196/196 - 20s - loss: 389.9367 - MinusLogProbMetric: 389.9367 - val_loss: 392.3247 - val_MinusLogProbMetric: 392.3247 - lr: 4.1667e-05 - 20s/epoch - 100ms/step
Epoch 700/1000
2023-09-10 15:44:55.754 
Epoch 700/1000 
	 loss: 389.9881, MinusLogProbMetric: 389.9881, val_loss: 391.8517, val_MinusLogProbMetric: 391.8517

Epoch 700: val_loss improved from 391.89423 to 391.85172, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 19s - loss: 389.9881 - MinusLogProbMetric: 389.9881 - val_loss: 391.8517 - val_MinusLogProbMetric: 391.8517 - lr: 4.1667e-05 - 19s/epoch - 99ms/step
Epoch 701/1000
2023-09-10 15:45:12.886 
Epoch 701/1000 
	 loss: 389.8549, MinusLogProbMetric: 389.8549, val_loss: 392.2132, val_MinusLogProbMetric: 392.2132

Epoch 701: val_loss did not improve from 391.85172
196/196 - 16s - loss: 389.8549 - MinusLogProbMetric: 389.8549 - val_loss: 392.2132 - val_MinusLogProbMetric: 392.2132 - lr: 4.1667e-05 - 16s/epoch - 83ms/step
Epoch 702/1000
2023-09-10 15:45:31.342 
Epoch 702/1000 
	 loss: 389.8520, MinusLogProbMetric: 389.8520, val_loss: 392.0239, val_MinusLogProbMetric: 392.0239

Epoch 702: val_loss did not improve from 391.85172
196/196 - 18s - loss: 389.8520 - MinusLogProbMetric: 389.8520 - val_loss: 392.0239 - val_MinusLogProbMetric: 392.0239 - lr: 4.1667e-05 - 18s/epoch - 94ms/step
Epoch 703/1000
2023-09-10 15:45:55.215 
Epoch 703/1000 
	 loss: 389.8727, MinusLogProbMetric: 389.8727, val_loss: 391.9632, val_MinusLogProbMetric: 391.9632

Epoch 703: val_loss did not improve from 391.85172
196/196 - 24s - loss: 389.8727 - MinusLogProbMetric: 389.8727 - val_loss: 391.9632 - val_MinusLogProbMetric: 391.9632 - lr: 4.1667e-05 - 24s/epoch - 122ms/step
Epoch 704/1000
2023-09-10 15:46:15.249 
Epoch 704/1000 
	 loss: 389.8575, MinusLogProbMetric: 389.8575, val_loss: 391.9558, val_MinusLogProbMetric: 391.9558

Epoch 704: val_loss did not improve from 391.85172
196/196 - 20s - loss: 389.8575 - MinusLogProbMetric: 389.8575 - val_loss: 391.9558 - val_MinusLogProbMetric: 391.9558 - lr: 4.1667e-05 - 20s/epoch - 102ms/step
Epoch 705/1000
2023-09-10 15:46:33.608 
Epoch 705/1000 
	 loss: 389.8708, MinusLogProbMetric: 389.8708, val_loss: 392.2820, val_MinusLogProbMetric: 392.2820

Epoch 705: val_loss did not improve from 391.85172
196/196 - 18s - loss: 389.8708 - MinusLogProbMetric: 389.8708 - val_loss: 392.2820 - val_MinusLogProbMetric: 392.2820 - lr: 4.1667e-05 - 18s/epoch - 94ms/step
Epoch 706/1000
2023-09-10 15:46:50.178 
Epoch 706/1000 
	 loss: 389.9305, MinusLogProbMetric: 389.9305, val_loss: 391.8701, val_MinusLogProbMetric: 391.8701

Epoch 706: val_loss did not improve from 391.85172
196/196 - 17s - loss: 389.9305 - MinusLogProbMetric: 389.9305 - val_loss: 391.8701 - val_MinusLogProbMetric: 391.8701 - lr: 4.1667e-05 - 17s/epoch - 84ms/step
Epoch 707/1000
2023-09-10 15:47:08.247 
Epoch 707/1000 
	 loss: 389.8353, MinusLogProbMetric: 389.8353, val_loss: 392.2650, val_MinusLogProbMetric: 392.2650

Epoch 707: val_loss did not improve from 391.85172
196/196 - 18s - loss: 389.8353 - MinusLogProbMetric: 389.8353 - val_loss: 392.2650 - val_MinusLogProbMetric: 392.2650 - lr: 4.1667e-05 - 18s/epoch - 92ms/step
Epoch 708/1000
2023-09-10 15:47:28.429 
Epoch 708/1000 
	 loss: 389.9099, MinusLogProbMetric: 389.9099, val_loss: 392.0176, val_MinusLogProbMetric: 392.0176

Epoch 708: val_loss did not improve from 391.85172
196/196 - 20s - loss: 389.9099 - MinusLogProbMetric: 389.9099 - val_loss: 392.0176 - val_MinusLogProbMetric: 392.0176 - lr: 4.1667e-05 - 20s/epoch - 103ms/step
Epoch 709/1000
2023-09-10 15:47:49.073 
Epoch 709/1000 
	 loss: 389.8083, MinusLogProbMetric: 389.8083, val_loss: 392.0250, val_MinusLogProbMetric: 392.0250

Epoch 709: val_loss did not improve from 391.85172
196/196 - 21s - loss: 389.8083 - MinusLogProbMetric: 389.8083 - val_loss: 392.0250 - val_MinusLogProbMetric: 392.0250 - lr: 4.1667e-05 - 21s/epoch - 105ms/step
Epoch 710/1000
2023-09-10 15:48:07.254 
Epoch 710/1000 
	 loss: 389.8839, MinusLogProbMetric: 389.8839, val_loss: 392.5607, val_MinusLogProbMetric: 392.5607

Epoch 710: val_loss did not improve from 391.85172
196/196 - 18s - loss: 389.8839 - MinusLogProbMetric: 389.8839 - val_loss: 392.5607 - val_MinusLogProbMetric: 392.5607 - lr: 4.1667e-05 - 18s/epoch - 93ms/step
Epoch 711/1000
2023-09-10 15:48:26.525 
Epoch 711/1000 
	 loss: 389.8750, MinusLogProbMetric: 389.8750, val_loss: 391.9656, val_MinusLogProbMetric: 391.9656

Epoch 711: val_loss did not improve from 391.85172
196/196 - 19s - loss: 389.8750 - MinusLogProbMetric: 389.8750 - val_loss: 391.9656 - val_MinusLogProbMetric: 391.9656 - lr: 4.1667e-05 - 19s/epoch - 98ms/step
Epoch 712/1000
2023-09-10 15:48:45.000 
Epoch 712/1000 
	 loss: 389.9121, MinusLogProbMetric: 389.9121, val_loss: 391.8957, val_MinusLogProbMetric: 391.8957

Epoch 712: val_loss did not improve from 391.85172
196/196 - 18s - loss: 389.9121 - MinusLogProbMetric: 389.9121 - val_loss: 391.8957 - val_MinusLogProbMetric: 391.8957 - lr: 4.1667e-05 - 18s/epoch - 94ms/step
Epoch 713/1000
2023-09-10 15:49:03.488 
Epoch 713/1000 
	 loss: 389.9456, MinusLogProbMetric: 389.9456, val_loss: 392.3412, val_MinusLogProbMetric: 392.3412

Epoch 713: val_loss did not improve from 391.85172
196/196 - 19s - loss: 389.9456 - MinusLogProbMetric: 389.9456 - val_loss: 392.3412 - val_MinusLogProbMetric: 392.3412 - lr: 4.1667e-05 - 19s/epoch - 94ms/step
Epoch 714/1000
2023-09-10 15:49:23.822 
Epoch 714/1000 
	 loss: 390.0644, MinusLogProbMetric: 390.0644, val_loss: 392.2879, val_MinusLogProbMetric: 392.2879

Epoch 714: val_loss did not improve from 391.85172
196/196 - 20s - loss: 390.0644 - MinusLogProbMetric: 390.0644 - val_loss: 392.2879 - val_MinusLogProbMetric: 392.2879 - lr: 4.1667e-05 - 20s/epoch - 104ms/step
Epoch 715/1000
2023-09-10 15:49:43.766 
Epoch 715/1000 
	 loss: 389.9868, MinusLogProbMetric: 389.9868, val_loss: 392.7875, val_MinusLogProbMetric: 392.7875

Epoch 715: val_loss did not improve from 391.85172
196/196 - 20s - loss: 389.9868 - MinusLogProbMetric: 389.9868 - val_loss: 392.7875 - val_MinusLogProbMetric: 392.7875 - lr: 4.1667e-05 - 20s/epoch - 102ms/step
Epoch 716/1000
2023-09-10 15:50:02.690 
Epoch 716/1000 
	 loss: 390.0020, MinusLogProbMetric: 390.0020, val_loss: 391.9470, val_MinusLogProbMetric: 391.9470

Epoch 716: val_loss did not improve from 391.85172
196/196 - 19s - loss: 390.0020 - MinusLogProbMetric: 390.0020 - val_loss: 391.9470 - val_MinusLogProbMetric: 391.9470 - lr: 4.1667e-05 - 19s/epoch - 97ms/step
Epoch 717/1000
2023-09-10 15:50:24.454 
Epoch 717/1000 
	 loss: 389.9706, MinusLogProbMetric: 389.9706, val_loss: 392.4161, val_MinusLogProbMetric: 392.4161

Epoch 717: val_loss did not improve from 391.85172
196/196 - 22s - loss: 389.9706 - MinusLogProbMetric: 389.9706 - val_loss: 392.4161 - val_MinusLogProbMetric: 392.4161 - lr: 4.1667e-05 - 22s/epoch - 111ms/step
Epoch 718/1000
2023-09-10 15:50:40.449 
Epoch 718/1000 
	 loss: 389.9719, MinusLogProbMetric: 389.9719, val_loss: 392.8701, val_MinusLogProbMetric: 392.8701

Epoch 718: val_loss did not improve from 391.85172
196/196 - 16s - loss: 389.9719 - MinusLogProbMetric: 389.9719 - val_loss: 392.8701 - val_MinusLogProbMetric: 392.8701 - lr: 4.1667e-05 - 16s/epoch - 82ms/step
Epoch 719/1000
2023-09-10 15:50:56.743 
Epoch 719/1000 
	 loss: 389.9774, MinusLogProbMetric: 389.9774, val_loss: 392.0723, val_MinusLogProbMetric: 392.0723

Epoch 719: val_loss did not improve from 391.85172
196/196 - 16s - loss: 389.9774 - MinusLogProbMetric: 389.9774 - val_loss: 392.0723 - val_MinusLogProbMetric: 392.0723 - lr: 4.1667e-05 - 16s/epoch - 83ms/step
Epoch 720/1000
2023-09-10 15:51:15.167 
Epoch 720/1000 
	 loss: 389.8924, MinusLogProbMetric: 389.8924, val_loss: 392.1729, val_MinusLogProbMetric: 392.1729

Epoch 720: val_loss did not improve from 391.85172
196/196 - 18s - loss: 389.8924 - MinusLogProbMetric: 389.8924 - val_loss: 392.1729 - val_MinusLogProbMetric: 392.1729 - lr: 4.1667e-05 - 18s/epoch - 94ms/step
Epoch 721/1000
2023-09-10 15:51:37.417 
Epoch 721/1000 
	 loss: 389.9198, MinusLogProbMetric: 389.9198, val_loss: 391.8654, val_MinusLogProbMetric: 391.8654

Epoch 721: val_loss did not improve from 391.85172
196/196 - 22s - loss: 389.9198 - MinusLogProbMetric: 389.9198 - val_loss: 391.8654 - val_MinusLogProbMetric: 391.8654 - lr: 4.1667e-05 - 22s/epoch - 113ms/step
Epoch 722/1000
2023-09-10 15:51:58.354 
Epoch 722/1000 
	 loss: 389.9076, MinusLogProbMetric: 389.9076, val_loss: 391.8629, val_MinusLogProbMetric: 391.8629

Epoch 722: val_loss did not improve from 391.85172
196/196 - 21s - loss: 389.9076 - MinusLogProbMetric: 389.9076 - val_loss: 391.8629 - val_MinusLogProbMetric: 391.8629 - lr: 4.1667e-05 - 21s/epoch - 107ms/step
Epoch 723/1000
2023-09-10 15:52:21.298 
Epoch 723/1000 
	 loss: 389.8367, MinusLogProbMetric: 389.8367, val_loss: 391.9001, val_MinusLogProbMetric: 391.9001

Epoch 723: val_loss did not improve from 391.85172
196/196 - 23s - loss: 389.8367 - MinusLogProbMetric: 389.8367 - val_loss: 391.9001 - val_MinusLogProbMetric: 391.9001 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 724/1000
2023-09-10 15:52:44.064 
Epoch 724/1000 
	 loss: 389.8459, MinusLogProbMetric: 389.8459, val_loss: 392.1048, val_MinusLogProbMetric: 392.1048

Epoch 724: val_loss did not improve from 391.85172
196/196 - 23s - loss: 389.8459 - MinusLogProbMetric: 389.8459 - val_loss: 392.1048 - val_MinusLogProbMetric: 392.1048 - lr: 4.1667e-05 - 23s/epoch - 116ms/step
Epoch 725/1000
2023-09-10 15:53:08.088 
Epoch 725/1000 
	 loss: 389.8003, MinusLogProbMetric: 389.8003, val_loss: 392.3228, val_MinusLogProbMetric: 392.3228

Epoch 725: val_loss did not improve from 391.85172
196/196 - 24s - loss: 389.8003 - MinusLogProbMetric: 389.8003 - val_loss: 392.3228 - val_MinusLogProbMetric: 392.3228 - lr: 4.1667e-05 - 24s/epoch - 123ms/step
Epoch 726/1000
2023-09-10 15:53:35.649 
Epoch 726/1000 
	 loss: 389.8431, MinusLogProbMetric: 389.8431, val_loss: 391.8751, val_MinusLogProbMetric: 391.8751

Epoch 726: val_loss did not improve from 391.85172
196/196 - 28s - loss: 389.8431 - MinusLogProbMetric: 389.8431 - val_loss: 391.8751 - val_MinusLogProbMetric: 391.8751 - lr: 4.1667e-05 - 28s/epoch - 140ms/step
Epoch 727/1000
2023-09-10 15:53:58.595 
Epoch 727/1000 
	 loss: 389.7788, MinusLogProbMetric: 389.7788, val_loss: 391.9461, val_MinusLogProbMetric: 391.9461

Epoch 727: val_loss did not improve from 391.85172
196/196 - 23s - loss: 389.7788 - MinusLogProbMetric: 389.7788 - val_loss: 391.9461 - val_MinusLogProbMetric: 391.9461 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 728/1000
2023-09-10 15:54:22.168 
Epoch 728/1000 
	 loss: 389.8022, MinusLogProbMetric: 389.8022, val_loss: 391.9127, val_MinusLogProbMetric: 391.9127

Epoch 728: val_loss did not improve from 391.85172
196/196 - 24s - loss: 389.8022 - MinusLogProbMetric: 389.8022 - val_loss: 391.9127 - val_MinusLogProbMetric: 391.9127 - lr: 4.1667e-05 - 24s/epoch - 120ms/step
Epoch 729/1000
2023-09-10 15:54:49.178 
Epoch 729/1000 
	 loss: 389.7955, MinusLogProbMetric: 389.7955, val_loss: 392.0425, val_MinusLogProbMetric: 392.0425

Epoch 729: val_loss did not improve from 391.85172
196/196 - 27s - loss: 389.7955 - MinusLogProbMetric: 389.7955 - val_loss: 392.0425 - val_MinusLogProbMetric: 392.0425 - lr: 4.1667e-05 - 27s/epoch - 138ms/step
Epoch 730/1000
2023-09-10 15:55:13.350 
Epoch 730/1000 
	 loss: 389.8427, MinusLogProbMetric: 389.8427, val_loss: 392.1833, val_MinusLogProbMetric: 392.1833

Epoch 730: val_loss did not improve from 391.85172
196/196 - 24s - loss: 389.8427 - MinusLogProbMetric: 389.8427 - val_loss: 392.1833 - val_MinusLogProbMetric: 392.1833 - lr: 4.1667e-05 - 24s/epoch - 123ms/step
Epoch 731/1000
2023-09-10 15:55:37.547 
Epoch 731/1000 
	 loss: 389.9155, MinusLogProbMetric: 389.9155, val_loss: 391.7789, val_MinusLogProbMetric: 391.7789

Epoch 731: val_loss improved from 391.85172 to 391.77890, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 25s - loss: 389.9155 - MinusLogProbMetric: 389.9155 - val_loss: 391.7789 - val_MinusLogProbMetric: 391.7789 - lr: 4.1667e-05 - 25s/epoch - 128ms/step
Epoch 732/1000
2023-09-10 15:56:05.615 
Epoch 732/1000 
	 loss: 389.8042, MinusLogProbMetric: 389.8042, val_loss: 391.8917, val_MinusLogProbMetric: 391.8917

Epoch 732: val_loss did not improve from 391.77890
196/196 - 27s - loss: 389.8042 - MinusLogProbMetric: 389.8042 - val_loss: 391.8917 - val_MinusLogProbMetric: 391.8917 - lr: 4.1667e-05 - 27s/epoch - 138ms/step
Epoch 733/1000
2023-09-10 15:56:32.197 
Epoch 733/1000 
	 loss: 389.8647, MinusLogProbMetric: 389.8647, val_loss: 392.0243, val_MinusLogProbMetric: 392.0243

Epoch 733: val_loss did not improve from 391.77890
196/196 - 27s - loss: 389.8647 - MinusLogProbMetric: 389.8647 - val_loss: 392.0243 - val_MinusLogProbMetric: 392.0243 - lr: 4.1667e-05 - 27s/epoch - 136ms/step
Epoch 734/1000
2023-09-10 15:56:58.464 
Epoch 734/1000 
	 loss: 389.8154, MinusLogProbMetric: 389.8154, val_loss: 392.4318, val_MinusLogProbMetric: 392.4318

Epoch 734: val_loss did not improve from 391.77890
196/196 - 26s - loss: 389.8154 - MinusLogProbMetric: 389.8154 - val_loss: 392.4318 - val_MinusLogProbMetric: 392.4318 - lr: 4.1667e-05 - 26s/epoch - 134ms/step
Epoch 735/1000
2023-09-10 15:57:22.709 
Epoch 735/1000 
	 loss: 389.8534, MinusLogProbMetric: 389.8534, val_loss: 392.2563, val_MinusLogProbMetric: 392.2563

Epoch 735: val_loss did not improve from 391.77890
196/196 - 24s - loss: 389.8534 - MinusLogProbMetric: 389.8534 - val_loss: 392.2563 - val_MinusLogProbMetric: 392.2563 - lr: 4.1667e-05 - 24s/epoch - 124ms/step
Epoch 736/1000
2023-09-10 15:57:43.690 
Epoch 736/1000 
	 loss: 389.8454, MinusLogProbMetric: 389.8454, val_loss: 391.8537, val_MinusLogProbMetric: 391.8537

Epoch 736: val_loss did not improve from 391.77890
196/196 - 21s - loss: 389.8454 - MinusLogProbMetric: 389.8454 - val_loss: 391.8537 - val_MinusLogProbMetric: 391.8537 - lr: 4.1667e-05 - 21s/epoch - 107ms/step
Epoch 737/1000
2023-09-10 15:58:11.048 
Epoch 737/1000 
	 loss: 389.9650, MinusLogProbMetric: 389.9650, val_loss: 392.1668, val_MinusLogProbMetric: 392.1668

Epoch 737: val_loss did not improve from 391.77890
196/196 - 27s - loss: 389.9650 - MinusLogProbMetric: 389.9650 - val_loss: 392.1668 - val_MinusLogProbMetric: 392.1668 - lr: 4.1667e-05 - 27s/epoch - 140ms/step
Epoch 738/1000
2023-09-10 15:58:32.285 
Epoch 738/1000 
	 loss: 389.8675, MinusLogProbMetric: 389.8675, val_loss: 391.7803, val_MinusLogProbMetric: 391.7803

Epoch 738: val_loss did not improve from 391.77890
196/196 - 21s - loss: 389.8675 - MinusLogProbMetric: 389.8675 - val_loss: 391.7803 - val_MinusLogProbMetric: 391.7803 - lr: 4.1667e-05 - 21s/epoch - 108ms/step
Epoch 739/1000
2023-09-10 15:59:00.239 
Epoch 739/1000 
	 loss: 389.8129, MinusLogProbMetric: 389.8129, val_loss: 391.9201, val_MinusLogProbMetric: 391.9201

Epoch 739: val_loss did not improve from 391.77890
196/196 - 28s - loss: 389.8129 - MinusLogProbMetric: 389.8129 - val_loss: 391.9201 - val_MinusLogProbMetric: 391.9201 - lr: 4.1667e-05 - 28s/epoch - 142ms/step
Epoch 740/1000
2023-09-10 15:59:24.444 
Epoch 740/1000 
	 loss: 389.8598, MinusLogProbMetric: 389.8598, val_loss: 392.0602, val_MinusLogProbMetric: 392.0602

Epoch 740: val_loss did not improve from 391.77890
196/196 - 24s - loss: 389.8598 - MinusLogProbMetric: 389.8598 - val_loss: 392.0602 - val_MinusLogProbMetric: 392.0602 - lr: 4.1667e-05 - 24s/epoch - 123ms/step
Epoch 741/1000
2023-09-10 15:59:52.152 
Epoch 741/1000 
	 loss: 389.8490, MinusLogProbMetric: 389.8490, val_loss: 391.6710, val_MinusLogProbMetric: 391.6710

Epoch 741: val_loss improved from 391.77890 to 391.67099, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 29s - loss: 389.8490 - MinusLogProbMetric: 389.8490 - val_loss: 391.6710 - val_MinusLogProbMetric: 391.6710 - lr: 4.1667e-05 - 29s/epoch - 146ms/step
Epoch 742/1000
2023-09-10 16:00:19.614 
Epoch 742/1000 
	 loss: 389.8210, MinusLogProbMetric: 389.8210, val_loss: 391.7828, val_MinusLogProbMetric: 391.7828

Epoch 742: val_loss did not improve from 391.67099
196/196 - 26s - loss: 389.8210 - MinusLogProbMetric: 389.8210 - val_loss: 391.7828 - val_MinusLogProbMetric: 391.7828 - lr: 4.1667e-05 - 26s/epoch - 135ms/step
Epoch 743/1000
2023-09-10 16:00:46.602 
Epoch 743/1000 
	 loss: 389.8588, MinusLogProbMetric: 389.8588, val_loss: 391.9909, val_MinusLogProbMetric: 391.9909

Epoch 743: val_loss did not improve from 391.67099
196/196 - 27s - loss: 389.8588 - MinusLogProbMetric: 389.8588 - val_loss: 391.9909 - val_MinusLogProbMetric: 391.9909 - lr: 4.1667e-05 - 27s/epoch - 138ms/step
Epoch 744/1000
2023-09-10 16:01:11.769 
Epoch 744/1000 
	 loss: 389.8353, MinusLogProbMetric: 389.8353, val_loss: 391.8511, val_MinusLogProbMetric: 391.8511

Epoch 744: val_loss did not improve from 391.67099
196/196 - 25s - loss: 389.8353 - MinusLogProbMetric: 389.8353 - val_loss: 391.8511 - val_MinusLogProbMetric: 391.8511 - lr: 4.1667e-05 - 25s/epoch - 128ms/step
Epoch 745/1000
2023-09-10 16:01:34.479 
Epoch 745/1000 
	 loss: 389.9128, MinusLogProbMetric: 389.9128, val_loss: 392.0803, val_MinusLogProbMetric: 392.0803

Epoch 745: val_loss did not improve from 391.67099
196/196 - 23s - loss: 389.9128 - MinusLogProbMetric: 389.9128 - val_loss: 392.0803 - val_MinusLogProbMetric: 392.0803 - lr: 4.1667e-05 - 23s/epoch - 116ms/step
Epoch 746/1000
2023-09-10 16:01:55.168 
Epoch 746/1000 
	 loss: 389.7916, MinusLogProbMetric: 389.7916, val_loss: 391.7900, val_MinusLogProbMetric: 391.7900

Epoch 746: val_loss did not improve from 391.67099
196/196 - 21s - loss: 389.7916 - MinusLogProbMetric: 389.7916 - val_loss: 391.7900 - val_MinusLogProbMetric: 391.7900 - lr: 4.1667e-05 - 21s/epoch - 105ms/step
Epoch 747/1000
2023-09-10 16:02:17.752 
Epoch 747/1000 
	 loss: 389.7937, MinusLogProbMetric: 389.7937, val_loss: 391.8742, val_MinusLogProbMetric: 391.8742

Epoch 747: val_loss did not improve from 391.67099
196/196 - 23s - loss: 389.7937 - MinusLogProbMetric: 389.7937 - val_loss: 391.8742 - val_MinusLogProbMetric: 391.8742 - lr: 4.1667e-05 - 23s/epoch - 115ms/step
Epoch 748/1000
2023-09-10 16:02:46.548 
Epoch 748/1000 
	 loss: 389.8683, MinusLogProbMetric: 389.8683, val_loss: 391.8930, val_MinusLogProbMetric: 391.8930

Epoch 748: val_loss did not improve from 391.67099
196/196 - 29s - loss: 389.8683 - MinusLogProbMetric: 389.8683 - val_loss: 391.8930 - val_MinusLogProbMetric: 391.8930 - lr: 4.1667e-05 - 29s/epoch - 147ms/step
Epoch 749/1000
2023-09-10 16:03:13.642 
Epoch 749/1000 
	 loss: 389.8835, MinusLogProbMetric: 389.8835, val_loss: 392.0844, val_MinusLogProbMetric: 392.0844

Epoch 749: val_loss did not improve from 391.67099
196/196 - 27s - loss: 389.8835 - MinusLogProbMetric: 389.8835 - val_loss: 392.0844 - val_MinusLogProbMetric: 392.0844 - lr: 4.1667e-05 - 27s/epoch - 138ms/step
Epoch 750/1000
2023-09-10 16:03:42.729 
Epoch 750/1000 
	 loss: 389.8007, MinusLogProbMetric: 389.8007, val_loss: 391.8932, val_MinusLogProbMetric: 391.8932

Epoch 750: val_loss did not improve from 391.67099
196/196 - 29s - loss: 389.8007 - MinusLogProbMetric: 389.8007 - val_loss: 391.8932 - val_MinusLogProbMetric: 391.8932 - lr: 4.1667e-05 - 29s/epoch - 149ms/step
Epoch 751/1000
2023-09-10 16:04:08.817 
Epoch 751/1000 
	 loss: 389.8893, MinusLogProbMetric: 389.8893, val_loss: 391.9341, val_MinusLogProbMetric: 391.9341

Epoch 751: val_loss did not improve from 391.67099
196/196 - 26s - loss: 389.8893 - MinusLogProbMetric: 389.8893 - val_loss: 391.9341 - val_MinusLogProbMetric: 391.9341 - lr: 4.1667e-05 - 26s/epoch - 133ms/step
Epoch 752/1000
2023-09-10 16:04:31.045 
Epoch 752/1000 
	 loss: 389.8799, MinusLogProbMetric: 389.8799, val_loss: 391.8623, val_MinusLogProbMetric: 391.8623

Epoch 752: val_loss did not improve from 391.67099
196/196 - 22s - loss: 389.8799 - MinusLogProbMetric: 389.8799 - val_loss: 391.8623 - val_MinusLogProbMetric: 391.8623 - lr: 4.1667e-05 - 22s/epoch - 113ms/step
Epoch 753/1000
2023-09-10 16:04:56.996 
Epoch 753/1000 
	 loss: 389.8780, MinusLogProbMetric: 389.8780, val_loss: 392.0864, val_MinusLogProbMetric: 392.0864

Epoch 753: val_loss did not improve from 391.67099
196/196 - 26s - loss: 389.8780 - MinusLogProbMetric: 389.8780 - val_loss: 392.0864 - val_MinusLogProbMetric: 392.0864 - lr: 4.1667e-05 - 26s/epoch - 133ms/step
Epoch 754/1000
2023-09-10 16:05:19.679 
Epoch 754/1000 
	 loss: 389.9523, MinusLogProbMetric: 389.9523, val_loss: 391.9394, val_MinusLogProbMetric: 391.9394

Epoch 754: val_loss did not improve from 391.67099
196/196 - 23s - loss: 389.9523 - MinusLogProbMetric: 389.9523 - val_loss: 391.9394 - val_MinusLogProbMetric: 391.9394 - lr: 4.1667e-05 - 23s/epoch - 116ms/step
Epoch 755/1000
2023-09-10 16:05:40.553 
Epoch 755/1000 
	 loss: 389.9171, MinusLogProbMetric: 389.9171, val_loss: 391.8770, val_MinusLogProbMetric: 391.8770

Epoch 755: val_loss did not improve from 391.67099
196/196 - 21s - loss: 389.9171 - MinusLogProbMetric: 389.9171 - val_loss: 391.8770 - val_MinusLogProbMetric: 391.8770 - lr: 4.1667e-05 - 21s/epoch - 107ms/step
Epoch 756/1000
2023-09-10 16:06:02.216 
Epoch 756/1000 
	 loss: 389.8627, MinusLogProbMetric: 389.8627, val_loss: 391.9845, val_MinusLogProbMetric: 391.9845

Epoch 756: val_loss did not improve from 391.67099
196/196 - 22s - loss: 389.8627 - MinusLogProbMetric: 389.8627 - val_loss: 391.9845 - val_MinusLogProbMetric: 391.9845 - lr: 4.1667e-05 - 22s/epoch - 110ms/step
Epoch 757/1000
2023-09-10 16:06:20.531 
Epoch 757/1000 
	 loss: 389.8937, MinusLogProbMetric: 389.8937, val_loss: 391.8618, val_MinusLogProbMetric: 391.8618

Epoch 757: val_loss did not improve from 391.67099
196/196 - 18s - loss: 389.8937 - MinusLogProbMetric: 389.8937 - val_loss: 391.8618 - val_MinusLogProbMetric: 391.8618 - lr: 4.1667e-05 - 18s/epoch - 94ms/step
Epoch 758/1000
2023-09-10 16:06:39.132 
Epoch 758/1000 
	 loss: 389.8186, MinusLogProbMetric: 389.8186, val_loss: 391.9115, val_MinusLogProbMetric: 391.9115

Epoch 758: val_loss did not improve from 391.67099
196/196 - 19s - loss: 389.8186 - MinusLogProbMetric: 389.8186 - val_loss: 391.9115 - val_MinusLogProbMetric: 391.9115 - lr: 4.1667e-05 - 19s/epoch - 95ms/step
Epoch 759/1000
2023-09-10 16:07:01.736 
Epoch 759/1000 
	 loss: 389.8699, MinusLogProbMetric: 389.8699, val_loss: 391.7337, val_MinusLogProbMetric: 391.7337

Epoch 759: val_loss did not improve from 391.67099
196/196 - 23s - loss: 389.8699 - MinusLogProbMetric: 389.8699 - val_loss: 391.7337 - val_MinusLogProbMetric: 391.7337 - lr: 4.1667e-05 - 23s/epoch - 115ms/step
Epoch 760/1000
2023-09-10 16:07:23.562 
Epoch 760/1000 
	 loss: 389.8245, MinusLogProbMetric: 389.8245, val_loss: 391.8296, val_MinusLogProbMetric: 391.8296

Epoch 760: val_loss did not improve from 391.67099
196/196 - 22s - loss: 389.8245 - MinusLogProbMetric: 389.8245 - val_loss: 391.8296 - val_MinusLogProbMetric: 391.8296 - lr: 4.1667e-05 - 22s/epoch - 111ms/step
Epoch 761/1000
2023-09-10 16:07:44.899 
Epoch 761/1000 
	 loss: 389.8052, MinusLogProbMetric: 389.8052, val_loss: 392.1631, val_MinusLogProbMetric: 392.1631

Epoch 761: val_loss did not improve from 391.67099
196/196 - 21s - loss: 389.8052 - MinusLogProbMetric: 389.8052 - val_loss: 392.1631 - val_MinusLogProbMetric: 392.1631 - lr: 4.1667e-05 - 21s/epoch - 109ms/step
Epoch 762/1000
2023-09-10 16:08:10.019 
Epoch 762/1000 
	 loss: 389.7539, MinusLogProbMetric: 389.7539, val_loss: 391.8169, val_MinusLogProbMetric: 391.8169

Epoch 762: val_loss did not improve from 391.67099
196/196 - 25s - loss: 389.7539 - MinusLogProbMetric: 389.7539 - val_loss: 391.8169 - val_MinusLogProbMetric: 391.8169 - lr: 4.1667e-05 - 25s/epoch - 128ms/step
Epoch 763/1000
2023-09-10 16:08:31.977 
Epoch 763/1000 
	 loss: 389.7550, MinusLogProbMetric: 389.7550, val_loss: 391.7559, val_MinusLogProbMetric: 391.7559

Epoch 763: val_loss did not improve from 391.67099
196/196 - 22s - loss: 389.7550 - MinusLogProbMetric: 389.7550 - val_loss: 391.7559 - val_MinusLogProbMetric: 391.7559 - lr: 4.1667e-05 - 22s/epoch - 112ms/step
Epoch 764/1000
2023-09-10 16:08:52.569 
Epoch 764/1000 
	 loss: 389.7778, MinusLogProbMetric: 389.7778, val_loss: 391.7913, val_MinusLogProbMetric: 391.7913

Epoch 764: val_loss did not improve from 391.67099
196/196 - 21s - loss: 389.7778 - MinusLogProbMetric: 389.7778 - val_loss: 391.7913 - val_MinusLogProbMetric: 391.7913 - lr: 4.1667e-05 - 21s/epoch - 105ms/step
Epoch 765/1000
2023-09-10 16:09:17.008 
Epoch 765/1000 
	 loss: 389.7587, MinusLogProbMetric: 389.7587, val_loss: 391.8843, val_MinusLogProbMetric: 391.8843

Epoch 765: val_loss did not improve from 391.67099
196/196 - 24s - loss: 389.7587 - MinusLogProbMetric: 389.7587 - val_loss: 391.8843 - val_MinusLogProbMetric: 391.8843 - lr: 4.1667e-05 - 24s/epoch - 125ms/step
Epoch 766/1000
2023-09-10 16:09:41.996 
Epoch 766/1000 
	 loss: 389.7197, MinusLogProbMetric: 389.7197, val_loss: 392.0178, val_MinusLogProbMetric: 392.0178

Epoch 766: val_loss did not improve from 391.67099
196/196 - 25s - loss: 389.7197 - MinusLogProbMetric: 389.7197 - val_loss: 392.0178 - val_MinusLogProbMetric: 392.0178 - lr: 4.1667e-05 - 25s/epoch - 127ms/step
Epoch 767/1000
2023-09-10 16:10:07.309 
Epoch 767/1000 
	 loss: 389.7745, MinusLogProbMetric: 389.7745, val_loss: 392.2276, val_MinusLogProbMetric: 392.2276

Epoch 767: val_loss did not improve from 391.67099
196/196 - 25s - loss: 389.7745 - MinusLogProbMetric: 389.7745 - val_loss: 392.2276 - val_MinusLogProbMetric: 392.2276 - lr: 4.1667e-05 - 25s/epoch - 129ms/step
Epoch 768/1000
2023-09-10 16:10:29.785 
Epoch 768/1000 
	 loss: 389.8221, MinusLogProbMetric: 389.8221, val_loss: 391.8626, val_MinusLogProbMetric: 391.8626

Epoch 768: val_loss did not improve from 391.67099
196/196 - 22s - loss: 389.8221 - MinusLogProbMetric: 389.8221 - val_loss: 391.8626 - val_MinusLogProbMetric: 391.8626 - lr: 4.1667e-05 - 22s/epoch - 115ms/step
Epoch 769/1000
2023-09-10 16:10:50.803 
Epoch 769/1000 
	 loss: 389.8140, MinusLogProbMetric: 389.8140, val_loss: 392.2572, val_MinusLogProbMetric: 392.2572

Epoch 769: val_loss did not improve from 391.67099
196/196 - 21s - loss: 389.8140 - MinusLogProbMetric: 389.8140 - val_loss: 392.2572 - val_MinusLogProbMetric: 392.2572 - lr: 4.1667e-05 - 21s/epoch - 107ms/step
Epoch 770/1000
2023-09-10 16:11:14.987 
Epoch 770/1000 
	 loss: 389.8083, MinusLogProbMetric: 389.8083, val_loss: 391.7725, val_MinusLogProbMetric: 391.7725

Epoch 770: val_loss did not improve from 391.67099
196/196 - 24s - loss: 389.8083 - MinusLogProbMetric: 389.8083 - val_loss: 391.7725 - val_MinusLogProbMetric: 391.7725 - lr: 4.1667e-05 - 24s/epoch - 123ms/step
Epoch 771/1000
2023-09-10 16:11:32.787 
Epoch 771/1000 
	 loss: 389.7903, MinusLogProbMetric: 389.7903, val_loss: 391.6868, val_MinusLogProbMetric: 391.6868

Epoch 771: val_loss did not improve from 391.67099
196/196 - 18s - loss: 389.7903 - MinusLogProbMetric: 389.7903 - val_loss: 391.6868 - val_MinusLogProbMetric: 391.6868 - lr: 4.1667e-05 - 18s/epoch - 91ms/step
Epoch 772/1000
2023-09-10 16:11:54.630 
Epoch 772/1000 
	 loss: 389.8186, MinusLogProbMetric: 389.8186, val_loss: 392.0629, val_MinusLogProbMetric: 392.0629

Epoch 772: val_loss did not improve from 391.67099
196/196 - 22s - loss: 389.8186 - MinusLogProbMetric: 389.8186 - val_loss: 392.0629 - val_MinusLogProbMetric: 392.0629 - lr: 4.1667e-05 - 22s/epoch - 111ms/step
Epoch 773/1000
2023-09-10 16:12:15.090 
Epoch 773/1000 
	 loss: 389.8883, MinusLogProbMetric: 389.8883, val_loss: 392.0311, val_MinusLogProbMetric: 392.0311

Epoch 773: val_loss did not improve from 391.67099
196/196 - 20s - loss: 389.8883 - MinusLogProbMetric: 389.8883 - val_loss: 392.0311 - val_MinusLogProbMetric: 392.0311 - lr: 4.1667e-05 - 20s/epoch - 104ms/step
Epoch 774/1000
2023-09-10 16:12:31.961 
Epoch 774/1000 
	 loss: 389.7716, MinusLogProbMetric: 389.7716, val_loss: 392.1615, val_MinusLogProbMetric: 392.1615

Epoch 774: val_loss did not improve from 391.67099
196/196 - 17s - loss: 389.7716 - MinusLogProbMetric: 389.7716 - val_loss: 392.1615 - val_MinusLogProbMetric: 392.1615 - lr: 4.1667e-05 - 17s/epoch - 86ms/step
Epoch 775/1000
2023-09-10 16:13:00.246 
Epoch 775/1000 
	 loss: 389.8540, MinusLogProbMetric: 389.8540, val_loss: 392.4388, val_MinusLogProbMetric: 392.4388

Epoch 775: val_loss did not improve from 391.67099
196/196 - 28s - loss: 389.8540 - MinusLogProbMetric: 389.8540 - val_loss: 392.4388 - val_MinusLogProbMetric: 392.4388 - lr: 4.1667e-05 - 28s/epoch - 144ms/step
Epoch 776/1000
2023-09-10 16:13:26.946 
Epoch 776/1000 
	 loss: 389.8197, MinusLogProbMetric: 389.8197, val_loss: 392.2760, val_MinusLogProbMetric: 392.2760

Epoch 776: val_loss did not improve from 391.67099
196/196 - 27s - loss: 389.8197 - MinusLogProbMetric: 389.8197 - val_loss: 392.2760 - val_MinusLogProbMetric: 392.2760 - lr: 4.1667e-05 - 27s/epoch - 136ms/step
Epoch 777/1000
2023-09-10 16:13:46.987 
Epoch 777/1000 
	 loss: 389.7962, MinusLogProbMetric: 389.7962, val_loss: 391.8980, val_MinusLogProbMetric: 391.8980

Epoch 777: val_loss did not improve from 391.67099
196/196 - 20s - loss: 389.7962 - MinusLogProbMetric: 389.7962 - val_loss: 391.8980 - val_MinusLogProbMetric: 391.8980 - lr: 4.1667e-05 - 20s/epoch - 102ms/step
Epoch 778/1000
2023-09-10 16:14:06.791 
Epoch 778/1000 
	 loss: 389.8309, MinusLogProbMetric: 389.8309, val_loss: 392.2189, val_MinusLogProbMetric: 392.2189

Epoch 778: val_loss did not improve from 391.67099
196/196 - 20s - loss: 389.8309 - MinusLogProbMetric: 389.8309 - val_loss: 392.2189 - val_MinusLogProbMetric: 392.2189 - lr: 4.1667e-05 - 20s/epoch - 101ms/step
Epoch 779/1000
2023-09-10 16:14:31.800 
Epoch 779/1000 
	 loss: 389.8756, MinusLogProbMetric: 389.8756, val_loss: 391.9535, val_MinusLogProbMetric: 391.9535

Epoch 779: val_loss did not improve from 391.67099
196/196 - 25s - loss: 389.8756 - MinusLogProbMetric: 389.8756 - val_loss: 391.9535 - val_MinusLogProbMetric: 391.9535 - lr: 4.1667e-05 - 25s/epoch - 127ms/step
Epoch 780/1000
2023-09-10 16:14:49.521 
Epoch 780/1000 
	 loss: 389.7761, MinusLogProbMetric: 389.7761, val_loss: 392.1404, val_MinusLogProbMetric: 392.1404

Epoch 780: val_loss did not improve from 391.67099
196/196 - 18s - loss: 389.7761 - MinusLogProbMetric: 389.7761 - val_loss: 392.1404 - val_MinusLogProbMetric: 392.1404 - lr: 4.1667e-05 - 18s/epoch - 90ms/step
Epoch 781/1000
2023-09-10 16:15:12.647 
Epoch 781/1000 
	 loss: 389.7077, MinusLogProbMetric: 389.7077, val_loss: 392.3354, val_MinusLogProbMetric: 392.3354

Epoch 781: val_loss did not improve from 391.67099
196/196 - 23s - loss: 389.7077 - MinusLogProbMetric: 389.7077 - val_loss: 392.3354 - val_MinusLogProbMetric: 392.3354 - lr: 4.1667e-05 - 23s/epoch - 118ms/step
Epoch 782/1000
2023-09-10 16:15:34.868 
Epoch 782/1000 
	 loss: 389.8982, MinusLogProbMetric: 389.8982, val_loss: 391.8062, val_MinusLogProbMetric: 391.8062

Epoch 782: val_loss did not improve from 391.67099
196/196 - 22s - loss: 389.8982 - MinusLogProbMetric: 389.8982 - val_loss: 391.8062 - val_MinusLogProbMetric: 391.8062 - lr: 4.1667e-05 - 22s/epoch - 113ms/step
Epoch 783/1000
2023-09-10 16:16:02.098 
Epoch 783/1000 
	 loss: 389.8032, MinusLogProbMetric: 389.8032, val_loss: 392.0310, val_MinusLogProbMetric: 392.0310

Epoch 783: val_loss did not improve from 391.67099
196/196 - 27s - loss: 389.8032 - MinusLogProbMetric: 389.8032 - val_loss: 392.0310 - val_MinusLogProbMetric: 392.0310 - lr: 4.1667e-05 - 27s/epoch - 139ms/step
Epoch 784/1000
2023-09-10 16:16:31.110 
Epoch 784/1000 
	 loss: 389.8367, MinusLogProbMetric: 389.8367, val_loss: 392.3969, val_MinusLogProbMetric: 392.3969

Epoch 784: val_loss did not improve from 391.67099
196/196 - 29s - loss: 389.8367 - MinusLogProbMetric: 389.8367 - val_loss: 392.3969 - val_MinusLogProbMetric: 392.3969 - lr: 4.1667e-05 - 29s/epoch - 148ms/step
Epoch 785/1000
2023-09-10 16:17:01.338 
Epoch 785/1000 
	 loss: 389.9328, MinusLogProbMetric: 389.9328, val_loss: 392.0236, val_MinusLogProbMetric: 392.0236

Epoch 785: val_loss did not improve from 391.67099
196/196 - 30s - loss: 389.9328 - MinusLogProbMetric: 389.9328 - val_loss: 392.0236 - val_MinusLogProbMetric: 392.0236 - lr: 4.1667e-05 - 30s/epoch - 154ms/step
Epoch 786/1000
2023-09-10 16:17:27.295 
Epoch 786/1000 
	 loss: 389.7482, MinusLogProbMetric: 389.7482, val_loss: 392.5898, val_MinusLogProbMetric: 392.5898

Epoch 786: val_loss did not improve from 391.67099
196/196 - 26s - loss: 389.7482 - MinusLogProbMetric: 389.7482 - val_loss: 392.5898 - val_MinusLogProbMetric: 392.5898 - lr: 4.1667e-05 - 26s/epoch - 132ms/step
Epoch 787/1000
2023-09-10 16:17:51.359 
Epoch 787/1000 
	 loss: 389.8282, MinusLogProbMetric: 389.8282, val_loss: 392.3829, val_MinusLogProbMetric: 392.3829

Epoch 787: val_loss did not improve from 391.67099
196/196 - 24s - loss: 389.8282 - MinusLogProbMetric: 389.8282 - val_loss: 392.3829 - val_MinusLogProbMetric: 392.3829 - lr: 4.1667e-05 - 24s/epoch - 123ms/step
Epoch 788/1000
2023-09-10 16:18:18.491 
Epoch 788/1000 
	 loss: 389.7252, MinusLogProbMetric: 389.7252, val_loss: 391.8403, val_MinusLogProbMetric: 391.8403

Epoch 788: val_loss did not improve from 391.67099
196/196 - 27s - loss: 389.7252 - MinusLogProbMetric: 389.7252 - val_loss: 391.8403 - val_MinusLogProbMetric: 391.8403 - lr: 4.1667e-05 - 27s/epoch - 138ms/step
Epoch 789/1000
2023-09-10 16:18:41.481 
Epoch 789/1000 
	 loss: 389.7469, MinusLogProbMetric: 389.7469, val_loss: 391.8831, val_MinusLogProbMetric: 391.8831

Epoch 789: val_loss did not improve from 391.67099
196/196 - 23s - loss: 389.7469 - MinusLogProbMetric: 389.7469 - val_loss: 391.8831 - val_MinusLogProbMetric: 391.8831 - lr: 4.1667e-05 - 23s/epoch - 117ms/step
Epoch 790/1000
2023-09-10 16:19:11.789 
Epoch 790/1000 
	 loss: 389.8032, MinusLogProbMetric: 389.8032, val_loss: 392.6919, val_MinusLogProbMetric: 392.6919

Epoch 790: val_loss did not improve from 391.67099
196/196 - 30s - loss: 389.8032 - MinusLogProbMetric: 389.8032 - val_loss: 392.6919 - val_MinusLogProbMetric: 392.6919 - lr: 4.1667e-05 - 30s/epoch - 154ms/step
Epoch 791/1000
2023-09-10 16:19:40.369 
Epoch 791/1000 
	 loss: 389.8253, MinusLogProbMetric: 389.8253, val_loss: 391.8210, val_MinusLogProbMetric: 391.8210

Epoch 791: val_loss did not improve from 391.67099
196/196 - 29s - loss: 389.8253 - MinusLogProbMetric: 389.8253 - val_loss: 391.8210 - val_MinusLogProbMetric: 391.8210 - lr: 4.1667e-05 - 29s/epoch - 146ms/step
Epoch 792/1000
2023-09-10 16:20:01.985 
Epoch 792/1000 
	 loss: 389.4991, MinusLogProbMetric: 389.4991, val_loss: 391.6654, val_MinusLogProbMetric: 391.6654

Epoch 792: val_loss improved from 391.67099 to 391.66537, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 23s - loss: 389.4991 - MinusLogProbMetric: 389.4991 - val_loss: 391.6654 - val_MinusLogProbMetric: 391.6654 - lr: 2.0833e-05 - 23s/epoch - 115ms/step
Epoch 793/1000
2023-09-10 16:20:26.597 
Epoch 793/1000 
	 loss: 389.5048, MinusLogProbMetric: 389.5048, val_loss: 391.7005, val_MinusLogProbMetric: 391.7005

Epoch 793: val_loss did not improve from 391.66537
196/196 - 24s - loss: 389.5048 - MinusLogProbMetric: 389.5048 - val_loss: 391.7005 - val_MinusLogProbMetric: 391.7005 - lr: 2.0833e-05 - 24s/epoch - 120ms/step
Epoch 794/1000
2023-09-10 16:20:48.678 
Epoch 794/1000 
	 loss: 389.5088, MinusLogProbMetric: 389.5088, val_loss: 391.6025, val_MinusLogProbMetric: 391.6025

Epoch 794: val_loss improved from 391.66537 to 391.60251, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 23s - loss: 389.5088 - MinusLogProbMetric: 389.5088 - val_loss: 391.6025 - val_MinusLogProbMetric: 391.6025 - lr: 2.0833e-05 - 23s/epoch - 117ms/step
Epoch 795/1000
2023-09-10 16:21:14.756 
Epoch 795/1000 
	 loss: 389.5268, MinusLogProbMetric: 389.5268, val_loss: 391.7044, val_MinusLogProbMetric: 391.7044

Epoch 795: val_loss did not improve from 391.60251
196/196 - 25s - loss: 389.5268 - MinusLogProbMetric: 389.5268 - val_loss: 391.7044 - val_MinusLogProbMetric: 391.7044 - lr: 2.0833e-05 - 25s/epoch - 129ms/step
Epoch 796/1000
2023-09-10 16:21:41.095 
Epoch 796/1000 
	 loss: 389.5179, MinusLogProbMetric: 389.5179, val_loss: 391.7338, val_MinusLogProbMetric: 391.7338

Epoch 796: val_loss did not improve from 391.60251
196/196 - 26s - loss: 389.5179 - MinusLogProbMetric: 389.5179 - val_loss: 391.7338 - val_MinusLogProbMetric: 391.7338 - lr: 2.0833e-05 - 26s/epoch - 134ms/step
Epoch 797/1000
2023-09-10 16:22:01.622 
Epoch 797/1000 
	 loss: 389.4772, MinusLogProbMetric: 389.4772, val_loss: 391.6920, val_MinusLogProbMetric: 391.6920

Epoch 797: val_loss did not improve from 391.60251
196/196 - 21s - loss: 389.4772 - MinusLogProbMetric: 389.4772 - val_loss: 391.6920 - val_MinusLogProbMetric: 391.6920 - lr: 2.0833e-05 - 21s/epoch - 105ms/step
Epoch 798/1000
2023-09-10 16:22:17.529 
Epoch 798/1000 
	 loss: 389.5031, MinusLogProbMetric: 389.5031, val_loss: 391.6489, val_MinusLogProbMetric: 391.6489

Epoch 798: val_loss did not improve from 391.60251
196/196 - 16s - loss: 389.5031 - MinusLogProbMetric: 389.5031 - val_loss: 391.6489 - val_MinusLogProbMetric: 391.6489 - lr: 2.0833e-05 - 16s/epoch - 81ms/step
Epoch 799/1000
2023-09-10 16:22:36.800 
Epoch 799/1000 
	 loss: 389.5004, MinusLogProbMetric: 389.5004, val_loss: 391.8144, val_MinusLogProbMetric: 391.8144

Epoch 799: val_loss did not improve from 391.60251
196/196 - 19s - loss: 389.5004 - MinusLogProbMetric: 389.5004 - val_loss: 391.8144 - val_MinusLogProbMetric: 391.8144 - lr: 2.0833e-05 - 19s/epoch - 98ms/step
Epoch 800/1000
2023-09-10 16:23:00.699 
Epoch 800/1000 
	 loss: 389.5068, MinusLogProbMetric: 389.5068, val_loss: 391.6791, val_MinusLogProbMetric: 391.6791

Epoch 800: val_loss did not improve from 391.60251
196/196 - 24s - loss: 389.5068 - MinusLogProbMetric: 389.5068 - val_loss: 391.6791 - val_MinusLogProbMetric: 391.6791 - lr: 2.0833e-05 - 24s/epoch - 122ms/step
Epoch 801/1000
2023-09-10 16:23:28.491 
Epoch 801/1000 
	 loss: 389.5224, MinusLogProbMetric: 389.5224, val_loss: 391.7586, val_MinusLogProbMetric: 391.7586

Epoch 801: val_loss did not improve from 391.60251
196/196 - 28s - loss: 389.5224 - MinusLogProbMetric: 389.5224 - val_loss: 391.7586 - val_MinusLogProbMetric: 391.7586 - lr: 2.0833e-05 - 28s/epoch - 142ms/step
Epoch 802/1000
2023-09-10 16:23:54.428 
Epoch 802/1000 
	 loss: 389.4812, MinusLogProbMetric: 389.4812, val_loss: 391.6304, val_MinusLogProbMetric: 391.6304

Epoch 802: val_loss did not improve from 391.60251
196/196 - 26s - loss: 389.4812 - MinusLogProbMetric: 389.4812 - val_loss: 391.6304 - val_MinusLogProbMetric: 391.6304 - lr: 2.0833e-05 - 26s/epoch - 132ms/step
Epoch 803/1000
2023-09-10 16:24:18.163 
Epoch 803/1000 
	 loss: 389.4889, MinusLogProbMetric: 389.4889, val_loss: 391.6541, val_MinusLogProbMetric: 391.6541

Epoch 803: val_loss did not improve from 391.60251
196/196 - 24s - loss: 389.4889 - MinusLogProbMetric: 389.4889 - val_loss: 391.6541 - val_MinusLogProbMetric: 391.6541 - lr: 2.0833e-05 - 24s/epoch - 121ms/step
Epoch 804/1000
2023-09-10 16:24:44.426 
Epoch 804/1000 
	 loss: 389.4791, MinusLogProbMetric: 389.4791, val_loss: 391.7673, val_MinusLogProbMetric: 391.7673

Epoch 804: val_loss did not improve from 391.60251
196/196 - 26s - loss: 389.4791 - MinusLogProbMetric: 389.4791 - val_loss: 391.7673 - val_MinusLogProbMetric: 391.7673 - lr: 2.0833e-05 - 26s/epoch - 134ms/step
Epoch 805/1000
2023-09-10 16:25:05.656 
Epoch 805/1000 
	 loss: 389.4972, MinusLogProbMetric: 389.4972, val_loss: 391.6944, val_MinusLogProbMetric: 391.6944

Epoch 805: val_loss did not improve from 391.60251
196/196 - 21s - loss: 389.4972 - MinusLogProbMetric: 389.4972 - val_loss: 391.6944 - val_MinusLogProbMetric: 391.6944 - lr: 2.0833e-05 - 21s/epoch - 108ms/step
Epoch 806/1000
2023-09-10 16:25:30.832 
Epoch 806/1000 
	 loss: 389.5172, MinusLogProbMetric: 389.5172, val_loss: 391.8195, val_MinusLogProbMetric: 391.8195

Epoch 806: val_loss did not improve from 391.60251
196/196 - 25s - loss: 389.5172 - MinusLogProbMetric: 389.5172 - val_loss: 391.8195 - val_MinusLogProbMetric: 391.8195 - lr: 2.0833e-05 - 25s/epoch - 128ms/step
Epoch 807/1000
2023-09-10 16:25:49.790 
Epoch 807/1000 
	 loss: 389.5106, MinusLogProbMetric: 389.5106, val_loss: 391.7492, val_MinusLogProbMetric: 391.7492

Epoch 807: val_loss did not improve from 391.60251
196/196 - 19s - loss: 389.5106 - MinusLogProbMetric: 389.5106 - val_loss: 391.7492 - val_MinusLogProbMetric: 391.7492 - lr: 2.0833e-05 - 19s/epoch - 97ms/step
Epoch 808/1000
2023-09-10 16:26:11.439 
Epoch 808/1000 
	 loss: 389.4874, MinusLogProbMetric: 389.4874, val_loss: 391.7362, val_MinusLogProbMetric: 391.7362

Epoch 808: val_loss did not improve from 391.60251
196/196 - 22s - loss: 389.4874 - MinusLogProbMetric: 389.4874 - val_loss: 391.7362 - val_MinusLogProbMetric: 391.7362 - lr: 2.0833e-05 - 22s/epoch - 110ms/step
Epoch 809/1000
2023-09-10 16:26:32.002 
Epoch 809/1000 
	 loss: 389.4850, MinusLogProbMetric: 389.4850, val_loss: 391.6236, val_MinusLogProbMetric: 391.6236

Epoch 809: val_loss did not improve from 391.60251
196/196 - 21s - loss: 389.4850 - MinusLogProbMetric: 389.4850 - val_loss: 391.6236 - val_MinusLogProbMetric: 391.6236 - lr: 2.0833e-05 - 21s/epoch - 105ms/step
Epoch 810/1000
2023-09-10 16:26:53.912 
Epoch 810/1000 
	 loss: 389.5151, MinusLogProbMetric: 389.5151, val_loss: 391.6899, val_MinusLogProbMetric: 391.6899

Epoch 810: val_loss did not improve from 391.60251
196/196 - 22s - loss: 389.5151 - MinusLogProbMetric: 389.5151 - val_loss: 391.6899 - val_MinusLogProbMetric: 391.6899 - lr: 2.0833e-05 - 22s/epoch - 112ms/step
Epoch 811/1000
2023-09-10 16:27:11.243 
Epoch 811/1000 
	 loss: 389.4778, MinusLogProbMetric: 389.4778, val_loss: 392.0647, val_MinusLogProbMetric: 392.0647

Epoch 811: val_loss did not improve from 391.60251
196/196 - 17s - loss: 389.4778 - MinusLogProbMetric: 389.4778 - val_loss: 392.0647 - val_MinusLogProbMetric: 392.0647 - lr: 2.0833e-05 - 17s/epoch - 88ms/step
Epoch 812/1000
2023-09-10 16:27:34.874 
Epoch 812/1000 
	 loss: 389.5081, MinusLogProbMetric: 389.5081, val_loss: 391.8016, val_MinusLogProbMetric: 391.8016

Epoch 812: val_loss did not improve from 391.60251
196/196 - 24s - loss: 389.5081 - MinusLogProbMetric: 389.5081 - val_loss: 391.8016 - val_MinusLogProbMetric: 391.8016 - lr: 2.0833e-05 - 24s/epoch - 120ms/step
Epoch 813/1000
2023-09-10 16:27:52.393 
Epoch 813/1000 
	 loss: 389.5347, MinusLogProbMetric: 389.5347, val_loss: 391.9429, val_MinusLogProbMetric: 391.9429

Epoch 813: val_loss did not improve from 391.60251
196/196 - 17s - loss: 389.5347 - MinusLogProbMetric: 389.5347 - val_loss: 391.9429 - val_MinusLogProbMetric: 391.9429 - lr: 2.0833e-05 - 17s/epoch - 89ms/step
Epoch 814/1000
2023-09-10 16:28:12.073 
Epoch 814/1000 
	 loss: 389.5309, MinusLogProbMetric: 389.5309, val_loss: 391.8150, val_MinusLogProbMetric: 391.8150

Epoch 814: val_loss did not improve from 391.60251
196/196 - 20s - loss: 389.5309 - MinusLogProbMetric: 389.5309 - val_loss: 391.8150 - val_MinusLogProbMetric: 391.8150 - lr: 2.0833e-05 - 20s/epoch - 101ms/step
Epoch 815/1000
2023-09-10 16:28:29.364 
Epoch 815/1000 
	 loss: 389.5176, MinusLogProbMetric: 389.5176, val_loss: 391.7112, val_MinusLogProbMetric: 391.7112

Epoch 815: val_loss did not improve from 391.60251
196/196 - 17s - loss: 389.5176 - MinusLogProbMetric: 389.5176 - val_loss: 391.7112 - val_MinusLogProbMetric: 391.7112 - lr: 2.0833e-05 - 17s/epoch - 88ms/step
Epoch 816/1000
2023-09-10 16:28:49.065 
Epoch 816/1000 
	 loss: 389.5155, MinusLogProbMetric: 389.5155, val_loss: 391.6837, val_MinusLogProbMetric: 391.6837

Epoch 816: val_loss did not improve from 391.60251
196/196 - 20s - loss: 389.5155 - MinusLogProbMetric: 389.5155 - val_loss: 391.6837 - val_MinusLogProbMetric: 391.6837 - lr: 2.0833e-05 - 20s/epoch - 101ms/step
Epoch 817/1000
2023-09-10 16:29:14.925 
Epoch 817/1000 
	 loss: 389.5320, MinusLogProbMetric: 389.5320, val_loss: 391.7356, val_MinusLogProbMetric: 391.7356

Epoch 817: val_loss did not improve from 391.60251
196/196 - 26s - loss: 389.5320 - MinusLogProbMetric: 389.5320 - val_loss: 391.7356 - val_MinusLogProbMetric: 391.7356 - lr: 2.0833e-05 - 26s/epoch - 132ms/step
Epoch 818/1000
2023-09-10 16:29:34.882 
Epoch 818/1000 
	 loss: 389.5272, MinusLogProbMetric: 389.5272, val_loss: 391.7194, val_MinusLogProbMetric: 391.7194

Epoch 818: val_loss did not improve from 391.60251
196/196 - 20s - loss: 389.5272 - MinusLogProbMetric: 389.5272 - val_loss: 391.7194 - val_MinusLogProbMetric: 391.7194 - lr: 2.0833e-05 - 20s/epoch - 102ms/step
Epoch 819/1000
2023-09-10 16:29:56.607 
Epoch 819/1000 
	 loss: 389.4905, MinusLogProbMetric: 389.4905, val_loss: 391.7312, val_MinusLogProbMetric: 391.7312

Epoch 819: val_loss did not improve from 391.60251
196/196 - 22s - loss: 389.4905 - MinusLogProbMetric: 389.4905 - val_loss: 391.7312 - val_MinusLogProbMetric: 391.7312 - lr: 2.0833e-05 - 22s/epoch - 111ms/step
Epoch 820/1000
2023-09-10 16:30:19.062 
Epoch 820/1000 
	 loss: 389.4932, MinusLogProbMetric: 389.4932, val_loss: 391.8559, val_MinusLogProbMetric: 391.8559

Epoch 820: val_loss did not improve from 391.60251
196/196 - 22s - loss: 389.4932 - MinusLogProbMetric: 389.4932 - val_loss: 391.8559 - val_MinusLogProbMetric: 391.8559 - lr: 2.0833e-05 - 22s/epoch - 114ms/step
Epoch 821/1000
2023-09-10 16:30:35.734 
Epoch 821/1000 
	 loss: 389.4933, MinusLogProbMetric: 389.4933, val_loss: 391.7072, val_MinusLogProbMetric: 391.7072

Epoch 821: val_loss did not improve from 391.60251
196/196 - 17s - loss: 389.4933 - MinusLogProbMetric: 389.4933 - val_loss: 391.7072 - val_MinusLogProbMetric: 391.7072 - lr: 2.0833e-05 - 17s/epoch - 85ms/step
Epoch 822/1000
2023-09-10 16:30:52.778 
Epoch 822/1000 
	 loss: 389.4450, MinusLogProbMetric: 389.4450, val_loss: 391.7576, val_MinusLogProbMetric: 391.7576

Epoch 822: val_loss did not improve from 391.60251
196/196 - 17s - loss: 389.4450 - MinusLogProbMetric: 389.4450 - val_loss: 391.7576 - val_MinusLogProbMetric: 391.7576 - lr: 2.0833e-05 - 17s/epoch - 87ms/step
Epoch 823/1000
2023-09-10 16:31:11.778 
Epoch 823/1000 
	 loss: 389.4499, MinusLogProbMetric: 389.4499, val_loss: 391.6864, val_MinusLogProbMetric: 391.6864

Epoch 823: val_loss did not improve from 391.60251
196/196 - 19s - loss: 389.4499 - MinusLogProbMetric: 389.4499 - val_loss: 391.6864 - val_MinusLogProbMetric: 391.6864 - lr: 2.0833e-05 - 19s/epoch - 97ms/step
Epoch 824/1000
2023-09-10 16:31:30.679 
Epoch 824/1000 
	 loss: 389.4758, MinusLogProbMetric: 389.4758, val_loss: 391.7652, val_MinusLogProbMetric: 391.7652

Epoch 824: val_loss did not improve from 391.60251
196/196 - 19s - loss: 389.4758 - MinusLogProbMetric: 389.4758 - val_loss: 391.7652 - val_MinusLogProbMetric: 391.7652 - lr: 2.0833e-05 - 19s/epoch - 96ms/step
Epoch 825/1000
2023-09-10 16:31:50.757 
Epoch 825/1000 
	 loss: 389.4653, MinusLogProbMetric: 389.4653, val_loss: 391.6693, val_MinusLogProbMetric: 391.6693

Epoch 825: val_loss did not improve from 391.60251
196/196 - 20s - loss: 389.4653 - MinusLogProbMetric: 389.4653 - val_loss: 391.6693 - val_MinusLogProbMetric: 391.6693 - lr: 2.0833e-05 - 20s/epoch - 102ms/step
Epoch 826/1000
2023-09-10 16:32:11.538 
Epoch 826/1000 
	 loss: 389.4570, MinusLogProbMetric: 389.4570, val_loss: 391.7463, val_MinusLogProbMetric: 391.7463

Epoch 826: val_loss did not improve from 391.60251
196/196 - 21s - loss: 389.4570 - MinusLogProbMetric: 389.4570 - val_loss: 391.7463 - val_MinusLogProbMetric: 391.7463 - lr: 2.0833e-05 - 21s/epoch - 106ms/step
Epoch 827/1000
2023-09-10 16:32:26.996 
Epoch 827/1000 
	 loss: 389.4353, MinusLogProbMetric: 389.4353, val_loss: 391.6502, val_MinusLogProbMetric: 391.6502

Epoch 827: val_loss did not improve from 391.60251
196/196 - 15s - loss: 389.4353 - MinusLogProbMetric: 389.4353 - val_loss: 391.6502 - val_MinusLogProbMetric: 391.6502 - lr: 2.0833e-05 - 15s/epoch - 79ms/step
Epoch 828/1000
2023-09-10 16:32:43.017 
Epoch 828/1000 
	 loss: 389.4493, MinusLogProbMetric: 389.4493, val_loss: 391.7498, val_MinusLogProbMetric: 391.7498

Epoch 828: val_loss did not improve from 391.60251
196/196 - 16s - loss: 389.4493 - MinusLogProbMetric: 389.4493 - val_loss: 391.7498 - val_MinusLogProbMetric: 391.7498 - lr: 2.0833e-05 - 16s/epoch - 82ms/step
Epoch 829/1000
2023-09-10 16:33:01.522 
Epoch 829/1000 
	 loss: 389.4596, MinusLogProbMetric: 389.4596, val_loss: 391.7752, val_MinusLogProbMetric: 391.7752

Epoch 829: val_loss did not improve from 391.60251
196/196 - 18s - loss: 389.4596 - MinusLogProbMetric: 389.4596 - val_loss: 391.7752 - val_MinusLogProbMetric: 391.7752 - lr: 2.0833e-05 - 18s/epoch - 94ms/step
Epoch 830/1000
2023-09-10 16:33:18.306 
Epoch 830/1000 
	 loss: 389.4345, MinusLogProbMetric: 389.4345, val_loss: 391.7860, val_MinusLogProbMetric: 391.7860

Epoch 830: val_loss did not improve from 391.60251
196/196 - 17s - loss: 389.4345 - MinusLogProbMetric: 389.4345 - val_loss: 391.7860 - val_MinusLogProbMetric: 391.7860 - lr: 2.0833e-05 - 17s/epoch - 86ms/step
Epoch 831/1000
2023-09-10 16:33:36.368 
Epoch 831/1000 
	 loss: 389.4326, MinusLogProbMetric: 389.4326, val_loss: 391.5679, val_MinusLogProbMetric: 391.5679

Epoch 831: val_loss improved from 391.60251 to 391.56790, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 19s - loss: 389.4326 - MinusLogProbMetric: 389.4326 - val_loss: 391.5679 - val_MinusLogProbMetric: 391.5679 - lr: 2.0833e-05 - 19s/epoch - 98ms/step
Epoch 832/1000
2023-09-10 16:33:57.908 
Epoch 832/1000 
	 loss: 389.4102, MinusLogProbMetric: 389.4102, val_loss: 391.6573, val_MinusLogProbMetric: 391.6573

Epoch 832: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.4102 - MinusLogProbMetric: 389.4102 - val_loss: 391.6573 - val_MinusLogProbMetric: 391.6573 - lr: 2.0833e-05 - 20s/epoch - 104ms/step
Epoch 833/1000
2023-09-10 16:34:18.103 
Epoch 833/1000 
	 loss: 389.4120, MinusLogProbMetric: 389.4120, val_loss: 391.6642, val_MinusLogProbMetric: 391.6642

Epoch 833: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.4120 - MinusLogProbMetric: 389.4120 - val_loss: 391.6642 - val_MinusLogProbMetric: 391.6642 - lr: 2.0833e-05 - 20s/epoch - 102ms/step
Epoch 834/1000
2023-09-10 16:34:36.858 
Epoch 834/1000 
	 loss: 389.4196, MinusLogProbMetric: 389.4196, val_loss: 391.6247, val_MinusLogProbMetric: 391.6247

Epoch 834: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.4196 - MinusLogProbMetric: 389.4196 - val_loss: 391.6247 - val_MinusLogProbMetric: 391.6247 - lr: 2.0833e-05 - 19s/epoch - 96ms/step
Epoch 835/1000
2023-09-10 16:34:56.990 
Epoch 835/1000 
	 loss: 389.4452, MinusLogProbMetric: 389.4452, val_loss: 391.7421, val_MinusLogProbMetric: 391.7421

Epoch 835: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.4452 - MinusLogProbMetric: 389.4452 - val_loss: 391.7421 - val_MinusLogProbMetric: 391.7421 - lr: 2.0833e-05 - 20s/epoch - 103ms/step
Epoch 836/1000
2023-09-10 16:35:21.324 
Epoch 836/1000 
	 loss: 389.4388, MinusLogProbMetric: 389.4388, val_loss: 391.7908, val_MinusLogProbMetric: 391.7908

Epoch 836: val_loss did not improve from 391.56790
196/196 - 24s - loss: 389.4388 - MinusLogProbMetric: 389.4388 - val_loss: 391.7908 - val_MinusLogProbMetric: 391.7908 - lr: 2.0833e-05 - 24s/epoch - 124ms/step
Epoch 837/1000
2023-09-10 16:35:40.690 
Epoch 837/1000 
	 loss: 389.4229, MinusLogProbMetric: 389.4229, val_loss: 391.6667, val_MinusLogProbMetric: 391.6667

Epoch 837: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.4229 - MinusLogProbMetric: 389.4229 - val_loss: 391.6667 - val_MinusLogProbMetric: 391.6667 - lr: 2.0833e-05 - 19s/epoch - 99ms/step
Epoch 838/1000
2023-09-10 16:35:59.455 
Epoch 838/1000 
	 loss: 389.4165, MinusLogProbMetric: 389.4165, val_loss: 391.6502, val_MinusLogProbMetric: 391.6502

Epoch 838: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.4165 - MinusLogProbMetric: 389.4165 - val_loss: 391.6502 - val_MinusLogProbMetric: 391.6502 - lr: 2.0833e-05 - 19s/epoch - 95ms/step
Epoch 839/1000
2023-09-10 16:36:21.584 
Epoch 839/1000 
	 loss: 389.4189, MinusLogProbMetric: 389.4189, val_loss: 391.6209, val_MinusLogProbMetric: 391.6209

Epoch 839: val_loss did not improve from 391.56790
196/196 - 22s - loss: 389.4189 - MinusLogProbMetric: 389.4189 - val_loss: 391.6209 - val_MinusLogProbMetric: 391.6209 - lr: 2.0833e-05 - 22s/epoch - 113ms/step
Epoch 840/1000
2023-09-10 16:36:42.209 
Epoch 840/1000 
	 loss: 389.4228, MinusLogProbMetric: 389.4228, val_loss: 391.7034, val_MinusLogProbMetric: 391.7034

Epoch 840: val_loss did not improve from 391.56790
196/196 - 21s - loss: 389.4228 - MinusLogProbMetric: 389.4228 - val_loss: 391.7034 - val_MinusLogProbMetric: 391.7034 - lr: 2.0833e-05 - 21s/epoch - 105ms/step
Epoch 841/1000
2023-09-10 16:36:59.809 
Epoch 841/1000 
	 loss: 389.4239, MinusLogProbMetric: 389.4239, val_loss: 391.7273, val_MinusLogProbMetric: 391.7273

Epoch 841: val_loss did not improve from 391.56790
196/196 - 18s - loss: 389.4239 - MinusLogProbMetric: 389.4239 - val_loss: 391.7273 - val_MinusLogProbMetric: 391.7273 - lr: 2.0833e-05 - 18s/epoch - 90ms/step
Epoch 842/1000
2023-09-10 16:37:19.474 
Epoch 842/1000 
	 loss: 389.4357, MinusLogProbMetric: 389.4357, val_loss: 391.6216, val_MinusLogProbMetric: 391.6216

Epoch 842: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.4357 - MinusLogProbMetric: 389.4357 - val_loss: 391.6216 - val_MinusLogProbMetric: 391.6216 - lr: 2.0833e-05 - 20s/epoch - 100ms/step
Epoch 843/1000
2023-09-10 16:37:39.286 
Epoch 843/1000 
	 loss: 389.3922, MinusLogProbMetric: 389.3922, val_loss: 391.6899, val_MinusLogProbMetric: 391.6899

Epoch 843: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.3922 - MinusLogProbMetric: 389.3922 - val_loss: 391.6899 - val_MinusLogProbMetric: 391.6899 - lr: 2.0833e-05 - 20s/epoch - 101ms/step
Epoch 844/1000
2023-09-10 16:37:59.230 
Epoch 844/1000 
	 loss: 389.4082, MinusLogProbMetric: 389.4082, val_loss: 391.6434, val_MinusLogProbMetric: 391.6434

Epoch 844: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.4082 - MinusLogProbMetric: 389.4082 - val_loss: 391.6434 - val_MinusLogProbMetric: 391.6434 - lr: 2.0833e-05 - 20s/epoch - 101ms/step
Epoch 845/1000
2023-09-10 16:38:26.002 
Epoch 845/1000 
	 loss: 389.3910, MinusLogProbMetric: 389.3910, val_loss: 391.6480, val_MinusLogProbMetric: 391.6480

Epoch 845: val_loss did not improve from 391.56790
196/196 - 27s - loss: 389.3910 - MinusLogProbMetric: 389.3910 - val_loss: 391.6480 - val_MinusLogProbMetric: 391.6480 - lr: 2.0833e-05 - 27s/epoch - 137ms/step
Epoch 846/1000
2023-09-10 16:38:46.521 
Epoch 846/1000 
	 loss: 389.3772, MinusLogProbMetric: 389.3772, val_loss: 391.6208, val_MinusLogProbMetric: 391.6208

Epoch 846: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.3772 - MinusLogProbMetric: 389.3772 - val_loss: 391.6208 - val_MinusLogProbMetric: 391.6208 - lr: 2.0833e-05 - 20s/epoch - 104ms/step
Epoch 847/1000
2023-09-10 16:39:10.737 
Epoch 847/1000 
	 loss: 389.4179, MinusLogProbMetric: 389.4179, val_loss: 391.7505, val_MinusLogProbMetric: 391.7505

Epoch 847: val_loss did not improve from 391.56790
196/196 - 24s - loss: 389.4179 - MinusLogProbMetric: 389.4179 - val_loss: 391.7505 - val_MinusLogProbMetric: 391.7505 - lr: 2.0833e-05 - 24s/epoch - 123ms/step
Epoch 848/1000
2023-09-10 16:39:36.979 
Epoch 848/1000 
	 loss: 389.3922, MinusLogProbMetric: 389.3922, val_loss: 391.6384, val_MinusLogProbMetric: 391.6384

Epoch 848: val_loss did not improve from 391.56790
196/196 - 26s - loss: 389.3922 - MinusLogProbMetric: 389.3922 - val_loss: 391.6384 - val_MinusLogProbMetric: 391.6384 - lr: 2.0833e-05 - 26s/epoch - 134ms/step
Epoch 849/1000
2023-09-10 16:40:03.870 
Epoch 849/1000 
	 loss: 389.3990, MinusLogProbMetric: 389.3990, val_loss: 391.6467, val_MinusLogProbMetric: 391.6467

Epoch 849: val_loss did not improve from 391.56790
196/196 - 27s - loss: 389.3990 - MinusLogProbMetric: 389.3990 - val_loss: 391.6467 - val_MinusLogProbMetric: 391.6467 - lr: 2.0833e-05 - 27s/epoch - 137ms/step
Epoch 850/1000
2023-09-10 16:40:31.167 
Epoch 850/1000 
	 loss: 389.3940, MinusLogProbMetric: 389.3940, val_loss: 391.7000, val_MinusLogProbMetric: 391.7000

Epoch 850: val_loss did not improve from 391.56790
196/196 - 27s - loss: 389.3940 - MinusLogProbMetric: 389.3940 - val_loss: 391.7000 - val_MinusLogProbMetric: 391.7000 - lr: 2.0833e-05 - 27s/epoch - 139ms/step
Epoch 851/1000
2023-09-10 16:40:56.766 
Epoch 851/1000 
	 loss: 389.4049, MinusLogProbMetric: 389.4049, val_loss: 391.5916, val_MinusLogProbMetric: 391.5916

Epoch 851: val_loss did not improve from 391.56790
196/196 - 26s - loss: 389.4049 - MinusLogProbMetric: 389.4049 - val_loss: 391.5916 - val_MinusLogProbMetric: 391.5916 - lr: 2.0833e-05 - 26s/epoch - 130ms/step
Epoch 852/1000
2023-09-10 16:41:15.954 
Epoch 852/1000 
	 loss: 389.3863, MinusLogProbMetric: 389.3863, val_loss: 391.6168, val_MinusLogProbMetric: 391.6168

Epoch 852: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.3863 - MinusLogProbMetric: 389.3863 - val_loss: 391.6168 - val_MinusLogProbMetric: 391.6168 - lr: 2.0833e-05 - 19s/epoch - 98ms/step
Epoch 853/1000
2023-09-10 16:41:37.623 
Epoch 853/1000 
	 loss: 389.3766, MinusLogProbMetric: 389.3766, val_loss: 391.6806, val_MinusLogProbMetric: 391.6806

Epoch 853: val_loss did not improve from 391.56790
196/196 - 22s - loss: 389.3766 - MinusLogProbMetric: 389.3766 - val_loss: 391.6806 - val_MinusLogProbMetric: 391.6806 - lr: 2.0833e-05 - 22s/epoch - 111ms/step
Epoch 854/1000
2023-09-10 16:41:56.337 
Epoch 854/1000 
	 loss: 389.3920, MinusLogProbMetric: 389.3920, val_loss: 391.7402, val_MinusLogProbMetric: 391.7402

Epoch 854: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.3920 - MinusLogProbMetric: 389.3920 - val_loss: 391.7402 - val_MinusLogProbMetric: 391.7402 - lr: 2.0833e-05 - 19s/epoch - 95ms/step
Epoch 855/1000
2023-09-10 16:42:23.424 
Epoch 855/1000 
	 loss: 389.3990, MinusLogProbMetric: 389.3990, val_loss: 391.5916, val_MinusLogProbMetric: 391.5916

Epoch 855: val_loss did not improve from 391.56790
196/196 - 27s - loss: 389.3990 - MinusLogProbMetric: 389.3990 - val_loss: 391.5916 - val_MinusLogProbMetric: 391.5916 - lr: 2.0833e-05 - 27s/epoch - 138ms/step
Epoch 856/1000
2023-09-10 16:42:46.616 
Epoch 856/1000 
	 loss: 389.4078, MinusLogProbMetric: 389.4078, val_loss: 391.7837, val_MinusLogProbMetric: 391.7837

Epoch 856: val_loss did not improve from 391.56790
196/196 - 23s - loss: 389.4078 - MinusLogProbMetric: 389.4078 - val_loss: 391.7837 - val_MinusLogProbMetric: 391.7837 - lr: 2.0833e-05 - 23s/epoch - 119ms/step
Epoch 857/1000
2023-09-10 16:43:08.469 
Epoch 857/1000 
	 loss: 389.3799, MinusLogProbMetric: 389.3799, val_loss: 391.6600, val_MinusLogProbMetric: 391.6600

Epoch 857: val_loss did not improve from 391.56790
196/196 - 22s - loss: 389.3799 - MinusLogProbMetric: 389.3799 - val_loss: 391.6600 - val_MinusLogProbMetric: 391.6600 - lr: 2.0833e-05 - 22s/epoch - 111ms/step
Epoch 858/1000
2023-09-10 16:43:27.949 
Epoch 858/1000 
	 loss: 389.4049, MinusLogProbMetric: 389.4049, val_loss: 391.6965, val_MinusLogProbMetric: 391.6965

Epoch 858: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.4049 - MinusLogProbMetric: 389.4049 - val_loss: 391.6965 - val_MinusLogProbMetric: 391.6965 - lr: 2.0833e-05 - 19s/epoch - 99ms/step
Epoch 859/1000
2023-09-10 16:43:47.375 
Epoch 859/1000 
	 loss: 389.3932, MinusLogProbMetric: 389.3932, val_loss: 391.7555, val_MinusLogProbMetric: 391.7555

Epoch 859: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.3932 - MinusLogProbMetric: 389.3932 - val_loss: 391.7555 - val_MinusLogProbMetric: 391.7555 - lr: 2.0833e-05 - 19s/epoch - 99ms/step
Epoch 860/1000
2023-09-10 16:44:06.381 
Epoch 860/1000 
	 loss: 389.4052, MinusLogProbMetric: 389.4052, val_loss: 391.5989, val_MinusLogProbMetric: 391.5989

Epoch 860: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.4052 - MinusLogProbMetric: 389.4052 - val_loss: 391.5989 - val_MinusLogProbMetric: 391.5989 - lr: 2.0833e-05 - 19s/epoch - 97ms/step
Epoch 861/1000
2023-09-10 16:44:29.967 
Epoch 861/1000 
	 loss: 389.4004, MinusLogProbMetric: 389.4004, val_loss: 391.7331, val_MinusLogProbMetric: 391.7331

Epoch 861: val_loss did not improve from 391.56790
196/196 - 24s - loss: 389.4004 - MinusLogProbMetric: 389.4004 - val_loss: 391.7331 - val_MinusLogProbMetric: 391.7331 - lr: 2.0833e-05 - 24s/epoch - 120ms/step
Epoch 862/1000
2023-09-10 16:44:52.123 
Epoch 862/1000 
	 loss: 389.4287, MinusLogProbMetric: 389.4287, val_loss: 391.7090, val_MinusLogProbMetric: 391.7090

Epoch 862: val_loss did not improve from 391.56790
196/196 - 22s - loss: 389.4287 - MinusLogProbMetric: 389.4287 - val_loss: 391.7090 - val_MinusLogProbMetric: 391.7090 - lr: 2.0833e-05 - 22s/epoch - 113ms/step
Epoch 863/1000
2023-09-10 16:45:14.905 
Epoch 863/1000 
	 loss: 389.4117, MinusLogProbMetric: 389.4117, val_loss: 391.7626, val_MinusLogProbMetric: 391.7626

Epoch 863: val_loss did not improve from 391.56790
196/196 - 23s - loss: 389.4117 - MinusLogProbMetric: 389.4117 - val_loss: 391.7626 - val_MinusLogProbMetric: 391.7626 - lr: 2.0833e-05 - 23s/epoch - 116ms/step
Epoch 864/1000
2023-09-10 16:45:38.077 
Epoch 864/1000 
	 loss: 389.3845, MinusLogProbMetric: 389.3845, val_loss: 392.1216, val_MinusLogProbMetric: 392.1216

Epoch 864: val_loss did not improve from 391.56790
196/196 - 23s - loss: 389.3845 - MinusLogProbMetric: 389.3845 - val_loss: 392.1216 - val_MinusLogProbMetric: 392.1216 - lr: 2.0833e-05 - 23s/epoch - 118ms/step
Epoch 865/1000
2023-09-10 16:45:59.586 
Epoch 865/1000 
	 loss: 389.3972, MinusLogProbMetric: 389.3972, val_loss: 391.6499, val_MinusLogProbMetric: 391.6499

Epoch 865: val_loss did not improve from 391.56790
196/196 - 21s - loss: 389.3972 - MinusLogProbMetric: 389.3972 - val_loss: 391.6499 - val_MinusLogProbMetric: 391.6499 - lr: 2.0833e-05 - 21s/epoch - 110ms/step
Epoch 866/1000
2023-09-10 16:46:20.250 
Epoch 866/1000 
	 loss: 389.4092, MinusLogProbMetric: 389.4092, val_loss: 391.6165, val_MinusLogProbMetric: 391.6165

Epoch 866: val_loss did not improve from 391.56790
196/196 - 21s - loss: 389.4092 - MinusLogProbMetric: 389.4092 - val_loss: 391.6165 - val_MinusLogProbMetric: 391.6165 - lr: 2.0833e-05 - 21s/epoch - 105ms/step
Epoch 867/1000
2023-09-10 16:46:41.724 
Epoch 867/1000 
	 loss: 389.4059, MinusLogProbMetric: 389.4059, val_loss: 391.6869, val_MinusLogProbMetric: 391.6869

Epoch 867: val_loss did not improve from 391.56790
196/196 - 21s - loss: 389.4059 - MinusLogProbMetric: 389.4059 - val_loss: 391.6869 - val_MinusLogProbMetric: 391.6869 - lr: 2.0833e-05 - 21s/epoch - 110ms/step
Epoch 868/1000
2023-09-10 16:46:59.891 
Epoch 868/1000 
	 loss: 389.4278, MinusLogProbMetric: 389.4278, val_loss: 391.5820, val_MinusLogProbMetric: 391.5820

Epoch 868: val_loss did not improve from 391.56790
196/196 - 18s - loss: 389.4278 - MinusLogProbMetric: 389.4278 - val_loss: 391.5820 - val_MinusLogProbMetric: 391.5820 - lr: 2.0833e-05 - 18s/epoch - 92ms/step
Epoch 869/1000
2023-09-10 16:47:17.122 
Epoch 869/1000 
	 loss: 389.4226, MinusLogProbMetric: 389.4226, val_loss: 391.7351, val_MinusLogProbMetric: 391.7351

Epoch 869: val_loss did not improve from 391.56790
196/196 - 17s - loss: 389.4226 - MinusLogProbMetric: 389.4226 - val_loss: 391.7351 - val_MinusLogProbMetric: 391.7351 - lr: 2.0833e-05 - 17s/epoch - 88ms/step
Epoch 870/1000
2023-09-10 16:47:32.962 
Epoch 870/1000 
	 loss: 389.3979, MinusLogProbMetric: 389.3979, val_loss: 391.5875, val_MinusLogProbMetric: 391.5875

Epoch 870: val_loss did not improve from 391.56790
196/196 - 16s - loss: 389.3979 - MinusLogProbMetric: 389.3979 - val_loss: 391.5875 - val_MinusLogProbMetric: 391.5875 - lr: 2.0833e-05 - 16s/epoch - 81ms/step
Epoch 871/1000
2023-09-10 16:47:50.319 
Epoch 871/1000 
	 loss: 389.3880, MinusLogProbMetric: 389.3880, val_loss: 391.7344, val_MinusLogProbMetric: 391.7344

Epoch 871: val_loss did not improve from 391.56790
196/196 - 17s - loss: 389.3880 - MinusLogProbMetric: 389.3880 - val_loss: 391.7344 - val_MinusLogProbMetric: 391.7344 - lr: 2.0833e-05 - 17s/epoch - 88ms/step
Epoch 872/1000
2023-09-10 16:48:16.069 
Epoch 872/1000 
	 loss: 389.4036, MinusLogProbMetric: 389.4036, val_loss: 391.6488, val_MinusLogProbMetric: 391.6488

Epoch 872: val_loss did not improve from 391.56790
196/196 - 26s - loss: 389.4036 - MinusLogProbMetric: 389.4036 - val_loss: 391.6488 - val_MinusLogProbMetric: 391.6488 - lr: 2.0833e-05 - 26s/epoch - 131ms/step
Epoch 873/1000
2023-09-10 16:48:32.773 
Epoch 873/1000 
	 loss: 389.3660, MinusLogProbMetric: 389.3660, val_loss: 391.7475, val_MinusLogProbMetric: 391.7475

Epoch 873: val_loss did not improve from 391.56790
196/196 - 17s - loss: 389.3660 - MinusLogProbMetric: 389.3660 - val_loss: 391.7475 - val_MinusLogProbMetric: 391.7475 - lr: 2.0833e-05 - 17s/epoch - 85ms/step
Epoch 874/1000
2023-09-10 16:48:57.424 
Epoch 874/1000 
	 loss: 389.3747, MinusLogProbMetric: 389.3747, val_loss: 391.6096, val_MinusLogProbMetric: 391.6096

Epoch 874: val_loss did not improve from 391.56790
196/196 - 25s - loss: 389.3747 - MinusLogProbMetric: 389.3747 - val_loss: 391.6096 - val_MinusLogProbMetric: 391.6096 - lr: 2.0833e-05 - 25s/epoch - 126ms/step
Epoch 875/1000
2023-09-10 16:49:17.144 
Epoch 875/1000 
	 loss: 389.3935, MinusLogProbMetric: 389.3935, val_loss: 391.5845, val_MinusLogProbMetric: 391.5845

Epoch 875: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.3935 - MinusLogProbMetric: 389.3935 - val_loss: 391.5845 - val_MinusLogProbMetric: 391.5845 - lr: 2.0833e-05 - 20s/epoch - 101ms/step
Epoch 876/1000
2023-09-10 16:49:37.002 
Epoch 876/1000 
	 loss: 389.3701, MinusLogProbMetric: 389.3701, val_loss: 391.6047, val_MinusLogProbMetric: 391.6047

Epoch 876: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.3701 - MinusLogProbMetric: 389.3701 - val_loss: 391.6047 - val_MinusLogProbMetric: 391.6047 - lr: 2.0833e-05 - 20s/epoch - 101ms/step
Epoch 877/1000
2023-09-10 16:49:54.763 
Epoch 877/1000 
	 loss: 389.3890, MinusLogProbMetric: 389.3890, val_loss: 391.7065, val_MinusLogProbMetric: 391.7065

Epoch 877: val_loss did not improve from 391.56790
196/196 - 18s - loss: 389.3890 - MinusLogProbMetric: 389.3890 - val_loss: 391.7065 - val_MinusLogProbMetric: 391.7065 - lr: 2.0833e-05 - 18s/epoch - 91ms/step
Epoch 878/1000
2023-09-10 16:50:18.258 
Epoch 878/1000 
	 loss: 389.3805, MinusLogProbMetric: 389.3805, val_loss: 391.7566, val_MinusLogProbMetric: 391.7566

Epoch 878: val_loss did not improve from 391.56790
196/196 - 23s - loss: 389.3805 - MinusLogProbMetric: 389.3805 - val_loss: 391.7566 - val_MinusLogProbMetric: 391.7566 - lr: 2.0833e-05 - 23s/epoch - 120ms/step
Epoch 879/1000
2023-09-10 16:50:35.875 
Epoch 879/1000 
	 loss: 389.4071, MinusLogProbMetric: 389.4071, val_loss: 391.7023, val_MinusLogProbMetric: 391.7023

Epoch 879: val_loss did not improve from 391.56790
196/196 - 18s - loss: 389.4071 - MinusLogProbMetric: 389.4071 - val_loss: 391.7023 - val_MinusLogProbMetric: 391.7023 - lr: 2.0833e-05 - 18s/epoch - 90ms/step
Epoch 880/1000
2023-09-10 16:50:56.069 
Epoch 880/1000 
	 loss: 389.3621, MinusLogProbMetric: 389.3621, val_loss: 391.8592, val_MinusLogProbMetric: 391.8592

Epoch 880: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.3621 - MinusLogProbMetric: 389.3621 - val_loss: 391.8592 - val_MinusLogProbMetric: 391.8592 - lr: 2.0833e-05 - 20s/epoch - 103ms/step
Epoch 881/1000
2023-09-10 16:51:22.698 
Epoch 881/1000 
	 loss: 389.3844, MinusLogProbMetric: 389.3844, val_loss: 391.5736, val_MinusLogProbMetric: 391.5736

Epoch 881: val_loss did not improve from 391.56790
196/196 - 27s - loss: 389.3844 - MinusLogProbMetric: 389.3844 - val_loss: 391.5736 - val_MinusLogProbMetric: 391.5736 - lr: 2.0833e-05 - 27s/epoch - 136ms/step
Epoch 882/1000
2023-09-10 16:51:43.880 
Epoch 882/1000 
	 loss: 389.2773, MinusLogProbMetric: 389.2773, val_loss: 391.5679, val_MinusLogProbMetric: 391.5679

Epoch 882: val_loss did not improve from 391.56790
196/196 - 21s - loss: 389.2773 - MinusLogProbMetric: 389.2773 - val_loss: 391.5679 - val_MinusLogProbMetric: 391.5679 - lr: 1.0417e-05 - 21s/epoch - 108ms/step
Epoch 883/1000
2023-09-10 16:52:02.944 
Epoch 883/1000 
	 loss: 389.2682, MinusLogProbMetric: 389.2682, val_loss: 391.5686, val_MinusLogProbMetric: 391.5686

Epoch 883: val_loss did not improve from 391.56790
196/196 - 19s - loss: 389.2682 - MinusLogProbMetric: 389.2682 - val_loss: 391.5686 - val_MinusLogProbMetric: 391.5686 - lr: 1.0417e-05 - 19s/epoch - 97ms/step
Epoch 884/1000
2023-09-10 16:52:22.968 
Epoch 884/1000 
	 loss: 389.2681, MinusLogProbMetric: 389.2681, val_loss: 391.6009, val_MinusLogProbMetric: 391.6009

Epoch 884: val_loss did not improve from 391.56790
196/196 - 20s - loss: 389.2681 - MinusLogProbMetric: 389.2681 - val_loss: 391.6009 - val_MinusLogProbMetric: 391.6009 - lr: 1.0417e-05 - 20s/epoch - 102ms/step
Epoch 885/1000
2023-09-10 16:52:39.738 
Epoch 885/1000 
	 loss: 389.2697, MinusLogProbMetric: 389.2697, val_loss: 391.6083, val_MinusLogProbMetric: 391.6083

Epoch 885: val_loss did not improve from 391.56790
196/196 - 17s - loss: 389.2697 - MinusLogProbMetric: 389.2697 - val_loss: 391.6083 - val_MinusLogProbMetric: 391.6083 - lr: 1.0417e-05 - 17s/epoch - 85ms/step
Epoch 886/1000
2023-09-10 16:53:02.095 
Epoch 886/1000 
	 loss: 389.2671, MinusLogProbMetric: 389.2671, val_loss: 391.5684, val_MinusLogProbMetric: 391.5684

Epoch 886: val_loss did not improve from 391.56790
196/196 - 22s - loss: 389.2671 - MinusLogProbMetric: 389.2671 - val_loss: 391.5684 - val_MinusLogProbMetric: 391.5684 - lr: 1.0417e-05 - 22s/epoch - 114ms/step
Epoch 887/1000
2023-09-10 16:53:20.401 
Epoch 887/1000 
	 loss: 389.2727, MinusLogProbMetric: 389.2727, val_loss: 391.5617, val_MinusLogProbMetric: 391.5617

Epoch 887: val_loss improved from 391.56790 to 391.56168, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 19s - loss: 389.2727 - MinusLogProbMetric: 389.2727 - val_loss: 391.5617 - val_MinusLogProbMetric: 391.5617 - lr: 1.0417e-05 - 19s/epoch - 98ms/step
Epoch 888/1000
2023-09-10 16:53:39.550 
Epoch 888/1000 
	 loss: 389.2773, MinusLogProbMetric: 389.2773, val_loss: 391.6031, val_MinusLogProbMetric: 391.6031

Epoch 888: val_loss did not improve from 391.56168
196/196 - 18s - loss: 389.2773 - MinusLogProbMetric: 389.2773 - val_loss: 391.6031 - val_MinusLogProbMetric: 391.6031 - lr: 1.0417e-05 - 18s/epoch - 93ms/step
Epoch 889/1000
2023-09-10 16:54:00.968 
Epoch 889/1000 
	 loss: 389.2735, MinusLogProbMetric: 389.2735, val_loss: 391.5570, val_MinusLogProbMetric: 391.5570

Epoch 889: val_loss improved from 391.56168 to 391.55701, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 23s - loss: 389.2735 - MinusLogProbMetric: 389.2735 - val_loss: 391.5570 - val_MinusLogProbMetric: 391.5570 - lr: 1.0417e-05 - 23s/epoch - 115ms/step
Epoch 890/1000
2023-09-10 16:54:25.345 
Epoch 890/1000 
	 loss: 389.2760, MinusLogProbMetric: 389.2760, val_loss: 391.5939, val_MinusLogProbMetric: 391.5939

Epoch 890: val_loss did not improve from 391.55701
196/196 - 23s - loss: 389.2760 - MinusLogProbMetric: 389.2760 - val_loss: 391.5939 - val_MinusLogProbMetric: 391.5939 - lr: 1.0417e-05 - 23s/epoch - 118ms/step
Epoch 891/1000
2023-09-10 16:54:41.662 
Epoch 891/1000 
	 loss: 389.2714, MinusLogProbMetric: 389.2714, val_loss: 391.6135, val_MinusLogProbMetric: 391.6135

Epoch 891: val_loss did not improve from 391.55701
196/196 - 16s - loss: 389.2714 - MinusLogProbMetric: 389.2714 - val_loss: 391.6135 - val_MinusLogProbMetric: 391.6135 - lr: 1.0417e-05 - 16s/epoch - 83ms/step
Epoch 892/1000
2023-09-10 16:55:01.233 
Epoch 892/1000 
	 loss: 389.2673, MinusLogProbMetric: 389.2673, val_loss: 391.5605, val_MinusLogProbMetric: 391.5605

Epoch 892: val_loss did not improve from 391.55701
196/196 - 20s - loss: 389.2673 - MinusLogProbMetric: 389.2673 - val_loss: 391.5605 - val_MinusLogProbMetric: 391.5605 - lr: 1.0417e-05 - 20s/epoch - 100ms/step
Epoch 893/1000
2023-09-10 16:55:27.782 
Epoch 893/1000 
	 loss: 389.2772, MinusLogProbMetric: 389.2772, val_loss: 391.6167, val_MinusLogProbMetric: 391.6167

Epoch 893: val_loss did not improve from 391.55701
196/196 - 27s - loss: 389.2772 - MinusLogProbMetric: 389.2772 - val_loss: 391.6167 - val_MinusLogProbMetric: 391.6167 - lr: 1.0417e-05 - 27s/epoch - 135ms/step
Epoch 894/1000
2023-09-10 16:55:50.190 
Epoch 894/1000 
	 loss: 389.2757, MinusLogProbMetric: 389.2757, val_loss: 391.5309, val_MinusLogProbMetric: 391.5309

Epoch 894: val_loss improved from 391.55701 to 391.53094, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 23s - loss: 389.2757 - MinusLogProbMetric: 389.2757 - val_loss: 391.5309 - val_MinusLogProbMetric: 391.5309 - lr: 1.0417e-05 - 23s/epoch - 118ms/step
Epoch 895/1000
2023-09-10 16:56:12.463 
Epoch 895/1000 
	 loss: 389.2764, MinusLogProbMetric: 389.2764, val_loss: 391.6065, val_MinusLogProbMetric: 391.6065

Epoch 895: val_loss did not improve from 391.53094
196/196 - 22s - loss: 389.2764 - MinusLogProbMetric: 389.2764 - val_loss: 391.6065 - val_MinusLogProbMetric: 391.6065 - lr: 1.0417e-05 - 22s/epoch - 110ms/step
Epoch 896/1000
2023-09-10 16:56:34.126 
Epoch 896/1000 
	 loss: 389.2782, MinusLogProbMetric: 389.2782, val_loss: 391.6387, val_MinusLogProbMetric: 391.6387

Epoch 896: val_loss did not improve from 391.53094
196/196 - 22s - loss: 389.2782 - MinusLogProbMetric: 389.2782 - val_loss: 391.6387 - val_MinusLogProbMetric: 391.6387 - lr: 1.0417e-05 - 22s/epoch - 110ms/step
Epoch 897/1000
2023-09-10 16:56:59.103 
Epoch 897/1000 
	 loss: 389.2769, MinusLogProbMetric: 389.2769, val_loss: 391.6268, val_MinusLogProbMetric: 391.6268

Epoch 897: val_loss did not improve from 391.53094
196/196 - 25s - loss: 389.2769 - MinusLogProbMetric: 389.2769 - val_loss: 391.6268 - val_MinusLogProbMetric: 391.6268 - lr: 1.0417e-05 - 25s/epoch - 128ms/step
Epoch 898/1000
2023-09-10 16:57:18.885 
Epoch 898/1000 
	 loss: 389.2802, MinusLogProbMetric: 389.2802, val_loss: 391.5674, val_MinusLogProbMetric: 391.5674

Epoch 898: val_loss did not improve from 391.53094
196/196 - 20s - loss: 389.2802 - MinusLogProbMetric: 389.2802 - val_loss: 391.5674 - val_MinusLogProbMetric: 391.5674 - lr: 1.0417e-05 - 20s/epoch - 101ms/step
Epoch 899/1000
2023-09-10 16:57:39.256 
Epoch 899/1000 
	 loss: 389.2708, MinusLogProbMetric: 389.2708, val_loss: 391.6534, val_MinusLogProbMetric: 391.6534

Epoch 899: val_loss did not improve from 391.53094
196/196 - 20s - loss: 389.2708 - MinusLogProbMetric: 389.2708 - val_loss: 391.6534 - val_MinusLogProbMetric: 391.6534 - lr: 1.0417e-05 - 20s/epoch - 104ms/step
Epoch 900/1000
2023-09-10 16:58:00.566 
Epoch 900/1000 
	 loss: 389.2719, MinusLogProbMetric: 389.2719, val_loss: 391.6020, val_MinusLogProbMetric: 391.6020

Epoch 900: val_loss did not improve from 391.53094
196/196 - 21s - loss: 389.2719 - MinusLogProbMetric: 389.2719 - val_loss: 391.6020 - val_MinusLogProbMetric: 391.6020 - lr: 1.0417e-05 - 21s/epoch - 109ms/step
Epoch 901/1000
2023-09-10 16:58:18.921 
Epoch 901/1000 
	 loss: 389.2744, MinusLogProbMetric: 389.2744, val_loss: 391.5632, val_MinusLogProbMetric: 391.5632

Epoch 901: val_loss did not improve from 391.53094
196/196 - 18s - loss: 389.2744 - MinusLogProbMetric: 389.2744 - val_loss: 391.5632 - val_MinusLogProbMetric: 391.5632 - lr: 1.0417e-05 - 18s/epoch - 93ms/step
Epoch 902/1000
2023-09-10 16:58:36.632 
Epoch 902/1000 
	 loss: 389.2591, MinusLogProbMetric: 389.2591, val_loss: 391.6032, val_MinusLogProbMetric: 391.6032

Epoch 902: val_loss did not improve from 391.53094
196/196 - 18s - loss: 389.2591 - MinusLogProbMetric: 389.2591 - val_loss: 391.6032 - val_MinusLogProbMetric: 391.6032 - lr: 1.0417e-05 - 18s/epoch - 90ms/step
Epoch 903/1000
2023-09-10 16:58:54.440 
Epoch 903/1000 
	 loss: 389.2628, MinusLogProbMetric: 389.2628, val_loss: 391.5819, val_MinusLogProbMetric: 391.5819

Epoch 903: val_loss did not improve from 391.53094
196/196 - 18s - loss: 389.2628 - MinusLogProbMetric: 389.2628 - val_loss: 391.5819 - val_MinusLogProbMetric: 391.5819 - lr: 1.0417e-05 - 18s/epoch - 91ms/step
Epoch 904/1000
2023-09-10 16:59:20.050 
Epoch 904/1000 
	 loss: 389.2627, MinusLogProbMetric: 389.2627, val_loss: 391.5236, val_MinusLogProbMetric: 391.5236

Epoch 904: val_loss improved from 391.53094 to 391.52359, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 27s - loss: 389.2627 - MinusLogProbMetric: 389.2627 - val_loss: 391.5236 - val_MinusLogProbMetric: 391.5236 - lr: 1.0417e-05 - 27s/epoch - 136ms/step
Epoch 905/1000
2023-09-10 16:59:43.417 
Epoch 905/1000 
	 loss: 389.2612, MinusLogProbMetric: 389.2612, val_loss: 391.6537, val_MinusLogProbMetric: 391.6537

Epoch 905: val_loss did not improve from 391.52359
196/196 - 22s - loss: 389.2612 - MinusLogProbMetric: 389.2612 - val_loss: 391.6537 - val_MinusLogProbMetric: 391.6537 - lr: 1.0417e-05 - 22s/epoch - 114ms/step
Epoch 906/1000
2023-09-10 17:00:04.045 
Epoch 906/1000 
	 loss: 389.2576, MinusLogProbMetric: 389.2576, val_loss: 391.5938, val_MinusLogProbMetric: 391.5938

Epoch 906: val_loss did not improve from 391.52359
196/196 - 21s - loss: 389.2576 - MinusLogProbMetric: 389.2576 - val_loss: 391.5938 - val_MinusLogProbMetric: 391.5938 - lr: 1.0417e-05 - 21s/epoch - 105ms/step
Epoch 907/1000
2023-09-10 17:00:25.511 
Epoch 907/1000 
	 loss: 389.2715, MinusLogProbMetric: 389.2715, val_loss: 391.6287, val_MinusLogProbMetric: 391.6287

Epoch 907: val_loss did not improve from 391.52359
196/196 - 21s - loss: 389.2715 - MinusLogProbMetric: 389.2715 - val_loss: 391.6287 - val_MinusLogProbMetric: 391.6287 - lr: 1.0417e-05 - 21s/epoch - 109ms/step
Epoch 908/1000
2023-09-10 17:00:51.890 
Epoch 908/1000 
	 loss: 389.2700, MinusLogProbMetric: 389.2700, val_loss: 391.5981, val_MinusLogProbMetric: 391.5981

Epoch 908: val_loss did not improve from 391.52359
196/196 - 26s - loss: 389.2700 - MinusLogProbMetric: 389.2700 - val_loss: 391.5981 - val_MinusLogProbMetric: 391.5981 - lr: 1.0417e-05 - 26s/epoch - 134ms/step
Epoch 909/1000
2023-09-10 17:01:13.063 
Epoch 909/1000 
	 loss: 389.2580, MinusLogProbMetric: 389.2580, val_loss: 391.5703, val_MinusLogProbMetric: 391.5703

Epoch 909: val_loss did not improve from 391.52359
196/196 - 21s - loss: 389.2580 - MinusLogProbMetric: 389.2580 - val_loss: 391.5703 - val_MinusLogProbMetric: 391.5703 - lr: 1.0417e-05 - 21s/epoch - 108ms/step
Epoch 910/1000
2023-09-10 17:01:33.981 
Epoch 910/1000 
	 loss: 389.2580, MinusLogProbMetric: 389.2580, val_loss: 391.6287, val_MinusLogProbMetric: 391.6287

Epoch 910: val_loss did not improve from 391.52359
196/196 - 21s - loss: 389.2580 - MinusLogProbMetric: 389.2580 - val_loss: 391.6287 - val_MinusLogProbMetric: 391.6287 - lr: 1.0417e-05 - 21s/epoch - 107ms/step
Epoch 911/1000
2023-09-10 17:01:57.091 
Epoch 911/1000 
	 loss: 389.2563, MinusLogProbMetric: 389.2563, val_loss: 391.5966, val_MinusLogProbMetric: 391.5966

Epoch 911: val_loss did not improve from 391.52359
196/196 - 23s - loss: 389.2563 - MinusLogProbMetric: 389.2563 - val_loss: 391.5966 - val_MinusLogProbMetric: 391.5966 - lr: 1.0417e-05 - 23s/epoch - 118ms/step
Epoch 912/1000
2023-09-10 17:02:18.114 
Epoch 912/1000 
	 loss: 389.2703, MinusLogProbMetric: 389.2703, val_loss: 391.5790, val_MinusLogProbMetric: 391.5790

Epoch 912: val_loss did not improve from 391.52359
196/196 - 21s - loss: 389.2703 - MinusLogProbMetric: 389.2703 - val_loss: 391.5790 - val_MinusLogProbMetric: 391.5790 - lr: 1.0417e-05 - 21s/epoch - 107ms/step
Epoch 913/1000
2023-09-10 17:02:43.444 
Epoch 913/1000 
	 loss: 389.2616, MinusLogProbMetric: 389.2616, val_loss: 391.5859, val_MinusLogProbMetric: 391.5859

Epoch 913: val_loss did not improve from 391.52359
196/196 - 25s - loss: 389.2616 - MinusLogProbMetric: 389.2616 - val_loss: 391.5859 - val_MinusLogProbMetric: 391.5859 - lr: 1.0417e-05 - 25s/epoch - 129ms/step
Epoch 914/1000
2023-09-10 17:03:03.533 
Epoch 914/1000 
	 loss: 389.2565, MinusLogProbMetric: 389.2565, val_loss: 391.6240, val_MinusLogProbMetric: 391.6240

Epoch 914: val_loss did not improve from 391.52359
196/196 - 20s - loss: 389.2565 - MinusLogProbMetric: 389.2565 - val_loss: 391.6240 - val_MinusLogProbMetric: 391.6240 - lr: 1.0417e-05 - 20s/epoch - 102ms/step
Epoch 915/1000
2023-09-10 17:03:21.873 
Epoch 915/1000 
	 loss: 389.2575, MinusLogProbMetric: 389.2575, val_loss: 391.5845, val_MinusLogProbMetric: 391.5845

Epoch 915: val_loss did not improve from 391.52359
196/196 - 18s - loss: 389.2575 - MinusLogProbMetric: 389.2575 - val_loss: 391.5845 - val_MinusLogProbMetric: 391.5845 - lr: 1.0417e-05 - 18s/epoch - 94ms/step
Epoch 916/1000
2023-09-10 17:03:48.133 
Epoch 916/1000 
	 loss: 389.2604, MinusLogProbMetric: 389.2604, val_loss: 391.5393, val_MinusLogProbMetric: 391.5393

Epoch 916: val_loss did not improve from 391.52359
196/196 - 26s - loss: 389.2604 - MinusLogProbMetric: 389.2604 - val_loss: 391.5393 - val_MinusLogProbMetric: 391.5393 - lr: 1.0417e-05 - 26s/epoch - 134ms/step
Epoch 917/1000
2023-09-10 17:04:11.325 
Epoch 917/1000 
	 loss: 389.2672, MinusLogProbMetric: 389.2672, val_loss: 391.5261, val_MinusLogProbMetric: 391.5261

Epoch 917: val_loss did not improve from 391.52359
196/196 - 23s - loss: 389.2672 - MinusLogProbMetric: 389.2672 - val_loss: 391.5261 - val_MinusLogProbMetric: 391.5261 - lr: 1.0417e-05 - 23s/epoch - 118ms/step
Epoch 918/1000
2023-09-10 17:04:32.543 
Epoch 918/1000 
	 loss: 389.2726, MinusLogProbMetric: 389.2726, val_loss: 391.5553, val_MinusLogProbMetric: 391.5553

Epoch 918: val_loss did not improve from 391.52359
196/196 - 21s - loss: 389.2726 - MinusLogProbMetric: 389.2726 - val_loss: 391.5553 - val_MinusLogProbMetric: 391.5553 - lr: 1.0417e-05 - 21s/epoch - 108ms/step
Epoch 919/1000
2023-09-10 17:04:57.209 
Epoch 919/1000 
	 loss: 389.2514, MinusLogProbMetric: 389.2514, val_loss: 391.5471, val_MinusLogProbMetric: 391.5471

Epoch 919: val_loss did not improve from 391.52359
196/196 - 25s - loss: 389.2514 - MinusLogProbMetric: 389.2514 - val_loss: 391.5471 - val_MinusLogProbMetric: 391.5471 - lr: 1.0417e-05 - 25s/epoch - 126ms/step
Epoch 920/1000
2023-09-10 17:05:16.379 
Epoch 920/1000 
	 loss: 389.2514, MinusLogProbMetric: 389.2514, val_loss: 391.5466, val_MinusLogProbMetric: 391.5466

Epoch 920: val_loss did not improve from 391.52359
196/196 - 19s - loss: 389.2514 - MinusLogProbMetric: 389.2514 - val_loss: 391.5466 - val_MinusLogProbMetric: 391.5466 - lr: 1.0417e-05 - 19s/epoch - 98ms/step
Epoch 921/1000
2023-09-10 17:05:36.966 
Epoch 921/1000 
	 loss: 389.2451, MinusLogProbMetric: 389.2451, val_loss: 391.5376, val_MinusLogProbMetric: 391.5376

Epoch 921: val_loss did not improve from 391.52359
196/196 - 21s - loss: 389.2451 - MinusLogProbMetric: 389.2451 - val_loss: 391.5376 - val_MinusLogProbMetric: 391.5376 - lr: 1.0417e-05 - 21s/epoch - 105ms/step
Epoch 922/1000
2023-09-10 17:05:57.353 
Epoch 922/1000 
	 loss: 389.2572, MinusLogProbMetric: 389.2572, val_loss: 391.5416, val_MinusLogProbMetric: 391.5416

Epoch 922: val_loss did not improve from 391.52359
196/196 - 20s - loss: 389.2572 - MinusLogProbMetric: 389.2572 - val_loss: 391.5416 - val_MinusLogProbMetric: 391.5416 - lr: 1.0417e-05 - 20s/epoch - 104ms/step
Epoch 923/1000
2023-09-10 17:06:17.249 
Epoch 923/1000 
	 loss: 389.2614, MinusLogProbMetric: 389.2614, val_loss: 391.6179, val_MinusLogProbMetric: 391.6179

Epoch 923: val_loss did not improve from 391.52359
196/196 - 20s - loss: 389.2614 - MinusLogProbMetric: 389.2614 - val_loss: 391.6179 - val_MinusLogProbMetric: 391.6179 - lr: 1.0417e-05 - 20s/epoch - 101ms/step
Epoch 924/1000
2023-09-10 17:06:42.289 
Epoch 924/1000 
	 loss: 389.2578, MinusLogProbMetric: 389.2578, val_loss: 391.5937, val_MinusLogProbMetric: 391.5937

Epoch 924: val_loss did not improve from 391.52359
196/196 - 25s - loss: 389.2578 - MinusLogProbMetric: 389.2578 - val_loss: 391.5937 - val_MinusLogProbMetric: 391.5937 - lr: 1.0417e-05 - 25s/epoch - 128ms/step
Epoch 925/1000
2023-09-10 17:07:07.419 
Epoch 925/1000 
	 loss: 389.2486, MinusLogProbMetric: 389.2486, val_loss: 391.5889, val_MinusLogProbMetric: 391.5889

Epoch 925: val_loss did not improve from 391.52359
196/196 - 25s - loss: 389.2486 - MinusLogProbMetric: 389.2486 - val_loss: 391.5889 - val_MinusLogProbMetric: 391.5889 - lr: 1.0417e-05 - 25s/epoch - 128ms/step
Epoch 926/1000
2023-09-10 17:07:29.119 
Epoch 926/1000 
	 loss: 389.2473, MinusLogProbMetric: 389.2473, val_loss: 391.6001, val_MinusLogProbMetric: 391.6001

Epoch 926: val_loss did not improve from 391.52359
196/196 - 22s - loss: 389.2473 - MinusLogProbMetric: 389.2473 - val_loss: 391.6001 - val_MinusLogProbMetric: 391.6001 - lr: 1.0417e-05 - 22s/epoch - 111ms/step
Epoch 927/1000
2023-09-10 17:07:53.455 
Epoch 927/1000 
	 loss: 389.2608, MinusLogProbMetric: 389.2608, val_loss: 391.5603, val_MinusLogProbMetric: 391.5603

Epoch 927: val_loss did not improve from 391.52359
196/196 - 24s - loss: 389.2608 - MinusLogProbMetric: 389.2608 - val_loss: 391.5603 - val_MinusLogProbMetric: 391.5603 - lr: 1.0417e-05 - 24s/epoch - 124ms/step
Epoch 928/1000
2023-09-10 17:08:12.120 
Epoch 928/1000 
	 loss: 389.2488, MinusLogProbMetric: 389.2488, val_loss: 391.5221, val_MinusLogProbMetric: 391.5221

Epoch 928: val_loss improved from 391.52359 to 391.52206, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 20s - loss: 389.2488 - MinusLogProbMetric: 389.2488 - val_loss: 391.5221 - val_MinusLogProbMetric: 391.5221 - lr: 1.0417e-05 - 20s/epoch - 100ms/step
Epoch 929/1000
2023-09-10 17:08:34.146 
Epoch 929/1000 
	 loss: 389.2402, MinusLogProbMetric: 389.2402, val_loss: 391.5811, val_MinusLogProbMetric: 391.5811

Epoch 929: val_loss did not improve from 391.52206
196/196 - 21s - loss: 389.2402 - MinusLogProbMetric: 389.2402 - val_loss: 391.5811 - val_MinusLogProbMetric: 391.5811 - lr: 1.0417e-05 - 21s/epoch - 108ms/step
Epoch 930/1000
2023-09-10 17:09:01.786 
Epoch 930/1000 
	 loss: 389.2375, MinusLogProbMetric: 389.2375, val_loss: 391.5501, val_MinusLogProbMetric: 391.5501

Epoch 930: val_loss did not improve from 391.52206
196/196 - 28s - loss: 389.2375 - MinusLogProbMetric: 389.2375 - val_loss: 391.5501 - val_MinusLogProbMetric: 391.5501 - lr: 1.0417e-05 - 28s/epoch - 141ms/step
Epoch 931/1000
2023-09-10 17:09:23.687 
Epoch 931/1000 
	 loss: 389.2440, MinusLogProbMetric: 389.2440, val_loss: 391.5845, val_MinusLogProbMetric: 391.5845

Epoch 931: val_loss did not improve from 391.52206
196/196 - 22s - loss: 389.2440 - MinusLogProbMetric: 389.2440 - val_loss: 391.5845 - val_MinusLogProbMetric: 391.5845 - lr: 1.0417e-05 - 22s/epoch - 112ms/step
Epoch 932/1000
2023-09-10 17:09:45.722 
Epoch 932/1000 
	 loss: 389.2375, MinusLogProbMetric: 389.2375, val_loss: 391.5735, val_MinusLogProbMetric: 391.5735

Epoch 932: val_loss did not improve from 391.52206
196/196 - 22s - loss: 389.2375 - MinusLogProbMetric: 389.2375 - val_loss: 391.5735 - val_MinusLogProbMetric: 391.5735 - lr: 1.0417e-05 - 22s/epoch - 112ms/step
Epoch 933/1000
2023-09-10 17:10:09.316 
Epoch 933/1000 
	 loss: 389.2267, MinusLogProbMetric: 389.2267, val_loss: 391.6106, val_MinusLogProbMetric: 391.6106

Epoch 933: val_loss did not improve from 391.52206
196/196 - 24s - loss: 389.2267 - MinusLogProbMetric: 389.2267 - val_loss: 391.6106 - val_MinusLogProbMetric: 391.6106 - lr: 1.0417e-05 - 24s/epoch - 120ms/step
Epoch 934/1000
2023-09-10 17:10:33.449 
Epoch 934/1000 
	 loss: 389.2260, MinusLogProbMetric: 389.2260, val_loss: 391.5446, val_MinusLogProbMetric: 391.5446

Epoch 934: val_loss did not improve from 391.52206
196/196 - 24s - loss: 389.2260 - MinusLogProbMetric: 389.2260 - val_loss: 391.5446 - val_MinusLogProbMetric: 391.5446 - lr: 1.0417e-05 - 24s/epoch - 123ms/step
Epoch 935/1000
2023-09-10 17:10:58.945 
Epoch 935/1000 
	 loss: 389.2326, MinusLogProbMetric: 389.2326, val_loss: 391.6331, val_MinusLogProbMetric: 391.6331

Epoch 935: val_loss did not improve from 391.52206
196/196 - 25s - loss: 389.2326 - MinusLogProbMetric: 389.2326 - val_loss: 391.6331 - val_MinusLogProbMetric: 391.6331 - lr: 1.0417e-05 - 25s/epoch - 130ms/step
Epoch 936/1000
2023-09-10 17:11:17.018 
Epoch 936/1000 
	 loss: 389.2303, MinusLogProbMetric: 389.2303, val_loss: 391.5145, val_MinusLogProbMetric: 391.5145

Epoch 936: val_loss improved from 391.52206 to 391.51447, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 19s - loss: 389.2303 - MinusLogProbMetric: 389.2303 - val_loss: 391.5145 - val_MinusLogProbMetric: 391.5145 - lr: 1.0417e-05 - 19s/epoch - 95ms/step
Epoch 937/1000
2023-09-10 17:11:40.171 
Epoch 937/1000 
	 loss: 389.2314, MinusLogProbMetric: 389.2314, val_loss: 391.5974, val_MinusLogProbMetric: 391.5974

Epoch 937: val_loss did not improve from 391.51447
196/196 - 23s - loss: 389.2314 - MinusLogProbMetric: 389.2314 - val_loss: 391.5974 - val_MinusLogProbMetric: 391.5974 - lr: 1.0417e-05 - 23s/epoch - 115ms/step
Epoch 938/1000
2023-09-10 17:12:03.465 
Epoch 938/1000 
	 loss: 389.2278, MinusLogProbMetric: 389.2278, val_loss: 391.5835, val_MinusLogProbMetric: 391.5835

Epoch 938: val_loss did not improve from 391.51447
196/196 - 23s - loss: 389.2278 - MinusLogProbMetric: 389.2278 - val_loss: 391.5835 - val_MinusLogProbMetric: 391.5835 - lr: 1.0417e-05 - 23s/epoch - 119ms/step
Epoch 939/1000
2023-09-10 17:12:26.439 
Epoch 939/1000 
	 loss: 389.2411, MinusLogProbMetric: 389.2411, val_loss: 391.6706, val_MinusLogProbMetric: 391.6706

Epoch 939: val_loss did not improve from 391.51447
196/196 - 23s - loss: 389.2411 - MinusLogProbMetric: 389.2411 - val_loss: 391.6706 - val_MinusLogProbMetric: 391.6706 - lr: 1.0417e-05 - 23s/epoch - 117ms/step
Epoch 940/1000
2023-09-10 17:12:52.153 
Epoch 940/1000 
	 loss: 389.2277, MinusLogProbMetric: 389.2277, val_loss: 391.5326, val_MinusLogProbMetric: 391.5326

Epoch 940: val_loss did not improve from 391.51447
196/196 - 26s - loss: 389.2277 - MinusLogProbMetric: 389.2277 - val_loss: 391.5326 - val_MinusLogProbMetric: 391.5326 - lr: 1.0417e-05 - 26s/epoch - 131ms/step
Epoch 941/1000
2023-09-10 17:13:19.474 
Epoch 941/1000 
	 loss: 389.2316, MinusLogProbMetric: 389.2316, val_loss: 391.5101, val_MinusLogProbMetric: 391.5101

Epoch 941: val_loss improved from 391.51447 to 391.51007, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 29s - loss: 389.2316 - MinusLogProbMetric: 389.2316 - val_loss: 391.5101 - val_MinusLogProbMetric: 391.5101 - lr: 1.0417e-05 - 29s/epoch - 146ms/step
Epoch 942/1000
2023-09-10 17:13:49.507 
Epoch 942/1000 
	 loss: 389.2340, MinusLogProbMetric: 389.2340, val_loss: 391.5997, val_MinusLogProbMetric: 391.5997

Epoch 942: val_loss did not improve from 391.51007
196/196 - 29s - loss: 389.2340 - MinusLogProbMetric: 389.2340 - val_loss: 391.5997 - val_MinusLogProbMetric: 391.5997 - lr: 1.0417e-05 - 29s/epoch - 147ms/step
Epoch 943/1000
2023-09-10 17:14:15.519 
Epoch 943/1000 
	 loss: 389.2281, MinusLogProbMetric: 389.2281, val_loss: 391.5704, val_MinusLogProbMetric: 391.5704

Epoch 943: val_loss did not improve from 391.51007
196/196 - 26s - loss: 389.2281 - MinusLogProbMetric: 389.2281 - val_loss: 391.5704 - val_MinusLogProbMetric: 391.5704 - lr: 1.0417e-05 - 26s/epoch - 133ms/step
Epoch 944/1000
2023-09-10 17:14:35.969 
Epoch 944/1000 
	 loss: 389.2239, MinusLogProbMetric: 389.2239, val_loss: 391.5925, val_MinusLogProbMetric: 391.5925

Epoch 944: val_loss did not improve from 391.51007
196/196 - 20s - loss: 389.2239 - MinusLogProbMetric: 389.2239 - val_loss: 391.5925 - val_MinusLogProbMetric: 391.5925 - lr: 1.0417e-05 - 20s/epoch - 104ms/step
Epoch 945/1000
2023-09-10 17:15:03.804 
Epoch 945/1000 
	 loss: 389.2252, MinusLogProbMetric: 389.2252, val_loss: 391.6205, val_MinusLogProbMetric: 391.6205

Epoch 945: val_loss did not improve from 391.51007
196/196 - 28s - loss: 389.2252 - MinusLogProbMetric: 389.2252 - val_loss: 391.6205 - val_MinusLogProbMetric: 391.6205 - lr: 1.0417e-05 - 28s/epoch - 142ms/step
Epoch 946/1000
2023-09-10 17:15:28.658 
Epoch 946/1000 
	 loss: 389.2362, MinusLogProbMetric: 389.2362, val_loss: 391.5263, val_MinusLogProbMetric: 391.5263

Epoch 946: val_loss did not improve from 391.51007
196/196 - 25s - loss: 389.2362 - MinusLogProbMetric: 389.2362 - val_loss: 391.5263 - val_MinusLogProbMetric: 391.5263 - lr: 1.0417e-05 - 25s/epoch - 127ms/step
Epoch 947/1000
2023-09-10 17:15:55.788 
Epoch 947/1000 
	 loss: 389.2389, MinusLogProbMetric: 389.2389, val_loss: 391.5370, val_MinusLogProbMetric: 391.5370

Epoch 947: val_loss did not improve from 391.51007
196/196 - 27s - loss: 389.2389 - MinusLogProbMetric: 389.2389 - val_loss: 391.5370 - val_MinusLogProbMetric: 391.5370 - lr: 1.0417e-05 - 27s/epoch - 138ms/step
Epoch 948/1000
2023-09-10 17:16:19.102 
Epoch 948/1000 
	 loss: 389.2345, MinusLogProbMetric: 389.2345, val_loss: 391.6170, val_MinusLogProbMetric: 391.6170

Epoch 948: val_loss did not improve from 391.51007
196/196 - 23s - loss: 389.2345 - MinusLogProbMetric: 389.2345 - val_loss: 391.6170 - val_MinusLogProbMetric: 391.6170 - lr: 1.0417e-05 - 23s/epoch - 119ms/step
Epoch 949/1000
2023-09-10 17:16:44.814 
Epoch 949/1000 
	 loss: 389.2435, MinusLogProbMetric: 389.2435, val_loss: 391.5743, val_MinusLogProbMetric: 391.5743

Epoch 949: val_loss did not improve from 391.51007
196/196 - 26s - loss: 389.2435 - MinusLogProbMetric: 389.2435 - val_loss: 391.5743 - val_MinusLogProbMetric: 391.5743 - lr: 1.0417e-05 - 26s/epoch - 131ms/step
Epoch 950/1000
2023-09-10 17:17:06.804 
Epoch 950/1000 
	 loss: 389.2297, MinusLogProbMetric: 389.2297, val_loss: 391.5896, val_MinusLogProbMetric: 391.5896

Epoch 950: val_loss did not improve from 391.51007
196/196 - 22s - loss: 389.2297 - MinusLogProbMetric: 389.2297 - val_loss: 391.5896 - val_MinusLogProbMetric: 391.5896 - lr: 1.0417e-05 - 22s/epoch - 112ms/step
Epoch 951/1000
2023-09-10 17:17:25.795 
Epoch 951/1000 
	 loss: 389.2328, MinusLogProbMetric: 389.2328, val_loss: 391.5188, val_MinusLogProbMetric: 391.5188

Epoch 951: val_loss did not improve from 391.51007
196/196 - 19s - loss: 389.2328 - MinusLogProbMetric: 389.2328 - val_loss: 391.5188 - val_MinusLogProbMetric: 391.5188 - lr: 1.0417e-05 - 19s/epoch - 97ms/step
Epoch 952/1000
2023-09-10 17:17:49.346 
Epoch 952/1000 
	 loss: 389.2342, MinusLogProbMetric: 389.2342, val_loss: 391.6211, val_MinusLogProbMetric: 391.6211

Epoch 952: val_loss did not improve from 391.51007
196/196 - 24s - loss: 389.2342 - MinusLogProbMetric: 389.2342 - val_loss: 391.6211 - val_MinusLogProbMetric: 391.6211 - lr: 1.0417e-05 - 24s/epoch - 120ms/step
Epoch 953/1000
2023-09-10 17:18:13.661 
Epoch 953/1000 
	 loss: 389.2330, MinusLogProbMetric: 389.2330, val_loss: 391.6110, val_MinusLogProbMetric: 391.6110

Epoch 953: val_loss did not improve from 391.51007
196/196 - 24s - loss: 389.2330 - MinusLogProbMetric: 389.2330 - val_loss: 391.6110 - val_MinusLogProbMetric: 391.6110 - lr: 1.0417e-05 - 24s/epoch - 124ms/step
Epoch 954/1000
2023-09-10 17:18:37.719 
Epoch 954/1000 
	 loss: 389.2287, MinusLogProbMetric: 389.2287, val_loss: 391.4754, val_MinusLogProbMetric: 391.4754

Epoch 954: val_loss improved from 391.51007 to 391.47543, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new/run_338/weights/best_weights.h5
196/196 - 25s - loss: 389.2287 - MinusLogProbMetric: 389.2287 - val_loss: 391.4754 - val_MinusLogProbMetric: 391.4754 - lr: 1.0417e-05 - 25s/epoch - 127ms/step
Epoch 955/1000
2023-09-10 17:19:04.089 
Epoch 955/1000 
	 loss: 389.2243, MinusLogProbMetric: 389.2243, val_loss: 391.6240, val_MinusLogProbMetric: 391.6240

Epoch 955: val_loss did not improve from 391.47543
196/196 - 26s - loss: 389.2243 - MinusLogProbMetric: 389.2243 - val_loss: 391.6240 - val_MinusLogProbMetric: 391.6240 - lr: 1.0417e-05 - 26s/epoch - 130ms/step
Epoch 956/1000
2023-09-10 17:19:22.768 
Epoch 956/1000 
	 loss: 389.2296, MinusLogProbMetric: 389.2296, val_loss: 391.6265, val_MinusLogProbMetric: 391.6265

Epoch 956: val_loss did not improve from 391.47543
196/196 - 19s - loss: 389.2296 - MinusLogProbMetric: 389.2296 - val_loss: 391.6265 - val_MinusLogProbMetric: 391.6265 - lr: 1.0417e-05 - 19s/epoch - 95ms/step
Epoch 957/1000
2023-09-10 17:19:49.463 
Epoch 957/1000 
	 loss: 389.2272, MinusLogProbMetric: 389.2272, val_loss: 391.6365, val_MinusLogProbMetric: 391.6365

Epoch 957: val_loss did not improve from 391.47543
196/196 - 27s - loss: 389.2272 - MinusLogProbMetric: 389.2272 - val_loss: 391.6365 - val_MinusLogProbMetric: 391.6365 - lr: 1.0417e-05 - 27s/epoch - 136ms/step
Epoch 958/1000
2023-09-10 17:20:16.959 
Epoch 958/1000 
	 loss: 389.2370, MinusLogProbMetric: 389.2370, val_loss: 391.6136, val_MinusLogProbMetric: 391.6136

Epoch 958: val_loss did not improve from 391.47543
196/196 - 27s - loss: 389.2370 - MinusLogProbMetric: 389.2370 - val_loss: 391.6136 - val_MinusLogProbMetric: 391.6136 - lr: 1.0417e-05 - 27s/epoch - 140ms/step
Epoch 959/1000
2023-09-10 17:20:39.916 
Epoch 959/1000 
	 loss: 389.2226, MinusLogProbMetric: 389.2226, val_loss: 391.5230, val_MinusLogProbMetric: 391.5230

Epoch 959: val_loss did not improve from 391.47543
196/196 - 23s - loss: 389.2226 - MinusLogProbMetric: 389.2226 - val_loss: 391.5230 - val_MinusLogProbMetric: 391.5230 - lr: 1.0417e-05 - 23s/epoch - 117ms/step
Epoch 960/1000
2023-09-10 17:21:06.124 
Epoch 960/1000 
	 loss: 389.2154, MinusLogProbMetric: 389.2154, val_loss: 391.6783, val_MinusLogProbMetric: 391.6783

Epoch 960: val_loss did not improve from 391.47543
196/196 - 26s - loss: 389.2154 - MinusLogProbMetric: 389.2154 - val_loss: 391.6783 - val_MinusLogProbMetric: 391.6783 - lr: 1.0417e-05 - 26s/epoch - 133ms/step
Epoch 961/1000
2023-09-10 17:21:31.285 
Epoch 961/1000 
	 loss: 389.2360, MinusLogProbMetric: 389.2360, val_loss: 391.7122, val_MinusLogProbMetric: 391.7122

Epoch 961: val_loss did not improve from 391.47543
196/196 - 25s - loss: 389.2360 - MinusLogProbMetric: 389.2360 - val_loss: 391.7122 - val_MinusLogProbMetric: 391.7122 - lr: 1.0417e-05 - 25s/epoch - 128ms/step
Epoch 962/1000
2023-09-10 17:21:53.992 
Epoch 962/1000 
	 loss: 389.2246, MinusLogProbMetric: 389.2246, val_loss: 391.6507, val_MinusLogProbMetric: 391.6507

Epoch 962: val_loss did not improve from 391.47543
196/196 - 23s - loss: 389.2246 - MinusLogProbMetric: 389.2246 - val_loss: 391.6507 - val_MinusLogProbMetric: 391.6507 - lr: 1.0417e-05 - 23s/epoch - 116ms/step
Epoch 963/1000
2023-09-10 17:22:18.536 
Epoch 963/1000 
	 loss: 389.2387, MinusLogProbMetric: 389.2387, val_loss: 391.6988, val_MinusLogProbMetric: 391.6988

Epoch 963: val_loss did not improve from 391.47543
196/196 - 25s - loss: 389.2387 - MinusLogProbMetric: 389.2387 - val_loss: 391.6988 - val_MinusLogProbMetric: 391.6988 - lr: 1.0417e-05 - 25s/epoch - 125ms/step
Epoch 964/1000
2023-09-10 17:22:41.768 
Epoch 964/1000 
	 loss: 389.2357, MinusLogProbMetric: 389.2357, val_loss: 391.5575, val_MinusLogProbMetric: 391.5575

Epoch 964: val_loss did not improve from 391.47543
196/196 - 23s - loss: 389.2357 - MinusLogProbMetric: 389.2357 - val_loss: 391.5575 - val_MinusLogProbMetric: 391.5575 - lr: 1.0417e-05 - 23s/epoch - 118ms/step
Epoch 965/1000
2023-09-10 17:23:02.728 
Epoch 965/1000 
	 loss: 389.2517, MinusLogProbMetric: 389.2517, val_loss: 391.8370, val_MinusLogProbMetric: 391.8370

Epoch 965: val_loss did not improve from 391.47543
196/196 - 21s - loss: 389.2517 - MinusLogProbMetric: 389.2517 - val_loss: 391.8370 - val_MinusLogProbMetric: 391.8370 - lr: 1.0417e-05 - 21s/epoch - 107ms/step
Epoch 966/1000
2023-09-10 17:23:27.440 
Epoch 966/1000 
	 loss: 389.2395, MinusLogProbMetric: 389.2395, val_loss: 391.7000, val_MinusLogProbMetric: 391.7000

Epoch 966: val_loss did not improve from 391.47543
196/196 - 25s - loss: 389.2395 - MinusLogProbMetric: 389.2395 - val_loss: 391.7000 - val_MinusLogProbMetric: 391.7000 - lr: 1.0417e-05 - 25s/epoch - 126ms/step
Epoch 967/1000
2023-09-10 17:23:54.231 
Epoch 967/1000 
	 loss: 389.2382, MinusLogProbMetric: 389.2382, val_loss: 391.5643, val_MinusLogProbMetric: 391.5643

Epoch 967: val_loss did not improve from 391.47543
196/196 - 27s - loss: 389.2382 - MinusLogProbMetric: 389.2382 - val_loss: 391.5643 - val_MinusLogProbMetric: 391.5643 - lr: 1.0417e-05 - 27s/epoch - 136ms/step
Epoch 968/1000
2023-09-10 17:24:13.528 
Epoch 968/1000 
	 loss: 389.2251, MinusLogProbMetric: 389.2251, val_loss: 391.5717, val_MinusLogProbMetric: 391.5717

Epoch 968: val_loss did not improve from 391.47543
196/196 - 19s - loss: 389.2251 - MinusLogProbMetric: 389.2251 - val_loss: 391.5717 - val_MinusLogProbMetric: 391.5717 - lr: 1.0417e-05 - 19s/epoch - 98ms/step
Epoch 969/1000
2023-09-10 17:24:35.097 
Epoch 969/1000 
	 loss: 389.2233, MinusLogProbMetric: 389.2233, val_loss: 391.5560, val_MinusLogProbMetric: 391.5560

Epoch 969: val_loss did not improve from 391.47543
196/196 - 22s - loss: 389.2233 - MinusLogProbMetric: 389.2233 - val_loss: 391.5560 - val_MinusLogProbMetric: 391.5560 - lr: 1.0417e-05 - 22s/epoch - 110ms/step
Epoch 970/1000
2023-09-10 17:24:56.882 
Epoch 970/1000 
	 loss: 389.2216, MinusLogProbMetric: 389.2216, val_loss: 391.5659, val_MinusLogProbMetric: 391.5659

Epoch 970: val_loss did not improve from 391.47543
196/196 - 22s - loss: 389.2216 - MinusLogProbMetric: 389.2216 - val_loss: 391.5659 - val_MinusLogProbMetric: 391.5659 - lr: 1.0417e-05 - 22s/epoch - 111ms/step
Epoch 971/1000
2023-09-10 17:25:20.468 
Epoch 971/1000 
	 loss: 389.2164, MinusLogProbMetric: 389.2164, val_loss: 391.5466, val_MinusLogProbMetric: 391.5466

Epoch 971: val_loss did not improve from 391.47543
196/196 - 24s - loss: 389.2164 - MinusLogProbMetric: 389.2164 - val_loss: 391.5466 - val_MinusLogProbMetric: 391.5466 - lr: 1.0417e-05 - 24s/epoch - 120ms/step
Epoch 972/1000
2023-09-10 17:25:47.036 
Epoch 972/1000 
	 loss: 389.2178, MinusLogProbMetric: 389.2178, val_loss: 391.5560, val_MinusLogProbMetric: 391.5560

Epoch 972: val_loss did not improve from 391.47543
196/196 - 27s - loss: 389.2178 - MinusLogProbMetric: 389.2178 - val_loss: 391.5560 - val_MinusLogProbMetric: 391.5560 - lr: 1.0417e-05 - 27s/epoch - 136ms/step
Epoch 973/1000
2023-09-10 17:26:09.335 
Epoch 973/1000 
	 loss: 389.2191, MinusLogProbMetric: 389.2191, val_loss: 391.6500, val_MinusLogProbMetric: 391.6500

Epoch 973: val_loss did not improve from 391.47543
196/196 - 22s - loss: 389.2191 - MinusLogProbMetric: 389.2191 - val_loss: 391.6500 - val_MinusLogProbMetric: 391.6500 - lr: 1.0417e-05 - 22s/epoch - 114ms/step
Epoch 974/1000
2023-09-10 17:26:33.575 
Epoch 974/1000 
	 loss: 389.2133, MinusLogProbMetric: 389.2133, val_loss: 391.6770, val_MinusLogProbMetric: 391.6770

Epoch 974: val_loss did not improve from 391.47543
196/196 - 24s - loss: 389.2133 - MinusLogProbMetric: 389.2133 - val_loss: 391.6770 - val_MinusLogProbMetric: 391.6770 - lr: 1.0417e-05 - 24s/epoch - 124ms/step
Epoch 975/1000
2023-09-10 17:26:55.052 
Epoch 975/1000 
	 loss: 389.2193, MinusLogProbMetric: 389.2193, val_loss: 391.6652, val_MinusLogProbMetric: 391.6652

Epoch 975: val_loss did not improve from 391.47543
196/196 - 21s - loss: 389.2193 - MinusLogProbMetric: 389.2193 - val_loss: 391.6652 - val_MinusLogProbMetric: 391.6652 - lr: 1.0417e-05 - 21s/epoch - 109ms/step
Epoch 976/1000
2023-09-10 17:27:12.976 
Epoch 976/1000 
	 loss: 389.2270, MinusLogProbMetric: 389.2270, val_loss: 391.5365, val_MinusLogProbMetric: 391.5365

Epoch 976: val_loss did not improve from 391.47543
196/196 - 18s - loss: 389.2270 - MinusLogProbMetric: 389.2270 - val_loss: 391.5365 - val_MinusLogProbMetric: 391.5365 - lr: 1.0417e-05 - 18s/epoch - 91ms/step
Epoch 977/1000
2023-09-10 17:27:40.075 
Epoch 977/1000 
	 loss: 389.2206, MinusLogProbMetric: 389.2206, val_loss: 391.5867, val_MinusLogProbMetric: 391.5867

Epoch 977: val_loss did not improve from 391.47543
196/196 - 27s - loss: 389.2206 - MinusLogProbMetric: 389.2206 - val_loss: 391.5867 - val_MinusLogProbMetric: 391.5867 - lr: 1.0417e-05 - 27s/epoch - 138ms/step
Epoch 978/1000
2023-09-10 17:27:59.311 
Epoch 978/1000 
	 loss: 389.2175, MinusLogProbMetric: 389.2175, val_loss: 391.6281, val_MinusLogProbMetric: 391.6281

Epoch 978: val_loss did not improve from 391.47543
196/196 - 19s - loss: 389.2175 - MinusLogProbMetric: 389.2175 - val_loss: 391.6281 - val_MinusLogProbMetric: 391.6281 - lr: 1.0417e-05 - 19s/epoch - 98ms/step
Epoch 979/1000
2023-09-10 17:28:22.202 
Epoch 979/1000 
	 loss: 389.2148, MinusLogProbMetric: 389.2148, val_loss: 391.6340, val_MinusLogProbMetric: 391.6340

Epoch 979: val_loss did not improve from 391.47543
196/196 - 23s - loss: 389.2148 - MinusLogProbMetric: 389.2148 - val_loss: 391.6340 - val_MinusLogProbMetric: 391.6340 - lr: 1.0417e-05 - 23s/epoch - 116ms/step
Epoch 980/1000
2023-09-10 17:28:43.499 
Epoch 980/1000 
	 loss: 389.2226, MinusLogProbMetric: 389.2226, val_loss: 391.6890, val_MinusLogProbMetric: 391.6890

Epoch 980: val_loss did not improve from 391.47543
196/196 - 21s - loss: 389.2226 - MinusLogProbMetric: 389.2226 - val_loss: 391.6890 - val_MinusLogProbMetric: 391.6890 - lr: 1.0417e-05 - 21s/epoch - 109ms/step
Epoch 981/1000
2023-09-10 17:29:04.955 
Epoch 981/1000 
	 loss: 389.2155, MinusLogProbMetric: 389.2155, val_loss: 391.6154, val_MinusLogProbMetric: 391.6154

Epoch 981: val_loss did not improve from 391.47543
196/196 - 21s - loss: 389.2155 - MinusLogProbMetric: 389.2155 - val_loss: 391.6154 - val_MinusLogProbMetric: 391.6154 - lr: 1.0417e-05 - 21s/epoch - 109ms/step
Epoch 982/1000
2023-09-10 17:29:26.966 
Epoch 982/1000 
	 loss: 389.2069, MinusLogProbMetric: 389.2069, val_loss: 391.6125, val_MinusLogProbMetric: 391.6125

Epoch 982: val_loss did not improve from 391.47543
196/196 - 22s - loss: 389.2069 - MinusLogProbMetric: 389.2069 - val_loss: 391.6125 - val_MinusLogProbMetric: 391.6125 - lr: 1.0417e-05 - 22s/epoch - 112ms/step
Epoch 983/1000
2023-09-10 17:29:53.143 
Epoch 983/1000 
	 loss: 389.2084, MinusLogProbMetric: 389.2084, val_loss: 391.6993, val_MinusLogProbMetric: 391.6993

Epoch 983: val_loss did not improve from 391.47543
196/196 - 26s - loss: 389.2084 - MinusLogProbMetric: 389.2084 - val_loss: 391.6993 - val_MinusLogProbMetric: 391.6993 - lr: 1.0417e-05 - 26s/epoch - 133ms/step
Epoch 984/1000
2023-09-10 17:30:15.707 
Epoch 984/1000 
	 loss: 389.2130, MinusLogProbMetric: 389.2130, val_loss: 391.5321, val_MinusLogProbMetric: 391.5321

Epoch 984: val_loss did not improve from 391.47543
196/196 - 23s - loss: 389.2130 - MinusLogProbMetric: 389.2130 - val_loss: 391.5321 - val_MinusLogProbMetric: 391.5321 - lr: 1.0417e-05 - 23s/epoch - 115ms/step
Epoch 985/1000
2023-09-10 17:30:40.104 
Epoch 985/1000 
	 loss: 389.2120, MinusLogProbMetric: 389.2120, val_loss: 391.5292, val_MinusLogProbMetric: 391.5292

Epoch 985: val_loss did not improve from 391.47543
196/196 - 24s - loss: 389.2120 - MinusLogProbMetric: 389.2120 - val_loss: 391.5292 - val_MinusLogProbMetric: 391.5292 - lr: 1.0417e-05 - 24s/epoch - 124ms/step
Epoch 986/1000
2023-09-10 17:31:04.217 
Epoch 986/1000 
	 loss: 389.2027, MinusLogProbMetric: 389.2027, val_loss: 391.6153, val_MinusLogProbMetric: 391.6153

Epoch 986: val_loss did not improve from 391.47543
196/196 - 24s - loss: 389.2027 - MinusLogProbMetric: 389.2027 - val_loss: 391.6153 - val_MinusLogProbMetric: 391.6153 - lr: 1.0417e-05 - 24s/epoch - 123ms/step
Epoch 987/1000
2023-09-10 17:31:27.525 
Epoch 987/1000 
	 loss: 389.2029, MinusLogProbMetric: 389.2029, val_loss: 391.5401, val_MinusLogProbMetric: 391.5401

Epoch 987: val_loss did not improve from 391.47543
196/196 - 23s - loss: 389.2029 - MinusLogProbMetric: 389.2029 - val_loss: 391.5401 - val_MinusLogProbMetric: 391.5401 - lr: 1.0417e-05 - 23s/epoch - 119ms/step
Epoch 988/1000
2023-09-10 17:31:52.108 
Epoch 988/1000 
	 loss: 389.2078, MinusLogProbMetric: 389.2078, val_loss: 391.5380, val_MinusLogProbMetric: 391.5380

Epoch 988: val_loss did not improve from 391.47543
196/196 - 25s - loss: 389.2078 - MinusLogProbMetric: 389.2078 - val_loss: 391.5380 - val_MinusLogProbMetric: 391.5380 - lr: 1.0417e-05 - 25s/epoch - 125ms/step
Epoch 989/1000
2023-09-10 17:32:13.522 
Epoch 989/1000 
	 loss: 389.2065, MinusLogProbMetric: 389.2065, val_loss: 391.4962, val_MinusLogProbMetric: 391.4962

Epoch 989: val_loss did not improve from 391.47543
196/196 - 21s - loss: 389.2065 - MinusLogProbMetric: 389.2065 - val_loss: 391.4962 - val_MinusLogProbMetric: 391.4962 - lr: 1.0417e-05 - 21s/epoch - 109ms/step
Epoch 990/1000
2023-09-10 17:32:33.930 
Epoch 990/1000 
	 loss: 389.2101, MinusLogProbMetric: 389.2101, val_loss: 391.5013, val_MinusLogProbMetric: 391.5013

Epoch 990: val_loss did not improve from 391.47543
196/196 - 20s - loss: 389.2101 - MinusLogProbMetric: 389.2101 - val_loss: 391.5013 - val_MinusLogProbMetric: 391.5013 - lr: 1.0417e-05 - 20s/epoch - 104ms/step
Epoch 991/1000
2023-09-10 17:33:01.881 
Epoch 991/1000 
	 loss: 389.2102, MinusLogProbMetric: 389.2102, val_loss: 391.6278, val_MinusLogProbMetric: 391.6278

Epoch 991: val_loss did not improve from 391.47543
196/196 - 28s - loss: 389.2102 - MinusLogProbMetric: 389.2102 - val_loss: 391.6278 - val_MinusLogProbMetric: 391.6278 - lr: 1.0417e-05 - 28s/epoch - 142ms/step
Epoch 992/1000
2023-09-10 17:33:26.869 
Epoch 992/1000 
	 loss: 389.1967, MinusLogProbMetric: 389.1967, val_loss: 391.5190, val_MinusLogProbMetric: 391.5190

Epoch 992: val_loss did not improve from 391.47543
196/196 - 25s - loss: 389.1967 - MinusLogProbMetric: 389.1967 - val_loss: 391.5190 - val_MinusLogProbMetric: 391.5190 - lr: 1.0417e-05 - 25s/epoch - 127ms/step
Epoch 993/1000
2023-09-10 17:33:47.127 
Epoch 993/1000 
	 loss: 389.2069, MinusLogProbMetric: 389.2069, val_loss: 391.6334, val_MinusLogProbMetric: 391.6334

Epoch 993: val_loss did not improve from 391.47543
196/196 - 20s - loss: 389.2069 - MinusLogProbMetric: 389.2069 - val_loss: 391.6334 - val_MinusLogProbMetric: 391.6334 - lr: 1.0417e-05 - 20s/epoch - 103ms/step
Epoch 994/1000
2023-09-10 17:34:06.943 
Epoch 994/1000 
	 loss: 389.2004, MinusLogProbMetric: 389.2004, val_loss: 391.5423, val_MinusLogProbMetric: 391.5423

Epoch 994: val_loss did not improve from 391.47543
196/196 - 20s - loss: 389.2004 - MinusLogProbMetric: 389.2004 - val_loss: 391.5423 - val_MinusLogProbMetric: 391.5423 - lr: 1.0417e-05 - 20s/epoch - 101ms/step
Epoch 995/1000
2023-09-10 17:34:23.855 
Epoch 995/1000 
	 loss: 389.1984, MinusLogProbMetric: 389.1984, val_loss: 391.5559, val_MinusLogProbMetric: 391.5559

Epoch 995: val_loss did not improve from 391.47543
196/196 - 17s - loss: 389.1984 - MinusLogProbMetric: 389.1984 - val_loss: 391.5559 - val_MinusLogProbMetric: 391.5559 - lr: 1.0417e-05 - 17s/epoch - 86ms/step
Epoch 996/1000
2023-09-10 17:34:44.801 
Epoch 996/1000 
	 loss: 389.1985, MinusLogProbMetric: 389.1985, val_loss: 391.7034, val_MinusLogProbMetric: 391.7034

Epoch 996: val_loss did not improve from 391.47543
196/196 - 21s - loss: 389.1985 - MinusLogProbMetric: 389.1985 - val_loss: 391.7034 - val_MinusLogProbMetric: 391.7034 - lr: 1.0417e-05 - 21s/epoch - 107ms/step
Epoch 997/1000
2023-09-10 17:35:09.173 
Epoch 997/1000 
	 loss: 389.2065, MinusLogProbMetric: 389.2065, val_loss: 391.5811, val_MinusLogProbMetric: 391.5811

Epoch 997: val_loss did not improve from 391.47543
196/196 - 24s - loss: 389.2065 - MinusLogProbMetric: 389.2065 - val_loss: 391.5811 - val_MinusLogProbMetric: 391.5811 - lr: 1.0417e-05 - 24s/epoch - 124ms/step
Epoch 998/1000
2023-09-10 17:35:33.280 
Epoch 998/1000 
	 loss: 389.1891, MinusLogProbMetric: 389.1891, val_loss: 391.5956, val_MinusLogProbMetric: 391.5956

Epoch 998: val_loss did not improve from 391.47543
196/196 - 24s - loss: 389.1891 - MinusLogProbMetric: 389.1891 - val_loss: 391.5956 - val_MinusLogProbMetric: 391.5956 - lr: 1.0417e-05 - 24s/epoch - 123ms/step
Epoch 999/1000
2023-09-10 17:35:53.467 
Epoch 999/1000 
	 loss: 389.1999, MinusLogProbMetric: 389.1999, val_loss: 391.5368, val_MinusLogProbMetric: 391.5368

Epoch 999: val_loss did not improve from 391.47543
196/196 - 20s - loss: 389.1999 - MinusLogProbMetric: 389.1999 - val_loss: 391.5368 - val_MinusLogProbMetric: 391.5368 - lr: 1.0417e-05 - 20s/epoch - 103ms/step
Epoch 1000/1000
2023-09-10 17:36:16.990 
Epoch 1000/1000 
	 loss: 389.1850, MinusLogProbMetric: 389.1850, val_loss: 391.5968, val_MinusLogProbMetric: 391.5968

Epoch 1000: val_loss did not improve from 391.47543
196/196 - 24s - loss: 389.1850 - MinusLogProbMetric: 389.1850 - val_loss: 391.5968 - val_MinusLogProbMetric: 391.5968 - lr: 1.0417e-05 - 24s/epoch - 120ms/step
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.
Parsing input distribution...
Input distribution is a tfp.distributions.Distribution object.

------------------------------------------
Starting LR metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
LR metric calculation completed in 2793.498417344992 seconds.

------------------------------------------
Starting KS tests calculation...
Running TF KS tests...
niter = 10
batch_size = 100000
The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.
The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.
KS tests calculation completed in 3190.166705624084 seconds.

------------------------------------------
Starting SWD metric calculation...
Running TF SWD calculation...
niter = 10
batch_size = 100000
SWD metric calculation completed in 2769.85759868694 seconds.

------------------------------------------
Starting FN metric calculation...
Running TF FN calculation...
niter = 10
batch_size = 100000
FN metric calculation completed in 3109.6025004979456 seconds.
Training succeeded with seed 520.
Model trained in 14028.68 s.

===========
Computing predictions
===========

Computing metrics...
Metrics computed in 12049.40 s.
                ===========
                print("===========
Failed to plot
===========
")
                Exception type: ValueError
                Exception message: Number of rows must be a positive integer, not 0
                Stack trace: ['File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py , Line : 470, Func.Name : prediction_function, Message : Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/Plotters.py , Line : 156, Func.Name : cornerplotter, Message : figure=corner.corner(target_samples,color=\'red\',bins=n_bins,labels=[r"%s" % s for s in labels],normalize1d=True)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/../../../code/corner.py , Line : 235, Func.Name : corner, Message : fig, axes = pl.subplots(K, K, figsize=(dim, dim))', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/pyplot.py , Line : 1502, Func.Name : subplots, Message : axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 905, Func.Name : subplots, Message : gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/figure.py , Line : 1527, Func.Name : add_gridspec, Message : gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 379, Func.Name : __init__, Message : super().__init__(nrows, ncols,', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/matplotlib/gridspec.py , Line : 49, Func.Name : __init__, Message : raise ValueError(']
                ===========

results.txt saved
results.json saved
Results log saved
Model predictions computed in 12050.32 s.
===========
Run 338/360 done in 26475.98 s.
===========

Directory ../../results/MAFN_new/run_339/ already exists.
Skipping it.
===========
Run 339/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_340/ already exists.
Skipping it.
===========
Run 340/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_341/ already exists.
Skipping it.
===========
Run 341/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_342/ already exists.
Skipping it.
===========
Run 342/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_343/ already exists.
Skipping it.
===========
Run 343/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_344/ already exists.
Skipping it.
===========
Run 344/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_345/ already exists.
Skipping it.
===========
Run 345/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_346/ already exists.
Skipping it.
===========
Run 346/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_347/ already exists.
Skipping it.
===========
Run 347/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_348/ already exists.
Skipping it.
===========
Run 348/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_349/ already exists.
Skipping it.
===========
Run 349/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_350/ already exists.
Skipping it.
===========
Run 350/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_351/ already exists.
Skipping it.
===========
Run 351/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_352/ already exists.
Skipping it.
===========
Run 352/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_353/ already exists.
Skipping it.
===========
Run 353/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_354/ already exists.
Skipping it.
===========
Run 354/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_355/ already exists.
Skipping it.
===========
Run 355/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_356/ already exists.
Skipping it.
===========
Run 356/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_357/ already exists.
Skipping it.
===========
Run 357/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_358/ already exists.
Skipping it.
===========
Run 358/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_359/ already exists.
Skipping it.
===========
Run 359/360 already exists. Skipping it.
===========

Directory ../../results/MAFN_new/run_360/ already exists.
Skipping it.
===========
Run 360/360 already exists. Skipping it.
===========

Traceback (most recent call last):
  File "/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MAFN/c_Main_MAFN.py", line 741, in <module>
    results_frame: pd.DataFrame = pd.DataFrame(dict_copy)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/frame.py", line 709, in __init__
    mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 481, in dict_to_mgr
    return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 115, in arrays_to_mgr
    index = _extract_index(arrays)
  File "/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/pandas/core/internals/construction.py", line 655, in _extract_index
    raise ValueError("All arrays must be of the same length")
ValueError: All arrays must be of the same length
