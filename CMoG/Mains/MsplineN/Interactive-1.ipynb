{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to tf2_12 (Python 3.10.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-11 14:37:56.151174: Importing os...\n",
      "2024-01-11 14:37:56.151333: Importing sys...\n",
      "2024-01-11 14:37:56.151409: Importing and initializing argparse...\n",
      "Visible devices: [0, 1, 2, 3]\n",
      "2024-01-11 14:37:56.151724: Importing timer from timeit...\n",
      "2024-01-11 14:37:56.151811: Setting env variables for tf import (only device [0, 1, 2, 3] will be available)...\n",
      "2024-01-11 14:37:56.151968: Importing numpy...\n",
      "2024-01-11 14:37:56.230924: Importing pandas...\n",
      "2024-01-11 14:37:56.528225: Importing shutil...\n",
      "2024-01-11 14:37:56.528369: Importing subprocess...\n",
      "2024-01-11 14:37:56.528431: Importing tensorflow...\n",
      "Tensorflow version: 2.12.0\n",
      "2024-01-11 14:37:58.842217: Importing tensorflow_probability...\n",
      "Tensorflow probability version: 0.20.1\n",
      "2024-01-11 14:37:59.222099: Importing textwrap...\n",
      "2024-01-11 14:37:59.222201: Importing timeit...\n",
      "2024-01-11 14:37:59.222273: Importing traceback...\n",
      "2024-01-11 14:37:59.222332: Importing typing...\n",
      "2024-01-11 14:37:59.222406: Setting tf configs...\n",
      "2024-01-11 14:37:59.825236: Importing custom module...\n",
      "Successfully loaded GPU model: NVIDIA A40\n",
      "2024-01-11 14:38:00.664727: All modues imported successfully.\n",
      "Directory ../../results/MsplineN_new/ already exists.\n",
      "Directory ../../results/MsplineN_new/run_1/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 1/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_2/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 2/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_3/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 3/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_4/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 4/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_5/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 5/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_6/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 6/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_7/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 7/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_8/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 8/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_9/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 9/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_10/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 10/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_11/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 11/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_12/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 12/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_13/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 13/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_14/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 14/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_15/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 15/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_16/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 16/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_17/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 17/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_18/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 18/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_19/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 19/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_20/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 20/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_21/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 21/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_22/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 22/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_23/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 23/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_24/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 24/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_25/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 25/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_26/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 26/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_27/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 27/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_28/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 28/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_29/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 29/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_30/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 30/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_31/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 31/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_32/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 32/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_33/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 33/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_34/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 34/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_35/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 35/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_36/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 36/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_37/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 37/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_38/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 38/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_39/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 39/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_40/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 40/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_41/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 41/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_42/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 42/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_43/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 43/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_44/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 44/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_45/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 45/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_46/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 46/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_47/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 47/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_48/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 48/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_49/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 49/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_50/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 50/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_51/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 51/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_52/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 52/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_53/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 53/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_54/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 54/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_55/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 55/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_56/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 56/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_57/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 57/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_58/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 58/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_59/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 59/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_60/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 60/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_61/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 61/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_62/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 62/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_63/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 63/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_64/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 64/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_65/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 65/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_66/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 66/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_67/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 67/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_68/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 68/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_69/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 69/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_70/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 70/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_71/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 71/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_72/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 72/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_73/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 73/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_74/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 74/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_75/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 75/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_76/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 76/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_77/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 77/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_78/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 78/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_79/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 79/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_80/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 80/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_81/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 81/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_82/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 82/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_83/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 83/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_84/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 84/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_85/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 85/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_86/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 86/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_87/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 87/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_88/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 88/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_89/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 89/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_90/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 90/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_91/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 91/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_92/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 92/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_93/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 93/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_94/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 94/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_95/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 95/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_96/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 96/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_97/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 97/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_98/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 98/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_99/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 99/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_100/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 100/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_101/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 101/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_102/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 102/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_103/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 103/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_104/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 104/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_105/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 105/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_106/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 106/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_107/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 107/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_108/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 108/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_109/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 109/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_110/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 110/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_111/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 111/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_112/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 112/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_113/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 113/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_114/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 114/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_115/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 115/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_116/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 116/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_117/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 117/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_118/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 118/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_119/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 119/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_120/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 120/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_121/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 121/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_122/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 122/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_123/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 123/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_124/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 124/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_125/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 125/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_126/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 126/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_127/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 127/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_128/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 128/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_129/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 129/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_130/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 130/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_131/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 131/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_132/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 132/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_133/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 133/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_134/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 134/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_135/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 135/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_136/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 136/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_137/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 137/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_138/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 138/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_139/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 139/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_140/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 140/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_141/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 141/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_142/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 142/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_143/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 143/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_144/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 144/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_145/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 145/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_146/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 146/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_147/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 147/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_148/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 148/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_149/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 149/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_150/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 150/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_151/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 151/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_152/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 152/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_153/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 153/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_154/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 154/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_155/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 155/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_156/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 156/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_157/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 157/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_158/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 158/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_159/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 159/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_160/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 160/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_161/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 161/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_162/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 162/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_163/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 163/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_164/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 164/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_165/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 165/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_166/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 166/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_167/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 167/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_168/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 168/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_169/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 169/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_170/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 170/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_171/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 171/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_172/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 172/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_173/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 173/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_174/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 174/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_175/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 175/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_176/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 176/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_177/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 177/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_178/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 178/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_179/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 179/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_180/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 180/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_181/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 181/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_182/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 182/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_183/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 183/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_184/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 184/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_185/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 185/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_186/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 186/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_187/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 187/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_188/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 188/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_189/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 189/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_190/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 190/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_191/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 191/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_192/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 192/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_193/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 193/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_194/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 194/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_195/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 195/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_196/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 196/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_197/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 197/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_198/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 198/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_199/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 199/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_200/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 200/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_201/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 201/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_202/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 202/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_203/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 203/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_204/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 204/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_205/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 205/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_206/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 206/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_207/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 207/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_208/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 208/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_209/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 209/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_210/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 210/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_211/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 211/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_212/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 212/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_213/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 213/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_214/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 214/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_215/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 215/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_216/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 216/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_217/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 217/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_218/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 218/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_219/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 219/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_220/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 220/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_221/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 221/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_222/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 222/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_223/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 223/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_224/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 224/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_225/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 225/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_226/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 226/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_227/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 227/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_228/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 228/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_229/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 229/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_230/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 230/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_231/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 231/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_232/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 232/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_233/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 233/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_234/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 234/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "===========\n",
      "Generating train data for run 235.\n",
      "===========\n",
      "Train data generated in 0.24 s.\n",
      "\n",
      "Building Trainer NFObject.\n",
      "\n",
      "\n",
      "--------------- Debub info ---------------\n",
      "Initializing Trainer with following parameters:\n",
      "base_distribution: tfp.distributions.Sample(\"SampleNormal\", batch_shape=[], event_shape=[100], dtype=float32)\n",
      "flow: tfp.bijectors._Chain(\"chain_of_MAFspline_of_permute_of_MAFspline\", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])\n",
      "x_data_train shape: (100000, 100)\n",
      "y_data_train shape: (100000, 0)\n",
      "io_kwargs: {'results_path': '../../results/MsplineN_new/run_235/', 'load_weights': True, 'load_results': True}\n",
      "data_kwargs: {'seed': 926}\n",
      "compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}\n",
      "callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_235/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]\n",
      "fit_kwargs: {'batch_size': 512, 'epochs': 10, 'validation_data': (array([[ 2.927723 ,  7.40039  ,  4.4594426, ...,  8.382537 , 10.012399 ,\n",
      "         8.527864 ],\n",
      "       [ 3.748757 ,  6.6037393,  3.8607926, ...,  8.967738 ,  9.710755 ,\n",
      "         8.6567335],\n",
      "       [ 7.1642637,  2.498219 ,  7.274355 , ...,  3.100315 ,  0.8821282,\n",
      "         4.6081243],\n",
      "       ...,\n",
      "       [ 3.6789045,  7.033133 ,  3.833719 , ...,  8.92615  ,  9.22691  ,\n",
      "         8.690898 ],\n",
      "       [ 2.7956169,  6.259902 ,  3.888586 , ...,  8.543673 ,  9.653591 ,\n",
      "        10.1968355],\n",
      "       [ 2.8517566,  6.793651 ,  3.5811145, ...,  8.554237 ,  9.502735 ,\n",
      "         8.024157 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}\n",
      "\n",
      "--------------- Debub info ---------------\n",
      "Defined attributes:\n",
      "self.base_dist: tfp.distributions.Sample(\"SampleNormal\", batch_shape=[], event_shape=[100], dtype=float32)\n",
      "self.flow: tfp.bijectors._Chain(\"chain_of_MAFspline_of_permute_of_MAFspline\", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])\n",
      "self.nf_dist: tfp.distributions._TransformedDistribution(\"chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal\", batch_shape=[], event_shape=[100], dtype=float32)\n",
      "self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_235/', 'load_weights': True, 'load_results': True}\n",
      "self.results_path: ../../results/MsplineN_new/run_235\n",
      "self.data_kwargs: {'seed': 926}\n",
      "self.x_data: [[ 2.897161    6.534043    4.435944   ...  9.075178    9.982332\n",
      "   7.9316616 ]\n",
      " [ 3.1196878   7.0884347   4.384429   ...  8.766316    9.813535\n",
      "  10.410667  ]\n",
      " [ 6.8242903   2.318904    7.2225437  ...  2.1615176   0.4732949\n",
      "   4.4273376 ]\n",
      " ...\n",
      " [ 7.16177     4.388022    7.4901805  ...  2.5969949   0.33093375\n",
      "   5.1520786 ]\n",
      " [ 6.586814    2.0034654   7.4105372  ...  2.7165298   0.646716\n",
      "   3.7854583 ]\n",
      " [ 5.588845    7.65905     6.214874   ...  0.6076801   8.275181\n",
      "   0.14240426]]\n",
      "self.y_data: []\n",
      "self.ndims: 100\n",
      "Model defined.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " log_prob_layer (LogProbLaye  (None,)                  994904    \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 994,904\n",
      "Trainable params: 994,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model summary:  None\n",
      "self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description=\"created by layer 'log_prob_layer'\")\n",
      "self.model: <keras.engine.functional.Functional object at 0x7f468002fd30>\n",
      "self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}\n",
      "optimizer: <keras.optimizers.adam.Adam object at 0x7f45d0388880>\n",
      "type(optimizer): <class 'keras.optimizers.adam.Adam'>\n",
      "self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}\n",
      "self.optimizer: <keras.optimizers.adam.Adam object at 0x7f45d0388880>\n",
      "self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}\n",
      "self.loss: <Trainer.MinusLogProbLoss object at 0x7f45d0389030>\n",
      "self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]\n",
      "self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f45d0389660>]\n",
      "self.compile_kwargs: {}\n",
      "self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]\n",
      "self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f45d0389bd0>, <keras.callbacks.ModelCheckpoint object at 0x7f45d0389d20>, <keras.callbacks.EarlyStopping object at 0x7f45d0389f30>, <keras.callbacks.ReduceLROnPlateau object at 0x7f45d0389f60>, <keras.callbacks.TerminateOnNaN object at 0x7f45d0389c90>]\n",
      "self.fit_kwargs: {'batch_size': 512, 'epochs': 10, 'validation_data': (array([[ 2.927723 ,  7.40039  ,  4.4594426, ...,  8.382537 , 10.012399 ,\n",
      "         8.527864 ],\n",
      "       [ 3.748757 ,  6.6037393,  3.8607926, ...,  8.967738 ,  9.710755 ,\n",
      "         8.6567335],\n",
      "       [ 7.1642637,  2.498219 ,  7.274355 , ...,  3.100315 ,  0.8821282,\n",
      "         4.6081243],\n",
      "       ...,\n",
      "       [ 3.6789045,  7.033133 ,  3.833719 , ...,  8.92615  ,  9.22691  ,\n",
      "         8.690898 ],\n",
      "       [ 2.7956169,  6.259902 ,  3.888586 , ...,  8.543673 ,  9.653591 ,\n",
      "        10.1968355],\n",
      "       [ 2.8517566,  6.793651 ,  3.5811145, ...,  8.554237 ,  9.502735 ,\n",
      "         8.024157 ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}\n",
      "self.is_compiled: False\n",
      "self.training_time: 0.0\n",
      "self.history: {}\n",
      "Model successfully compiled.\n",
      "No weights found in ../../results/MsplineN_new/run_235/weights/best_weights.h5. Training from scratch.\n",
      "No history found. Generating new history.\n",
      "===============\n",
      "Running 235/360 with hyperparameters:\n",
      "timestamp = 2024-01-11 14:38:05.660125\n",
      "ndims = 100\n",
      "seed_train = 926\n",
      "nsamples_train = 100000\n",
      "nsamples_val = 30000\n",
      "nsamples_test = 100000\n",
      "bijector = MsplineN\n",
      "nbijectors = 2\n",
      "spline_knots = 12\n",
      "range_min = -16\n",
      "hidden_layers = 128-128-128\n",
      "trainable_parameters = 994904\n",
      "epochs_input = 10\n",
      "batch_size = 512\n",
      "activation = relu\n",
      "training_device = NVIDIA A40\n",
      "===============\n",
      "\n",
      "Training model with initial learning rate 0.001...\n",
      "Train first sample: [ 2.897161    6.534043    4.435944    2.0167708   0.76581025 -0.41404212\n",
      "  6.5563097   4.585651    5.459547    9.5439205   9.760288    2.033808\n",
      "  8.196959    2.0907156  -0.1036547   6.7959566   3.3730316   4.214541\n",
      "  5.6409063   8.944769    6.184706    8.709543    2.697753    9.58591\n",
      "  1.8438077   9.485045    6.244172    1.4593337   9.492012    7.4136834\n",
      "  2.5470083   2.4741476   6.0162086   0.34030312  1.7608478   4.1857457\n",
      "  3.586665    4.903299    2.8457909   4.5210953   8.644069    0.41436762\n",
      "  5.7846313   2.1569214   5.6997633   3.9680712   6.089412    3.2219284\n",
      "  1.8645954   4.9286904   3.3696916   9.425047    6.778146    7.3377466\n",
      "  8.553487    0.71973974  5.6847825   5.7251053   8.456307    2.1439555\n",
      "  2.2539096   1.1093227   0.14606133  7.90942     6.787351    7.9762983\n",
      "  2.522771    5.1720147   0.36467698  4.7447834   9.287053    8.882705\n",
      "  3.40204     9.946664    0.94367206  9.900721    9.411645    7.757124\n",
      "  6.1314373   7.9882326   2.9185889   9.392013    6.52124     0.11681265\n",
      "  3.5914495   1.5088241   9.763006    4.7435894   5.040696    6.034357\n",
      "  3.4570153   0.48393005  9.1817875   1.9410974   4.7118406   2.7683043\n",
      "  0.5505208   9.075178    9.982332    7.9316616 ]\n",
      "Epoch 1/10\n",
      "2024-01-11 14:38:39.558 \n",
      "Epoch 1/10 \n",
      "\t loss: 157.4606, MinusLogProbMetric: 157.4606, val_loss: 55.0267, val_MinusLogProbMetric: 55.0267\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 55.02674, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 34s - loss: 157.4606 - MinusLogProbMetric: 157.4606 - val_loss: 55.0267 - val_MinusLogProbMetric: 55.0267 - lr: 0.0010 - 34s/epoch - 173ms/step\n",
      "Epoch 2/10\n",
      "2024-01-11 14:38:50.427 \n",
      "Epoch 2/10 \n",
      "\t loss: 50.3810, MinusLogProbMetric: 50.3810, val_loss: 49.5979, val_MinusLogProbMetric: 49.5979\n",
      "\n",
      "Epoch 2: val_loss improved from 55.02674 to 49.59787, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 50.3810 - MinusLogProbMetric: 50.3810 - val_loss: 49.5979 - val_MinusLogProbMetric: 49.5979 - lr: 0.0010 - 11s/epoch - 55ms/step\n",
      "Epoch 3/10\n",
      "2024-01-11 14:39:01.390 \n",
      "Epoch 3/10 \n",
      "\t loss: 46.1409, MinusLogProbMetric: 46.1409, val_loss: 44.8331, val_MinusLogProbMetric: 44.8331\n",
      "\n",
      "Epoch 3: val_loss improved from 49.59787 to 44.83310, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 46.1409 - MinusLogProbMetric: 46.1409 - val_loss: 44.8331 - val_MinusLogProbMetric: 44.8331 - lr: 0.0010 - 11s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "2024-01-11 14:39:11.960 \n",
      "Epoch 4/10 \n",
      "\t loss: 44.5165, MinusLogProbMetric: 44.5165, val_loss: 44.5587, val_MinusLogProbMetric: 44.5587\n",
      "\n",
      "Epoch 4: val_loss improved from 44.83310 to 44.55874, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 44.5165 - MinusLogProbMetric: 44.5165 - val_loss: 44.5587 - val_MinusLogProbMetric: 44.5587 - lr: 0.0010 - 11s/epoch - 54ms/step\n",
      "Epoch 5/10\n",
      "2024-01-11 14:39:22.971 \n",
      "Epoch 5/10 \n",
      "\t loss: 43.5635, MinusLogProbMetric: 43.5635, val_loss: 43.3754, val_MinusLogProbMetric: 43.3754\n",
      "\n",
      "Epoch 5: val_loss improved from 44.55874 to 43.37545, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 43.5635 - MinusLogProbMetric: 43.5635 - val_loss: 43.3754 - val_MinusLogProbMetric: 43.3754 - lr: 0.0010 - 11s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "2024-01-11 14:39:33.936 \n",
      "Epoch 6/10 \n",
      "\t loss: 42.8698, MinusLogProbMetric: 42.8698, val_loss: 42.5541, val_MinusLogProbMetric: 42.5541\n",
      "\n",
      "Epoch 6: val_loss improved from 43.37545 to 42.55405, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 42.8698 - MinusLogProbMetric: 42.8698 - val_loss: 42.5541 - val_MinusLogProbMetric: 42.5541 - lr: 0.0010 - 11s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "2024-01-11 14:39:45.030 \n",
      "Epoch 7/10 \n",
      "\t loss: 42.7440, MinusLogProbMetric: 42.7440, val_loss: 43.6429, val_MinusLogProbMetric: 43.6429\n",
      "\n",
      "Epoch 7: val_loss did not improve from 42.55405\n",
      "196/196 - 11s - loss: 42.7440 - MinusLogProbMetric: 42.7440 - val_loss: 43.6429 - val_MinusLogProbMetric: 43.6429 - lr: 0.0010 - 11s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "2024-01-11 14:39:55.890 \n",
      "Epoch 8/10 \n",
      "\t loss: 42.4687, MinusLogProbMetric: 42.4687, val_loss: 42.1787, val_MinusLogProbMetric: 42.1787\n",
      "\n",
      "Epoch 8: val_loss improved from 42.55405 to 42.17871, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 42.4687 - MinusLogProbMetric: 42.4687 - val_loss: 42.1787 - val_MinusLogProbMetric: 42.1787 - lr: 0.0010 - 11s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "2024-01-11 14:40:06.853 \n",
      "Epoch 9/10 \n",
      "\t loss: 42.1142, MinusLogProbMetric: 42.1142, val_loss: 42.1622, val_MinusLogProbMetric: 42.1622\n",
      "\n",
      "Epoch 9: val_loss improved from 42.17871 to 42.16220, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 42.1142 - MinusLogProbMetric: 42.1142 - val_loss: 42.1622 - val_MinusLogProbMetric: 42.1622 - lr: 0.0010 - 11s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "2024-01-11 14:40:17.719 \n",
      "Epoch 10/10 \n",
      "\t loss: 41.8679, MinusLogProbMetric: 41.8679, val_loss: 41.6598, val_MinusLogProbMetric: 41.6598\n",
      "\n",
      "Epoch 10: val_loss improved from 42.16220 to 41.65979, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_235/weights/best_weights.h5\n",
      "196/196 - 11s - loss: 41.8679 - MinusLogProbMetric: 41.8679 - val_loss: 41.6598 - val_MinusLogProbMetric: 41.6598 - lr: 0.0010 - 11s/epoch - 55ms/step\n",
      "Training succeeded with seed 926.\n",
      "Model trained in 132.20 s.\n",
      "\n",
      "===========\n",
      "Computing predictions\n",
      "===========\n",
      "\n",
      "Computing metrics...\n",
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n",
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n",
      "Metrics computed in 5.22 s.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots done in 98.59 s.\n",
      "results.txt saved\n",
      "results.json saved\n",
      "Results log saved\n",
      "Model predictions computed in 103.81 s.\n",
      "===========\n",
      "Run 235/360 done in 237.43 s.\n",
      "===========\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Interrupted after one run.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN_teogpu02.py\u001b[0m in \u001b[0;36mline 628\n\u001b[1;32m    <a href='file:///home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN_teogpu02.py?line=625'>626</a>\u001b[0m \u001b[39mfor\u001b[39;00m hidden_layers \u001b[39min\u001b[39;00m hidden_layers_list:\n\u001b[1;32m    <a href='file:///home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN_teogpu02.py?line=626'>627</a>\u001b[0m     \u001b[39mif\u001b[39;00m run \u001b[39m>\u001b[39m run_max:\n\u001b[0;32m--> <a href='file:///home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN_teogpu02.py?line=627'>628</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInterrupted after one run.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN_teogpu02.py?line=628'>629</a>\u001b[0m     start_run: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m timer()\n\u001b[1;32m    <a href='file:///home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/c_Main_MsplineN_teogpu02.py?line=629'>630</a>\u001b[0m     hllabel: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(e) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m hidden_layers)\n",
      "\u001b[0;31mException\u001b[0m: Interrupted after one run."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################################################\n",
    "######################################### Initialize #########################################\n",
    "##############################################################################################\n",
    "\n",
    "visible_devices = [0,1,2,3]\n",
    "import datetime\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing os...\")\n",
    "import os\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing sys...\")\n",
    "import sys\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing and initializing argparse...\")\n",
    "if not any(\"ipykernel\" in arg for arg in sys.argv):\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-v\", \"--visible_devices\", help=\"Set visible devices\", nargs='*', type=list, default=visible_devices)\n",
    "    args = parser.parse_args()\n",
    "    visible_devices = args.visible_devices if args.visible_devices else visible_devices\n",
    "    if len(visible_devices) == 0:\n",
    "        visible_devices = int(visible_devices)\n",
    "    elif len(visible_devices) == 1:\n",
    "        if len(visible_devices[0]) == 0:\n",
    "            visible_devices = int(visible_devices[0])\n",
    "        else:\n",
    "            visible_devices = [int(i) for i in visible_devices[0]]\n",
    "    else:\n",
    "        visible_devices = [int(i) for i in visible_devices]\n",
    "print(\"Visible devices:\", visible_devices)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing timer from timeit...\")\n",
    "from timeit import default_timer as timer\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Setting env variables for tf import (only device\", visible_devices, \"will be available)...\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(i) for i in visible_devices])\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2'\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing numpy...\")\n",
    "import numpy as np\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing pandas...\")\n",
    "import pandas as pd\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing shutil...\")\n",
    "import shutil\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing subprocess...\")\n",
    "import subprocess\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing tensorflow...\")\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing tensorflow_probability...\")\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "print(\"Tensorflow probability version:\", tfp.__version__)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing textwrap...\")\n",
    "import textwrap\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing timeit...\")\n",
    "from timeit import default_timer as timer\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing traceback...\")\n",
    "import traceback\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing typing...\")\n",
    "from typing import List, Tuple, Dict, Union, Optional, Any\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Setting tf configs...\")\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu_device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_device, True)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing custom module...\")\n",
    "\n",
    "sys.path.append('../../../code')\n",
    "import Bijectors, Distributions, MixtureDistributions, Plotters, Trainer, Utils # type: ignore\n",
    "import GenerativeModelsMetrics as GMetrics # type: ignore\n",
    "\n",
    "def get_gpu_info() -> Optional[List[str]]:\n",
    "    try:\n",
    "        gpu_info: str = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=gpu_name\", \"--format=csv,noheader\"]).decode('utf-8')\n",
    "        return gpu_info.strip().split('\\n')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "gpu_models: Optional[List[str]] = get_gpu_info()\n",
    "if gpu_models:\n",
    "    training_device: str = gpu_models[0]\n",
    "    print(\"Successfully loaded GPU model: {}\".format(training_device))\n",
    "else:\n",
    "    training_device = 'undetermined'\n",
    "    print(\"Failed to load GPU model. Defaulting to 'undetermined'.\")\n",
    "    \n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"All modues imported successfully.\")\n",
    "\n",
    "##############################################################################################\n",
    "####################################### Helper functions #####################################\n",
    "##############################################################################################\n",
    "\n",
    "def MixtureGaussian(ncomp: int,\n",
    "                    ndims: int,\n",
    "                    seed: int = 0) -> tfp.distributions.Mixture:\n",
    "    targ_dist: tfp.distributions.Mixture = MixtureDistributions.MixMultiNormal1(ncomp,ndims,seed=seed)\n",
    "    return targ_dist\n",
    "\n",
    "def get_io_kwargs(path_to_results: str) -> Dict[str,Any]:\n",
    "    return {'results_path': path_to_results,\n",
    "            'load_weights': True,\n",
    "            'load_results': True}\n",
    "    \n",
    "def get_data_kwargs(seed: int = 0) -> Dict[str,Any]:\n",
    "    return {'seed': seed}\n",
    "\n",
    "def get_compiler_kwargs(lr: float,\n",
    "                        ignore_nans: bool,\n",
    "                        nan_threshold: float\n",
    "                       ) -> Dict[str,Any]:\n",
    "    compiler_kwargs = {'optimizer': {'class_name': 'Custom>Adam', # this gives the new Adam optimizer\n",
    "    #compiler_kwargs = {'optimizer': {'class_name': 'Adam', # this gives the new Adam optimizer\n",
    "                                     'config': {'learning_rate': lr,\n",
    "                                                'beta_1': 0.9,\n",
    "                                                'beta_2': 0.999,\n",
    "                                                'epsilon': 1e-07,\n",
    "                                                'amsgrad': True}},\n",
    "                       'metrics': [{'class_name': 'MinusLogProbMetric',\n",
    "                                    'config': {'ignore_nans': ignore_nans, \n",
    "                                               'debug_print_mode': False}}],\n",
    "                       'loss': {'class_name': 'MinusLogProbLoss', \n",
    "                                'config': {'name': \"MLP\", \n",
    "                                           'ignore_nans': ignore_nans, \n",
    "                                           'nan_threshold': nan_threshold, \n",
    "                                           'debug_print_mode': False}}}\n",
    "    return compiler_kwargs\n",
    "    \n",
    "def get_callbacks_kwargs(checkpoint_path: str,\n",
    "                         es_min_delta: float,\n",
    "                         es_patience: int,\n",
    "                         lr_reduce_factor: float,\n",
    "                         lr_min_delta: float,\n",
    "                         lr_patience: int,\n",
    "                         min_lr: float\n",
    "                         ) -> List[Dict[str,Any]]:\n",
    "    callbacks_kwargs = [{'class_name': 'PrintEpochInfo',\n",
    "                         'config': {}},\n",
    "                        #{'class_name': 'HandleNaNCallback',\n",
    "                        # 'config': {'checkpoint_path': checkpoint_path,\n",
    "                        #            'lr_reduction_factor': lr_reduce_factor_on_nan,\n",
    "                        #            'random_seed_var': np.random.randint(1000000)}},\n",
    "                        #{'class_name': 'TerminateOnNaNFractionCallback',\n",
    "                        # 'config': {'threshold': 0.1,\n",
    "                        #            'validation_data': X_data_val}},\n",
    "                        {'class_name': 'ModelCheckpoint',\n",
    "                         'config': {'filepath': checkpoint_path,\n",
    "                                    'monitor': 'val_loss',\n",
    "                                    'save_best_only': True,\n",
    "                                    'save_weights_only': True,\n",
    "                                    'verbose': 1,\n",
    "                                    'mode': 'auto',\n",
    "                                    'save_freq': 'epoch'}},\n",
    "                        {'class_name': 'EarlyStopping',\n",
    "                         'config': {'monitor': 'val_loss', \n",
    "                                    'min_delta': es_min_delta, \n",
    "                                    'patience': es_patience, \n",
    "                                    'verbose': 1,\n",
    "                                    'mode': 'auto', \n",
    "                                    'baseline': None, \n",
    "                                    'restore_best_weights': True}},\n",
    "                        {'class_name': 'ReduceLROnPlateau', \n",
    "                         'config': {'monitor': 'val_loss', \n",
    "                                    'factor': lr_reduce_factor, \n",
    "                                    'min_delta': lr_min_delta, \n",
    "                                    'patience': lr_patience, \n",
    "                                    'min_lr': min_lr}},\n",
    "                        {'class_name': 'TerminateOnNaN', 'config': {}}\n",
    "                        ]\n",
    "    return callbacks_kwargs\n",
    "\n",
    "def get_fit_kwargs(batch_size: int,\n",
    "                   epochs_input: int,\n",
    "                   validation_data: Tuple[Union[np.ndarray,tf.Tensor],Union[np.ndarray,tf.Tensor]],\n",
    "                   shuffle: bool,\n",
    "                   verbose: int\n",
    "                  ) -> Dict[str,Any]:\n",
    "    fit_kwargs = {'batch_size': batch_size, \n",
    "                  'epochs': epochs_input, \n",
    "                  'validation_data': validation_data,\n",
    "                  'shuffle': shuffle, \n",
    "                  'verbose': verbose}\n",
    "    return fit_kwargs\n",
    "\n",
    "def train_function(seeds: List[int],\n",
    "                   nsamples: List[int],\n",
    "                   run_number: int,\n",
    "                   base_dist: tfp.distributions.Distribution,\n",
    "                   targ_dist: tfp.distributions.Distribution,\n",
    "                   hyperparams_dict: Dict[str, Any],\n",
    "                   n_runs: int,\n",
    "                   ndims: int,\n",
    "                   bijector_name: str,\n",
    "                   nbijectors: int,\n",
    "                   spline_knots: Union[int,str],\n",
    "                   range_min: int,\n",
    "                   hidden_layers: List[int],\n",
    "                   batch_size: int,\n",
    "                   epochs_input: int,\n",
    "                   lr_orig: float,\n",
    "                   es_min_delta: float,\n",
    "                   es_patience: int,\n",
    "                   lr_reduce_factor: float,\n",
    "                   lr_min_delta: float,\n",
    "                   lr_patience: int,\n",
    "                   min_lr: float,\n",
    "                   activation: str,\n",
    "                   regulariser: Optional[str],\n",
    "                   eps_regulariser: float,\n",
    "                   training_device: str,\n",
    "                   path_to_results: str,\n",
    "                   checkpoint_path: str,\n",
    "                   max_retry: int,\n",
    "                   debug_print_mode: bool,\n",
    "                   nan_threshold: float,\n",
    "                  ) -> Tuple[Dict[str, Any], Trainer.Trainer, int, float]:\n",
    "    succeeded = False\n",
    "    retry: int = 0\n",
    "    lr: float = lr_orig\n",
    "    while not succeeded:\n",
    "        seed_train: int\n",
    "        seed_test: int\n",
    "        seed_dist: int\n",
    "        seed_metrics: int\n",
    "        seed_train, seed_test, seed_dist, seed_metrics = seeds\n",
    "        seed_test = seed_train + 1                     \n",
    "        Utils.reset_random_seeds(seed = seed_train)\n",
    "        nsamples_train: int\n",
    "        nsamples_val: int\n",
    "        nsamples_test: int\n",
    "        nsamples_train, nsamples_val, nsamples_test = nsamples\n",
    "        X_data_train: tf.Tensor\n",
    "        X_data_val: tf.Tensor\n",
    "        Y_data_train: tf.Tensor\n",
    "        Y_data_val: tf.Tensor\n",
    "        X_data_train, X_data_val, Y_data_train, Y_data_val = Utils.generate_train_data(run_number = run_number,\n",
    "                                                                                       targ_dist = targ_dist,\n",
    "                                                                                       nsamples_train = nsamples_train,\n",
    "                                                                                       nsamples_val = nsamples_val,\n",
    "                                                                                       seed_train = seed_train)\n",
    "        bijector: tfp.bijectors.Bijector = Bijectors.ChooseBijector(bijector_name = bijector_name,\n",
    "                                                                    ndims = ndims,\n",
    "                                                                    spline_knots = spline_knots,\n",
    "                                                                    nbijectors = nbijectors,\n",
    "                                                                    range_min = range_min,\n",
    "                                                                    hidden_layers = hidden_layers,\n",
    "                                                                    activation = activation,\n",
    "                                                                    regulariser = regulariser,\n",
    "                                                                    eps_regulariser = eps_regulariser)\n",
    "        Utils.save_bijector_info(path_to_results, bijector)\n",
    "        print(\"Building Trainer NFObject.\\n\")\n",
    "        NFObject: Trainer.Trainer = Trainer.Trainer(base_distribution = base_dist,\n",
    "                                                    flow = bijector, \n",
    "                                                    x_data_train = X_data_train,\n",
    "                                                    y_data_train = Y_data_train,\n",
    "                                                    io_kwargs = get_io_kwargs(path_to_results = path_to_results),\n",
    "                                                    data_kwargs = get_data_kwargs(seed = seed_train),\n",
    "                                                    compiler_kwargs = get_compiler_kwargs(lr = lr,\n",
    "                                                                                          ignore_nans = True,\n",
    "                                                                                          nan_threshold = nan_threshold),\n",
    "                                                    callbacks_kwargs = get_callbacks_kwargs(checkpoint_path = checkpoint_path,\n",
    "                                                                                            es_min_delta = es_min_delta,\n",
    "                                                                                            es_patience = es_patience,\n",
    "                                                                                            lr_reduce_factor = lr_reduce_factor,\n",
    "                                                                                            lr_min_delta = lr_min_delta,\n",
    "                                                                                            lr_patience = lr_patience,\n",
    "                                                                                            min_lr = min_lr),\n",
    "                                                    fit_kwargs = get_fit_kwargs(batch_size = batch_size,\n",
    "                                                                                epochs_input = epochs_input,\n",
    "                                                                                validation_data = (X_data_val, Y_data_val),\n",
    "                                                                                shuffle = True,\n",
    "                                                                                verbose = 2),\n",
    "                                                    debug_print_mode = debug_print_mode)\n",
    "        trainable_params: int = NFObject.trainable_params\n",
    "        non_trainable_params: int = NFObject.non_trainable_params\n",
    "        hyperparams_dict = Utils.update_hyperparams_dict(hyperparams_dict = hyperparams_dict,\n",
    "                                                         run_number = run_number,\n",
    "                                                         n_runs = n_runs,\n",
    "                                                         seeds = [seed_train, seed_test, seed_dist, seed_metrics],\n",
    "                                                         nsamples = [nsamples_train, nsamples_val, nsamples_test],\n",
    "                                                         ndims = ndims,\n",
    "                                                         corr = None,\n",
    "                                                         bijector_name = bijector_name,\n",
    "                                                         nbijectors = nbijectors,\n",
    "                                                         spline_knots = spline_knots,\n",
    "                                                         range_min = range_min,\n",
    "                                                         hllabel = '-'.join(str(e) for e in hidden_layers),\n",
    "                                                         trainable_parameters = trainable_params,\n",
    "                                                         non_trainable_parameters = non_trainable_params,\n",
    "                                                         batch_size = batch_size,\n",
    "                                                         epochs_input = epochs_input,\n",
    "                                                         activation = activation,\n",
    "                                                         regulariser = regulariser,\n",
    "                                                         eps_regulariser = eps_regulariser,\n",
    "                                                         training_device = training_device)\n",
    "        Utils.save_hyperparams_dict(path_to_results, hyperparams_dict)\n",
    "        print(f\"Training model with initial learning rate {lr}...\")\n",
    "        print(\"Train first sample:\", X_data_train[0]) # type: ignore\n",
    "        NFObject.train()\n",
    "        training_time: float = NFObject.training_time # type: ignore\n",
    "        loss_history = list(NFObject.history['loss'])\n",
    "        if np.isnan(loss_history).any():\n",
    "            print(\"The loss history contains NaN values.\")\n",
    "\n",
    "        if np.isinf(loss_history).any():\n",
    "            print(\"The loss history contains Inf values.\")\n",
    "\n",
    "        if len(loss_history) > 0:\n",
    "            if np.isnan(loss_history).any() or np.isinf(loss_history).any():\n",
    "                succeeded = False\n",
    "                seed_train = np.random.randint(1000000)\n",
    "                lr = lr * lr_reduce_factor_on_nan\n",
    "                retry = retry + 1\n",
    "                print(f\"Training failed: trying again with seed {seed_train} and lr {lr}.\")\n",
    "            else:\n",
    "                succeeded = True\n",
    "                print(f\"Training succeeded with seed {seed_train}.\")\n",
    "        else:\n",
    "            succeeded = False\n",
    "            seed_train = np.random.randint(1000000)\n",
    "            lr = lr * lr_reduce_factor_on_nan\n",
    "            retry = retry + 1\n",
    "            print(f\"Training failed: trying again with seed {seed_train} and lr {lr}.\")\n",
    "            \n",
    "        if retry > max_retry:\n",
    "            raise Exception(\"Training failed for the maximum number of retry.\")\n",
    "        \n",
    "    return hyperparams_dict, NFObject, seed_train, training_time # type: ignore\n",
    "    \n",
    "\n",
    "def prediction_function(hyperparams_dict: Dict[str, Any],\n",
    "                        results_dict: Dict[str, Any],\n",
    "                        gpu_models: Optional[List[str]],\n",
    "                        NFObject: Trainer.Trainer,\n",
    "                        ndims: int,\n",
    "                        targ_dist: tfp.distributions.Distribution,\n",
    "                        seed_test: int,\n",
    "                        seed_metrics: int,\n",
    "                        n_iter: int,\n",
    "                        nsamples_test: int,\n",
    "                        n_slices_factor: int,\n",
    "                        dtype: type,\n",
    "                        max_vectorize: int,\n",
    "                        mirror_strategy: bool,\n",
    "                        make_plots: bool,\n",
    "                        path_to_results: str\n",
    "                       ) -> Tuple[Dict[str, Any], GMetrics.TwoSampleTestInputs, int, float]:\n",
    "    start_pred: float = timer()\n",
    "    t_losses_all: list = list(NFObject.history['loss']) # type: ignore\n",
    "    v_losses_all: list = list(NFObject.history['val_loss']) # type: ignore\n",
    "    lr_all: list = list(NFObject.history['lr']) # type: ignore\n",
    "    epochs_output: int = len(t_losses_all)\n",
    "    training_time: float = NFObject.training_time # type: ignore\n",
    "    try:\n",
    "        print(\"===========\\nComputing predictions\\n===========\\n\")\n",
    "        print(\"Computing metrics...\")\n",
    "        start = timer()\n",
    "        DataInputs: GMetrics.TwoSampleTestInputs = GMetrics.TwoSampleTestInputs(dist_1_input = targ_dist,\n",
    "                                                                                dist_2_input = NFObject.nf_dist,\n",
    "                                                                                niter = n_iter,\n",
    "                                                                                batch_size = nsamples_test,\n",
    "                                                                                dtype_input = dtype,\n",
    "                                                                                seed_input = seed_metrics,\n",
    "                                                                                use_tf = True,\n",
    "                                                                                mirror_strategy = mirror_strategy,\n",
    "                                                                                verbose = True)\n",
    "        #LRMetric: GMetrics.LRMetric = GMetrics.LRMetric(data_input = DataInputs,\n",
    "        #                                                verbose = True)\n",
    "        #KSTest: GMetrics.KSTest = GMetrics.KSTest(data_input = DataInputs,\n",
    "        #                                          verbose = True)\n",
    "        #SWDMetric: GMetrics.SWDMetric = GMetrics.SWDMetric(data_input = DataInputs,\n",
    "        #                                                   verbose = True)\n",
    "        #FNMetric: GMetrics.FNMetric = GMetrics.FNMetric(data_input = DataInputs,\n",
    "        #                                                verbose = True)\n",
    "        ##LRMetric.compute()\n",
    "        #KSTest.compute(max_vectorize = max_vectorize)\n",
    "        #SWDMetric.compute(nslices = n_slices_factor*ndims)\n",
    "        #FNMetric.compute(max_vectorize = max_vectorize)\n",
    "        ##lr_result: Dict[str, np.ndarray] = LRMetric.Results[-1].result_value\n",
    "        logprob_ref_ref_sum_list = None#lr_result[\"logprob_ref_ref_sum_list\"].tolist()\n",
    "        logprob_ref_alt_sum_list = None#lr_result[\"logprob_ref_alt_sum_list\"].tolist()\n",
    "        logprob_alt_alt_sum_list = None#lr_result[\"logprob_alt_alt_sum_list\"].tolist()\n",
    "        lik_ratio_list = None#lr_result[\"lik_ratio_list\"].tolist()\n",
    "        lik_ratio_norm_list = None#lr_result[\"lik_ratio_norm_list\"].tolist()\n",
    "        ks_result: Dict[str, np.ndarray] = None#KSTest.Results[-1].result_value\n",
    "        ks_lists: List[List[float]] = None#ks_result[\"statistic_lists\"].tolist()\n",
    "        ks_means: List[float] = None#ks_result[\"statistic_means\"].tolist()\n",
    "        ks_stds: List[float] = None#ks_result[\"statistic_stds\"].tolist()\n",
    "        swd_result: Dict[str, np.ndarray] = None#SWDMetric.Results[-1].result_value\n",
    "        swd_lists: List[List[float]] = None#swd_result[\"metric_lists\"].tolist()\n",
    "        swd_means: List[float] = None#swd_result[\"metric_means\"].tolist()\n",
    "        swd_stds: List[float] = None#swd_result[\"metric_stds\"].tolist()\n",
    "        fn_result: Dict[str, np.ndarray] = None#FNMetric.Results[-1].result_value\n",
    "        fn_list: List[float] = None#fn_result[\"metric_list\"].tolist()\n",
    "        ad_lists: Optional[List[List[float]]] = None\n",
    "        ad_means: Optional[List[float]] = None\n",
    "        ad_stds: Optional[List[float]] = None\n",
    "        wd_lists: Optional[List[List[float]]] = None\n",
    "        wd_means: Optional[List[float]] = None\n",
    "        wd_stds: Optional[List[float]] = None\n",
    "        end = timer()\n",
    "        metrics_time = end - start\n",
    "        print(f\"Metrics computed in {metrics_time:.2f} s.\")\n",
    "    except:\n",
    "        raise Exception(\"Failed computing metrics\")\n",
    "        try:\n",
    "            print(\"===========\\nFailed on GPU, re-trying on CPU\\n===========\\n\")\n",
    "            with tf.device('/device:CPU:0'): # type: ignore\n",
    "                print(\"Computing metrics...\")\n",
    "                start = timer()\n",
    "                DataInputs = GMetrics.TwoSampleTestInputs(dist_1_input = targ_dist,\n",
    "                                                          dist_2_input = NFObject.nf_dist,\n",
    "                                                          niter = n_iter,\n",
    "                                                          batch_size = nsamples_test,\n",
    "                                                          dtype_input = dtype,\n",
    "                                                          seed_input = seed_metrics,\n",
    "                                                          use_tf = True,\n",
    "                                                          verbose = True)\n",
    "                LRMetric = GMetrics.LRMetric(data_input = DataInputs,\n",
    "                                             verbose = True)\n",
    "                KSTest = GMetrics.KSTest(data_input = DataInputs,\n",
    "                                         verbose = True)\n",
    "                SWDMetric = GMetrics.SWDMetric(data_input = DataInputs,\n",
    "                                               verbose = True)\n",
    "                FNMetric = GMetrics.FNMetric(data_input = DataInputs,\n",
    "                                             verbose = True)\n",
    "                LRMetric.compute()\n",
    "                KSTest.compute(max_vectorize = max_vectorize)\n",
    "                SWDMetric.compute(nslices = n_slices_factor*ndims)\n",
    "                FNMetric.compute(max_vectorize = max_vectorize)\n",
    "                lr_result = LRMetric.Results[-1].result_value\n",
    "                logprob_ref_ref_sum_list = lr_result[\"logprob_ref_ref_sum_list\"].tolist()\n",
    "                logprob_ref_alt_sum_list = lr_result[\"logprob_ref_alt_sum_list\"].tolist()\n",
    "                logprob_alt_alt_sum_list = lr_result[\"logprob_alt_alt_sum_list\"].tolist()\n",
    "                lik_ratio_list = lr_result[\"lik_ratio_list\"].tolist()\n",
    "                lik_ratio_norm_list = lr_result[\"lik_ratio_norm_list\"].tolist()\n",
    "                ks_result = KSTest.Results[-1].result_value\n",
    "                ks_lists = ks_result[\"statistic_lists\"].tolist()\n",
    "                ks_means = ks_result[\"statistic_means\"].tolist()\n",
    "                ks_stds = ks_result[\"statistic_stds\"].tolist()\n",
    "                swd_result = SWDMetric.Results[-1].result_value\n",
    "                swd_lists = swd_result[\"metric_lists\"].tolist()\n",
    "                swd_means = swd_result[\"metric_means\"].tolist()\n",
    "                swd_stds = swd_result[\"metric_stds\"].tolist()\n",
    "                fn_result = FNMetric.Results[-1].result_value\n",
    "                fn_list = fn_result[\"metric_list\"].tolist()\n",
    "                ad_lists = None\n",
    "                ad_means = None\n",
    "                ad_stds = None\n",
    "                wd_lists = None\n",
    "                wd_means = None\n",
    "                wd_stds = None\n",
    "                end = timer()\n",
    "                metrics_time = end - start\n",
    "                print(f\"Metrics computed in {metrics_time:.2f} s.\")\n",
    "        except:\n",
    "            print(\"===========\\nFailed computing metrics\\n===========\\n\")\n",
    "            logprob_ref_ref_sum_list = []\n",
    "            logprob_ref_alt_sum_list = []\n",
    "            logprob_alt_alt_sum_list = []\n",
    "            lik_ratio_list = []\n",
    "            lik_ratio_norm_list = []\n",
    "            ks_means = []\n",
    "            ks_stds = []\n",
    "            ks_lists = []\n",
    "            ad_means = []\n",
    "            ad_stds = []\n",
    "            ad_lists = []\n",
    "            fn_list = []\n",
    "            wd_means = []\n",
    "            wd_stds = []\n",
    "            wd_lists = []\n",
    "            swd_means = []\n",
    "            swd_stds = []\n",
    "            swd_lists = []\n",
    "            metrics_time = 0.\n",
    "    if make_plots:\n",
    "        try:\n",
    "            start = timer()\n",
    "            Plotters.train_plotter(t_losses_all,v_losses_all,path_to_results)\n",
    "            #X_data_test: tf.Tensor = DataInputs.dist_1_num[:nsamples_test] # type: ignore\n",
    "            #X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore\n",
    "            X_data_test: np.ndarray = GMetrics.utils.generate_and_clean_data(DataInputs.dist_1_symb,100000,10000,dtype,seed_metrics,mirror_strategy=True).numpy() # type: ignore\n",
    "            X_data_nf: np.ndarray = GMetrics.utils.generate_and_clean_data(DataInputs.dist_2_symb,100000,10000,dtype,seed_metrics,mirror_strategy=True).numpy() # type: ignore\n",
    "            Plotters.cornerplotter(X_data_test,X_data_nf,path_to_results,ndims,norm=True) # type: ignore\n",
    "            Plotters.marginal_plot(X_data_test,X_data_nf,path_to_results,ndims) # type: ignore\n",
    "            #Plotters.sample_plotter(X_data_test,nf_dist,path_to_results)\n",
    "            end = timer()\n",
    "            plots_time: float = end - start\n",
    "            print(f\"Plots done in {plots_time:.2f} s.\")\n",
    "        except Exception as ex:\n",
    "            # Get current system exception\n",
    "            ex_type, ex_value, ex_traceback = sys.exc_info()\n",
    "            # Extract unformatter stack traces as tuples\n",
    "            trace_back = traceback.extract_tb(ex_traceback) # type: ignore\n",
    "            # Format stacktrace\n",
    "            stack_trace = list()\n",
    "            for trace in trace_back:\n",
    "                stack_trace.append(\"File : %s , Line : %d, Func.Name : %s, Message : %s\" % (trace[0], trace[1], trace[2], trace[3]))\n",
    "            ex_type_str = f\"Exception type: {ex_type.__name__}\" # type: ignore\n",
    "            print(textwrap.dedent(f\"\"\"\\\n",
    "                ===========\n",
    "                print(\"===========\\nFailed to plot\\n===========\\n\")\n",
    "                {ex_type_str}\n",
    "                Exception message: {ex_value}\n",
    "                Stack trace: {stack_trace}\n",
    "                ===========\n",
    "                \"\"\"))\n",
    "        \n",
    "    end_pred: float = timer()\n",
    "    prediction_time: float = end_pred - start_pred\n",
    "    total_time: float = training_time + prediction_time\n",
    "    results_dict = Utils.update_results_dict(results_dict = results_dict,\n",
    "                                             hyperparams_dict = hyperparams_dict,\n",
    "                                             train_loss_history = t_losses_all,\n",
    "                                             val_loss_history = v_losses_all,\n",
    "                                             lr_history = lr_all,\n",
    "                                             epochs_output = epochs_output,\n",
    "                                             training_time = training_time,\n",
    "                                             prediction_time = prediction_time,\n",
    "                                             total_time = total_time,\n",
    "                                             logprob_ref_ref_sum_list = logprob_ref_ref_sum_list,\n",
    "                                             logprob_ref_alt_sum_list = logprob_ref_alt_sum_list,\n",
    "                                             logprob_alt_alt_sum_list = logprob_alt_alt_sum_list,\n",
    "                                             lik_ratio_list = lik_ratio_list,\n",
    "                                             lik_ratio_norm_list = lik_ratio_norm_list,\n",
    "                                             ks_means = ks_means,\n",
    "                                             ks_stds = ks_stds,\n",
    "                                             ks_lists = ks_lists,\n",
    "                                             ad_means = ad_means,\n",
    "                                             ad_stds = ad_stds,\n",
    "                                             ad_lists = ad_lists,\n",
    "                                             fn_list = fn_list,\n",
    "                                             wd_means = wd_means,\n",
    "                                             wd_stds = wd_stds,\n",
    "                                             wd_lists = wd_lists,\n",
    "                                             swd_means = swd_means,\n",
    "                                             swd_stds = swd_stds,\n",
    "                                             swd_lists = swd_lists\n",
    "                                             )\n",
    "    return results_dict, DataInputs, prediction_time, total_time # type: ignore\n",
    "\n",
    "##############################################################################################\n",
    "################################## Parameters initialization #################################\n",
    "##############################################################################################\n",
    "\n",
    "### Initialize number of components ###\n",
    "ncomp: int = 3\n",
    "\n",
    "### Initialize hyperparameters lists ###\n",
    "ndims_list: List[int] = [4, 8, 16, 32, 64, 100, 200, 400, 1000]\n",
    "nbijectors_list: List[int] = [2]\n",
    "hidden_layers_list: List[List[int]] = [[128, 128, 128], [256, 256, 256]]\n",
    "seeds_list: List[int] = [0, 187, 377, 440, 520, 541, 721, 869, 926, 933]\n",
    "\n",
    "### Initialize nsamples inputs ###\n",
    "nsamples_train: int = 100000\n",
    "nsamples_val: int = 30000\n",
    "nsamples_test: int = 100000\n",
    "\n",
    "### Initialize seeds inputs ###\n",
    "seed_test: int = 0 # overwritten in the loop by seed_train + 1\n",
    "seed_dist: int = 0\n",
    "seed_metrics: int = seed_test\n",
    "\n",
    "### Initialize bijector inputs ###\n",
    "bijector_name: str = 'MsplineN'\n",
    "range_min: int = -16\n",
    "spline_knots_list: List[Union[int,str]] = [8, 12] # Only relevant for the neural spline\n",
    "\n",
    "### Initialize NN hyperparameters ###\n",
    "activation: str = 'relu'\n",
    "regulariser: Optional[str] = None\n",
    "eps_regulariser: float = 0.\n",
    "\n",
    "### Initialzie training hyperparameters ###\n",
    "epochs_input: int = 10\n",
    "batch_size: int = 512\n",
    "nan_threshold: float = 0.01\n",
    "max_retry: int = 10\n",
    "debug_print_mode: bool = True\n",
    "\n",
    "### Initialize optimizer hyperparameters ###\n",
    "lr_orig: float = 0.001\n",
    "\n",
    "### Initialize callbacks hyperparameters ###\n",
    "es_min_delta: float = .0001\n",
    "es_patience: int = 100\n",
    "lr_min_delta: float = .0001\n",
    "lr_patience: int = 50\n",
    "lr_reduce_factor: float = .5\n",
    "lr_reduce_factor_on_nan: float = float(1/3)\n",
    "min_lr: float = 1e-6\n",
    "\n",
    "### Initialize parameters for inference ###\n",
    "n_iter: int = 10\n",
    "n_slices_factor: int = 2\n",
    "dtype: type = tf.float32\n",
    "max_vectorize: int = 10\n",
    "mirror_strategy = True\n",
    "make_plots = True\n",
    "\n",
    "### Initialize old variables for backward compatibility\n",
    "corr: Optional[str] = None\n",
    "\n",
    "### Initialize dictionaries ###\n",
    "results_dict: Dict[str, Any] = Utils.init_results_dict()\n",
    "hyperparams_dict: Dict[str, Any] = Utils.init_hyperparams_dict()\n",
    "\n",
    "### Initialize output dir ###\n",
    "mother_output_dir: str = Utils.define_dir('../../results/MsplineN_new/')\n",
    "\n",
    "### Create 'log' file ####\n",
    "log_file_name: str = Utils.create_log_file(mother_output_dir, results_dict)\n",
    "\n",
    "##############################################################################################\n",
    "####################################### Training loop ########################################\n",
    "##############################################################################################\n",
    "run: int = 250\n",
    "run_max: int = 250\n",
    "run_number: int = 0\n",
    "n_runs: int = len(ndims_list) * len(seeds_list) * len(nbijectors_list) * len(spline_knots_list) * len(hidden_layers_list)\n",
    "start_global: float = timer()\n",
    "for ndims in ndims_list:\n",
    "    targ_dist: tfp.distributions.Distribution = MixtureGaussian(ncomp = ncomp, ndims = ndims, seed = seed_dist)\n",
    "    base_dist: tfp.distributions.Distribution = Distributions.gaussians(ndims)\n",
    "    for seed_train in seeds_list:\n",
    "        for nbijectors in nbijectors_list:\n",
    "            for spline_knots in spline_knots_list:\n",
    "                for hidden_layers in hidden_layers_list:\n",
    "                    if run > run_max:\n",
    "                        raise Exception(\"Interrupted after one run.\")\n",
    "                    start_run: float = timer()\n",
    "                    hllabel: str = '-'.join(str(e) for e in hidden_layers)\n",
    "                    run_number = run_number + 1\n",
    "                    results_dict_txt_saved: bool = False\n",
    "                    results_dict_json_saved: bool = False\n",
    "                    results_log_saved: bool = False\n",
    "                    path_to_results: str\n",
    "                    to_run: bool\n",
    "                    path_to_results, to_run = Utils.define_run_dir(mother_output_dir+'run_'+str(run_number)+'/',\n",
    "                                                                   force = \"skip\",\n",
    "                                                                   bkp = False)\n",
    "                    if to_run:\n",
    "                        try:\n",
    "                            dummy_file_path: str = os.path.join(path_to_results,'running.txt')\n",
    "                            with open(dummy_file_path, 'w') as f:\n",
    "                                pass\n",
    "                            path_to_weights: str = Utils.define_dir(os.path.join(path_to_results, 'weights'))\n",
    "                            checkpoint_path: str = os.path.join(path_to_weights, 'best_weights.h5')\n",
    "                            ########### Model train ###########\n",
    "                            NFObject: Trainer.Trainer\n",
    "                            hyperparams_dict, NFObject, seed_train, training_time = train_function(seeds = [seed_train, seed_test, seed_dist, seed_metrics],\n",
    "                                                                                                   nsamples = [nsamples_train, nsamples_val, nsamples_test],\n",
    "                                                                                                   run_number = run_number,\n",
    "                                                                                                   base_dist = base_dist,\n",
    "                                                                                                   targ_dist = targ_dist,\n",
    "                                                                                                   hyperparams_dict = hyperparams_dict,\n",
    "                                                                                                   n_runs = n_runs,\n",
    "                                                                                                   ndims = ndims,\n",
    "                                                                                                   bijector_name = bijector_name,\n",
    "                                                                                                   nbijectors = nbijectors,\n",
    "                                                                                                   spline_knots = spline_knots,\n",
    "                                                                                                   range_min = range_min,\n",
    "                                                                                                   hidden_layers = hidden_layers,\n",
    "                                                                                                   batch_size = batch_size,\n",
    "                                                                                                   epochs_input = epochs_input,\n",
    "                                                                                                   lr_orig = lr_orig,\n",
    "                                                                                                   es_min_delta = es_min_delta,\n",
    "                                                                                                   es_patience = es_patience,\n",
    "                                                                                                   lr_reduce_factor = lr_reduce_factor,\n",
    "                                                                                                   lr_min_delta = lr_min_delta,\n",
    "                                                                                                   lr_patience = lr_patience,\n",
    "                                                                                                   min_lr = min_lr,\n",
    "                                                                                                   activation = activation,\n",
    "                                                                                                   regulariser = regulariser,\n",
    "                                                                                                   eps_regulariser = eps_regulariser,\n",
    "                                                                                                   training_device = training_device,\n",
    "                                                                                                   path_to_results = path_to_results,\n",
    "                                                                                                   checkpoint_path = checkpoint_path,\n",
    "                                                                                                   max_retry = max_retry,\n",
    "                                                                                                   debug_print_mode = debug_print_mode,\n",
    "                                                                                                   nan_threshold = nan_threshold)\n",
    "                            \n",
    "                            print(f\"Model trained in {training_time:.2f} s.\\n\") # type: ignore\n",
    "                            ########## Model prediction ###########\n",
    "                            results_dict, DataInputs, prediction_time, total_time = prediction_function(hyperparams_dict = hyperparams_dict,\n",
    "                                                                                                        results_dict = results_dict,\n",
    "                                                                                                        gpu_models = gpu_models,\n",
    "                                                                                                        NFObject = NFObject, # type: ignore\n",
    "                                                                                                        ndims = ndims,\n",
    "                                                                                                        targ_dist = targ_dist,\n",
    "                                                                                                        seed_test = seed_test,\n",
    "                                                                                                        seed_metrics = seed_metrics,\n",
    "                                                                                                        n_iter = n_iter,\n",
    "                                                                                                        nsamples_test = nsamples_test,\n",
    "                                                                                                        n_slices_factor = n_slices_factor,\n",
    "                                                                                                        dtype = dtype,\n",
    "                                                                                                        max_vectorize = max_vectorize,\n",
    "                                                                                                        mirror_strategy = mirror_strategy,\n",
    "                                                                                                        make_plots = make_plots,\n",
    "                                                                                                        path_to_results = path_to_results)\n",
    "                            ########### Save results ###########\n",
    "                            Utils.save_results_current_run_txt(path_to_results, results_dict)\n",
    "                            results_dict_txt_saved = True\n",
    "                            print(\"results.txt saved\")\n",
    "                            Utils.save_results_current_run_json(path_to_results, results_dict)\n",
    "                            results_dict_json_saved = True\n",
    "                            print(\"results.json saved\")\n",
    "                            Utils.save_results_log(log_file_name, results_dict)\n",
    "                            results_log_saved = True\n",
    "                            print(\"Results log saved\")\n",
    "                            print(f\"Model predictions computed in {prediction_time:.2f} s.\")\n",
    "                            end_run: float = timer()\n",
    "                            total_time_run=end_run-start_run\n",
    "                            print(textwrap.dedent(f\"\"\"\\\n",
    "                                ===========\n",
    "                                Run {run_number}/{n_runs} done in {total_time_run:.2f} s.\n",
    "                                ===========\n",
    "                                \"\"\"))\n",
    "                            run = run + 1\n",
    "                            try:\n",
    "                                os.remove(dummy_file_path)\n",
    "                            except:\n",
    "                                pass\n",
    "                            dummy_file_path = os.path.join(path_to_results,'done.txt')\n",
    "                            with open(dummy_file_path, 'w') as f:\n",
    "                                pass\n",
    "                        except Exception as ex:\n",
    "                            try:\n",
    "                                os.remove(dummy_file_path)\n",
    "                            except:\n",
    "                                pass\n",
    "                            # Get current system exception\n",
    "                            ex_type, ex_value, ex_traceback = sys.exc_info()\n",
    "                            # Extract unformatter stack traces as tuples\n",
    "                            trace_back = traceback.extract_tb(ex_traceback) # type: ignore\n",
    "                            # Format stacktrace\n",
    "                            stack_trace = list()\n",
    "                            for trace in trace_back:\n",
    "                                stack_trace.append(\"File : %s , Line : %d, Func.Name : %s, Message : %s\" % (trace[0], trace[1], trace[2], trace[3]))\n",
    "                            if not results_dict_txt_saved:\n",
    "                                results_dict = Utils.update_results_dict(results_dict = results_dict,\n",
    "                                                                         hyperparams_dict = hyperparams_dict)\n",
    "                                Utils.save_results_current_run_txt(path_to_results, results_dict)\n",
    "                            if not results_dict_json_saved:\n",
    "                                Utils.save_results_current_run_json(path_to_results, results_dict)\n",
    "                            if not results_log_saved:\n",
    "                                Utils.save_results_log(log_file_name, results_dict)\n",
    "                            ex_type_str = f\"Exception type: {ex_type.__name__}\" # type: ignore\n",
    "                            print(textwrap.dedent(f\"\"\"\\\n",
    "                                ===========\n",
    "                                Run {run_number}/{n_runs} failed.\n",
    "                                {ex_type_str}\n",
    "                                Exception message: {ex_value}\n",
    "                                Stack trace: {stack_trace}\n",
    "                                ===========\n",
    "                                \"\"\"))\n",
    "                    else:\n",
    "                        print(textwrap.dedent(f\"\"\"\\\n",
    "                            ===========\n",
    "                            Run {run_number}/{n_runs} already exists. Skipping it.\n",
    "                            ===========\n",
    "                            \"\"\"))\n",
    "keys_to_remove = ['ks_lists', 'ad_lists', 'fn_list', 'wd_lists', 'swd_lists', 'train_loss_history', 'val_loss_history', 'lr_history']\n",
    "dict_copy: Dict[str, Any] = {k: v for k, v in results_dict.items() if k not in keys_to_remove}\n",
    "results_frame: pd.DataFrame = pd.DataFrame(dict_copy)\n",
    "results_last_run_file: str = os.path.join(mother_output_dir,'results_last_run.txt')\n",
    "results_frame.to_csv(results_last_run_file,index=False)\n",
    "end_global: float = timer()\n",
    "print(f\"Everything done in {end_global-start_global:.2f} s.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_data_test\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_data_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GenerativeModelsMetrics.base.TwoSampleTestInputs at 0x7f4a28d16e00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "X_data_test: np.ndarray = GMetrics.utils.generate_and_clean_data(DataInputs.dist_1_symb,100000,10000,dtype,seed_metrics,mirror_strategy=True).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.0135806 ,  6.7743177 ,  3.5256774 , ...,  8.114433  ,\n",
       "         9.672192  ,  9.885937  ],\n",
       "       [ 2.961013  ,  7.300559  ,  4.214094  , ...,  8.53371   ,\n",
       "        10.072328  , 10.635068  ],\n",
       "       [ 5.750245  ,  6.4018464 ,  5.7767906 , ...,  0.14544174,\n",
       "         8.30282   , -0.09358285],\n",
       "       ...,\n",
       "       [ 7.050107  ,  3.1410584 ,  7.4368067 , ...,  2.387996  ,\n",
       "         0.2435883 ,  4.29028   ],\n",
       "       [ 2.3139744 ,  6.103998  ,  4.265177  , ...,  8.132029  ,\n",
       "         9.074183  ,  9.112792  ],\n",
       "       [ 3.317526  ,  6.7196155 ,  3.1706188 , ...,  8.46518   ,\n",
       "         9.155292  , 10.379258  ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.90578973, -2.6910897 ,  2.60570709, ..., -5.1122826 ,\n",
       "        -6.03239352, -4.76054391],\n",
       "       [-2.6910897 ,  4.12019916, -2.63239653, ...,  3.56909606,\n",
       "         7.59805895,  2.63663328],\n",
       "       [ 2.60570709, -2.63239653,  2.70930627, ..., -4.93901169,\n",
       "        -5.88953338, -4.58428739],\n",
       "       ...,\n",
       "       [-5.1122826 ,  3.56909606, -4.93901169, ..., 12.3457557 ,\n",
       "         9.12495038, 12.36540563],\n",
       "       [-6.03239352,  7.59805895, -5.88953338, ...,  9.12495038,\n",
       "        16.02715957,  7.45115305],\n",
       "       [-4.76054391,  2.63663328, -4.58428739, ..., 12.36540563,\n",
       "         7.45115305, 13.57922158]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X_data_test,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "covv = np.cov(X_data_test,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.90578973, -2.6910897 ,  2.60570709, ..., -5.1122826 ,\n",
       "        -6.03239352, -4.76054391],\n",
       "       [-2.6910897 ,  4.12019916, -2.63239653, ...,  3.56909606,\n",
       "         7.59805895,  2.63663328],\n",
       "       [ 2.60570709, -2.63239653,  2.70930627, ..., -4.93901169,\n",
       "        -5.88953338, -4.58428739],\n",
       "       ...,\n",
       "       [-5.1122826 ,  3.56909606, -4.93901169, ..., 12.3457557 ,\n",
       "         9.12495038, 12.36540563],\n",
       "       [-6.03239352,  7.59805895, -5.88953338, ...,  9.12495038,\n",
       "        16.02715957,  7.45115305],\n",
       "       [-4.76054391,  2.63663328, -4.58428739, ..., 12.36540563,\n",
       "         7.45115305, 13.57922158]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.32577269,  1.58305697, ..., -1.45497662,\n",
       "        -1.50682003, -1.29187097],\n",
       "       [-1.32577269,  1.        , -1.59927172, ...,  1.01577939,\n",
       "         1.8979046 ,  0.71550437],\n",
       "       [ 1.58305697, -1.59927172,  1.        , ..., -1.405663  ,\n",
       "        -1.47113527, -1.24404015],\n",
       "       ...,\n",
       "       [-1.45497662,  1.01577939, -1.405663  , ...,  1.        ,\n",
       "         2.27930389,  3.35560575],\n",
       "       [-1.50682003,  1.8979046 , -1.47113527, ...,  2.27930389,\n",
       "         1.        ,  2.02202279],\n",
       "       [-1.29187097,  0.71550437, -1.24404015, ...,  3.35560575,\n",
       "         2.02202279,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = covv\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        corr[i,j]=covv[i,j]/np.sqrt(covv[i,i])/np.sqrt(covv[j,j])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.32577269,  1.58305697, ..., -1.45497662,\n",
       "        -1.50682003, -1.29187097],\n",
       "       [-1.32577269,  1.        , -1.59927172, ...,  1.01577939,\n",
       "         1.8979046 ,  0.71550437],\n",
       "       [ 1.58305697, -1.59927172,  1.        , ..., -1.405663  ,\n",
       "        -1.47113527, -1.24404015],\n",
       "       ...,\n",
       "       [-1.45497662,  1.01577939, -1.405663  , ...,  1.        ,\n",
       "         2.27930389,  3.35560575],\n",
       "       [-1.50682003,  1.8979046 , -1.47113527, ...,  2.27930389,\n",
       "         1.        ,  2.02202279],\n",
       "       [-1.29187097,  0.71550437, -1.24404015, ...,  3.35560575,\n",
       "         2.02202279,  1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = covv\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        corr[i,j]=covv[i,j]/np.sqrt(covv[i,i]*covv[j,j])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.77774455,  0.92867649, ..., -0.85354008,\n",
       "        -0.88395324, -0.75785662],\n",
       "       [-0.77774455,  1.        , -0.78788558, ...,  0.50042649,\n",
       "         0.93500789,  0.35249518],\n",
       "       [ 0.92867649, -0.78788558,  1.        , ..., -0.85398878,\n",
       "        -0.89376544, -0.75579732],\n",
       "       ...,\n",
       "       [-0.85354008,  0.50042649, -0.85398878, ...,  1.        ,\n",
       "         0.64869924,  0.95501917],\n",
       "       [-0.88395324,  0.93500789, -0.89376544, ...,  0.64869924,\n",
       "         1.        ,  0.5050772 ],\n",
       "       [-0.75785662,  0.35249518, -0.75579732, ...,  0.95501917,\n",
       "         0.5050772 ,  1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the covariance matrix\n",
    "covariance_matrix = np.cov(X_data_test, rowvar=False)\n",
    "\n",
    "# Calculate the standard deviations of each feature\n",
    "std_devs = np.sqrt(np.diag(covariance_matrix))\n",
    "\n",
    "# Normalize the covariance matrix to get the correlation matrix\n",
    "correlation_matrix = covariance_matrix / np.outer(std_devs, std_devs)\n",
    "\n",
    "# Ensure the diagonal elements are exactly 1\n",
    "# np.fill_diagonal(correlation_matrix, 1)\n",
    "correlation_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
