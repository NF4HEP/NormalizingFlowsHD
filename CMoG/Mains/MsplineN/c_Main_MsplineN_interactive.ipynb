{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to tf2_12 (Python 3.10.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MAFN_new'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(\"../../results/MAFN_new/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing ../../results/RealNVPN_new/run_83/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_83/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_64/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_64/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_45/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_45/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_89/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_89/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_26/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_26/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_92/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_92/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_219/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_219/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_208/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_208/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_98/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_98/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_79/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_79/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_268/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_268/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_257/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_257/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_246/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_246/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_235/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_235/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_224/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_224/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_213/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_213/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_309/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_309/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_202/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_202/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_119/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_119/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_108/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_108/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_273/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_273/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_262/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_262/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_358/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_358/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_179/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_179/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_3/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_3/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_251/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_251/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_347/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_347/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_168/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_168/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_240/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_240/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_336/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_336/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_157/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_157/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_325/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_325/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_146/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_146/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_314/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_314/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_135/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_135/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_303/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_303/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_124/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_124/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_23/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_23/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_113/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_113/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_209/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_209/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_195/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_195/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_102/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_102/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_184/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_184/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_352/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_352/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_173/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_173/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_269/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_269/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_341/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_341/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_162/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_162/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_258/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_258/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_2/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_2/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_330/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_330/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_151/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_151/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_247/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_247/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_140/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_140/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_236/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_236/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_70/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_70/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_225/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_225/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_51/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_51/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_214/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_214/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_296/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_296/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_32/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_32/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_203/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_203/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_285/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_285/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_13/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_13/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_57/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_57/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_274/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_274/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_38/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_38/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_263/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_263/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_359/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_359/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_19/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_19/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_252/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_252/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_241/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_241/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_230/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_230/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_60/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_60/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_290/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_290/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_41/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_41/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_85/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_85/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_22/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_22/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_66/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_66/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_47/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_47/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_28/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_28/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_50/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_50/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_94/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_94/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_75/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_75/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_56/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_56/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_37/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_37/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_329/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_329/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_84/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_84/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_318/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_318/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_139/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_139/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_307/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_307/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_128/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_128/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_117/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_117/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_199/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_199/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_106/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_106/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_188/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_188/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_177/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_177/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_345/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_345/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_166/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_166/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_334/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_334/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_155/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_155/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_323/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_323/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_144/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_144/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_312/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_312/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_133/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_133/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_229/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_229/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_301/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_301/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_122/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_122/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_218/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_218/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_111/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_111/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_207/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_207/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_193/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_193/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_289/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_289/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_100/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_100/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_182/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_182/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_278/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_278/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_350/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_350/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_171/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_171/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_267/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_267/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_160/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_160/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_256/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_256/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_245/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_245/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_234/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_234/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_223/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_223/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_319/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_319/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_15/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_15/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_212/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_212/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_308/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_308/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_129/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_129/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_294/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_294/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_201/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_201/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_118/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_118/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_283/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_283/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_5/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_5/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_107/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_107/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_272/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_272/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_189/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_189/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_261/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_261/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_357/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_357/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_178/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_178/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_250/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_250/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_346/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_346/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_167/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_167/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_335/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_335/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_156/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_156/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_62/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_62/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_324/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_324/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_145/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_145/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_43/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_43/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_313/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_313/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_134/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_134/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_24/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_24/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_302/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_302/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_123/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_123/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_112/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_112/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_49/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_49/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_194/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_194/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_101/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_101/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_183/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_183/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_279/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_279/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_4/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_4/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_351/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_351/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_172/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_172/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_340/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_340/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_161/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_161/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_90/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_90/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_150/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_150/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_71/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_71/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_52/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_52/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_96/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_96/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_33/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_33/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_77/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_77/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_295/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_295/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_14/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_14/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_58/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_58/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_284/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_284/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_39/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_39/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_80/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_80/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_61/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_61/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_42/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_42/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_86/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_86/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_67/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_67/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_48/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_48/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_29/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_29/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_95/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_95/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_249/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_249/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_76/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_76/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_238/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_238/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_227/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_227/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_216/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_216/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_205/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_205/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_276/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_276/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_265/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_265/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_254/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_254/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_243/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_243/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_339/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_339/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_232/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_232/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_328/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_328/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_149/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_149/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_221/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_221/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_317/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_317/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_138/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_138/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_210/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_210/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_306/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_306/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_127/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_127/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_116/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_116/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_281/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_281/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_198/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_198/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_105/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_105/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_270/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_270/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_187/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_187/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_355/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_355/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_176/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_176/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_20/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_20/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_344/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_344/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_165/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_165/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_333/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_333/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_154/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_154/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_322/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_322/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_143/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_143/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_239/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_239/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_311/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_311/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_132/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_132/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_8/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_8/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_228/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_228/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_300/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_300/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_121/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_121/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_217/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_217/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_299/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_299/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_110/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_110/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_206/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_206/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_192/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_192/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_288/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_288/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_360/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_360/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_181/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_181/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_277/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_277/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_170/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_170/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_266/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_266/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_73/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_73/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_255/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_255/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_10/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_10/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_54/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_54/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_244/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_244/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_35/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_35/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_233/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_233/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_16/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_16/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_222/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_222/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_211/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_211/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_7/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_7/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_293/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_293/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_200/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_200/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_282/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_282/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_271/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_271/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_260/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_260/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_356/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_356/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_82/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_82/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_63/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_63/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_44/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_44/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_88/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_88/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_25/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_25/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_69/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_69/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_6/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_6/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_91/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_91/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_72/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_72/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_53/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_53/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_97/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_97/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_34/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_34/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_78/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_78/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_59/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_59/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_81/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_81/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_109/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_109/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_87/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_87/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_348/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_348/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_169/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_169/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_68/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_68/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_337/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_337/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_158/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_158/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_1/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_1/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_326/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_326/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_147/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_147/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_315/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_315/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_136/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_136/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_304/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_304/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_125/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_125/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_114/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_114/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_196/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_196/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_103/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_103/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_185/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_185/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_353/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_353/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_174/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_174/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_342/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_342/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_163/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_163/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_259/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_259/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_331/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_331/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_152/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_152/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_248/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_248/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_320/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_320/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_141/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_141/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_237/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_237/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_130/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_130/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_226/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_226/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_215/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_215/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_297/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_297/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_204/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_204/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_190/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_190/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_286/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_286/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_31/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_31/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_275/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_275/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_12/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_12/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_264/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_264/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_253/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_253/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_349/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_349/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_18/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_18/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_242/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_242/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_338/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_338/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_159/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_159/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_231/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_231/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_327/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_327/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_148/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_148/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_220/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_220/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_316/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_316/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_137/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_137/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_305/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_305/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_126/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_126/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_291/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_291/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_115/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_115/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_280/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_280/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_197/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_197/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_40/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_40/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_104/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_104/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_186/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_186/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_21/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_21/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_65/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_65/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_354/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_354/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_175/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_175/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_46/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_46/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_343/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_343/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_164/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_164/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_27/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_27/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_332/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_332/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_153/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_153/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_321/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_321/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_142/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_142/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_310/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_310/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_131/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_131/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_120/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_120/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_298/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_298/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_191/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_191/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_287/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_287/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_93/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_93/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_180/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_180/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_30/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_30/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_74/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_74/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_11/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_11/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_55/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_55/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_99/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_99/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_36/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_36/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_17/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_17/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_9/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_9/done_new.txt\n",
      "Removing ../../results/RealNVPN_new/run_292/results_original.json\n",
      "Creating ../../results/RealNVPN_new/run_292/done_new.txt\n"
     ]
    }
   ],
   "source": [
    "def remove_and_create_files(root_folder, target_filename, new_filename):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename == target_filename:\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                print(f\"Removing {file_path}\")\n",
    "                os.remove(file_path)\n",
    "                \n",
    "                # Create a new empty file in the same directory\n",
    "                new_file_path = os.path.join(dirpath, new_filename)\n",
    "                print(f\"Creating {new_file_path}\")\n",
    "                with open(new_file_path, 'w') as f:\n",
    "                    pass\n",
    "\n",
    "root_folder = \"../../results/RealNVPN_new/\"\n",
    "target_filename = \"results_original.json\"\n",
    "new_filename = \"done_new.txt\"\n",
    "remove_and_create_files(root_folder, target_filename, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-11 17:31:55.050659: Importing os...\n",
      "2023-10-11 17:31:55.050926: Importing sys...\n",
      "2023-10-11 17:31:55.051002: Importing and initializing argparse...\n",
      "Visible devices: [0, 1, 2]\n",
      "2023-10-11 17:31:55.051235: Importing timer from timeit...\n",
      "2023-10-11 17:31:55.051323: Setting env variables for tf import (only device [0, 1, 2] will be available)...\n",
      "2023-10-11 17:31:55.051483: Importing numpy...\n",
      "2023-10-11 17:31:55.193314: Importing pandas...\n",
      "2023-10-11 17:31:55.382353: Importing shutil...\n",
      "2023-10-11 17:31:55.382515: Importing subprocess...\n",
      "2023-10-11 17:31:55.382580: Importing tensorflow...\n",
      "Tensorflow version: 2.12.0\n",
      "2023-10-11 17:31:57.722465: Importing tensorflow_probability...\n",
      "Tensorflow probability version: 0.20.1\n",
      "2023-10-11 17:31:58.095919: Importing textwrap...\n",
      "2023-10-11 17:31:58.096011: Importing timeit...\n",
      "2023-10-11 17:31:58.096079: Importing traceback...\n",
      "2023-10-11 17:31:58.096141: Importing typing...\n",
      "2023-10-11 17:31:58.096220: Setting tf configs...\n",
      "2023-10-11 17:31:58.447897: Importing custom module...\n",
      "Successfully loaded GPU model: NVIDIA A40\n",
      "2023-10-11 17:31:59.714275: All modues imported successfully.\n",
      "Directory ../../results/MsplineN_new/ already exists.\n",
      "Directory ../../results/MsplineN_new/run_1/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 1/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_2/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 2/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_3/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 3/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_4/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 4/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_5/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 5/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_6/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 6/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_7/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 7/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_8/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 8/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_9/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 9/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_10/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 10/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_11/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 11/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_12/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 12/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_13/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 13/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_14/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 14/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_15/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 15/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_16/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 16/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_17/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 17/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_18/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 18/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_19/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 19/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_20/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 20/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_21/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 21/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_22/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 22/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_23/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 23/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_24/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 24/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_25/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 25/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_26/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 26/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_27/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 27/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_28/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 28/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_29/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 29/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_30/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 30/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_31/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 31/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_32/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 32/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_33/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 33/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_34/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 34/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_35/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 35/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_36/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 36/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_37/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 37/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_38/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 38/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_39/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 39/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_40/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 40/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_41/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 41/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_42/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 42/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_43/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 43/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_44/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 44/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_45/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 45/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_46/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 46/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_47/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 47/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_48/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 48/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_49/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 49/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_50/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 50/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_51/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 51/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_52/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 52/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_53/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 53/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_54/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 54/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_55/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 55/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_56/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 56/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_57/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 57/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_58/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 58/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_59/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 59/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_60/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 60/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_61/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 61/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_62/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 62/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_63/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 63/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_64/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 64/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_65/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 65/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_66/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 66/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_67/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 67/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_68/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 68/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_69/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 69/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_70/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 70/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_71/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 71/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_72/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 72/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_73/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 73/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_74/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 74/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_75/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 75/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_76/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 76/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_77/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 77/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_78/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 78/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_79/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 79/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_80/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 80/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_81/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 81/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_82/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 82/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_83/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 83/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_84/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 84/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_85/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 85/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_86/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 86/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_87/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 87/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_88/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 88/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_89/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 89/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_90/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 90/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_91/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 91/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_92/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 92/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_93/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 93/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_94/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 94/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_95/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 95/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_96/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 96/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_97/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 97/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_98/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 98/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_99/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 99/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_100/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 100/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_101/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 101/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_102/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 102/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_103/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 103/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_104/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 104/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_105/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 105/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_106/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 106/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_107/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 107/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_108/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 108/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_109/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 109/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_110/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 110/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_111/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 111/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_112/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 112/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_113/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 113/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_114/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 114/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_115/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 115/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_116/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 116/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_117/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 117/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_118/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 118/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_119/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 119/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_120/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 120/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_121/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 121/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_122/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 122/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_123/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 123/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_124/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 124/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_125/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 125/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_126/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 126/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_127/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 127/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_128/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 128/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_129/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 129/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_130/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 130/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_131/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 131/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_132/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 132/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_133/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 133/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_134/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 134/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_135/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 135/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_136/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 136/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_137/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 137/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_138/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 138/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_139/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 139/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_140/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 140/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_141/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 141/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_142/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 142/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_143/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 143/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_144/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 144/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_145/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 145/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_146/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 146/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_147/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 147/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_148/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 148/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_149/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 149/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_150/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 150/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_151/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 151/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_152/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 152/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_153/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 153/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_154/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 154/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_155/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 155/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_156/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 156/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_157/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 157/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_158/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 158/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_159/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 159/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_160/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 160/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_161/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 161/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_162/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 162/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_163/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 163/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_164/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 164/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_165/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 165/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_166/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 166/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_167/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 167/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_168/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 168/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_169/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 169/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_170/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 170/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_171/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 171/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_172/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 172/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_173/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 173/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_174/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 174/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_175/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 175/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_176/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 176/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_177/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 177/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_178/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 178/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_179/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 179/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_180/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 180/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_181/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 181/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_182/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 182/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_183/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 183/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_184/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 184/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_185/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 185/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_186/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 186/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_187/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 187/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_188/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 188/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_189/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 189/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_190/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 190/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_191/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 191/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_192/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 192/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_193/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 193/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_194/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 194/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_195/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 195/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_196/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 196/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_197/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 197/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_198/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 198/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_199/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 199/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_200/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 200/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_201/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 201/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_202/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 202/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_203/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 203/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_204/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 204/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_205/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 205/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_206/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 206/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_207/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 207/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_208/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 208/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_209/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 209/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_210/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 210/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_211/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 211/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_212/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 212/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_213/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 213/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_214/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 214/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_215/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 215/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_216/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 216/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_217/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 217/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_218/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 218/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_219/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 219/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_220/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 220/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_221/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 221/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_222/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 222/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_223/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 223/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_224/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 224/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_225/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 225/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_226/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 226/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_227/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 227/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_228/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 228/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_229/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 229/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_230/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 230/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_231/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 231/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_232/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 232/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_233/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 233/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_234/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 234/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_235/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 235/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_236/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 236/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_237/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 237/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_238/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 238/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_239/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 239/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_240/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 240/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_241/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 241/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_242/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 242/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_243/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 243/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_244/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 244/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_245/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 245/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_246/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 246/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_247/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 247/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_248/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 248/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_249/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 249/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_250/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 250/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_251/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 251/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_252/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 252/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_253/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 253/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_254/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 254/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_255/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 255/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_256/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 256/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_257/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 257/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_258/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 258/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_259/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 259/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_260/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 260/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_261/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 261/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_262/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 262/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_263/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 263/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_264/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 264/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_265/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 265/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_266/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 266/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_267/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 267/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_268/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 268/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_269/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 269/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_270/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 270/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_271/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 271/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_272/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 272/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_273/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 273/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_274/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 274/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_275/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 275/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_276/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 276/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_277/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 277/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_278/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 278/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_279/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 279/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_280/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 280/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_281/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 281/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_282/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 282/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_283/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 283/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_284/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 284/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_285/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 285/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_286/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 286/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_287/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 287/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_288/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 288/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_289/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 289/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_290/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 290/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_291/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 291/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_292/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 292/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_293/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 293/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_294/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 294/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_295/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 295/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_296/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 296/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_297/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 297/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_298/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 298/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_299/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 299/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_300/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 300/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_301/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 301/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_302/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 302/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_303/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 303/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_304/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 304/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_305/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 305/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_306/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 306/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_307/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 307/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_308/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 308/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_309/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 309/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_310/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 310/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_311/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 311/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_312/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 312/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_313/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 313/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_314/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 314/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_315/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 315/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_316/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 316/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_317/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 317/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_318/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 318/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_319/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 319/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_320/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 320/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_321/ already exists.\n",
      "Skipping it.\n",
      "Directory ../../results/MsplineN_new/run_321/weights already exists.\n",
      "===========\n",
      "Generating train data for run 321.\n",
      "===========\n",
      "Train data generated in 1.26 s.\n",
      "\n",
      "Building Trainer NFObject.\n",
      "\n",
      "\n",
      "--------------- Debub info ---------------\n",
      "Initializing Trainer with following parameters:\n",
      "base_distribution: tfp.distributions.Sample(\"SampleNormal\", batch_shape=[], event_shape=[1000], dtype=float32)\n",
      "flow: tfp.bijectors._Chain(\"chain_of_MAFspline_of_permute_of_MAFspline\", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])\n",
      "x_data_train shape: (100000, 1000)\n",
      "y_data_train shape: (100000, 0)\n",
      "io_kwargs: {'results_path': '../../results/MsplineN_new/run_321/', 'load_weights': True, 'load_results': False}\n",
      "data_kwargs: {'seed': 0}\n",
      "compiler_kwargs: {'optimizer': {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}, 'metrics': [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}], 'loss': {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}}\n",
      "callbacks_kwargs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '../../results/MsplineN_new/run_321/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]\n",
      "fit_kwargs: {'batch_size': 512, 'epochs': 1, 'validation_data': (array([[6.277253 , 6.974316 , 5.431759 , ..., 8.818214 , 1.8372726,\n",
      "        6.879843 ],\n",
      "       [8.248872 , 4.6043487, 5.1827307, ..., 2.8883853, 8.569977 ,\n",
      "        6.566897 ],\n",
      "       [7.511346 , 4.894093 , 5.228927 , ..., 2.959833 , 8.1193695,\n",
      "        7.606636 ],\n",
      "       ...,\n",
      "       [5.4142895, 7.32243  , 7.81261  , ..., 9.441056 , 0.9493766,\n",
      "        6.7277093],\n",
      "       [5.4575763, 6.765944 , 6.234851 , ..., 9.695062 , 1.5681067,\n",
      "        6.672586 ],\n",
      "       [5.466369 , 6.341171 , 6.2548084, ..., 9.017296 , 2.8553374,\n",
      "        6.70359  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}\n",
      "\n",
      "--------------- Debub info ---------------\n",
      "Defined attributes:\n",
      "self.base_dist: tfp.distributions.Sample(\"SampleNormal\", batch_shape=[], event_shape=[1000], dtype=float32)\n",
      "self.flow: tfp.bijectors._Chain(\"chain_of_MAFspline_of_permute_of_MAFspline\", batch_shape=[], min_event_ndims=1, bijectors=[MaskedAutoregressiveFlow, Permute, MaskedAutoregressiveFlow])\n",
      "self.nf_dist: tfp.distributions._TransformedDistribution(\"chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal\", batch_shape=[], event_shape=[1000], dtype=float32)\n",
      "self.io_kwargs: {'results_path': '../../results/MsplineN_new/run_321/', 'load_weights': True, 'load_results': False}\n",
      "self.results_path: ../../results/MsplineN_new/run_321\n",
      "self.data_kwargs: {'seed': 0}\n",
      "self.x_data: [[8.210789   4.3589015  5.1949253  ... 2.1186912  8.28666    6.44192   ]\n",
      " [5.776202   0.0413513  4.6274076  ... 4.7782993  6.688914   5.570342  ]\n",
      " [5.7263374  6.2561994  5.7377024  ... 8.820506   0.58727944 6.515802  ]\n",
      " ...\n",
      " [5.7884197  0.56533414 4.7867274  ... 4.878848   6.0022035  4.9900055 ]\n",
      " [5.9892163  0.222366   4.8566475  ... 4.5662537  6.433208   4.1020565 ]\n",
      " [7.8653784  4.6189337  5.157348   ... 2.6189103  7.542449   6.328924  ]]\n",
      "self.y_data: []\n",
      "self.ndims: 1000\n",
      "Model defined.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " log_prob_layer (LogProbLaye  (None,)                  6256304   \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,256,304\n",
      "Trainable params: 6,256,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model summary:  None\n",
      "self.log_prob: KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='log_prob_layer/chain_of_MAFspline_of_permute_of_MAFsplineSampleNormal_CONSTRUCTED_AT_top_level/log_prob/sub:0', description=\"created by layer 'log_prob_layer'\")\n",
      "self.model: <keras.engine.functional.Functional object at 0x7f76000ffdc0>\n",
      "self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}\n",
      "optimizer: <keras.optimizers.adam.Adam object at 0x7f75e834b220>\n",
      "type(optimizer): <class 'keras.optimizers.adam.Adam'>\n",
      "self.optimizer_config: {'class_name': 'Custom>Adam', 'config': {'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': True}}\n",
      "self.optimizer: <keras.optimizers.adam.Adam object at 0x7f75e834b220>\n",
      "self.loss_config: {'class_name': 'MinusLogProbLoss', 'config': {'name': 'MLP', 'ignore_nans': True, 'nan_threshold': 0.01, 'debug_print_mode': False}}\n",
      "self.loss: <Trainer.MinusLogProbLoss object at 0x7f75e834b3d0>\n",
      "self.metrics_configs: [{'class_name': 'MinusLogProbMetric', 'config': {'ignore_nans': True, 'debug_print_mode': False}}]\n",
      "self.metrics: [<Trainer.MinusLogProbMetric object at 0x7f75e834ba00>]\n",
      "self.compile_kwargs: {}\n",
      "self.callbacks_configs: [{'class_name': 'PrintEpochInfo', 'config': {}}, {'class_name': 'ModelCheckpoint', 'config': {'filepath': '/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_321/weights/best_weights.h5', 'monitor': 'val_loss', 'save_best_only': True, 'save_weights_only': True, 'verbose': 1, 'mode': 'auto', 'save_freq': 'epoch'}}, {'class_name': 'EarlyStopping', 'config': {'monitor': 'val_loss', 'min_delta': 0.0001, 'patience': 100, 'verbose': 1, 'mode': 'auto', 'baseline': None, 'restore_best_weights': True}}, {'class_name': 'ReduceLROnPlateau', 'config': {'monitor': 'val_loss', 'factor': 0.5, 'min_delta': 0.0001, 'patience': 50, 'min_lr': 1e-06}}, {'class_name': 'TerminateOnNaN', 'config': {}}]\n",
      "self.callbacks: [<keras.callbacks.LambdaCallback object at 0x7f75e834bf70>, <keras.callbacks.ModelCheckpoint object at 0x7f75e834bf10>, <keras.callbacks.EarlyStopping object at 0x7f75e82a42e0>, <keras.callbacks.ReduceLROnPlateau object at 0x7f75e82a4340>, <keras.callbacks.TerminateOnNaN object at 0x7f75e82a4310>]\n",
      "self.fit_kwargs: {'batch_size': 512, 'epochs': 1, 'validation_data': (array([[6.277253 , 6.974316 , 5.431759 , ..., 8.818214 , 1.8372726,\n",
      "        6.879843 ],\n",
      "       [8.248872 , 4.6043487, 5.1827307, ..., 2.8883853, 8.569977 ,\n",
      "        6.566897 ],\n",
      "       [7.511346 , 4.894093 , 5.228927 , ..., 2.959833 , 8.1193695,\n",
      "        7.606636 ],\n",
      "       ...,\n",
      "       [5.4142895, 7.32243  , 7.81261  , ..., 9.441056 , 0.9493766,\n",
      "        6.7277093],\n",
      "       [5.4575763, 6.765944 , 6.234851 , ..., 9.695062 , 1.5681067,\n",
      "        6.672586 ],\n",
      "       [5.466369 , 6.341171 , 6.2548084, ..., 9.017296 , 2.8553374,\n",
      "        6.70359  ]], dtype=float32), <tf.Tensor: shape=(30000, 0), dtype=float32, numpy=array([], shape=(30000, 0), dtype=float32)>), 'shuffle': True, 'verbose': 2}\n",
      "self.is_compiled: False\n",
      "self.training_time: 0.0\n",
      "self.history: {}\n",
      "Model successfully compiled.\n",
      "Found and loaded existing weights.\n",
      "===============\n",
      "Running 321/360 with hyperparameters:\n",
      "timestamp = 2023-10-11 17:32:08.690058\n",
      "ndims = 1000\n",
      "seed_train = 0\n",
      "nsamples_train = 100000\n",
      "nsamples_val = 30000\n",
      "nsamples_test = 100000\n",
      "bijector = MsplineN\n",
      "nbijectors = 2\n",
      "spline_knots = 8\n",
      "range_min = -16\n",
      "hidden_layers = 128-128-128\n",
      "trainable_parameters = 6256304\n",
      "epochs_input = 1\n",
      "batch_size = 512\n",
      "activation = relu\n",
      "training_device = NVIDIA A40\n",
      "===============\n",
      "\n",
      "Training model with initial learning rate 0.001...\n",
      "Train first sample: [ 8.21078873e+00  4.35890150e+00  5.19492531e+00  2.84795880e+00\n",
      "  6.23694658e+00  2.48332572e+00  6.01452780e+00  1.49544990e+00\n",
      "  1.56305087e+00  4.33542109e+00  3.63919592e+00  2.33469009e+00\n",
      "  7.12970674e-01  4.46248204e-01  1.55621916e-01  3.05101776e+00\n",
      "  4.20721769e+00  7.49161625e+00  3.96869850e+00  9.05481625e+00\n",
      "  4.47121114e-01  2.05655861e+00  3.52404070e+00  5.90453529e+00\n",
      "  8.73787975e+00  3.53096032e+00  2.76253247e+00  6.50554955e-01\n",
      "  8.03491688e+00  3.65929008e+00  4.93096781e+00  1.00386086e+01\n",
      "  5.29845119e-01  1.22730446e+00  7.25914860e+00  7.58729315e+00\n",
      "  7.71210337e+00  5.14168453e+00  9.58227444e+00  4.79759741e+00\n",
      "  6.05360174e+00 -3.22920084e-03  4.30121565e+00  7.28324509e+00\n",
      "  2.30840397e+00  9.72805214e+00  7.01551247e+00  3.15825868e+00\n",
      "  7.77309942e+00  1.27091324e+00  9.88113785e+00  5.76226175e-01\n",
      "  9.93493366e+00  6.19022250e-01  7.72215176e+00  1.45727849e+00\n",
      "  2.63241100e+00  7.56394577e+00  4.26764488e+00  1.30306756e+00\n",
      "  4.47696209e+00  4.10884666e+00  6.25260830e+00  7.17153311e+00\n",
      "  7.79660606e+00  4.86149597e+00  4.01030636e+00  1.48931491e+00\n",
      "  8.25993347e+00  6.99169493e+00  4.15396929e+00  5.40362930e+00\n",
      "  6.69921494e+00  1.80113685e+00 -2.28963286e-01  3.53704309e+00\n",
      "  5.97519684e+00  5.03495884e+00  5.96093559e+00  8.27530861e+00\n",
      "  5.11110401e+00  1.71916723e-01  1.00485516e+01  5.39971399e+00\n",
      "  6.97965956e+00  6.67698717e+00  9.53224850e+00  2.60424829e+00\n",
      "  6.92656088e+00  2.48836160e+00  1.50950837e+00  3.11806774e+00\n",
      "  3.62086797e+00  9.48242664e+00  2.35715413e+00  1.47683930e+00\n",
      "  6.57032585e+00  2.31288910e+00  5.07415724e+00  8.22896194e+00\n",
      "  2.67307043e+00  4.70531940e+00  5.81045723e+00  3.97613907e+00\n",
      "  1.00836468e+01  6.80917358e+00  7.91102648e+00  9.83973694e+00\n",
      "  3.97975469e+00  2.81087971e+00  6.61194921e-01  2.09042239e+00\n",
      "  1.80242181e+00  2.45311332e+00  7.75794411e+00  5.35263777e+00\n",
      "  6.36038160e+00  8.03104973e+00  2.23086929e+00  3.26186609e+00\n",
      "  7.10611820e+00  4.36860800e+00  5.38674593e-01  5.03258133e+00\n",
      "  8.79059315e+00  4.12663126e+00  2.96597481e+00  9.92143154e+00\n",
      "  6.63155603e+00  2.29087067e+00  9.67418194e-01  8.54019165e+00\n",
      "  7.32748413e+00  9.67831326e+00  3.08930302e+00  1.43350685e+00\n",
      "  7.23957300e+00  2.06572795e+00  1.31994998e+00  2.38906145e+00\n",
      "  8.15470123e+00  4.92610788e+00  4.60461289e-01  4.69264269e+00\n",
      "  7.11180496e+00  6.15540504e+00  5.58532810e+00  1.97622848e+00\n",
      "  8.55810928e+00  5.60682297e+00  6.50732088e+00  9.74595356e+00\n",
      "  3.70203424e+00  8.65994740e+00  3.66820455e-01 -1.19887441e-01\n",
      "  5.62859249e+00  3.21332264e+00  2.41353798e+00  2.97626567e+00\n",
      "  3.33519387e+00  7.60388327e+00  5.94638872e+00  7.90076303e+00\n",
      "  8.14614868e+00  8.43794918e+00  5.11629820e+00  4.45509529e+00\n",
      "  8.96594524e+00  6.83408117e+00  5.29020429e-01  5.47313118e+00\n",
      "  3.56114149e+00  9.86122417e+00 -8.47060025e-01  5.97660685e+00\n",
      "  7.56903505e+00  3.27315211e+00  9.39664459e+00  9.18616390e+00\n",
      "  9.16251087e+00  3.12576860e-01  5.81769562e+00  2.36430216e+00\n",
      "  8.91152668e+00  6.80723286e+00  5.49286032e+00  1.25512540e+00\n",
      "  6.51518726e+00  6.32031965e+00  9.03301430e+00  5.99218893e+00\n",
      "  9.68340588e+00  9.75206280e+00  6.48233700e+00  5.02287769e+00\n",
      "  4.40520668e+00  8.71606636e+00  1.15936518e-01  1.15061617e+00\n",
      "  1.13465822e+00  7.72926044e+00  3.59013176e+00  6.88610840e+00\n",
      "  6.62146950e+00  3.82466817e+00  5.06336927e+00  6.39645910e+00\n",
      "  9.77296638e+00  6.23589993e+00  6.13958120e+00  6.46353066e-01\n",
      "  7.98168039e+00  5.24744987e+00  8.84934807e+00  7.04309762e-01\n",
      "  4.59585285e+00  2.57471061e+00  2.76045990e+00  7.58923578e+00\n",
      "  6.31161690e+00  3.93680930e+00  3.41281295e-03  9.66006947e+00\n",
      "  9.57943439e+00  2.44953036e+00  7.60993719e-01  5.62422276e+00\n",
      "  9.45851040e+00  9.12294960e+00  5.39434481e+00  2.33969688e+00\n",
      "  3.87983751e+00  8.94526768e+00  4.94882011e+00  7.46908426e-01\n",
      "  3.23506546e+00  2.77883267e+00  1.57590222e+00  5.10829020e+00\n",
      "  9.52500534e+00  6.17966223e+00  1.10281193e+00  5.18856943e-01\n",
      "  2.46926522e+00  3.78143835e+00  6.96128178e+00  1.00144138e+01\n",
      "  3.66667557e+00  5.97449923e+00  9.95713520e+00  7.44061518e+00\n",
      "  6.02692795e+00  7.26248920e-01  3.43354082e+00  1.11553822e+01\n",
      "  1.09044552e+00  8.32242012e+00  7.46725512e+00  3.50707126e+00\n",
      "  4.66837549e+00  6.27135944e+00  7.01602077e+00  4.99376917e+00\n",
      "  1.22947979e+00  6.21938133e+00  4.57749987e+00  9.84504700e+00\n",
      "  3.30335212e+00  2.10937715e+00  8.59310150e-01  5.95748758e+00\n",
      "  7.51813459e+00  1.18187451e+00  3.30510187e+00  6.36148548e+00\n",
      "  4.50776958e+00  4.50498581e+00  1.05220985e+01  9.05682564e+00\n",
      "  6.02789402e+00  7.13881588e+00  7.25975084e+00  6.13174152e+00\n",
      "  2.50386310e+00  6.21227741e+00  6.38945484e+00  8.56712151e+00\n",
      "  3.63186836e-01  9.32480907e+00  5.54315186e+00 -3.98739636e-01\n",
      "  3.37429929e+00  7.95210361e+00  5.01406813e+00  9.63213921e+00\n",
      "  3.99637389e+00  2.97415352e+00  8.29203606e+00  6.00829792e+00\n",
      "  6.21376610e+00  7.23727989e+00  6.71069527e+00  5.01448536e+00\n",
      "  9.13507938e-01  6.87569332e+00  9.86827469e+00  4.45279694e+00\n",
      "  8.80540848e+00  5.50182295e+00  6.56988764e+00  8.22664070e+00\n",
      "  6.11226082e+00  9.90539372e-01  8.70905399e+00  2.35227823e+00\n",
      "  6.95939922e+00  4.88893890e+00  4.05508137e+00  1.27094746e+00\n",
      "  7.41610336e+00  9.57014084e-01  1.03208637e+01  8.77536011e+00\n",
      "  5.40437126e+00  3.66490221e+00  1.92103791e+00  5.05432844e+00\n",
      "  6.88084650e+00  2.36994123e+00  4.34519386e+00  1.71688604e+00\n",
      "  3.39162683e+00  1.85334861e+00  9.56473351e+00  6.55594063e+00\n",
      "  7.24569368e+00  9.57989931e-01  3.30405354e+00  8.91251564e+00\n",
      "  9.43958402e-01  2.91835928e+00  6.76908159e+00  6.41434669e+00\n",
      "  8.02711487e+00  8.37068748e+00  1.76286387e+00  2.83487058e+00\n",
      "  4.26155806e+00 -1.64624956e-02  5.80787063e-02  2.90215087e+00\n",
      "  4.82958937e+00  2.67308688e+00  8.74459743e+00  3.35418940e+00\n",
      "  9.50176620e+00  9.24923992e+00  5.82722712e+00  3.35397267e+00\n",
      "  3.11244607e+00  7.65114069e+00  2.58552289e+00  3.75996971e+00\n",
      "  5.17049551e+00  5.17774963e+00  9.58946896e+00  2.46264791e+00\n",
      "  4.03688717e+00  2.72447777e+00  2.75106120e+00  1.24247396e+00\n",
      "  2.18880701e+00  8.80450439e+00  2.16815996e+00  4.50869846e+00\n",
      "  9.47779369e+00  6.92755127e+00  5.21426487e+00  7.63384438e+00\n",
      "  1.33627713e+00  5.05314064e+00  8.01588058e-01  2.33411765e+00\n",
      "  2.04597259e+00  3.71735334e+00  3.99399781e+00  9.83961201e+00\n",
      "  2.91163659e+00  3.73780441e+00  7.86999273e+00  7.62870979e+00\n",
      "  7.85087109e+00  2.87814641e+00  5.46488953e+00  1.44017196e+00\n",
      "  2.16978312e+00  4.34651899e+00  7.40160513e+00  5.01842690e+00\n",
      "  8.79978561e+00  8.01273918e+00  6.23900414e-01  5.34396315e+00\n",
      "  5.84303570e+00  9.49287987e+00 -2.03253716e-01  5.55819988e+00\n",
      "  2.56452465e+00  5.52358687e-01  5.80285740e+00  8.33415508e+00\n",
      "  8.18197632e+00 -8.59678984e-02  3.97874522e+00  4.08348382e-01\n",
      "  2.77977419e+00  2.01314735e+00  2.23359156e+00  3.15110850e+00\n",
      "  3.16415262e+00  9.69314194e+00  3.46537042e+00  8.90620518e+00\n",
      "  1.80000591e+00  6.60689974e+00 -7.20865309e-01  4.78756142e+00\n",
      " -1.09752685e-01  9.03241920e+00  8.91885853e+00  6.74625039e-01\n",
      "  9.64687729e+00  5.28304863e+00  3.44711399e+00  9.08611012e+00\n",
      "  3.02275133e+00  4.11477327e+00  1.01315606e+00  7.55140066e+00\n",
      "  7.66734123e-01  4.76552486e+00  6.70099640e+00  7.79399300e+00\n",
      "  1.63697755e+00  6.94904470e+00  6.56399965e+00  4.96204281e+00\n",
      "  5.89378309e+00  5.83356380e-01  6.12774992e+00  4.05969334e+00\n",
      "  8.60876942e+00  3.77930760e+00  5.77260780e+00  4.28877592e+00\n",
      "  9.17067528e+00  2.55027103e+00  1.33500242e+00  8.23266697e+00\n",
      "  4.27657557e+00  5.92882109e+00  3.65143597e-01  1.05127277e+01\n",
      "  9.12497520e+00  4.73808956e+00  1.15415120e+00  4.24439526e+00\n",
      "  9.80254364e+00  7.13764381e+00  2.21075535e+00  4.46259594e+00\n",
      "  9.60248947e+00  6.37608194e+00  3.89600515e-01  6.30370569e+00\n",
      "  2.47006059e+00  9.89494145e-01  4.10520649e+00  5.44608831e+00\n",
      "  5.12012959e-01  4.04597473e+00  5.92461109e+00  8.09785938e+00\n",
      "  5.32709646e+00  5.15376234e+00  7.13395691e+00  8.32365990e+00\n",
      "  4.20349646e+00  6.05286407e+00  6.26060724e+00  6.60055876e-03\n",
      "  8.09364128e+00  3.49219418e+00  7.10890245e+00  4.91867685e+00\n",
      "  7.30661583e+00  6.67151976e+00  2.00603342e+00  6.53424406e+00\n",
      "  8.17309189e+00  2.37493563e+00  7.19742537e+00  6.21698093e+00\n",
      "  1.02654848e+01  4.02459478e+00  2.00096679e+00  3.60146332e+00\n",
      "  2.72641587e+00  7.55267096e+00  7.33097744e+00  6.48247480e+00\n",
      "  1.84161115e+00  8.67273045e+00  1.03891554e+01  5.11711931e+00\n",
      "  6.14349842e+00  4.63130045e+00  1.04338384e+00  3.16097307e+00\n",
      "  2.48957181e+00  2.08219433e+00  9.02428818e+00  7.58692598e+00\n",
      "  3.53382182e+00  2.87967825e+00  9.43597221e+00  1.85656917e+00\n",
      "  5.57112312e+00  9.00374889e-01  1.43457806e+00  5.70213127e+00\n",
      "  6.18463993e+00  5.21287870e+00  8.30662155e+00  9.78884792e+00\n",
      "  8.07082462e+00  4.94385624e+00  9.57595062e+00  4.81561422e-01\n",
      "  5.93677044e+00  6.03051233e+00  1.27146268e+00  9.59977341e+00\n",
      "  3.53188229e+00  5.92599010e+00  8.90297794e+00  5.73115826e+00\n",
      "  8.29036653e-01  6.28442287e+00  4.10012245e+00  8.16020679e+00\n",
      "  9.57242489e+00  8.73237801e+00  3.82743692e+00  7.33982182e+00\n",
      "  9.39437389e+00  5.32039928e+00  4.49351358e+00  7.41679072e-01\n",
      "  7.33104944e+00  8.68616486e+00  2.54391122e+00  2.88136458e+00\n",
      "  5.05854321e+00  4.12581384e-01  7.20838428e-01  4.39249325e+00\n",
      "  2.12579203e+00  5.69973421e+00  3.94032979e+00  1.01283722e+01\n",
      "  9.79717064e+00  2.52009940e+00  8.86107635e+00  8.79512429e-01\n",
      "  4.84236622e+00  1.72291732e+00  3.82897258e+00  6.94665861e+00\n",
      "  4.18651247e+00  8.54575062e+00  7.19269276e+00  9.72444630e+00\n",
      "  5.51988173e+00  8.01771069e+00  3.28205919e+00  3.97813463e+00\n",
      "  4.18136644e+00  5.16412115e+00  1.75697100e+00  5.15417719e+00\n",
      "  1.50469279e+00  9.25226021e+00  4.35976595e-01  4.19854736e+00\n",
      "  3.64054823e+00  1.06782198e-01  8.30288601e+00  7.06305122e+00\n",
      "  1.87979758e+00  6.35672998e+00  8.16109753e+00  6.51096630e+00\n",
      "  5.61127961e-01  6.76316595e+00  6.57550716e+00  7.76742983e+00\n",
      "  5.40051842e+00  4.99695921e+00  1.05247574e+01  7.60159779e+00\n",
      "  5.60209799e+00  3.34395909e+00  9.19912910e+00  4.68194294e+00\n",
      "  1.00466835e+00  5.51672554e+00  8.06357193e+00  4.60604143e+00\n",
      "  7.99039245e-01  6.11217165e+00  9.98776340e+00  7.64210176e+00\n",
      "  6.11796856e+00  9.89960003e+00  7.96584511e+00  6.26075697e+00\n",
      "  4.63107634e+00  7.38753414e+00  6.49842548e+00  7.23403335e-01\n",
      "  7.84123564e+00  3.43258095e+00  5.87750053e+00  8.16937256e+00\n",
      "  4.84820747e+00  1.59829724e+00  4.18775225e+00  1.30482543e+00\n",
      "  6.89824677e+00  9.70094967e+00  7.83443594e+00  4.79529858e+00\n",
      "  6.26568747e+00  3.08977580e+00  5.72115278e+00  2.92952847e+00\n",
      "  7.45006084e+00  2.38916183e+00  9.71957111e+00  6.54768562e+00\n",
      "  6.25139415e-01 -2.21325979e-02  1.01162004e+01  1.64097524e+00\n",
      "  3.30466270e+00  2.32712507e+00  9.82605267e+00  5.42485619e+00\n",
      "  4.57557726e+00  5.65397930e+00  2.95226574e+00  6.00716829e+00\n",
      "  4.69566488e+00  1.86493647e+00  5.55787706e+00  4.29599905e+00\n",
      "  8.97355652e+00  4.49551582e+00  5.21416712e+00  7.87060261e+00\n",
      "  4.67125940e+00  9.76075363e+00  8.19973755e+00  8.41541100e+00\n",
      "  9.90537739e+00  2.93996453e+00  5.85271358e+00  7.30432892e+00\n",
      "  7.22648525e+00  9.17044544e+00  2.83920431e+00  3.20150447e+00\n",
      "  8.31029034e+00  7.78128242e+00  2.25734663e+00  5.91900253e+00\n",
      "  7.87056684e+00  3.05571938e+00  3.93086529e+00  5.76315022e+00\n",
      "  5.30861235e+00  7.55313301e+00 -1.47460684e-01  4.09288597e+00\n",
      "  1.74171937e+00  4.78674221e+00  7.88887119e+00  7.54741371e-01\n",
      "  1.54648781e+00  7.28928089e+00  7.57703447e+00  5.61207056e+00\n",
      "  9.85756111e+00  4.10112953e+00  1.57129598e+00  6.85865021e+00\n",
      "  6.33887672e+00  6.33726215e+00  5.35512924e+00  8.78589249e+00\n",
      "  8.93958569e-01 -1.22548640e-01  1.54779208e+00  2.83668208e+00\n",
      "  5.92615891e+00  5.92532015e+00  2.29801345e+00  4.49938583e+00\n",
      "  4.36498499e+00  5.37602377e+00  8.03752041e+00  5.66677046e+00\n",
      "  8.83142376e+00  1.65858328e+00  5.42761660e+00  8.26859760e+00\n",
      "  1.79626775e+00  4.40248251e+00  5.96399355e+00  2.07387352e+00\n",
      "  7.58685493e+00  6.19924068e-01  9.63695049e+00  4.80245113e+00\n",
      "  2.84362292e+00  1.11408031e+00  4.65407324e+00  6.60547924e+00\n",
      "  1.22691751e+00  3.05578947e+00  1.09281607e+01  6.40130091e+00\n",
      "  2.10371280e+00  1.27200794e+00  8.89848232e+00  2.80182910e+00\n",
      "  2.19280529e+00  1.05606747e+01  2.94065785e+00  1.69049454e+00\n",
      "  5.48146868e+00  4.31994724e+00  9.06744099e+00  1.15592277e+00\n",
      " -7.79310703e-01  1.04373407e+00  8.86706924e+00  4.28514481e+00\n",
      "  1.81781006e+00  5.78969526e+00  5.54994345e+00  2.30405951e+00\n",
      "  5.54053879e+00  2.74468279e+00  2.27062321e+00  4.07878542e+00\n",
      "  2.84625888e+00  2.04214787e+00  8.94879723e+00  6.88817441e-01\n",
      "  2.71495771e+00  3.84625363e+00  2.55016398e+00  2.09636283e+00\n",
      "  7.99209976e+00  3.07564521e+00  1.11745620e+00  5.30355263e+00\n",
      "  9.93744850e-01  2.74349833e+00  8.41612911e+00  4.34795761e+00\n",
      "  6.55439472e+00  6.15104818e+00  5.19303381e-01  6.36637783e+00\n",
      "  8.49066544e+00  8.24014544e-01  6.90668011e+00  7.08179665e+00\n",
      "  9.01312637e+00  3.36554408e+00  2.87336349e+00  6.86589861e+00\n",
      " -2.01100767e-01  7.31349230e+00  8.66450596e+00  4.29815626e+00\n",
      "  3.38823771e+00  3.01338983e+00  8.08154404e-01  1.78297210e+00\n",
      "  9.61242580e+00  8.81327534e+00  2.97019339e+00  8.63016319e+00\n",
      "  3.02107668e+00  2.72670150e+00  2.13139439e+00  8.94742870e+00\n",
      "  9.83511925e+00  3.19685555e+00  6.81030130e+00  3.50014639e+00\n",
      "  1.05297625e+00  4.07330465e+00  5.53509521e+00  1.18256664e+00\n",
      "  8.23826122e+00  5.53470898e+00  2.24809480e+00  5.40734196e+00\n",
      "  7.84483671e+00  2.75392199e+00  7.62425852e+00  4.27786589e+00\n",
      "  9.72611332e+00  8.83753872e+00  3.43726850e+00  1.27960294e-01\n",
      "  7.29834032e+00  2.04023504e+00  1.30689442e+00  9.04135704e+00\n",
      "  1.00866823e+01  2.58009624e+00  3.01804805e+00  1.68803823e+00\n",
      "  4.80738878e+00  8.68211079e+00  6.73749733e+00  8.63989162e+00\n",
      "  2.21114421e+00  7.04848576e+00  9.34753704e+00  2.76184368e+00\n",
      "  6.90854836e+00  4.05415773e+00  3.81649780e+00  9.40583229e+00\n",
      "  4.05083704e+00  8.92635822e-01  3.82358503e+00  4.43289518e+00\n",
      "  7.26910877e+00  8.82122993e+00  8.22476578e+00  9.33980370e+00\n",
      "  4.71105146e+00  6.95373154e+00  3.06833911e+00 -4.22824502e-01\n",
      "  3.65492988e+00  6.86570597e+00  2.05108023e+00  8.74809170e+00\n",
      "  8.31052685e+00  1.87380075e+00  2.81262565e+00  8.66123104e+00\n",
      "  3.31760716e+00  3.31471944e+00  3.48811197e+00  7.28613329e+00\n",
      " -9.66772735e-02 -7.69796014e-01  6.32836771e+00  3.86802888e+00\n",
      "  5.99920893e+00  2.40654874e+00  9.12174988e+00  8.34914875e+00\n",
      "  7.07096219e-01  7.57762194e+00  9.58280849e+00  8.65084171e+00\n",
      "  6.67687321e+00  1.21811235e+00  5.86707783e+00  3.30112028e+00\n",
      "  1.01402960e+01  7.17766523e+00  5.74374008e+00  6.99432039e+00\n",
      "  4.40368319e+00  2.86542940e+00  9.42987251e+00  3.30265784e+00\n",
      "  3.83230895e-01  4.20491457e+00  8.71614361e+00  7.57816601e+00\n",
      "  9.77553654e+00  6.46106720e-01  9.44217777e+00  4.46305180e+00\n",
      "  4.83198547e+00  3.06845570e+00  1.06641746e+00  4.49923372e+00\n",
      "  7.57343435e+00  5.86748123e-03  1.58664107e+00  5.31323195e-01\n",
      "  8.55088329e+00  6.48872995e+00  1.54820132e+00  7.71537733e+00\n",
      "  8.20388412e+00  9.80402565e+00  9.79537868e+00 -8.38677704e-01\n",
      "  5.94942427e+00  2.88661289e+00  5.26643085e+00  3.18921828e+00\n",
      "  7.79481411e-01  4.42821693e+00  5.33531380e+00  9.32881355e+00\n",
      "  2.65765786e-02  3.08747840e+00  8.52437019e+00  6.85948515e+00\n",
      "  8.21984768e+00  6.24451685e+00  7.30141687e+00  4.90936804e+00\n",
      "  2.20824790e+00  8.48395348e+00  5.67844057e+00  1.24840343e+00\n",
      "  8.05260468e+00  9.64081573e+00  3.07099938e+00  3.18240905e+00\n",
      "  9.12044704e-01  5.96499348e+00  9.19813156e+00  3.36040854e-01\n",
      "  4.73263264e+00  1.30067658e+00  5.19609153e-01  6.70743704e+00\n",
      "  8.23411751e+00  3.52812862e+00  8.22581482e+00  1.19572031e+00\n",
      "  2.63071656e+00  9.79853821e+00  4.98861170e+00  6.00117397e+00\n",
      "  3.19664389e-01  1.32244027e+00  6.05848253e-01  7.35753870e+00\n",
      "  1.13696325e+00  8.69066429e+00  3.58892393e+00  7.88068628e+00\n",
      "  3.04448676e+00  2.65313506e+00  9.56735551e-01  2.75976801e+00\n",
      "  4.98727465e+00  7.08365965e+00  5.05365181e+00  9.17652988e+00\n",
      "  5.92350817e+00  1.26345801e+00  3.95679140e+00  7.46081781e+00\n",
      "  2.64605379e+00  6.97033882e+00  5.93741179e+00  1.01776525e-01\n",
      "  7.47330189e+00  5.93837404e+00  8.12254488e-01  3.60206747e+00\n",
      "  3.23938537e+00  8.24193764e+00  3.56294060e+00  9.41426849e+00\n",
      "  5.64243269e+00  2.11869121e+00  8.28666019e+00  6.44191980e+00]\n",
      "2023-10-11 17:32:48.669 \n",
      "Epoch 1/1 \n",
      "\t loss: 447.1331, MinusLogProbMetric: 447.1331, val_loss: 417.9531, val_MinusLogProbMetric: 417.9531\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 417.95306, saving model to /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/results/MsplineN_new/run_321/weights/best_weights.h5\n",
      "196/196 - 40s - loss: 447.1331 - MinusLogProbMetric: 447.1331 - val_loss: 417.9531 - val_MinusLogProbMetric: 417.9531 - lr: 0.0010 - 40s/epoch - 203ms/step\n",
      "Training succeeded with seed 0.\n",
      "Model trained in 40.00 s.\n",
      "\n",
      "===========\n",
      "Computing predictions\n",
      "===========\n",
      "\n",
      "Computing metrics...\n",
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n",
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n",
      "\n",
      "------------------------------------------\n",
      "Starting KS tests calculation...\n",
      "Running TF KS tests...\n",
      "niter = 10\n",
      "batch_size = 100000\n",
      "The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.\n",
      "The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.\n",
      "nchunks = 10\n",
      "Iterating from 0 to 1 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 1 to 2 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 2 to 3 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 3 to 4 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 4 to 5 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f79c3b9a560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iterating from 5 to 6 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f79c4b84670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iterating from 6 to 7 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 7 to 8 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 8 to 9 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 9 to 10 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: (100000, 1000)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "KS tests calculation completed in 18481.81169636501 seconds.\n",
      "\n",
      "------------------------------------------\n",
      "Starting SWD metric calculation...\n",
      "Running TF SWD calculation...\n",
      "niter = 10\n",
      "batch_size = 100000\n",
      "                            ===========\n",
      "                            Run 321/360 failed.\n",
      "                            Exception type: NameError\n",
      "                            Exception message: in user code:\n",
      "\n",
      "File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/swd_metrics.py\", line 475, in body  *\n",
      "    dist_1_k: tf.Tensor = tf.cond(tf.equal(tf.shape(dist_1_num[0])[0],0), # type: ignore\n",
      "File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/swd_metrics.py\", line 449, in set_dist_num_from_symb  *\n",
      "    dist_num: tf.Tensor = generate_and_clean_data(dist, nsamples, 100, dtype = self.Inputs.dtype, seed = int(seed), mirror_strategy = self.Inputs.mirror_strategy) # type: ignore\n",
      "\n",
      "NameError: name 'generate_and_clean_data' is not defined\n",
      "\n",
      "                            Stack trace: ['File : /tmp/ipykernel_8005/3761596295.py , Line : 678, Func.Name : <module>, Message : results_dict, DataInputs, prediction_time, total_time = prediction_function(hyperparams_dict = hyperparams_dict,', 'File : /tmp/ipykernel_8005/3761596295.py , Line : 364, Func.Name : prediction_function, Message : SWDMetric.compute(nslices = n_slices_factor*ndims)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/swd_metrics.py , Line : 266, Func.Name : compute, Message : self.Test_np(nslices = nslices)', 'File : /mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/swd_metrics.py , Line : 515, Func.Name : Test_tf, Message : ', 'File : /local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py , Line : 153, Func.Name : error_handler, Message : raise e.with_traceback(filtered_tb) from None', 'File : /tmp/__autograph_generated_fileqqbpyk2d.py , Line : 52, Func.Name : tf__compute_test, Message : (_, res) = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.autograph_artifact(lambda i, _: ag__.ld(i) < ag__.ld(niter)), ag__.ld(body), [0, ag__.ld(res)]), None, fscope)', 'File : /tmp/__autograph_generated_fileqqbpyk2d.py , Line : 35, Func.Name : body, Message : dist_1_k: ag__.ld(tf).Tensor = ag__.converted_call(ag__.ld(tf).cond, (ag__.converted_call(ag__.ld(tf).equal, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(dist_1_num)[0],), None, fscope_1)[0], 0), None, fscope_1),), dict(true_fn=ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(set_dist_num_from_symb), (ag__.ld(dist_1_symb),), dict(nsamples=ag__.ld(batch_size), seed=ag__.ld(seed_dist_1)), fscope_1)), false_fn=ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(return_dist_num), (ag__.ld(dist_1_num)[ag__.ld(i) * ag__.ld(batch_size):(ag__.ld(i) + 1) * ag__.ld(batch_size), :],), None, fscope_1))), fscope_1)', 'File : /tmp/__autograph_generated_fileqqbpyk2d.py , Line : 35, Func.Name : <lambda>, Message : dist_1_k: ag__.ld(tf).Tensor = ag__.converted_call(ag__.ld(tf).cond, (ag__.converted_call(ag__.ld(tf).equal, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(dist_1_num)[0],), None, fscope_1)[0], 0), None, fscope_1),), dict(true_fn=ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(set_dist_num_from_symb), (ag__.ld(dist_1_symb),), dict(nsamples=ag__.ld(batch_size), seed=ag__.ld(seed_dist_1)), fscope_1)), false_fn=ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(return_dist_num), (ag__.ld(dist_1_num)[ag__.ld(i) * ag__.ld(batch_size):(ag__.ld(i) + 1) * ag__.ld(batch_size), :],), None, fscope_1))), fscope_1)', 'File : /tmp/__autograph_generated_file56zadk3z.py , Line : 12, Func.Name : tf__set_dist_num_from_symb, Message : dist_num: ag__.ld(tf).Tensor = ag__.converted_call(ag__.ld(generate_and_clean_data), (ag__.ld(dist), ag__.ld(nsamples), 100), dict(dtype=ag__.ld(self).Inputs.dtype, seed=ag__.converted_call(ag__.ld(int), (ag__.ld(seed),), None, fscope), mirror_strategy=ag__.ld(self).Inputs.mirror_strategy), fscope)']\n",
      "                            ===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_322/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 322/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_323/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 323/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_324/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 324/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_325/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 325/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_326/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 326/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_327/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 327/360 already exists. Skipping it.\n",
      "===========\n",
      "\n",
      "Directory ../../results/MsplineN_new/run_328/ already exists.\n",
      "Skipping it.\n",
      "===========\n",
      "Run 328/360 already exists. Skipping it.\n",
      "===========\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Run different than 321. Skipping.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=632'>633</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=633'>634</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=634'>635</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRun different than \u001b[39m\u001b[39m{\u001b[39;00mrun_to_evaluate\u001b[39m}\u001b[39;00m\u001b[39m. Skipping.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=635'>636</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=636'>637</a>\u001b[0m     dummy_file_path: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_to_results,\u001b[39m'\u001b[39m\u001b[39mrunning.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Run different than 321. Skipping."
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "######################################### Initialize #########################################\n",
    "##############################################################################################\n",
    "\n",
    "visible_devices = [0,1,2]\n",
    "import datetime\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing os...\")\n",
    "import os\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing sys...\")\n",
    "import sys\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing and initializing argparse...\")\n",
    "if not any(\"ipykernel\" in arg for arg in sys.argv):\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-v\", \"--visible_devices\", help=\"Set visible devices\", nargs='*', type=int, default=visible_devices)\n",
    "    args = parser.parse_args()\n",
    "    visible_devices = args.visible_devices if args.visible_devices else visible_devices\n",
    "print(\"Visible devices:\", visible_devices)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing timer from timeit...\")\n",
    "from timeit import default_timer as timer\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Setting env variables for tf import (only device\", visible_devices, \"will be available)...\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(i) for i in visible_devices])\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2'\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing numpy...\")\n",
    "import numpy as np\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing pandas...\")\n",
    "import pandas as pd\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing shutil...\")\n",
    "import shutil\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing subprocess...\")\n",
    "import subprocess\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing tensorflow...\")\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing tensorflow_probability...\")\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "print(\"Tensorflow probability version:\", tfp.__version__)\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing textwrap...\")\n",
    "import textwrap\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing timeit...\")\n",
    "from timeit import default_timer as timer\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing traceback...\")\n",
    "import traceback\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing typing...\")\n",
    "from typing import List, Tuple, Dict, Union, Optional, Any\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Setting tf configs...\")\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu_device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_device, True)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"Importing custom module...\")\n",
    "\n",
    "sys.path.append('../../../code')\n",
    "import Bijectors, Distributions, MixtureDistributions, Plotters, Trainer, Utils # type: ignore\n",
    "import GenerativeModelsMetrics as GMetrics # type: ignore\n",
    "\n",
    "def get_gpu_info() -> Optional[List[str]]:\n",
    "    try:\n",
    "        gpu_info: str = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=gpu_name\", \"--format=csv,noheader\"]).decode('utf-8')\n",
    "        return gpu_info.strip().split('\\n')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "gpu_models: Optional[List[str]] = get_gpu_info()\n",
    "if gpu_models:\n",
    "    training_device: str = gpu_models[0]\n",
    "    print(\"Successfully loaded GPU model: {}\".format(training_device))\n",
    "else:\n",
    "    training_device = 'undetermined'\n",
    "    print(\"Failed to load GPU model. Defaulting to 'undetermined'.\")\n",
    "    \n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")+\":\", \"All modues imported successfully.\")\n",
    "\n",
    "##############################################################################################\n",
    "####################################### Helper functions #####################################\n",
    "##############################################################################################\n",
    "\n",
    "def MixtureGaussian(ncomp: int,\n",
    "                    ndims: int,\n",
    "                    seed: int = 0) -> tfp.distributions.Mixture:\n",
    "    targ_dist: tfp.distributions.Mixture = MixtureDistributions.MixMultiNormal1(ncomp,ndims,seed=seed)\n",
    "    return targ_dist\n",
    "\n",
    "def get_io_kwargs(path_to_results: str) -> Dict[str,Any]:\n",
    "    return {'results_path': path_to_results,\n",
    "            'load_weights': True,\n",
    "            'load_results': False}\n",
    "    \n",
    "def get_data_kwargs(seed: int = 0) -> Dict[str,Any]:\n",
    "    return {'seed': seed}\n",
    "\n",
    "def get_compiler_kwargs(lr: float,\n",
    "                        ignore_nans: bool,\n",
    "                        nan_threshold: float\n",
    "                       ) -> Dict[str,Any]:\n",
    "    compiler_kwargs = {'optimizer': {'class_name': 'Custom>Adam', # this gives the new Adam optimizer\n",
    "                                     'config': {'learning_rate': lr,\n",
    "                                                'beta_1': 0.9,\n",
    "                                                'beta_2': 0.999,\n",
    "                                                'epsilon': 1e-07,\n",
    "                                                'amsgrad': True}},\n",
    "                       'metrics': [{'class_name': 'MinusLogProbMetric',\n",
    "                                    'config': {'ignore_nans': ignore_nans, \n",
    "                                               'debug_print_mode': False}}],\n",
    "                       'loss': {'class_name': 'MinusLogProbLoss', \n",
    "                                'config': {'name': \"MLP\", \n",
    "                                           'ignore_nans': ignore_nans, \n",
    "                                           'nan_threshold': nan_threshold, \n",
    "                                           'debug_print_mode': False}}}\n",
    "    return compiler_kwargs\n",
    "    \n",
    "def get_callbacks_kwargs(checkpoint_path: str,\n",
    "                         es_min_delta: float,\n",
    "                         es_patience: int,\n",
    "                         lr_reduce_factor: float,\n",
    "                         lr_min_delta: float,\n",
    "                         lr_patience: int,\n",
    "                         min_lr: float\n",
    "                         ) -> List[Dict[str,Any]]:\n",
    "    callbacks_kwargs = [{'class_name': 'PrintEpochInfo',\n",
    "                         'config': {}},\n",
    "                        #{'class_name': 'HandleNaNCallback',\n",
    "                        # 'config': {'checkpoint_path': checkpoint_path,\n",
    "                        #            'lr_reduction_factor': lr_reduce_factor_on_nan,\n",
    "                        #            'random_seed_var': np.random.randint(1000000)}},\n",
    "                        #{'class_name': 'TerminateOnNaNFractionCallback',\n",
    "                        # 'config': {'threshold': 0.1,\n",
    "                        #            'validation_data': X_data_val}},\n",
    "                        {'class_name': 'ModelCheckpoint',\n",
    "                         'config': {'filepath': checkpoint_path,\n",
    "                                    'monitor': 'val_loss',\n",
    "                                    'save_best_only': True,\n",
    "                                    'save_weights_only': True,\n",
    "                                    'verbose': 1,\n",
    "                                    'mode': 'auto',\n",
    "                                    'save_freq': 'epoch'}},\n",
    "                        {'class_name': 'EarlyStopping',\n",
    "                         'config': {'monitor': 'val_loss', \n",
    "                                    'min_delta': es_min_delta, \n",
    "                                    'patience': es_patience, \n",
    "                                    'verbose': 1,\n",
    "                                    'mode': 'auto', \n",
    "                                    'baseline': None, \n",
    "                                    'restore_best_weights': True}},\n",
    "                        {'class_name': 'ReduceLROnPlateau', \n",
    "                         'config': {'monitor': 'val_loss', \n",
    "                                    'factor': lr_reduce_factor, \n",
    "                                    'min_delta': lr_min_delta, \n",
    "                                    'patience': lr_patience, \n",
    "                                    'min_lr': min_lr}},\n",
    "                        {'class_name': 'TerminateOnNaN', 'config': {}}\n",
    "                        ]\n",
    "    return callbacks_kwargs\n",
    "\n",
    "def get_fit_kwargs(batch_size: int,\n",
    "                   epochs_input: int,\n",
    "                   validation_data: Tuple[Union[np.ndarray,tf.Tensor],Union[np.ndarray,tf.Tensor]],\n",
    "                   shuffle: bool,\n",
    "                   verbose: int\n",
    "                  ) -> Dict[str,Any]:\n",
    "    fit_kwargs = {'batch_size': batch_size, \n",
    "                  'epochs': epochs_input, \n",
    "                  'validation_data': validation_data,\n",
    "                  'shuffle': shuffle, \n",
    "                  'verbose': verbose}\n",
    "    return fit_kwargs\n",
    "\n",
    "def train_function(seeds: List[int],\n",
    "                   nsamples: List[int],\n",
    "                   run_number: int,\n",
    "                   base_dist: tfp.distributions.Distribution,\n",
    "                   targ_dist: tfp.distributions.Distribution,\n",
    "                   hyperparams_dict: Dict[str, Any],\n",
    "                   n_runs: int,\n",
    "                   ndims: int,\n",
    "                   bijector_name: str,\n",
    "                   nbijectors: int,\n",
    "                   spline_knots: Union[int,str],\n",
    "                   range_min: int,\n",
    "                   hidden_layers: List[int],\n",
    "                   batch_size: int,\n",
    "                   epochs_input: int,\n",
    "                   lr_orig: float,\n",
    "                   es_min_delta: float,\n",
    "                   es_patience: int,\n",
    "                   lr_reduce_factor: float,\n",
    "                   lr_min_delta: float,\n",
    "                   lr_patience: int,\n",
    "                   min_lr: float,\n",
    "                   activation: str,\n",
    "                   regulariser: Optional[str],\n",
    "                   eps_regulariser: float,\n",
    "                   training_device: str,\n",
    "                   path_to_results: str,\n",
    "                   checkpoint_path: str,\n",
    "                   max_retry: int,\n",
    "                   debug_print_mode: bool,\n",
    "                   nan_threshold: float,\n",
    "                  ) -> Tuple[Dict[str, Any], Trainer.Trainer, int, float]:\n",
    "    succeeded = False\n",
    "    retry: int = 0\n",
    "    lr: float = lr_orig\n",
    "    while not succeeded:\n",
    "        seed_train: int\n",
    "        seed_test: int\n",
    "        seed_dist: int\n",
    "        seed_metrics: int\n",
    "        seed_train, seed_test, seed_dist, seed_metrics = seeds\n",
    "        seed_test = seed_train + 1                     \n",
    "        Utils.reset_random_seeds(seed = seed_train)\n",
    "        nsamples_train: int\n",
    "        nsamples_val: int\n",
    "        nsamples_test: int\n",
    "        nsamples_train, nsamples_val, nsamples_test = nsamples\n",
    "        X_data_train: tf.Tensor\n",
    "        X_data_val: tf.Tensor\n",
    "        Y_data_train: tf.Tensor\n",
    "        Y_data_val: tf.Tensor\n",
    "        X_data_train, X_data_val, Y_data_train, Y_data_val = Utils.generate_train_data(run_number = run_number,\n",
    "                                                                                       targ_dist = targ_dist,\n",
    "                                                                                       nsamples_train = nsamples_train,\n",
    "                                                                                       nsamples_val = nsamples_val,\n",
    "                                                                                       seed_train = seed_train)\n",
    "        bijector: tfp.bijectors.Bijector = Bijectors.ChooseBijector(bijector_name = bijector_name,\n",
    "                                                                    ndims = ndims,\n",
    "                                                                    spline_knots = spline_knots,\n",
    "                                                                    nbijectors = nbijectors,\n",
    "                                                                    range_min = range_min,\n",
    "                                                                    hidden_layers = hidden_layers,\n",
    "                                                                    activation = activation,\n",
    "                                                                    regulariser = regulariser,\n",
    "                                                                    eps_regulariser = eps_regulariser)\n",
    "        Utils.save_bijector_info(path_to_results, bijector)\n",
    "        print(\"Building Trainer NFObject.\\n\")\n",
    "        NFObject: Trainer.Trainer = Trainer.Trainer(base_distribution = base_dist,\n",
    "                                                    flow = bijector, \n",
    "                                                    x_data_train = X_data_train,\n",
    "                                                    y_data_train = Y_data_train,\n",
    "                                                    io_kwargs = get_io_kwargs(path_to_results = path_to_results),\n",
    "                                                    data_kwargs = get_data_kwargs(seed = seed_train),\n",
    "                                                    compiler_kwargs = get_compiler_kwargs(lr = lr,\n",
    "                                                                                          ignore_nans = True,\n",
    "                                                                                          nan_threshold = nan_threshold),\n",
    "                                                    callbacks_kwargs = get_callbacks_kwargs(checkpoint_path = checkpoint_path,\n",
    "                                                                                            es_min_delta = es_min_delta,\n",
    "                                                                                            es_patience = es_patience,\n",
    "                                                                                            lr_reduce_factor = lr_reduce_factor,\n",
    "                                                                                            lr_min_delta = lr_min_delta,\n",
    "                                                                                            lr_patience = lr_patience,\n",
    "                                                                                            min_lr = min_lr),\n",
    "                                                    fit_kwargs = get_fit_kwargs(batch_size = batch_size,\n",
    "                                                                                epochs_input = epochs_input,\n",
    "                                                                                validation_data = (X_data_val, Y_data_val),\n",
    "                                                                                shuffle = True,\n",
    "                                                                                verbose = 2),\n",
    "                                                    debug_print_mode = debug_print_mode)\n",
    "        trainable_params: int = NFObject.trainable_params\n",
    "        non_trainable_params: int = NFObject.non_trainable_params\n",
    "        hyperparams_dict = Utils.update_hyperparams_dict(hyperparams_dict = hyperparams_dict,\n",
    "                                                         run_number = run_number,\n",
    "                                                         n_runs = n_runs,\n",
    "                                                         seeds = [seed_train, seed_test, seed_dist, seed_metrics],\n",
    "                                                         nsamples = [nsamples_train, nsamples_val, nsamples_test],\n",
    "                                                         ndims = ndims,\n",
    "                                                         corr = None,\n",
    "                                                         bijector_name = bijector_name,\n",
    "                                                         nbijectors = nbijectors,\n",
    "                                                         spline_knots = spline_knots,\n",
    "                                                         range_min = range_min,\n",
    "                                                         hllabel = '-'.join(str(e) for e in hidden_layers),\n",
    "                                                         trainable_parameters = trainable_params,\n",
    "                                                         non_trainable_parameters = non_trainable_params,\n",
    "                                                         batch_size = batch_size,\n",
    "                                                         epochs_input = epochs_input,\n",
    "                                                         activation = activation,\n",
    "                                                         regulariser = regulariser,\n",
    "                                                         eps_regulariser = eps_regulariser,\n",
    "                                                         training_device = training_device)\n",
    "        Utils.save_hyperparams_dict(path_to_results, hyperparams_dict)\n",
    "        print(f\"Training model with initial learning rate {lr}...\")\n",
    "        print(\"Train first sample:\", X_data_train[0]) # type: ignore\n",
    "        NFObject.train()\n",
    "        training_time: float = NFObject.training_time # type: ignore\n",
    "        loss_history = list(NFObject.history['loss'])\n",
    "        if np.isnan(loss_history).any():\n",
    "            print(\"The loss history contains NaN values.\")\n",
    "\n",
    "        if np.isinf(loss_history).any():\n",
    "            print(\"The loss history contains Inf values.\")\n",
    "\n",
    "        if len(loss_history) > 0:\n",
    "            if np.isnan(loss_history).any() or np.isinf(loss_history).any():\n",
    "                succeeded = False\n",
    "                seed_train = np.random.randint(1000000)\n",
    "                lr = lr * lr_reduce_factor_on_nan\n",
    "                retry = retry + 1\n",
    "                print(f\"Training failed: trying again with seed {seed_train} and lr {lr}.\")\n",
    "            else:\n",
    "                succeeded = True\n",
    "                print(f\"Training succeeded with seed {seed_train}.\")\n",
    "        else:\n",
    "            succeeded = False\n",
    "            seed_train = np.random.randint(1000000)\n",
    "            lr = lr * lr_reduce_factor_on_nan\n",
    "            retry = retry + 1\n",
    "            print(f\"Training failed: trying again with seed {seed_train} and lr {lr}.\")\n",
    "            \n",
    "        if retry > max_retry:\n",
    "            raise Exception(\"Training failed for the maximum number of retry.\")\n",
    "        \n",
    "    return hyperparams_dict, NFObject, seed_train, training_time # type: ignore\n",
    "    \n",
    "\n",
    "def prediction_function(hyperparams_dict: Dict[str, Any],\n",
    "                        results_dict: Dict[str, Any],\n",
    "                        gpu_models: Optional[List[str]],\n",
    "                        NFObject: Trainer.Trainer,\n",
    "                        ndims: int,\n",
    "                        targ_dist: tfp.distributions.Distribution,\n",
    "                        seed_test: int,\n",
    "                        seed_metrics: int,\n",
    "                        n_iter: int,\n",
    "                        nsamples_test: int,\n",
    "                        n_slices_factor: int,\n",
    "                        dtype: type,\n",
    "                        max_vectorize: int,\n",
    "                        mirror_strategy: bool,\n",
    "                        make_plots: bool,\n",
    "                        path_to_results: str\n",
    "                       ) -> Tuple[Dict[str, Any], GMetrics.TwoSampleTestInputs, int, float]:\n",
    "    start_pred: float = timer()\n",
    "    t_losses_all: list = list(NFObject.history['loss']) # type: ignore\n",
    "    v_losses_all: list = list(NFObject.history['val_loss']) # type: ignore\n",
    "    lr_all: list = list(NFObject.history['lr']) # type: ignore\n",
    "    epochs_output: int = len(t_losses_all)\n",
    "    training_time: float = NFObject.training_time # type: ignore\n",
    "    #try:\n",
    "    print(\"===========\\nComputing predictions\\n===========\\n\")\n",
    "    print(\"Computing metrics...\")\n",
    "    start = timer()\n",
    "    #raise Exception(\"Stopped before test.\")\n",
    "    DataInputs: GMetrics.TwoSampleTestInputs = GMetrics.TwoSampleTestInputs(dist_1_input = targ_dist,\n",
    "                                                                            dist_2_input = NFObject.nf_dist,\n",
    "                                                                            niter = n_iter,\n",
    "                                                                            batch_size = nsamples_test,\n",
    "                                                                            dtype_input = dtype,\n",
    "                                                                            seed_input = seed_metrics,\n",
    "                                                                            use_tf = True,\n",
    "                                                                            mirror_strategy = mirror_strategy,\n",
    "                                                                            verbose = True)\n",
    "    #LRMetric: GMetrics.LRMetric = GMetrics.LRMetric(data_input = DataInputs,\n",
    "    #                                                verbose = True)\n",
    "    KSTest: GMetrics.KSTest = GMetrics.KSTest(data_input = DataInputs,\n",
    "                                              verbose = True)\n",
    "    SWDMetric: GMetrics.SWDMetric = GMetrics.SWDMetric(data_input = DataInputs,\n",
    "                                                       verbose = True)\n",
    "    FNMetric: GMetrics.FNMetric = GMetrics.FNMetric(data_input = DataInputs,\n",
    "                                                    verbose = True)\n",
    "    #LRMetric.compute()\n",
    "    KSTest.compute(max_vectorize = max_vectorize)\n",
    "    SWDMetric.compute(nslices = n_slices_factor*ndims)\n",
    "    FNMetric.compute(max_vectorize = max_vectorize)\n",
    "    #lr_result: Dict[str, np.ndarray] = LRMetric.Results[-1].result_value\n",
    "    logprob_ref_ref_sum_list = None#lr_result[\"logprob_ref_ref_sum_list\"].tolist()\n",
    "    logprob_ref_alt_sum_list = None#lr_result[\"logprob_ref_alt_sum_list\"].tolist()\n",
    "    logprob_alt_alt_sum_list = None#lr_result[\"logprob_alt_alt_sum_list\"].tolist()\n",
    "    lik_ratio_list = None#lr_result[\"lik_ratio_list\"].tolist()\n",
    "    lik_ratio_norm_list = None#lr_result[\"lik_ratio_norm_list\"].tolist()\n",
    "    ks_result: Dict[str, np.ndarray] = KSTest.Results[-1].result_value\n",
    "    ks_lists: List[List[float]] = ks_result[\"statistic_lists\"].tolist()\n",
    "    ks_means: List[float] = ks_result[\"statistic_means\"].tolist()\n",
    "    ks_stds: List[float] = ks_result[\"statistic_stds\"].tolist()\n",
    "    swd_result: Dict[str, np.ndarray] = SWDMetric.Results[-1].result_value\n",
    "    swd_lists: List[List[float]] = swd_result[\"metric_lists\"].tolist()\n",
    "    swd_means: List[float] = swd_result[\"metric_means\"].tolist()\n",
    "    swd_stds: List[float] = swd_result[\"metric_stds\"].tolist()\n",
    "    fn_result: Dict[str, np.ndarray] = FNMetric.Results[-1].result_value\n",
    "    fn_list: List[float] = fn_result[\"metric_list\"].tolist()\n",
    "    ad_lists: Optional[List[List[float]]] = None\n",
    "    ad_means: Optional[List[float]] = None\n",
    "    ad_stds: Optional[List[float]] = None\n",
    "    wd_lists: Optional[List[List[float]]] = None\n",
    "    wd_means: Optional[List[float]] = None\n",
    "    wd_stds: Optional[List[float]] = None\n",
    "    end = timer()\n",
    "    metrics_time = end - start\n",
    "    print(f\"Metrics computed in {metrics_time:.2f} s.\")\n",
    "    #except:\n",
    "    #    try:\n",
    "    #        print(\"===========\\nFailed on GPU, re-trying on CPU\\n===========\\n\")\n",
    "    #        with tf.device('/device:CPU:0'): # type: ignore\n",
    "    #            print(\"Computing metrics...\")\n",
    "    #            start = timer()\n",
    "    #            DataInputs = GMetrics.TwoSampleTestInputs(dist_1_input = targ_dist,\n",
    "    #                                                      dist_2_input = NFObject.nf_dist,\n",
    "    #                                                      niter = n_iter,\n",
    "    #                                                      batch_size = nsamples_test,\n",
    "    #                                                      dtype_input = dtype,\n",
    "    #                                                      seed_input = seed_metrics,\n",
    "    #                                                      use_tf = True,\n",
    "    #                                                      verbose = True)\n",
    "    #            LRMetric = GMetrics.LRMetric(data_input = DataInputs,\n",
    "    #                                         verbose = True)\n",
    "    #            KSTest = GMetrics.KSTest(data_input = DataInputs,\n",
    "    #                                     verbose = True)\n",
    "    #            SWDMetric = GMetrics.SWDMetric(data_input = DataInputs,\n",
    "    #                                           verbose = True)\n",
    "    #            FNMetric = GMetrics.FNMetric(data_input = DataInputs,\n",
    "    #                                         verbose = True)\n",
    "    #            LRMetric.compute()\n",
    "    #            KSTest.compute(max_vectorize = max_vectorize)\n",
    "    #            SWDMetric.compute(nslices = n_slices_factor*ndims)\n",
    "    #            FNMetric.compute(max_vectorize = max_vectorize)\n",
    "    #            lr_result = LRMetric.Results[-1].result_value\n",
    "    #            logprob_ref_ref_sum_list = lr_result[\"logprob_ref_ref_sum_list\"].tolist()\n",
    "    #            logprob_ref_alt_sum_list = lr_result[\"logprob_ref_alt_sum_list\"].tolist()\n",
    "    #            logprob_alt_alt_sum_list = lr_result[\"logprob_alt_alt_sum_list\"].tolist()\n",
    "    #            lik_ratio_list = lr_result[\"lik_ratio_list\"].tolist()\n",
    "    #            lik_ratio_norm_list = lr_result[\"lik_ratio_norm_list\"].tolist()\n",
    "    #            ks_result = KSTest.Results[-1].result_value\n",
    "    #            ks_lists = ks_result[\"statistic_lists\"].tolist()\n",
    "    #            ks_means = ks_result[\"statistic_means\"].tolist()\n",
    "    #            ks_stds = ks_result[\"statistic_stds\"].tolist()\n",
    "    #            swd_result = SWDMetric.Results[-1].result_value\n",
    "    #            swd_lists = swd_result[\"metric_lists\"].tolist()\n",
    "    #            swd_means = swd_result[\"metric_means\"].tolist()\n",
    "    #            swd_stds = swd_result[\"metric_stds\"].tolist()\n",
    "    #            fn_result = FNMetric.Results[-1].result_value\n",
    "    #            fn_list = fn_result[\"metric_list\"].tolist()\n",
    "    #            ad_lists = None\n",
    "    #            ad_means = None\n",
    "    #            ad_stds = None\n",
    "    #            wd_lists = None\n",
    "    #            wd_means = None\n",
    "    #            wd_stds = None\n",
    "    #            end = timer()\n",
    "    #            metrics_time = end - start\n",
    "    #            print(f\"Metrics computed in {metrics_time:.2f} s.\")\n",
    "    #    except:\n",
    "    #        print(\"===========\\nFailed computing metrics\\n===========\\n\")\n",
    "    #        logprob_ref_ref_sum_list = []\n",
    "    #        logprob_ref_alt_sum_list = []\n",
    "    #        logprob_alt_alt_sum_list = []\n",
    "    #        lik_ratio_list = []\n",
    "    #        lik_ratio_norm_list = []\n",
    "    #        ks_means = []\n",
    "    #        ks_stds = []\n",
    "    #        ks_lists = []\n",
    "    #        ad_means = []\n",
    "    #        ad_stds = []\n",
    "    #        ad_lists = []\n",
    "    #        fn_list = []\n",
    "    #        wd_means = []\n",
    "    #        wd_stds = []\n",
    "    #        wd_lists = []\n",
    "    #        swd_means = []\n",
    "    #        swd_stds = []\n",
    "    #        swd_lists = []\n",
    "    #        metrics_time = 0.\n",
    "    if make_plots:\n",
    "        try:\n",
    "            start = timer()\n",
    "            Plotters.train_plotter(t_losses_all,v_losses_all,path_to_results)\n",
    "            X_data_test: tf.Tensor = DataInputs.dist_1_num[:nsamples_test] # type: ignore\n",
    "            X_data_nf: tf.Tensor = DataInputs.dist_2_num[:nsamples_test] # type: ignore\n",
    "            Plotters.cornerplotter(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims,norm=True) # type: ignore\n",
    "            Plotters.marginal_plot(X_data_test.numpy(),X_data_nf.numpy(),path_to_results,ndims) # type: ignore\n",
    "            #Plotters.sample_plotter(X_data_test,nf_dist,path_to_results)\n",
    "            end = timer()\n",
    "            plots_time: float = end - start\n",
    "            print(f\"Plots done in {plots_time:.2f} s.\")\n",
    "        except Exception as ex:\n",
    "            # Get current system exception\n",
    "            ex_type, ex_value, ex_traceback = sys.exc_info()\n",
    "            # Extract unformatter stack traces as tuples\n",
    "            trace_back = traceback.extract_tb(ex_traceback) # type: ignore\n",
    "            # Format stacktrace\n",
    "            stack_trace = list()\n",
    "            for trace in trace_back:\n",
    "                stack_trace.append(\"File : %s , Line : %d, Func.Name : %s, Message : %s\" % (trace[0], trace[1], trace[2], trace[3]))\n",
    "            ex_type_str = f\"Exception type: {ex_type.__name__}\" # type: ignore\n",
    "            print(textwrap.dedent(f\"\"\"\\\n",
    "                ===========\n",
    "                print(\"===========\\nFailed to plot\\n===========\\n\")\n",
    "                {ex_type_str}\n",
    "                Exception message: {ex_value}\n",
    "                Stack trace: {stack_trace}\n",
    "                ===========\n",
    "                \"\"\"))\n",
    "        \n",
    "    end_pred: float = timer()\n",
    "    prediction_time: float = end_pred - start_pred\n",
    "    total_time: float = training_time + prediction_time\n",
    "    results_dict = Utils.update_results_dict(results_dict = results_dict,\n",
    "                                             hyperparams_dict = hyperparams_dict,\n",
    "                                             train_loss_history = t_losses_all,\n",
    "                                             val_loss_history = v_losses_all,\n",
    "                                             lr_history = lr_all,\n",
    "                                             epochs_output = epochs_output,\n",
    "                                             training_time = training_time,\n",
    "                                             prediction_time = prediction_time,\n",
    "                                             total_time = total_time,\n",
    "                                             logprob_ref_ref_sum_list = logprob_ref_ref_sum_list,\n",
    "                                             logprob_ref_alt_sum_list = logprob_ref_alt_sum_list,\n",
    "                                             logprob_alt_alt_sum_list = logprob_alt_alt_sum_list,\n",
    "                                             lik_ratio_list = lik_ratio_list,\n",
    "                                             lik_ratio_norm_list = lik_ratio_norm_list,\n",
    "                                             ks_means = ks_means,\n",
    "                                             ks_stds = ks_stds,\n",
    "                                             ks_lists = ks_lists,\n",
    "                                             ad_means = ad_means,\n",
    "                                             ad_stds = ad_stds,\n",
    "                                             ad_lists = ad_lists,\n",
    "                                             fn_list = fn_list,\n",
    "                                             wd_means = wd_means,\n",
    "                                             wd_stds = wd_stds,\n",
    "                                             wd_lists = wd_lists,\n",
    "                                             swd_means = swd_means,\n",
    "                                             swd_stds = swd_stds,\n",
    "                                             swd_lists = swd_lists\n",
    "                                             )\n",
    "    return results_dict, DataInputs, prediction_time, total_time # type: ignore\n",
    "\n",
    "##############################################################################################\n",
    "################################## Parameters initialization #################################\n",
    "##############################################################################################\n",
    "\n",
    "### Initialize number of components ###\n",
    "ncomp: int = 3\n",
    "\n",
    "### Initialize hyperparameters lists ###\n",
    "ndims_list: List[int] = [4, 8, 16, 32, 64, 100, 200, 400, 1000]\n",
    "nbijectors_list: List[int] = [2]\n",
    "hidden_layers_list: List[List[int]] = [[128, 128, 128], [256, 256, 256]]\n",
    "seeds_list: List[int] = [0, 187, 377, 440, 520, 541, 721, 869, 926, 933]\n",
    "\n",
    "### Initialize nsamples inputs ###\n",
    "nsamples_train: int = 100000\n",
    "nsamples_val: int = 30000\n",
    "nsamples_test: int = 100000\n",
    "\n",
    "### Initialize seeds inputs ###\n",
    "seed_test: int = 0 # overwritten in the loop by seed_train + 1\n",
    "seed_dist: int = 0\n",
    "seed_metrics: int = seed_test\n",
    "\n",
    "### Initialize bijector inputs ###\n",
    "bijector_name: str = 'MsplineN'\n",
    "range_min: int = -16\n",
    "spline_knots_list: List[Union[int,str]] = [8, 12] # Only relevant for the neural spline\n",
    "\n",
    "### Initialize NN hyperparameters ###\n",
    "activation: str = 'relu'\n",
    "regulariser: Optional[str] = None\n",
    "eps_regulariser: float = 0.\n",
    "\n",
    "### Initialzie training hyperparameters ###\n",
    "epochs_input: int = 1\n",
    "batch_size: int = 512\n",
    "nan_threshold: float = 0.01\n",
    "max_retry: int = 10\n",
    "debug_print_mode: bool = True\n",
    "\n",
    "### Initialize optimizer hyperparameters ###\n",
    "lr_orig: float = 0.001\n",
    "\n",
    "### Initialize callbacks hyperparameters ###\n",
    "es_min_delta: float = .0001\n",
    "es_patience: int = 100\n",
    "lr_min_delta: float = .0001\n",
    "lr_patience: int = 50\n",
    "lr_reduce_factor: float = .5\n",
    "lr_reduce_factor_on_nan: float = float(1/3)\n",
    "min_lr: float = 1e-6\n",
    "\n",
    "### Initialize parameters for inference ###\n",
    "n_iter: int = 10\n",
    "n_slices_factor: int = 2\n",
    "dtype: type = tf.float32\n",
    "max_vectorize: int = 10\n",
    "mirror_strategy = True\n",
    "make_plots = True\n",
    "\n",
    "### Initialize old variables for backward compatibility\n",
    "corr: Optional[str] = None\n",
    "\n",
    "### Initialize dictionaries ###\n",
    "results_dict: Dict[str, Any] = Utils.init_results_dict()\n",
    "hyperparams_dict: Dict[str, Any] = Utils.init_hyperparams_dict()\n",
    "\n",
    "### Initialize output dir ###\n",
    "mother_output_dir: str = Utils.define_dir('../../results/MsplineN_new/')\n",
    "\n",
    "### Create 'log' file ####\n",
    "log_file_name: str = Utils.create_log_file(mother_output_dir, results_dict)\n",
    "\n",
    "##############################################################################################\n",
    "####################################### Training loop ########################################\n",
    "##############################################################################################\n",
    "run_to_evaluate = 321\n",
    "run: int = 0\n",
    "run_max: int = 1\n",
    "run_number: int = 0\n",
    "n_runs: int = len(ndims_list) * len(seeds_list) * len(nbijectors_list) * len(spline_knots_list) * len(hidden_layers_list)\n",
    "start_global: float = timer()\n",
    "for ndims in ndims_list:\n",
    "    targ_dist: tfp.distributions.Distribution = MixtureGaussian(ncomp = ncomp, ndims = ndims, seed = seed_dist)\n",
    "    base_dist: tfp.distributions.Distribution = Distributions.gaussians(ndims)\n",
    "    for seed_train in seeds_list:\n",
    "        for nbijectors in nbijectors_list:\n",
    "            for spline_knots in spline_knots_list:\n",
    "                for hidden_layers in hidden_layers_list:\n",
    "                    if run > run_max:\n",
    "                        raise Exception(\"Interrupted after one run.\")\n",
    "                    start_run: float = timer()\n",
    "                    hllabel: str = '-'.join(str(e) for e in hidden_layers)\n",
    "                    run_number = run_number + 1\n",
    "                    results_dict_txt_saved: bool = False\n",
    "                    results_dict_json_saved: bool = False\n",
    "                    results_log_saved: bool = False\n",
    "                    path_to_results: str\n",
    "                    to_run: bool\n",
    "                    path_to_results, to_run = Utils.define_run_dir(mother_output_dir+'run_'+str(run_number)+'/',\n",
    "                                                                   force = \"skip\",\n",
    "                                                                   bkp = False)\n",
    "                    if run_number == run_to_evaluate:\n",
    "                        to_run = True\n",
    "                    if to_run:\n",
    "                        if run_number == run_to_evaluate:\n",
    "                            pass\n",
    "                        else:\n",
    "                            raise Exception(f\"Run different than {run_to_evaluate}. Skipping.\")\n",
    "                        try:\n",
    "                            dummy_file_path: str = os.path.join(path_to_results,'running.txt')\n",
    "                            with open(dummy_file_path, 'w') as f:\n",
    "                                pass\n",
    "                            path_to_weights: str = Utils.define_dir(os.path.join(path_to_results, 'weights'))\n",
    "                            checkpoint_path: str = os.path.join(path_to_weights, 'best_weights.h5')\n",
    "                            ########### Model train ###########\n",
    "                            NFObject: Trainer.Trainer\n",
    "                            hyperparams_dict, NFObject, seed_train, training_time = train_function(seeds = [seed_train, seed_test, seed_dist, seed_metrics],\n",
    "                                                                                                   nsamples = [nsamples_train, nsamples_val, nsamples_test],\n",
    "                                                                                                   run_number = run_number,\n",
    "                                                                                                   base_dist = base_dist,\n",
    "                                                                                                   targ_dist = targ_dist,\n",
    "                                                                                                   hyperparams_dict = hyperparams_dict,\n",
    "                                                                                                   n_runs = n_runs,\n",
    "                                                                                                   ndims = ndims,\n",
    "                                                                                                   bijector_name = bijector_name,\n",
    "                                                                                                   nbijectors = nbijectors,\n",
    "                                                                                                   spline_knots = spline_knots,\n",
    "                                                                                                   range_min = range_min,\n",
    "                                                                                                   hidden_layers = hidden_layers,\n",
    "                                                                                                   batch_size = batch_size,\n",
    "                                                                                                   epochs_input = epochs_input,\n",
    "                                                                                                   lr_orig = lr_orig,\n",
    "                                                                                                   es_min_delta = es_min_delta,\n",
    "                                                                                                   es_patience = es_patience,\n",
    "                                                                                                   lr_reduce_factor = lr_reduce_factor,\n",
    "                                                                                                   lr_min_delta = lr_min_delta,\n",
    "                                                                                                   lr_patience = lr_patience,\n",
    "                                                                                                   min_lr = min_lr,\n",
    "                                                                                                   activation = activation,\n",
    "                                                                                                   regulariser = regulariser,\n",
    "                                                                                                   eps_regulariser = eps_regulariser,\n",
    "                                                                                                   training_device = training_device,\n",
    "                                                                                                   path_to_results = path_to_results,\n",
    "                                                                                                   checkpoint_path = checkpoint_path,\n",
    "                                                                                                   max_retry = max_retry,\n",
    "                                                                                                   debug_print_mode = debug_print_mode,\n",
    "                                                                                                   nan_threshold = nan_threshold)\n",
    "                            \n",
    "                            print(f\"Model trained in {training_time:.2f} s.\\n\") # type: ignore\n",
    "                            ########## Model prediction ###########\n",
    "                            results_dict, DataInputs, prediction_time, total_time = prediction_function(hyperparams_dict = hyperparams_dict,\n",
    "                                                                                                        results_dict = results_dict,\n",
    "                                                                                                        gpu_models = gpu_models,\n",
    "                                                                                                        NFObject = NFObject, # type: ignore\n",
    "                                                                                                        ndims = ndims,\n",
    "                                                                                                        targ_dist = targ_dist,\n",
    "                                                                                                        seed_test = seed_test,\n",
    "                                                                                                        seed_metrics = seed_metrics,\n",
    "                                                                                                        n_iter = n_iter,\n",
    "                                                                                                        nsamples_test = nsamples_test,\n",
    "                                                                                                        n_slices_factor = n_slices_factor,\n",
    "                                                                                                        dtype = dtype,\n",
    "                                                                                                        max_vectorize = max_vectorize,\n",
    "                                                                                                        mirror_strategy = mirror_strategy,\n",
    "                                                                                                        make_plots = make_plots,\n",
    "                                                                                                        path_to_results = path_to_results)\n",
    "                            ########### Save results ###########\n",
    "                            Utils.save_results_current_run_txt(path_to_results, results_dict)\n",
    "                            results_dict_txt_saved = True\n",
    "                            print(\"results.txt saved\")\n",
    "                            Utils.save_results_current_run_json(path_to_results, results_dict)\n",
    "                            results_dict_json_saved = True\n",
    "                            print(\"results.json saved\")\n",
    "                            Utils.save_results_log(log_file_name, results_dict)\n",
    "                            results_log_saved = True\n",
    "                            print(\"Results log saved\")\n",
    "                            print(f\"Model predictions computed in {prediction_time:.2f} s.\")\n",
    "                            end_run: float = timer()\n",
    "                            total_time_run=end_run-start_run\n",
    "                            print(textwrap.dedent(f\"\"\"\\\n",
    "                                ===========\n",
    "                                Run {run_number}/{n_runs} done in {total_time_run:.2f} s.\n",
    "                                ===========\n",
    "                                \"\"\"))\n",
    "                            run = run + 1\n",
    "                            try:\n",
    "                                os.remove(dummy_file_path)\n",
    "                            except:\n",
    "                                pass\n",
    "                            dummy_file_path = os.path.join(path_to_results,'done.txt')\n",
    "                            with open(dummy_file_path, 'w') as f:\n",
    "                                pass\n",
    "                        except Exception as ex:\n",
    "                            try:\n",
    "                                os.remove(dummy_file_path)\n",
    "                            except:\n",
    "                                pass\n",
    "                            # Get current system exception\n",
    "                            ex_type, ex_value, ex_traceback = sys.exc_info()\n",
    "                            # Extract unformatter stack traces as tuples\n",
    "                            trace_back = traceback.extract_tb(ex_traceback) # type: ignore\n",
    "                            # Format stacktrace\n",
    "                            stack_trace = list()\n",
    "                            for trace in trace_back:\n",
    "                                stack_trace.append(\"File : %s , Line : %d, Func.Name : %s, Message : %s\" % (trace[0], trace[1], trace[2], trace[3]))\n",
    "                            if not results_dict_txt_saved:\n",
    "                                results_dict = Utils.update_results_dict(results_dict = results_dict,\n",
    "                                                                         hyperparams_dict = hyperparams_dict)\n",
    "                                Utils.save_results_current_run_txt(path_to_results, results_dict)\n",
    "                            if not results_dict_json_saved:\n",
    "                                Utils.save_results_current_run_json(path_to_results, results_dict)\n",
    "                            if not results_log_saved:\n",
    "                                Utils.save_results_log(log_file_name, results_dict)\n",
    "                            ex_type_str = f\"Exception type: {ex_type.__name__}\" # type: ignore\n",
    "                            print(textwrap.dedent(f\"\"\"\\\n",
    "                                ===========\n",
    "                                Run {run_number}/{n_runs} failed.\n",
    "                                {ex_type_str}\n",
    "                                Exception message: {ex_value}\n",
    "                                Stack trace: {stack_trace}\n",
    "                                ===========\n",
    "                                \"\"\"))\n",
    "                    else:\n",
    "                        print(textwrap.dedent(f\"\"\"\\\n",
    "                            ===========\n",
    "                            Run {run_number}/{n_runs} already exists. Skipping it.\n",
    "                            ===========\n",
    "                            \"\"\"))\n",
    "keys_to_remove = ['ks_lists', 'ad_lists', 'fn_list', 'wd_lists', 'swd_lists', 'train_loss_history', 'val_loss_history', 'lr_history']\n",
    "dict_copy: Dict[str, Any] = {k: v for k, v in results_dict.items() if k not in keys_to_remove}\n",
    "results_frame: pd.DataFrame = pd.DataFrame(dict_copy)\n",
    "results_last_run_file: str = os.path.join(mother_output_dir,'results_last_run.txt')\n",
    "results_frame.to_csv(results_last_run_file,index=False)\n",
    "end_global: float = timer()\n",
    "print(f\"Everything done in {end_global-start_global:.2f} s.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n",
      "Parsing input distribution...\n",
      "Input distribution is a tfp.distributions.Distribution object.\n"
     ]
    }
   ],
   "source": [
    "DataInputs: GMetrics.TwoSampleTestInputs = GMetrics.TwoSampleTestInputs(dist_1_input = targ_dist,\n",
    "                                                                        dist_2_input = NFObject.nf_dist,\n",
    "                                                                        niter = 10,\n",
    "                                                                        batch_size = 100000,\n",
    "                                                                        dtype_input = dtype,\n",
    "                                                                        seed_input = seed_metrics,\n",
    "                                                                        use_tf = True,\n",
    "                                                                        mirror_strategy = True,\n",
    "                                                                        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSTest: GMetrics.KSTest = GMetrics.KSTest(data_input = DataInputs,\n",
    "                                          verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_tf_new(self, max_vectorize: int = 100) -> None:\n",
    "    \"\"\"\n",
    "    Function that computes the Kolmogorov-Smirnov test-statistic and p-value for two samples using tensorflow functions.\n",
    "    The calculation is based in the custom function ks_2samp_tf.\n",
    "    The calculation is performed in batches of size batch_size.\n",
    "    The number of batches is niter.\n",
    "    The total number of samples is niter*batch_size.\n",
    "    The calculation is parallelized over max_vectorize (out of ndims*niter).\n",
    "    The results are stored in the Results attribute.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    max_vectorize: int, optional, default = 100\n",
    "        A maximum number of batch_size*max_vectorize samples per time are processed by the tensorflow backend.\n",
    "        Given a value of max_vectorize, the ndims*niter KS calculations are split in chunks of max_vectorize.\n",
    "        Each chunk is processed by the tensorflow backend in parallel. If ndims is larger than max_vectorize,\n",
    "        the calculation is vectorized niter times over ndims.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    max_vectorize = int(max_vectorize)\n",
    "    # Set alias for inputs\n",
    "    if isinstance(self.Inputs.dist_1_num, np.ndarray):\n",
    "        dist_1_num: tf.Tensor = tf.convert_to_tensor(self.Inputs.dist_1_num)\n",
    "    else:\n",
    "        dist_1_num = self.Inputs.dist_1_num # type: ignore\n",
    "    if isinstance(self.Inputs.dist_2_num, np.ndarray):\n",
    "        dist_2_num: tf.Tensor = tf.convert_to_tensor(self.Inputs.dist_2_num)\n",
    "    else:\n",
    "        dist_2_num = self.Inputs.dist_2_num # type: ignore\n",
    "    if isinstance(self.Inputs.dist_1_symb, tfp.distributions.Distribution):\n",
    "        dist_1_symb: tfp.distributions.Distribution = self.Inputs.dist_1_symb\n",
    "    else:\n",
    "        raise ValueError(\"dist_1_symb must be a tfp.distributions.Distribution object when use_tf is True.\")\n",
    "    if isinstance(self.Inputs.dist_2_symb, tfp.distributions.Distribution):\n",
    "        dist_2_symb: tfp.distributions.Distribution = self.Inputs.dist_2_symb\n",
    "    else:\n",
    "        raise ValueError(\"dist_2_symb must be a tfp.distributions.Distribution object when use_tf is True.\")\n",
    "    ndims: int = self.Inputs.ndims\n",
    "    niter: int\n",
    "    batch_size: int\n",
    "    niter, batch_size = [int(i) for i in self.get_niter_batch_size_tf()] # type: ignore\n",
    "    dtype: tf.DType = tf.as_dtype(self.Inputs.dtype)\n",
    "    seed: int = self.Inputs.seed\n",
    "    \n",
    "    # Utility functions\n",
    "    def start_calculation() -> None:\n",
    "        GMetrics.utils.conditional_tf_print(self.verbose, \"\\n------------------------------------------\")\n",
    "        GMetrics.utils.conditional_tf_print(self.verbose, \"Starting KS tests calculation...\")\n",
    "        GMetrics.utils.conditional_tf_print(self.verbose, \"Running TF KS tests...\")\n",
    "        GMetrics.utils.conditional_tf_print(self.verbose, \"niter =\", niter)\n",
    "        GMetrics.utils.conditional_tf_print(self.verbose, \"batch_size =\", batch_size)\n",
    "        self._start = timer()\n",
    "\n",
    "    def end_calculation() -> None:\n",
    "        self._end = timer()\n",
    "        elapsed = self.end - self.start\n",
    "        GMetrics.utils.conditional_tf_print(self.verbose, \"KS tests calculation completed in\", str(elapsed), \"seconds.\")\n",
    "        \n",
    "    def set_dist_num_from_symb(dist,\n",
    "                               nsamples: int,\n",
    "                               seed: int = 0\n",
    "                              ) -> tf.Tensor:\n",
    "        nonlocal dtype\n",
    "        #dist_num: tf.Tensor = tf.cast(dist.sample(nsamples, seed = int(seed)), dtype = dtype) # type: ignore\n",
    "        dist_num: tf.Tensor = GMetrics.utils.generate_and_clean_data(dist, nsamples, 1000, dtype = self.Inputs.dtype, seed = int(seed), mirror_strategy = True) # type: ignore\n",
    "        return dist_num\n",
    "    \n",
    "    def return_dist_num(dist_num: tf.Tensor) -> tf.Tensor:\n",
    "        return dist_num\n",
    "    \n",
    "    #@tf.function(experimental_compile=True)\n",
    "    #@tf.function(reduce_retracing=True)\n",
    "    def batched_test(start, end):\n",
    "        GMetrics.utils.conditional_tf_print(tf.logical_and(tf.logical_or(tf.math.logical_not(tf.equal(start,0)),tf.math.logical_not(tf.equal(end,niter))), self.verbose), \"Iterating from\", start, \"to\", end, \"out of\", niter, \".\")\n",
    "        # Define unique constants for the two distributions. It is sufficient that these two are different to get different samples from the two distributions, if they are equal. \n",
    "        # There is not problem with subsequent calls to the batched_test function, since the random state is updated at each call.\n",
    "        seed_dist_1  = int(1e6)  # Seed for distribution 1\n",
    "        seed_dist_2  = int(1e12)  # Seed for distribution 2\n",
    "        \n",
    "        # Define batched distributions\n",
    "        dist_1_k: tf.Tensor = tf.cond(tf.equal(tf.shape(dist_1_num[0])[0],0), # type: ignore\n",
    "                                           true_fn = lambda: set_dist_num_from_symb(dist_1_symb, nsamples = batch_size*(end-start), seed = seed_dist_1),\n",
    "                                           false_fn = lambda: return_dist_num(dist_1_num[start*batch_size:end*batch_size, :])) # type: ignore\n",
    "        dist_2_k: tf.Tensor = tf.cond(tf.equal(tf.shape(dist_1_num[0])[0],0), # type: ignore\n",
    "                                           true_fn = lambda: set_dist_num_from_symb(dist_2_symb, nsamples = batch_size*(end-start), seed = seed_dist_2),\n",
    "                                           false_fn = lambda: return_dist_num(dist_2_num[start*batch_size:end*batch_size, :])) # type: ignore\n",
    "        \n",
    "        print(\"dist_1_k shape:\", tf.shape(dist_1_k))\n",
    "        print(\"Target shape:\", (end-start, batch_size, ndims))\n",
    "        \n",
    "        dist_1_k = tf.reshape(dist_1_k, (end-start, batch_size, ndims))\n",
    "        dist_2_k = tf.reshape(dist_2_k, (end-start, batch_size, ndims))\n",
    "        # Define the loop body function\n",
    "        def loop_body(args):\n",
    "            idx1 = args[0]\n",
    "            idx2 = args[1]\n",
    "            metric, pvalue, _, _ = GMetrics.ks_metrics.ks_2samp_tf(dist_1_k[idx1, :, idx2], dist_2_k[idx1, :, idx2], verbose=False) # type: ignore\n",
    "            metric = tf.cast(metric, dtype=dtype)\n",
    "            pvalue = tf.cast(pvalue, dtype=dtype)\n",
    "            return metric, pvalue\n",
    "        \n",
    "        # Create the range of indices for both loops\n",
    "        indices = tf.stack(tf.meshgrid(tf.range(end-start), tf.range(ndims), indexing='ij'), axis=-1)\n",
    "        indices = tf.reshape(indices, [-1, 2])\n",
    "        \n",
    "        # Use tf.vectorized_map to iterate over the indices\n",
    "        statistic_lists, pvalue_lists = tf.vectorized_map(loop_body, indices) # type: ignore\n",
    "        \n",
    "        # Reshape the results back to (chunk_size, ndims)\n",
    "        statistic_lists = tf.reshape(statistic_lists, (end-start, ndims))\n",
    "        pvalue_lists = tf.reshape(pvalue_lists, (end-start, ndims))\n",
    "\n",
    "        # Compute the mean values\n",
    "        statistic_means = tf.cast(tf.reduce_mean(statistic_lists, axis=1), dtype=dtype)\n",
    "        statistic_stds = tf.cast(tf.math.reduce_std(statistic_lists, axis=1), dtype=dtype)\n",
    "        pvalue_means = tf.cast(tf.reduce_mean(pvalue_lists, axis=1), dtype=dtype)\n",
    "        pvalue_stds = tf.cast(tf.math.reduce_std(pvalue_lists, axis=1), dtype=dtype)\n",
    "        \n",
    "        statistic_means = tf.expand_dims(statistic_means, axis=1)\n",
    "        statistic_stds = tf.expand_dims(statistic_stds, axis=1)\n",
    "        pvalue_means = tf.expand_dims(pvalue_means, axis=1)\n",
    "        pvalue_stds = tf.expand_dims(pvalue_stds, axis=1)\n",
    "        \n",
    "        res = tf.concat([statistic_means, statistic_stds, statistic_lists, pvalue_means, pvalue_stds, pvalue_lists], axis=1)\n",
    "    \n",
    "        return res\n",
    "\n",
    "    #@tf.function(experimental_compile=True)\n",
    "    #@tf.function(reduce_retracing=True)\n",
    "    def compute_test(max_vectorize: int = 100) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "        # Check if numerical distributions are empty and print a warning if so\n",
    "        GMetrics.utils.conditional_tf_print(tf.logical_and(tf.equal(tf.shape(dist_1_num[0])[0],0),self.verbose), \"The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.\") # type: ignore\n",
    "        GMetrics.utils.conditional_tf_print(tf.logical_and(tf.equal(tf.shape(dist_1_num[0])[0],0),self.verbose), \"The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.\") # type: ignore\n",
    "        \n",
    "        # Ensure that max_vectorize is an integer larger than ndims\n",
    "        max_vectorize = int(tf.cast(tf.maximum(max_vectorize, ndims),tf.int32)) # type: ignore\n",
    "\n",
    "        # Compute the maximum number of iterations per chunk\n",
    "        max_iter_per_chunk: int = int(tf.cast(tf.math.floor(max_vectorize / ndims), tf.int32)) # type: ignore\n",
    "\n",
    "        # Compute the number of chunks\n",
    "        nchunks: int = int(tf.cast(tf.math.ceil(niter / max_iter_per_chunk), tf.int32)) # type: ignore\n",
    "        GMetrics.utils.conditional_tf_print(tf.logical_and(self.verbose,tf.logical_not(tf.equal(nchunks,1))), \"nchunks =\", nchunks)\n",
    "        \n",
    "        # Run the computation in chunks\n",
    "        # Initialize the result TensorArray\n",
    "        res = tf.TensorArray(dtype, size = nchunks)\n",
    "        statistic_means = tf.TensorArray(dtype, size = nchunks)\n",
    "        statistic_stds = tf.TensorArray(dtype, size = nchunks)\n",
    "        statistic_lists = tf.TensorArray(dtype, size = nchunks)\n",
    "        pvalue_means = tf.TensorArray(dtype, size = nchunks)\n",
    "        pvalue_stds = tf.TensorArray(dtype, size = nchunks)\n",
    "        pvalue_lists = tf.TensorArray(dtype, size = nchunks)\n",
    "\n",
    "        def body(i, res):\n",
    "            start = i * max_iter_per_chunk\n",
    "            end = tf.minimum(start + max_iter_per_chunk, niter)\n",
    "            chunk_result = batched_test(start, end) # type: ignore\n",
    "            res = res.write(i, chunk_result)\n",
    "            return i+1, res\n",
    "\n",
    "        _, res = tf.while_loop(lambda i, res: i < nchunks, body, [0, res])\n",
    "        \n",
    "        for i in range(nchunks):\n",
    "            res_i = res.read(i)\n",
    "            statistic_means = statistic_means.write(i, res_i[:,0])\n",
    "            statistic_stds = statistic_stds.write(i, res_i[:,1])\n",
    "            statistic_lists = statistic_lists.write(i, res_i[:,2:2+ndims])\n",
    "            pvalue_means = pvalue_means.write(i, res_i[:,2+ndims])\n",
    "            pvalue_stds = pvalue_stds.write(i, res_i[:,3+ndims])\n",
    "            pvalue_lists = pvalue_lists.write(i, res_i[:,4+ndims:])\n",
    "            \n",
    "        statistic_means_stacked = tf.reshape(statistic_means.stack(), (niter,))\n",
    "        statistic_stds_stacked = tf.reshape(statistic_stds.stack(), (niter,))\n",
    "        statistic_lists_stacked = tf.reshape(statistic_lists.stack(), (niter, ndims))\n",
    "        pvalue_means_stacked = tf.reshape(pvalue_means.stack(), (niter,))\n",
    "        pvalue_stds_stacked = tf.reshape(pvalue_stds.stack(), (niter,))\n",
    "        pvalue_lists_stacked = tf.reshape(pvalue_lists.stack(), (niter, ndims))\n",
    "        \n",
    "        return statistic_means_stacked, statistic_stds_stacked, statistic_lists_stacked, pvalue_means_stacked, pvalue_stds_stacked, pvalue_lists_stacked\n",
    "            \n",
    "    start_calculation()\n",
    "    \n",
    "    Utils.reset_random_seeds(seed = seed)\n",
    "    \n",
    "    statistic_means, statistic_stds, statistic_lists, pvalue_means, pvalue_stds, pvalue_lists = compute_test(max_vectorize = max_vectorize) # type: ignore\n",
    "                         \n",
    "    end_calculation()\n",
    "    \n",
    "    timestamp: str = datetime.now().isoformat()\n",
    "    test_name: str = \"KS Test_np\"\n",
    "    parameters = {**self.param_dict, **{\"backend\": \"tensorflow\"}}\n",
    "    result_value = {\"statistic_lists\": statistic_lists.numpy(),\n",
    "                    \"statistic_means\": statistic_means.numpy(),\n",
    "                    \"statistic_stds\": statistic_stds.numpy(),\n",
    "                    \"pvalue_lists\": pvalue_lists.numpy(),\n",
    "                    \"pvalue_means\": pvalue_means.numpy(),\n",
    "                    \"pvalue_stds\": pvalue_stds.numpy()}\n",
    "    result = TwoSampleTestResult(timestamp, test_name, parameters, result_value) # type: ignore\n",
    "    self.Results.append(result)\n",
    "KSTest.Test_tf = Test_tf_new.__get__(KSTest, GMetrics.KSTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting KS tests calculation...\n",
      "Running TF KS tests...\n",
      "niter = 10\n",
      "batch_size = 100000\n",
      "The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.\n",
      "The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.\n",
      "nchunks = 10\n",
      "Iterating from 0 to 1 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "dist_1_k shape: tf.Tensor([100000   1000], shape=(2,), dtype=int32)\n",
      "Target shape: (<tf.Tensor: shape=(), dtype=int32, numpy=1>, 100000, 1000)\n",
      "Iterating from 1 to 2 out of 10 .\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "KSTest.Test_tf(max_vectorize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Starting KS tests calculation...\n",
      "Running TF KS tests...\n",
      "niter = 10\n",
      "batch_size = 10000\n",
      "Warning: Batch size larger than number of samples. Setting batch size to Tensor(\"cond_1/mul:0\", shape=(), dtype=int32)\n",
      "Warning: Batch size larger than number of samples. Setting batch size to Tensor(\"cond_2/mul:0\", shape=(), dtype=int32)\n",
      "Tensor(\"mul:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Shape_2:0\", shape=(2,), dtype=int32)\n",
      "The dist_1_num tensor is empty. Batches will be generated 'on-the-fly' from dist_1_symb.\n",
      "The dist_2_num tensor is empty. Batches will be generated 'on-the-fly' from dist_2_symb.\n",
      "Iterating from 0 to 1 out of 10 .\n",
      "nchunks = 10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Reshape' defined at (most recent call last):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_40791/1059454068.py\", line 1, in <module>\n      KSTest.compute(max_vectorize = 1)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 425, in compute\n      self.Test_tf(max_vectorize = max_vectorize)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 736, in Test_tf\n      statistic_means, statistic_stds, statistic_lists, pvalue_means, pvalue_stds, pvalue_lists = compute_test(max_vectorize = max_vectorize) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 712, in compute_test\n      _, res = tf.while_loop(lambda i, res: i < nchunks, body, [0, res])\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 708, in body\n      chunk_result = batched_test(start, end) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 640, in batched_test\n      dist_1_k = tf.reshape(dist_1_k, (end-start, batch_size, ndims))\nNode: 'Reshape'\nDetected at node 'Reshape' defined at (most recent call last):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_40791/1059454068.py\", line 1, in <module>\n      KSTest.compute(max_vectorize = 1)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 425, in compute\n      self.Test_tf(max_vectorize = max_vectorize)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 736, in Test_tf\n      statistic_means, statistic_stds, statistic_lists, pvalue_means, pvalue_stds, pvalue_lists = compute_test(max_vectorize = max_vectorize) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 712, in compute_test\n      _, res = tf.while_loop(lambda i, res: i < nchunks, body, [0, res])\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 708, in body\n      chunk_result = batched_test(start, end) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 640, in batched_test\n      dist_1_k = tf.reshape(dist_1_k, (end-start, batch_size, ndims))\nNode: 'Reshape'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 990100000 values, but the requested shape has 10000000\n\t [[{{node Reshape}}]]\n\t [[while/LoopCond/_96/_38]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 990100000 values, but the requested shape has 10000000\n\t [[{{node Reshape}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_compute_test_488001]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m KSTest\u001b[39m.\u001b[39;49mcompute(max_vectorize \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py:425\u001b[0m, in \u001b[0;36mKSTest.compute\u001b[0;34m(self, max_vectorize)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39mFunction that computes the Kolmogorov-Smirnov test-statistic and p-value for two samples\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mselecting among the Test_np and Test_tf methods depending on the use_tf attribute.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_tf:\n\u001b[0;32m--> 425\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mTest_tf(max_vectorize \u001b[39m=\u001b[39;49m max_vectorize)\n\u001b[1;32m    426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTest_np()\n",
      "File \u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py:736\u001b[0m, in \u001b[0;36mKSTest.Test_tf\u001b[0;34m(self, max_vectorize)\u001b[0m\n\u001b[1;32m    732\u001b[0m start_calculation()\n\u001b[1;32m    734\u001b[0m reset_random_seeds(seed \u001b[39m=\u001b[39m seed)\n\u001b[0;32m--> 736\u001b[0m statistic_means, statistic_stds, statistic_lists, pvalue_means, pvalue_stds, pvalue_lists \u001b[39m=\u001b[39m compute_test(max_vectorize \u001b[39m=\u001b[39;49m max_vectorize) \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    738\u001b[0m end_calculation()\n\u001b[1;32m    740\u001b[0m timestamp: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39misoformat()\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Reshape' defined at (most recent call last):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_40791/1059454068.py\", line 1, in <module>\n      KSTest.compute(max_vectorize = 1)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 425, in compute\n      self.Test_tf(max_vectorize = max_vectorize)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 736, in Test_tf\n      statistic_means, statistic_stds, statistic_lists, pvalue_means, pvalue_stds, pvalue_lists = compute_test(max_vectorize = max_vectorize) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 712, in compute_test\n      _, res = tf.while_loop(lambda i, res: i < nchunks, body, [0, res])\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 708, in body\n      chunk_result = batched_test(start, end) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 640, in batched_test\n      dist_1_k = tf.reshape(dist_1_k, (end-start, batch_size, ndims))\nNode: 'Reshape'\nDetected at node 'Reshape' defined at (most recent call last):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_40791/1059454068.py\", line 1, in <module>\n      KSTest.compute(max_vectorize = 1)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 425, in compute\n      self.Test_tf(max_vectorize = max_vectorize)\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 736, in Test_tf\n      statistic_means, statistic_stds, statistic_lists, pvalue_means, pvalue_stds, pvalue_lists = compute_test(max_vectorize = max_vectorize) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 712, in compute_test\n      _, res = tf.while_loop(lambda i, res: i < nchunks, body, [0, res])\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 708, in body\n      chunk_result = batched_test(start, end) # type: ignore\n    File \"/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/GenerativeModelsMetrics/ks_metrics.py\", line 640, in batched_test\n      dist_1_k = tf.reshape(dist_1_k, (end-start, batch_size, ndims))\nNode: 'Reshape'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 990100000 values, but the requested shape has 10000000\n\t [[{{node Reshape}}]]\n\t [[while/LoopCond/_96/_38]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 990100000 values, but the requested shape has 10000000\n\t [[{{node Reshape}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_compute_test_488001]"
     ]
    }
   ],
   "source": [
    "KSTest.compute(max_vectorize = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Batch size too large. Halving batch size to 50 and retrying.\n",
      "Warning: Batch size too large. Halving batch size to 25 and retrying.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m prova \u001b[39m=\u001b[39m Utils\u001b[39m.\u001b[39;49mgenerate_and_clean_data(KSTest\u001b[39m.\u001b[39;49mInputs\u001b[39m.\u001b[39;49mdist_2_input,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                                       \u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                                       \u001b[39m100\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                                       dtype \u001b[39m=\u001b[39;49m KSTest\u001b[39m.\u001b[39;49mInputs\u001b[39m.\u001b[39;49mdtype, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                                       seed \u001b[39m=\u001b[39;49m \u001b[39mint\u001b[39;49m(KSTest\u001b[39m.\u001b[39;49mInputs\u001b[39m.\u001b[39;49mseed), \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bteogpu02.ge.infn.it/home/rtorre/teo_fs/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/Interactive-1.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                                       mirror_strategy \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m) \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/Utils.py:619\u001b[0m, in \u001b[0;36mgenerate_and_clean_data\u001b[0;34m(dist, n_samples, batch_size, dtype, seed, mirror_strategy)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[39mreturn\u001b[39;00m generate_and_clean_data_simple(dist, n_samples, batch_size, dtype, seed)\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m generate_and_clean_data_simple(dist, n_samples, batch_size, dtype, seed)\n",
      "File \u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/Utils.py:541\u001b[0m, in \u001b[0;36mgenerate_and_clean_data_simple\u001b[0;34m(dist, n_samples, batch_size, dtype, seed)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mwhile\u001b[39;00m total_samples \u001b[39m<\u001b[39m n_samples:\n\u001b[1;32m    540\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m         batch \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39;49msample(batch_size, seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    543\u001b[0m         \u001b[39m# Find finite values\u001b[39;00m\n\u001b[1;32m    544\u001b[0m         finite_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_all(tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mis_finite(batch), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[39mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[39m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_sample_n(sample_shape, seed, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py:338\u001b[0m, in \u001b[0;36m_TransformedDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_broadcast_distribution_batch_shape()\u001b[39m.\u001b[39msample(\n\u001b[1;32m    334\u001b[0m     sample_shape\u001b[39m=\u001b[39msample_shape, seed\u001b[39m=\u001b[39mseed, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdistribution_kwargs)\n\u001b[1;32m    335\u001b[0m \u001b[39m# Apply the bijector's forward transformation. For caching to\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[39m# work, it is imperative that this is the last modification to the\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m# returned result.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbijector\u001b[39m.\u001b[39;49mforward(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbijector_kwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/bijector.py:1326\u001b[0m, in \u001b[0;36mBijector.forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1311\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the forward `Bijector` evaluation, i.e., X = g(Y).\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \n\u001b[1;32m   1313\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39m    NotImplementedError: if `_forward` is not implemented.\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_forward(x, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/bijector.py:1308\u001b[0m, in \u001b[0;36mBijector._call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1308\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache\u001b[39m.\u001b[39;49mforward(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:334\u001b[0m, in \u001b[0;36mBijectorCache.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    324\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Invokes the 'forward' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m    The output of the bijector's `_forward` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lookup(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[39m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[39m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[39m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke(\u001b[39minput\u001b[39;49m, forward_name, kwargs, attrs))\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[39m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[39m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbijector, fn_name)(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/composition.py:605\u001b[0m, in \u001b[0;36mComposition._forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 605\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_walk_forward(\n\u001b[1;32m    606\u001b[0m       \u001b[39mlambda\u001b[39;49;00m b, x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs: b\u001b[39m.\u001b[39;49mforward(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    607\u001b[0m       x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/composition.py:290\u001b[0m, in \u001b[0;36mComposition._call_walk_forward\u001b[0;34m(self, step_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(nest_util\u001b[39m.\u001b[39mcoerce_structure(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_min_event_ndims, x)\n\u001b[1;32m    287\u001b[0m              \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m args)\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 290\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_walk_forward(step_fn, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    292\u001b[0m \u001b[39m# Convert a tuple of structures to a structure of tuples. This\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39m# allows `_walk` methods to route aligned structures of inputs/outputs\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39m# independently, obviates the need for conditional tuple unpacking.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m packed_args \u001b[39m=\u001b[39m pack_structs_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_min_event_ndims, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/chain.py:143\u001b[0m, in \u001b[0;36m_Chain._walk_forward\u001b[0;34m(self, step_fn, x, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Applies `transform_fn` to `x` sequentially over nested bijectors.\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m bij \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijectors):\n\u001b[0;32m--> 143\u001b[0m   x \u001b[39m=\u001b[39m step_fn(bij, x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(bij\u001b[39m.\u001b[39;49mname, {}))\n\u001b[1;32m    144\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/composition.py:606\u001b[0m, in \u001b[0;36mComposition._forward.<locals>.<lambda>\u001b[0;34m(b, x, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_walk_forward(\n\u001b[0;32m--> 606\u001b[0m       \u001b[39mlambda\u001b[39;00m b, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: b\u001b[39m.\u001b[39;49mforward(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    607\u001b[0m       x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/bijector.py:1326\u001b[0m, in \u001b[0;36mBijector.forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1311\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the forward `Bijector` evaluation, i.e., X = g(Y).\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \n\u001b[1;32m   1313\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39m    NotImplementedError: if `_forward` is not implemented.\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_forward(x, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/bijector.py:1308\u001b[0m, in \u001b[0;36mBijector._call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1308\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache\u001b[39m.\u001b[39;49mforward(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:334\u001b[0m, in \u001b[0;36mBijectorCache.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    324\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Invokes the 'forward' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m    The output of the bijector's `_forward` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lookup(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[39m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[39m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[39m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke(\u001b[39minput\u001b[39;49m, forward_name, kwargs, attrs))\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[39m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[39m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbijector, fn_name)(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/MAF_spline.py:347\u001b[0m, in \u001b[0;36mMaskedAutoregressiveFlow._forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m   y \u001b[39m=\u001b[39m bijector\u001b[39m.\u001b[39mforward(x)\n\u001b[1;32m    346\u001b[0m   \u001b[39mreturn\u001b[39;00m (y,)\n\u001b[0;32m--> 347\u001b[0m (y,) \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m    348\u001b[0m     cond\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m _: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    349\u001b[0m     body\u001b[39m=\u001b[39;49m_loop_body,\n\u001b[1;32m    350\u001b[0m     loop_vars\u001b[39m=\u001b[39;49m(y0,),\n\u001b[1;32m    351\u001b[0m     maximum_iterations\u001b[39m=\u001b[39;49mevent_size)\n\u001b[1;32m    352\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:648\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    641\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    642\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    643\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m\n\u001b[1;32m    647\u001b[0m             (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[0;32m--> 648\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2574\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2368\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2369\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2370\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2385\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2386\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2387\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2388\u001b[0m \n\u001b[1;32m   2389\u001b[0m \u001b[39m  Note: This op is automatically used in a `tf.function` to convert Python for-\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2572\u001b[0m \n\u001b[1;32m   2573\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2574\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[1;32m   2575\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m   2576\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m   2577\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[1;32m   2578\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2579\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2580\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m   2581\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m   2582\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2583\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2584\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2823\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2820\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m   2821\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[1;32m   2822\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[0;32m-> 2823\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[1;32m   2824\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[1;32m   2825\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2814\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     loop_vars \u001b[39m=\u001b[39m (counter, loop_vars)\n\u001b[1;32m   2812\u001b[0m     cond \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m   2813\u001b[0m         math_ops\u001b[39m.\u001b[39mlogical_and(i \u001b[39m<\u001b[39m maximum_iterations, orig_cond(\u001b[39m*\u001b[39mlv)))\n\u001b[0;32m-> 2814\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, orig_body(\u001b[39m*\u001b[39;49mlv))\n\u001b[1;32m   2815\u001b[0m   try_to_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2817\u001b[0m \u001b[39mif\u001b[39;00m executing_eagerly:\n",
      "File \u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/MAF_spline.py:345\u001b[0m, in \u001b[0;36mMaskedAutoregressiveFlow._forward.<locals>._loop_body\u001b[0;34m(y0)\u001b[0m\n\u001b[1;32m    342\u001b[0m     vs\u001b[39m.\u001b[39mset_caching_device(\u001b[39mlambda\u001b[39;00m op: op\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    343\u001b[0m   bijector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijector_fn(y0, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 345\u001b[0m y \u001b[39m=\u001b[39m bijector\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m    346\u001b[0m \u001b[39mreturn\u001b[39;00m (y,)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/bijector.py:1326\u001b[0m, in \u001b[0;36mBijector.forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1311\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the forward `Bijector` evaluation, i.e., X = g(Y).\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \n\u001b[1;32m   1313\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39m    NotImplementedError: if `_forward` is not implemented.\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_forward(x, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/bijectors/bijector.py:1308\u001b[0m, in \u001b[0;36mBijector._call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1308\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache\u001b[39m.\u001b[39;49mforward(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:334\u001b[0m, in \u001b[0;36mBijectorCache.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    324\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Invokes the 'forward' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m    The output of the bijector's `_forward` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lookup(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[39m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[39m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[39m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke(\u001b[39minput\u001b[39;49m, forward_name, kwargs, attrs))\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[39m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[39m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbijector, fn_name)(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/project_mnt/teo_fs/rtorre/cernbox/git/GitHub/NormalizingFlows/NF4HEP/NormalizingFlowsHD/CMoG/Mains/MsplineN/../../../code/RQS.py:320\u001b[0m, in \u001b[0;36mRationalQuadraticSpline._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    317\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_shared(x\u001b[39m=\u001b[39mx)\n\u001b[1;32m    318\u001b[0m relx \u001b[39m=\u001b[39m (x \u001b[39m-\u001b[39m d\u001b[39m.\u001b[39mx_k) \u001b[39m/\u001b[39m d\u001b[39m.\u001b[39mw_k\n\u001b[1;32m    319\u001b[0m spline_val \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 320\u001b[0m     d\u001b[39m.\u001b[39my_k \u001b[39m+\u001b[39m ((d\u001b[39m.\u001b[39mh_k \u001b[39m*\u001b[39m (d\u001b[39m.\u001b[39ms_k \u001b[39m*\u001b[39m relx\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m d\u001b[39m.\u001b[39md_k \u001b[39m*\u001b[39m relx \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m relx))) \u001b[39m/\u001b[39m\n\u001b[1;32m    321\u001b[0m              (d\u001b[39m.\u001b[39ms_k \u001b[39m+\u001b[39m (d\u001b[39m.\u001b[39md_kp1 \u001b[39m+\u001b[39m d\u001b[39m.\u001b[39md_k \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m d\u001b[39m.\u001b[39ms_k) \u001b[39m*\u001b[39m relx \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m relx))))\n\u001b[1;32m    323\u001b[0m \u001b[39m#print(spline_val)\u001b[39;00m\n\u001b[1;32m    324\u001b[0m y_val \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mwhere(d\u001b[39m.\u001b[39mout_of_bounds, x, spline_val)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py:1494\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.r_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39mNone\u001b[39;00m, op_name, [x, y]) \u001b[39mas\u001b[39;00m name:\n\u001b[1;32m   1491\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m   y, x \u001b[39m=\u001b[39m maybe_promote_tensors(y, x, force_same_dtype\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1494\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py:549\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.subtract\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msubtract\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[1;32m    547\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msubtract\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 549\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49msub(x, y, name)\n",
      "File \u001b[0;32m/local_data/scratch/rtorre/anaconda3/envs/tf2_12/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py:11342\u001b[0m, in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  11340\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m  11341\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m> 11342\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m  11343\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mSub\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y)\n\u001b[1;32m  11344\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m  11345\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prova = Utils.generate_and_clean_data(KSTest.Inputs.dist_2_input,\n",
    "                                      1000,\n",
    "                                      100, \n",
    "                                      dtype = KSTest.Inputs.dtype, \n",
    "                                      seed = int(KSTest.Inputs.seed), \n",
    "                                      mirror_strategy = False) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50, 1000), dtype=float32, numpy=\n",
       "array([[8.051592 , 4.5737743, 4.9140997, ..., 3.57656  , 7.913433 ,\n",
       "        6.203442 ],\n",
       "       [6.7708473, 5.3443394, 5.3992977, ..., 4.2715263, 6.98471  ,\n",
       "        6.9213696],\n",
       "       [8.160212 , 4.7832146, 5.2080464, ..., 3.6006298, 8.060825 ,\n",
       "        7.019944 ],\n",
       "       ...,\n",
       "       [8.28524  , 4.652333 , 5.267612 , ..., 3.6960063, 8.3304825,\n",
       "        6.7796307],\n",
       "       [5.8332796, 5.9626746, 5.3240795, ..., 8.798139 , 4.5733037,\n",
       "        6.8851285],\n",
       "       [5.393865 , 3.2084398, 5.251758 , ..., 4.878972 , 5.1827655,\n",
       "        6.6090274]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KSTest.Inputs.dist_2_input.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
       "array([[ 6.45104170e+00,  1.68934059e+00,  5.01805258e+00,\n",
       "         7.11854696e+00,  5.76389253e-01,  9.02331448e+00,\n",
       "         5.01788568e+00,  5.07622242e-01,  2.07638168e+00,\n",
       "         8.33012295e+00,  6.10408020e+00,  1.38044083e+00,\n",
       "         3.54392028e+00,  5.45957899e+00, -1.15596056e-01,\n",
       "         3.42731190e+00,  4.72251320e+00,  3.81470037e+00,\n",
       "         7.34879112e+00,  7.59150076e+00,  2.12879753e+00,\n",
       "         7.82541275e+00,  6.29458618e+00,  1.01701736e+01,\n",
       "         7.47314453e+00,  8.11322021e+00,  5.59832859e+00,\n",
       "         1.58839810e+00,  9.29706287e+00,  9.39323127e-01,\n",
       "         5.16181564e+00,  1.39245522e+00,  8.82531452e+00,\n",
       "         9.59433365e+00,  7.20421886e+00,  3.93652034e+00,\n",
       "         3.03527951e+00,  3.04610515e+00,  1.38380134e+00,\n",
       "         5.32061338e+00,  8.41667414e-01,  2.74513292e+00,\n",
       "         6.29477310e+00,  7.28790236e+00,  2.07620144e-01,\n",
       "         4.20255184e+00,  6.27298069e+00,  8.37334728e+00,\n",
       "         4.70837975e+00,  9.26613998e+00,  1.50833631e+00,\n",
       "         4.76337045e-01,  5.07351685e+00,  2.78293061e+00,\n",
       "         8.32910442e+00,  1.54371107e+00,  2.73847580e+00,\n",
       "         7.91024256e+00,  6.23745823e+00,  6.31514835e+00,\n",
       "         6.83591652e+00,  3.38129258e+00,  1.41080379e-01,\n",
       "        -4.28795099e-01,  5.56695080e+00,  1.30911410e+00,\n",
       "         1.27872491e+00,  9.34905910e+00,  8.68422985e+00,\n",
       "         1.67423666e+00,  6.09319687e-01,  9.49194717e+00,\n",
       "         3.56167936e+00,  2.44828558e+00,  7.54625511e+00,\n",
       "         9.50682402e-01,  2.69374466e+00,  9.78614712e+00,\n",
       "         6.53995037e+00,  6.09298229e+00,  4.69448566e+00,\n",
       "         7.77908897e+00,  2.47539330e+00,  9.53529644e+00,\n",
       "         8.60847950e+00,  6.11364841e+00,  2.63176322e+00,\n",
       "         5.38819504e+00,  7.98664808e+00,  5.41430330e+00,\n",
       "         3.05926466e+00,  1.26123118e+00,  7.44059181e+00,\n",
       "         9.09374905e+00,  1.33886600e+00,  5.67982817e+00,\n",
       "         1.52363658e+00,  9.69463921e+00,  5.51879072e+00,\n",
       "         5.59850454e+00,  3.69618607e+00,  8.99806881e+00,\n",
       "         3.92061782e+00,  8.36124325e+00,  1.06178379e+01,\n",
       "         7.71579933e+00,  5.45730352e+00, -4.24905062e-01,\n",
       "         4.83666420e+00,  4.35293865e+00,  2.78932023e+00,\n",
       "         4.12453651e+00,  3.79436088e+00,  3.09155750e+00,\n",
       "         4.81970310e+00,  2.25055456e+00,  6.01842928e+00,\n",
       "         9.09264147e-01,  1.00294170e+01,  7.96356964e+00,\n",
       "         6.11064386e+00,  8.53032589e+00,  9.69761658e+00,\n",
       "         1.16774178e+00,  5.40706635e+00,  9.83122253e+00,\n",
       "         8.71125412e+00,  6.57384253e+00,  1.38782394e+00,\n",
       "         6.72887421e+00,  4.07376766e-01,  1.88029683e+00,\n",
       "         1.04059887e+01,  4.06847811e+00,  6.08200264e+00,\n",
       "         3.89517403e+00,  9.70489597e+00,  8.14825821e+00,\n",
       "         3.01721263e+00,  8.07004356e+00,  4.88597691e-01,\n",
       "         3.09752083e+00,  2.25734854e+00,  8.52107334e+00,\n",
       "         1.95788753e+00,  4.70435524e+00,  2.25190878e+00,\n",
       "         6.68853569e+00,  2.54186058e+00,  7.41354465e+00,\n",
       "        -7.80915499e-01,  4.95633459e+00,  1.91745305e+00,\n",
       "         2.61183977e+00,  9.62833214e+00,  9.41681099e+00,\n",
       "         3.14877915e+00,  8.25933838e+00,  5.32542229e-01,\n",
       "         5.59887314e+00,  7.81399536e+00,  1.63688445e+00,\n",
       "         3.97954917e+00,  9.06693554e+00,  1.18499947e+00,\n",
       "         5.61239868e-02,  6.10128546e+00,  5.15100288e+00,\n",
       "         7.88320923e+00,  8.72025776e+00,  3.52763367e+00,\n",
       "         3.98903322e+00,  4.24789715e+00,  5.63088512e+00,\n",
       "         9.87948418e+00,  6.19990015e+00,  3.94162917e+00,\n",
       "         2.56453943e+00,  9.51158142e+00,  1.19366169e+00,\n",
       "         6.06080627e+00,  9.04307175e+00,  5.58542061e+00,\n",
       "         4.39308119e+00,  2.55099869e+00,  3.56690264e+00,\n",
       "         6.59712458e+00,  6.49199772e+00,  9.88888168e+00,\n",
       "         7.58807039e+00,  8.28092766e+00,  8.67587566e+00,\n",
       "         2.67403269e+00,  4.13293743e+00,  3.83764744e+00,\n",
       "         5.67204428e+00,  6.71797180e+00,  2.87614202e+00,\n",
       "        -8.23786259e-02,  3.85315561e+00,  4.04492950e+00,\n",
       "         9.19095135e+00,  9.05679512e+00,  9.19673538e+00,\n",
       "         6.58987474e+00,  3.74156618e+00,  6.60415888e+00,\n",
       "         8.65007496e+00,  5.59618473e-01,  8.29234695e+00,\n",
       "         9.71090734e-01,  7.97956800e+00,  8.08297539e+00,\n",
       "         8.66864026e-01,  6.17553616e+00,  6.31836510e+00,\n",
       "         2.39478731e+00,  1.48649907e+00,  7.34461880e+00,\n",
       "         6.36809921e+00,  8.83650780e+00,  9.58562469e+00,\n",
       "         1.03684578e+01,  6.11920357e-02,  9.58682442e+00,\n",
       "         2.52421355e+00,  5.57628441e+00,  7.80130672e+00,\n",
       "         2.25885105e+00,  5.57672501e+00,  1.11312604e+00,\n",
       "         9.00677025e-01,  1.69221091e+00,  3.26267648e+00,\n",
       "         7.09376335e-02,  4.32162666e+00,  7.50797844e+00,\n",
       "         4.33931684e+00,  7.91408539e-01,  1.51403284e+00,\n",
       "         2.63294959e+00,  2.43937635e+00,  1.07616577e+01,\n",
       "         2.02181149e+00,  7.77593374e+00,  5.77342272e+00,\n",
       "         5.76484680e+00,  4.42026806e+00,  9.68565178e+00,\n",
       "         2.70253181e+00,  7.87986040e+00,  6.20634842e+00,\n",
       "         4.56614876e+00,  1.03679638e+01,  6.30196428e+00,\n",
       "         1.47446620e+00,  4.87095737e+00,  7.64213276e+00,\n",
       "         6.72875023e+00,  8.02897644e+00,  2.71238184e+00,\n",
       "         8.46885490e+00,  3.67346954e+00,  5.13272858e+00,\n",
       "         9.68196869e+00,  9.87466812e+00,  8.46732426e+00,\n",
       "         4.31082153e+00,  8.71364784e+00,  6.85851288e+00,\n",
       "         4.49092197e+00,  5.08038759e-01,  7.33920002e+00,\n",
       "         5.04412317e+00,  8.07083702e+00,  7.84373093e+00,\n",
       "         7.77228689e+00,  3.15267944e+00,  7.00727367e+00,\n",
       "         5.43929768e+00,  4.36804676e+00,  6.68149137e+00,\n",
       "         7.49111176e-03,  1.57267284e+00,  3.01939154e+00,\n",
       "         9.45692062e+00,  1.28138590e+00,  2.91087723e+00,\n",
       "         7.78907061e-01,  3.35997343e+00,  4.25311708e+00,\n",
       "         1.00529385e+01,  8.09978294e+00,  4.08816481e+00,\n",
       "         1.80204153e+00,  8.86967564e+00,  6.54897213e+00,\n",
       "         1.86312580e+00,  9.75230598e+00,  1.37468958e+00,\n",
       "         7.90376329e+00,  3.14189315e+00,  4.40242338e+00,\n",
       "         7.52672243e+00,  7.87042570e+00,  9.67307568e+00,\n",
       "         6.32371235e+00,  1.03841662e+00,  8.71571732e+00,\n",
       "         8.09744072e+00,  7.14809895e+00,  4.10114706e-01,\n",
       "         3.32685018e+00,  1.82907724e+00,  9.62167263e+00,\n",
       "         6.53992748e+00,  9.52212620e+00,  9.99307442e+00,\n",
       "         7.47051716e+00,  9.96524143e+00,  6.21935463e+00,\n",
       "         4.89786178e-01, -6.95772648e-01,  3.35648203e+00,\n",
       "         8.30202484e+00,  9.39432144e+00,  1.03912983e+01,\n",
       "         6.67632222e-01,  2.05207849e+00,  8.96729660e+00,\n",
       "         2.89966822e+00,  5.48586750e+00,  1.00138769e+01,\n",
       "         3.85658908e+00,  7.07037210e+00,  3.90300918e+00,\n",
       "         7.71702957e+00,  4.83690453e+00,  2.71773148e+00,\n",
       "         1.53234839e+00,  2.62633181e+00,  5.67452049e+00,\n",
       "         6.20368433e+00,  9.46740913e+00,  7.57722855e+00,\n",
       "         6.86456871e+00,  1.98711836e+00,  3.92518353e+00,\n",
       "         3.40363169e+00,  6.49408627e+00,  3.11093688e+00,\n",
       "         2.52264309e+00,  3.41308475e+00,  6.17430019e+00,\n",
       "         5.56379795e+00,  7.23205030e-01,  8.76945198e-01,\n",
       "         2.83634639e+00,  7.87715626e+00,  7.87912273e+00,\n",
       "         7.24127150e+00,  7.79438114e+00,  3.07725024e+00,\n",
       "         6.27808809e+00,  6.96178198e+00,  8.64445210e+00,\n",
       "         1.00811310e+01,  2.59247732e+00,  8.02824688e+00,\n",
       "         6.59050369e+00,  7.09327030e+00,  8.24930859e+00,\n",
       "         9.45166683e+00,  2.96322823e-01,  1.33462262e+00,\n",
       "         7.87097549e+00,  5.29647350e-01,  4.61950684e+00,\n",
       "         3.36587310e+00,  3.23737764e+00,  7.54878330e+00,\n",
       "         6.46247268e-01,  8.59140301e+00,  4.45108461e+00,\n",
       "         4.99655724e+00,  5.49564314e+00,  6.57662439e+00,\n",
       "         4.47629070e+00,  1.49447966e+00,  4.04208946e+00,\n",
       "         1.74214268e+00,  5.45697975e+00,  3.12674665e+00,\n",
       "         9.60343361e+00,  9.63460255e+00,  6.69575453e+00,\n",
       "         5.49342060e+00,  8.80421257e+00,  8.86985493e+00,\n",
       "         6.64185858e+00,  3.28229165e+00,  3.67227960e+00,\n",
       "         2.42105770e+00,  6.91991138e+00,  9.93704224e+00,\n",
       "         9.16404915e+00,  1.31545055e+00,  1.44661105e+00,\n",
       "         8.99639320e+00,  5.01919317e+00,  1.54330885e+00,\n",
       "         6.29301071e+00,  6.62598705e+00,  1.35124421e+00,\n",
       "         2.96159101e+00,  1.15228307e+00,  2.11598754e+00,\n",
       "         2.19470406e+00,  1.93184185e+00,  6.99575806e+00,\n",
       "         3.65045547e-01,  1.18853617e+00,  2.06128836e+00,\n",
       "         3.10082531e+00,  3.01127768e+00,  3.13377786e+00,\n",
       "         7.76568413e+00,  9.52373028e+00,  5.77034473e+00,\n",
       "         9.84943199e+00,  3.94874310e+00,  1.52188885e+00,\n",
       "         4.14870310e+00,  2.04325223e+00,  5.16381884e+00,\n",
       "         6.16005325e+00,  4.65419960e+00,  1.06103296e+01,\n",
       "         9.23182869e+00,  6.70369196e+00,  3.83474135e+00,\n",
       "         1.13171792e+00,  3.74208069e+00,  7.03478146e+00,\n",
       "         1.83121538e+00,  6.47359610e-01,  8.65339088e+00,\n",
       "         6.90676451e+00,  7.19393253e+00,  8.40206814e+00,\n",
       "         8.60757542e+00,  4.65523720e+00,  7.91823912e+00,\n",
       "         9.60979080e+00,  3.26980662e+00,  5.75720930e+00,\n",
       "         5.77825832e+00,  5.00156689e+00,  8.86124611e+00,\n",
       "         3.73762989e+00,  9.69886017e+00,  8.91684914e+00,\n",
       "         4.22085619e+00,  7.93091488e+00,  8.40397644e+00,\n",
       "         5.54742098e+00,  2.02564001e+00,  4.26828003e+00,\n",
       "         6.47143936e+00,  8.00483704e+00,  3.39612961e-02,\n",
       "         6.61062479e+00,  5.06870556e+00,  8.61270142e+00,\n",
       "         3.07121038e+00,  6.37635612e+00,  5.23265123e+00,\n",
       "         1.40767193e+00,  6.04636574e+00,  7.97699165e+00,\n",
       "         2.59546041e-01,  2.70787668e+00,  9.00768816e-01,\n",
       "         9.27331734e+00,  6.06389713e+00,  9.85362339e+00,\n",
       "         5.92959595e+00,  7.62449360e+00,  4.38300991e+00,\n",
       "         3.70542812e+00,  3.89115524e+00,  7.02412271e+00,\n",
       "         3.47571468e+00,  9.11459827e+00,  1.03783445e+01,\n",
       "         4.03371453e-02,  2.01355028e+00,  7.22043514e-01,\n",
       "         6.53621614e-01,  1.95081294e+00,  5.11172009e+00,\n",
       "         8.11897850e+00,  2.49019051e+00,  3.87411189e+00,\n",
       "         8.63496017e+00,  6.65836525e+00,  1.08780727e+01,\n",
       "         5.09475899e+00,  9.79083729e+00,  5.88009071e+00,\n",
       "         8.77555847e-01,  1.31531632e+00,  4.16723347e+00,\n",
       "         6.70523643e+00,  7.63235664e+00,  4.79638577e+00,\n",
       "         6.76924133e+00,  8.48102951e+00,  3.98687387e+00,\n",
       "         9.66138935e+00,  7.06757927e+00,  8.25541878e+00,\n",
       "         6.03338623e+00,  7.51708794e+00,  8.77189732e+00,\n",
       "         9.87199688e+00,  7.42763042e-01,  5.08543730e+00,\n",
       "         4.13986158e+00,  8.91458225e+00,  8.70360315e-01,\n",
       "         9.00314713e+00,  8.20055485e+00,  7.03424692e-01,\n",
       "         5.06551456e+00,  7.20596218e+00,  6.95266056e+00,\n",
       "         9.65545464e+00,  8.24279022e+00,  2.05870152e+00,\n",
       "         4.92198086e+00,  6.85157347e+00,  3.24930906e+00,\n",
       "         1.80972624e+00,  4.13947248e+00,  3.55054235e+00,\n",
       "         8.11475468e+00,  6.63229752e+00,  3.80741405e+00,\n",
       "         8.54735088e+00,  7.99073553e+00,  1.08348923e+01,\n",
       "         8.54869270e+00,  4.12107229e+00,  1.37483907e+00,\n",
       "         9.50659084e+00, -2.64492989e-01,  2.89673376e+00,\n",
       "         8.72722530e+00,  1.04949684e+01,  6.34014893e+00,\n",
       "         6.37193871e+00,  8.46246004e-01,  4.76701975e+00,\n",
       "         4.36371708e+00,  3.46058750e+00,  1.06307805e+00,\n",
       "         3.06153321e+00,  3.36081100e+00,  3.14561749e+00,\n",
       "         5.81384802e+00,  7.50610685e+00,  2.75624466e+00,\n",
       "         3.14096475e+00,  4.67341721e-01,  3.30855560e+00,\n",
       "         2.53882813e+00,  7.37272310e+00,  5.61030006e+00,\n",
       "         8.68383789e+00,  7.86251402e+00,  8.63739872e+00,\n",
       "         6.96489191e+00,  9.53471279e+00,  9.10446739e+00,\n",
       "         4.85374165e+00,  4.70582294e+00, -8.11425328e-01,\n",
       "         9.21060944e+00,  1.52947962e+00,  7.47683239e+00,\n",
       "         8.56767750e+00,  4.69408607e+00,  1.74383783e+00,\n",
       "         1.58738184e+00,  8.74910355e+00,  4.45733404e+00,\n",
       "         7.12861443e+00,  9.06619930e+00,  1.77267778e+00,\n",
       "         9.06070042e+00,  3.59044290e+00,  3.06680393e+00,\n",
       "         9.19952774e+00,  9.86649323e+00,  2.08651924e+00,\n",
       "         6.99516821e+00,  1.37131619e+00,  6.70525408e+00,\n",
       "         7.95979118e+00,  7.08460474e+00,  4.03905964e+00,\n",
       "         3.88609886e+00,  3.73646688e+00,  4.99081516e+00,\n",
       "         8.98002815e+00,  9.30258465e+00,  9.32055831e-01,\n",
       "         2.38465595e+00,  1.95356059e+00,  1.89753461e+00,\n",
       "         4.63942099e+00,  5.61027479e+00,  6.63417959e+00,\n",
       "         8.82052326e+00,  8.70103550e+00,  1.02106600e+01,\n",
       "         6.79762173e+00,  8.53739929e+00,  6.81543636e+00,\n",
       "         2.08070326e+00,  9.36980438e+00,  2.17668295e-01,\n",
       "        -3.79745752e-01,  2.61120176e+00,  4.21790600e+00,\n",
       "         5.87815332e+00,  1.14643073e+00,  7.03407955e+00,\n",
       "         8.29889011e+00,  1.83080482e+00,  3.57023287e+00,\n",
       "         4.87789822e+00,  4.61263943e+00,  7.71042395e+00,\n",
       "         9.62118912e+00,  7.73998117e+00,  8.16578865e-01,\n",
       "         7.65189648e+00,  1.79275012e+00,  2.34528875e+00,\n",
       "         1.81846881e+00,  2.47376037e+00,  5.62483120e+00,\n",
       "         6.69119692e+00,  5.05285454e+00,  9.57820511e+00,\n",
       "         2.06460166e+00,  7.73478937e+00,  8.59443474e+00,\n",
       "         5.30543184e+00,  4.86033440e+00,  6.72880888e+00,\n",
       "         4.76598549e+00,  5.59228420e+00,  4.59336901e+00,\n",
       "         4.24432278e+00,  6.78628159e+00,  6.18015766e-01,\n",
       "         1.45986962e+00,  9.03226376e+00,  7.54425621e+00,\n",
       "         2.74202752e+00,  3.25736403e+00,  9.03429413e+00,\n",
       "         7.68897676e+00,  6.21484470e+00,  2.32538414e+00,\n",
       "         8.06514859e-01,  4.32092953e+00,  6.57204103e+00,\n",
       "         7.93491459e+00,  8.96354961e+00,  2.30982780e-01,\n",
       "         2.39166999e+00,  3.22030950e+00,  2.11649227e+00,\n",
       "         7.93213987e+00,  8.05738831e+00,  5.10485744e+00,\n",
       "         9.78596401e+00,  1.06105709e+00,  9.84799862e+00,\n",
       "         1.19687963e+00,  8.62022996e-01,  6.88600683e+00,\n",
       "         1.20244265e+00,  4.87451172e+00,  2.35682964e+00,\n",
       "         7.28436708e+00,  8.57376671e+00,  7.25556517e+00,\n",
       "         1.03842735e+01,  4.46038485e-01,  3.10531712e+00,\n",
       "         5.16805553e+00,  5.56516552e+00,  2.31775475e+00,\n",
       "         2.51311111e+00,  9.43317795e+00,  3.36390257e+00,\n",
       "         3.65442824e+00,  1.49545240e+00,  9.02779770e+00,\n",
       "         1.74481416e+00,  2.29772949e+00,  2.87186909e+00,\n",
       "         8.78504372e+00,  2.06095958e+00,  8.31429195e+00,\n",
       "         7.78651667e+00,  9.55245113e+00, -4.79288340e-01,\n",
       "         2.73761129e+00,  8.36125278e+00,  1.94986987e+00,\n",
       "         3.65420532e+00,  1.53787518e+00,  1.32061410e+00,\n",
       "         4.77294683e+00,  1.34513533e+00,  3.19482040e+00,\n",
       "         4.21640396e+00,  7.21012130e-02,  5.67875481e+00,\n",
       "         8.80166590e-01,  6.42364120e+00,  8.53392696e+00,\n",
       "         7.94186020e+00,  9.66517150e-01,  5.94220686e+00,\n",
       "         8.41599178e+00,  2.26693225e+00,  7.60425138e+00,\n",
       "         9.35294724e+00,  8.09887886e+00,  2.38684154e+00,\n",
       "         1.83376551e-01,  2.06243134e+00,  2.96190143e+00,\n",
       "         5.56613398e+00,  3.55985880e+00,  6.70129204e+00,\n",
       "         3.49232650e+00,  2.64353991e+00,  3.77654290e+00,\n",
       "         8.86527634e+00,  9.75634956e+00,  1.99688125e+00,\n",
       "         8.45552254e+00,  2.70879626e+00,  9.07742691e+00,\n",
       "         1.91699815e+00,  5.83220673e+00,  6.78129911e-01,\n",
       "         9.71551991e+00,  6.84815979e+00,  8.44269466e+00,\n",
       "         6.02934074e+00,  4.68242311e+00,  6.24013281e+00,\n",
       "         5.29284048e+00,  4.17224789e+00,  6.41791677e+00,\n",
       "         2.35995913e+00,  1.56135559e+00,  4.33281517e+00,\n",
       "         3.83993030e+00,  7.20191121e-01,  8.42590523e+00,\n",
       "         7.68093681e+00,  5.62455368e+00,  9.66716290e+00,\n",
       "         6.45284653e-01,  7.22660398e+00,  2.27179790e+00,\n",
       "         3.60967636e+00,  4.24630165e+00,  8.73124218e+00,\n",
       "         1.44851208e+00,  7.58265972e+00,  5.98454046e+00,\n",
       "         1.00932384e+00,  8.17786026e+00,  5.29625511e+00,\n",
       "         9.58284664e+00,  7.10684586e+00,  5.62850523e+00,\n",
       "         8.53944302e+00,  3.84009790e+00,  5.10618210e+00,\n",
       "         1.67927027e+00,  1.05121193e+01,  1.93575120e+00,\n",
       "         1.28399777e+00,  3.24880600e+00,  4.73274851e+00,\n",
       "         5.31720400e-01,  7.82682323e+00,  8.32897186e+00,\n",
       "         6.97032738e+00,  6.86940193e+00,  9.54746151e+00,\n",
       "         9.53182602e+00,  8.30999851e+00,  6.28140593e+00,\n",
       "         4.80946970e+00,  1.31902456e-01,  5.80272102e+00,\n",
       "         9.51810455e+00,  8.14310646e+00,  3.29955244e+00,\n",
       "         1.45537102e+00,  9.12463570e+00,  7.53004932e+00,\n",
       "         1.00348682e+01,  8.65079308e+00,  5.59475040e+00,\n",
       "         5.92905045e-01,  5.37406015e+00,  3.23517442e+00,\n",
       "         5.00492048e+00,  2.33722162e+00,  8.51166916e+00,\n",
       "         9.17784786e+00,  3.72120619e+00,  6.62085962e+00,\n",
       "         4.38472414e+00,  8.46876335e+00,  1.79856467e+00,\n",
       "         7.22983170e+00,  1.00846825e+01,  1.09293246e+00,\n",
       "         7.68969357e-01,  6.74539900e+00,  7.72859478e+00,\n",
       "         4.09814453e+00,  5.69218302e+00,  2.53750896e+00,\n",
       "         4.88041639e+00,  5.60362577e-01,  4.05542946e+00,\n",
       "         2.78579855e+00,  4.04944658e+00,  1.04166584e+01,\n",
       "         1.69139791e+00,  4.00689220e+00,  6.83829308e+00,\n",
       "         9.77968788e+00,  9.72486734e-01,  9.20894146e+00,\n",
       "         1.13213563e+00,  3.67970181e+00,  4.30496597e+00,\n",
       "         1.85547626e+00,  3.40269780e+00,  3.11997604e+00,\n",
       "         8.70955658e+00,  1.09525938e+01,  5.20516062e+00,\n",
       "         8.46438313e+00,  5.75658560e+00,  3.39415717e+00,\n",
       "         2.11012077e+00,  4.26413059e+00,  6.36625004e+00,\n",
       "         2.69171476e-01,  6.57155514e-01,  5.64993954e+00,\n",
       "         1.60014844e+00,  8.26118279e+00,  4.18410206e+00,\n",
       "         6.83994055e-01,  5.56200266e-01,  1.02659798e+01,\n",
       "         1.64629245e+00,  1.97080374e+00,  7.33754253e+00,\n",
       "         2.43517089e+00,  6.34200859e+00,  8.14798260e+00,\n",
       "         5.99481249e+00,  8.33391762e+00,  7.05877352e+00,\n",
       "         1.19645739e+00,  6.02284336e+00,  6.24812031e+00,\n",
       "         8.46639442e+00,  1.02942705e-01,  7.35536814e+00,\n",
       "         5.89682388e+00,  6.95999908e+00,  4.97007370e+00,\n",
       "         4.65440083e+00,  4.97041607e+00,  6.59819794e+00,\n",
       "         9.26990700e+00,  5.77582073e+00,  8.90606308e+00,\n",
       "         5.79952145e+00, -7.04013824e-01,  3.93843293e+00,\n",
       "         2.72730017e+00,  2.89592075e+00,  3.47864604e+00,\n",
       "         3.65916157e+00,  5.60128975e+00,  7.60122347e+00,\n",
       "         2.51813245e+00,  6.16572142e-01,  6.27328634e-01,\n",
       "         6.13022470e+00,  1.72150075e+00, -4.81583595e-01,\n",
       "         9.19860554e+00,  4.59223223e+00,  4.51346874e-01,\n",
       "         7.69721508e+00,  1.10146790e+01,  3.92799306e+00,\n",
       "         2.83929050e-01,  1.00765693e+00,  3.16012120e+00,\n",
       "         8.54007435e+00,  1.47677886e+00,  8.29460907e+00,\n",
       "        -1.20721102e-01,  4.19465160e+00,  6.35078716e+00,\n",
       "         5.48022389e-01,  6.60953426e+00,  9.86563969e+00,\n",
       "         1.85661399e+00,  6.76249170e+00,  6.02341175e+00,\n",
       "         1.12250042e+00,  1.25928879e-01,  5.18088818e-01,\n",
       "         4.36861038e+00,  8.28714275e+00,  6.47552204e+00,\n",
       "         7.42741776e+00,  5.04818153e+00,  5.59114456e+00,\n",
       "         1.48505116e+00,  8.72912121e+00,  7.19239902e+00,\n",
       "         9.92549419e+00,  2.78149986e+00,  4.73526764e+00,\n",
       "         3.74929667e-01,  9.37472534e+00,  8.15118027e+00,\n",
       "         3.39739299e+00,  5.38402891e+00,  4.04538918e+00,\n",
       "         1.79128242e+00,  1.97288918e+00,  9.61602879e+00,\n",
       "         3.03124905e+00,  8.94831085e+00,  4.06275272e-01,\n",
       "         5.79794979e+00,  1.44046855e+00, -2.60810614e-01,\n",
       "         6.03385925e+00,  1.56735587e+00,  6.90303373e+00,\n",
       "         6.18855476e+00,  1.94423366e+00,  9.81892586e+00,\n",
       "         6.57769775e+00,  3.01148176e+00,  6.31553602e+00,\n",
       "         7.05468082e+00,  2.85888910e+00,  4.05546951e+00,\n",
       "         4.51663256e+00,  6.11877537e+00,  8.98851299e+00,\n",
       "         1.24549913e+00,  8.69534874e+00,  4.06424999e-02,\n",
       "         6.51211548e+00,  4.33908272e+00,  7.59412098e+00,\n",
       "         7.54557323e+00,  5.17244673e+00,  6.33224773e+00,\n",
       "         4.67657757e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KSTest.Inputs.dist_2_input.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
